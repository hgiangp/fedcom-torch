test_train
['f_00000', 'f_00001', 'f_00002', 'f_00003', 'f_00004']
5
dict_keys(['x', 'y'])
len(train_data['y'] = 171
len(test_data['y']) = 43
id = 0, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
)
pretrain_params =
{'linear.weight': tensor([[-0.0203,  0.0203, -0.3645, -0.3918, -0.3331],
        [-0.0477,  0.2286,  0.3181,  0.1731, -0.4126],
        [ 0.0572, -0.1803, -0.0776, -0.1285, -0.4035]]), 'linear.bias': tensor([ 0.2214, -0.3931, -0.2305])}
Epoch 1
-------------------------------
loss: -0.355189  [    0/  171]
loss: -0.393570  [   32/  171]
loss: -0.245105  [   64/  171]
loss: -0.556083  [   96/  171]
loss: -0.586590  [  128/  171]
loss: -0.515568  [   55/  171]
Epoch 2
-------------------------------
loss: -0.455870  [    0/  171]
loss: -0.338374  [   32/  171]
loss: -0.598895  [   64/  171]
loss: -0.485818  [   96/  171]
loss: -0.678968  [  128/  171]
loss: -0.394894  [   55/  171]
Epoch 3
-------------------------------
loss: -0.504632  [    0/  171]
loss: -0.513932  [   32/  171]
loss: -0.533036  [   64/  171]
loss: -0.585821  [   96/  171]
loss: -0.608234  [  128/  171]
loss: -0.897816  [   55/  171]
Epoch 4
-------------------------------
loss: -0.701855  [    0/  171]
loss: -0.731272  [   32/  171]
loss: -0.747959  [   64/  171]
loss: -0.551177  [   96/  171]
loss: -0.553809  [  128/  171]
loss: -0.227056  [   55/  171]
Epoch 5
-------------------------------
loss: -0.617581  [    0/  171]
loss: -0.564863  [   32/  171]
loss: -0.811809  [   64/  171]
loss: -0.636227  [   96/  171]
loss: -0.708989  [  128/  171]
loss: -0.655457  [   55/  171]
Done!
pretrain_params =
{'linear.weight': tensor([[-0.0203,  0.0203, -0.3645, -0.3918, -0.3331],
        [-0.0477,  0.2286,  0.3181,  0.1731, -0.4126],
        [ 0.0572, -0.1803, -0.0776, -0.1285, -0.4035]]), 'linear.bias': tensor([ 0.2214, -0.3931, -0.2305])}
posttrain_params =
{'linear.weight': tensor([[-0.1224,  0.0692, -0.2720, -0.3257, -0.2666],
        [-0.0583,  0.2067,  0.2792,  0.1305, -0.4518],
        [ 0.1698, -0.2073, -0.1311, -0.1520, -0.4308]]), 'linear.bias': tensor([ 0.1565, -0.3648, -0.1939])}
##########################
##########################
['f_00000', 'f_00001', 'f_00002', 'f_00003', 'f_00004']
5
dict_keys(['x', 'y'])
len(train_data['y'] = 110
len(test_data['y']) = 28
id = 1, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
)
pretrain_params2 =
{'linear.weight': tensor([[-0.0203,  0.0203, -0.3645, -0.3918, -0.3331],
        [-0.0477,  0.2286,  0.3181,  0.1731, -0.4126],
        [ 0.0572, -0.1803, -0.0776, -0.1285, -0.4035]]), 'linear.bias': tensor([ 0.2214, -0.3931, -0.2305])}
Epoch 1
-------------------------------
loss: -1.221667  [    0/  110]
loss: -1.207888  [   32/  110]
loss: -1.215336  [   64/  110]
loss: -1.170740  [   42/  110]
Epoch 2
-------------------------------
loss: -1.198821  [    0/  110]
loss: -1.237787  [   32/  110]
loss: -1.236095  [   64/  110]
loss: -1.230004  [   42/  110]
Epoch 3
-------------------------------
loss: -1.237340  [    0/  110]
loss: -1.239324  [   32/  110]
loss: -1.236537  [   64/  110]
loss: -1.244579  [   42/  110]
Epoch 4
-------------------------------
loss: -1.235674  [    0/  110]
loss: -1.269087  [   32/  110]
loss: -1.254920  [   64/  110]
loss: -1.212425  [   42/  110]
Epoch 5
-------------------------------
loss: -1.240034  [    0/  110]
loss: -1.254384  [   32/  110]
loss: -1.274008  [   64/  110]
loss: -1.250468  [   42/  110]
Done!
posttrain_params2 =
{'linear.weight': tensor([[-0.0101,  0.0367, -0.3732, -0.4988, -0.2869],
        [-0.0497,  0.2211,  0.3199,  0.2087, -0.4283],
        [ 0.0489, -0.1892, -0.0707, -0.0572, -0.4340]]), 'linear.bias': tensor([ 0.2732, -0.4105, -0.2649])}
client.get_params() =
{'linear.weight': tensor([[-0.1224,  0.0692, -0.2720, -0.3257, -0.2666],
        [-0.0583,  0.2067,  0.2792,  0.1305, -0.4518],
        [ 0.1698, -0.2073, -0.1311, -0.1520, -0.4308]]), 'linear.bias': tensor([ 0.1565, -0.3648, -0.1939])}
