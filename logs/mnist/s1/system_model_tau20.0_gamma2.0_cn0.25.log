Arguments:
	      dataset : mnist
	learning_rate : 0.01
	        model : mclr
	 model_params : (784, 10)
	        optim : 1
	      sce_idx : 1
	          tau : 20.0
	    xi_factor : 1.0
['f_00000', 'f_00001', 'f_00002', 'f_00003', 'f_00004', 'f_00005', 'f_00006', 'f_00007', 'f_00008', 'f_00009']
10
dict_keys(['x', 'y'])
id = f_00000, model = <class 'flearn.models.mnist.mclr.Model'>, device = cuda, num_samples = 523
id = f_00001, model = <class 'flearn.models.mnist.mclr.Model'>, device = cuda, num_samples = 516
id = f_00002, model = <class 'flearn.models.mnist.mclr.Model'>, device = cuda, num_samples = 580
id = f_00003, model = <class 'flearn.models.mnist.mclr.Model'>, device = cuda, num_samples = 496
id = f_00004, model = <class 'flearn.models.mnist.mclr.Model'>, device = cuda, num_samples = 536
id = f_00005, model = <class 'flearn.models.mnist.mclr.Model'>, device = cuda, num_samples = 783
id = f_00006, model = <class 'flearn.models.mnist.mclr.Model'>, device = cuda, num_samples = 672
id = f_00007, model = <class 'flearn.models.mnist.mclr.Model'>, device = cuda, num_samples = 1107
id = f_00008, model = <class 'flearn.models.mnist.mclr.Model'>, device = cuda, num_samples = 695
id = f_00009, model = <class 'flearn.models.mnist.mclr.Model'>, device = cuda, num_samples = 976
BaseFederated generated!
num_samples = [ 523  516  580  496  536  783  672 1107  695  976]
msize = 300240
xs = [-280.  400. -385. -350. -200. -100.  400. -180.  500.  425.]
ys = [-300.  355. -400.  455.  385.  335.   60. -200.   10.  385.]
dists_uav = [714.702735 261.199158 858.268606 606.403331 444.100214 336.489227 274.954542 575.152154 379.605058 296.395007]
uav_gains = [5.494875e-13 1.802536e-11 3.593089e-13 8.081917e-13 1.762643e-12 4.643011e-12 1.366745e-11 9.167988e-13 2.857829e-12 8.947599e-12]
dists_bs = [ 344.093011  943.941206  397.775062 1017.116021  907.317475  840.966706  688.186021  349.857114  714.212853  981.758626]
bs_gains = [3.619341e-11 2.495838e-12 2.464796e-11 2.047806e-12 2.771778e-12 3.389665e-12 5.766337e-12 3.463460e-11 5.226094e-12 2.249096e-12]
v = 34.18803418803419 a_0 = 38.37641821656742
SystemModel __init__!
solve_bound_eta tau = 20.0
af = [0.989954 0.976704 1.097845 0.938847 1.01456  1.482091 1.271986 2.09537  1.315521 1.847408]
bf = [1.172963 1.924745 1.243004 2.019357 1.877995 1.794188 1.604423 1.180587 1.63653  1.97343 ]
tmp = [-1.111625e-07 -1.879514e-07 -6.925393e-07 -1.025411e-07 -3.446792e-07 -6.242210e-05 -8.236486e-06 -1.200011e-03 -1.316983e-05 -6.262177e-04]
w0 = [-1.111625e-07+0.j -1.879514e-07+0.j -6.925398e-07+0.j -1.025412e-07+0.j -3.446793e-07+0.j -6.242600e-05+0.j -8.236553e-06+0.j -1.201453e-03+0.j -1.317000e-05+0.j -6.266102e-04+0.j]
w_1 = [-18.954304+0.j -18.3994  +0.j -17.017121+0.j -19.039518+0.j -17.757457+0.j -12.18151 +0.j -14.372235+0.j  -8.912927+0.j -13.867101+0.j  -9.641934+0.j]
xs_min = [-19.018103 -18.506386 -17.085283 -19.151837 -17.861928 -12.283807 -14.462081  -8.980225 -13.959068  -9.757134]
xs_max = [-0.063799 -0.106986 -0.068163 -0.112318 -0.104471 -0.102359 -0.089854 -0.068499 -0.09198  -0.115827]
solve_bound_eta x_min = -8.980225373861776	x_max = -0.11582671989239302
solve_bound_eta eta_min = 0.00012587447548799505	eta_max = 0.8906295383094618
af = 10.424229290121753	bf = 1.6427220595961534	zeta = 10.52847158302297	eta = 0.9900990099009901
af = 10.424229290121753	bf = 1.6427220595961534	zeta = 176.39110558213704	eta = 0.05909725014602666
af = 10.424229290121753	bf = 1.6427220595961534	zeta = 33.08353974696897	eta = 0.31508808821089934
af = 10.424229290121753	bf = 1.6427220595961534	zeta = 19.975847783910996	eta = 0.5218416461161496
af = 10.424229290121753	bf = 1.6427220595961534	zeta = 17.614557844948234	eta = 0.5917962506854164
af = 10.424229290121753	bf = 1.6427220595961534	zeta = 17.420708357187983	eta = 0.5983814823362562
af = 10.424229290121753	bf = 1.6427220595961534	zeta = 17.419124970256625	eta = 0.5984358748169759
af = 10.424229290121753	bf = 1.6427220595961534	zeta = 17.41912486302377	eta = 0.5984358785009719
eta = 0.5984358785009719
opt_as = [0.208111 0.208111 0.208111 0.208111 0.208111 0.208111 0.208111 0.208111 0.208111 0.208111]
opt_bs = [9048.353179  623.959564 6161.990667  511.951403  692.944528  847.416125 1441.584338 8658.649719 1306.523561  562.274031]
opt_cs = [26489062.134765 26134524.018238 29376015.369338 25121557.97102  27147490.065457 39657620.748606 34035659.186543 56067670.713546 35200570.140844 49432743.104265]
opt_tau = [0.209276 0.209276 0.209276 0.209276 0.209276 0.209276 0.209276 0.209276 0.209276 0.209276]
iter = 10 converged! (z, t) = (0.40934151918654, 4.684508110240289)
iter = 8 converged! (z, t) = (0.6156571525955703, 3.1051560289199807)
iter = 10 converged! (z, t) = (0.4144365601435392, 4.188038891140408)
iter = 8 converged! (z, t) = (0.6399609937267299, 3.0290275048055393)
iter = 8 converged! (z, t) = (0.5986211812092407, 3.1198884058473904)
iter = 8 converged! (z, t) = (0.49396698980886544, 2.684900772811824)
iter = 8 converged! (z, t) = (0.4884047299665947, 3.162399198310896)
iter = 8 converged! (z, t) = (0.28195522280249913, 2.6860158720535527)
iter = 10 converged! (z, t) = (0.48820673196081665, 3.058914851678203)
iter = 7 converged! (z, t) = (0.4748862855957828, 2.2343018965807526)
opt_freqs = [2.134696e+08 3.220450e+08 2.387752e+08 3.301390e+08 3.205243e+08 3.724532e+08 3.162156e+08 3.722986e+08 3.269133e+08 4.475671e+08]
opt_powers = [0.001161 0.00653  0.00165  0.007366 0.006227 0.007755 0.004681 0.003892 0.00517  0.012829]
optimize_network iter = 0 obj = 0.9819775438445457
solve_bound_eta tau = 20.0
af = [ 9.27489   6.065634  9.195637  5.687586  6.33063   7.958535  8.045056 11.256394  8.048136  8.255336]
bf = [3.269221 4.916968 3.309912 5.111071 4.78091  3.945085 3.900662 2.251846 3.899081 3.792696]
tmp = [-0.355064 -0.274297 -0.354163 -0.256572 -0.285444 -0.334261 -0.336058 -0.367173 -0.33612  -0.340146]
w0 = [-0.756796+0.j -0.415663+0.j -0.749056+0.j -0.372305+0.j -0.445782+0.j -0.623622+0.j -0.632677+0.j -0.93928 +0.j -0.632999+0.j -0.654508+0.j]
w_1 = [-1.290443+0.j -1.973201+0.j -1.301565+0.j -2.104358+0.j -1.890604+0.j -1.503885+0.j -1.487711+0.j -1.063282+0.j -1.487142+0.j -1.449816+0.j]
xs_min = [-1.047083 -2.070975 -1.065945 -2.245489 -1.958259 -1.393699 -1.36847  -0.637437 -1.367579 -1.308743]
xs_max = [-0.513436 -0.513436 -0.513436 -0.513436 -0.513436 -0.513436 -0.513436 -0.513436 -0.513436 -0.513436]
solve_bound_eta x_min = -0.637437144427257	x_max = -0.5134358967312542
solve_bound_eta eta_min = 0.5286455315393896	eta_max = 0.5984358785009718
af = 0.309887104970722	bf = 0.23521978609961328	zeta = 0.31298597602042927	eta = 0.99009900990099
af = 0.309887104970722	bf = 0.23521978609961328	zeta = 24.068629797441158	eta = 0.012875145264965082
af = 0.309887104970722	bf = 0.23521978609961328	zeta = 1.6046500482930794	eta = 0.1931181850524726
af = 0.309887104970722	bf = 0.23521978609961328	zeta = 0.9230776141567707	eta = 0.33571077904841534
af = 0.309887104970722	bf = 0.23521978609961328	zeta = 0.8632733680745251	eta = 0.358967525735104
af = 0.309887104970722	bf = 0.23521978609961328	zeta = 0.8622127331464803	eta = 0.3594091029482346
af = 0.309887104970722	bf = 0.23521978609961328	zeta = 0.8622123677336319	eta = 0.35940925526883327
eta = 0.35940925526883327
opt_as = [0.208111 0.208111 0.208111 0.208111 0.208111 0.208111 0.208111 0.208111 0.208111 0.208111]
opt_bs = [9048.353179  623.959564 6161.990667  511.951403  692.944528  847.416125 1441.584338 8658.649719 1306.523561  562.274031]
opt_cs = [32886504.884521 32446341.339221 36470693.753388 31188731.209794 33703951.468648 49235436.567074 42255700.348753 69608720.663794 43701951.997595 61371374.316046]
opt_tau = [0.245648 0.245648 0.245648 0.245648 0.245648 0.245648 0.245648 0.245648 0.245648 0.245648]
iter = 9 converged! (z, t) = (0.41853787172559337, 4.821000116012903)
iter = 10 converged! (z, t) = (0.6596507878580938, 3.3399054434827034)
iter = 9 converged! (z, t) = (0.4241892404816477, 4.3149641110259696)
iter = 11 converged! (z, t) = (0.6897140413214877, 3.273978424382451)
iter = 8 converged! (z, t) = (0.638783513759193, 3.3441304711473845)
iter = 8 converged! (z, t) = (0.5143695842010797, 2.8150914673766776)
iter = 9 converged! (z, t) = (0.5079397561412243, 3.311751337950366)
iter = 6 converged! (z, t) = (0.28195552590618395, 2.6860149594348948)
iter = 8 converged! (z, t) = (0.5077118809541004, 3.20323896275874)
iter = 7 converged! (z, t) = (0.49239136777121467, 2.332946863046105)
opt_freqs = [2.074258e+08 2.994097e+08 2.317516e+08 3.054388e+08 2.990314e+08 3.552282e+08 3.019550e+08 3.722987e+08 3.121840e+08 4.286424e+08]
opt_powers = [0.001095 0.005695 0.001552 0.006373 0.005462 0.007066 0.004274 0.003892 0.004721 0.011775]
optimize_network iter = 1 obj = 0.8583481016791684
solve_bound_eta tau = 20.0
af = [ 9.545132  6.524196  9.474325  6.147529  6.785645  8.344443  8.425004 11.25639   8.427859  8.619811]
bf = [3.342668 5.268325 3.387803 5.508426 5.101667 4.108031 4.056679 2.251848 4.054859 3.932501]
tmp = [-0.365894 -0.320526 -0.365589 -0.308011 -0.328032 -0.356878 -0.357774 -0.367173 -0.357805 -0.359748]
w0 = [-0.899539+0.j -0.562593+0.j -0.892371+0.j -0.516032+0.j -0.594341+0.j -0.773394+0.j -0.78217 +0.j -0.939281+0.j -0.78248 +0.j -0.803204+0.j]
w_1 = [-1.107676+0.j -1.620569+0.j -1.115954+0.j -1.719863+0.j -1.558129+0.j -1.26706 +0.j -1.254944+0.j -1.063281+0.j -1.254519+0.j -1.226583+0.j]
xs_min = [-0.845574 -1.695413 -0.86102  -1.841269 -1.601226 -1.131103 -1.110211 -0.637437 -1.109476 -1.060816]
xs_max = [-0.637437 -0.637437 -0.637437 -0.637437 -0.637437 -0.637437 -0.637437 -0.513437 -0.637437 -0.637437]
solve_bound_eta x_min = -0.6374371695343649	x_max = -0.6374371444272591
solve_bound_eta eta_min = 0.5286455182666294	eta_max = 0.5286455315393885
Done!
af = 0.2856988019802301	bf = 0.22247118472059207	zeta = 0.28855579000003245	eta = 0.99009900990099
af = 0.2856988019802301	bf = 0.22247118472059207	zeta = 22.756712214789292	eta = 0.01255448499254467
af = 0.2856988019802301	bf = 0.22247118472059207	zeta = 1.4918983624806605	eta = 0.1915001780048764
af = 0.2856988019802301	bf = 0.22247118472059207	zeta = 0.8592372643389783	eta = 0.33250280666076754
af = 0.2856988019802301	bf = 0.22247118472059207	zeta = 0.8045818536763624	eta = 0.3550897906468949
af = 0.2856988019802301	bf = 0.22247118472059207	zeta = 0.8036457078538422	eta = 0.3555034254375558
af = 0.2856988019802301	bf = 0.22247118472059207	zeta = 0.8036454075634843	eta = 0.35550355827506075
eta = 0.35550355827506075
At round 0 optimal eta: 0.5286455182666294
At round 0 optimal freqs: [2.074258e+08 2.994097e+08 2.317516e+08 3.054388e+08 2.990314e+08 3.552282e+08 3.019550e+08 3.722987e+08 3.121840e+08 4.286424e+08]
At round 0 optimal decs: [0 0 0 0 0 0 0 0 0 0]
At round 0 optimal powers: [0.001095 0.005695 0.001552 0.006373 0.005462 0.007066 0.004274 0.003892 0.004721 0.011775]
At round 0 t_co: [0.087102 0.13728  0.088278 0.143537 0.132938 0.107046 0.105708 0.058678 0.10566  0.102472]
At round 0 e_co: [9.535357e-05 7.818797e-04 1.370142e-04 9.147374e-04 7.261217e-04 7.563458e-04 4.518161e-04 2.283590e-04 4.988105e-04 1.206642e-03]
At round 0 t_cp: [0.158546 0.108368 0.15737  0.102111 0.11271  0.138602 0.13994  0.18697  0.139988 0.143176]
At round 0 e_cp: [0.000141 0.000291 0.000196 0.000291 0.000301 0.000621 0.000385 0.000965 0.000426 0.001128]
At round 0 average t_co: 0.14353674054273075 average t_cp: 0.18697007237437552 t: 0.24564798052460396
At round 0 average e_co: 0.005797080474397931 average e_cp: 0.004745493303880462 e: 0.010542573778278393
At round 0 a_n: 38.37641821656742
At round 0 local rounds: 31.440254474035065
At round 0 global rounds: 81.41731903225156
At round 0 tau: 20.0
At round 0 accuracy: 0.16067285382830626
At round 0 training accuracy: 0.15819291109819872
At round 0 training loss: 2.3249139180050507
At round 0 test loss: 2.3141367202276544
gradient difference: 5.269041061401367
ground = 1 remain_eps = 0.001092709645997344	remain_tau = 19.754352019475395
update_location
xs = [-276.88873  396.88873 -381.88873 -346.06469 -196.06469  -96.06469  396.06469 -176.88873  496.06469  421.88873]
ys = [-296.88873  351.88873 -396.88873  453.03192  383.03192  333.03192   61.96808 -196.88873   11.96808  381.88873]
dists_uav = [710.349787 257.215492 853.90058  602.071858 439.8257   332.310872 270.952857 570.825129 375.408552 292.30561 ]
uav_gains = [5.573691e-13 1.949518e-11 3.635755e-13 8.220571e-13 1.810530e-12 4.921303e-12 1.482062e-11 9.335520e-13 2.973071e-12 9.675801e-12]
dists_bs = [ 343.397083  939.80587   395.564073 1013.918444  904.536752  838.552685  687.513899  350.950231  712.875509  977.608221]
bs_gains = [3.638811e-11 2.525047e-12 2.501474e-11 2.064964e-12 2.794416e-12 3.415585e-12 5.781288e-12 3.434946e-11 5.252115e-12 2.274488e-12]
At round 1 optimal eta: 0.5286455182666294
At round 1 optimal freqs: [2.074258e+08 2.994097e+08 2.317516e+08 3.054388e+08 2.990314e+08 3.552282e+08 3.019550e+08 3.722987e+08 3.121840e+08 4.286424e+08]
At round 1 optimal decs: [0 0 0 0 0 0 0 0 0 0]
At round 1 optimal powers: [0.001095 0.005695 0.001552 0.006373 0.005462 0.007066 0.004274 0.003892 0.004721 0.011775]
At round 1 t_co: [0.086925 0.136462 0.08778  0.142907 0.132393 0.106687 0.105588 0.058811 0.105431 0.101982]
At round 1 e_co: [9.515944e-05 7.772186e-04 1.362409e-04 9.107218e-04 7.231470e-04 7.538134e-04 4.513053e-04 2.288770e-04 4.977301e-04 1.200871e-03]
At round 1 t_cp: [0.158546 0.108368 0.15737  0.102111 0.11271  0.138602 0.13994  0.18697  0.139988 0.143176]
At round 1 e_cp: [0.000141 0.000291 0.000196 0.000291 0.000301 0.000621 0.000385 0.000965 0.000426 0.001128]
At round 1 average t_co: 0.14290663328966752 average t_cp: 0.18697007237437552 t: 0.24578109683722182
At round 1 average e_co: 0.005775084546068215 average e_cp: 0.004745493303880462 e: 0.010520577849948677
At round 1 a_n: 38.37641821656742
At round 1 local rounds: 31.440254474035065
At round 1 global rounds: 81.41731903225156
At round 1 tau: 19.754352019475395
At round 1 accuracy: 0.7685614849187935
At round 1 training accuracy: 0.7805055200464845
At round 1 training loss: 0.9025223889463092
At round 1 test loss: 0.9396008317665391
gradient difference: 0.14890509843826294
ground = 2 remain_eps = 0.0011940143704556407	remain_tau = 19.50857092263817
update_location
xs = [-273.77746   393.77746  -378.77746  -342.129381 -192.129381  -92.129381  392.129381 -173.77746   492.129381  418.77746 ]
ys = [-293.77746   348.77746  -393.77746   451.063841  381.063841  331.063841   63.936159 -193.77746    13.936159  378.77746 ]
dists_uav = [705.997423 253.245609 849.532883 597.741385 435.553684 328.138312 266.963708 566.499229 371.216758 288.225362]
uav_gains = [5.654156e-13 2.105031e-11 3.679153e-13 8.362774e-13 1.860718e-12 5.227995e-12 1.606337e-11 9.507689e-13 3.097138e-12 1.047733e-11]
dists_bs = [ 342.756231  935.672948  393.389873 1010.729906  901.768923  836.154848  686.869306  352.094944  711.56286   973.460007]
bs_gains = [3.656868e-11 2.554711e-12 2.538278e-11 2.082272e-12 2.817203e-12 3.441603e-12 5.795677e-12 3.405431e-11 5.277830e-12 2.300263e-12]
At round 2 optimal eta: 0.5286455182666294
At round 2 optimal freqs: [2.074258e+08 2.994097e+08 2.317516e+08 3.054388e+08 2.990314e+08 3.552282e+08 3.019550e+08 3.722987e+08 3.121840e+08 4.286424e+08]
At round 2 optimal decs: [0 0 0 0 0 0 0 0 0 0]
At round 2 optimal powers: [0.001095 0.005695 0.001552 0.006373 0.005462 0.007066 0.004274 0.003892 0.004721 0.011775]
At round 2 t_co: [0.086762 0.135648 0.087292 0.142281 0.131853 0.106332 0.105474 0.058951 0.105207 0.101494]
At round 2 e_co: [9.498094e-05 7.725835e-04 1.354836e-04 9.067324e-04 7.201962e-04 7.513049e-04 4.508159e-04 2.294202e-04 4.966716e-04 1.195125e-03]
At round 2 t_cp: [0.158546 0.108368 0.15737  0.102111 0.11271  0.138602 0.13994  0.18697  0.139988 0.143176]
At round 2 e_cp: [0.000141 0.000291 0.000196 0.000291 0.000301 0.000621 0.000385 0.000965 0.000426 0.001128]
At round 2 average t_co: 0.14228062460845925 average t_cp: 0.18697007237437552 t: 0.24592066402594384
At round 2 average e_co: 0.005753314092246161 average e_cp: 0.004745493303880462 e: 0.010498807396126623
At round 2 a_n: 38.37641821656742
At round 2 local rounds: 31.440254474035065
At round 2 global rounds: 81.41731903225156
At round 2 tau: 19.50857092263817
At round 2 accuracy: 0.8161252900232019
At round 2 training accuracy: 0.8251016850668216
At round 2 training loss: 0.6219954116106355
At round 2 test loss: 0.6741981248608276
gradient difference: 0.12459459155797958
