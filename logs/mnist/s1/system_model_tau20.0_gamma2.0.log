Arguments:
	      dataset : mnist
	learning_rate : 0.01
	        model : mclr
	 model_params : (784, 10)
	        optim : 1
	      sce_idx : 1
	          tau : 20.0
['f_00000', 'f_00001', 'f_00002', 'f_00003', 'f_00004', 'f_00005', 'f_00006', 'f_00007', 'f_00008', 'f_00009']
10
dict_keys(['x', 'y'])
id = f_00000, model = <class 'flearn.models.mnist.mclr.Model'>, device = cpu, num_samples = 523
id = f_00001, model = <class 'flearn.models.mnist.mclr.Model'>, device = cpu, num_samples = 516
id = f_00002, model = <class 'flearn.models.mnist.mclr.Model'>, device = cpu, num_samples = 580
id = f_00003, model = <class 'flearn.models.mnist.mclr.Model'>, device = cpu, num_samples = 496
id = f_00004, model = <class 'flearn.models.mnist.mclr.Model'>, device = cpu, num_samples = 536
id = f_00005, model = <class 'flearn.models.mnist.mclr.Model'>, device = cpu, num_samples = 783
id = f_00006, model = <class 'flearn.models.mnist.mclr.Model'>, device = cpu, num_samples = 672
id = f_00007, model = <class 'flearn.models.mnist.mclr.Model'>, device = cpu, num_samples = 1107
id = f_00008, model = <class 'flearn.models.mnist.mclr.Model'>, device = cpu, num_samples = 695
id = f_00009, model = <class 'flearn.models.mnist.mclr.Model'>, device = cpu, num_samples = 976
BaseFederated generated!
num_samples = [ 523  516  580  496  536  783  672 1107  695  976]
msize = 300240
xs = [-280.  400. -385. -350. -200. -100.  400. -180.  500.  425.]
ys = [-300.  355. -400.  455.  385.  335.   60. -200.   10.  385.]
dists_uav = [714.702735 261.199158 858.268606 606.403331 444.100214 336.489227 274.954542 575.152154 379.605058 296.395007]
uav_gains = [5.494875e-13 1.802536e-11 3.593089e-13 8.081917e-13 1.762643e-12 4.643011e-12 1.366745e-11 9.167988e-13 2.857829e-12 8.947599e-12]
dists_bs = [ 344.093011  943.941206  397.775062 1017.116021  907.317475  840.966706  688.186021  349.857114  714.212853  981.758626]
bs_gains = [3.619341e-11 2.495838e-12 2.464796e-11 2.047806e-12 2.771778e-12 3.389665e-12 5.766337e-12 3.463460e-11 5.226094e-12 2.249096e-12]
v = 50.607287449392715 a_0 = 19.894335203468554
SystemModel __init__!
solve_bound_eta tau = 20.0
af = [ 7.596591  7.494915  8.424517  7.204415  7.785416 11.373098  9.76082  16.079208 10.094896 14.176429]
bf = [0.608064 0.997788 0.644373 1.046835 0.973553 0.930107 0.831733 0.612017 0.848377 1.023026]
tmp = [-0.205013 -0.211435 -0.238604 -0.199941 -0.223046 -0.328811 -0.287526 -0.372479 -0.297168 -0.369917]
w0 = [-0.268031+0.j       -0.27966 +0.j       -0.332832+0.j       -0.259068+0.j       -0.301547+0.j       -0.597839+0.j       -0.451697+0.j       -0.991714+0.157533j -0.480473+0.j       -0.996318+0.105067j]
w_1 = [-2.501623+0.j       -2.449878+0.j       -2.238961+0.j       -2.543127+0.j       -2.358332+0.j       -1.551486+0.j       -1.875106+0.j       -0.991714-0.157533j -1.802795+0.j       -0.996318-0.105067j]
xs_min = [-2.284684 -2.255687 -1.964703 -2.371703 -2.142311 -1.078916 -1.5121   -0.214066 -1.416686 -0.342311]
xs_max = [-0.051093 -0.085469 -0.058574 -0.087644 -0.085525 -0.125268 -0.08869  -0.214066 -0.094364 -0.342311]
solve_bound_eta x_min = -0.21406572263208767	x_max = -0.3423110767928862
solve_bound_eta eta_min = 0.8072953257054242	eta_max = 0.7101272662340217
af = 79.99224371051326	bf = 0.851587115694646	zeta = 80.7921661476184	eta = 0.99009900990099
af = 79.99224371051326	bf = 0.851587115694646	zeta = 166.401177036452	eta = 0.4807192180677309
af = 79.99224371051326	bf = 0.851587115694646	zeta = 114.47305959154514	eta = 0.6987866315090735
af = 79.99224371051326	bf = 0.851587115694646	zeta = 98.00890928836344	eta = 0.8161731855943704
af = 79.99224371051326	bf = 0.851587115694646	zeta = 93.02401496237803	eta = 0.8599096022985544
af = 79.99224371051326	bf = 0.851587115694646	zeta = 92.25940817992196	eta = 0.867036167785885
af = 79.99224371051326	bf = 0.851587115694646	zeta = 92.238973941416	eta = 0.867228247370997
af = 79.99224371051326	bf = 0.851587115694646	zeta = 92.23895916150167	eta = 0.8672283863313596
eta = 0.8672283863313596
opt_as = [0.208111 0.208111 0.208111 0.208111 0.208111 0.208111 0.208111 0.208111 0.208111 0.208111]
opt_bs = [9048.353179  623.959564 6161.990667  511.951403  692.944528  847.416125 1441.584338 8658.649719 1306.523561  562.274031]
opt_cs = [2.614209e+08 2.579219e+08 2.899122e+08 2.479249e+08 2.679189e+08 3.913815e+08 3.358983e+08 5.533325e+08 3.473948e+08 4.878523e+08]
opt_tau = [0.291412 0.291412 0.291412 0.291412 0.291412 0.291412 0.291412 0.291412 0.291412 0.291412]
iter = 9 converged! (z, t) = (0.16787294229873054, 0.9810854930740737)
iter = 10 converged! (z, t) = (0.2522958657815745, 0.9262761237777518)
iter = 9 converged! (z, t) = (0.1695255972205945, 0.8834821291692576)
iter = 8 converged! (z, t) = (0.2663150752283273, 0.9518581123539133)
iter = 9 converged! (z, t) = (0.24322580754151976, 0.8987589022974024)
iter = 10 converged! (z, t) = (0.22465154678006996, 0.6251189142214675)
iter = 10 converged! (z, t) = (0.20089097475060386, 0.7430963590848345)
iter = 9 converged! (z, t) = (0.20491115620082706, 0.7160963492366342)
opt_freqs = [1.019279e+09 1.079592e+09 1.131885e+09 1.050577e+09 1.112645e+09 1.599696e+09 1.345720e+09 2.000000e+09 1.396460e+09 2.000000e+09]
opt_powers = [0.042594 0.082772 0.059008 0.081516 0.086634 0.1      0.1      0.1      0.1      0.1     ]
optimize_network iter = 0 obj = 57.530715895870514
solve_bound_eta tau = 20.0
af = [14.90581  13.884722 14.885821 13.715161 13.994424 14.219078 14.50646  16.079208 14.457836 14.176429]
bf = [0.695031 1.04456  0.701873 1.102603 1.007008 0.930107 0.831733 0.612017 0.848377 1.023026]
tmp = [-0.367457 -0.367785 -0.36748  -0.367653 -0.367839 -0.367879 -0.367798 -0.372479 -0.367821 -0.369917]
w0 = [-0.952819+0.j       -0.977454+0.j       -0.954099+0.j       -0.965286+0.j       -0.985274+0.j       -0.998837+0.j       -0.97905 +0.j       -0.991714+0.157533j -0.982342+0.j       -0.996318+0.105067j]
w_1 = [-1.048713+0.j       -1.02289 +0.j       -1.04735 +0.j       -1.035536+0.j       -1.014872+0.j       -1.001164+0.j       -1.021247+0.j       -0.991714-0.157533j -1.017868+0.j       -0.996318-0.105067j]
xs_min = [-0.342311 -0.387747 -0.342311 -0.412561 -0.371909 -0.342311 -0.342311 -0.214066 -0.342311 -0.342311]
xs_max = [-0.246418 -0.342311 -0.24906  -0.342311 -0.342311 -0.339985 -0.300114 -0.214066 -0.306786 -0.342311]
solve_bound_eta x_min = -0.21406572263208756	x_max = -0.34231107679289763
solve_bound_eta eta_min = 0.8072953257054243	eta_max = 0.7101272662340136
af = 46.49998202793237	bf = 0.7591269734184307	zeta = 46.96498184821169	eta = 0.9900990099009901
af = 46.49998202793237	bf = 0.7591269734184307	zeta = 123.40353510553541	eta = 0.37681239834957175
af = 46.49998202793237	bf = 0.7591269734184307	zeta = 74.0442741823202	eta = 0.6280024018256273
af = 46.49998202793237	bf = 0.7591269734184307	zeta = 60.19244106024528	eta = 0.7725219514090078
af = 46.49998202793237	bf = 0.7591269734184307	zeta = 56.09566791415207	eta = 0.8289406964383633
af = 46.49998202793237	bf = 0.7591269734184307	zeta = 55.435940743168985	eta = 0.8388056810177297
af = 46.49998202793237	bf = 0.7591269734184307	zeta = 55.41583292068086	eta = 0.8391100444973886
af = 46.49998202793237	bf = 0.7591269734184307	zeta = 55.41581390350011	eta = 0.8391103324568403
eta = 0.8391103324568403
opt_as = [0.208111 0.208111 0.208111 0.208111 0.208111 0.208111 0.208111 0.208111 0.208111 0.208111]
opt_bs = [9048.353179  623.959564 6161.990667  511.951403  692.944528  847.416125 1441.584338 8658.649719 1306.523561  562.274031]
opt_cs = [2.614209e+08 2.579219e+08 2.899122e+08 2.479249e+08 2.679189e+08 3.913815e+08 3.358983e+08 5.533325e+08 3.473948e+08 4.878523e+08]
opt_tau = [0.291412 0.291412 0.291412 0.291412 0.291412 0.291412 0.291412 0.291412 0.291412 0.291412]
iter = 9 converged! (z, t) = (0.16787292049376404, 0.9810855104324526)
iter = 9 converged! (z, t) = (0.2522958255534245, 0.926276156236804)
iter = 9 converged! (z, t) = (0.16952561440036912, 0.8834821168369322)
iter = 7 converged! (z, t) = (0.26631505938724837, 0.9518581256503781)
iter = 11 converged! (z, t) = (0.24322580530746327, 0.8987589040327438)
iter = 8 converged! (z, t) = (0.22465156019457178, 0.6251189070885328)
iter = 10 converged! (z, t) = (0.20089097377455842, 0.7430963596895567)
iter = 7 converged! (z, t) = (0.20491115686319789, 0.7160963488398533)
opt_freqs = [1.019279e+09 1.079592e+09 1.131885e+09 1.050577e+09 1.112645e+09 1.599696e+09 1.345720e+09 2.000000e+09 1.396460e+09 2.000000e+09]
opt_powers = [0.042594 0.082772 0.059008 0.081516 0.086634 0.1      0.1      0.1      0.1      0.1     ]
optimize_network iter = 1 obj = 57.53071598585232
Done!
At round 0 optimal eta: 0.7101272662340136
At round 0 optimal freqs: [1.019279e+09 1.079592e+09 1.131885e+09 1.050577e+09 1.112645e+09 1.599696e+09 1.345720e+09 2.000000e+09 1.396460e+09 2.000000e+09]
At round 0 optimal decs: [0 0 0 0 0 0 0 0 0 0]
At round 0 optimal powers: [0.042594 0.082772 0.059008 0.081516 0.086634 0.1      0.1      0.1      0.1      0.1     ]
At round 0 t_co: [0.034936 0.052505 0.03528  0.055423 0.050618 0.046752 0.041808 0.030763 0.042644 0.051423]
At round 0 e_co: [0.001488 0.004346 0.002082 0.004518 0.004385 0.004675 0.004181 0.003076 0.004264 0.005142]
At round 0 t_cp: [0.256476 0.238907 0.256132 0.235989 0.240794 0.24466  0.249605 0.276666 0.248768 0.243926]
At round 0 e_cp: [0.02716  0.030061 0.037142 0.027364 0.033168 0.100156 0.06083  0.221333 0.067745 0.195141]
At round 0 average t_co: 0.05542296269429086 average t_cp: 0.27666624275001783 t: 0.30742959854390856
At round 0 average e_co: 0.038157948225190405 average e_cp: 0.8001000658162141 e: 0.8382580140414045
At round 0 a_n: 19.894335203468554
At round 0 local rounds: 24.9924338527568
At round 0 global rounds: 68.63127464595964
At round 0 tau: 20.0
At round 0 accuracy: 0.14733178654292342
At round 0 training accuracy: 0.1356769320162696
At round 0 training loss: 2.37978868071533
At round 0 test loss: 2.3785728381155815
gradient difference: 8.35952377319336
ground = 1 remain_eps = 0.001111914475224785	remain_tau = 19.69257040145609
update_location
xs = [-276.88873  396.88873 -381.88873 -346.06469 -196.06469  -96.06469  396.06469 -176.88873  496.06469  421.88873]
ys = [-296.88873  351.88873 -396.88873  453.03192  383.03192  333.03192   61.96808 -196.88873   11.96808  381.88873]
dists_uav = [710.349787 257.215492 853.90058  602.071858 439.8257   332.310872 270.952857 570.825129 375.408552 292.30561 ]
uav_gains = [5.573691e-13 1.949518e-11 3.635755e-13 8.220571e-13 1.810530e-12 4.921303e-12 1.482062e-11 9.335520e-13 2.973071e-12 9.675801e-12]
dists_bs = [ 343.397083  939.80587   395.564073 1013.918444  904.536752  838.552685  687.513899  350.950231  712.875509  977.608221]
bs_gains = [3.638811e-11 2.525047e-12 2.501474e-11 2.064964e-12 2.794416e-12 3.415585e-12 5.781288e-12 3.434946e-11 5.252115e-12 2.274488e-12]
At round 1 optimal eta: 0.7101272662340136
At round 1 optimal freqs: [1.019279e+09 1.079592e+09 1.131885e+09 1.050577e+09 1.112645e+09 1.599696e+09 1.345720e+09 2.000000e+09 1.396460e+09 2.000000e+09]
At round 1 optimal decs: [0 0 0 0 0 0 0 0 0 0]
At round 1 optimal powers: [0.042594 0.082772 0.059008 0.081516 0.086634 0.1      0.1      0.1      0.1      0.1     ]
At round 1 t_co: [0.034905 0.052355 0.035192 0.055303 0.05052  0.046673 0.041786 0.030801 0.042601 0.051283]
At round 1 e_co: [0.001487 0.004334 0.002077 0.004508 0.004377 0.004667 0.004179 0.00308  0.00426  0.005128]
At round 1 t_cp: [0.256476 0.238907 0.256132 0.235989 0.240794 0.24466  0.249605 0.276666 0.248768 0.243926]
At round 1 e_cp: [0.02716  0.030061 0.037142 0.027364 0.033168 0.100156 0.06083  0.221333 0.067745 0.195141]
At round 1 average t_co: 0.0553029348114914 average t_cp: 0.27666624275001783 t: 0.30746719482553075
At round 1 average e_co: 0.038096068944765665 average e_cp: 0.8001000658162141 e: 0.8381961347609799
At round 1 a_n: 19.894335203468554
At round 1 local rounds: 24.9924338527568
At round 1 global rounds: 68.63127464595964
At round 1 tau: 19.69257040145609
At round 1 accuracy: 0.798723897911833
At round 1 training accuracy: 0.7918361417780361
At round 1 training loss: 0.9139200812719586
At round 1 test loss: 0.940990178907815
gradient difference: 0.3957505226135254
ground = 2 remain_eps = 0.001236353800214409	remain_tau = 19.38510320663056
update_location
xs = [-273.77746   393.77746  -378.77746  -342.129381 -192.129381  -92.129381  392.129381 -173.77746   492.129381  418.77746 ]
ys = [-293.77746   348.77746  -393.77746   451.063841  381.063841  331.063841   63.936159 -193.77746    13.936159  378.77746 ]
dists_uav = [705.997423 253.245609 849.532883 597.741385 435.553684 328.138312 266.963708 566.499229 371.216758 288.225362]
uav_gains = [5.654156e-13 2.105031e-11 3.679153e-13 8.362774e-13 1.860718e-12 5.227995e-12 1.606337e-11 9.507689e-13 3.097138e-12 1.047733e-11]
dists_bs = [ 342.756231  935.672948  393.389873 1010.729906  901.768923  836.154848  686.869306  352.094944  711.56286   973.460007]
bs_gains = [3.656868e-11 2.554711e-12 2.538278e-11 2.082272e-12 2.817203e-12 3.441603e-12 5.795677e-12 3.405431e-11 5.277830e-12 2.300263e-12]
At round 2 optimal eta: 0.7101272662340136
At round 2 optimal freqs: [1.019279e+09 1.079592e+09 1.131885e+09 1.050577e+09 1.112645e+09 1.599696e+09 1.345720e+09 2.000000e+09 1.396460e+09 2.000000e+09]
At round 2 optimal decs: [0 0 0 0 0 0 0 0 0 0]
At round 2 optimal powers: [0.042594 0.082772 0.059008 0.081516 0.086634 0.1      0.1      0.1      0.1      0.1     ]
At round 2 t_co: [0.034876 0.052204 0.035106 0.055183 0.050422 0.046595 0.041765 0.03084  0.042559 0.051144]
At round 2 e_co: [0.001486 0.004321 0.002072 0.004498 0.004368 0.00466  0.004177 0.003084 0.004256 0.005114]
At round 2 t_cp: [0.256476 0.238907 0.256132 0.235989 0.240794 0.24466  0.249605 0.276666 0.248768 0.243926]
At round 2 e_cp: [0.02716  0.030061 0.037142 0.027364 0.033168 0.100156 0.06083  0.221333 0.067745 0.195141]
At round 2 average t_co: 0.05518336458619154 average t_cp: 0.27666624275001783 t: 0.3075065381054049
At round 2 average e_co: 0.038034902938882134 average e_cp: 0.8001000658162141 e: 0.8381349687550963
At round 2 a_n: 19.894335203468554
At round 2 local rounds: 24.9924338527568
At round 2 global rounds: 68.63127464595964
At round 2 tau: 19.38510320663056
At round 2 accuracy: 0.8317865429234339
At round 2 training accuracy: 0.8306217315514236
At round 2 training loss: 0.6289081166976583
At round 2 test loss: 0.6888307922519983
gradient difference: 0.21427294611930847
