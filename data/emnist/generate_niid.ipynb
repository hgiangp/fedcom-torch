{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets \n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "np.set_printoptions(precision=3, linewidth=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "num_users = 10\n",
    "num_labels = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directory for train/test data \n",
    "train_file = 'data_niid_seed_0_train_8.json'\n",
    "test_file = 'data_niid_seed_0_test_8.json'\n",
    "current_dir = os.path.abspath('')\n",
    "data_dir = os.path.join(current_dir, 'data')\n",
    "train_path = os.path.join(data_dir, 'train', train_file)\n",
    "test_path = os.path.join(data_dir, 'test', test_file)\n",
    "dir_path = os.path.dirname(train_path)\n",
    "if not os.path.exists(dir_path): \n",
    "    os.makedirs(dir_path)\n",
    "dir_path = os.path.dirname(test_path)\n",
    "if not os.path.exists(dir_path): \n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "# print(\"data_dir\", data_dir)\n",
    "# print(\"train_path\", train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697932\n"
     ]
    }
   ],
   "source": [
    "# Get MNIST data, normalize, divide by level \n",
    "emnist_byclass = datasets.EMNIST(root=data_dir, split='byclass' ,train=True, download=True)\n",
    "print(len(emnist_byclass))\n",
    "# mnist_test = datasets.MNIST(root='./data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tranform data from Image to numpy array \n",
    "mnist_image = []\n",
    "mnist_target = []\n",
    "\n",
    "for image, target in emnist_byclass: \n",
    "    mnist_image.append(np.asarray(image).reshape(-1))\n",
    "    mnist_target.append(target)\n",
    "\n",
    "targets = set(mnist_target) # sorted \n",
    "mnist_image = np.asarray(mnist_image)\n",
    "mnist_target = np.asarray(mnist_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples of each label: [34585, 38374, 34203, 35143, 33535, 31416, 34232, 35754, 33946, 33847, 6407, 3878, 10094, 4562, 4934, 9182, 2517, 3152, 11946, 3762, 2468, 5076, 9002, 8237, 24983, 8347, 2605, 5073, 20764, 9820, 12602, 4637, 4695, 2771, 4743, 2701, 10033, 5159, 2854, 10177, 24631, 2561, 3687, 8738, 2725, 1896, 2491, 15318, 2645, 11418, 2749, 2448, 2994, 14105, 2699, 18262, 2830, 2910, 2697, 2822, 2365, 2725]\n",
      "697932\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61}\n"
     ]
    }
   ],
   "source": [
    "mnist_data = []\n",
    "for i in targets:\n",
    "    idx = mnist_target==i\n",
    "    mnist_data.append(mnist_image[idx])\n",
    "\n",
    "len_data = [len(v) for v in mnist_data]\n",
    "print(f\"Number of samples of each label: {len_data}\\n{np.asarray(len_data).sum()}\")\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sams_per_lab = 60\n",
    "X = [[] for _ in range(num_users)]\n",
    "y = [[] for _ in range(num_users)]\n",
    "\n",
    "num_classes = len(targets)\n",
    "idx = np.zeros(num_classes, dtype=int) # 10 labels 0 - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx = [ 60 120 180 240 300 360 360 360 360 360 300 240 180 120  60   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "for user in range(num_users): \n",
    "    for j in range(num_labels): \n",
    "        l = (user + j)%num_classes \n",
    "        X[user] += mnist_data[l][idx[l]:idx[l]+sams_per_lab].tolist()\n",
    "        y[user] += (l*np.ones(sams_per_lab)).tolist()\n",
    "        idx[l] += sams_per_lab\n",
    " \n",
    "print(f\"idx = {idx}\") #  90 * 10 / 10 = 60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
