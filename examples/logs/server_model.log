v = 22.697160301531774
a_0 = 27.840057009285058	a_alpha = -0.3425458469693173
['f_00000', 'f_00001', 'f_00002', 'f_00003', 'f_00004', 'f_00005', 'f_00006', 'f_00007', 'f_00008', 'f_00009']
10
dict_keys(['x', 'y'])
id = f_00000, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 126
id = f_00001, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 265
id = f_00002, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 124
id = f_00003, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 43
id = f_00004, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 306
id = f_00005, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 146
id = f_00006, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 54
id = f_00007, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 179
id = f_00008, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 130
id = f_00009, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 118
BaseFederated generated!
gradient difference: 1.0801069736480713
train() client id: f_00000-0-0 loss: 0.815603  [   32/  126]
train() client id: f_00000-0-1 loss: 0.887908  [   64/  126]
train() client id: f_00000-0-2 loss: 0.913467  [   96/  126]
train() client id: f_00000-1-0 loss: 0.845964  [   32/  126]
train() client id: f_00000-1-1 loss: 1.015873  [   64/  126]
train() client id: f_00000-1-2 loss: 0.819100  [   96/  126]
train() client id: f_00000-2-0 loss: 0.889211  [   32/  126]
train() client id: f_00000-2-1 loss: 0.824768  [   64/  126]
train() client id: f_00000-2-2 loss: 0.830514  [   96/  126]
train() client id: f_00000-3-0 loss: 0.717190  [   32/  126]
train() client id: f_00000-3-1 loss: 0.889102  [   64/  126]
train() client id: f_00000-3-2 loss: 0.859344  [   96/  126]
train() client id: f_00000-4-0 loss: 0.811424  [   32/  126]
train() client id: f_00000-4-1 loss: 0.914435  [   64/  126]
train() client id: f_00000-4-2 loss: 0.894569  [   96/  126]
train() client id: f_00000-5-0 loss: 0.815122  [   32/  126]
train() client id: f_00000-5-1 loss: 0.846365  [   64/  126]
train() client id: f_00000-5-2 loss: 0.848039  [   96/  126]
train() client id: f_00000-6-0 loss: 0.835936  [   32/  126]
train() client id: f_00000-6-1 loss: 1.040643  [   64/  126]
train() client id: f_00000-6-2 loss: 0.717622  [   96/  126]
train() client id: f_00000-7-0 loss: 1.065394  [   32/  126]
train() client id: f_00000-7-1 loss: 0.788944  [   64/  126]
train() client id: f_00000-7-2 loss: 0.683556  [   96/  126]
train() client id: f_00000-8-0 loss: 1.010723  [   32/  126]
train() client id: f_00000-8-1 loss: 0.877482  [   64/  126]
train() client id: f_00000-8-2 loss: 0.799957  [   96/  126]
train() client id: f_00000-9-0 loss: 0.747105  [   32/  126]
train() client id: f_00000-9-1 loss: 0.977597  [   64/  126]
train() client id: f_00000-9-2 loss: 0.810099  [   96/  126]
train() client id: f_00000-10-0 loss: 0.754082  [   32/  126]
train() client id: f_00000-10-1 loss: 0.789225  [   64/  126]
train() client id: f_00000-10-2 loss: 0.997961  [   96/  126]
train() client id: f_00000-11-0 loss: 1.032466  [   32/  126]
train() client id: f_00000-11-1 loss: 0.840910  [   64/  126]
train() client id: f_00000-11-2 loss: 0.808285  [   96/  126]
train() client id: f_00000-12-0 loss: 0.819087  [   32/  126]
train() client id: f_00000-12-1 loss: 0.984256  [   64/  126]
train() client id: f_00000-12-2 loss: 0.887190  [   96/  126]
train() client id: f_00001-0-0 loss: 0.912713  [   32/  265]
train() client id: f_00001-0-1 loss: 0.982828  [   64/  265]
train() client id: f_00001-0-2 loss: 0.982725  [   96/  265]
train() client id: f_00001-0-3 loss: 0.967879  [  128/  265]
train() client id: f_00001-0-4 loss: 1.038139  [  160/  265]
train() client id: f_00001-0-5 loss: 0.991772  [  192/  265]
train() client id: f_00001-0-6 loss: 0.895944  [  224/  265]
train() client id: f_00001-0-7 loss: 0.942840  [  256/  265]
train() client id: f_00001-1-0 loss: 0.939065  [   32/  265]
train() client id: f_00001-1-1 loss: 0.916210  [   64/  265]
train() client id: f_00001-1-2 loss: 1.001431  [   96/  265]
train() client id: f_00001-1-3 loss: 0.900683  [  128/  265]
train() client id: f_00001-1-4 loss: 0.953589  [  160/  265]
train() client id: f_00001-1-5 loss: 1.097816  [  192/  265]
train() client id: f_00001-1-6 loss: 1.012696  [  224/  265]
train() client id: f_00001-1-7 loss: 1.054718  [  256/  265]
train() client id: f_00001-2-0 loss: 0.967977  [   32/  265]
train() client id: f_00001-2-1 loss: 0.965889  [   64/  265]
train() client id: f_00001-2-2 loss: 1.008490  [   96/  265]
train() client id: f_00001-2-3 loss: 0.967491  [  128/  265]
train() client id: f_00001-2-4 loss: 0.992665  [  160/  265]
train() client id: f_00001-2-5 loss: 0.991504  [  192/  265]
train() client id: f_00001-2-6 loss: 1.100306  [  224/  265]
train() client id: f_00001-2-7 loss: 1.038740  [  256/  265]
train() client id: f_00001-3-0 loss: 1.047006  [   32/  265]
train() client id: f_00001-3-1 loss: 1.014376  [   64/  265]
train() client id: f_00001-3-2 loss: 1.033159  [   96/  265]
train() client id: f_00001-3-3 loss: 1.090451  [  128/  265]
train() client id: f_00001-3-4 loss: 1.063767  [  160/  265]
train() client id: f_00001-3-5 loss: 1.003336  [  192/  265]
train() client id: f_00001-3-6 loss: 1.002471  [  224/  265]
train() client id: f_00001-3-7 loss: 1.022864  [  256/  265]
train() client id: f_00001-4-0 loss: 1.063112  [   32/  265]
train() client id: f_00001-4-1 loss: 1.080248  [   64/  265]
train() client id: f_00001-4-2 loss: 1.045446  [   96/  265]
train() client id: f_00001-4-3 loss: 1.089996  [  128/  265]
train() client id: f_00001-4-4 loss: 1.117131  [  160/  265]
train() client id: f_00001-4-5 loss: 1.040423  [  192/  265]
train() client id: f_00001-4-6 loss: 1.091566  [  224/  265]
train() client id: f_00001-4-7 loss: 0.977308  [  256/  265]
train() client id: f_00001-5-0 loss: 1.102981  [   32/  265]
train() client id: f_00001-5-1 loss: 1.055787  [   64/  265]
train() client id: f_00001-5-2 loss: 1.026193  [   96/  265]
train() client id: f_00001-5-3 loss: 1.102334  [  128/  265]
train() client id: f_00001-5-4 loss: 1.064623  [  160/  265]
train() client id: f_00001-5-5 loss: 1.114353  [  192/  265]
train() client id: f_00001-5-6 loss: 1.212180  [  224/  265]
train() client id: f_00001-5-7 loss: 1.093273  [  256/  265]
train() client id: f_00001-6-0 loss: 1.157027  [   32/  265]
train() client id: f_00001-6-1 loss: 1.087284  [   64/  265]
train() client id: f_00001-6-2 loss: 1.085525  [   96/  265]
train() client id: f_00001-6-3 loss: 1.087424  [  128/  265]
train() client id: f_00001-6-4 loss: 1.134108  [  160/  265]
train() client id: f_00001-6-5 loss: 1.157507  [  192/  265]
train() client id: f_00001-6-6 loss: 1.137270  [  224/  265]
train() client id: f_00001-6-7 loss: 1.138091  [  256/  265]
train() client id: f_00001-7-0 loss: 1.185899  [   32/  265]
train() client id: f_00001-7-1 loss: 1.111098  [   64/  265]
train() client id: f_00001-7-2 loss: 1.145214  [   96/  265]
train() client id: f_00001-7-3 loss: 1.144129  [  128/  265]
train() client id: f_00001-7-4 loss: 1.179518  [  160/  265]
train() client id: f_00001-7-5 loss: 1.136173  [  192/  265]
train() client id: f_00001-7-6 loss: 1.084799  [  224/  265]
train() client id: f_00001-7-7 loss: 1.243177  [  256/  265]
train() client id: f_00001-8-0 loss: 1.240279  [   32/  265]
train() client id: f_00001-8-1 loss: 1.149353  [   64/  265]
train() client id: f_00001-8-2 loss: 1.178964  [   96/  265]
train() client id: f_00001-8-3 loss: 1.155360  [  128/  265]
train() client id: f_00001-8-4 loss: 1.095495  [  160/  265]
train() client id: f_00001-8-5 loss: 1.240970  [  192/  265]
train() client id: f_00001-8-6 loss: 1.231669  [  224/  265]
train() client id: f_00001-8-7 loss: 1.165002  [  256/  265]
train() client id: f_00001-9-0 loss: 1.196198  [   32/  265]
train() client id: f_00001-9-1 loss: 1.199503  [   64/  265]
train() client id: f_00001-9-2 loss: 1.275750  [   96/  265]
train() client id: f_00001-9-3 loss: 1.138378  [  128/  265]
train() client id: f_00001-9-4 loss: 1.293806  [  160/  265]
train() client id: f_00001-9-5 loss: 1.154488  [  192/  265]
train() client id: f_00001-9-6 loss: 1.244408  [  224/  265]
train() client id: f_00001-9-7 loss: 1.163529  [  256/  265]
train() client id: f_00001-10-0 loss: 1.244885  [   32/  265]
train() client id: f_00001-10-1 loss: 1.273858  [   64/  265]
train() client id: f_00001-10-2 loss: 1.185530  [   96/  265]
train() client id: f_00001-10-3 loss: 1.173901  [  128/  265]
train() client id: f_00001-10-4 loss: 1.212188  [  160/  265]
train() client id: f_00001-10-5 loss: 1.320919  [  192/  265]
train() client id: f_00001-10-6 loss: 1.273188  [  224/  265]
train() client id: f_00001-10-7 loss: 1.276226  [  256/  265]
train() client id: f_00001-11-0 loss: 1.357197  [   32/  265]
train() client id: f_00001-11-1 loss: 1.289055  [   64/  265]
train() client id: f_00001-11-2 loss: 1.197565  [   96/  265]
train() client id: f_00001-11-3 loss: 1.283797  [  128/  265]
train() client id: f_00001-11-4 loss: 1.223154  [  160/  265]
train() client id: f_00001-11-5 loss: 1.256842  [  192/  265]
train() client id: f_00001-11-6 loss: 1.277294  [  224/  265]
train() client id: f_00001-11-7 loss: 1.226140  [  256/  265]
train() client id: f_00001-12-0 loss: 1.370024  [   32/  265]
train() client id: f_00001-12-1 loss: 1.273888  [   64/  265]
train() client id: f_00001-12-2 loss: 1.269334  [   96/  265]
train() client id: f_00001-12-3 loss: 1.201163  [  128/  265]
train() client id: f_00001-12-4 loss: 1.198542  [  160/  265]
train() client id: f_00001-12-5 loss: 1.367018  [  192/  265]
train() client id: f_00001-12-6 loss: 1.308273  [  224/  265]
train() client id: f_00001-12-7 loss: 1.293814  [  256/  265]
train() client id: f_00002-0-0 loss: 0.995912  [   32/  124]
train() client id: f_00002-0-1 loss: 0.904688  [   64/  124]
train() client id: f_00002-0-2 loss: 0.994780  [   96/  124]
train() client id: f_00002-1-0 loss: 0.910172  [   32/  124]
train() client id: f_00002-1-1 loss: 1.035908  [   64/  124]
train() client id: f_00002-1-2 loss: 0.994521  [   96/  124]
train() client id: f_00002-2-0 loss: 0.967555  [   32/  124]
train() client id: f_00002-2-1 loss: 1.014450  [   64/  124]
train() client id: f_00002-2-2 loss: 1.008315  [   96/  124]
train() client id: f_00002-3-0 loss: 1.013556  [   32/  124]
train() client id: f_00002-3-1 loss: 1.030568  [   64/  124]
train() client id: f_00002-3-2 loss: 0.911001  [   96/  124]
train() client id: f_00002-4-0 loss: 1.019370  [   32/  124]
train() client id: f_00002-4-1 loss: 1.002470  [   64/  124]
train() client id: f_00002-4-2 loss: 0.989883  [   96/  124]
train() client id: f_00002-5-0 loss: 0.980102  [   32/  124]
train() client id: f_00002-5-1 loss: 1.055389  [   64/  124]
train() client id: f_00002-5-2 loss: 0.925305  [   96/  124]
train() client id: f_00002-6-0 loss: 1.005855  [   32/  124]
train() client id: f_00002-6-1 loss: 1.008478  [   64/  124]
train() client id: f_00002-6-2 loss: 1.056356  [   96/  124]
train() client id: f_00002-7-0 loss: 0.971469  [   32/  124]
train() client id: f_00002-7-1 loss: 0.981171  [   64/  124]
train() client id: f_00002-7-2 loss: 1.086601  [   96/  124]
train() client id: f_00002-8-0 loss: 0.982355  [   32/  124]
train() client id: f_00002-8-1 loss: 1.055896  [   64/  124]
train() client id: f_00002-8-2 loss: 1.038984  [   96/  124]
train() client id: f_00002-9-0 loss: 1.063976  [   32/  124]
train() client id: f_00002-9-1 loss: 1.002716  [   64/  124]
train() client id: f_00002-9-2 loss: 1.005303  [   96/  124]
train() client id: f_00002-10-0 loss: 1.022652  [   32/  124]
train() client id: f_00002-10-1 loss: 1.013174  [   64/  124]
train() client id: f_00002-10-2 loss: 1.118296  [   96/  124]
train() client id: f_00002-11-0 loss: 1.067640  [   32/  124]
train() client id: f_00002-11-1 loss: 1.081779  [   64/  124]
train() client id: f_00002-11-2 loss: 1.115558  [   96/  124]
train() client id: f_00002-12-0 loss: 1.137483  [   32/  124]
train() client id: f_00002-12-1 loss: 1.047632  [   64/  124]
train() client id: f_00002-12-2 loss: 1.054118  [   96/  124]
train() client id: f_00003-0-0 loss: 1.083295  [   32/   43]
train() client id: f_00003-1-0 loss: 1.015056  [   32/   43]
train() client id: f_00003-2-0 loss: 1.044179  [   32/   43]
train() client id: f_00003-3-0 loss: 1.024612  [   32/   43]
train() client id: f_00003-4-0 loss: 1.039352  [   32/   43]
train() client id: f_00003-5-0 loss: 1.016796  [   32/   43]
train() client id: f_00003-6-0 loss: 1.064570  [   32/   43]
train() client id: f_00003-7-0 loss: 1.053020  [   32/   43]
train() client id: f_00003-8-0 loss: 1.012056  [   32/   43]
train() client id: f_00003-9-0 loss: 1.070290  [   32/   43]
train() client id: f_00003-10-0 loss: 1.085063  [   32/   43]
train() client id: f_00003-11-0 loss: 1.013306  [   32/   43]
train() client id: f_00003-12-0 loss: 1.085806  [   32/   43]
train() client id: f_00004-0-0 loss: 1.192011  [   32/  306]
train() client id: f_00004-0-1 loss: 1.159179  [   64/  306]
train() client id: f_00004-0-2 loss: 1.101550  [   96/  306]
train() client id: f_00004-0-3 loss: 1.132616  [  128/  306]
train() client id: f_00004-0-4 loss: 1.022066  [  160/  306]
train() client id: f_00004-0-5 loss: 1.145697  [  192/  306]
train() client id: f_00004-0-6 loss: 1.099991  [  224/  306]
train() client id: f_00004-0-7 loss: 1.142786  [  256/  306]
train() client id: f_00004-0-8 loss: 1.062959  [  288/  306]
train() client id: f_00004-1-0 loss: 1.183625  [   32/  306]
train() client id: f_00004-1-1 loss: 1.178674  [   64/  306]
train() client id: f_00004-1-2 loss: 1.113524  [   96/  306]
train() client id: f_00004-1-3 loss: 1.020435  [  128/  306]
train() client id: f_00004-1-4 loss: 1.103936  [  160/  306]
train() client id: f_00004-1-5 loss: 1.182812  [  192/  306]
train() client id: f_00004-1-6 loss: 1.053032  [  224/  306]
train() client id: f_00004-1-7 loss: 1.127402  [  256/  306]
train() client id: f_00004-1-8 loss: 1.110736  [  288/  306]
train() client id: f_00004-2-0 loss: 1.188717  [   32/  306]
train() client id: f_00004-2-1 loss: 1.073318  [   64/  306]
train() client id: f_00004-2-2 loss: 1.206675  [   96/  306]
train() client id: f_00004-2-3 loss: 1.112779  [  128/  306]
train() client id: f_00004-2-4 loss: 1.147730  [  160/  306]
train() client id: f_00004-2-5 loss: 1.125666  [  192/  306]
train() client id: f_00004-2-6 loss: 1.107806  [  224/  306]
train() client id: f_00004-2-7 loss: 1.079330  [  256/  306]
train() client id: f_00004-2-8 loss: 1.070871  [  288/  306]
train() client id: f_00004-3-0 loss: 1.160059  [   32/  306]
train() client id: f_00004-3-1 loss: 1.106730  [   64/  306]
train() client id: f_00004-3-2 loss: 1.040269  [   96/  306]
train() client id: f_00004-3-3 loss: 1.098987  [  128/  306]
train() client id: f_00004-3-4 loss: 1.154421  [  160/  306]
train() client id: f_00004-3-5 loss: 1.219681  [  192/  306]
train() client id: f_00004-3-6 loss: 1.163183  [  224/  306]
train() client id: f_00004-3-7 loss: 1.041091  [  256/  306]
train() client id: f_00004-3-8 loss: 1.053474  [  288/  306]
train() client id: f_00004-4-0 loss: 1.201363  [   32/  306]
train() client id: f_00004-4-1 loss: 1.076699  [   64/  306]
train() client id: f_00004-4-2 loss: 1.087719  [   96/  306]
train() client id: f_00004-4-3 loss: 1.224677  [  128/  306]
train() client id: f_00004-4-4 loss: 1.137159  [  160/  306]
train() client id: f_00004-4-5 loss: 1.137940  [  192/  306]
train() client id: f_00004-4-6 loss: 1.103831  [  224/  306]
train() client id: f_00004-4-7 loss: 1.088248  [  256/  306]
train() client id: f_00004-4-8 loss: 1.076940  [  288/  306]
train() client id: f_00004-5-0 loss: 1.122811  [   32/  306]
train() client id: f_00004-5-1 loss: 1.052309  [   64/  306]
train() client id: f_00004-5-2 loss: 1.156453  [   96/  306]
train() client id: f_00004-5-3 loss: 1.209141  [  128/  306]
train() client id: f_00004-5-4 loss: 1.113822  [  160/  306]
train() client id: f_00004-5-5 loss: 1.158596  [  192/  306]
train() client id: f_00004-5-6 loss: 1.169507  [  224/  306]
train() client id: f_00004-5-7 loss: 1.040849  [  256/  306]
train() client id: f_00004-5-8 loss: 1.001565  [  288/  306]
train() client id: f_00004-6-0 loss: 1.130387  [   32/  306]
train() client id: f_00004-6-1 loss: 1.131924  [   64/  306]
train() client id: f_00004-6-2 loss: 1.087742  [   96/  306]
train() client id: f_00004-6-3 loss: 1.076681  [  128/  306]
train() client id: f_00004-6-4 loss: 1.131222  [  160/  306]
train() client id: f_00004-6-5 loss: 1.278649  [  192/  306]
train() client id: f_00004-6-6 loss: 1.002926  [  224/  306]
train() client id: f_00004-6-7 loss: 1.158896  [  256/  306]
train() client id: f_00004-6-8 loss: 1.130619  [  288/  306]
train() client id: f_00004-7-0 loss: 1.099184  [   32/  306]
train() client id: f_00004-7-1 loss: 1.194243  [   64/  306]
train() client id: f_00004-7-2 loss: 1.130120  [   96/  306]
train() client id: f_00004-7-3 loss: 1.087713  [  128/  306]
train() client id: f_00004-7-4 loss: 1.058831  [  160/  306]
train() client id: f_00004-7-5 loss: 1.076502  [  192/  306]
train() client id: f_00004-7-6 loss: 1.115888  [  224/  306]
train() client id: f_00004-7-7 loss: 1.016176  [  256/  306]
train() client id: f_00004-7-8 loss: 1.203021  [  288/  306]
train() client id: f_00004-8-0 loss: 1.097867  [   32/  306]
train() client id: f_00004-8-1 loss: 1.116363  [   64/  306]
train() client id: f_00004-8-2 loss: 1.051796  [   96/  306]
train() client id: f_00004-8-3 loss: 1.124295  [  128/  306]
train() client id: f_00004-8-4 loss: 1.219972  [  160/  306]
train() client id: f_00004-8-5 loss: 1.071323  [  192/  306]
train() client id: f_00004-8-6 loss: 1.131282  [  224/  306]
train() client id: f_00004-8-7 loss: 1.115912  [  256/  306]
train() client id: f_00004-8-8 loss: 1.150506  [  288/  306]
train() client id: f_00004-9-0 loss: 1.171524  [   32/  306]
train() client id: f_00004-9-1 loss: 1.145477  [   64/  306]
train() client id: f_00004-9-2 loss: 1.078087  [   96/  306]
train() client id: f_00004-9-3 loss: 1.132982  [  128/  306]
train() client id: f_00004-9-4 loss: 1.171426  [  160/  306]
train() client id: f_00004-9-5 loss: 1.164973  [  192/  306]
train() client id: f_00004-9-6 loss: 1.108467  [  224/  306]
train() client id: f_00004-9-7 loss: 1.123538  [  256/  306]
train() client id: f_00004-9-8 loss: 1.022905  [  288/  306]
train() client id: f_00004-10-0 loss: 1.089977  [   32/  306]
train() client id: f_00004-10-1 loss: 1.044836  [   64/  306]
train() client id: f_00004-10-2 loss: 1.121222  [   96/  306]
train() client id: f_00004-10-3 loss: 1.181971  [  128/  306]
train() client id: f_00004-10-4 loss: 1.078333  [  160/  306]
train() client id: f_00004-10-5 loss: 1.141084  [  192/  306]
train() client id: f_00004-10-6 loss: 1.067594  [  224/  306]
train() client id: f_00004-10-7 loss: 1.147053  [  256/  306]
train() client id: f_00004-10-8 loss: 1.247612  [  288/  306]
train() client id: f_00004-11-0 loss: 1.049956  [   32/  306]
train() client id: f_00004-11-1 loss: 1.168612  [   64/  306]
train() client id: f_00004-11-2 loss: 1.115884  [   96/  306]
train() client id: f_00004-11-3 loss: 1.056447  [  128/  306]
train() client id: f_00004-11-4 loss: 1.052785  [  160/  306]
train() client id: f_00004-11-5 loss: 1.146853  [  192/  306]
train() client id: f_00004-11-6 loss: 1.211397  [  224/  306]
train() client id: f_00004-11-7 loss: 1.177876  [  256/  306]
train() client id: f_00004-11-8 loss: 1.076125  [  288/  306]
train() client id: f_00004-12-0 loss: 1.102031  [   32/  306]
train() client id: f_00004-12-1 loss: 1.164439  [   64/  306]
train() client id: f_00004-12-2 loss: 1.097849  [   96/  306]
train() client id: f_00004-12-3 loss: 1.057472  [  128/  306]
train() client id: f_00004-12-4 loss: 1.103262  [  160/  306]
train() client id: f_00004-12-5 loss: 1.154796  [  192/  306]
train() client id: f_00004-12-6 loss: 1.109127  [  224/  306]
train() client id: f_00004-12-7 loss: 1.118306  [  256/  306]
train() client id: f_00004-12-8 loss: 1.211423  [  288/  306]
train() client id: f_00005-0-0 loss: 1.001286  [   32/  146]
train() client id: f_00005-0-1 loss: 0.992829  [   64/  146]
train() client id: f_00005-0-2 loss: 1.013902  [   96/  146]
train() client id: f_00005-0-3 loss: 1.022576  [  128/  146]
train() client id: f_00005-1-0 loss: 1.028280  [   32/  146]
train() client id: f_00005-1-1 loss: 0.990002  [   64/  146]
train() client id: f_00005-1-2 loss: 1.035613  [   96/  146]
train() client id: f_00005-1-3 loss: 1.018335  [  128/  146]
train() client id: f_00005-2-0 loss: 1.025757  [   32/  146]
train() client id: f_00005-2-1 loss: 1.068088  [   64/  146]
train() client id: f_00005-2-2 loss: 0.999602  [   96/  146]
train() client id: f_00005-2-3 loss: 1.044155  [  128/  146]
train() client id: f_00005-3-0 loss: 1.043483  [   32/  146]
train() client id: f_00005-3-1 loss: 1.020053  [   64/  146]
train() client id: f_00005-3-2 loss: 1.008817  [   96/  146]
train() client id: f_00005-3-3 loss: 1.155419  [  128/  146]
train() client id: f_00005-4-0 loss: 1.063535  [   32/  146]
train() client id: f_00005-4-1 loss: 1.102598  [   64/  146]
train() client id: f_00005-4-2 loss: 1.031142  [   96/  146]
train() client id: f_00005-4-3 loss: 1.083990  [  128/  146]
train() client id: f_00005-5-0 loss: 1.086416  [   32/  146]
train() client id: f_00005-5-1 loss: 1.060679  [   64/  146]
train() client id: f_00005-5-2 loss: 1.093847  [   96/  146]
train() client id: f_00005-5-3 loss: 1.086091  [  128/  146]
train() client id: f_00005-6-0 loss: 1.103075  [   32/  146]
train() client id: f_00005-6-1 loss: 1.108102  [   64/  146]
train() client id: f_00005-6-2 loss: 1.090361  [   96/  146]
train() client id: f_00005-6-3 loss: 1.083183  [  128/  146]
train() client id: f_00005-7-0 loss: 1.089853  [   32/  146]
train() client id: f_00005-7-1 loss: 1.235850  [   64/  146]
train() client id: f_00005-7-2 loss: 1.115651  [   96/  146]
train() client id: f_00005-7-3 loss: 1.150847  [  128/  146]
train() client id: f_00005-8-0 loss: 1.220738  [   32/  146]
train() client id: f_00005-8-1 loss: 1.083319  [   64/  146]
train() client id: f_00005-8-2 loss: 1.195668  [   96/  146]
train() client id: f_00005-8-3 loss: 1.196782  [  128/  146]
train() client id: f_00005-9-0 loss: 1.181818  [   32/  146]
train() client id: f_00005-9-1 loss: 1.180315  [   64/  146]
train() client id: f_00005-9-2 loss: 1.191483  [   96/  146]
train() client id: f_00005-9-3 loss: 1.228657  [  128/  146]
train() client id: f_00005-10-0 loss: 1.193575  [   32/  146]
train() client id: f_00005-10-1 loss: 1.166037  [   64/  146]
train() client id: f_00005-10-2 loss: 1.295613  [   96/  146]
train() client id: f_00005-10-3 loss: 1.226473  [  128/  146]
train() client id: f_00005-11-0 loss: 1.243134  [   32/  146]
train() client id: f_00005-11-1 loss: 1.280375  [   64/  146]
train() client id: f_00005-11-2 loss: 1.211966  [   96/  146]
train() client id: f_00005-11-3 loss: 1.219392  [  128/  146]
train() client id: f_00005-12-0 loss: 1.257528  [   32/  146]
train() client id: f_00005-12-1 loss: 1.247695  [   64/  146]
train() client id: f_00005-12-2 loss: 1.285112  [   96/  146]
train() client id: f_00005-12-3 loss: 1.254777  [  128/  146]
train() client id: f_00006-0-0 loss: 1.137783  [   32/   54]
train() client id: f_00006-1-0 loss: 1.044901  [   32/   54]
train() client id: f_00006-2-0 loss: 1.093279  [   32/   54]
train() client id: f_00006-3-0 loss: 1.090137  [   32/   54]
train() client id: f_00006-4-0 loss: 1.093943  [   32/   54]
train() client id: f_00006-5-0 loss: 1.116518  [   32/   54]
train() client id: f_00006-6-0 loss: 1.156001  [   32/   54]
train() client id: f_00006-7-0 loss: 1.108155  [   32/   54]
train() client id: f_00006-8-0 loss: 1.089407  [   32/   54]
train() client id: f_00006-9-0 loss: 1.138548  [   32/   54]
train() client id: f_00006-10-0 loss: 1.057555  [   32/   54]
train() client id: f_00006-11-0 loss: 1.071386  [   32/   54]
train() client id: f_00006-12-0 loss: 1.096385  [   32/   54]
train() client id: f_00007-0-0 loss: 0.972427  [   32/  179]
train() client id: f_00007-0-1 loss: 0.914850  [   64/  179]
train() client id: f_00007-0-2 loss: 1.000013  [   96/  179]
train() client id: f_00007-0-3 loss: 0.986010  [  128/  179]
train() client id: f_00007-0-4 loss: 0.899560  [  160/  179]
train() client id: f_00007-1-0 loss: 0.911485  [   32/  179]
train() client id: f_00007-1-1 loss: 0.996930  [   64/  179]
train() client id: f_00007-1-2 loss: 1.038781  [   96/  179]
train() client id: f_00007-1-3 loss: 0.943225  [  128/  179]
train() client id: f_00007-1-4 loss: 1.010520  [  160/  179]
train() client id: f_00007-2-0 loss: 1.030459  [   32/  179]
train() client id: f_00007-2-1 loss: 0.899349  [   64/  179]
train() client id: f_00007-2-2 loss: 0.960556  [   96/  179]
train() client id: f_00007-2-3 loss: 0.968841  [  128/  179]
train() client id: f_00007-2-4 loss: 0.988108  [  160/  179]
train() client id: f_00007-3-0 loss: 0.955592  [   32/  179]
train() client id: f_00007-3-1 loss: 1.000470  [   64/  179]
train() client id: f_00007-3-2 loss: 1.016378  [   96/  179]
train() client id: f_00007-3-3 loss: 1.005099  [  128/  179]
train() client id: f_00007-3-4 loss: 0.924878  [  160/  179]
train() client id: f_00007-4-0 loss: 0.912138  [   32/  179]
train() client id: f_00007-4-1 loss: 1.026267  [   64/  179]
train() client id: f_00007-4-2 loss: 0.974314  [   96/  179]
train() client id: f_00007-4-3 loss: 1.076618  [  128/  179]
train() client id: f_00007-4-4 loss: 0.998009  [  160/  179]
train() client id: f_00007-5-0 loss: 1.022747  [   32/  179]
train() client id: f_00007-5-1 loss: 1.029129  [   64/  179]
train() client id: f_00007-5-2 loss: 1.071094  [   96/  179]
train() client id: f_00007-5-3 loss: 0.933529  [  128/  179]
train() client id: f_00007-5-4 loss: 0.977632  [  160/  179]
train() client id: f_00007-6-0 loss: 0.985733  [   32/  179]
train() client id: f_00007-6-1 loss: 0.996882  [   64/  179]
train() client id: f_00007-6-2 loss: 1.016555  [   96/  179]
train() client id: f_00007-6-3 loss: 1.013455  [  128/  179]
train() client id: f_00007-6-4 loss: 1.080658  [  160/  179]
train() client id: f_00007-7-0 loss: 1.020502  [   32/  179]
train() client id: f_00007-7-1 loss: 0.986145  [   64/  179]
train() client id: f_00007-7-2 loss: 1.051408  [   96/  179]
train() client id: f_00007-7-3 loss: 1.007536  [  128/  179]
train() client id: f_00007-7-4 loss: 1.103893  [  160/  179]
train() client id: f_00007-8-0 loss: 1.056260  [   32/  179]
train() client id: f_00007-8-1 loss: 1.020095  [   64/  179]
train() client id: f_00007-8-2 loss: 1.080638  [   96/  179]
train() client id: f_00007-8-3 loss: 1.058231  [  128/  179]
train() client id: f_00007-8-4 loss: 1.010782  [  160/  179]
train() client id: f_00007-9-0 loss: 1.047068  [   32/  179]
train() client id: f_00007-9-1 loss: 1.045285  [   64/  179]
train() client id: f_00007-9-2 loss: 1.033495  [   96/  179]
train() client id: f_00007-9-3 loss: 1.026228  [  128/  179]
train() client id: f_00007-9-4 loss: 1.142940  [  160/  179]
train() client id: f_00007-10-0 loss: 1.065138  [   32/  179]
train() client id: f_00007-10-1 loss: 0.993435  [   64/  179]
train() client id: f_00007-10-2 loss: 1.064118  [   96/  179]
train() client id: f_00007-10-3 loss: 1.097616  [  128/  179]
train() client id: f_00007-10-4 loss: 1.043844  [  160/  179]
train() client id: f_00007-11-0 loss: 1.199311  [   32/  179]
train() client id: f_00007-11-1 loss: 1.049266  [   64/  179]
train() client id: f_00007-11-2 loss: 1.060166  [   96/  179]
train() client id: f_00007-11-3 loss: 1.125682  [  128/  179]
train() client id: f_00007-11-4 loss: 1.044318  [  160/  179]
train() client id: f_00007-12-0 loss: 1.031767  [   32/  179]
train() client id: f_00007-12-1 loss: 1.113432  [   64/  179]
train() client id: f_00007-12-2 loss: 1.164892  [   96/  179]
train() client id: f_00007-12-3 loss: 1.140485  [  128/  179]
train() client id: f_00007-12-4 loss: 1.053724  [  160/  179]
train() client id: f_00008-0-0 loss: 1.148881  [   32/  130]
train() client id: f_00008-0-1 loss: 1.176809  [   64/  130]
train() client id: f_00008-0-2 loss: 1.157796  [   96/  130]
train() client id: f_00008-0-3 loss: 1.293804  [  128/  130]
train() client id: f_00008-1-0 loss: 1.084710  [   32/  130]
train() client id: f_00008-1-1 loss: 1.148750  [   64/  130]
train() client id: f_00008-1-2 loss: 1.270361  [   96/  130]
train() client id: f_00008-1-3 loss: 1.281059  [  128/  130]
train() client id: f_00008-2-0 loss: 1.261877  [   32/  130]
train() client id: f_00008-2-1 loss: 1.187735  [   64/  130]
train() client id: f_00008-2-2 loss: 1.156595  [   96/  130]
train() client id: f_00008-2-3 loss: 1.143505  [  128/  130]
train() client id: f_00008-3-0 loss: 1.275125  [   32/  130]
train() client id: f_00008-3-1 loss: 1.240950  [   64/  130]
train() client id: f_00008-3-2 loss: 1.092308  [   96/  130]
train() client id: f_00008-3-3 loss: 1.188358  [  128/  130]
train() client id: f_00008-4-0 loss: 1.144932  [   32/  130]
train() client id: f_00008-4-1 loss: 1.341238  [   64/  130]
train() client id: f_00008-4-2 loss: 1.179976  [   96/  130]
train() client id: f_00008-4-3 loss: 1.089696  [  128/  130]
train() client id: f_00008-5-0 loss: 1.193855  [   32/  130]
train() client id: f_00008-5-1 loss: 1.213526  [   64/  130]
train() client id: f_00008-5-2 loss: 1.120507  [   96/  130]
train() client id: f_00008-5-3 loss: 1.212198  [  128/  130]
train() client id: f_00008-6-0 loss: 1.177562  [   32/  130]
train() client id: f_00008-6-1 loss: 1.259328  [   64/  130]
train() client id: f_00008-6-2 loss: 1.156060  [   96/  130]
train() client id: f_00008-6-3 loss: 1.227175  [  128/  130]
train() client id: f_00008-7-0 loss: 1.178456  [   32/  130]
train() client id: f_00008-7-1 loss: 1.212975  [   64/  130]
train() client id: f_00008-7-2 loss: 1.246498  [   96/  130]
train() client id: f_00008-7-3 loss: 1.222202  [  128/  130]
train() client id: f_00008-8-0 loss: 1.193635  [   32/  130]
train() client id: f_00008-8-1 loss: 1.134815  [   64/  130]
train() client id: f_00008-8-2 loss: 1.252375  [   96/  130]
train() client id: f_00008-8-3 loss: 1.287702  [  128/  130]
train() client id: f_00008-9-0 loss: 1.214674  [   32/  130]
train() client id: f_00008-9-1 loss: 1.252602  [   64/  130]
train() client id: f_00008-9-2 loss: 1.169635  [   96/  130]
train() client id: f_00008-9-3 loss: 1.218815  [  128/  130]
train() client id: f_00008-10-0 loss: 1.278136  [   32/  130]
train() client id: f_00008-10-1 loss: 1.269895  [   64/  130]
train() client id: f_00008-10-2 loss: 1.289623  [   96/  130]
train() client id: f_00008-10-3 loss: 1.054060  [  128/  130]
train() client id: f_00008-11-0 loss: 1.179032  [   32/  130]
train() client id: f_00008-11-1 loss: 1.227563  [   64/  130]
train() client id: f_00008-11-2 loss: 1.377775  [   96/  130]
train() client id: f_00008-11-3 loss: 1.145561  [  128/  130]
train() client id: f_00008-12-0 loss: 1.302614  [   32/  130]
train() client id: f_00008-12-1 loss: 1.180155  [   64/  130]
train() client id: f_00008-12-2 loss: 1.252186  [   96/  130]
train() client id: f_00008-12-3 loss: 1.235997  [  128/  130]
train() client id: f_00009-0-0 loss: 0.894572  [   32/  118]
train() client id: f_00009-0-1 loss: 0.991079  [   64/  118]
train() client id: f_00009-0-2 loss: 0.894773  [   96/  118]
train() client id: f_00009-1-0 loss: 0.948397  [   32/  118]
train() client id: f_00009-1-1 loss: 0.948734  [   64/  118]
train() client id: f_00009-1-2 loss: 0.865250  [   96/  118]
train() client id: f_00009-2-0 loss: 0.856895  [   32/  118]
train() client id: f_00009-2-1 loss: 1.049351  [   64/  118]
train() client id: f_00009-2-2 loss: 0.947078  [   96/  118]
train() client id: f_00009-3-0 loss: 0.844090  [   32/  118]
train() client id: f_00009-3-1 loss: 0.954115  [   64/  118]
train() client id: f_00009-3-2 loss: 0.999999  [   96/  118]
train() client id: f_00009-4-0 loss: 0.936109  [   32/  118]
train() client id: f_00009-4-1 loss: 0.879290  [   64/  118]
train() client id: f_00009-4-2 loss: 1.010647  [   96/  118]
train() client id: f_00009-5-0 loss: 0.944148  [   32/  118]
train() client id: f_00009-5-1 loss: 0.890784  [   64/  118]
train() client id: f_00009-5-2 loss: 0.979506  [   96/  118]
train() client id: f_00009-6-0 loss: 0.987013  [   32/  118]
train() client id: f_00009-6-1 loss: 0.958518  [   64/  118]
train() client id: f_00009-6-2 loss: 0.957036  [   96/  118]
train() client id: f_00009-7-0 loss: 0.920916  [   32/  118]
train() client id: f_00009-7-1 loss: 0.983585  [   64/  118]
train() client id: f_00009-7-2 loss: 0.952528  [   96/  118]
train() client id: f_00009-8-0 loss: 0.944018  [   32/  118]
train() client id: f_00009-8-1 loss: 1.002656  [   64/  118]
train() client id: f_00009-8-2 loss: 1.014199  [   96/  118]
train() client id: f_00009-9-0 loss: 1.120804  [   32/  118]
train() client id: f_00009-9-1 loss: 0.903868  [   64/  118]
train() client id: f_00009-9-2 loss: 0.908328  [   96/  118]
train() client id: f_00009-10-0 loss: 1.017793  [   32/  118]
train() client id: f_00009-10-1 loss: 0.913524  [   64/  118]
train() client id: f_00009-10-2 loss: 1.023136  [   96/  118]
train() client id: f_00009-11-0 loss: 1.101790  [   32/  118]
train() client id: f_00009-11-1 loss: 0.917693  [   64/  118]
train() client id: f_00009-11-2 loss: 0.929997  [   96/  118]
train() client id: f_00009-12-0 loss: 0.952170  [   32/  118]
train() client id: f_00009-12-1 loss: 1.004369  [   64/  118]
train() client id: f_00009-12-2 loss: 1.028152  [   96/  118]
At round 0 accuracy: 0.35543766578249336
At round 0 training accuracy: 0.2917505030181087
At round 0 training loss: 1.1547749854642593
gradient difference: 0.4216514527797699
train() client id: f_00000-0-0 loss: 0.922405  [   32/  126]
train() client id: f_00000-0-1 loss: 0.803446  [   64/  126]
train() client id: f_00000-0-2 loss: 0.884796  [   96/  126]
train() client id: f_00000-1-0 loss: 0.817838  [   32/  126]
train() client id: f_00000-1-1 loss: 0.791791  [   64/  126]
train() client id: f_00000-1-2 loss: 0.824295  [   96/  126]
train() client id: f_00000-2-0 loss: 0.886032  [   32/  126]
train() client id: f_00000-2-1 loss: 0.696346  [   64/  126]
train() client id: f_00000-2-2 loss: 0.741167  [   96/  126]
train() client id: f_00000-3-0 loss: 0.822583  [   32/  126]
train() client id: f_00000-3-1 loss: 0.777426  [   64/  126]
train() client id: f_00000-3-2 loss: 0.695882  [   96/  126]
train() client id: f_00000-4-0 loss: 0.700386  [   32/  126]
train() client id: f_00000-4-1 loss: 0.700491  [   64/  126]
train() client id: f_00000-4-2 loss: 0.801607  [   96/  126]
train() client id: f_00000-5-0 loss: 0.762683  [   32/  126]
train() client id: f_00000-5-1 loss: 0.730442  [   64/  126]
train() client id: f_00000-5-2 loss: 0.691100  [   96/  126]
train() client id: f_00000-6-0 loss: 0.768600  [   32/  126]
train() client id: f_00000-6-1 loss: 0.725758  [   64/  126]
train() client id: f_00000-6-2 loss: 0.764851  [   96/  126]
train() client id: f_00000-7-0 loss: 0.816089  [   32/  126]
train() client id: f_00000-7-1 loss: 0.772808  [   64/  126]
train() client id: f_00000-7-2 loss: 0.672419  [   96/  126]
train() client id: f_00000-8-0 loss: 0.628160  [   32/  126]
train() client id: f_00000-8-1 loss: 0.726281  [   64/  126]
train() client id: f_00000-8-2 loss: 0.794915  [   96/  126]
train() client id: f_00000-9-0 loss: 0.680748  [   32/  126]
train() client id: f_00000-9-1 loss: 0.688538  [   64/  126]
train() client id: f_00000-9-2 loss: 0.800466  [   96/  126]
train() client id: f_00000-10-0 loss: 0.731738  [   32/  126]
train() client id: f_00000-10-1 loss: 0.672003  [   64/  126]
train() client id: f_00000-10-2 loss: 0.780916  [   96/  126]
train() client id: f_00000-11-0 loss: 0.618778  [   32/  126]
train() client id: f_00000-11-1 loss: 0.742528  [   64/  126]
train() client id: f_00000-11-2 loss: 0.772947  [   96/  126]
train() client id: f_00000-12-0 loss: 0.608053  [   32/  126]
train() client id: f_00000-12-1 loss: 0.799879  [   64/  126]
train() client id: f_00000-12-2 loss: 0.718907  [   96/  126]
train() client id: f_00001-0-0 loss: 1.212981  [   32/  265]
train() client id: f_00001-0-1 loss: 1.271046  [   64/  265]
train() client id: f_00001-0-2 loss: 1.055518  [   96/  265]
train() client id: f_00001-0-3 loss: 1.176613  [  128/  265]
train() client id: f_00001-0-4 loss: 1.179823  [  160/  265]
train() client id: f_00001-0-5 loss: 1.168969  [  192/  265]
train() client id: f_00001-0-6 loss: 1.156219  [  224/  265]
train() client id: f_00001-0-7 loss: 1.084734  [  256/  265]
train() client id: f_00001-1-0 loss: 1.065129  [   32/  265]
train() client id: f_00001-1-1 loss: 1.035370  [   64/  265]
train() client id: f_00001-1-2 loss: 1.046754  [   96/  265]
train() client id: f_00001-1-3 loss: 0.977919  [  128/  265]
train() client id: f_00001-1-4 loss: 1.015876  [  160/  265]
train() client id: f_00001-1-5 loss: 0.948328  [  192/  265]
train() client id: f_00001-1-6 loss: 0.957566  [  224/  265]
train() client id: f_00001-1-7 loss: 0.895332  [  256/  265]
train() client id: f_00001-2-0 loss: 0.905221  [   32/  265]
train() client id: f_00001-2-1 loss: 0.937936  [   64/  265]
train() client id: f_00001-2-2 loss: 0.883256  [   96/  265]
train() client id: f_00001-2-3 loss: 0.865264  [  128/  265]
train() client id: f_00001-2-4 loss: 0.911693  [  160/  265]
train() client id: f_00001-2-5 loss: 0.796611  [  192/  265]
train() client id: f_00001-2-6 loss: 0.864109  [  224/  265]
train() client id: f_00001-2-7 loss: 0.794935  [  256/  265]
train() client id: f_00001-3-0 loss: 0.861237  [   32/  265]
train() client id: f_00001-3-1 loss: 0.812081  [   64/  265]
train() client id: f_00001-3-2 loss: 0.834306  [   96/  265]
train() client id: f_00001-3-3 loss: 0.790830  [  128/  265]
train() client id: f_00001-3-4 loss: 0.805456  [  160/  265]
train() client id: f_00001-3-5 loss: 0.711293  [  192/  265]
train() client id: f_00001-3-6 loss: 0.714540  [  224/  265]
train() client id: f_00001-3-7 loss: 0.722798  [  256/  265]
train() client id: f_00001-4-0 loss: 0.765182  [   32/  265]
train() client id: f_00001-4-1 loss: 0.685619  [   64/  265]
train() client id: f_00001-4-2 loss: 0.696952  [   96/  265]
train() client id: f_00001-4-3 loss: 0.677199  [  128/  265]
train() client id: f_00001-4-4 loss: 0.736631  [  160/  265]
train() client id: f_00001-4-5 loss: 0.721525  [  192/  265]
train() client id: f_00001-4-6 loss: 0.734676  [  224/  265]
train() client id: f_00001-4-7 loss: 0.702823  [  256/  265]
train() client id: f_00001-5-0 loss: 0.700642  [   32/  265]
train() client id: f_00001-5-1 loss: 0.661469  [   64/  265]
train() client id: f_00001-5-2 loss: 0.688801  [   96/  265]
train() client id: f_00001-5-3 loss: 0.659517  [  128/  265]
train() client id: f_00001-5-4 loss: 0.694518  [  160/  265]
train() client id: f_00001-5-5 loss: 0.647065  [  192/  265]
train() client id: f_00001-5-6 loss: 0.733548  [  224/  265]
train() client id: f_00001-5-7 loss: 0.605614  [  256/  265]
train() client id: f_00001-6-0 loss: 0.714707  [   32/  265]
train() client id: f_00001-6-1 loss: 0.621331  [   64/  265]
train() client id: f_00001-6-2 loss: 0.627243  [   96/  265]
train() client id: f_00001-6-3 loss: 0.672074  [  128/  265]
train() client id: f_00001-6-4 loss: 0.631556  [  160/  265]
train() client id: f_00001-6-5 loss: 0.542531  [  192/  265]
train() client id: f_00001-6-6 loss: 0.661627  [  224/  265]
train() client id: f_00001-6-7 loss: 0.648704  [  256/  265]
train() client id: f_00001-7-0 loss: 0.569560  [   32/  265]
train() client id: f_00001-7-1 loss: 0.551849  [   64/  265]
train() client id: f_00001-7-2 loss: 0.649209  [   96/  265]
train() client id: f_00001-7-3 loss: 0.580617  [  128/  265]
train() client id: f_00001-7-4 loss: 0.653417  [  160/  265]
train() client id: f_00001-7-5 loss: 0.664721  [  192/  265]
train() client id: f_00001-7-6 loss: 0.582781  [  224/  265]
train() client id: f_00001-7-7 loss: 0.687943  [  256/  265]
train() client id: f_00001-8-0 loss: 0.604158  [   32/  265]
train() client id: f_00001-8-1 loss: 0.673160  [   64/  265]
train() client id: f_00001-8-2 loss: 0.559717  [   96/  265]
train() client id: f_00001-8-3 loss: 0.545068  [  128/  265]
train() client id: f_00001-8-4 loss: 0.663867  [  160/  265]
train() client id: f_00001-8-5 loss: 0.581711  [  192/  265]
train() client id: f_00001-8-6 loss: 0.566319  [  224/  265]
train() client id: f_00001-8-7 loss: 0.599648  [  256/  265]
train() client id: f_00001-9-0 loss: 0.553265  [   32/  265]
train() client id: f_00001-9-1 loss: 0.610040  [   64/  265]
train() client id: f_00001-9-2 loss: 0.623280  [   96/  265]
train() client id: f_00001-9-3 loss: 0.569740  [  128/  265]
train() client id: f_00001-9-4 loss: 0.599953  [  160/  265]
train() client id: f_00001-9-5 loss: 0.577174  [  192/  265]
train() client id: f_00001-9-6 loss: 0.595059  [  224/  265]
train() client id: f_00001-9-7 loss: 0.561435  [  256/  265]
train() client id: f_00001-10-0 loss: 0.559137  [   32/  265]
train() client id: f_00001-10-1 loss: 0.548018  [   64/  265]
train() client id: f_00001-10-2 loss: 0.582451  [   96/  265]
train() client id: f_00001-10-3 loss: 0.604747  [  128/  265]
train() client id: f_00001-10-4 loss: 0.545415  [  160/  265]
train() client id: f_00001-10-5 loss: 0.530111  [  192/  265]
train() client id: f_00001-10-6 loss: 0.646763  [  224/  265]
train() client id: f_00001-10-7 loss: 0.636328  [  256/  265]
train() client id: f_00001-11-0 loss: 0.598780  [   32/  265]
train() client id: f_00001-11-1 loss: 0.622757  [   64/  265]
train() client id: f_00001-11-2 loss: 0.564748  [   96/  265]
train() client id: f_00001-11-3 loss: 0.568226  [  128/  265]
train() client id: f_00001-11-4 loss: 0.580420  [  160/  265]
train() client id: f_00001-11-5 loss: 0.492441  [  192/  265]
train() client id: f_00001-11-6 loss: 0.610277  [  224/  265]
train() client id: f_00001-11-7 loss: 0.560631  [  256/  265]
train() client id: f_00001-12-0 loss: 0.555678  [   32/  265]
train() client id: f_00001-12-1 loss: 0.516618  [   64/  265]
train() client id: f_00001-12-2 loss: 0.557325  [   96/  265]
train() client id: f_00001-12-3 loss: 0.580042  [  128/  265]
train() client id: f_00001-12-4 loss: 0.604065  [  160/  265]
train() client id: f_00001-12-5 loss: 0.602173  [  192/  265]
train() client id: f_00001-12-6 loss: 0.649445  [  224/  265]
train() client id: f_00001-12-7 loss: 0.519098  [  256/  265]
train() client id: f_00002-0-0 loss: 1.200291  [   32/  124]
train() client id: f_00002-0-1 loss: 1.090437  [   64/  124]
train() client id: f_00002-0-2 loss: 1.220929  [   96/  124]
train() client id: f_00002-1-0 loss: 1.091381  [   32/  124]
train() client id: f_00002-1-1 loss: 1.160286  [   64/  124]
train() client id: f_00002-1-2 loss: 1.125483  [   96/  124]
train() client id: f_00002-2-0 loss: 1.070641  [   32/  124]
train() client id: f_00002-2-1 loss: 1.100494  [   64/  124]
train() client id: f_00002-2-2 loss: 1.088663  [   96/  124]
train() client id: f_00002-3-0 loss: 1.050645  [   32/  124]
train() client id: f_00002-3-1 loss: 1.044734  [   64/  124]
train() client id: f_00002-3-2 loss: 1.105002  [   96/  124]
train() client id: f_00002-4-0 loss: 1.046010  [   32/  124]
train() client id: f_00002-4-1 loss: 1.008527  [   64/  124]
train() client id: f_00002-4-2 loss: 1.034597  [   96/  124]
train() client id: f_00002-5-0 loss: 1.032310  [   32/  124]
train() client id: f_00002-5-1 loss: 0.973693  [   64/  124]
train() client id: f_00002-5-2 loss: 0.989852  [   96/  124]
train() client id: f_00002-6-0 loss: 1.010946  [   32/  124]
train() client id: f_00002-6-1 loss: 0.967926  [   64/  124]
train() client id: f_00002-6-2 loss: 0.918923  [   96/  124]
train() client id: f_00002-7-0 loss: 0.961096  [   32/  124]
train() client id: f_00002-7-1 loss: 0.945843  [   64/  124]
train() client id: f_00002-7-2 loss: 0.970838  [   96/  124]
train() client id: f_00002-8-0 loss: 0.890875  [   32/  124]
train() client id: f_00002-8-1 loss: 0.988658  [   64/  124]
train() client id: f_00002-8-2 loss: 0.981294  [   96/  124]
train() client id: f_00002-9-0 loss: 0.935398  [   32/  124]
train() client id: f_00002-9-1 loss: 1.012065  [   64/  124]
train() client id: f_00002-9-2 loss: 0.871972  [   96/  124]
train() client id: f_00002-10-0 loss: 0.951841  [   32/  124]
train() client id: f_00002-10-1 loss: 0.935413  [   64/  124]
train() client id: f_00002-10-2 loss: 0.936513  [   96/  124]
train() client id: f_00002-11-0 loss: 0.900245  [   32/  124]
train() client id: f_00002-11-1 loss: 0.970687  [   64/  124]
train() client id: f_00002-11-2 loss: 0.933649  [   96/  124]
train() client id: f_00002-12-0 loss: 0.923774  [   32/  124]
train() client id: f_00002-12-1 loss: 0.922639  [   64/  124]
train() client id: f_00002-12-2 loss: 0.895883  [   96/  124]
train() client id: f_00003-0-0 loss: 1.041350  [   32/   43]
train() client id: f_00003-1-0 loss: 1.029277  [   32/   43]
train() client id: f_00003-2-0 loss: 0.975377  [   32/   43]
train() client id: f_00003-3-0 loss: 1.045588  [   32/   43]
train() client id: f_00003-4-0 loss: 1.010071  [   32/   43]
train() client id: f_00003-5-0 loss: 0.989588  [   32/   43]
train() client id: f_00003-6-0 loss: 0.985555  [   32/   43]
train() client id: f_00003-7-0 loss: 1.008325  [   32/   43]
train() client id: f_00003-8-0 loss: 1.035198  [   32/   43]
train() client id: f_00003-9-0 loss: 0.983001  [   32/   43]
train() client id: f_00003-10-0 loss: 1.009315  [   32/   43]
train() client id: f_00003-11-0 loss: 1.017207  [   32/   43]
train() client id: f_00003-12-0 loss: 0.996347  [   32/   43]
train() client id: f_00004-0-0 loss: 0.960363  [   32/  306]
train() client id: f_00004-0-1 loss: 0.960282  [   64/  306]
train() client id: f_00004-0-2 loss: 0.912970  [   96/  306]
train() client id: f_00004-0-3 loss: 1.028910  [  128/  306]
train() client id: f_00004-0-4 loss: 0.862432  [  160/  306]
train() client id: f_00004-0-5 loss: 0.925979  [  192/  306]
train() client id: f_00004-0-6 loss: 0.922743  [  224/  306]
train() client id: f_00004-0-7 loss: 0.998555  [  256/  306]
train() client id: f_00004-0-8 loss: 1.007403  [  288/  306]
train() client id: f_00004-1-0 loss: 0.992492  [   32/  306]
train() client id: f_00004-1-1 loss: 0.900951  [   64/  306]
train() client id: f_00004-1-2 loss: 0.894558  [   96/  306]
train() client id: f_00004-1-3 loss: 0.988143  [  128/  306]
train() client id: f_00004-1-4 loss: 0.982314  [  160/  306]
train() client id: f_00004-1-5 loss: 0.883568  [  192/  306]
train() client id: f_00004-1-6 loss: 1.003494  [  224/  306]
train() client id: f_00004-1-7 loss: 0.857928  [  256/  306]
train() client id: f_00004-1-8 loss: 1.030619  [  288/  306]
train() client id: f_00004-2-0 loss: 0.966552  [   32/  306]
train() client id: f_00004-2-1 loss: 0.945301  [   64/  306]
train() client id: f_00004-2-2 loss: 0.821651  [   96/  306]
train() client id: f_00004-2-3 loss: 0.978117  [  128/  306]
train() client id: f_00004-2-4 loss: 0.872220  [  160/  306]
train() client id: f_00004-2-5 loss: 0.999139  [  192/  306]
train() client id: f_00004-2-6 loss: 0.970189  [  224/  306]
train() client id: f_00004-2-7 loss: 0.949400  [  256/  306]
train() client id: f_00004-2-8 loss: 0.925837  [  288/  306]
train() client id: f_00004-3-0 loss: 0.902764  [   32/  306]
train() client id: f_00004-3-1 loss: 0.917717  [   64/  306]
train() client id: f_00004-3-2 loss: 0.991144  [   96/  306]
train() client id: f_00004-3-3 loss: 0.938447  [  128/  306]
train() client id: f_00004-3-4 loss: 0.904500  [  160/  306]
train() client id: f_00004-3-5 loss: 0.933866  [  192/  306]
train() client id: f_00004-3-6 loss: 0.962639  [  224/  306]
train() client id: f_00004-3-7 loss: 0.906292  [  256/  306]
train() client id: f_00004-3-8 loss: 0.900984  [  288/  306]
train() client id: f_00004-4-0 loss: 0.953267  [   32/  306]
train() client id: f_00004-4-1 loss: 1.080952  [   64/  306]
train() client id: f_00004-4-2 loss: 0.934721  [   96/  306]
train() client id: f_00004-4-3 loss: 0.870287  [  128/  306]
train() client id: f_00004-4-4 loss: 0.907604  [  160/  306]
train() client id: f_00004-4-5 loss: 0.851380  [  192/  306]
train() client id: f_00004-4-6 loss: 0.938029  [  224/  306]
train() client id: f_00004-4-7 loss: 0.933254  [  256/  306]
train() client id: f_00004-4-8 loss: 0.883969  [  288/  306]
train() client id: f_00004-5-0 loss: 0.898320  [   32/  306]
train() client id: f_00004-5-1 loss: 1.019621  [   64/  306]
train() client id: f_00004-5-2 loss: 0.928192  [   96/  306]
train() client id: f_00004-5-3 loss: 0.887105  [  128/  306]
train() client id: f_00004-5-4 loss: 0.967828  [  160/  306]
train() client id: f_00004-5-5 loss: 0.773511  [  192/  306]
train() client id: f_00004-5-6 loss: 0.935861  [  224/  306]
train() client id: f_00004-5-7 loss: 0.890099  [  256/  306]
train() client id: f_00004-5-8 loss: 0.933757  [  288/  306]
train() client id: f_00004-6-0 loss: 1.034853  [   32/  306]
train() client id: f_00004-6-1 loss: 0.980652  [   64/  306]
train() client id: f_00004-6-2 loss: 0.867113  [   96/  306]
train() client id: f_00004-6-3 loss: 0.863228  [  128/  306]
train() client id: f_00004-6-4 loss: 0.913105  [  160/  306]
train() client id: f_00004-6-5 loss: 0.792194  [  192/  306]
train() client id: f_00004-6-6 loss: 0.942729  [  224/  306]
train() client id: f_00004-6-7 loss: 0.880107  [  256/  306]
train() client id: f_00004-6-8 loss: 0.797837  [  288/  306]
train() client id: f_00004-7-0 loss: 0.740711  [   32/  306]
train() client id: f_00004-7-1 loss: 1.030483  [   64/  306]
train() client id: f_00004-7-2 loss: 1.042875  [   96/  306]
train() client id: f_00004-7-3 loss: 0.917664  [  128/  306]
train() client id: f_00004-7-4 loss: 0.862459  [  160/  306]
train() client id: f_00004-7-5 loss: 0.815159  [  192/  306]
train() client id: f_00004-7-6 loss: 0.929755  [  224/  306]
train() client id: f_00004-7-7 loss: 0.866505  [  256/  306]
train() client id: f_00004-7-8 loss: 0.832735  [  288/  306]
train() client id: f_00004-8-0 loss: 0.953171  [   32/  306]
train() client id: f_00004-8-1 loss: 0.861851  [   64/  306]
train() client id: f_00004-8-2 loss: 0.988903  [   96/  306]
train() client id: f_00004-8-3 loss: 0.976934  [  128/  306]
train() client id: f_00004-8-4 loss: 0.918874  [  160/  306]
train() client id: f_00004-8-5 loss: 0.893027  [  192/  306]
train() client id: f_00004-8-6 loss: 0.877597  [  224/  306]
train() client id: f_00004-8-7 loss: 0.860413  [  256/  306]
train() client id: f_00004-8-8 loss: 0.819444  [  288/  306]
train() client id: f_00004-9-0 loss: 1.001938  [   32/  306]
train() client id: f_00004-9-1 loss: 0.773476  [   64/  306]
train() client id: f_00004-9-2 loss: 0.840153  [   96/  306]
train() client id: f_00004-9-3 loss: 0.838088  [  128/  306]
train() client id: f_00004-9-4 loss: 0.792605  [  160/  306]
train() client id: f_00004-9-5 loss: 1.018626  [  192/  306]
train() client id: f_00004-9-6 loss: 0.978546  [  224/  306]
train() client id: f_00004-9-7 loss: 0.882683  [  256/  306]
train() client id: f_00004-9-8 loss: 0.966135  [  288/  306]
train() client id: f_00004-10-0 loss: 0.868638  [   32/  306]
train() client id: f_00004-10-1 loss: 0.903643  [   64/  306]
train() client id: f_00004-10-2 loss: 1.002530  [   96/  306]
train() client id: f_00004-10-3 loss: 0.926966  [  128/  306]
train() client id: f_00004-10-4 loss: 0.886507  [  160/  306]
train() client id: f_00004-10-5 loss: 0.843467  [  192/  306]
train() client id: f_00004-10-6 loss: 0.910835  [  224/  306]
train() client id: f_00004-10-7 loss: 0.869330  [  256/  306]
train() client id: f_00004-10-8 loss: 0.840873  [  288/  306]
train() client id: f_00004-11-0 loss: 0.915538  [   32/  306]
train() client id: f_00004-11-1 loss: 0.915010  [   64/  306]
train() client id: f_00004-11-2 loss: 0.874468  [   96/  306]
train() client id: f_00004-11-3 loss: 0.848125  [  128/  306]
train() client id: f_00004-11-4 loss: 0.850549  [  160/  306]
train() client id: f_00004-11-5 loss: 0.869964  [  192/  306]
train() client id: f_00004-11-6 loss: 0.987019  [  224/  306]
train() client id: f_00004-11-7 loss: 0.830585  [  256/  306]
train() client id: f_00004-11-8 loss: 0.975911  [  288/  306]
train() client id: f_00004-12-0 loss: 0.945549  [   32/  306]
train() client id: f_00004-12-1 loss: 0.809153  [   64/  306]
train() client id: f_00004-12-2 loss: 0.827724  [   96/  306]
train() client id: f_00004-12-3 loss: 1.007823  [  128/  306]
train() client id: f_00004-12-4 loss: 0.895589  [  160/  306]
train() client id: f_00004-12-5 loss: 0.976618  [  192/  306]
train() client id: f_00004-12-6 loss: 0.885129  [  224/  306]
train() client id: f_00004-12-7 loss: 0.840000  [  256/  306]
train() client id: f_00004-12-8 loss: 0.915828  [  288/  306]
train() client id: f_00005-0-0 loss: 1.231270  [   32/  146]
train() client id: f_00005-0-1 loss: 1.240342  [   64/  146]
train() client id: f_00005-0-2 loss: 1.291582  [   96/  146]
train() client id: f_00005-0-3 loss: 1.195644  [  128/  146]
train() client id: f_00005-1-0 loss: 1.183185  [   32/  146]
train() client id: f_00005-1-1 loss: 1.151157  [   64/  146]
train() client id: f_00005-1-2 loss: 1.204232  [   96/  146]
train() client id: f_00005-1-3 loss: 1.112008  [  128/  146]
train() client id: f_00005-2-0 loss: 1.142800  [   32/  146]
train() client id: f_00005-2-1 loss: 1.114175  [   64/  146]
train() client id: f_00005-2-2 loss: 1.118440  [   96/  146]
train() client id: f_00005-2-3 loss: 1.019840  [  128/  146]
train() client id: f_00005-3-0 loss: 1.086063  [   32/  146]
train() client id: f_00005-3-1 loss: 1.087884  [   64/  146]
train() client id: f_00005-3-2 loss: 0.997818  [   96/  146]
train() client id: f_00005-3-3 loss: 1.065192  [  128/  146]
train() client id: f_00005-4-0 loss: 0.984526  [   32/  146]
train() client id: f_00005-4-1 loss: 1.015756  [   64/  146]
train() client id: f_00005-4-2 loss: 1.058301  [   96/  146]
train() client id: f_00005-4-3 loss: 1.054754  [  128/  146]
train() client id: f_00005-5-0 loss: 1.043065  [   32/  146]
train() client id: f_00005-5-1 loss: 1.065894  [   64/  146]
train() client id: f_00005-5-2 loss: 0.964627  [   96/  146]
train() client id: f_00005-5-3 loss: 0.923945  [  128/  146]
train() client id: f_00005-6-0 loss: 0.998948  [   32/  146]
train() client id: f_00005-6-1 loss: 0.960890  [   64/  146]
train() client id: f_00005-6-2 loss: 0.999969  [   96/  146]
train() client id: f_00005-6-3 loss: 0.990396  [  128/  146]
train() client id: f_00005-7-0 loss: 0.973519  [   32/  146]
train() client id: f_00005-7-1 loss: 0.963334  [   64/  146]
train() client id: f_00005-7-2 loss: 0.923203  [   96/  146]
train() client id: f_00005-7-3 loss: 1.045856  [  128/  146]
train() client id: f_00005-8-0 loss: 0.978873  [   32/  146]
train() client id: f_00005-8-1 loss: 0.875505  [   64/  146]
train() client id: f_00005-8-2 loss: 1.005941  [   96/  146]
train() client id: f_00005-8-3 loss: 0.866936  [  128/  146]
train() client id: f_00005-9-0 loss: 0.911642  [   32/  146]
train() client id: f_00005-9-1 loss: 0.933148  [   64/  146]
train() client id: f_00005-9-2 loss: 0.914422  [   96/  146]
train() client id: f_00005-9-3 loss: 0.995336  [  128/  146]
train() client id: f_00005-10-0 loss: 0.890848  [   32/  146]
train() client id: f_00005-10-1 loss: 0.918440  [   64/  146]
train() client id: f_00005-10-2 loss: 0.941704  [   96/  146]
train() client id: f_00005-10-3 loss: 0.931119  [  128/  146]
train() client id: f_00005-11-0 loss: 0.966795  [   32/  146]
train() client id: f_00005-11-1 loss: 0.941603  [   64/  146]
train() client id: f_00005-11-2 loss: 0.922052  [   96/  146]
train() client id: f_00005-11-3 loss: 0.837677  [  128/  146]
train() client id: f_00005-12-0 loss: 0.975123  [   32/  146]
train() client id: f_00005-12-1 loss: 0.813877  [   64/  146]
train() client id: f_00005-12-2 loss: 0.834332  [   96/  146]
train() client id: f_00005-12-3 loss: 1.011841  [  128/  146]
train() client id: f_00006-0-0 loss: 1.016875  [   32/   54]
train() client id: f_00006-1-0 loss: 0.982708  [   32/   54]
train() client id: f_00006-2-0 loss: 1.007774  [   32/   54]
train() client id: f_00006-3-0 loss: 0.997799  [   32/   54]
train() client id: f_00006-4-0 loss: 1.041835  [   32/   54]
train() client id: f_00006-5-0 loss: 1.015819  [   32/   54]
train() client id: f_00006-6-0 loss: 1.074397  [   32/   54]
train() client id: f_00006-7-0 loss: 1.020304  [   32/   54]
train() client id: f_00006-8-0 loss: 1.017025  [   32/   54]
train() client id: f_00006-9-0 loss: 1.018933  [   32/   54]
train() client id: f_00006-10-0 loss: 1.006760  [   32/   54]
train() client id: f_00006-11-0 loss: 1.033187  [   32/   54]
train() client id: f_00006-12-0 loss: 1.010806  [   32/   54]
train() client id: f_00007-0-0 loss: 1.053331  [   32/  179]
train() client id: f_00007-0-1 loss: 0.978437  [   64/  179]
train() client id: f_00007-0-2 loss: 1.098308  [   96/  179]
train() client id: f_00007-0-3 loss: 0.920563  [  128/  179]
train() client id: f_00007-0-4 loss: 1.018236  [  160/  179]
train() client id: f_00007-1-0 loss: 0.928514  [   32/  179]
train() client id: f_00007-1-1 loss: 0.977732  [   64/  179]
train() client id: f_00007-1-2 loss: 0.934478  [   96/  179]
train() client id: f_00007-1-3 loss: 0.913091  [  128/  179]
train() client id: f_00007-1-4 loss: 0.963254  [  160/  179]
train() client id: f_00007-2-0 loss: 0.899792  [   32/  179]
train() client id: f_00007-2-1 loss: 0.865810  [   64/  179]
train() client id: f_00007-2-2 loss: 0.939541  [   96/  179]
train() client id: f_00007-2-3 loss: 0.888784  [  128/  179]
train() client id: f_00007-2-4 loss: 0.820272  [  160/  179]
train() client id: f_00007-3-0 loss: 0.825375  [   32/  179]
train() client id: f_00007-3-1 loss: 0.872212  [   64/  179]
train() client id: f_00007-3-2 loss: 0.797474  [   96/  179]
train() client id: f_00007-3-3 loss: 0.865292  [  128/  179]
train() client id: f_00007-3-4 loss: 0.833085  [  160/  179]
train() client id: f_00007-4-0 loss: 0.814161  [   32/  179]
train() client id: f_00007-4-1 loss: 0.861524  [   64/  179]
train() client id: f_00007-4-2 loss: 0.800744  [   96/  179]
train() client id: f_00007-4-3 loss: 0.806138  [  128/  179]
train() client id: f_00007-4-4 loss: 0.771553  [  160/  179]
train() client id: f_00007-5-0 loss: 0.840187  [   32/  179]
train() client id: f_00007-5-1 loss: 0.744208  [   64/  179]
train() client id: f_00007-5-2 loss: 0.734164  [   96/  179]
train() client id: f_00007-5-3 loss: 0.753282  [  128/  179]
train() client id: f_00007-5-4 loss: 0.832034  [  160/  179]
train() client id: f_00007-6-0 loss: 0.836921  [   32/  179]
train() client id: f_00007-6-1 loss: 0.799421  [   64/  179]
train() client id: f_00007-6-2 loss: 0.776244  [   96/  179]
train() client id: f_00007-6-3 loss: 0.725401  [  128/  179]
train() client id: f_00007-6-4 loss: 0.691054  [  160/  179]
train() client id: f_00007-7-0 loss: 0.778019  [   32/  179]
train() client id: f_00007-7-1 loss: 0.802314  [   64/  179]
train() client id: f_00007-7-2 loss: 0.764485  [   96/  179]
train() client id: f_00007-7-3 loss: 0.714138  [  128/  179]
train() client id: f_00007-7-4 loss: 0.688740  [  160/  179]
train() client id: f_00007-8-0 loss: 0.673062  [   32/  179]
train() client id: f_00007-8-1 loss: 0.804120  [   64/  179]
train() client id: f_00007-8-2 loss: 0.725521  [   96/  179]
train() client id: f_00007-8-3 loss: 0.718258  [  128/  179]
train() client id: f_00007-8-4 loss: 0.808967  [  160/  179]
train() client id: f_00007-9-0 loss: 0.768894  [   32/  179]
train() client id: f_00007-9-1 loss: 0.760200  [   64/  179]
train() client id: f_00007-9-2 loss: 0.656513  [   96/  179]
train() client id: f_00007-9-3 loss: 0.699367  [  128/  179]
train() client id: f_00007-9-4 loss: 0.709747  [  160/  179]
train() client id: f_00007-10-0 loss: 0.806873  [   32/  179]
train() client id: f_00007-10-1 loss: 0.705715  [   64/  179]
train() client id: f_00007-10-2 loss: 0.673051  [   96/  179]
train() client id: f_00007-10-3 loss: 0.722368  [  128/  179]
train() client id: f_00007-10-4 loss: 0.731720  [  160/  179]
train() client id: f_00007-11-0 loss: 0.677749  [   32/  179]
train() client id: f_00007-11-1 loss: 0.669866  [   64/  179]
train() client id: f_00007-11-2 loss: 0.666064  [   96/  179]
train() client id: f_00007-11-3 loss: 0.775843  [  128/  179]
train() client id: f_00007-11-4 loss: 0.758179  [  160/  179]
train() client id: f_00007-12-0 loss: 0.839333  [   32/  179]
train() client id: f_00007-12-1 loss: 0.661450  [   64/  179]
train() client id: f_00007-12-2 loss: 0.697163  [   96/  179]
train() client id: f_00007-12-3 loss: 0.697610  [  128/  179]
train() client id: f_00007-12-4 loss: 0.645407  [  160/  179]
train() client id: f_00008-0-0 loss: 1.124122  [   32/  130]
train() client id: f_00008-0-1 loss: 0.989416  [   64/  130]
train() client id: f_00008-0-2 loss: 1.105818  [   96/  130]
train() client id: f_00008-0-3 loss: 1.038464  [  128/  130]
train() client id: f_00008-1-0 loss: 1.058013  [   32/  130]
train() client id: f_00008-1-1 loss: 1.027704  [   64/  130]
train() client id: f_00008-1-2 loss: 0.961430  [   96/  130]
train() client id: f_00008-1-3 loss: 1.143577  [  128/  130]
train() client id: f_00008-2-0 loss: 1.007855  [   32/  130]
train() client id: f_00008-2-1 loss: 1.050529  [   64/  130]
train() client id: f_00008-2-2 loss: 1.042115  [   96/  130]
train() client id: f_00008-2-3 loss: 1.001345  [  128/  130]
train() client id: f_00008-3-0 loss: 1.047288  [   32/  130]
train() client id: f_00008-3-1 loss: 0.949214  [   64/  130]
train() client id: f_00008-3-2 loss: 1.018606  [   96/  130]
train() client id: f_00008-3-3 loss: 1.040389  [  128/  130]
train() client id: f_00008-4-0 loss: 1.011974  [   32/  130]
train() client id: f_00008-4-1 loss: 1.016998  [   64/  130]
train() client id: f_00008-4-2 loss: 1.031019  [   96/  130]
train() client id: f_00008-4-3 loss: 0.949418  [  128/  130]
train() client id: f_00008-5-0 loss: 0.846750  [   32/  130]
train() client id: f_00008-5-1 loss: 1.088691  [   64/  130]
train() client id: f_00008-5-2 loss: 1.007717  [   96/  130]
train() client id: f_00008-5-3 loss: 1.020273  [  128/  130]
train() client id: f_00008-6-0 loss: 1.038441  [   32/  130]
train() client id: f_00008-6-1 loss: 0.977381  [   64/  130]
train() client id: f_00008-6-2 loss: 0.923606  [   96/  130]
train() client id: f_00008-6-3 loss: 1.009821  [  128/  130]
train() client id: f_00008-7-0 loss: 0.921065  [   32/  130]
train() client id: f_00008-7-1 loss: 0.992280  [   64/  130]
train() client id: f_00008-7-2 loss: 1.006233  [   96/  130]
train() client id: f_00008-7-3 loss: 0.936596  [  128/  130]
train() client id: f_00008-8-0 loss: 1.003417  [   32/  130]
train() client id: f_00008-8-1 loss: 0.927321  [   64/  130]
train() client id: f_00008-8-2 loss: 0.998500  [   96/  130]
train() client id: f_00008-8-3 loss: 0.937269  [  128/  130]
train() client id: f_00008-9-0 loss: 0.915912  [   32/  130]
train() client id: f_00008-9-1 loss: 0.964016  [   64/  130]
train() client id: f_00008-9-2 loss: 0.975542  [   96/  130]
train() client id: f_00008-9-3 loss: 0.959659  [  128/  130]
train() client id: f_00008-10-0 loss: 0.908293  [   32/  130]
train() client id: f_00008-10-1 loss: 0.971647  [   64/  130]
train() client id: f_00008-10-2 loss: 0.925525  [   96/  130]
train() client id: f_00008-10-3 loss: 1.013995  [  128/  130]
train() client id: f_00008-11-0 loss: 0.875226  [   32/  130]
train() client id: f_00008-11-1 loss: 0.989868  [   64/  130]
train() client id: f_00008-11-2 loss: 0.975078  [   96/  130]
train() client id: f_00008-11-3 loss: 0.988678  [  128/  130]
train() client id: f_00008-12-0 loss: 0.872111  [   32/  130]
train() client id: f_00008-12-1 loss: 0.960763  [   64/  130]
train() client id: f_00008-12-2 loss: 1.094582  [   96/  130]
train() client id: f_00008-12-3 loss: 0.906568  [  128/  130]
train() client id: f_00009-0-0 loss: 1.132613  [   32/  118]
train() client id: f_00009-0-1 loss: 1.133273  [   64/  118]
train() client id: f_00009-0-2 loss: 0.966682  [   96/  118]
train() client id: f_00009-1-0 loss: 1.080088  [   32/  118]
train() client id: f_00009-1-1 loss: 0.985521  [   64/  118]
train() client id: f_00009-1-2 loss: 1.033209  [   96/  118]
train() client id: f_00009-2-0 loss: 1.018059  [   32/  118]
train() client id: f_00009-2-1 loss: 0.987094  [   64/  118]
train() client id: f_00009-2-2 loss: 1.022364  [   96/  118]
train() client id: f_00009-3-0 loss: 0.924476  [   32/  118]
train() client id: f_00009-3-1 loss: 0.970016  [   64/  118]
train() client id: f_00009-3-2 loss: 0.909718  [   96/  118]
train() client id: f_00009-4-0 loss: 1.027575  [   32/  118]
train() client id: f_00009-4-1 loss: 0.982367  [   64/  118]
train() client id: f_00009-4-2 loss: 0.840798  [   96/  118]
train() client id: f_00009-5-0 loss: 0.948161  [   32/  118]
train() client id: f_00009-5-1 loss: 0.898176  [   64/  118]
train() client id: f_00009-5-2 loss: 0.903740  [   96/  118]
train() client id: f_00009-6-0 loss: 0.875289  [   32/  118]
train() client id: f_00009-6-1 loss: 0.962200  [   64/  118]
train() client id: f_00009-6-2 loss: 0.915306  [   96/  118]
train() client id: f_00009-7-0 loss: 0.940131  [   32/  118]
train() client id: f_00009-7-1 loss: 0.801594  [   64/  118]
train() client id: f_00009-7-2 loss: 0.934928  [   96/  118]
train() client id: f_00009-8-0 loss: 0.862742  [   32/  118]
train() client id: f_00009-8-1 loss: 0.894329  [   64/  118]
train() client id: f_00009-8-2 loss: 0.802102  [   96/  118]
train() client id: f_00009-9-0 loss: 0.830552  [   32/  118]
train() client id: f_00009-9-1 loss: 0.896194  [   64/  118]
train() client id: f_00009-9-2 loss: 0.894342  [   96/  118]
train() client id: f_00009-10-0 loss: 0.922197  [   32/  118]
train() client id: f_00009-10-1 loss: 0.828183  [   64/  118]
train() client id: f_00009-10-2 loss: 0.865489  [   96/  118]
train() client id: f_00009-11-0 loss: 0.741138  [   32/  118]
train() client id: f_00009-11-1 loss: 0.935956  [   64/  118]
train() client id: f_00009-11-2 loss: 0.865350  [   96/  118]
train() client id: f_00009-12-0 loss: 0.817322  [   32/  118]
train() client id: f_00009-12-1 loss: 0.802547  [   64/  118]
train() client id: f_00009-12-2 loss: 0.874472  [   96/  118]
At round 1 accuracy: 0.47214854111405835
At round 1 training accuracy: 0.3950368879946345
At round 1 training loss: 1.0543667884323251
gradient difference: 0.41595458984375
train() client id: f_00000-0-0 loss: 1.022392  [   32/  126]
train() client id: f_00000-0-1 loss: 1.073974  [   64/  126]
train() client id: f_00000-0-2 loss: 0.974451  [   96/  126]
train() client id: f_00000-1-0 loss: 0.976332  [   32/  126]
train() client id: f_00000-1-1 loss: 0.930546  [   64/  126]
train() client id: f_00000-1-2 loss: 0.952372  [   96/  126]
train() client id: f_00000-2-0 loss: 0.903011  [   32/  126]
train() client id: f_00000-2-1 loss: 0.972872  [   64/  126]
train() client id: f_00000-2-2 loss: 0.908986  [   96/  126]
train() client id: f_00000-3-0 loss: 0.920764  [   32/  126]
train() client id: f_00000-3-1 loss: 0.904064  [   64/  126]
train() client id: f_00000-3-2 loss: 0.846990  [   96/  126]
train() client id: f_00000-4-0 loss: 0.855964  [   32/  126]
train() client id: f_00000-4-1 loss: 0.921820  [   64/  126]
train() client id: f_00000-4-2 loss: 0.858161  [   96/  126]
train() client id: f_00000-5-0 loss: 0.926025  [   32/  126]
train() client id: f_00000-5-1 loss: 0.877533  [   64/  126]
train() client id: f_00000-5-2 loss: 0.753505  [   96/  126]
train() client id: f_00000-6-0 loss: 0.942308  [   32/  126]
train() client id: f_00000-6-1 loss: 0.755734  [   64/  126]
train() client id: f_00000-6-2 loss: 0.886429  [   96/  126]
train() client id: f_00000-7-0 loss: 0.846942  [   32/  126]
train() client id: f_00000-7-1 loss: 0.793574  [   64/  126]
train() client id: f_00000-7-2 loss: 0.802089  [   96/  126]
train() client id: f_00000-8-0 loss: 0.895265  [   32/  126]
train() client id: f_00000-8-1 loss: 0.760620  [   64/  126]
train() client id: f_00000-8-2 loss: 0.844210  [   96/  126]
train() client id: f_00000-9-0 loss: 0.820492  [   32/  126]
train() client id: f_00000-9-1 loss: 0.741911  [   64/  126]
train() client id: f_00000-9-2 loss: 0.891381  [   96/  126]
train() client id: f_00000-10-0 loss: 0.873801  [   32/  126]
train() client id: f_00000-10-1 loss: 0.812414  [   64/  126]
train() client id: f_00000-10-2 loss: 0.783346  [   96/  126]
train() client id: f_00000-11-0 loss: 0.868053  [   32/  126]
train() client id: f_00000-11-1 loss: 0.767286  [   64/  126]
train() client id: f_00000-11-2 loss: 0.850674  [   96/  126]
train() client id: f_00000-12-0 loss: 0.801616  [   32/  126]
train() client id: f_00000-12-1 loss: 0.715331  [   64/  126]
train() client id: f_00000-12-2 loss: 0.910320  [   96/  126]
train() client id: f_00001-0-0 loss: 1.009494  [   32/  265]
train() client id: f_00001-0-1 loss: 0.961528  [   64/  265]
train() client id: f_00001-0-2 loss: 1.000310  [   96/  265]
train() client id: f_00001-0-3 loss: 0.984742  [  128/  265]
train() client id: f_00001-0-4 loss: 0.939446  [  160/  265]
train() client id: f_00001-0-5 loss: 0.922828  [  192/  265]
train() client id: f_00001-0-6 loss: 0.970917  [  224/  265]
train() client id: f_00001-0-7 loss: 0.915810  [  256/  265]
train() client id: f_00001-1-0 loss: 0.955510  [   32/  265]
train() client id: f_00001-1-1 loss: 0.873543  [   64/  265]
train() client id: f_00001-1-2 loss: 0.903731  [   96/  265]
train() client id: f_00001-1-3 loss: 0.865174  [  128/  265]
train() client id: f_00001-1-4 loss: 0.780693  [  160/  265]
train() client id: f_00001-1-5 loss: 0.857759  [  192/  265]
train() client id: f_00001-1-6 loss: 0.830654  [  224/  265]
train() client id: f_00001-1-7 loss: 0.852761  [  256/  265]
train() client id: f_00001-2-0 loss: 0.820117  [   32/  265]
train() client id: f_00001-2-1 loss: 0.772080  [   64/  265]
train() client id: f_00001-2-2 loss: 0.838624  [   96/  265]
train() client id: f_00001-2-3 loss: 0.835002  [  128/  265]
train() client id: f_00001-2-4 loss: 0.761200  [  160/  265]
train() client id: f_00001-2-5 loss: 0.774637  [  192/  265]
train() client id: f_00001-2-6 loss: 0.789325  [  224/  265]
train() client id: f_00001-2-7 loss: 0.755173  [  256/  265]
train() client id: f_00001-3-0 loss: 0.813420  [   32/  265]
train() client id: f_00001-3-1 loss: 0.783140  [   64/  265]
train() client id: f_00001-3-2 loss: 0.717220  [   96/  265]
train() client id: f_00001-3-3 loss: 0.765226  [  128/  265]
train() client id: f_00001-3-4 loss: 0.742260  [  160/  265]
train() client id: f_00001-3-5 loss: 0.684247  [  192/  265]
train() client id: f_00001-3-6 loss: 0.726935  [  224/  265]
train() client id: f_00001-3-7 loss: 0.719365  [  256/  265]
train() client id: f_00001-4-0 loss: 0.764653  [   32/  265]
train() client id: f_00001-4-1 loss: 0.681009  [   64/  265]
train() client id: f_00001-4-2 loss: 0.752225  [   96/  265]
train() client id: f_00001-4-3 loss: 0.683569  [  128/  265]
train() client id: f_00001-4-4 loss: 0.755877  [  160/  265]
train() client id: f_00001-4-5 loss: 0.704127  [  192/  265]
train() client id: f_00001-4-6 loss: 0.725796  [  224/  265]
train() client id: f_00001-4-7 loss: 0.656303  [  256/  265]
train() client id: f_00001-5-0 loss: 0.657277  [   32/  265]
train() client id: f_00001-5-1 loss: 0.755470  [   64/  265]
train() client id: f_00001-5-2 loss: 0.741872  [   96/  265]
train() client id: f_00001-5-3 loss: 0.691905  [  128/  265]
train() client id: f_00001-5-4 loss: 0.655002  [  160/  265]
train() client id: f_00001-5-5 loss: 0.691699  [  192/  265]
train() client id: f_00001-5-6 loss: 0.644170  [  224/  265]
train() client id: f_00001-5-7 loss: 0.694202  [  256/  265]
train() client id: f_00001-6-0 loss: 0.657102  [   32/  265]
train() client id: f_00001-6-1 loss: 0.653148  [   64/  265]
train() client id: f_00001-6-2 loss: 0.660290  [   96/  265]
train() client id: f_00001-6-3 loss: 0.694551  [  128/  265]
train() client id: f_00001-6-4 loss: 0.716086  [  160/  265]
train() client id: f_00001-6-5 loss: 0.664344  [  192/  265]
train() client id: f_00001-6-6 loss: 0.653573  [  224/  265]
train() client id: f_00001-6-7 loss: 0.694738  [  256/  265]
train() client id: f_00001-7-0 loss: 0.769309  [   32/  265]
train() client id: f_00001-7-1 loss: 0.627087  [   64/  265]
train() client id: f_00001-7-2 loss: 0.698460  [   96/  265]
train() client id: f_00001-7-3 loss: 0.664528  [  128/  265]
train() client id: f_00001-7-4 loss: 0.618411  [  160/  265]
train() client id: f_00001-7-5 loss: 0.639609  [  192/  265]
train() client id: f_00001-7-6 loss: 0.617096  [  224/  265]
train() client id: f_00001-7-7 loss: 0.737296  [  256/  265]
train() client id: f_00001-8-0 loss: 0.624987  [   32/  265]
train() client id: f_00001-8-1 loss: 0.622329  [   64/  265]
train() client id: f_00001-8-2 loss: 0.666799  [   96/  265]
train() client id: f_00001-8-3 loss: 0.668290  [  128/  265]
train() client id: f_00001-8-4 loss: 0.680398  [  160/  265]
train() client id: f_00001-8-5 loss: 0.696167  [  192/  265]
train() client id: f_00001-8-6 loss: 0.732634  [  224/  265]
train() client id: f_00001-8-7 loss: 0.643104  [  256/  265]
train() client id: f_00001-9-0 loss: 0.684287  [   32/  265]
train() client id: f_00001-9-1 loss: 0.719221  [   64/  265]
train() client id: f_00001-9-2 loss: 0.622351  [   96/  265]
train() client id: f_00001-9-3 loss: 0.668088  [  128/  265]
train() client id: f_00001-9-4 loss: 0.603463  [  160/  265]
train() client id: f_00001-9-5 loss: 0.746860  [  192/  265]
train() client id: f_00001-9-6 loss: 0.642853  [  224/  265]
train() client id: f_00001-9-7 loss: 0.644256  [  256/  265]
train() client id: f_00001-10-0 loss: 0.663364  [   32/  265]
train() client id: f_00001-10-1 loss: 0.654667  [   64/  265]
train() client id: f_00001-10-2 loss: 0.664134  [   96/  265]
train() client id: f_00001-10-3 loss: 0.641784  [  128/  265]
train() client id: f_00001-10-4 loss: 0.666517  [  160/  265]
train() client id: f_00001-10-5 loss: 0.637805  [  192/  265]
train() client id: f_00001-10-6 loss: 0.766577  [  224/  265]
train() client id: f_00001-10-7 loss: 0.615846  [  256/  265]
train() client id: f_00001-11-0 loss: 0.652946  [   32/  265]
train() client id: f_00001-11-1 loss: 0.604904  [   64/  265]
train() client id: f_00001-11-2 loss: 0.661602  [   96/  265]
train() client id: f_00001-11-3 loss: 0.713993  [  128/  265]
train() client id: f_00001-11-4 loss: 0.592552  [  160/  265]
train() client id: f_00001-11-5 loss: 0.717132  [  192/  265]
train() client id: f_00001-11-6 loss: 0.668151  [  224/  265]
train() client id: f_00001-11-7 loss: 0.706902  [  256/  265]
train() client id: f_00001-12-0 loss: 0.654244  [   32/  265]
train() client id: f_00001-12-1 loss: 0.681619  [   64/  265]
train() client id: f_00001-12-2 loss: 0.662218  [   96/  265]
train() client id: f_00001-12-3 loss: 0.739867  [  128/  265]
train() client id: f_00001-12-4 loss: 0.604552  [  160/  265]
train() client id: f_00001-12-5 loss: 0.661861  [  192/  265]
train() client id: f_00001-12-6 loss: 0.723439  [  224/  265]
train() client id: f_00001-12-7 loss: 0.630674  [  256/  265]
train() client id: f_00002-0-0 loss: 1.199404  [   32/  124]
train() client id: f_00002-0-1 loss: 1.173359  [   64/  124]
train() client id: f_00002-0-2 loss: 1.232682  [   96/  124]
train() client id: f_00002-1-0 loss: 1.130007  [   32/  124]
train() client id: f_00002-1-1 loss: 1.253955  [   64/  124]
train() client id: f_00002-1-2 loss: 1.155631  [   96/  124]
train() client id: f_00002-2-0 loss: 1.150898  [   32/  124]
train() client id: f_00002-2-1 loss: 1.198181  [   64/  124]
train() client id: f_00002-2-2 loss: 1.110609  [   96/  124]
train() client id: f_00002-3-0 loss: 1.074443  [   32/  124]
train() client id: f_00002-3-1 loss: 1.120729  [   64/  124]
train() client id: f_00002-3-2 loss: 1.174648  [   96/  124]
train() client id: f_00002-4-0 loss: 1.112269  [   32/  124]
train() client id: f_00002-4-1 loss: 1.033728  [   64/  124]
train() client id: f_00002-4-2 loss: 1.106505  [   96/  124]
train() client id: f_00002-5-0 loss: 1.035743  [   32/  124]
train() client id: f_00002-5-1 loss: 1.100252  [   64/  124]
train() client id: f_00002-5-2 loss: 1.013551  [   96/  124]
train() client id: f_00002-6-0 loss: 1.071497  [   32/  124]
train() client id: f_00002-6-1 loss: 1.028301  [   64/  124]
train() client id: f_00002-6-2 loss: 1.048534  [   96/  124]
train() client id: f_00002-7-0 loss: 1.018669  [   32/  124]
train() client id: f_00002-7-1 loss: 1.034686  [   64/  124]
train() client id: f_00002-7-2 loss: 1.058186  [   96/  124]
train() client id: f_00002-8-0 loss: 1.000251  [   32/  124]
train() client id: f_00002-8-1 loss: 1.091158  [   64/  124]
train() client id: f_00002-8-2 loss: 1.000323  [   96/  124]
train() client id: f_00002-9-0 loss: 1.011217  [   32/  124]
train() client id: f_00002-9-1 loss: 1.000480  [   64/  124]
train() client id: f_00002-9-2 loss: 1.027991  [   96/  124]
train() client id: f_00002-10-0 loss: 1.032032  [   32/  124]
train() client id: f_00002-10-1 loss: 1.010787  [   64/  124]
train() client id: f_00002-10-2 loss: 0.935141  [   96/  124]
train() client id: f_00002-11-0 loss: 0.993715  [   32/  124]
train() client id: f_00002-11-1 loss: 1.006386  [   64/  124]
train() client id: f_00002-11-2 loss: 0.962631  [   96/  124]
train() client id: f_00002-12-0 loss: 0.950623  [   32/  124]
train() client id: f_00002-12-1 loss: 1.043879  [   64/  124]
train() client id: f_00002-12-2 loss: 1.024053  [   96/  124]
train() client id: f_00003-0-0 loss: 1.058866  [   32/   43]
train() client id: f_00003-1-0 loss: 1.087056  [   32/   43]
train() client id: f_00003-2-0 loss: 1.087454  [   32/   43]
train() client id: f_00003-3-0 loss: 1.093747  [   32/   43]
train() client id: f_00003-4-0 loss: 1.133339  [   32/   43]
train() client id: f_00003-5-0 loss: 1.123804  [   32/   43]
train() client id: f_00003-6-0 loss: 1.137444  [   32/   43]
train() client id: f_00003-7-0 loss: 1.119145  [   32/   43]
train() client id: f_00003-8-0 loss: 1.116336  [   32/   43]
train() client id: f_00003-9-0 loss: 1.138714  [   32/   43]
train() client id: f_00003-10-0 loss: 1.060984  [   32/   43]
train() client id: f_00003-11-0 loss: 1.094249  [   32/   43]
train() client id: f_00003-12-0 loss: 1.077428  [   32/   43]
train() client id: f_00004-0-0 loss: 0.903697  [   32/  306]
train() client id: f_00004-0-1 loss: 0.828844  [   64/  306]
train() client id: f_00004-0-2 loss: 0.838870  [   96/  306]
train() client id: f_00004-0-3 loss: 0.979295  [  128/  306]
train() client id: f_00004-0-4 loss: 0.857810  [  160/  306]
train() client id: f_00004-0-5 loss: 0.981298  [  192/  306]
train() client id: f_00004-0-6 loss: 1.109581  [  224/  306]
train() client id: f_00004-0-7 loss: 1.042684  [  256/  306]
train() client id: f_00004-0-8 loss: 0.930553  [  288/  306]
train() client id: f_00004-1-0 loss: 0.930490  [   32/  306]
train() client id: f_00004-1-1 loss: 0.852826  [   64/  306]
train() client id: f_00004-1-2 loss: 0.858631  [   96/  306]
train() client id: f_00004-1-3 loss: 0.963325  [  128/  306]
train() client id: f_00004-1-4 loss: 0.990419  [  160/  306]
train() client id: f_00004-1-5 loss: 0.922767  [  192/  306]
train() client id: f_00004-1-6 loss: 0.896645  [  224/  306]
train() client id: f_00004-1-7 loss: 0.934581  [  256/  306]
train() client id: f_00004-1-8 loss: 0.954284  [  288/  306]
train() client id: f_00004-2-0 loss: 0.785623  [   32/  306]
train() client id: f_00004-2-1 loss: 0.915393  [   64/  306]
train() client id: f_00004-2-2 loss: 0.972572  [   96/  306]
train() client id: f_00004-2-3 loss: 0.806083  [  128/  306]
train() client id: f_00004-2-4 loss: 0.979902  [  160/  306]
train() client id: f_00004-2-5 loss: 0.997551  [  192/  306]
train() client id: f_00004-2-6 loss: 0.794363  [  224/  306]
train() client id: f_00004-2-7 loss: 0.961315  [  256/  306]
train() client id: f_00004-2-8 loss: 1.037861  [  288/  306]
train() client id: f_00004-3-0 loss: 0.815542  [   32/  306]
train() client id: f_00004-3-1 loss: 1.005627  [   64/  306]
train() client id: f_00004-3-2 loss: 0.818317  [   96/  306]
train() client id: f_00004-3-3 loss: 0.854751  [  128/  306]
train() client id: f_00004-3-4 loss: 0.978727  [  160/  306]
train() client id: f_00004-3-5 loss: 1.002288  [  192/  306]
train() client id: f_00004-3-6 loss: 0.943636  [  224/  306]
train() client id: f_00004-3-7 loss: 0.961565  [  256/  306]
train() client id: f_00004-3-8 loss: 0.898013  [  288/  306]
train() client id: f_00004-4-0 loss: 0.883329  [   32/  306]
train() client id: f_00004-4-1 loss: 0.946345  [   64/  306]
train() client id: f_00004-4-2 loss: 0.873667  [   96/  306]
train() client id: f_00004-4-3 loss: 0.829204  [  128/  306]
train() client id: f_00004-4-4 loss: 0.949626  [  160/  306]
train() client id: f_00004-4-5 loss: 0.941016  [  192/  306]
train() client id: f_00004-4-6 loss: 0.983142  [  224/  306]
train() client id: f_00004-4-7 loss: 0.914326  [  256/  306]
train() client id: f_00004-4-8 loss: 1.015238  [  288/  306]
train() client id: f_00004-5-0 loss: 1.022628  [   32/  306]
train() client id: f_00004-5-1 loss: 0.855197  [   64/  306]
train() client id: f_00004-5-2 loss: 0.925603  [   96/  306]
train() client id: f_00004-5-3 loss: 0.959147  [  128/  306]
train() client id: f_00004-5-4 loss: 0.930090  [  160/  306]
train() client id: f_00004-5-5 loss: 0.962438  [  192/  306]
train() client id: f_00004-5-6 loss: 0.796180  [  224/  306]
train() client id: f_00004-5-7 loss: 0.877943  [  256/  306]
train() client id: f_00004-5-8 loss: 0.956441  [  288/  306]
train() client id: f_00004-6-0 loss: 0.872437  [   32/  306]
train() client id: f_00004-6-1 loss: 0.883299  [   64/  306]
train() client id: f_00004-6-2 loss: 0.916469  [   96/  306]
train() client id: f_00004-6-3 loss: 0.868327  [  128/  306]
train() client id: f_00004-6-4 loss: 0.997525  [  160/  306]
train() client id: f_00004-6-5 loss: 0.973919  [  192/  306]
train() client id: f_00004-6-6 loss: 0.919798  [  224/  306]
train() client id: f_00004-6-7 loss: 1.050060  [  256/  306]
train() client id: f_00004-6-8 loss: 0.838391  [  288/  306]
train() client id: f_00004-7-0 loss: 0.889340  [   32/  306]
train() client id: f_00004-7-1 loss: 0.914876  [   64/  306]
train() client id: f_00004-7-2 loss: 0.917464  [   96/  306]
train() client id: f_00004-7-3 loss: 0.930382  [  128/  306]
train() client id: f_00004-7-4 loss: 1.018364  [  160/  306]
train() client id: f_00004-7-5 loss: 0.906656  [  192/  306]
train() client id: f_00004-7-6 loss: 0.920915  [  224/  306]
train() client id: f_00004-7-7 loss: 0.909772  [  256/  306]
train() client id: f_00004-7-8 loss: 0.893736  [  288/  306]
train() client id: f_00004-8-0 loss: 0.907330  [   32/  306]
train() client id: f_00004-8-1 loss: 0.845469  [   64/  306]
train() client id: f_00004-8-2 loss: 0.806060  [   96/  306]
train() client id: f_00004-8-3 loss: 0.976750  [  128/  306]
train() client id: f_00004-8-4 loss: 0.777945  [  160/  306]
train() client id: f_00004-8-5 loss: 0.994035  [  192/  306]
train() client id: f_00004-8-6 loss: 0.977089  [  224/  306]
train() client id: f_00004-8-7 loss: 0.963910  [  256/  306]
train() client id: f_00004-8-8 loss: 0.972351  [  288/  306]
train() client id: f_00004-9-0 loss: 0.951429  [   32/  306]
train() client id: f_00004-9-1 loss: 0.999880  [   64/  306]
train() client id: f_00004-9-2 loss: 1.000567  [   96/  306]
train() client id: f_00004-9-3 loss: 0.876635  [  128/  306]
train() client id: f_00004-9-4 loss: 0.873371  [  160/  306]
train() client id: f_00004-9-5 loss: 1.001906  [  192/  306]
train() client id: f_00004-9-6 loss: 0.838837  [  224/  306]
train() client id: f_00004-9-7 loss: 0.893151  [  256/  306]
train() client id: f_00004-9-8 loss: 0.875920  [  288/  306]
train() client id: f_00004-10-0 loss: 0.850629  [   32/  306]
train() client id: f_00004-10-1 loss: 0.864418  [   64/  306]
train() client id: f_00004-10-2 loss: 0.881366  [   96/  306]
train() client id: f_00004-10-3 loss: 0.857450  [  128/  306]
train() client id: f_00004-10-4 loss: 0.978410  [  160/  306]
train() client id: f_00004-10-5 loss: 0.967358  [  192/  306]
train() client id: f_00004-10-6 loss: 0.949306  [  224/  306]
train() client id: f_00004-10-7 loss: 0.952903  [  256/  306]
train() client id: f_00004-10-8 loss: 0.937013  [  288/  306]
train() client id: f_00004-11-0 loss: 1.078080  [   32/  306]
train() client id: f_00004-11-1 loss: 0.970536  [   64/  306]
train() client id: f_00004-11-2 loss: 0.883645  [   96/  306]
train() client id: f_00004-11-3 loss: 0.922159  [  128/  306]
train() client id: f_00004-11-4 loss: 0.842480  [  160/  306]
train() client id: f_00004-11-5 loss: 0.892501  [  192/  306]
train() client id: f_00004-11-6 loss: 0.895102  [  224/  306]
train() client id: f_00004-11-7 loss: 0.946617  [  256/  306]
train() client id: f_00004-11-8 loss: 0.869989  [  288/  306]
train() client id: f_00004-12-0 loss: 0.942848  [   32/  306]
train() client id: f_00004-12-1 loss: 1.033262  [   64/  306]
train() client id: f_00004-12-2 loss: 0.786265  [   96/  306]
train() client id: f_00004-12-3 loss: 0.879822  [  128/  306]
train() client id: f_00004-12-4 loss: 0.833393  [  160/  306]
train() client id: f_00004-12-5 loss: 0.896284  [  192/  306]
train() client id: f_00004-12-6 loss: 1.030748  [  224/  306]
train() client id: f_00004-12-7 loss: 0.886257  [  256/  306]
train() client id: f_00004-12-8 loss: 0.977168  [  288/  306]
train() client id: f_00005-0-0 loss: 1.100559  [   32/  146]
train() client id: f_00005-0-1 loss: 1.229774  [   64/  146]
train() client id: f_00005-0-2 loss: 1.075543  [   96/  146]
train() client id: f_00005-0-3 loss: 1.101720  [  128/  146]
train() client id: f_00005-1-0 loss: 1.062718  [   32/  146]
train() client id: f_00005-1-1 loss: 1.140433  [   64/  146]
train() client id: f_00005-1-2 loss: 1.068314  [   96/  146]
train() client id: f_00005-1-3 loss: 1.036289  [  128/  146]
train() client id: f_00005-2-0 loss: 1.058374  [   32/  146]
train() client id: f_00005-2-1 loss: 1.070110  [   64/  146]
train() client id: f_00005-2-2 loss: 0.981033  [   96/  146]
train() client id: f_00005-2-3 loss: 1.025352  [  128/  146]
train() client id: f_00005-3-0 loss: 1.031303  [   32/  146]
train() client id: f_00005-3-1 loss: 1.008136  [   64/  146]
train() client id: f_00005-3-2 loss: 0.959696  [   96/  146]
train() client id: f_00005-3-3 loss: 0.899824  [  128/  146]
train() client id: f_00005-4-0 loss: 0.955739  [   32/  146]
train() client id: f_00005-4-1 loss: 1.048230  [   64/  146]
train() client id: f_00005-4-2 loss: 0.924964  [   96/  146]
train() client id: f_00005-4-3 loss: 0.871373  [  128/  146]
train() client id: f_00005-5-0 loss: 0.941488  [   32/  146]
train() client id: f_00005-5-1 loss: 0.939837  [   64/  146]
train() client id: f_00005-5-2 loss: 0.918249  [   96/  146]
train() client id: f_00005-5-3 loss: 0.865929  [  128/  146]
train() client id: f_00005-6-0 loss: 0.826509  [   32/  146]
train() client id: f_00005-6-1 loss: 0.833543  [   64/  146]
train() client id: f_00005-6-2 loss: 0.918307  [   96/  146]
train() client id: f_00005-6-3 loss: 0.997228  [  128/  146]
train() client id: f_00005-7-0 loss: 0.861188  [   32/  146]
train() client id: f_00005-7-1 loss: 0.867724  [   64/  146]
train() client id: f_00005-7-2 loss: 0.868496  [   96/  146]
train() client id: f_00005-7-3 loss: 0.884762  [  128/  146]
train() client id: f_00005-8-0 loss: 0.811918  [   32/  146]
train() client id: f_00005-8-1 loss: 0.802292  [   64/  146]
train() client id: f_00005-8-2 loss: 0.835677  [   96/  146]
train() client id: f_00005-8-3 loss: 0.923883  [  128/  146]
train() client id: f_00005-9-0 loss: 0.830838  [   32/  146]
train() client id: f_00005-9-1 loss: 0.869168  [   64/  146]
train() client id: f_00005-9-2 loss: 0.800768  [   96/  146]
train() client id: f_00005-9-3 loss: 0.920719  [  128/  146]
train() client id: f_00005-10-0 loss: 0.900632  [   32/  146]
train() client id: f_00005-10-1 loss: 0.801467  [   64/  146]
train() client id: f_00005-10-2 loss: 0.880322  [   96/  146]
train() client id: f_00005-10-3 loss: 0.770387  [  128/  146]
train() client id: f_00005-11-0 loss: 0.798432  [   32/  146]
train() client id: f_00005-11-1 loss: 0.780436  [   64/  146]
train() client id: f_00005-11-2 loss: 0.911245  [   96/  146]
train() client id: f_00005-11-3 loss: 0.895285  [  128/  146]
train() client id: f_00005-12-0 loss: 0.840421  [   32/  146]
train() client id: f_00005-12-1 loss: 0.833760  [   64/  146]
train() client id: f_00005-12-2 loss: 0.783955  [   96/  146]
train() client id: f_00005-12-3 loss: 0.750767  [  128/  146]
train() client id: f_00006-0-0 loss: 1.087160  [   32/   54]
train() client id: f_00006-1-0 loss: 1.115937  [   32/   54]
train() client id: f_00006-2-0 loss: 1.085567  [   32/   54]
train() client id: f_00006-3-0 loss: 1.074511  [   32/   54]
train() client id: f_00006-4-0 loss: 1.063714  [   32/   54]
train() client id: f_00006-5-0 loss: 1.079009  [   32/   54]
train() client id: f_00006-6-0 loss: 1.054581  [   32/   54]
train() client id: f_00006-7-0 loss: 1.068509  [   32/   54]
train() client id: f_00006-8-0 loss: 1.050377  [   32/   54]
train() client id: f_00006-9-0 loss: 1.062220  [   32/   54]
train() client id: f_00006-10-0 loss: 1.068748  [   32/   54]
train() client id: f_00006-11-0 loss: 1.076971  [   32/   54]
train() client id: f_00006-12-0 loss: 1.095421  [   32/   54]
train() client id: f_00007-0-0 loss: 0.947787  [   32/  179]
train() client id: f_00007-0-1 loss: 0.930991  [   64/  179]
train() client id: f_00007-0-2 loss: 0.952119  [   96/  179]
train() client id: f_00007-0-3 loss: 0.888625  [  128/  179]
train() client id: f_00007-0-4 loss: 0.998520  [  160/  179]
train() client id: f_00007-1-0 loss: 0.980903  [   32/  179]
train() client id: f_00007-1-1 loss: 0.849273  [   64/  179]
train() client id: f_00007-1-2 loss: 0.907782  [   96/  179]
train() client id: f_00007-1-3 loss: 0.925140  [  128/  179]
train() client id: f_00007-1-4 loss: 0.811127  [  160/  179]
train() client id: f_00007-2-0 loss: 0.924293  [   32/  179]
train() client id: f_00007-2-1 loss: 0.823151  [   64/  179]
train() client id: f_00007-2-2 loss: 0.831115  [   96/  179]
train() client id: f_00007-2-3 loss: 0.817799  [  128/  179]
train() client id: f_00007-2-4 loss: 0.807218  [  160/  179]
train() client id: f_00007-3-0 loss: 0.911365  [   32/  179]
train() client id: f_00007-3-1 loss: 0.815828  [   64/  179]
train() client id: f_00007-3-2 loss: 0.778311  [   96/  179]
train() client id: f_00007-3-3 loss: 0.841293  [  128/  179]
train() client id: f_00007-3-4 loss: 0.730505  [  160/  179]
train() client id: f_00007-4-0 loss: 0.778457  [   32/  179]
train() client id: f_00007-4-1 loss: 0.791774  [   64/  179]
train() client id: f_00007-4-2 loss: 0.761580  [   96/  179]
train() client id: f_00007-4-3 loss: 0.816393  [  128/  179]
train() client id: f_00007-4-4 loss: 0.858386  [  160/  179]
train() client id: f_00007-5-0 loss: 0.881604  [   32/  179]
train() client id: f_00007-5-1 loss: 0.709368  [   64/  179]
train() client id: f_00007-5-2 loss: 0.721556  [   96/  179]
train() client id: f_00007-5-3 loss: 0.718602  [  128/  179]
train() client id: f_00007-5-4 loss: 0.789378  [  160/  179]
train() client id: f_00007-6-0 loss: 0.831114  [   32/  179]
train() client id: f_00007-6-1 loss: 0.714227  [   64/  179]
train() client id: f_00007-6-2 loss: 0.708962  [   96/  179]
train() client id: f_00007-6-3 loss: 0.778951  [  128/  179]
train() client id: f_00007-6-4 loss: 0.754759  [  160/  179]
train() client id: f_00007-7-0 loss: 0.740717  [   32/  179]
train() client id: f_00007-7-1 loss: 0.673555  [   64/  179]
train() client id: f_00007-7-2 loss: 0.723807  [   96/  179]
train() client id: f_00007-7-3 loss: 0.857266  [  128/  179]
train() client id: f_00007-7-4 loss: 0.702625  [  160/  179]
train() client id: f_00007-8-0 loss: 0.700109  [   32/  179]
train() client id: f_00007-8-1 loss: 0.724895  [   64/  179]
train() client id: f_00007-8-2 loss: 0.818575  [   96/  179]
train() client id: f_00007-8-3 loss: 0.750007  [  128/  179]
train() client id: f_00007-8-4 loss: 0.736437  [  160/  179]
train() client id: f_00007-9-0 loss: 0.774757  [   32/  179]
train() client id: f_00007-9-1 loss: 0.708454  [   64/  179]
train() client id: f_00007-9-2 loss: 0.655241  [   96/  179]
train() client id: f_00007-9-3 loss: 0.803125  [  128/  179]
train() client id: f_00007-9-4 loss: 0.646966  [  160/  179]
train() client id: f_00007-10-0 loss: 0.812674  [   32/  179]
train() client id: f_00007-10-1 loss: 0.644025  [   64/  179]
train() client id: f_00007-10-2 loss: 0.659865  [   96/  179]
train() client id: f_00007-10-3 loss: 0.731722  [  128/  179]
train() client id: f_00007-10-4 loss: 0.755103  [  160/  179]
train() client id: f_00007-11-0 loss: 0.744281  [   32/  179]
train() client id: f_00007-11-1 loss: 0.651583  [   64/  179]
train() client id: f_00007-11-2 loss: 0.716573  [   96/  179]
train() client id: f_00007-11-3 loss: 0.905893  [  128/  179]
train() client id: f_00007-11-4 loss: 0.646422  [  160/  179]
train() client id: f_00007-12-0 loss: 0.706969  [   32/  179]
train() client id: f_00007-12-1 loss: 0.639586  [   64/  179]
train() client id: f_00007-12-2 loss: 0.891086  [   96/  179]
train() client id: f_00007-12-3 loss: 0.649491  [  128/  179]
train() client id: f_00007-12-4 loss: 0.705096  [  160/  179]
train() client id: f_00008-0-0 loss: 1.044497  [   32/  130]
train() client id: f_00008-0-1 loss: 1.060675  [   64/  130]
train() client id: f_00008-0-2 loss: 1.046630  [   96/  130]
train() client id: f_00008-0-3 loss: 1.034200  [  128/  130]
train() client id: f_00008-1-0 loss: 0.984223  [   32/  130]
train() client id: f_00008-1-1 loss: 1.132159  [   64/  130]
train() client id: f_00008-1-2 loss: 1.010343  [   96/  130]
train() client id: f_00008-1-3 loss: 1.021631  [  128/  130]
train() client id: f_00008-2-0 loss: 0.987494  [   32/  130]
train() client id: f_00008-2-1 loss: 1.018226  [   64/  130]
train() client id: f_00008-2-2 loss: 0.992943  [   96/  130]
train() client id: f_00008-2-3 loss: 1.127981  [  128/  130]
train() client id: f_00008-3-0 loss: 1.005843  [   32/  130]
train() client id: f_00008-3-1 loss: 1.057152  [   64/  130]
train() client id: f_00008-3-2 loss: 0.956884  [   96/  130]
train() client id: f_00008-3-3 loss: 1.061262  [  128/  130]
train() client id: f_00008-4-0 loss: 1.026030  [   32/  130]
train() client id: f_00008-4-1 loss: 0.997447  [   64/  130]
train() client id: f_00008-4-2 loss: 1.022597  [   96/  130]
train() client id: f_00008-4-3 loss: 1.040706  [  128/  130]
train() client id: f_00008-5-0 loss: 1.011171  [   32/  130]
train() client id: f_00008-5-1 loss: 0.949393  [   64/  130]
train() client id: f_00008-5-2 loss: 1.083750  [   96/  130]
train() client id: f_00008-5-3 loss: 0.999340  [  128/  130]
train() client id: f_00008-6-0 loss: 0.965282  [   32/  130]
train() client id: f_00008-6-1 loss: 1.028370  [   64/  130]
train() client id: f_00008-6-2 loss: 1.006027  [   96/  130]
train() client id: f_00008-6-3 loss: 1.029052  [  128/  130]
train() client id: f_00008-7-0 loss: 0.920908  [   32/  130]
train() client id: f_00008-7-1 loss: 0.987846  [   64/  130]
train() client id: f_00008-7-2 loss: 1.018123  [   96/  130]
train() client id: f_00008-7-3 loss: 1.129690  [  128/  130]
train() client id: f_00008-8-0 loss: 1.069626  [   32/  130]
train() client id: f_00008-8-1 loss: 0.917645  [   64/  130]
train() client id: f_00008-8-2 loss: 1.036083  [   96/  130]
train() client id: f_00008-8-3 loss: 1.042036  [  128/  130]
train() client id: f_00008-9-0 loss: 0.987084  [   32/  130]
train() client id: f_00008-9-1 loss: 1.005114  [   64/  130]
train() client id: f_00008-9-2 loss: 1.010853  [   96/  130]
train() client id: f_00008-9-3 loss: 1.092965  [  128/  130]
train() client id: f_00008-10-0 loss: 0.970555  [   32/  130]
train() client id: f_00008-10-1 loss: 1.035189  [   64/  130]
train() client id: f_00008-10-2 loss: 1.034819  [   96/  130]
train() client id: f_00008-10-3 loss: 1.025312  [  128/  130]
train() client id: f_00008-11-0 loss: 1.042238  [   32/  130]
train() client id: f_00008-11-1 loss: 1.074425  [   64/  130]
train() client id: f_00008-11-2 loss: 1.080735  [   96/  130]
train() client id: f_00008-11-3 loss: 0.911489  [  128/  130]
train() client id: f_00008-12-0 loss: 1.105165  [   32/  130]
train() client id: f_00008-12-1 loss: 0.971922  [   64/  130]
train() client id: f_00008-12-2 loss: 0.898599  [   96/  130]
train() client id: f_00008-12-3 loss: 1.139782  [  128/  130]
train() client id: f_00009-0-0 loss: 1.082645  [   32/  118]
train() client id: f_00009-0-1 loss: 1.112622  [   64/  118]
train() client id: f_00009-0-2 loss: 1.121426  [   96/  118]
train() client id: f_00009-1-0 loss: 1.144935  [   32/  118]
train() client id: f_00009-1-1 loss: 1.059820  [   64/  118]
train() client id: f_00009-1-2 loss: 1.102853  [   96/  118]
train() client id: f_00009-2-0 loss: 1.064267  [   32/  118]
train() client id: f_00009-2-1 loss: 1.111254  [   64/  118]
train() client id: f_00009-2-2 loss: 1.024193  [   96/  118]
train() client id: f_00009-3-0 loss: 1.069329  [   32/  118]
train() client id: f_00009-3-1 loss: 1.045570  [   64/  118]
train() client id: f_00009-3-2 loss: 0.946375  [   96/  118]
train() client id: f_00009-4-0 loss: 1.048697  [   32/  118]
train() client id: f_00009-4-1 loss: 0.988767  [   64/  118]
train() client id: f_00009-4-2 loss: 1.001581  [   96/  118]
train() client id: f_00009-5-0 loss: 1.026708  [   32/  118]
train() client id: f_00009-5-1 loss: 0.990511  [   64/  118]
train() client id: f_00009-5-2 loss: 0.972547  [   96/  118]
train() client id: f_00009-6-0 loss: 0.955707  [   32/  118]
train() client id: f_00009-6-1 loss: 1.007132  [   64/  118]
train() client id: f_00009-6-2 loss: 0.965504  [   96/  118]
train() client id: f_00009-7-0 loss: 0.872251  [   32/  118]
train() client id: f_00009-7-1 loss: 0.970762  [   64/  118]
train() client id: f_00009-7-2 loss: 1.008558  [   96/  118]
train() client id: f_00009-8-0 loss: 0.950700  [   32/  118]
train() client id: f_00009-8-1 loss: 0.909848  [   64/  118]
train() client id: f_00009-8-2 loss: 0.899065  [   96/  118]
train() client id: f_00009-9-0 loss: 0.991228  [   32/  118]
train() client id: f_00009-9-1 loss: 0.950792  [   64/  118]
train() client id: f_00009-9-2 loss: 0.907199  [   96/  118]
train() client id: f_00009-10-0 loss: 0.906523  [   32/  118]
train() client id: f_00009-10-1 loss: 0.853766  [   64/  118]
train() client id: f_00009-10-2 loss: 0.979268  [   96/  118]
train() client id: f_00009-11-0 loss: 0.978975  [   32/  118]
train() client id: f_00009-11-1 loss: 0.818368  [   64/  118]
train() client id: f_00009-11-2 loss: 0.954045  [   96/  118]
train() client id: f_00009-12-0 loss: 0.888891  [   32/  118]
train() client id: f_00009-12-1 loss: 1.026452  [   64/  118]
train() client id: f_00009-12-2 loss: 0.871529  [   96/  118]
At round 2 accuracy: 0.5570291777188329
At round 2 training accuracy: 0.5023474178403756
At round 2 training loss: 0.9878479403076145
gradient difference: 0.4264959394931793
train() client id: f_00000-0-0 loss: 1.085909  [   32/  126]
train() client id: f_00000-0-1 loss: 0.959743  [   64/  126]
train() client id: f_00000-0-2 loss: 1.009537  [   96/  126]
train() client id: f_00000-1-0 loss: 0.897443  [   32/  126]
train() client id: f_00000-1-1 loss: 1.002871  [   64/  126]
train() client id: f_00000-1-2 loss: 0.874785  [   96/  126]
train() client id: f_00000-2-0 loss: 0.883292  [   32/  126]
train() client id: f_00000-2-1 loss: 0.952729  [   64/  126]
train() client id: f_00000-2-2 loss: 0.914601  [   96/  126]
train() client id: f_00000-3-0 loss: 0.953212  [   32/  126]
train() client id: f_00000-3-1 loss: 0.817779  [   64/  126]
train() client id: f_00000-3-2 loss: 0.825683  [   96/  126]
train() client id: f_00000-4-0 loss: 0.776330  [   32/  126]
train() client id: f_00000-4-1 loss: 0.890493  [   64/  126]
train() client id: f_00000-4-2 loss: 0.761970  [   96/  126]
train() client id: f_00000-5-0 loss: 0.800544  [   32/  126]
train() client id: f_00000-5-1 loss: 0.756891  [   64/  126]
train() client id: f_00000-5-2 loss: 0.794583  [   96/  126]
train() client id: f_00000-6-0 loss: 0.816229  [   32/  126]
train() client id: f_00000-6-1 loss: 0.745409  [   64/  126]
train() client id: f_00000-6-2 loss: 0.669915  [   96/  126]
train() client id: f_00000-7-0 loss: 0.773835  [   32/  126]
train() client id: f_00000-7-1 loss: 0.689389  [   64/  126]
train() client id: f_00000-7-2 loss: 0.728475  [   96/  126]
train() client id: f_00000-8-0 loss: 0.699670  [   32/  126]
train() client id: f_00000-8-1 loss: 0.843945  [   64/  126]
train() client id: f_00000-8-2 loss: 0.640458  [   96/  126]
train() client id: f_00000-9-0 loss: 0.658125  [   32/  126]
train() client id: f_00000-9-1 loss: 0.721256  [   64/  126]
train() client id: f_00000-9-2 loss: 0.773011  [   96/  126]
train() client id: f_00000-10-0 loss: 0.757333  [   32/  126]
train() client id: f_00000-10-1 loss: 0.759826  [   64/  126]
train() client id: f_00000-10-2 loss: 0.623070  [   96/  126]
train() client id: f_00000-11-0 loss: 0.575922  [   32/  126]
train() client id: f_00000-11-1 loss: 0.688547  [   64/  126]
train() client id: f_00000-11-2 loss: 0.854366  [   96/  126]
train() client id: f_00000-12-0 loss: 0.723274  [   32/  126]
train() client id: f_00000-12-1 loss: 0.662954  [   64/  126]
train() client id: f_00000-12-2 loss: 0.599072  [   96/  126]
train() client id: f_00001-0-0 loss: 0.839003  [   32/  265]
train() client id: f_00001-0-1 loss: 0.816439  [   64/  265]
train() client id: f_00001-0-2 loss: 0.805569  [   96/  265]
train() client id: f_00001-0-3 loss: 0.866625  [  128/  265]
train() client id: f_00001-0-4 loss: 0.818714  [  160/  265]
train() client id: f_00001-0-5 loss: 0.801036  [  192/  265]
train() client id: f_00001-0-6 loss: 0.799566  [  224/  265]
train() client id: f_00001-0-7 loss: 0.799365  [  256/  265]
train() client id: f_00001-1-0 loss: 0.777889  [   32/  265]
train() client id: f_00001-1-1 loss: 0.778340  [   64/  265]
train() client id: f_00001-1-2 loss: 0.836885  [   96/  265]
train() client id: f_00001-1-3 loss: 0.706625  [  128/  265]
train() client id: f_00001-1-4 loss: 0.774910  [  160/  265]
train() client id: f_00001-1-5 loss: 0.737891  [  192/  265]
train() client id: f_00001-1-6 loss: 0.744873  [  224/  265]
train() client id: f_00001-1-7 loss: 0.735034  [  256/  265]
train() client id: f_00001-2-0 loss: 0.742000  [   32/  265]
train() client id: f_00001-2-1 loss: 0.701997  [   64/  265]
train() client id: f_00001-2-2 loss: 0.721982  [   96/  265]
train() client id: f_00001-2-3 loss: 0.753855  [  128/  265]
train() client id: f_00001-2-4 loss: 0.708189  [  160/  265]
train() client id: f_00001-2-5 loss: 0.743410  [  192/  265]
train() client id: f_00001-2-6 loss: 0.638466  [  224/  265]
train() client id: f_00001-2-7 loss: 0.680975  [  256/  265]
train() client id: f_00001-3-0 loss: 0.696931  [   32/  265]
train() client id: f_00001-3-1 loss: 0.675098  [   64/  265]
train() client id: f_00001-3-2 loss: 0.630446  [   96/  265]
train() client id: f_00001-3-3 loss: 0.659465  [  128/  265]
train() client id: f_00001-3-4 loss: 0.705850  [  160/  265]
train() client id: f_00001-3-5 loss: 0.662606  [  192/  265]
train() client id: f_00001-3-6 loss: 0.688262  [  224/  265]
train() client id: f_00001-3-7 loss: 0.688508  [  256/  265]
train() client id: f_00001-4-0 loss: 0.686154  [   32/  265]
train() client id: f_00001-4-1 loss: 0.624676  [   64/  265]
train() client id: f_00001-4-2 loss: 0.657476  [   96/  265]
train() client id: f_00001-4-3 loss: 0.672740  [  128/  265]
train() client id: f_00001-4-4 loss: 0.663842  [  160/  265]
train() client id: f_00001-4-5 loss: 0.636281  [  192/  265]
train() client id: f_00001-4-6 loss: 0.685585  [  224/  265]
train() client id: f_00001-4-7 loss: 0.630174  [  256/  265]
train() client id: f_00001-5-0 loss: 0.605212  [   32/  265]
train() client id: f_00001-5-1 loss: 0.652843  [   64/  265]
train() client id: f_00001-5-2 loss: 0.661386  [   96/  265]
train() client id: f_00001-5-3 loss: 0.589494  [  128/  265]
train() client id: f_00001-5-4 loss: 0.653137  [  160/  265]
train() client id: f_00001-5-5 loss: 0.674623  [  192/  265]
train() client id: f_00001-5-6 loss: 0.566470  [  224/  265]
train() client id: f_00001-5-7 loss: 0.669872  [  256/  265]
train() client id: f_00001-6-0 loss: 0.612439  [   32/  265]
train() client id: f_00001-6-1 loss: 0.626382  [   64/  265]
train() client id: f_00001-6-2 loss: 0.584185  [   96/  265]
train() client id: f_00001-6-3 loss: 0.694874  [  128/  265]
train() client id: f_00001-6-4 loss: 0.620747  [  160/  265]
train() client id: f_00001-6-5 loss: 0.673768  [  192/  265]
train() client id: f_00001-6-6 loss: 0.637198  [  224/  265]
train() client id: f_00001-6-7 loss: 0.600708  [  256/  265]
train() client id: f_00001-7-0 loss: 0.657524  [   32/  265]
train() client id: f_00001-7-1 loss: 0.596591  [   64/  265]
train() client id: f_00001-7-2 loss: 0.612298  [   96/  265]
train() client id: f_00001-7-3 loss: 0.604809  [  128/  265]
train() client id: f_00001-7-4 loss: 0.580208  [  160/  265]
train() client id: f_00001-7-5 loss: 0.635879  [  192/  265]
train() client id: f_00001-7-6 loss: 0.707153  [  224/  265]
train() client id: f_00001-7-7 loss: 0.639700  [  256/  265]
train() client id: f_00001-8-0 loss: 0.670595  [   32/  265]
train() client id: f_00001-8-1 loss: 0.655883  [   64/  265]
train() client id: f_00001-8-2 loss: 0.593439  [   96/  265]
train() client id: f_00001-8-3 loss: 0.600114  [  128/  265]
train() client id: f_00001-8-4 loss: 0.548812  [  160/  265]
train() client id: f_00001-8-5 loss: 0.651069  [  192/  265]
train() client id: f_00001-8-6 loss: 0.681804  [  224/  265]
train() client id: f_00001-8-7 loss: 0.591773  [  256/  265]
train() client id: f_00001-9-0 loss: 0.613080  [   32/  265]
train() client id: f_00001-9-1 loss: 0.684055  [   64/  265]
train() client id: f_00001-9-2 loss: 0.577417  [   96/  265]
train() client id: f_00001-9-3 loss: 0.584791  [  128/  265]
train() client id: f_00001-9-4 loss: 0.602218  [  160/  265]
train() client id: f_00001-9-5 loss: 0.620030  [  192/  265]
train() client id: f_00001-9-6 loss: 0.658581  [  224/  265]
train() client id: f_00001-9-7 loss: 0.660204  [  256/  265]
train() client id: f_00001-10-0 loss: 0.650216  [   32/  265]
train() client id: f_00001-10-1 loss: 0.656950  [   64/  265]
train() client id: f_00001-10-2 loss: 0.627580  [   96/  265]
train() client id: f_00001-10-3 loss: 0.645832  [  128/  265]
train() client id: f_00001-10-4 loss: 0.642278  [  160/  265]
train() client id: f_00001-10-5 loss: 0.667004  [  192/  265]
train() client id: f_00001-10-6 loss: 0.537058  [  224/  265]
train() client id: f_00001-10-7 loss: 0.581494  [  256/  265]
train() client id: f_00001-11-0 loss: 0.562280  [   32/  265]
train() client id: f_00001-11-1 loss: 0.567740  [   64/  265]
train() client id: f_00001-11-2 loss: 0.604422  [   96/  265]
train() client id: f_00001-11-3 loss: 0.609389  [  128/  265]
train() client id: f_00001-11-4 loss: 0.639696  [  160/  265]
train() client id: f_00001-11-5 loss: 0.620090  [  192/  265]
train() client id: f_00001-11-6 loss: 0.733666  [  224/  265]
train() client id: f_00001-11-7 loss: 0.680248  [  256/  265]
train() client id: f_00001-12-0 loss: 0.583125  [   32/  265]
train() client id: f_00001-12-1 loss: 0.638899  [   64/  265]
train() client id: f_00001-12-2 loss: 0.575023  [   96/  265]
train() client id: f_00001-12-3 loss: 0.656284  [  128/  265]
train() client id: f_00001-12-4 loss: 0.740837  [  160/  265]
train() client id: f_00001-12-5 loss: 0.582904  [  192/  265]
train() client id: f_00001-12-6 loss: 0.671698  [  224/  265]
train() client id: f_00001-12-7 loss: 0.569626  [  256/  265]
train() client id: f_00002-0-0 loss: 1.192508  [   32/  124]
train() client id: f_00002-0-1 loss: 1.281072  [   64/  124]
train() client id: f_00002-0-2 loss: 1.200210  [   96/  124]
train() client id: f_00002-1-0 loss: 1.210077  [   32/  124]
train() client id: f_00002-1-1 loss: 1.142821  [   64/  124]
train() client id: f_00002-1-2 loss: 1.181607  [   96/  124]
train() client id: f_00002-2-0 loss: 1.161028  [   32/  124]
train() client id: f_00002-2-1 loss: 1.100940  [   64/  124]
train() client id: f_00002-2-2 loss: 1.131475  [   96/  124]
train() client id: f_00002-3-0 loss: 1.114219  [   32/  124]
train() client id: f_00002-3-1 loss: 1.077988  [   64/  124]
train() client id: f_00002-3-2 loss: 1.137143  [   96/  124]
train() client id: f_00002-4-0 loss: 1.033335  [   32/  124]
train() client id: f_00002-4-1 loss: 1.130861  [   64/  124]
train() client id: f_00002-4-2 loss: 1.124757  [   96/  124]
train() client id: f_00002-5-0 loss: 1.063995  [   32/  124]
train() client id: f_00002-5-1 loss: 1.044935  [   64/  124]
train() client id: f_00002-5-2 loss: 1.058423  [   96/  124]
train() client id: f_00002-6-0 loss: 1.068388  [   32/  124]
train() client id: f_00002-6-1 loss: 1.025808  [   64/  124]
train() client id: f_00002-6-2 loss: 1.064730  [   96/  124]
train() client id: f_00002-7-0 loss: 1.076516  [   32/  124]
train() client id: f_00002-7-1 loss: 1.030485  [   64/  124]
train() client id: f_00002-7-2 loss: 1.002743  [   96/  124]
train() client id: f_00002-8-0 loss: 1.013660  [   32/  124]
train() client id: f_00002-8-1 loss: 1.026220  [   64/  124]
train() client id: f_00002-8-2 loss: 1.008948  [   96/  124]
train() client id: f_00002-9-0 loss: 1.019097  [   32/  124]
train() client id: f_00002-9-1 loss: 0.978408  [   64/  124]
train() client id: f_00002-9-2 loss: 0.989678  [   96/  124]
train() client id: f_00002-10-0 loss: 0.978655  [   32/  124]
train() client id: f_00002-10-1 loss: 0.985839  [   64/  124]
train() client id: f_00002-10-2 loss: 1.046027  [   96/  124]
train() client id: f_00002-11-0 loss: 0.949933  [   32/  124]
train() client id: f_00002-11-1 loss: 0.948537  [   64/  124]
train() client id: f_00002-11-2 loss: 0.955078  [   96/  124]
train() client id: f_00002-12-0 loss: 1.008867  [   32/  124]
train() client id: f_00002-12-1 loss: 0.984699  [   64/  124]
train() client id: f_00002-12-2 loss: 1.004119  [   96/  124]
train() client id: f_00003-0-0 loss: 1.079835  [   32/   43]
train() client id: f_00003-1-0 loss: 1.112235  [   32/   43]
train() client id: f_00003-2-0 loss: 1.137376  [   32/   43]
train() client id: f_00003-3-0 loss: 1.142295  [   32/   43]
train() client id: f_00003-4-0 loss: 1.116914  [   32/   43]
train() client id: f_00003-5-0 loss: 1.088687  [   32/   43]
train() client id: f_00003-6-0 loss: 1.136404  [   32/   43]
train() client id: f_00003-7-0 loss: 1.123019  [   32/   43]
train() client id: f_00003-8-0 loss: 1.111004  [   32/   43]
train() client id: f_00003-9-0 loss: 1.119906  [   32/   43]
train() client id: f_00003-10-0 loss: 1.079403  [   32/   43]
train() client id: f_00003-11-0 loss: 1.124454  [   32/   43]
train() client id: f_00003-12-0 loss: 1.169134  [   32/   43]
train() client id: f_00004-0-0 loss: 0.926184  [   32/  306]
train() client id: f_00004-0-1 loss: 1.069896  [   64/  306]
train() client id: f_00004-0-2 loss: 0.758099  [   96/  306]
train() client id: f_00004-0-3 loss: 0.950132  [  128/  306]
train() client id: f_00004-0-4 loss: 0.821561  [  160/  306]
train() client id: f_00004-0-5 loss: 0.793129  [  192/  306]
train() client id: f_00004-0-6 loss: 0.829473  [  224/  306]
train() client id: f_00004-0-7 loss: 0.993665  [  256/  306]
train() client id: f_00004-0-8 loss: 0.844404  [  288/  306]
train() client id: f_00004-1-0 loss: 0.921361  [   32/  306]
train() client id: f_00004-1-1 loss: 0.872163  [   64/  306]
train() client id: f_00004-1-2 loss: 0.885994  [   96/  306]
train() client id: f_00004-1-3 loss: 0.783349  [  128/  306]
train() client id: f_00004-1-4 loss: 0.789528  [  160/  306]
train() client id: f_00004-1-5 loss: 0.959279  [  192/  306]
train() client id: f_00004-1-6 loss: 0.994102  [  224/  306]
train() client id: f_00004-1-7 loss: 0.849786  [  256/  306]
train() client id: f_00004-1-8 loss: 0.887015  [  288/  306]
train() client id: f_00004-2-0 loss: 0.869207  [   32/  306]
train() client id: f_00004-2-1 loss: 0.932051  [   64/  306]
train() client id: f_00004-2-2 loss: 0.999457  [   96/  306]
train() client id: f_00004-2-3 loss: 0.918097  [  128/  306]
train() client id: f_00004-2-4 loss: 0.819991  [  160/  306]
train() client id: f_00004-2-5 loss: 0.843806  [  192/  306]
train() client id: f_00004-2-6 loss: 0.819386  [  224/  306]
train() client id: f_00004-2-7 loss: 0.983376  [  256/  306]
train() client id: f_00004-2-8 loss: 0.830784  [  288/  306]
train() client id: f_00004-3-0 loss: 1.030851  [   32/  306]
train() client id: f_00004-3-1 loss: 0.910913  [   64/  306]
train() client id: f_00004-3-2 loss: 0.931576  [   96/  306]
train() client id: f_00004-3-3 loss: 0.914660  [  128/  306]
train() client id: f_00004-3-4 loss: 0.903471  [  160/  306]
train() client id: f_00004-3-5 loss: 0.781154  [  192/  306]
train() client id: f_00004-3-6 loss: 0.872577  [  224/  306]
train() client id: f_00004-3-7 loss: 0.851362  [  256/  306]
train() client id: f_00004-3-8 loss: 0.837156  [  288/  306]
train() client id: f_00004-4-0 loss: 0.954515  [   32/  306]
train() client id: f_00004-4-1 loss: 0.864305  [   64/  306]
train() client id: f_00004-4-2 loss: 0.862147  [   96/  306]
train() client id: f_00004-4-3 loss: 0.805615  [  128/  306]
train() client id: f_00004-4-4 loss: 0.924455  [  160/  306]
train() client id: f_00004-4-5 loss: 0.840851  [  192/  306]
train() client id: f_00004-4-6 loss: 0.956939  [  224/  306]
train() client id: f_00004-4-7 loss: 0.925120  [  256/  306]
train() client id: f_00004-4-8 loss: 0.842731  [  288/  306]
train() client id: f_00004-5-0 loss: 0.909793  [   32/  306]
train() client id: f_00004-5-1 loss: 0.845307  [   64/  306]
train() client id: f_00004-5-2 loss: 0.805704  [   96/  306]
train() client id: f_00004-5-3 loss: 0.808860  [  128/  306]
train() client id: f_00004-5-4 loss: 0.909744  [  160/  306]
train() client id: f_00004-5-5 loss: 0.957710  [  192/  306]
train() client id: f_00004-5-6 loss: 0.882119  [  224/  306]
train() client id: f_00004-5-7 loss: 0.931031  [  256/  306]
train() client id: f_00004-5-8 loss: 0.970507  [  288/  306]
train() client id: f_00004-6-0 loss: 0.865497  [   32/  306]
train() client id: f_00004-6-1 loss: 0.975997  [   64/  306]
train() client id: f_00004-6-2 loss: 0.901504  [   96/  306]
train() client id: f_00004-6-3 loss: 0.847723  [  128/  306]
train() client id: f_00004-6-4 loss: 0.871320  [  160/  306]
train() client id: f_00004-6-5 loss: 0.943201  [  192/  306]
train() client id: f_00004-6-6 loss: 0.869013  [  224/  306]
train() client id: f_00004-6-7 loss: 0.907910  [  256/  306]
train() client id: f_00004-6-8 loss: 0.864994  [  288/  306]
train() client id: f_00004-7-0 loss: 0.907214  [   32/  306]
train() client id: f_00004-7-1 loss: 0.884905  [   64/  306]
train() client id: f_00004-7-2 loss: 0.807863  [   96/  306]
train() client id: f_00004-7-3 loss: 0.869389  [  128/  306]
train() client id: f_00004-7-4 loss: 0.957747  [  160/  306]
train() client id: f_00004-7-5 loss: 0.965504  [  192/  306]
train() client id: f_00004-7-6 loss: 0.825531  [  224/  306]
train() client id: f_00004-7-7 loss: 0.807912  [  256/  306]
train() client id: f_00004-7-8 loss: 0.999502  [  288/  306]
train() client id: f_00004-8-0 loss: 0.917312  [   32/  306]
train() client id: f_00004-8-1 loss: 0.875666  [   64/  306]
train() client id: f_00004-8-2 loss: 0.825938  [   96/  306]
train() client id: f_00004-8-3 loss: 0.840695  [  128/  306]
train() client id: f_00004-8-4 loss: 0.904114  [  160/  306]
train() client id: f_00004-8-5 loss: 0.944438  [  192/  306]
train() client id: f_00004-8-6 loss: 0.939280  [  224/  306]
train() client id: f_00004-8-7 loss: 0.972072  [  256/  306]
train() client id: f_00004-8-8 loss: 0.878197  [  288/  306]
train() client id: f_00004-9-0 loss: 0.859805  [   32/  306]
train() client id: f_00004-9-1 loss: 0.900351  [   64/  306]
train() client id: f_00004-9-2 loss: 0.904662  [   96/  306]
train() client id: f_00004-9-3 loss: 0.984064  [  128/  306]
train() client id: f_00004-9-4 loss: 0.848260  [  160/  306]
train() client id: f_00004-9-5 loss: 0.974641  [  192/  306]
train() client id: f_00004-9-6 loss: 0.908135  [  224/  306]
train() client id: f_00004-9-7 loss: 0.879797  [  256/  306]
train() client id: f_00004-9-8 loss: 0.900427  [  288/  306]
train() client id: f_00004-10-0 loss: 0.825805  [   32/  306]
train() client id: f_00004-10-1 loss: 0.895979  [   64/  306]
train() client id: f_00004-10-2 loss: 0.939004  [   96/  306]
train() client id: f_00004-10-3 loss: 0.932545  [  128/  306]
train() client id: f_00004-10-4 loss: 0.842479  [  160/  306]
train() client id: f_00004-10-5 loss: 0.806009  [  192/  306]
train() client id: f_00004-10-6 loss: 0.946566  [  224/  306]
train() client id: f_00004-10-7 loss: 0.940451  [  256/  306]
train() client id: f_00004-10-8 loss: 0.998907  [  288/  306]
train() client id: f_00004-11-0 loss: 0.926880  [   32/  306]
train() client id: f_00004-11-1 loss: 0.896328  [   64/  306]
train() client id: f_00004-11-2 loss: 0.825676  [   96/  306]
train() client id: f_00004-11-3 loss: 0.867087  [  128/  306]
train() client id: f_00004-11-4 loss: 1.004086  [  160/  306]
train() client id: f_00004-11-5 loss: 0.853379  [  192/  306]
train() client id: f_00004-11-6 loss: 0.932956  [  224/  306]
train() client id: f_00004-11-7 loss: 0.942581  [  256/  306]
train() client id: f_00004-11-8 loss: 0.884649  [  288/  306]
train() client id: f_00004-12-0 loss: 0.896281  [   32/  306]
train() client id: f_00004-12-1 loss: 0.860290  [   64/  306]
train() client id: f_00004-12-2 loss: 0.886408  [   96/  306]
train() client id: f_00004-12-3 loss: 0.911428  [  128/  306]
train() client id: f_00004-12-4 loss: 0.868874  [  160/  306]
train() client id: f_00004-12-5 loss: 0.928668  [  192/  306]
train() client id: f_00004-12-6 loss: 0.943388  [  224/  306]
train() client id: f_00004-12-7 loss: 0.851831  [  256/  306]
train() client id: f_00004-12-8 loss: 1.054333  [  288/  306]
train() client id: f_00005-0-0 loss: 1.157058  [   32/  146]
train() client id: f_00005-0-1 loss: 1.141161  [   64/  146]
train() client id: f_00005-0-2 loss: 1.017770  [   96/  146]
train() client id: f_00005-0-3 loss: 1.002460  [  128/  146]
train() client id: f_00005-1-0 loss: 1.020064  [   32/  146]
train() client id: f_00005-1-1 loss: 1.046727  [   64/  146]
train() client id: f_00005-1-2 loss: 1.037523  [   96/  146]
train() client id: f_00005-1-3 loss: 1.015864  [  128/  146]
train() client id: f_00005-2-0 loss: 1.006639  [   32/  146]
train() client id: f_00005-2-1 loss: 0.998157  [   64/  146]
train() client id: f_00005-2-2 loss: 1.070463  [   96/  146]
train() client id: f_00005-2-3 loss: 1.037470  [  128/  146]
train() client id: f_00005-3-0 loss: 0.976569  [   32/  146]
train() client id: f_00005-3-1 loss: 1.032128  [   64/  146]
train() client id: f_00005-3-2 loss: 0.986437  [   96/  146]
train() client id: f_00005-3-3 loss: 1.031632  [  128/  146]
train() client id: f_00005-4-0 loss: 0.920539  [   32/  146]
train() client id: f_00005-4-1 loss: 0.999293  [   64/  146]
train() client id: f_00005-4-2 loss: 1.045031  [   96/  146]
train() client id: f_00005-4-3 loss: 1.027004  [  128/  146]
train() client id: f_00005-5-0 loss: 0.931909  [   32/  146]
train() client id: f_00005-5-1 loss: 1.037596  [   64/  146]
train() client id: f_00005-5-2 loss: 0.966203  [   96/  146]
train() client id: f_00005-5-3 loss: 1.054405  [  128/  146]
train() client id: f_00005-6-0 loss: 0.961557  [   32/  146]
train() client id: f_00005-6-1 loss: 0.998883  [   64/  146]
train() client id: f_00005-6-2 loss: 0.965933  [   96/  146]
train() client id: f_00005-6-3 loss: 1.021761  [  128/  146]
train() client id: f_00005-7-0 loss: 1.015715  [   32/  146]
train() client id: f_00005-7-1 loss: 0.952121  [   64/  146]
train() client id: f_00005-7-2 loss: 0.980105  [   96/  146]
train() client id: f_00005-7-3 loss: 0.994664  [  128/  146]
train() client id: f_00005-8-0 loss: 0.945383  [   32/  146]
train() client id: f_00005-8-1 loss: 0.957632  [   64/  146]
train() client id: f_00005-8-2 loss: 0.964208  [   96/  146]
train() client id: f_00005-8-3 loss: 0.974258  [  128/  146]
train() client id: f_00005-9-0 loss: 0.975330  [   32/  146]
train() client id: f_00005-9-1 loss: 0.912276  [   64/  146]
train() client id: f_00005-9-2 loss: 0.972011  [   96/  146]
train() client id: f_00005-9-3 loss: 1.108227  [  128/  146]
train() client id: f_00005-10-0 loss: 0.987068  [   32/  146]
train() client id: f_00005-10-1 loss: 0.901769  [   64/  146]
train() client id: f_00005-10-2 loss: 0.969613  [   96/  146]
train() client id: f_00005-10-3 loss: 0.986931  [  128/  146]
train() client id: f_00005-11-0 loss: 1.063223  [   32/  146]
train() client id: f_00005-11-1 loss: 1.069573  [   64/  146]
train() client id: f_00005-11-2 loss: 0.881283  [   96/  146]
train() client id: f_00005-11-3 loss: 0.907663  [  128/  146]
train() client id: f_00005-12-0 loss: 0.975432  [   32/  146]
train() client id: f_00005-12-1 loss: 0.897647  [   64/  146]
train() client id: f_00005-12-2 loss: 1.046795  [   96/  146]
train() client id: f_00005-12-3 loss: 1.085736  [  128/  146]
train() client id: f_00006-0-0 loss: 1.025859  [   32/   54]
train() client id: f_00006-1-0 loss: 1.040053  [   32/   54]
train() client id: f_00006-2-0 loss: 1.006476  [   32/   54]
train() client id: f_00006-3-0 loss: 1.020025  [   32/   54]
train() client id: f_00006-4-0 loss: 0.998059  [   32/   54]
train() client id: f_00006-5-0 loss: 1.029566  [   32/   54]
train() client id: f_00006-6-0 loss: 1.040583  [   32/   54]
train() client id: f_00006-7-0 loss: 0.997013  [   32/   54]
train() client id: f_00006-8-0 loss: 1.039715  [   32/   54]
train() client id: f_00006-9-0 loss: 0.984998  [   32/   54]
train() client id: f_00006-10-0 loss: 1.048916  [   32/   54]
train() client id: f_00006-11-0 loss: 1.013296  [   32/   54]
train() client id: f_00006-12-0 loss: 1.030316  [   32/   54]
train() client id: f_00007-0-0 loss: 0.851072  [   32/  179]
train() client id: f_00007-0-1 loss: 0.967590  [   64/  179]
train() client id: f_00007-0-2 loss: 0.886934  [   96/  179]
train() client id: f_00007-0-3 loss: 0.790278  [  128/  179]
train() client id: f_00007-0-4 loss: 0.920513  [  160/  179]
train() client id: f_00007-1-0 loss: 0.836889  [   32/  179]
train() client id: f_00007-1-1 loss: 0.893535  [   64/  179]
train() client id: f_00007-1-2 loss: 0.828297  [   96/  179]
train() client id: f_00007-1-3 loss: 0.860588  [  128/  179]
train() client id: f_00007-1-4 loss: 0.787290  [  160/  179]
train() client id: f_00007-2-0 loss: 0.853173  [   32/  179]
train() client id: f_00007-2-1 loss: 0.852936  [   64/  179]
train() client id: f_00007-2-2 loss: 0.729514  [   96/  179]
train() client id: f_00007-2-3 loss: 0.809221  [  128/  179]
train() client id: f_00007-2-4 loss: 0.764724  [  160/  179]
train() client id: f_00007-3-0 loss: 0.812440  [   32/  179]
train() client id: f_00007-3-1 loss: 0.908110  [   64/  179]
train() client id: f_00007-3-2 loss: 0.713590  [   96/  179]
train() client id: f_00007-3-3 loss: 0.759743  [  128/  179]
train() client id: f_00007-3-4 loss: 0.761470  [  160/  179]
train() client id: f_00007-4-0 loss: 0.829905  [   32/  179]
train() client id: f_00007-4-1 loss: 0.733470  [   64/  179]
train() client id: f_00007-4-2 loss: 0.739186  [   96/  179]
train() client id: f_00007-4-3 loss: 0.812280  [  128/  179]
train() client id: f_00007-4-4 loss: 0.745914  [  160/  179]
train() client id: f_00007-5-0 loss: 0.838168  [   32/  179]
train() client id: f_00007-5-1 loss: 0.730532  [   64/  179]
train() client id: f_00007-5-2 loss: 0.743239  [   96/  179]
train() client id: f_00007-5-3 loss: 0.778674  [  128/  179]
train() client id: f_00007-5-4 loss: 0.705832  [  160/  179]
train() client id: f_00007-6-0 loss: 0.864459  [   32/  179]
train() client id: f_00007-6-1 loss: 0.749081  [   64/  179]
train() client id: f_00007-6-2 loss: 0.640829  [   96/  179]
train() client id: f_00007-6-3 loss: 0.683814  [  128/  179]
train() client id: f_00007-6-4 loss: 0.693581  [  160/  179]
train() client id: f_00007-7-0 loss: 0.754629  [   32/  179]
train() client id: f_00007-7-1 loss: 0.796560  [   64/  179]
train() client id: f_00007-7-2 loss: 0.761598  [   96/  179]
train() client id: f_00007-7-3 loss: 0.645705  [  128/  179]
train() client id: f_00007-7-4 loss: 0.734743  [  160/  179]
train() client id: f_00007-8-0 loss: 0.723706  [   32/  179]
train() client id: f_00007-8-1 loss: 0.809029  [   64/  179]
train() client id: f_00007-8-2 loss: 0.697664  [   96/  179]
train() client id: f_00007-8-3 loss: 0.650210  [  128/  179]
train() client id: f_00007-8-4 loss: 0.790601  [  160/  179]
train() client id: f_00007-9-0 loss: 0.809837  [   32/  179]
train() client id: f_00007-9-1 loss: 0.611115  [   64/  179]
train() client id: f_00007-9-2 loss: 0.718834  [   96/  179]
train() client id: f_00007-9-3 loss: 0.839153  [  128/  179]
train() client id: f_00007-9-4 loss: 0.670615  [  160/  179]
train() client id: f_00007-10-0 loss: 0.817353  [   32/  179]
train() client id: f_00007-10-1 loss: 0.623804  [   64/  179]
train() client id: f_00007-10-2 loss: 0.763539  [   96/  179]
train() client id: f_00007-10-3 loss: 0.733199  [  128/  179]
train() client id: f_00007-10-4 loss: 0.687728  [  160/  179]
train() client id: f_00007-11-0 loss: 0.613865  [   32/  179]
train() client id: f_00007-11-1 loss: 0.700116  [   64/  179]
train() client id: f_00007-11-2 loss: 0.807995  [   96/  179]
train() client id: f_00007-11-3 loss: 0.824661  [  128/  179]
train() client id: f_00007-11-4 loss: 0.608710  [  160/  179]
train() client id: f_00007-12-0 loss: 0.635502  [   32/  179]
train() client id: f_00007-12-1 loss: 0.846521  [   64/  179]
train() client id: f_00007-12-2 loss: 0.913274  [   96/  179]
train() client id: f_00007-12-3 loss: 0.627799  [  128/  179]
train() client id: f_00007-12-4 loss: 0.622896  [  160/  179]
train() client id: f_00008-0-0 loss: 0.907452  [   32/  130]
train() client id: f_00008-0-1 loss: 0.928495  [   64/  130]
train() client id: f_00008-0-2 loss: 0.906752  [   96/  130]
train() client id: f_00008-0-3 loss: 0.885235  [  128/  130]
train() client id: f_00008-1-0 loss: 0.861312  [   32/  130]
train() client id: f_00008-1-1 loss: 0.883080  [   64/  130]
train() client id: f_00008-1-2 loss: 0.921483  [   96/  130]
train() client id: f_00008-1-3 loss: 0.912464  [  128/  130]
train() client id: f_00008-2-0 loss: 0.923167  [   32/  130]
train() client id: f_00008-2-1 loss: 0.900489  [   64/  130]
train() client id: f_00008-2-2 loss: 0.821395  [   96/  130]
train() client id: f_00008-2-3 loss: 0.908544  [  128/  130]
train() client id: f_00008-3-0 loss: 0.986895  [   32/  130]
train() client id: f_00008-3-1 loss: 0.907147  [   64/  130]
train() client id: f_00008-3-2 loss: 0.798554  [   96/  130]
train() client id: f_00008-3-3 loss: 0.796711  [  128/  130]
train() client id: f_00008-4-0 loss: 0.912584  [   32/  130]
train() client id: f_00008-4-1 loss: 0.831169  [   64/  130]
train() client id: f_00008-4-2 loss: 0.819593  [   96/  130]
train() client id: f_00008-4-3 loss: 0.884066  [  128/  130]
train() client id: f_00008-5-0 loss: 0.816706  [   32/  130]
train() client id: f_00008-5-1 loss: 0.798648  [   64/  130]
train() client id: f_00008-5-2 loss: 0.943811  [   96/  130]
train() client id: f_00008-5-3 loss: 0.891631  [  128/  130]
train() client id: f_00008-6-0 loss: 0.820688  [   32/  130]
train() client id: f_00008-6-1 loss: 0.808251  [   64/  130]
train() client id: f_00008-6-2 loss: 0.952944  [   96/  130]
train() client id: f_00008-6-3 loss: 0.825817  [  128/  130]
train() client id: f_00008-7-0 loss: 0.906469  [   32/  130]
train() client id: f_00008-7-1 loss: 0.826658  [   64/  130]
train() client id: f_00008-7-2 loss: 0.773814  [   96/  130]
train() client id: f_00008-7-3 loss: 0.901386  [  128/  130]
train() client id: f_00008-8-0 loss: 0.875549  [   32/  130]
train() client id: f_00008-8-1 loss: 0.752100  [   64/  130]
train() client id: f_00008-8-2 loss: 0.907612  [   96/  130]
train() client id: f_00008-8-3 loss: 0.865982  [  128/  130]
train() client id: f_00008-9-0 loss: 0.827076  [   32/  130]
train() client id: f_00008-9-1 loss: 0.731387  [   64/  130]
train() client id: f_00008-9-2 loss: 0.925448  [   96/  130]
train() client id: f_00008-9-3 loss: 0.909638  [  128/  130]
train() client id: f_00008-10-0 loss: 0.892804  [   32/  130]
train() client id: f_00008-10-1 loss: 0.831124  [   64/  130]
train() client id: f_00008-10-2 loss: 0.789367  [   96/  130]
train() client id: f_00008-10-3 loss: 0.835291  [  128/  130]
train() client id: f_00008-11-0 loss: 0.790705  [   32/  130]
train() client id: f_00008-11-1 loss: 0.769948  [   64/  130]
train() client id: f_00008-11-2 loss: 0.871930  [   96/  130]
train() client id: f_00008-11-3 loss: 0.924669  [  128/  130]
train() client id: f_00008-12-0 loss: 0.825673  [   32/  130]
train() client id: f_00008-12-1 loss: 0.830210  [   64/  130]
train() client id: f_00008-12-2 loss: 0.814150  [   96/  130]
train() client id: f_00008-12-3 loss: 0.899357  [  128/  130]
train() client id: f_00009-0-0 loss: 1.265846  [   32/  118]
train() client id: f_00009-0-1 loss: 1.146231  [   64/  118]
train() client id: f_00009-0-2 loss: 1.103789  [   96/  118]
train() client id: f_00009-1-0 loss: 1.133076  [   32/  118]
train() client id: f_00009-1-1 loss: 1.186558  [   64/  118]
train() client id: f_00009-1-2 loss: 1.103514  [   96/  118]
train() client id: f_00009-2-0 loss: 1.131590  [   32/  118]
train() client id: f_00009-2-1 loss: 1.078603  [   64/  118]
train() client id: f_00009-2-2 loss: 1.114853  [   96/  118]
train() client id: f_00009-3-0 loss: 1.114352  [   32/  118]
train() client id: f_00009-3-1 loss: 1.068267  [   64/  118]
train() client id: f_00009-3-2 loss: 1.091899  [   96/  118]
train() client id: f_00009-4-0 loss: 1.085001  [   32/  118]
train() client id: f_00009-4-1 loss: 1.030378  [   64/  118]
train() client id: f_00009-4-2 loss: 1.040694  [   96/  118]
train() client id: f_00009-5-0 loss: 1.063008  [   32/  118]
train() client id: f_00009-5-1 loss: 1.049274  [   64/  118]
train() client id: f_00009-5-2 loss: 1.058118  [   96/  118]
train() client id: f_00009-6-0 loss: 1.044516  [   32/  118]
train() client id: f_00009-6-1 loss: 1.041436  [   64/  118]
train() client id: f_00009-6-2 loss: 1.020893  [   96/  118]
train() client id: f_00009-7-0 loss: 1.069931  [   32/  118]
train() client id: f_00009-7-1 loss: 1.006422  [   64/  118]
train() client id: f_00009-7-2 loss: 0.979711  [   96/  118]
train() client id: f_00009-8-0 loss: 1.040676  [   32/  118]
train() client id: f_00009-8-1 loss: 1.053212  [   64/  118]
train() client id: f_00009-8-2 loss: 0.996792  [   96/  118]
train() client id: f_00009-9-0 loss: 1.037496  [   32/  118]
train() client id: f_00009-9-1 loss: 0.993864  [   64/  118]
train() client id: f_00009-9-2 loss: 0.938155  [   96/  118]
train() client id: f_00009-10-0 loss: 1.002722  [   32/  118]
train() client id: f_00009-10-1 loss: 1.005021  [   64/  118]
train() client id: f_00009-10-2 loss: 1.003038  [   96/  118]
train() client id: f_00009-11-0 loss: 1.010694  [   32/  118]
train() client id: f_00009-11-1 loss: 0.955704  [   64/  118]
train() client id: f_00009-11-2 loss: 1.057983  [   96/  118]
train() client id: f_00009-12-0 loss: 0.991985  [   32/  118]
train() client id: f_00009-12-1 loss: 0.999433  [   64/  118]
train() client id: f_00009-12-2 loss: 0.994929  [   96/  118]
At round 3 accuracy: 0.6047745358090185
At round 3 training accuracy: 0.5506371562709591
At round 3 training loss: 0.9425616484589286
gradient difference: 0.5000285506248474
train() client id: f_00000-0-0 loss: 1.031658  [   32/  126]
train() client id: f_00000-0-1 loss: 1.058676  [   64/  126]
train() client id: f_00000-0-2 loss: 1.115812  [   96/  126]
train() client id: f_00000-1-0 loss: 1.102599  [   32/  126]
train() client id: f_00000-1-1 loss: 0.985098  [   64/  126]
train() client id: f_00000-1-2 loss: 0.966461  [   96/  126]
train() client id: f_00000-2-0 loss: 1.061507  [   32/  126]
train() client id: f_00000-2-1 loss: 0.899371  [   64/  126]
train() client id: f_00000-2-2 loss: 1.012738  [   96/  126]
train() client id: f_00000-3-0 loss: 0.945314  [   32/  126]
train() client id: f_00000-3-1 loss: 1.063666  [   64/  126]
train() client id: f_00000-3-2 loss: 0.921936  [   96/  126]
train() client id: f_00000-4-0 loss: 0.924972  [   32/  126]
train() client id: f_00000-4-1 loss: 0.902574  [   64/  126]
train() client id: f_00000-4-2 loss: 0.956712  [   96/  126]
train() client id: f_00000-5-0 loss: 0.923927  [   32/  126]
train() client id: f_00000-5-1 loss: 0.920638  [   64/  126]
train() client id: f_00000-5-2 loss: 0.891227  [   96/  126]
train() client id: f_00000-6-0 loss: 0.860895  [   32/  126]
train() client id: f_00000-6-1 loss: 0.988437  [   64/  126]
train() client id: f_00000-6-2 loss: 0.961537  [   96/  126]
train() client id: f_00000-7-0 loss: 1.044840  [   32/  126]
train() client id: f_00000-7-1 loss: 0.791502  [   64/  126]
train() client id: f_00000-7-2 loss: 0.922345  [   96/  126]
train() client id: f_00000-8-0 loss: 0.905953  [   32/  126]
train() client id: f_00000-8-1 loss: 0.888913  [   64/  126]
train() client id: f_00000-8-2 loss: 0.904888  [   96/  126]
train() client id: f_00000-9-0 loss: 0.909131  [   32/  126]
train() client id: f_00000-9-1 loss: 0.875746  [   64/  126]
train() client id: f_00000-9-2 loss: 0.876036  [   96/  126]
train() client id: f_00000-10-0 loss: 0.997786  [   32/  126]
train() client id: f_00000-10-1 loss: 0.784454  [   64/  126]
train() client id: f_00000-10-2 loss: 0.953465  [   96/  126]
train() client id: f_00000-11-0 loss: 0.895828  [   32/  126]
train() client id: f_00000-11-1 loss: 0.891053  [   64/  126]
train() client id: f_00000-11-2 loss: 1.024487  [   96/  126]
train() client id: f_00000-12-0 loss: 0.940063  [   32/  126]
train() client id: f_00000-12-1 loss: 1.004652  [   64/  126]
train() client id: f_00000-12-2 loss: 0.940758  [   96/  126]
train() client id: f_00001-0-0 loss: 0.752224  [   32/  265]
train() client id: f_00001-0-1 loss: 0.750242  [   64/  265]
train() client id: f_00001-0-2 loss: 0.824394  [   96/  265]
train() client id: f_00001-0-3 loss: 0.811395  [  128/  265]
train() client id: f_00001-0-4 loss: 0.788768  [  160/  265]
train() client id: f_00001-0-5 loss: 0.805109  [  192/  265]
train() client id: f_00001-0-6 loss: 0.730987  [  224/  265]
train() client id: f_00001-0-7 loss: 0.673435  [  256/  265]
train() client id: f_00001-1-0 loss: 0.751551  [   32/  265]
train() client id: f_00001-1-1 loss: 0.651719  [   64/  265]
train() client id: f_00001-1-2 loss: 0.719015  [   96/  265]
train() client id: f_00001-1-3 loss: 0.736301  [  128/  265]
train() client id: f_00001-1-4 loss: 0.699470  [  160/  265]
train() client id: f_00001-1-5 loss: 0.690442  [  192/  265]
train() client id: f_00001-1-6 loss: 0.726727  [  224/  265]
train() client id: f_00001-1-7 loss: 0.723623  [  256/  265]
train() client id: f_00001-2-0 loss: 0.686262  [   32/  265]
train() client id: f_00001-2-1 loss: 0.629523  [   64/  265]
train() client id: f_00001-2-2 loss: 0.684437  [   96/  265]
train() client id: f_00001-2-3 loss: 0.742977  [  128/  265]
train() client id: f_00001-2-4 loss: 0.657877  [  160/  265]
train() client id: f_00001-2-5 loss: 0.681148  [  192/  265]
train() client id: f_00001-2-6 loss: 0.680165  [  224/  265]
train() client id: f_00001-2-7 loss: 0.658976  [  256/  265]
train() client id: f_00001-3-0 loss: 0.668661  [   32/  265]
train() client id: f_00001-3-1 loss: 0.689635  [   64/  265]
train() client id: f_00001-3-2 loss: 0.665725  [   96/  265]
train() client id: f_00001-3-3 loss: 0.647576  [  128/  265]
train() client id: f_00001-3-4 loss: 0.628628  [  160/  265]
train() client id: f_00001-3-5 loss: 0.685691  [  192/  265]
train() client id: f_00001-3-6 loss: 0.620907  [  224/  265]
train() client id: f_00001-3-7 loss: 0.633081  [  256/  265]
train() client id: f_00001-4-0 loss: 0.598722  [   32/  265]
train() client id: f_00001-4-1 loss: 0.641232  [   64/  265]
train() client id: f_00001-4-2 loss: 0.679123  [   96/  265]
train() client id: f_00001-4-3 loss: 0.611502  [  128/  265]
train() client id: f_00001-4-4 loss: 0.665105  [  160/  265]
train() client id: f_00001-4-5 loss: 0.612988  [  192/  265]
train() client id: f_00001-4-6 loss: 0.621742  [  224/  265]
train() client id: f_00001-4-7 loss: 0.677605  [  256/  265]
train() client id: f_00001-5-0 loss: 0.718561  [   32/  265]
train() client id: f_00001-5-1 loss: 0.585599  [   64/  265]
train() client id: f_00001-5-2 loss: 0.664830  [   96/  265]
train() client id: f_00001-5-3 loss: 0.599577  [  128/  265]
train() client id: f_00001-5-4 loss: 0.573621  [  160/  265]
train() client id: f_00001-5-5 loss: 0.669867  [  192/  265]
train() client id: f_00001-5-6 loss: 0.603924  [  224/  265]
train() client id: f_00001-5-7 loss: 0.608843  [  256/  265]
train() client id: f_00001-6-0 loss: 0.588737  [   32/  265]
train() client id: f_00001-6-1 loss: 0.594586  [   64/  265]
train() client id: f_00001-6-2 loss: 0.631199  [   96/  265]
train() client id: f_00001-6-3 loss: 0.666557  [  128/  265]
train() client id: f_00001-6-4 loss: 0.593893  [  160/  265]
train() client id: f_00001-6-5 loss: 0.559722  [  192/  265]
train() client id: f_00001-6-6 loss: 0.654266  [  224/  265]
train() client id: f_00001-6-7 loss: 0.603194  [  256/  265]
train() client id: f_00001-7-0 loss: 0.616582  [   32/  265]
train() client id: f_00001-7-1 loss: 0.585117  [   64/  265]
train() client id: f_00001-7-2 loss: 0.595360  [   96/  265]
train() client id: f_00001-7-3 loss: 0.702710  [  128/  265]
train() client id: f_00001-7-4 loss: 0.599688  [  160/  265]
train() client id: f_00001-7-5 loss: 0.563933  [  192/  265]
train() client id: f_00001-7-6 loss: 0.622118  [  224/  265]
train() client id: f_00001-7-7 loss: 0.618772  [  256/  265]
train() client id: f_00001-8-0 loss: 0.663134  [   32/  265]
train() client id: f_00001-8-1 loss: 0.672675  [   64/  265]
train() client id: f_00001-8-2 loss: 0.648481  [   96/  265]
train() client id: f_00001-8-3 loss: 0.620837  [  128/  265]
train() client id: f_00001-8-4 loss: 0.593463  [  160/  265]
train() client id: f_00001-8-5 loss: 0.524396  [  192/  265]
train() client id: f_00001-8-6 loss: 0.605911  [  224/  265]
train() client id: f_00001-8-7 loss: 0.577648  [  256/  265]
train() client id: f_00001-9-0 loss: 0.564214  [   32/  265]
train() client id: f_00001-9-1 loss: 0.600253  [   64/  265]
train() client id: f_00001-9-2 loss: 0.614950  [   96/  265]
train() client id: f_00001-9-3 loss: 0.691058  [  128/  265]
train() client id: f_00001-9-4 loss: 0.584236  [  160/  265]
train() client id: f_00001-9-5 loss: 0.567934  [  192/  265]
train() client id: f_00001-9-6 loss: 0.619799  [  224/  265]
train() client id: f_00001-9-7 loss: 0.639923  [  256/  265]
train() client id: f_00001-10-0 loss: 0.597014  [   32/  265]
train() client id: f_00001-10-1 loss: 0.597766  [   64/  265]
train() client id: f_00001-10-2 loss: 0.582119  [   96/  265]
train() client id: f_00001-10-3 loss: 0.646623  [  128/  265]
train() client id: f_00001-10-4 loss: 0.573947  [  160/  265]
train() client id: f_00001-10-5 loss: 0.545769  [  192/  265]
train() client id: f_00001-10-6 loss: 0.618129  [  224/  265]
train() client id: f_00001-10-7 loss: 0.676679  [  256/  265]
train() client id: f_00001-11-0 loss: 0.596719  [   32/  265]
train() client id: f_00001-11-1 loss: 0.592889  [   64/  265]
train() client id: f_00001-11-2 loss: 0.546714  [   96/  265]
train() client id: f_00001-11-3 loss: 0.755006  [  128/  265]
train() client id: f_00001-11-4 loss: 0.586020  [  160/  265]
train() client id: f_00001-11-5 loss: 0.625600  [  192/  265]
train() client id: f_00001-11-6 loss: 0.586937  [  224/  265]
train() client id: f_00001-11-7 loss: 0.590352  [  256/  265]
train() client id: f_00001-12-0 loss: 0.527382  [   32/  265]
train() client id: f_00001-12-1 loss: 0.602927  [   64/  265]
train() client id: f_00001-12-2 loss: 0.656686  [   96/  265]
train() client id: f_00001-12-3 loss: 0.653215  [  128/  265]
train() client id: f_00001-12-4 loss: 0.672602  [  160/  265]
train() client id: f_00001-12-5 loss: 0.624531  [  192/  265]
train() client id: f_00001-12-6 loss: 0.552523  [  224/  265]
train() client id: f_00001-12-7 loss: 0.598488  [  256/  265]
train() client id: f_00002-0-0 loss: 1.204641  [   32/  124]
train() client id: f_00002-0-1 loss: 1.146621  [   64/  124]
train() client id: f_00002-0-2 loss: 1.213019  [   96/  124]
train() client id: f_00002-1-0 loss: 1.187098  [   32/  124]
train() client id: f_00002-1-1 loss: 1.108303  [   64/  124]
train() client id: f_00002-1-2 loss: 1.119468  [   96/  124]
train() client id: f_00002-2-0 loss: 1.141536  [   32/  124]
train() client id: f_00002-2-1 loss: 1.140725  [   64/  124]
train() client id: f_00002-2-2 loss: 1.076209  [   96/  124]
train() client id: f_00002-3-0 loss: 1.054794  [   32/  124]
train() client id: f_00002-3-1 loss: 1.150452  [   64/  124]
train() client id: f_00002-3-2 loss: 1.077005  [   96/  124]
train() client id: f_00002-4-0 loss: 1.085671  [   32/  124]
train() client id: f_00002-4-1 loss: 1.104704  [   64/  124]
train() client id: f_00002-4-2 loss: 1.058008  [   96/  124]
train() client id: f_00002-5-0 loss: 1.016926  [   32/  124]
train() client id: f_00002-5-1 loss: 1.079103  [   64/  124]
train() client id: f_00002-5-2 loss: 1.043828  [   96/  124]
train() client id: f_00002-6-0 loss: 1.067269  [   32/  124]
train() client id: f_00002-6-1 loss: 1.072863  [   64/  124]
train() client id: f_00002-6-2 loss: 0.994790  [   96/  124]
train() client id: f_00002-7-0 loss: 0.975118  [   32/  124]
train() client id: f_00002-7-1 loss: 1.000426  [   64/  124]
train() client id: f_00002-7-2 loss: 1.039338  [   96/  124]
train() client id: f_00002-8-0 loss: 1.016688  [   32/  124]
train() client id: f_00002-8-1 loss: 1.014246  [   64/  124]
train() client id: f_00002-8-2 loss: 0.976042  [   96/  124]
train() client id: f_00002-9-0 loss: 1.051248  [   32/  124]
train() client id: f_00002-9-1 loss: 0.984467  [   64/  124]
train() client id: f_00002-9-2 loss: 0.940691  [   96/  124]
train() client id: f_00002-10-0 loss: 0.944441  [   32/  124]
train() client id: f_00002-10-1 loss: 1.043856  [   64/  124]
train() client id: f_00002-10-2 loss: 0.965888  [   96/  124]
train() client id: f_00002-11-0 loss: 0.979234  [   32/  124]
train() client id: f_00002-11-1 loss: 1.015775  [   64/  124]
train() client id: f_00002-11-2 loss: 0.975513  [   96/  124]
train() client id: f_00002-12-0 loss: 0.935737  [   32/  124]
train() client id: f_00002-12-1 loss: 1.044462  [   64/  124]
train() client id: f_00002-12-2 loss: 1.022659  [   96/  124]
train() client id: f_00003-0-0 loss: 0.954041  [   32/   43]
train() client id: f_00003-1-0 loss: 0.978036  [   32/   43]
train() client id: f_00003-2-0 loss: 0.972407  [   32/   43]
train() client id: f_00003-3-0 loss: 0.963923  [   32/   43]
train() client id: f_00003-4-0 loss: 0.972126  [   32/   43]
train() client id: f_00003-5-0 loss: 1.022095  [   32/   43]
train() client id: f_00003-6-0 loss: 0.974895  [   32/   43]
train() client id: f_00003-7-0 loss: 1.019294  [   32/   43]
train() client id: f_00003-8-0 loss: 1.014197  [   32/   43]
train() client id: f_00003-9-0 loss: 0.996165  [   32/   43]
train() client id: f_00003-10-0 loss: 1.024659  [   32/   43]
train() client id: f_00003-11-0 loss: 0.938480  [   32/   43]
train() client id: f_00003-12-0 loss: 1.025078  [   32/   43]
train() client id: f_00004-0-0 loss: 0.863003  [   32/  306]
train() client id: f_00004-0-1 loss: 0.709424  [   64/  306]
train() client id: f_00004-0-2 loss: 0.708819  [   96/  306]
train() client id: f_00004-0-3 loss: 0.693970  [  128/  306]
train() client id: f_00004-0-4 loss: 0.787855  [  160/  306]
train() client id: f_00004-0-5 loss: 0.780297  [  192/  306]
train() client id: f_00004-0-6 loss: 0.834427  [  224/  306]
train() client id: f_00004-0-7 loss: 0.809915  [  256/  306]
train() client id: f_00004-0-8 loss: 0.839565  [  288/  306]
train() client id: f_00004-1-0 loss: 0.830657  [   32/  306]
train() client id: f_00004-1-1 loss: 0.709109  [   64/  306]
train() client id: f_00004-1-2 loss: 0.708849  [   96/  306]
train() client id: f_00004-1-3 loss: 0.756813  [  128/  306]
train() client id: f_00004-1-4 loss: 0.756288  [  160/  306]
train() client id: f_00004-1-5 loss: 0.781028  [  192/  306]
train() client id: f_00004-1-6 loss: 0.836434  [  224/  306]
train() client id: f_00004-1-7 loss: 0.714013  [  256/  306]
train() client id: f_00004-1-8 loss: 0.887977  [  288/  306]
train() client id: f_00004-2-0 loss: 0.650415  [   32/  306]
train() client id: f_00004-2-1 loss: 0.733577  [   64/  306]
train() client id: f_00004-2-2 loss: 0.785444  [   96/  306]
train() client id: f_00004-2-3 loss: 0.937774  [  128/  306]
train() client id: f_00004-2-4 loss: 0.827791  [  160/  306]
train() client id: f_00004-2-5 loss: 0.602655  [  192/  306]
train() client id: f_00004-2-6 loss: 0.828046  [  224/  306]
train() client id: f_00004-2-7 loss: 0.808037  [  256/  306]
train() client id: f_00004-2-8 loss: 0.859955  [  288/  306]
train() client id: f_00004-3-0 loss: 0.718879  [   32/  306]
train() client id: f_00004-3-1 loss: 0.840477  [   64/  306]
train() client id: f_00004-3-2 loss: 0.771552  [   96/  306]
train() client id: f_00004-3-3 loss: 0.734378  [  128/  306]
train() client id: f_00004-3-4 loss: 0.730150  [  160/  306]
train() client id: f_00004-3-5 loss: 0.915516  [  192/  306]
train() client id: f_00004-3-6 loss: 0.767267  [  224/  306]
train() client id: f_00004-3-7 loss: 0.856477  [  256/  306]
train() client id: f_00004-3-8 loss: 0.727619  [  288/  306]
train() client id: f_00004-4-0 loss: 0.938911  [   32/  306]
train() client id: f_00004-4-1 loss: 0.754651  [   64/  306]
train() client id: f_00004-4-2 loss: 0.736796  [   96/  306]
train() client id: f_00004-4-3 loss: 0.754948  [  128/  306]
train() client id: f_00004-4-4 loss: 0.850489  [  160/  306]
train() client id: f_00004-4-5 loss: 0.763551  [  192/  306]
train() client id: f_00004-4-6 loss: 0.765572  [  224/  306]
train() client id: f_00004-4-7 loss: 0.830768  [  256/  306]
train() client id: f_00004-4-8 loss: 0.803470  [  288/  306]
train() client id: f_00004-5-0 loss: 0.787711  [   32/  306]
train() client id: f_00004-5-1 loss: 0.741246  [   64/  306]
train() client id: f_00004-5-2 loss: 0.693151  [   96/  306]
train() client id: f_00004-5-3 loss: 0.772594  [  128/  306]
train() client id: f_00004-5-4 loss: 0.799803  [  160/  306]
train() client id: f_00004-5-5 loss: 0.887021  [  192/  306]
train() client id: f_00004-5-6 loss: 0.786940  [  224/  306]
train() client id: f_00004-5-7 loss: 0.894744  [  256/  306]
train() client id: f_00004-5-8 loss: 0.742765  [  288/  306]
train() client id: f_00004-6-0 loss: 0.696125  [   32/  306]
train() client id: f_00004-6-1 loss: 0.758704  [   64/  306]
train() client id: f_00004-6-2 loss: 0.868088  [   96/  306]
train() client id: f_00004-6-3 loss: 0.747318  [  128/  306]
train() client id: f_00004-6-4 loss: 0.796510  [  160/  306]
train() client id: f_00004-6-5 loss: 0.833419  [  192/  306]
train() client id: f_00004-6-6 loss: 0.772010  [  224/  306]
train() client id: f_00004-6-7 loss: 0.827404  [  256/  306]
train() client id: f_00004-6-8 loss: 0.812961  [  288/  306]
train() client id: f_00004-7-0 loss: 0.926586  [   32/  306]
train() client id: f_00004-7-1 loss: 0.785262  [   64/  306]
train() client id: f_00004-7-2 loss: 0.707868  [   96/  306]
train() client id: f_00004-7-3 loss: 0.866042  [  128/  306]
train() client id: f_00004-7-4 loss: 0.783083  [  160/  306]
train() client id: f_00004-7-5 loss: 0.932472  [  192/  306]
train() client id: f_00004-7-6 loss: 0.727115  [  224/  306]
train() client id: f_00004-7-7 loss: 0.797033  [  256/  306]
train() client id: f_00004-7-8 loss: 0.664688  [  288/  306]
train() client id: f_00004-8-0 loss: 0.804859  [   32/  306]
train() client id: f_00004-8-1 loss: 0.790398  [   64/  306]
train() client id: f_00004-8-2 loss: 0.788761  [   96/  306]
train() client id: f_00004-8-3 loss: 0.819458  [  128/  306]
train() client id: f_00004-8-4 loss: 0.821580  [  160/  306]
train() client id: f_00004-8-5 loss: 0.782651  [  192/  306]
train() client id: f_00004-8-6 loss: 0.738255  [  224/  306]
train() client id: f_00004-8-7 loss: 0.784485  [  256/  306]
train() client id: f_00004-8-8 loss: 0.781626  [  288/  306]
train() client id: f_00004-9-0 loss: 0.876453  [   32/  306]
train() client id: f_00004-9-1 loss: 0.781565  [   64/  306]
train() client id: f_00004-9-2 loss: 0.772938  [   96/  306]
train() client id: f_00004-9-3 loss: 0.742426  [  128/  306]
train() client id: f_00004-9-4 loss: 0.826328  [  160/  306]
train() client id: f_00004-9-5 loss: 0.776021  [  192/  306]
train() client id: f_00004-9-6 loss: 0.773453  [  224/  306]
train() client id: f_00004-9-7 loss: 0.798390  [  256/  306]
train() client id: f_00004-9-8 loss: 0.907061  [  288/  306]
train() client id: f_00004-10-0 loss: 0.875883  [   32/  306]
train() client id: f_00004-10-1 loss: 0.799250  [   64/  306]
train() client id: f_00004-10-2 loss: 0.819112  [   96/  306]
train() client id: f_00004-10-3 loss: 0.842489  [  128/  306]
train() client id: f_00004-10-4 loss: 0.753591  [  160/  306]
train() client id: f_00004-10-5 loss: 0.741822  [  192/  306]
train() client id: f_00004-10-6 loss: 0.747128  [  224/  306]
train() client id: f_00004-10-7 loss: 0.795002  [  256/  306]
train() client id: f_00004-10-8 loss: 0.878832  [  288/  306]
train() client id: f_00004-11-0 loss: 0.750687  [   32/  306]
train() client id: f_00004-11-1 loss: 0.733900  [   64/  306]
train() client id: f_00004-11-2 loss: 0.732534  [   96/  306]
train() client id: f_00004-11-3 loss: 0.739792  [  128/  306]
train() client id: f_00004-11-4 loss: 0.967160  [  160/  306]
train() client id: f_00004-11-5 loss: 0.797516  [  192/  306]
train() client id: f_00004-11-6 loss: 0.818762  [  224/  306]
train() client id: f_00004-11-7 loss: 0.824662  [  256/  306]
train() client id: f_00004-11-8 loss: 0.814630  [  288/  306]
train() client id: f_00004-12-0 loss: 0.841113  [   32/  306]
train() client id: f_00004-12-1 loss: 0.779519  [   64/  306]
train() client id: f_00004-12-2 loss: 0.818152  [   96/  306]
train() client id: f_00004-12-3 loss: 0.742991  [  128/  306]
train() client id: f_00004-12-4 loss: 0.835285  [  160/  306]
train() client id: f_00004-12-5 loss: 0.813426  [  192/  306]
train() client id: f_00004-12-6 loss: 0.858276  [  224/  306]
train() client id: f_00004-12-7 loss: 0.829629  [  256/  306]
train() client id: f_00004-12-8 loss: 0.769571  [  288/  306]
train() client id: f_00005-0-0 loss: 0.986213  [   32/  146]
train() client id: f_00005-0-1 loss: 0.948745  [   64/  146]
train() client id: f_00005-0-2 loss: 0.955027  [   96/  146]
train() client id: f_00005-0-3 loss: 0.899461  [  128/  146]
train() client id: f_00005-1-0 loss: 0.945895  [   32/  146]
train() client id: f_00005-1-1 loss: 0.919528  [   64/  146]
train() client id: f_00005-1-2 loss: 0.815466  [   96/  146]
train() client id: f_00005-1-3 loss: 0.944511  [  128/  146]
train() client id: f_00005-2-0 loss: 0.871172  [   32/  146]
train() client id: f_00005-2-1 loss: 0.892958  [   64/  146]
train() client id: f_00005-2-2 loss: 0.848087  [   96/  146]
train() client id: f_00005-2-3 loss: 0.878971  [  128/  146]
train() client id: f_00005-3-0 loss: 0.899321  [   32/  146]
train() client id: f_00005-3-1 loss: 0.820180  [   64/  146]
train() client id: f_00005-3-2 loss: 0.799355  [   96/  146]
train() client id: f_00005-3-3 loss: 0.874138  [  128/  146]
train() client id: f_00005-4-0 loss: 0.781363  [   32/  146]
train() client id: f_00005-4-1 loss: 0.806894  [   64/  146]
train() client id: f_00005-4-2 loss: 0.923188  [   96/  146]
train() client id: f_00005-4-3 loss: 0.843339  [  128/  146]
train() client id: f_00005-5-0 loss: 0.795677  [   32/  146]
train() client id: f_00005-5-1 loss: 0.782383  [   64/  146]
train() client id: f_00005-5-2 loss: 0.913633  [   96/  146]
train() client id: f_00005-5-3 loss: 0.778279  [  128/  146]
train() client id: f_00005-6-0 loss: 0.840614  [   32/  146]
train() client id: f_00005-6-1 loss: 0.752210  [   64/  146]
train() client id: f_00005-6-2 loss: 0.767655  [   96/  146]
train() client id: f_00005-6-3 loss: 0.893776  [  128/  146]
train() client id: f_00005-7-0 loss: 0.782115  [   32/  146]
train() client id: f_00005-7-1 loss: 0.943254  [   64/  146]
train() client id: f_00005-7-2 loss: 0.665364  [   96/  146]
train() client id: f_00005-7-3 loss: 0.785048  [  128/  146]
train() client id: f_00005-8-0 loss: 0.778849  [   32/  146]
train() client id: f_00005-8-1 loss: 0.889294  [   64/  146]
train() client id: f_00005-8-2 loss: 0.818639  [   96/  146]
train() client id: f_00005-8-3 loss: 0.726466  [  128/  146]
train() client id: f_00005-9-0 loss: 0.849972  [   32/  146]
train() client id: f_00005-9-1 loss: 0.764039  [   64/  146]
train() client id: f_00005-9-2 loss: 0.716498  [   96/  146]
train() client id: f_00005-9-3 loss: 0.826137  [  128/  146]
train() client id: f_00005-10-0 loss: 0.678682  [   32/  146]
train() client id: f_00005-10-1 loss: 0.778377  [   64/  146]
train() client id: f_00005-10-2 loss: 0.809460  [   96/  146]
train() client id: f_00005-10-3 loss: 0.819281  [  128/  146]
train() client id: f_00005-11-0 loss: 0.712606  [   32/  146]
train() client id: f_00005-11-1 loss: 0.831202  [   64/  146]
train() client id: f_00005-11-2 loss: 0.908875  [   96/  146]
train() client id: f_00005-11-3 loss: 0.719551  [  128/  146]
train() client id: f_00005-12-0 loss: 0.675635  [   32/  146]
train() client id: f_00005-12-1 loss: 0.817526  [   64/  146]
train() client id: f_00005-12-2 loss: 0.898207  [   96/  146]
train() client id: f_00005-12-3 loss: 0.790429  [  128/  146]
train() client id: f_00006-0-0 loss: 0.968109  [   32/   54]
train() client id: f_00006-1-0 loss: 0.995232  [   32/   54]
train() client id: f_00006-2-0 loss: 0.975138  [   32/   54]
train() client id: f_00006-3-0 loss: 1.005261  [   32/   54]
train() client id: f_00006-4-0 loss: 0.963308  [   32/   54]
train() client id: f_00006-5-0 loss: 0.987809  [   32/   54]
train() client id: f_00006-6-0 loss: 0.977339  [   32/   54]
train() client id: f_00006-7-0 loss: 0.976440  [   32/   54]
train() client id: f_00006-8-0 loss: 0.956939  [   32/   54]
train() client id: f_00006-9-0 loss: 0.974300  [   32/   54]
train() client id: f_00006-10-0 loss: 1.017956  [   32/   54]
train() client id: f_00006-11-0 loss: 0.960191  [   32/   54]
train() client id: f_00006-12-0 loss: 1.006069  [   32/   54]
train() client id: f_00007-0-0 loss: 0.883546  [   32/  179]
train() client id: f_00007-0-1 loss: 0.881201  [   64/  179]
train() client id: f_00007-0-2 loss: 0.945890  [   96/  179]
train() client id: f_00007-0-3 loss: 0.852222  [  128/  179]
train() client id: f_00007-0-4 loss: 0.873408  [  160/  179]
train() client id: f_00007-1-0 loss: 0.815163  [   32/  179]
train() client id: f_00007-1-1 loss: 0.835175  [   64/  179]
train() client id: f_00007-1-2 loss: 0.827713  [   96/  179]
train() client id: f_00007-1-3 loss: 0.857608  [  128/  179]
train() client id: f_00007-1-4 loss: 0.852402  [  160/  179]
train() client id: f_00007-2-0 loss: 0.763885  [   32/  179]
train() client id: f_00007-2-1 loss: 0.798612  [   64/  179]
train() client id: f_00007-2-2 loss: 0.783567  [   96/  179]
train() client id: f_00007-2-3 loss: 0.844143  [  128/  179]
train() client id: f_00007-2-4 loss: 0.868376  [  160/  179]
train() client id: f_00007-3-0 loss: 0.739489  [   32/  179]
train() client id: f_00007-3-1 loss: 0.856026  [   64/  179]
train() client id: f_00007-3-2 loss: 0.805895  [   96/  179]
train() client id: f_00007-3-3 loss: 0.942828  [  128/  179]
train() client id: f_00007-3-4 loss: 0.763243  [  160/  179]
train() client id: f_00007-4-0 loss: 0.848909  [   32/  179]
train() client id: f_00007-4-1 loss: 0.777852  [   64/  179]
train() client id: f_00007-4-2 loss: 0.769993  [   96/  179]
train() client id: f_00007-4-3 loss: 0.745427  [  128/  179]
train() client id: f_00007-4-4 loss: 0.730167  [  160/  179]
train() client id: f_00007-5-0 loss: 0.908372  [   32/  179]
train() client id: f_00007-5-1 loss: 0.815294  [   64/  179]
train() client id: f_00007-5-2 loss: 0.794546  [   96/  179]
train() client id: f_00007-5-3 loss: 0.759732  [  128/  179]
train() client id: f_00007-5-4 loss: 0.693430  [  160/  179]
train() client id: f_00007-6-0 loss: 0.791197  [   32/  179]
train() client id: f_00007-6-1 loss: 0.846492  [   64/  179]
train() client id: f_00007-6-2 loss: 0.701007  [   96/  179]
train() client id: f_00007-6-3 loss: 0.785405  [  128/  179]
train() client id: f_00007-6-4 loss: 0.764248  [  160/  179]
train() client id: f_00007-7-0 loss: 0.748024  [   32/  179]
train() client id: f_00007-7-1 loss: 0.886369  [   64/  179]
train() client id: f_00007-7-2 loss: 0.691246  [   96/  179]
train() client id: f_00007-7-3 loss: 0.792675  [  128/  179]
train() client id: f_00007-7-4 loss: 0.747866  [  160/  179]
train() client id: f_00007-8-0 loss: 0.743739  [   32/  179]
train() client id: f_00007-8-1 loss: 0.796634  [   64/  179]
train() client id: f_00007-8-2 loss: 0.666905  [   96/  179]
train() client id: f_00007-8-3 loss: 0.758444  [  128/  179]
train() client id: f_00007-8-4 loss: 0.878177  [  160/  179]
train() client id: f_00007-9-0 loss: 0.709951  [   32/  179]
train() client id: f_00007-9-1 loss: 0.723134  [   64/  179]
train() client id: f_00007-9-2 loss: 0.814543  [   96/  179]
train() client id: f_00007-9-3 loss: 0.897578  [  128/  179]
train() client id: f_00007-9-4 loss: 0.775695  [  160/  179]
train() client id: f_00007-10-0 loss: 0.677343  [   32/  179]
train() client id: f_00007-10-1 loss: 0.850470  [   64/  179]
train() client id: f_00007-10-2 loss: 0.754027  [   96/  179]
train() client id: f_00007-10-3 loss: 0.754251  [  128/  179]
train() client id: f_00007-10-4 loss: 0.703561  [  160/  179]
train() client id: f_00007-11-0 loss: 0.840995  [   32/  179]
train() client id: f_00007-11-1 loss: 0.797673  [   64/  179]
train() client id: f_00007-11-2 loss: 0.735433  [   96/  179]
train() client id: f_00007-11-3 loss: 0.712642  [  128/  179]
train() client id: f_00007-11-4 loss: 0.709359  [  160/  179]
train() client id: f_00007-12-0 loss: 0.712145  [   32/  179]
train() client id: f_00007-12-1 loss: 0.859692  [   64/  179]
train() client id: f_00007-12-2 loss: 0.662816  [   96/  179]
train() client id: f_00007-12-3 loss: 0.773849  [  128/  179]
train() client id: f_00007-12-4 loss: 0.869663  [  160/  179]
train() client id: f_00008-0-0 loss: 0.854269  [   32/  130]
train() client id: f_00008-0-1 loss: 0.945896  [   64/  130]
train() client id: f_00008-0-2 loss: 0.901068  [   96/  130]
train() client id: f_00008-0-3 loss: 0.838356  [  128/  130]
train() client id: f_00008-1-0 loss: 0.910404  [   32/  130]
train() client id: f_00008-1-1 loss: 0.859960  [   64/  130]
train() client id: f_00008-1-2 loss: 0.875075  [   96/  130]
train() client id: f_00008-1-3 loss: 0.840604  [  128/  130]
train() client id: f_00008-2-0 loss: 0.833399  [   32/  130]
train() client id: f_00008-2-1 loss: 0.791876  [   64/  130]
train() client id: f_00008-2-2 loss: 0.866559  [   96/  130]
train() client id: f_00008-2-3 loss: 0.951206  [  128/  130]
train() client id: f_00008-3-0 loss: 0.904892  [   32/  130]
train() client id: f_00008-3-1 loss: 0.815487  [   64/  130]
train() client id: f_00008-3-2 loss: 0.928017  [   96/  130]
train() client id: f_00008-3-3 loss: 0.798530  [  128/  130]
train() client id: f_00008-4-0 loss: 0.899236  [   32/  130]
train() client id: f_00008-4-1 loss: 0.754820  [   64/  130]
train() client id: f_00008-4-2 loss: 0.860726  [   96/  130]
train() client id: f_00008-4-3 loss: 0.919564  [  128/  130]
train() client id: f_00008-5-0 loss: 0.759648  [   32/  130]
train() client id: f_00008-5-1 loss: 0.859584  [   64/  130]
train() client id: f_00008-5-2 loss: 0.893263  [   96/  130]
train() client id: f_00008-5-3 loss: 0.865435  [  128/  130]
train() client id: f_00008-6-0 loss: 0.862992  [   32/  130]
train() client id: f_00008-6-1 loss: 0.842984  [   64/  130]
train() client id: f_00008-6-2 loss: 0.893384  [   96/  130]
train() client id: f_00008-6-3 loss: 0.776937  [  128/  130]
train() client id: f_00008-7-0 loss: 0.820052  [   32/  130]
train() client id: f_00008-7-1 loss: 0.874885  [   64/  130]
train() client id: f_00008-7-2 loss: 0.817031  [   96/  130]
train() client id: f_00008-7-3 loss: 0.851314  [  128/  130]
train() client id: f_00008-8-0 loss: 0.867334  [   32/  130]
train() client id: f_00008-8-1 loss: 0.780265  [   64/  130]
train() client id: f_00008-8-2 loss: 0.861756  [   96/  130]
train() client id: f_00008-8-3 loss: 0.873329  [  128/  130]
train() client id: f_00008-9-0 loss: 0.844660  [   32/  130]
train() client id: f_00008-9-1 loss: 0.765529  [   64/  130]
train() client id: f_00008-9-2 loss: 0.821879  [   96/  130]
train() client id: f_00008-9-3 loss: 0.941669  [  128/  130]
train() client id: f_00008-10-0 loss: 0.784463  [   32/  130]
train() client id: f_00008-10-1 loss: 0.745404  [   64/  130]
train() client id: f_00008-10-2 loss: 0.830717  [   96/  130]
train() client id: f_00008-10-3 loss: 0.968738  [  128/  130]
train() client id: f_00008-11-0 loss: 0.860405  [   32/  130]
train() client id: f_00008-11-1 loss: 0.887187  [   64/  130]
train() client id: f_00008-11-2 loss: 0.823096  [   96/  130]
train() client id: f_00008-11-3 loss: 0.789500  [  128/  130]
train() client id: f_00008-12-0 loss: 0.830373  [   32/  130]
train() client id: f_00008-12-1 loss: 0.849495  [   64/  130]
train() client id: f_00008-12-2 loss: 0.856062  [   96/  130]
train() client id: f_00008-12-3 loss: 0.799130  [  128/  130]
train() client id: f_00009-0-0 loss: 1.147972  [   32/  118]
train() client id: f_00009-0-1 loss: 1.124660  [   64/  118]
train() client id: f_00009-0-2 loss: 1.107642  [   96/  118]
train() client id: f_00009-1-0 loss: 1.140178  [   32/  118]
train() client id: f_00009-1-1 loss: 1.093187  [   64/  118]
train() client id: f_00009-1-2 loss: 1.063000  [   96/  118]
train() client id: f_00009-2-0 loss: 1.108842  [   32/  118]
train() client id: f_00009-2-1 loss: 1.035350  [   64/  118]
train() client id: f_00009-2-2 loss: 1.037217  [   96/  118]
train() client id: f_00009-3-0 loss: 1.047372  [   32/  118]
train() client id: f_00009-3-1 loss: 0.988647  [   64/  118]
train() client id: f_00009-3-2 loss: 1.030810  [   96/  118]
train() client id: f_00009-4-0 loss: 1.062370  [   32/  118]
train() client id: f_00009-4-1 loss: 1.006043  [   64/  118]
train() client id: f_00009-4-2 loss: 0.997035  [   96/  118]
train() client id: f_00009-5-0 loss: 1.019813  [   32/  118]
train() client id: f_00009-5-1 loss: 1.037304  [   64/  118]
train() client id: f_00009-5-2 loss: 0.965964  [   96/  118]
train() client id: f_00009-6-0 loss: 0.964254  [   32/  118]
train() client id: f_00009-6-1 loss: 0.983436  [   64/  118]
train() client id: f_00009-6-2 loss: 1.028009  [   96/  118]
train() client id: f_00009-7-0 loss: 0.972205  [   32/  118]
train() client id: f_00009-7-1 loss: 1.014916  [   64/  118]
train() client id: f_00009-7-2 loss: 0.943629  [   96/  118]
train() client id: f_00009-8-0 loss: 0.932601  [   32/  118]
train() client id: f_00009-8-1 loss: 0.973620  [   64/  118]
train() client id: f_00009-8-2 loss: 1.002251  [   96/  118]
train() client id: f_00009-9-0 loss: 0.923822  [   32/  118]
train() client id: f_00009-9-1 loss: 0.980105  [   64/  118]
train() client id: f_00009-9-2 loss: 0.960648  [   96/  118]
train() client id: f_00009-10-0 loss: 0.976143  [   32/  118]
train() client id: f_00009-10-1 loss: 0.931801  [   64/  118]
train() client id: f_00009-10-2 loss: 0.986826  [   96/  118]
train() client id: f_00009-11-0 loss: 0.881602  [   32/  118]
train() client id: f_00009-11-1 loss: 0.975694  [   64/  118]
train() client id: f_00009-11-2 loss: 1.025283  [   96/  118]
train() client id: f_00009-12-0 loss: 0.971863  [   32/  118]
train() client id: f_00009-12-1 loss: 1.012720  [   64/  118]
train() client id: f_00009-12-2 loss: 0.920517  [   96/  118]
At round 4 accuracy: 0.6127320954907162
At round 4 training accuracy: 0.5707578806170356
At round 4 training loss: 0.9098991672940869
gradient difference: 0.393589049577713
train() client id: f_00000-0-0 loss: 1.140565  [   32/  126]
train() client id: f_00000-0-1 loss: 1.132861  [   64/  126]
train() client id: f_00000-0-2 loss: 1.135981  [   96/  126]
train() client id: f_00000-1-0 loss: 1.038715  [   32/  126]
train() client id: f_00000-1-1 loss: 1.066386  [   64/  126]
train() client id: f_00000-1-2 loss: 1.109459  [   96/  126]
train() client id: f_00000-2-0 loss: 1.024779  [   32/  126]
train() client id: f_00000-2-1 loss: 1.058907  [   64/  126]
train() client id: f_00000-2-2 loss: 0.902843  [   96/  126]
train() client id: f_00000-3-0 loss: 0.941117  [   32/  126]
train() client id: f_00000-3-1 loss: 0.876866  [   64/  126]
train() client id: f_00000-3-2 loss: 0.943690  [   96/  126]
train() client id: f_00000-4-0 loss: 0.877255  [   32/  126]
train() client id: f_00000-4-1 loss: 0.955696  [   64/  126]
train() client id: f_00000-4-2 loss: 0.853345  [   96/  126]
train() client id: f_00000-5-0 loss: 0.890946  [   32/  126]
train() client id: f_00000-5-1 loss: 0.959267  [   64/  126]
train() client id: f_00000-5-2 loss: 0.878512  [   96/  126]
train() client id: f_00000-6-0 loss: 0.873588  [   32/  126]
train() client id: f_00000-6-1 loss: 0.910690  [   64/  126]
train() client id: f_00000-6-2 loss: 0.887365  [   96/  126]
train() client id: f_00000-7-0 loss: 0.781814  [   32/  126]
train() client id: f_00000-7-1 loss: 0.980780  [   64/  126]
train() client id: f_00000-7-2 loss: 0.836266  [   96/  126]
train() client id: f_00000-8-0 loss: 0.895267  [   32/  126]
train() client id: f_00000-8-1 loss: 0.802748  [   64/  126]
train() client id: f_00000-8-2 loss: 0.782321  [   96/  126]
train() client id: f_00000-9-0 loss: 0.917081  [   32/  126]
train() client id: f_00000-9-1 loss: 0.832094  [   64/  126]
train() client id: f_00000-9-2 loss: 0.770558  [   96/  126]
train() client id: f_00000-10-0 loss: 0.919371  [   32/  126]
train() client id: f_00000-10-1 loss: 0.793605  [   64/  126]
train() client id: f_00000-10-2 loss: 0.835744  [   96/  126]
train() client id: f_00000-11-0 loss: 0.838627  [   32/  126]
train() client id: f_00000-11-1 loss: 0.794966  [   64/  126]
train() client id: f_00000-11-2 loss: 0.857849  [   96/  126]
train() client id: f_00000-12-0 loss: 0.671235  [   32/  126]
train() client id: f_00000-12-1 loss: 0.973031  [   64/  126]
train() client id: f_00000-12-2 loss: 0.926871  [   96/  126]
train() client id: f_00001-0-0 loss: 0.696250  [   32/  265]
train() client id: f_00001-0-1 loss: 0.727601  [   64/  265]
train() client id: f_00001-0-2 loss: 0.745763  [   96/  265]
train() client id: f_00001-0-3 loss: 0.690980  [  128/  265]
train() client id: f_00001-0-4 loss: 0.670646  [  160/  265]
train() client id: f_00001-0-5 loss: 0.677364  [  192/  265]
train() client id: f_00001-0-6 loss: 0.693247  [  224/  265]
train() client id: f_00001-0-7 loss: 0.686106  [  256/  265]
train() client id: f_00001-1-0 loss: 0.649226  [   32/  265]
train() client id: f_00001-1-1 loss: 0.652531  [   64/  265]
train() client id: f_00001-1-2 loss: 0.696363  [   96/  265]
train() client id: f_00001-1-3 loss: 0.642494  [  128/  265]
train() client id: f_00001-1-4 loss: 0.675192  [  160/  265]
train() client id: f_00001-1-5 loss: 0.676510  [  192/  265]
train() client id: f_00001-1-6 loss: 0.587691  [  224/  265]
train() client id: f_00001-1-7 loss: 0.685185  [  256/  265]
train() client id: f_00001-2-0 loss: 0.662679  [   32/  265]
train() client id: f_00001-2-1 loss: 0.693276  [   64/  265]
train() client id: f_00001-2-2 loss: 0.619413  [   96/  265]
train() client id: f_00001-2-3 loss: 0.622637  [  128/  265]
train() client id: f_00001-2-4 loss: 0.602972  [  160/  265]
train() client id: f_00001-2-5 loss: 0.615880  [  192/  265]
train() client id: f_00001-2-6 loss: 0.608937  [  224/  265]
train() client id: f_00001-2-7 loss: 0.556863  [  256/  265]
train() client id: f_00001-3-0 loss: 0.657530  [   32/  265]
train() client id: f_00001-3-1 loss: 0.680061  [   64/  265]
train() client id: f_00001-3-2 loss: 0.541181  [   96/  265]
train() client id: f_00001-3-3 loss: 0.616869  [  128/  265]
train() client id: f_00001-3-4 loss: 0.655051  [  160/  265]
train() client id: f_00001-3-5 loss: 0.544742  [  192/  265]
train() client id: f_00001-3-6 loss: 0.578811  [  224/  265]
train() client id: f_00001-3-7 loss: 0.539644  [  256/  265]
train() client id: f_00001-4-0 loss: 0.598082  [   32/  265]
train() client id: f_00001-4-1 loss: 0.635359  [   64/  265]
train() client id: f_00001-4-2 loss: 0.649656  [   96/  265]
train() client id: f_00001-4-3 loss: 0.557876  [  128/  265]
train() client id: f_00001-4-4 loss: 0.568332  [  160/  265]
train() client id: f_00001-4-5 loss: 0.574796  [  192/  265]
train() client id: f_00001-4-6 loss: 0.544265  [  224/  265]
train() client id: f_00001-4-7 loss: 0.537343  [  256/  265]
train() client id: f_00001-5-0 loss: 0.584209  [   32/  265]
train() client id: f_00001-5-1 loss: 0.542087  [   64/  265]
train() client id: f_00001-5-2 loss: 0.580112  [   96/  265]
train() client id: f_00001-5-3 loss: 0.573169  [  128/  265]
train() client id: f_00001-5-4 loss: 0.561551  [  160/  265]
train() client id: f_00001-5-5 loss: 0.598198  [  192/  265]
train() client id: f_00001-5-6 loss: 0.573691  [  224/  265]
train() client id: f_00001-5-7 loss: 0.587326  [  256/  265]
train() client id: f_00001-6-0 loss: 0.615659  [   32/  265]
train() client id: f_00001-6-1 loss: 0.534385  [   64/  265]
train() client id: f_00001-6-2 loss: 0.569153  [   96/  265]
train() client id: f_00001-6-3 loss: 0.542322  [  128/  265]
train() client id: f_00001-6-4 loss: 0.480816  [  160/  265]
train() client id: f_00001-6-5 loss: 0.536653  [  192/  265]
train() client id: f_00001-6-6 loss: 0.662049  [  224/  265]
train() client id: f_00001-6-7 loss: 0.589721  [  256/  265]
train() client id: f_00001-7-0 loss: 0.539925  [   32/  265]
train() client id: f_00001-7-1 loss: 0.541710  [   64/  265]
train() client id: f_00001-7-2 loss: 0.606446  [   96/  265]
train() client id: f_00001-7-3 loss: 0.527839  [  128/  265]
train() client id: f_00001-7-4 loss: 0.516952  [  160/  265]
train() client id: f_00001-7-5 loss: 0.626655  [  192/  265]
train() client id: f_00001-7-6 loss: 0.496814  [  224/  265]
train() client id: f_00001-7-7 loss: 0.597321  [  256/  265]
train() client id: f_00001-8-0 loss: 0.558385  [   32/  265]
train() client id: f_00001-8-1 loss: 0.587477  [   64/  265]
train() client id: f_00001-8-2 loss: 0.497088  [   96/  265]
train() client id: f_00001-8-3 loss: 0.547877  [  128/  265]
train() client id: f_00001-8-4 loss: 0.534229  [  160/  265]
train() client id: f_00001-8-5 loss: 0.523998  [  192/  265]
train() client id: f_00001-8-6 loss: 0.610513  [  224/  265]
train() client id: f_00001-8-7 loss: 0.536964  [  256/  265]
train() client id: f_00001-9-0 loss: 0.531278  [   32/  265]
train() client id: f_00001-9-1 loss: 0.570192  [   64/  265]
train() client id: f_00001-9-2 loss: 0.489652  [   96/  265]
train() client id: f_00001-9-3 loss: 0.512503  [  128/  265]
train() client id: f_00001-9-4 loss: 0.589154  [  160/  265]
train() client id: f_00001-9-5 loss: 0.469247  [  192/  265]
train() client id: f_00001-9-6 loss: 0.644590  [  224/  265]
train() client id: f_00001-9-7 loss: 0.515111  [  256/  265]
train() client id: f_00001-10-0 loss: 0.526439  [   32/  265]
train() client id: f_00001-10-1 loss: 0.536569  [   64/  265]
train() client id: f_00001-10-2 loss: 0.574511  [   96/  265]
train() client id: f_00001-10-3 loss: 0.556760  [  128/  265]
train() client id: f_00001-10-4 loss: 0.522968  [  160/  265]
train() client id: f_00001-10-5 loss: 0.553825  [  192/  265]
train() client id: f_00001-10-6 loss: 0.494717  [  224/  265]
train() client id: f_00001-10-7 loss: 0.619948  [  256/  265]
train() client id: f_00001-11-0 loss: 0.509550  [   32/  265]
train() client id: f_00001-11-1 loss: 0.557863  [   64/  265]
train() client id: f_00001-11-2 loss: 0.498797  [   96/  265]
train() client id: f_00001-11-3 loss: 0.527803  [  128/  265]
train() client id: f_00001-11-4 loss: 0.565341  [  160/  265]
train() client id: f_00001-11-5 loss: 0.510686  [  192/  265]
train() client id: f_00001-11-6 loss: 0.616794  [  224/  265]
train() client id: f_00001-11-7 loss: 0.459376  [  256/  265]
train() client id: f_00001-12-0 loss: 0.516508  [   32/  265]
train() client id: f_00001-12-1 loss: 0.487414  [   64/  265]
train() client id: f_00001-12-2 loss: 0.541270  [   96/  265]
train() client id: f_00001-12-3 loss: 0.690859  [  128/  265]
train() client id: f_00001-12-4 loss: 0.505332  [  160/  265]
train() client id: f_00001-12-5 loss: 0.488607  [  192/  265]
train() client id: f_00001-12-6 loss: 0.549000  [  224/  265]
train() client id: f_00001-12-7 loss: 0.523698  [  256/  265]
train() client id: f_00002-0-0 loss: 1.242082  [   32/  124]
train() client id: f_00002-0-1 loss: 1.340238  [   64/  124]
train() client id: f_00002-0-2 loss: 1.213885  [   96/  124]
train() client id: f_00002-1-0 loss: 1.289019  [   32/  124]
train() client id: f_00002-1-1 loss: 1.204917  [   64/  124]
train() client id: f_00002-1-2 loss: 1.224530  [   96/  124]
train() client id: f_00002-2-0 loss: 1.233457  [   32/  124]
train() client id: f_00002-2-1 loss: 1.153295  [   64/  124]
train() client id: f_00002-2-2 loss: 1.171409  [   96/  124]
train() client id: f_00002-3-0 loss: 1.201808  [   32/  124]
train() client id: f_00002-3-1 loss: 1.156646  [   64/  124]
train() client id: f_00002-3-2 loss: 1.119516  [   96/  124]
train() client id: f_00002-4-0 loss: 1.101925  [   32/  124]
train() client id: f_00002-4-1 loss: 1.098034  [   64/  124]
train() client id: f_00002-4-2 loss: 1.140251  [   96/  124]
train() client id: f_00002-5-0 loss: 1.139920  [   32/  124]
train() client id: f_00002-5-1 loss: 1.120641  [   64/  124]
train() client id: f_00002-5-2 loss: 1.019533  [   96/  124]
train() client id: f_00002-6-0 loss: 1.129202  [   32/  124]
train() client id: f_00002-6-1 loss: 0.997192  [   64/  124]
train() client id: f_00002-6-2 loss: 1.094006  [   96/  124]
train() client id: f_00002-7-0 loss: 0.982148  [   32/  124]
train() client id: f_00002-7-1 loss: 1.073326  [   64/  124]
train() client id: f_00002-7-2 loss: 1.026656  [   96/  124]
train() client id: f_00002-8-0 loss: 1.161870  [   32/  124]
train() client id: f_00002-8-1 loss: 0.951487  [   64/  124]
train() client id: f_00002-8-2 loss: 0.955284  [   96/  124]
train() client id: f_00002-9-0 loss: 1.000217  [   32/  124]
train() client id: f_00002-9-1 loss: 1.014092  [   64/  124]
train() client id: f_00002-9-2 loss: 0.948739  [   96/  124]
train() client id: f_00002-10-0 loss: 0.969197  [   32/  124]
train() client id: f_00002-10-1 loss: 1.079479  [   64/  124]
train() client id: f_00002-10-2 loss: 0.984448  [   96/  124]
train() client id: f_00002-11-0 loss: 0.974898  [   32/  124]
train() client id: f_00002-11-1 loss: 1.039331  [   64/  124]
train() client id: f_00002-11-2 loss: 0.989333  [   96/  124]
train() client id: f_00002-12-0 loss: 1.102496  [   32/  124]
train() client id: f_00002-12-1 loss: 0.880324  [   64/  124]
train() client id: f_00002-12-2 loss: 1.011700  [   96/  124]
train() client id: f_00003-0-0 loss: 0.901917  [   32/   43]
train() client id: f_00003-1-0 loss: 0.940803  [   32/   43]
train() client id: f_00003-2-0 loss: 0.913204  [   32/   43]
train() client id: f_00003-3-0 loss: 0.941784  [   32/   43]
train() client id: f_00003-4-0 loss: 0.943682  [   32/   43]
train() client id: f_00003-5-0 loss: 0.977559  [   32/   43]
train() client id: f_00003-6-0 loss: 0.933690  [   32/   43]
train() client id: f_00003-7-0 loss: 0.904356  [   32/   43]
train() client id: f_00003-8-0 loss: 0.846577  [   32/   43]
train() client id: f_00003-9-0 loss: 0.984855  [   32/   43]
train() client id: f_00003-10-0 loss: 0.923914  [   32/   43]
train() client id: f_00003-11-0 loss: 0.893258  [   32/   43]
train() client id: f_00003-12-0 loss: 1.000612  [   32/   43]
train() client id: f_00004-0-0 loss: 1.068291  [   32/  306]
train() client id: f_00004-0-1 loss: 0.949413  [   64/  306]
train() client id: f_00004-0-2 loss: 1.059243  [   96/  306]
train() client id: f_00004-0-3 loss: 0.913583  [  128/  306]
train() client id: f_00004-0-4 loss: 1.024576  [  160/  306]
train() client id: f_00004-0-5 loss: 0.907073  [  192/  306]
train() client id: f_00004-0-6 loss: 0.918636  [  224/  306]
train() client id: f_00004-0-7 loss: 0.871347  [  256/  306]
train() client id: f_00004-0-8 loss: 1.038469  [  288/  306]
train() client id: f_00004-1-0 loss: 1.078665  [   32/  306]
train() client id: f_00004-1-1 loss: 0.937317  [   64/  306]
train() client id: f_00004-1-2 loss: 1.061401  [   96/  306]
train() client id: f_00004-1-3 loss: 0.864513  [  128/  306]
train() client id: f_00004-1-4 loss: 0.932333  [  160/  306]
train() client id: f_00004-1-5 loss: 1.058454  [  192/  306]
train() client id: f_00004-1-6 loss: 0.906519  [  224/  306]
train() client id: f_00004-1-7 loss: 0.893092  [  256/  306]
train() client id: f_00004-1-8 loss: 0.996387  [  288/  306]
train() client id: f_00004-2-0 loss: 0.930181  [   32/  306]
train() client id: f_00004-2-1 loss: 1.001680  [   64/  306]
train() client id: f_00004-2-2 loss: 0.982249  [   96/  306]
train() client id: f_00004-2-3 loss: 0.974000  [  128/  306]
train() client id: f_00004-2-4 loss: 0.955607  [  160/  306]
train() client id: f_00004-2-5 loss: 0.887168  [  192/  306]
train() client id: f_00004-2-6 loss: 0.983407  [  224/  306]
train() client id: f_00004-2-7 loss: 1.011205  [  256/  306]
train() client id: f_00004-2-8 loss: 0.920069  [  288/  306]
train() client id: f_00004-3-0 loss: 0.960495  [   32/  306]
train() client id: f_00004-3-1 loss: 1.030493  [   64/  306]
train() client id: f_00004-3-2 loss: 0.996975  [   96/  306]
train() client id: f_00004-3-3 loss: 1.024580  [  128/  306]
train() client id: f_00004-3-4 loss: 1.005213  [  160/  306]
train() client id: f_00004-3-5 loss: 0.800269  [  192/  306]
train() client id: f_00004-3-6 loss: 0.923593  [  224/  306]
train() client id: f_00004-3-7 loss: 0.990190  [  256/  306]
train() client id: f_00004-3-8 loss: 0.881008  [  288/  306]
train() client id: f_00004-4-0 loss: 0.876657  [   32/  306]
train() client id: f_00004-4-1 loss: 0.879455  [   64/  306]
train() client id: f_00004-4-2 loss: 0.826515  [   96/  306]
train() client id: f_00004-4-3 loss: 1.095645  [  128/  306]
train() client id: f_00004-4-4 loss: 0.981141  [  160/  306]
train() client id: f_00004-4-5 loss: 0.955792  [  192/  306]
train() client id: f_00004-4-6 loss: 0.971805  [  224/  306]
train() client id: f_00004-4-7 loss: 0.957507  [  256/  306]
train() client id: f_00004-4-8 loss: 1.007053  [  288/  306]
train() client id: f_00004-5-0 loss: 0.922054  [   32/  306]
train() client id: f_00004-5-1 loss: 0.943663  [   64/  306]
train() client id: f_00004-5-2 loss: 0.934599  [   96/  306]
train() client id: f_00004-5-3 loss: 0.978781  [  128/  306]
train() client id: f_00004-5-4 loss: 1.022497  [  160/  306]
train() client id: f_00004-5-5 loss: 1.002029  [  192/  306]
train() client id: f_00004-5-6 loss: 0.931794  [  224/  306]
train() client id: f_00004-5-7 loss: 0.932950  [  256/  306]
train() client id: f_00004-5-8 loss: 0.959018  [  288/  306]
train() client id: f_00004-6-0 loss: 1.028816  [   32/  306]
train() client id: f_00004-6-1 loss: 0.898025  [   64/  306]
train() client id: f_00004-6-2 loss: 0.941803  [   96/  306]
train() client id: f_00004-6-3 loss: 0.969376  [  128/  306]
train() client id: f_00004-6-4 loss: 0.928854  [  160/  306]
train() client id: f_00004-6-5 loss: 0.966012  [  192/  306]
train() client id: f_00004-6-6 loss: 0.903504  [  224/  306]
train() client id: f_00004-6-7 loss: 0.972347  [  256/  306]
train() client id: f_00004-6-8 loss: 0.978036  [  288/  306]
train() client id: f_00004-7-0 loss: 0.965962  [   32/  306]
train() client id: f_00004-7-1 loss: 1.035518  [   64/  306]
train() client id: f_00004-7-2 loss: 0.961642  [   96/  306]
train() client id: f_00004-7-3 loss: 0.919387  [  128/  306]
train() client id: f_00004-7-4 loss: 0.908992  [  160/  306]
train() client id: f_00004-7-5 loss: 0.977600  [  192/  306]
train() client id: f_00004-7-6 loss: 0.874992  [  224/  306]
train() client id: f_00004-7-7 loss: 0.969559  [  256/  306]
train() client id: f_00004-7-8 loss: 0.946851  [  288/  306]
train() client id: f_00004-8-0 loss: 1.028160  [   32/  306]
train() client id: f_00004-8-1 loss: 0.893022  [   64/  306]
train() client id: f_00004-8-2 loss: 0.993414  [   96/  306]
train() client id: f_00004-8-3 loss: 1.035088  [  128/  306]
train() client id: f_00004-8-4 loss: 0.961932  [  160/  306]
train() client id: f_00004-8-5 loss: 0.890560  [  192/  306]
train() client id: f_00004-8-6 loss: 0.851755  [  224/  306]
train() client id: f_00004-8-7 loss: 0.895344  [  256/  306]
train() client id: f_00004-8-8 loss: 0.942762  [  288/  306]
train() client id: f_00004-9-0 loss: 0.981153  [   32/  306]
train() client id: f_00004-9-1 loss: 0.960081  [   64/  306]
train() client id: f_00004-9-2 loss: 0.915859  [   96/  306]
train() client id: f_00004-9-3 loss: 0.909751  [  128/  306]
train() client id: f_00004-9-4 loss: 0.904718  [  160/  306]
train() client id: f_00004-9-5 loss: 0.929998  [  192/  306]
train() client id: f_00004-9-6 loss: 1.021198  [  224/  306]
train() client id: f_00004-9-7 loss: 0.985956  [  256/  306]
train() client id: f_00004-9-8 loss: 0.899086  [  288/  306]
train() client id: f_00004-10-0 loss: 0.995525  [   32/  306]
train() client id: f_00004-10-1 loss: 0.984329  [   64/  306]
train() client id: f_00004-10-2 loss: 1.036902  [   96/  306]
train() client id: f_00004-10-3 loss: 0.903831  [  128/  306]
train() client id: f_00004-10-4 loss: 0.954876  [  160/  306]
train() client id: f_00004-10-5 loss: 0.938585  [  192/  306]
train() client id: f_00004-10-6 loss: 0.935239  [  224/  306]
train() client id: f_00004-10-7 loss: 0.883582  [  256/  306]
train() client id: f_00004-10-8 loss: 0.839454  [  288/  306]
train() client id: f_00004-11-0 loss: 1.088814  [   32/  306]
train() client id: f_00004-11-1 loss: 0.993830  [   64/  306]
train() client id: f_00004-11-2 loss: 0.933955  [   96/  306]
train() client id: f_00004-11-3 loss: 0.943313  [  128/  306]
train() client id: f_00004-11-4 loss: 0.865810  [  160/  306]
train() client id: f_00004-11-5 loss: 0.989406  [  192/  306]
train() client id: f_00004-11-6 loss: 0.851548  [  224/  306]
train() client id: f_00004-11-7 loss: 0.910112  [  256/  306]
train() client id: f_00004-11-8 loss: 0.999078  [  288/  306]
train() client id: f_00004-12-0 loss: 1.066121  [   32/  306]
train() client id: f_00004-12-1 loss: 0.965036  [   64/  306]
train() client id: f_00004-12-2 loss: 0.864778  [   96/  306]
train() client id: f_00004-12-3 loss: 0.869323  [  128/  306]
train() client id: f_00004-12-4 loss: 0.947365  [  160/  306]
train() client id: f_00004-12-5 loss: 0.892719  [  192/  306]
train() client id: f_00004-12-6 loss: 1.014179  [  224/  306]
train() client id: f_00004-12-7 loss: 1.022480  [  256/  306]
train() client id: f_00004-12-8 loss: 0.973391  [  288/  306]
train() client id: f_00005-0-0 loss: 1.002224  [   32/  146]
train() client id: f_00005-0-1 loss: 0.863291  [   64/  146]
train() client id: f_00005-0-2 loss: 0.888470  [   96/  146]
train() client id: f_00005-0-3 loss: 0.949910  [  128/  146]
train() client id: f_00005-1-0 loss: 0.872401  [   32/  146]
train() client id: f_00005-1-1 loss: 0.907517  [   64/  146]
train() client id: f_00005-1-2 loss: 0.850357  [   96/  146]
train() client id: f_00005-1-3 loss: 0.943944  [  128/  146]
train() client id: f_00005-2-0 loss: 0.958972  [   32/  146]
train() client id: f_00005-2-1 loss: 0.755794  [   64/  146]
train() client id: f_00005-2-2 loss: 0.887477  [   96/  146]
train() client id: f_00005-2-3 loss: 0.930174  [  128/  146]
train() client id: f_00005-3-0 loss: 0.846461  [   32/  146]
train() client id: f_00005-3-1 loss: 0.823905  [   64/  146]
train() client id: f_00005-3-2 loss: 0.855145  [   96/  146]
train() client id: f_00005-3-3 loss: 0.885390  [  128/  146]
train() client id: f_00005-4-0 loss: 0.867302  [   32/  146]
train() client id: f_00005-4-1 loss: 0.890947  [   64/  146]
train() client id: f_00005-4-2 loss: 0.755800  [   96/  146]
train() client id: f_00005-4-3 loss: 0.851212  [  128/  146]
train() client id: f_00005-5-0 loss: 0.834762  [   32/  146]
train() client id: f_00005-5-1 loss: 0.852547  [   64/  146]
train() client id: f_00005-5-2 loss: 0.855554  [   96/  146]
train() client id: f_00005-5-3 loss: 0.854685  [  128/  146]
train() client id: f_00005-6-0 loss: 0.926082  [   32/  146]
train() client id: f_00005-6-1 loss: 0.858740  [   64/  146]
train() client id: f_00005-6-2 loss: 0.729072  [   96/  146]
train() client id: f_00005-6-3 loss: 0.785797  [  128/  146]
train() client id: f_00005-7-0 loss: 0.830536  [   32/  146]
train() client id: f_00005-7-1 loss: 0.838252  [   64/  146]
train() client id: f_00005-7-2 loss: 0.876801  [   96/  146]
train() client id: f_00005-7-3 loss: 0.787353  [  128/  146]
train() client id: f_00005-8-0 loss: 0.811644  [   32/  146]
train() client id: f_00005-8-1 loss: 0.731336  [   64/  146]
train() client id: f_00005-8-2 loss: 0.826210  [   96/  146]
train() client id: f_00005-8-3 loss: 0.940927  [  128/  146]
train() client id: f_00005-9-0 loss: 0.689362  [   32/  146]
train() client id: f_00005-9-1 loss: 0.759924  [   64/  146]
train() client id: f_00005-9-2 loss: 1.024969  [   96/  146]
train() client id: f_00005-9-3 loss: 0.863732  [  128/  146]
train() client id: f_00005-10-0 loss: 0.802253  [   32/  146]
train() client id: f_00005-10-1 loss: 0.819696  [   64/  146]
train() client id: f_00005-10-2 loss: 0.879148  [   96/  146]
train() client id: f_00005-10-3 loss: 0.707922  [  128/  146]
train() client id: f_00005-11-0 loss: 0.772526  [   32/  146]
train() client id: f_00005-11-1 loss: 0.755874  [   64/  146]
train() client id: f_00005-11-2 loss: 0.689669  [   96/  146]
train() client id: f_00005-11-3 loss: 1.022537  [  128/  146]
train() client id: f_00005-12-0 loss: 0.723790  [   32/  146]
train() client id: f_00005-12-1 loss: 0.974261  [   64/  146]
train() client id: f_00005-12-2 loss: 0.680947  [   96/  146]
train() client id: f_00005-12-3 loss: 0.937822  [  128/  146]
train() client id: f_00006-0-0 loss: 0.907378  [   32/   54]
train() client id: f_00006-1-0 loss: 0.890084  [   32/   54]
train() client id: f_00006-2-0 loss: 0.917687  [   32/   54]
train() client id: f_00006-3-0 loss: 0.917395  [   32/   54]
train() client id: f_00006-4-0 loss: 0.899049  [   32/   54]
train() client id: f_00006-5-0 loss: 0.924061  [   32/   54]
train() client id: f_00006-6-0 loss: 0.878237  [   32/   54]
train() client id: f_00006-7-0 loss: 0.895085  [   32/   54]
train() client id: f_00006-8-0 loss: 0.931171  [   32/   54]
train() client id: f_00006-9-0 loss: 0.906265  [   32/   54]
train() client id: f_00006-10-0 loss: 0.873154  [   32/   54]
train() client id: f_00006-11-0 loss: 0.902205  [   32/   54]
train() client id: f_00006-12-0 loss: 0.917072  [   32/   54]
train() client id: f_00007-0-0 loss: 0.709440  [   32/  179]
train() client id: f_00007-0-1 loss: 0.736401  [   64/  179]
train() client id: f_00007-0-2 loss: 0.724292  [   96/  179]
train() client id: f_00007-0-3 loss: 0.618961  [  128/  179]
train() client id: f_00007-0-4 loss: 0.673519  [  160/  179]
train() client id: f_00007-1-0 loss: 0.639076  [   32/  179]
train() client id: f_00007-1-1 loss: 0.808057  [   64/  179]
train() client id: f_00007-1-2 loss: 0.619409  [   96/  179]
train() client id: f_00007-1-3 loss: 0.678819  [  128/  179]
train() client id: f_00007-1-4 loss: 0.641269  [  160/  179]
train() client id: f_00007-2-0 loss: 0.655041  [   32/  179]
train() client id: f_00007-2-1 loss: 0.659021  [   64/  179]
train() client id: f_00007-2-2 loss: 0.595609  [   96/  179]
train() client id: f_00007-2-3 loss: 0.609235  [  128/  179]
train() client id: f_00007-2-4 loss: 0.554176  [  160/  179]
train() client id: f_00007-3-0 loss: 0.683383  [   32/  179]
train() client id: f_00007-3-1 loss: 0.650058  [   64/  179]
train() client id: f_00007-3-2 loss: 0.602139  [   96/  179]
train() client id: f_00007-3-3 loss: 0.580675  [  128/  179]
train() client id: f_00007-3-4 loss: 0.596946  [  160/  179]
train() client id: f_00007-4-0 loss: 0.637123  [   32/  179]
train() client id: f_00007-4-1 loss: 0.748845  [   64/  179]
train() client id: f_00007-4-2 loss: 0.510741  [   96/  179]
train() client id: f_00007-4-3 loss: 0.590503  [  128/  179]
train() client id: f_00007-4-4 loss: 0.537936  [  160/  179]
train() client id: f_00007-5-0 loss: 0.781700  [   32/  179]
train() client id: f_00007-5-1 loss: 0.508848  [   64/  179]
train() client id: f_00007-5-2 loss: 0.542940  [   96/  179]
train() client id: f_00007-5-3 loss: 0.603410  [  128/  179]
train() client id: f_00007-5-4 loss: 0.505571  [  160/  179]
train() client id: f_00007-6-0 loss: 0.516069  [   32/  179]
train() client id: f_00007-6-1 loss: 0.493903  [   64/  179]
train() client id: f_00007-6-2 loss: 0.538145  [   96/  179]
train() client id: f_00007-6-3 loss: 0.522911  [  128/  179]
train() client id: f_00007-6-4 loss: 0.715348  [  160/  179]
train() client id: f_00007-7-0 loss: 0.533982  [   32/  179]
train() client id: f_00007-7-1 loss: 0.488064  [   64/  179]
train() client id: f_00007-7-2 loss: 0.536581  [   96/  179]
train() client id: f_00007-7-3 loss: 0.775181  [  128/  179]
train() client id: f_00007-7-4 loss: 0.459661  [  160/  179]
train() client id: f_00007-8-0 loss: 0.528588  [   32/  179]
train() client id: f_00007-8-1 loss: 0.476373  [   64/  179]
train() client id: f_00007-8-2 loss: 0.633208  [   96/  179]
train() client id: f_00007-8-3 loss: 0.672268  [  128/  179]
train() client id: f_00007-8-4 loss: 0.521122  [  160/  179]
train() client id: f_00007-9-0 loss: 0.753090  [   32/  179]
train() client id: f_00007-9-1 loss: 0.543445  [   64/  179]
train() client id: f_00007-9-2 loss: 0.466870  [   96/  179]
train() client id: f_00007-9-3 loss: 0.468238  [  128/  179]
train() client id: f_00007-9-4 loss: 0.565910  [  160/  179]
train() client id: f_00007-10-0 loss: 0.523356  [   32/  179]
train() client id: f_00007-10-1 loss: 0.668147  [   64/  179]
train() client id: f_00007-10-2 loss: 0.514194  [   96/  179]
train() client id: f_00007-10-3 loss: 0.561648  [  128/  179]
train() client id: f_00007-10-4 loss: 0.596679  [  160/  179]
train() client id: f_00007-11-0 loss: 0.458361  [   32/  179]
train() client id: f_00007-11-1 loss: 0.551426  [   64/  179]
train() client id: f_00007-11-2 loss: 0.510602  [   96/  179]
train() client id: f_00007-11-3 loss: 0.510303  [  128/  179]
train() client id: f_00007-11-4 loss: 0.585029  [  160/  179]
train() client id: f_00007-12-0 loss: 0.540921  [   32/  179]
train() client id: f_00007-12-1 loss: 0.448052  [   64/  179]
train() client id: f_00007-12-2 loss: 0.627981  [   96/  179]
train() client id: f_00007-12-3 loss: 0.632545  [  128/  179]
train() client id: f_00007-12-4 loss: 0.594084  [  160/  179]
train() client id: f_00008-0-0 loss: 0.908855  [   32/  130]
train() client id: f_00008-0-1 loss: 1.000936  [   64/  130]
train() client id: f_00008-0-2 loss: 0.901024  [   96/  130]
train() client id: f_00008-0-3 loss: 0.932269  [  128/  130]
train() client id: f_00008-1-0 loss: 0.979149  [   32/  130]
train() client id: f_00008-1-1 loss: 0.890351  [   64/  130]
train() client id: f_00008-1-2 loss: 1.008566  [   96/  130]
train() client id: f_00008-1-3 loss: 0.848579  [  128/  130]
train() client id: f_00008-2-0 loss: 0.880219  [   32/  130]
train() client id: f_00008-2-1 loss: 0.895876  [   64/  130]
train() client id: f_00008-2-2 loss: 1.001219  [   96/  130]
train() client id: f_00008-2-3 loss: 0.905726  [  128/  130]
train() client id: f_00008-3-0 loss: 0.907707  [   32/  130]
train() client id: f_00008-3-1 loss: 0.826817  [   64/  130]
train() client id: f_00008-3-2 loss: 0.931851  [   96/  130]
train() client id: f_00008-3-3 loss: 1.016620  [  128/  130]
train() client id: f_00008-4-0 loss: 0.889395  [   32/  130]
train() client id: f_00008-4-1 loss: 0.992965  [   64/  130]
train() client id: f_00008-4-2 loss: 0.965813  [   96/  130]
train() client id: f_00008-4-3 loss: 0.835552  [  128/  130]
train() client id: f_00008-5-0 loss: 0.921194  [   32/  130]
train() client id: f_00008-5-1 loss: 0.942402  [   64/  130]
train() client id: f_00008-5-2 loss: 0.836573  [   96/  130]
train() client id: f_00008-5-3 loss: 0.952894  [  128/  130]
train() client id: f_00008-6-0 loss: 0.934178  [   32/  130]
train() client id: f_00008-6-1 loss: 0.892308  [   64/  130]
train() client id: f_00008-6-2 loss: 0.882731  [   96/  130]
train() client id: f_00008-6-3 loss: 0.952209  [  128/  130]
train() client id: f_00008-7-0 loss: 0.731337  [   32/  130]
train() client id: f_00008-7-1 loss: 0.926375  [   64/  130]
train() client id: f_00008-7-2 loss: 0.983063  [   96/  130]
train() client id: f_00008-7-3 loss: 1.003535  [  128/  130]
train() client id: f_00008-8-0 loss: 0.929235  [   32/  130]
train() client id: f_00008-8-1 loss: 0.986618  [   64/  130]
train() client id: f_00008-8-2 loss: 0.847415  [   96/  130]
train() client id: f_00008-8-3 loss: 0.843721  [  128/  130]
train() client id: f_00008-9-0 loss: 0.903916  [   32/  130]
train() client id: f_00008-9-1 loss: 0.913615  [   64/  130]
train() client id: f_00008-9-2 loss: 0.867967  [   96/  130]
train() client id: f_00008-9-3 loss: 0.976068  [  128/  130]
train() client id: f_00008-10-0 loss: 0.886490  [   32/  130]
train() client id: f_00008-10-1 loss: 0.970326  [   64/  130]
train() client id: f_00008-10-2 loss: 0.935684  [   96/  130]
train() client id: f_00008-10-3 loss: 0.824561  [  128/  130]
train() client id: f_00008-11-0 loss: 0.900244  [   32/  130]
train() client id: f_00008-11-1 loss: 0.983266  [   64/  130]
train() client id: f_00008-11-2 loss: 0.810104  [   96/  130]
train() client id: f_00008-11-3 loss: 0.958856  [  128/  130]
train() client id: f_00008-12-0 loss: 0.966480  [   32/  130]
train() client id: f_00008-12-1 loss: 0.939850  [   64/  130]
train() client id: f_00008-12-2 loss: 0.928595  [   96/  130]
train() client id: f_00008-12-3 loss: 0.798537  [  128/  130]
train() client id: f_00009-0-0 loss: 1.230944  [   32/  118]
train() client id: f_00009-0-1 loss: 1.131212  [   64/  118]
train() client id: f_00009-0-2 loss: 1.172483  [   96/  118]
train() client id: f_00009-1-0 loss: 1.168634  [   32/  118]
train() client id: f_00009-1-1 loss: 1.181575  [   64/  118]
train() client id: f_00009-1-2 loss: 1.127610  [   96/  118]
train() client id: f_00009-2-0 loss: 1.129240  [   32/  118]
train() client id: f_00009-2-1 loss: 1.137625  [   64/  118]
train() client id: f_00009-2-2 loss: 1.068448  [   96/  118]
train() client id: f_00009-3-0 loss: 1.112988  [   32/  118]
train() client id: f_00009-3-1 loss: 1.074041  [   64/  118]
train() client id: f_00009-3-2 loss: 1.079467  [   96/  118]
train() client id: f_00009-4-0 loss: 1.070175  [   32/  118]
train() client id: f_00009-4-1 loss: 1.089296  [   64/  118]
train() client id: f_00009-4-2 loss: 1.041213  [   96/  118]
train() client id: f_00009-5-0 loss: 1.074574  [   32/  118]
train() client id: f_00009-5-1 loss: 1.048249  [   64/  118]
train() client id: f_00009-5-2 loss: 1.030203  [   96/  118]
train() client id: f_00009-6-0 loss: 1.034979  [   32/  118]
train() client id: f_00009-6-1 loss: 1.046085  [   64/  118]
train() client id: f_00009-6-2 loss: 1.011678  [   96/  118]
train() client id: f_00009-7-0 loss: 1.021287  [   32/  118]
train() client id: f_00009-7-1 loss: 1.022740  [   64/  118]
train() client id: f_00009-7-2 loss: 1.038504  [   96/  118]
train() client id: f_00009-8-0 loss: 1.039107  [   32/  118]
train() client id: f_00009-8-1 loss: 1.024089  [   64/  118]
train() client id: f_00009-8-2 loss: 0.952354  [   96/  118]
train() client id: f_00009-9-0 loss: 1.085957  [   32/  118]
train() client id: f_00009-9-1 loss: 0.990183  [   64/  118]
train() client id: f_00009-9-2 loss: 0.911213  [   96/  118]
train() client id: f_00009-10-0 loss: 0.998589  [   32/  118]
train() client id: f_00009-10-1 loss: 0.998336  [   64/  118]
train() client id: f_00009-10-2 loss: 1.037288  [   96/  118]
train() client id: f_00009-11-0 loss: 0.949764  [   32/  118]
train() client id: f_00009-11-1 loss: 1.060842  [   64/  118]
train() client id: f_00009-11-2 loss: 0.968080  [   96/  118]
train() client id: f_00009-12-0 loss: 0.985079  [   32/  118]
train() client id: f_00009-12-1 loss: 1.082584  [   64/  118]
train() client id: f_00009-12-2 loss: 0.916917  [   96/  118]
At round 5 accuracy: 0.6259946949602122
At round 5 training accuracy: 0.5754527162977867
At round 5 training loss: 0.8988937272697107
gradient difference: 0.38071101903915405
train() client id: f_00000-0-0 loss: 1.188599  [   32/  126]
train() client id: f_00000-0-1 loss: 1.199052  [   64/  126]
train() client id: f_00000-0-2 loss: 1.124201  [   96/  126]
train() client id: f_00000-1-0 loss: 1.119195  [   32/  126]
train() client id: f_00000-1-1 loss: 1.108073  [   64/  126]
train() client id: f_00000-1-2 loss: 0.987150  [   96/  126]
train() client id: f_00000-2-0 loss: 0.981421  [   32/  126]
train() client id: f_00000-2-1 loss: 0.994643  [   64/  126]
train() client id: f_00000-2-2 loss: 1.018833  [   96/  126]
train() client id: f_00000-3-0 loss: 0.995755  [   32/  126]
train() client id: f_00000-3-1 loss: 0.890024  [   64/  126]
train() client id: f_00000-3-2 loss: 0.909916  [   96/  126]
train() client id: f_00000-4-0 loss: 0.889774  [   32/  126]
train() client id: f_00000-4-1 loss: 0.860694  [   64/  126]
train() client id: f_00000-4-2 loss: 0.947459  [   96/  126]
train() client id: f_00000-5-0 loss: 0.811983  [   32/  126]
train() client id: f_00000-5-1 loss: 0.907047  [   64/  126]
train() client id: f_00000-5-2 loss: 0.923834  [   96/  126]
train() client id: f_00000-6-0 loss: 0.833301  [   32/  126]
train() client id: f_00000-6-1 loss: 0.911751  [   64/  126]
train() client id: f_00000-6-2 loss: 0.808672  [   96/  126]
train() client id: f_00000-7-0 loss: 0.841207  [   32/  126]
train() client id: f_00000-7-1 loss: 0.858731  [   64/  126]
train() client id: f_00000-7-2 loss: 0.825619  [   96/  126]
train() client id: f_00000-8-0 loss: 0.736350  [   32/  126]
train() client id: f_00000-8-1 loss: 0.768210  [   64/  126]
train() client id: f_00000-8-2 loss: 0.875419  [   96/  126]
train() client id: f_00000-9-0 loss: 0.834754  [   32/  126]
train() client id: f_00000-9-1 loss: 0.878460  [   64/  126]
train() client id: f_00000-9-2 loss: 0.730715  [   96/  126]
train() client id: f_00000-10-0 loss: 0.784604  [   32/  126]
train() client id: f_00000-10-1 loss: 0.830021  [   64/  126]
train() client id: f_00000-10-2 loss: 0.864631  [   96/  126]
train() client id: f_00000-11-0 loss: 0.721192  [   32/  126]
train() client id: f_00000-11-1 loss: 0.814713  [   64/  126]
train() client id: f_00000-11-2 loss: 0.795431  [   96/  126]
train() client id: f_00000-12-0 loss: 0.793210  [   32/  126]
train() client id: f_00000-12-1 loss: 0.709067  [   64/  126]
train() client id: f_00000-12-2 loss: 0.812844  [   96/  126]
train() client id: f_00001-0-0 loss: 0.668964  [   32/  265]
train() client id: f_00001-0-1 loss: 0.612493  [   64/  265]
train() client id: f_00001-0-2 loss: 0.667215  [   96/  265]
train() client id: f_00001-0-3 loss: 0.615392  [  128/  265]
train() client id: f_00001-0-4 loss: 0.664420  [  160/  265]
train() client id: f_00001-0-5 loss: 0.590635  [  192/  265]
train() client id: f_00001-0-6 loss: 0.652995  [  224/  265]
train() client id: f_00001-0-7 loss: 0.611506  [  256/  265]
train() client id: f_00001-1-0 loss: 0.562094  [   32/  265]
train() client id: f_00001-1-1 loss: 0.587606  [   64/  265]
train() client id: f_00001-1-2 loss: 0.624319  [   96/  265]
train() client id: f_00001-1-3 loss: 0.575075  [  128/  265]
train() client id: f_00001-1-4 loss: 0.651352  [  160/  265]
train() client id: f_00001-1-5 loss: 0.597923  [  192/  265]
train() client id: f_00001-1-6 loss: 0.555457  [  224/  265]
train() client id: f_00001-1-7 loss: 0.666389  [  256/  265]
train() client id: f_00001-2-0 loss: 0.569946  [   32/  265]
train() client id: f_00001-2-1 loss: 0.548435  [   64/  265]
train() client id: f_00001-2-2 loss: 0.639837  [   96/  265]
train() client id: f_00001-2-3 loss: 0.548827  [  128/  265]
train() client id: f_00001-2-4 loss: 0.563192  [  160/  265]
train() client id: f_00001-2-5 loss: 0.579978  [  192/  265]
train() client id: f_00001-2-6 loss: 0.612322  [  224/  265]
train() client id: f_00001-2-7 loss: 0.590099  [  256/  265]
train() client id: f_00001-3-0 loss: 0.603020  [   32/  265]
train() client id: f_00001-3-1 loss: 0.535465  [   64/  265]
train() client id: f_00001-3-2 loss: 0.547430  [   96/  265]
train() client id: f_00001-3-3 loss: 0.555148  [  128/  265]
train() client id: f_00001-3-4 loss: 0.663230  [  160/  265]
train() client id: f_00001-3-5 loss: 0.489512  [  192/  265]
train() client id: f_00001-3-6 loss: 0.559665  [  224/  265]
train() client id: f_00001-3-7 loss: 0.567435  [  256/  265]
train() client id: f_00001-4-0 loss: 0.558183  [   32/  265]
train() client id: f_00001-4-1 loss: 0.553607  [   64/  265]
train() client id: f_00001-4-2 loss: 0.625294  [   96/  265]
train() client id: f_00001-4-3 loss: 0.502084  [  128/  265]
train() client id: f_00001-4-4 loss: 0.576496  [  160/  265]
train() client id: f_00001-4-5 loss: 0.521366  [  192/  265]
train() client id: f_00001-4-6 loss: 0.484819  [  224/  265]
train() client id: f_00001-4-7 loss: 0.617610  [  256/  265]
train() client id: f_00001-5-0 loss: 0.518493  [   32/  265]
train() client id: f_00001-5-1 loss: 0.495946  [   64/  265]
train() client id: f_00001-5-2 loss: 0.564229  [   96/  265]
train() client id: f_00001-5-3 loss: 0.568822  [  128/  265]
train() client id: f_00001-5-4 loss: 0.551822  [  160/  265]
train() client id: f_00001-5-5 loss: 0.508677  [  192/  265]
train() client id: f_00001-5-6 loss: 0.497890  [  224/  265]
train() client id: f_00001-5-7 loss: 0.661586  [  256/  265]
train() client id: f_00001-6-0 loss: 0.557019  [   32/  265]
train() client id: f_00001-6-1 loss: 0.491474  [   64/  265]
train() client id: f_00001-6-2 loss: 0.548207  [   96/  265]
train() client id: f_00001-6-3 loss: 0.521197  [  128/  265]
train() client id: f_00001-6-4 loss: 0.493182  [  160/  265]
train() client id: f_00001-6-5 loss: 0.464274  [  192/  265]
train() client id: f_00001-6-6 loss: 0.599484  [  224/  265]
train() client id: f_00001-6-7 loss: 0.642811  [  256/  265]
train() client id: f_00001-7-0 loss: 0.594622  [   32/  265]
train() client id: f_00001-7-1 loss: 0.541587  [   64/  265]
train() client id: f_00001-7-2 loss: 0.529253  [   96/  265]
train() client id: f_00001-7-3 loss: 0.462304  [  128/  265]
train() client id: f_00001-7-4 loss: 0.480460  [  160/  265]
train() client id: f_00001-7-5 loss: 0.538275  [  192/  265]
train() client id: f_00001-7-6 loss: 0.604538  [  224/  265]
train() client id: f_00001-7-7 loss: 0.457822  [  256/  265]
train() client id: f_00001-8-0 loss: 0.510113  [   32/  265]
train() client id: f_00001-8-1 loss: 0.563180  [   64/  265]
train() client id: f_00001-8-2 loss: 0.511539  [   96/  265]
train() client id: f_00001-8-3 loss: 0.492030  [  128/  265]
train() client id: f_00001-8-4 loss: 0.574875  [  160/  265]
train() client id: f_00001-8-5 loss: 0.581659  [  192/  265]
train() client id: f_00001-8-6 loss: 0.512282  [  224/  265]
train() client id: f_00001-8-7 loss: 0.498511  [  256/  265]
train() client id: f_00001-9-0 loss: 0.511718  [   32/  265]
train() client id: f_00001-9-1 loss: 0.606886  [   64/  265]
train() client id: f_00001-9-2 loss: 0.525687  [   96/  265]
train() client id: f_00001-9-3 loss: 0.467646  [  128/  265]
train() client id: f_00001-9-4 loss: 0.508409  [  160/  265]
train() client id: f_00001-9-5 loss: 0.518734  [  192/  265]
train() client id: f_00001-9-6 loss: 0.580793  [  224/  265]
train() client id: f_00001-9-7 loss: 0.476296  [  256/  265]
train() client id: f_00001-10-0 loss: 0.521945  [   32/  265]
train() client id: f_00001-10-1 loss: 0.504018  [   64/  265]
train() client id: f_00001-10-2 loss: 0.493199  [   96/  265]
train() client id: f_00001-10-3 loss: 0.489786  [  128/  265]
train() client id: f_00001-10-4 loss: 0.564957  [  160/  265]
train() client id: f_00001-10-5 loss: 0.558196  [  192/  265]
train() client id: f_00001-10-6 loss: 0.579473  [  224/  265]
train() client id: f_00001-10-7 loss: 0.454208  [  256/  265]
train() client id: f_00001-11-0 loss: 0.522666  [   32/  265]
train() client id: f_00001-11-1 loss: 0.481920  [   64/  265]
train() client id: f_00001-11-2 loss: 0.553046  [   96/  265]
train() client id: f_00001-11-3 loss: 0.520982  [  128/  265]
train() client id: f_00001-11-4 loss: 0.472900  [  160/  265]
train() client id: f_00001-11-5 loss: 0.623862  [  192/  265]
train() client id: f_00001-11-6 loss: 0.454295  [  224/  265]
train() client id: f_00001-11-7 loss: 0.570051  [  256/  265]
train() client id: f_00001-12-0 loss: 0.484938  [   32/  265]
train() client id: f_00001-12-1 loss: 0.613888  [   64/  265]
train() client id: f_00001-12-2 loss: 0.450074  [   96/  265]
train() client id: f_00001-12-3 loss: 0.500615  [  128/  265]
train() client id: f_00001-12-4 loss: 0.500999  [  160/  265]
train() client id: f_00001-12-5 loss: 0.488461  [  192/  265]
train() client id: f_00001-12-6 loss: 0.618321  [  224/  265]
train() client id: f_00001-12-7 loss: 0.484764  [  256/  265]
train() client id: f_00002-0-0 loss: 1.377208  [   32/  124]
train() client id: f_00002-0-1 loss: 1.290964  [   64/  124]
train() client id: f_00002-0-2 loss: 1.300965  [   96/  124]
train() client id: f_00002-1-0 loss: 1.322899  [   32/  124]
train() client id: f_00002-1-1 loss: 1.235359  [   64/  124]
train() client id: f_00002-1-2 loss: 1.214656  [   96/  124]
train() client id: f_00002-2-0 loss: 1.231646  [   32/  124]
train() client id: f_00002-2-1 loss: 1.263544  [   64/  124]
train() client id: f_00002-2-2 loss: 1.211392  [   96/  124]
train() client id: f_00002-3-0 loss: 1.256764  [   32/  124]
train() client id: f_00002-3-1 loss: 1.181023  [   64/  124]
train() client id: f_00002-3-2 loss: 1.150864  [   96/  124]
train() client id: f_00002-4-0 loss: 1.120190  [   32/  124]
train() client id: f_00002-4-1 loss: 1.144563  [   64/  124]
train() client id: f_00002-4-2 loss: 1.125861  [   96/  124]
train() client id: f_00002-5-0 loss: 1.079619  [   32/  124]
train() client id: f_00002-5-1 loss: 1.173023  [   64/  124]
train() client id: f_00002-5-2 loss: 1.059914  [   96/  124]
train() client id: f_00002-6-0 loss: 1.062015  [   32/  124]
train() client id: f_00002-6-1 loss: 1.083483  [   64/  124]
train() client id: f_00002-6-2 loss: 1.118692  [   96/  124]
train() client id: f_00002-7-0 loss: 1.061989  [   32/  124]
train() client id: f_00002-7-1 loss: 1.117210  [   64/  124]
train() client id: f_00002-7-2 loss: 1.004197  [   96/  124]
train() client id: f_00002-8-0 loss: 1.024927  [   32/  124]
train() client id: f_00002-8-1 loss: 0.986515  [   64/  124]
train() client id: f_00002-8-2 loss: 1.086799  [   96/  124]
train() client id: f_00002-9-0 loss: 1.114599  [   32/  124]
train() client id: f_00002-9-1 loss: 0.966061  [   64/  124]
train() client id: f_00002-9-2 loss: 1.045283  [   96/  124]
train() client id: f_00002-10-0 loss: 0.918075  [   32/  124]
train() client id: f_00002-10-1 loss: 1.042433  [   64/  124]
train() client id: f_00002-10-2 loss: 1.016793  [   96/  124]
train() client id: f_00002-11-0 loss: 0.977198  [   32/  124]
train() client id: f_00002-11-1 loss: 1.057879  [   64/  124]
train() client id: f_00002-11-2 loss: 1.005254  [   96/  124]
train() client id: f_00002-12-0 loss: 1.012961  [   32/  124]
train() client id: f_00002-12-1 loss: 1.043594  [   64/  124]
train() client id: f_00002-12-2 loss: 0.957027  [   96/  124]
train() client id: f_00003-0-0 loss: 1.042676  [   32/   43]
train() client id: f_00003-1-0 loss: 1.000735  [   32/   43]
train() client id: f_00003-2-0 loss: 0.946224  [   32/   43]
train() client id: f_00003-3-0 loss: 0.915083  [   32/   43]
train() client id: f_00003-4-0 loss: 0.972731  [   32/   43]
train() client id: f_00003-5-0 loss: 1.043784  [   32/   43]
train() client id: f_00003-6-0 loss: 0.902234  [   32/   43]
train() client id: f_00003-7-0 loss: 0.957961  [   32/   43]
train() client id: f_00003-8-0 loss: 0.957073  [   32/   43]
train() client id: f_00003-9-0 loss: 0.957528  [   32/   43]
train() client id: f_00003-10-0 loss: 0.967174  [   32/   43]
train() client id: f_00003-11-0 loss: 0.891428  [   32/   43]
train() client id: f_00003-12-0 loss: 0.957739  [   32/   43]
train() client id: f_00004-0-0 loss: 0.991171  [   32/  306]
train() client id: f_00004-0-1 loss: 0.975139  [   64/  306]
train() client id: f_00004-0-2 loss: 1.023064  [   96/  306]
train() client id: f_00004-0-3 loss: 0.855230  [  128/  306]
train() client id: f_00004-0-4 loss: 0.803528  [  160/  306]
train() client id: f_00004-0-5 loss: 0.816305  [  192/  306]
train() client id: f_00004-0-6 loss: 0.874118  [  224/  306]
train() client id: f_00004-0-7 loss: 0.951182  [  256/  306]
train() client id: f_00004-0-8 loss: 0.869729  [  288/  306]
train() client id: f_00004-1-0 loss: 0.815678  [   32/  306]
train() client id: f_00004-1-1 loss: 0.794080  [   64/  306]
train() client id: f_00004-1-2 loss: 0.888432  [   96/  306]
train() client id: f_00004-1-3 loss: 1.051387  [  128/  306]
train() client id: f_00004-1-4 loss: 0.908466  [  160/  306]
train() client id: f_00004-1-5 loss: 0.931238  [  192/  306]
train() client id: f_00004-1-6 loss: 0.983136  [  224/  306]
train() client id: f_00004-1-7 loss: 0.887587  [  256/  306]
train() client id: f_00004-1-8 loss: 0.851140  [  288/  306]
train() client id: f_00004-2-0 loss: 0.964718  [   32/  306]
train() client id: f_00004-2-1 loss: 0.920366  [   64/  306]
train() client id: f_00004-2-2 loss: 0.910096  [   96/  306]
train() client id: f_00004-2-3 loss: 0.827435  [  128/  306]
train() client id: f_00004-2-4 loss: 0.905885  [  160/  306]
train() client id: f_00004-2-5 loss: 0.857965  [  192/  306]
train() client id: f_00004-2-6 loss: 0.935393  [  224/  306]
train() client id: f_00004-2-7 loss: 0.866193  [  256/  306]
train() client id: f_00004-2-8 loss: 0.948255  [  288/  306]
train() client id: f_00004-3-0 loss: 0.950496  [   32/  306]
train() client id: f_00004-3-1 loss: 0.864698  [   64/  306]
train() client id: f_00004-3-2 loss: 0.840347  [   96/  306]
train() client id: f_00004-3-3 loss: 0.806955  [  128/  306]
train() client id: f_00004-3-4 loss: 0.908396  [  160/  306]
train() client id: f_00004-3-5 loss: 0.923965  [  192/  306]
train() client id: f_00004-3-6 loss: 0.929891  [  224/  306]
train() client id: f_00004-3-7 loss: 0.971646  [  256/  306]
train() client id: f_00004-3-8 loss: 0.889506  [  288/  306]
train() client id: f_00004-4-0 loss: 0.911414  [   32/  306]
train() client id: f_00004-4-1 loss: 0.831408  [   64/  306]
train() client id: f_00004-4-2 loss: 0.943515  [   96/  306]
train() client id: f_00004-4-3 loss: 0.959782  [  128/  306]
train() client id: f_00004-4-4 loss: 0.867206  [  160/  306]
train() client id: f_00004-4-5 loss: 0.962806  [  192/  306]
train() client id: f_00004-4-6 loss: 0.833961  [  224/  306]
train() client id: f_00004-4-7 loss: 0.882692  [  256/  306]
train() client id: f_00004-4-8 loss: 0.810558  [  288/  306]
train() client id: f_00004-5-0 loss: 1.049478  [   32/  306]
train() client id: f_00004-5-1 loss: 0.821254  [   64/  306]
train() client id: f_00004-5-2 loss: 0.873996  [   96/  306]
train() client id: f_00004-5-3 loss: 0.927247  [  128/  306]
train() client id: f_00004-5-4 loss: 0.919744  [  160/  306]
train() client id: f_00004-5-5 loss: 0.994542  [  192/  306]
train() client id: f_00004-5-6 loss: 0.863082  [  224/  306]
train() client id: f_00004-5-7 loss: 0.863193  [  256/  306]
train() client id: f_00004-5-8 loss: 0.803300  [  288/  306]
train() client id: f_00004-6-0 loss: 0.744543  [   32/  306]
train() client id: f_00004-6-1 loss: 0.882394  [   64/  306]
train() client id: f_00004-6-2 loss: 0.910076  [   96/  306]
train() client id: f_00004-6-3 loss: 1.031231  [  128/  306]
train() client id: f_00004-6-4 loss: 0.860001  [  160/  306]
train() client id: f_00004-6-5 loss: 0.886274  [  192/  306]
train() client id: f_00004-6-6 loss: 0.885299  [  224/  306]
train() client id: f_00004-6-7 loss: 0.874154  [  256/  306]
train() client id: f_00004-6-8 loss: 1.008643  [  288/  306]
train() client id: f_00004-7-0 loss: 0.939821  [   32/  306]
train() client id: f_00004-7-1 loss: 0.883862  [   64/  306]
train() client id: f_00004-7-2 loss: 0.855241  [   96/  306]
train() client id: f_00004-7-3 loss: 0.917517  [  128/  306]
train() client id: f_00004-7-4 loss: 0.878836  [  160/  306]
train() client id: f_00004-7-5 loss: 1.000654  [  192/  306]
train() client id: f_00004-7-6 loss: 0.799376  [  224/  306]
train() client id: f_00004-7-7 loss: 0.979818  [  256/  306]
train() client id: f_00004-7-8 loss: 0.841370  [  288/  306]
train() client id: f_00004-8-0 loss: 0.807135  [   32/  306]
train() client id: f_00004-8-1 loss: 0.874569  [   64/  306]
train() client id: f_00004-8-2 loss: 0.908007  [   96/  306]
train() client id: f_00004-8-3 loss: 0.878014  [  128/  306]
train() client id: f_00004-8-4 loss: 0.916925  [  160/  306]
train() client id: f_00004-8-5 loss: 0.946596  [  192/  306]
train() client id: f_00004-8-6 loss: 0.942811  [  224/  306]
train() client id: f_00004-8-7 loss: 0.904374  [  256/  306]
train() client id: f_00004-8-8 loss: 0.945039  [  288/  306]
train() client id: f_00004-9-0 loss: 0.784886  [   32/  306]
train() client id: f_00004-9-1 loss: 0.823073  [   64/  306]
train() client id: f_00004-9-2 loss: 0.915883  [   96/  306]
train() client id: f_00004-9-3 loss: 0.948067  [  128/  306]
train() client id: f_00004-9-4 loss: 0.961046  [  160/  306]
train() client id: f_00004-9-5 loss: 0.963354  [  192/  306]
train() client id: f_00004-9-6 loss: 0.986113  [  224/  306]
train() client id: f_00004-9-7 loss: 0.848111  [  256/  306]
train() client id: f_00004-9-8 loss: 0.866826  [  288/  306]
train() client id: f_00004-10-0 loss: 0.829845  [   32/  306]
train() client id: f_00004-10-1 loss: 0.960314  [   64/  306]
train() client id: f_00004-10-2 loss: 0.804622  [   96/  306]
train() client id: f_00004-10-3 loss: 0.901782  [  128/  306]
train() client id: f_00004-10-4 loss: 0.863794  [  160/  306]
train() client id: f_00004-10-5 loss: 1.019116  [  192/  306]
train() client id: f_00004-10-6 loss: 0.886398  [  224/  306]
train() client id: f_00004-10-7 loss: 0.966525  [  256/  306]
train() client id: f_00004-10-8 loss: 0.831813  [  288/  306]
train() client id: f_00004-11-0 loss: 1.010826  [   32/  306]
train() client id: f_00004-11-1 loss: 0.874553  [   64/  306]
train() client id: f_00004-11-2 loss: 0.856501  [   96/  306]
train() client id: f_00004-11-3 loss: 0.790347  [  128/  306]
train() client id: f_00004-11-4 loss: 0.920553  [  160/  306]
train() client id: f_00004-11-5 loss: 0.830907  [  192/  306]
train() client id: f_00004-11-6 loss: 1.002326  [  224/  306]
train() client id: f_00004-11-7 loss: 0.875771  [  256/  306]
train() client id: f_00004-11-8 loss: 0.876119  [  288/  306]
train() client id: f_00004-12-0 loss: 0.859182  [   32/  306]
train() client id: f_00004-12-1 loss: 0.991965  [   64/  306]
train() client id: f_00004-12-2 loss: 0.843019  [   96/  306]
train() client id: f_00004-12-3 loss: 0.844378  [  128/  306]
train() client id: f_00004-12-4 loss: 0.938361  [  160/  306]
train() client id: f_00004-12-5 loss: 0.904278  [  192/  306]
train() client id: f_00004-12-6 loss: 0.919517  [  224/  306]
train() client id: f_00004-12-7 loss: 0.904901  [  256/  306]
train() client id: f_00004-12-8 loss: 0.843264  [  288/  306]
train() client id: f_00005-0-0 loss: 0.773022  [   32/  146]
train() client id: f_00005-0-1 loss: 0.936977  [   64/  146]
train() client id: f_00005-0-2 loss: 0.776491  [   96/  146]
train() client id: f_00005-0-3 loss: 0.717308  [  128/  146]
train() client id: f_00005-1-0 loss: 0.857758  [   32/  146]
train() client id: f_00005-1-1 loss: 0.916391  [   64/  146]
train() client id: f_00005-1-2 loss: 0.683324  [   96/  146]
train() client id: f_00005-1-3 loss: 0.753833  [  128/  146]
train() client id: f_00005-2-0 loss: 0.622992  [   32/  146]
train() client id: f_00005-2-1 loss: 0.810766  [   64/  146]
train() client id: f_00005-2-2 loss: 0.729179  [   96/  146]
train() client id: f_00005-2-3 loss: 0.895587  [  128/  146]
train() client id: f_00005-3-0 loss: 0.673134  [   32/  146]
train() client id: f_00005-3-1 loss: 0.742917  [   64/  146]
train() client id: f_00005-3-2 loss: 0.815902  [   96/  146]
train() client id: f_00005-3-3 loss: 0.747236  [  128/  146]
train() client id: f_00005-4-0 loss: 0.770107  [   32/  146]
train() client id: f_00005-4-1 loss: 0.855558  [   64/  146]
train() client id: f_00005-4-2 loss: 0.633573  [   96/  146]
train() client id: f_00005-4-3 loss: 0.753453  [  128/  146]
train() client id: f_00005-5-0 loss: 0.801880  [   32/  146]
train() client id: f_00005-5-1 loss: 0.833742  [   64/  146]
train() client id: f_00005-5-2 loss: 0.691166  [   96/  146]
train() client id: f_00005-5-3 loss: 0.682229  [  128/  146]
train() client id: f_00005-6-0 loss: 0.728496  [   32/  146]
train() client id: f_00005-6-1 loss: 0.632978  [   64/  146]
train() client id: f_00005-6-2 loss: 0.731176  [   96/  146]
train() client id: f_00005-6-3 loss: 0.656735  [  128/  146]
train() client id: f_00005-7-0 loss: 0.736678  [   32/  146]
train() client id: f_00005-7-1 loss: 0.818228  [   64/  146]
train() client id: f_00005-7-2 loss: 0.546020  [   96/  146]
train() client id: f_00005-7-3 loss: 0.738516  [  128/  146]
train() client id: f_00005-8-0 loss: 0.665881  [   32/  146]
train() client id: f_00005-8-1 loss: 0.607496  [   64/  146]
train() client id: f_00005-8-2 loss: 0.831996  [   96/  146]
train() client id: f_00005-8-3 loss: 0.796293  [  128/  146]
train() client id: f_00005-9-0 loss: 0.684339  [   32/  146]
train() client id: f_00005-9-1 loss: 0.715233  [   64/  146]
train() client id: f_00005-9-2 loss: 0.742338  [   96/  146]
train() client id: f_00005-9-3 loss: 0.707838  [  128/  146]
train() client id: f_00005-10-0 loss: 0.855932  [   32/  146]
train() client id: f_00005-10-1 loss: 0.744902  [   64/  146]
train() client id: f_00005-10-2 loss: 0.583444  [   96/  146]
train() client id: f_00005-10-3 loss: 0.638314  [  128/  146]
train() client id: f_00005-11-0 loss: 0.648992  [   32/  146]
train() client id: f_00005-11-1 loss: 0.836423  [   64/  146]
train() client id: f_00005-11-2 loss: 0.545298  [   96/  146]
train() client id: f_00005-11-3 loss: 0.837335  [  128/  146]
train() client id: f_00005-12-0 loss: 0.711096  [   32/  146]
train() client id: f_00005-12-1 loss: 0.533975  [   64/  146]
train() client id: f_00005-12-2 loss: 0.744163  [   96/  146]
train() client id: f_00005-12-3 loss: 0.936228  [  128/  146]
train() client id: f_00006-0-0 loss: 0.868972  [   32/   54]
train() client id: f_00006-1-0 loss: 0.804653  [   32/   54]
train() client id: f_00006-2-0 loss: 0.846078  [   32/   54]
train() client id: f_00006-3-0 loss: 0.843832  [   32/   54]
train() client id: f_00006-4-0 loss: 0.848189  [   32/   54]
train() client id: f_00006-5-0 loss: 0.873273  [   32/   54]
train() client id: f_00006-6-0 loss: 0.837854  [   32/   54]
train() client id: f_00006-7-0 loss: 0.859646  [   32/   54]
train() client id: f_00006-8-0 loss: 0.866806  [   32/   54]
train() client id: f_00006-9-0 loss: 0.866763  [   32/   54]
train() client id: f_00006-10-0 loss: 0.808207  [   32/   54]
train() client id: f_00006-11-0 loss: 0.820324  [   32/   54]
train() client id: f_00006-12-0 loss: 0.830279  [   32/   54]
train() client id: f_00007-0-0 loss: 0.637731  [   32/  179]
train() client id: f_00007-0-1 loss: 0.757161  [   64/  179]
train() client id: f_00007-0-2 loss: 0.797236  [   96/  179]
train() client id: f_00007-0-3 loss: 0.646007  [  128/  179]
train() client id: f_00007-0-4 loss: 0.665501  [  160/  179]
train() client id: f_00007-1-0 loss: 0.661050  [   32/  179]
train() client id: f_00007-1-1 loss: 0.613164  [   64/  179]
train() client id: f_00007-1-2 loss: 0.732276  [   96/  179]
train() client id: f_00007-1-3 loss: 0.697368  [  128/  179]
train() client id: f_00007-1-4 loss: 0.583257  [  160/  179]
train() client id: f_00007-2-0 loss: 0.620975  [   32/  179]
train() client id: f_00007-2-1 loss: 0.582287  [   64/  179]
train() client id: f_00007-2-2 loss: 0.602200  [   96/  179]
train() client id: f_00007-2-3 loss: 0.637291  [  128/  179]
train() client id: f_00007-2-4 loss: 0.747828  [  160/  179]
train() client id: f_00007-3-0 loss: 0.732260  [   32/  179]
train() client id: f_00007-3-1 loss: 0.581205  [   64/  179]
train() client id: f_00007-3-2 loss: 0.684683  [   96/  179]
train() client id: f_00007-3-3 loss: 0.567032  [  128/  179]
train() client id: f_00007-3-4 loss: 0.571302  [  160/  179]
train() client id: f_00007-4-0 loss: 0.635627  [   32/  179]
train() client id: f_00007-4-1 loss: 0.589287  [   64/  179]
train() client id: f_00007-4-2 loss: 0.666839  [   96/  179]
train() client id: f_00007-4-3 loss: 0.562590  [  128/  179]
train() client id: f_00007-4-4 loss: 0.601146  [  160/  179]
train() client id: f_00007-5-0 loss: 0.541385  [   32/  179]
train() client id: f_00007-5-1 loss: 0.570253  [   64/  179]
train() client id: f_00007-5-2 loss: 0.598397  [   96/  179]
train() client id: f_00007-5-3 loss: 0.567138  [  128/  179]
train() client id: f_00007-5-4 loss: 0.669632  [  160/  179]
train() client id: f_00007-6-0 loss: 0.509168  [   32/  179]
train() client id: f_00007-6-1 loss: 0.492638  [   64/  179]
train() client id: f_00007-6-2 loss: 0.547961  [   96/  179]
train() client id: f_00007-6-3 loss: 0.683584  [  128/  179]
train() client id: f_00007-6-4 loss: 0.681103  [  160/  179]
train() client id: f_00007-7-0 loss: 0.704480  [   32/  179]
train() client id: f_00007-7-1 loss: 0.544316  [   64/  179]
train() client id: f_00007-7-2 loss: 0.508465  [   96/  179]
train() client id: f_00007-7-3 loss: 0.478094  [  128/  179]
train() client id: f_00007-7-4 loss: 0.686599  [  160/  179]
train() client id: f_00007-8-0 loss: 0.801382  [   32/  179]
train() client id: f_00007-8-1 loss: 0.633148  [   64/  179]
train() client id: f_00007-8-2 loss: 0.516428  [   96/  179]
train() client id: f_00007-8-3 loss: 0.520979  [  128/  179]
train() client id: f_00007-8-4 loss: 0.512718  [  160/  179]
train() client id: f_00007-9-0 loss: 0.467430  [   32/  179]
train() client id: f_00007-9-1 loss: 0.610227  [   64/  179]
train() client id: f_00007-9-2 loss: 0.492010  [   96/  179]
train() client id: f_00007-9-3 loss: 0.732132  [  128/  179]
train() client id: f_00007-9-4 loss: 0.590612  [  160/  179]
train() client id: f_00007-10-0 loss: 0.549988  [   32/  179]
train() client id: f_00007-10-1 loss: 0.465199  [   64/  179]
train() client id: f_00007-10-2 loss: 0.711938  [   96/  179]
train() client id: f_00007-10-3 loss: 0.614096  [  128/  179]
train() client id: f_00007-10-4 loss: 0.605053  [  160/  179]
train() client id: f_00007-11-0 loss: 0.517205  [   32/  179]
train() client id: f_00007-11-1 loss: 0.505887  [   64/  179]
train() client id: f_00007-11-2 loss: 0.657301  [   96/  179]
train() client id: f_00007-11-3 loss: 0.462728  [  128/  179]
train() client id: f_00007-11-4 loss: 0.688039  [  160/  179]
train() client id: f_00007-12-0 loss: 0.674436  [   32/  179]
train() client id: f_00007-12-1 loss: 0.523499  [   64/  179]
train() client id: f_00007-12-2 loss: 0.626002  [   96/  179]
train() client id: f_00007-12-3 loss: 0.522954  [  128/  179]
train() client id: f_00007-12-4 loss: 0.600527  [  160/  179]
train() client id: f_00008-0-0 loss: 1.037527  [   32/  130]
train() client id: f_00008-0-1 loss: 0.911463  [   64/  130]
train() client id: f_00008-0-2 loss: 0.999902  [   96/  130]
train() client id: f_00008-0-3 loss: 0.961754  [  128/  130]
train() client id: f_00008-1-0 loss: 0.985644  [   32/  130]
train() client id: f_00008-1-1 loss: 0.985365  [   64/  130]
train() client id: f_00008-1-2 loss: 0.922965  [   96/  130]
train() client id: f_00008-1-3 loss: 1.015027  [  128/  130]
train() client id: f_00008-2-0 loss: 1.039475  [   32/  130]
train() client id: f_00008-2-1 loss: 0.936922  [   64/  130]
train() client id: f_00008-2-2 loss: 1.030280  [   96/  130]
train() client id: f_00008-2-3 loss: 0.901490  [  128/  130]
train() client id: f_00008-3-0 loss: 0.925234  [   32/  130]
train() client id: f_00008-3-1 loss: 1.037562  [   64/  130]
train() client id: f_00008-3-2 loss: 0.977894  [   96/  130]
train() client id: f_00008-3-3 loss: 0.968170  [  128/  130]
train() client id: f_00008-4-0 loss: 1.034644  [   32/  130]
train() client id: f_00008-4-1 loss: 1.000774  [   64/  130]
train() client id: f_00008-4-2 loss: 0.910607  [   96/  130]
train() client id: f_00008-4-3 loss: 0.958525  [  128/  130]
train() client id: f_00008-5-0 loss: 0.931042  [   32/  130]
train() client id: f_00008-5-1 loss: 0.925006  [   64/  130]
train() client id: f_00008-5-2 loss: 1.024006  [   96/  130]
train() client id: f_00008-5-3 loss: 0.983749  [  128/  130]
train() client id: f_00008-6-0 loss: 1.001502  [   32/  130]
train() client id: f_00008-6-1 loss: 0.915433  [   64/  130]
train() client id: f_00008-6-2 loss: 0.984989  [   96/  130]
train() client id: f_00008-6-3 loss: 1.003251  [  128/  130]
train() client id: f_00008-7-0 loss: 1.016325  [   32/  130]
train() client id: f_00008-7-1 loss: 0.992100  [   64/  130]
train() client id: f_00008-7-2 loss: 0.925342  [   96/  130]
train() client id: f_00008-7-3 loss: 0.957201  [  128/  130]
train() client id: f_00008-8-0 loss: 0.963722  [   32/  130]
train() client id: f_00008-8-1 loss: 0.921346  [   64/  130]
train() client id: f_00008-8-2 loss: 0.852503  [   96/  130]
train() client id: f_00008-8-3 loss: 1.135040  [  128/  130]
train() client id: f_00008-9-0 loss: 0.873141  [   32/  130]
train() client id: f_00008-9-1 loss: 0.953572  [   64/  130]
train() client id: f_00008-9-2 loss: 1.034647  [   96/  130]
train() client id: f_00008-9-3 loss: 1.040716  [  128/  130]
train() client id: f_00008-10-0 loss: 0.971256  [   32/  130]
train() client id: f_00008-10-1 loss: 0.907936  [   64/  130]
train() client id: f_00008-10-2 loss: 0.954744  [   96/  130]
train() client id: f_00008-10-3 loss: 1.072943  [  128/  130]
train() client id: f_00008-11-0 loss: 0.958675  [   32/  130]
train() client id: f_00008-11-1 loss: 0.985904  [   64/  130]
train() client id: f_00008-11-2 loss: 0.942599  [   96/  130]
train() client id: f_00008-11-3 loss: 1.004609  [  128/  130]
train() client id: f_00008-12-0 loss: 1.084258  [   32/  130]
train() client id: f_00008-12-1 loss: 0.952553  [   64/  130]
train() client id: f_00008-12-2 loss: 0.940380  [   96/  130]
train() client id: f_00008-12-3 loss: 0.919989  [  128/  130]
train() client id: f_00009-0-0 loss: 1.252338  [   32/  118]
train() client id: f_00009-0-1 loss: 1.191647  [   64/  118]
train() client id: f_00009-0-2 loss: 1.143309  [   96/  118]
train() client id: f_00009-1-0 loss: 1.225592  [   32/  118]
train() client id: f_00009-1-1 loss: 1.107278  [   64/  118]
train() client id: f_00009-1-2 loss: 1.157751  [   96/  118]
train() client id: f_00009-2-0 loss: 1.149535  [   32/  118]
train() client id: f_00009-2-1 loss: 1.086848  [   64/  118]
train() client id: f_00009-2-2 loss: 1.119336  [   96/  118]
train() client id: f_00009-3-0 loss: 1.156839  [   32/  118]
train() client id: f_00009-3-1 loss: 1.031627  [   64/  118]
train() client id: f_00009-3-2 loss: 1.143273  [   96/  118]
train() client id: f_00009-4-0 loss: 1.018984  [   32/  118]
train() client id: f_00009-4-1 loss: 1.136638  [   64/  118]
train() client id: f_00009-4-2 loss: 1.066657  [   96/  118]
train() client id: f_00009-5-0 loss: 1.043756  [   32/  118]
train() client id: f_00009-5-1 loss: 1.079339  [   64/  118]
train() client id: f_00009-5-2 loss: 0.996508  [   96/  118]
train() client id: f_00009-6-0 loss: 1.029173  [   32/  118]
train() client id: f_00009-6-1 loss: 1.045825  [   64/  118]
train() client id: f_00009-6-2 loss: 1.080292  [   96/  118]
train() client id: f_00009-7-0 loss: 0.999404  [   32/  118]
train() client id: f_00009-7-1 loss: 1.073454  [   64/  118]
train() client id: f_00009-7-2 loss: 1.047569  [   96/  118]
train() client id: f_00009-8-0 loss: 0.985434  [   32/  118]
train() client id: f_00009-8-1 loss: 0.998597  [   64/  118]
train() client id: f_00009-8-2 loss: 1.005553  [   96/  118]
train() client id: f_00009-9-0 loss: 0.981813  [   32/  118]
train() client id: f_00009-9-1 loss: 1.085145  [   64/  118]
train() client id: f_00009-9-2 loss: 1.048865  [   96/  118]
train() client id: f_00009-10-0 loss: 1.139581  [   32/  118]
train() client id: f_00009-10-1 loss: 0.991070  [   64/  118]
train() client id: f_00009-10-2 loss: 0.897704  [   96/  118]
train() client id: f_00009-11-0 loss: 0.993111  [   32/  118]
train() client id: f_00009-11-1 loss: 0.997001  [   64/  118]
train() client id: f_00009-11-2 loss: 1.102834  [   96/  118]
train() client id: f_00009-12-0 loss: 1.052078  [   32/  118]
train() client id: f_00009-12-1 loss: 1.043866  [   64/  118]
train() client id: f_00009-12-2 loss: 0.999019  [   96/  118]
At round 6 accuracy: 0.6286472148541115
At round 6 training accuracy: 0.5761234071093226
At round 6 training loss: 0.8813454388262921
gradient difference: 0.4335782527923584
train() client id: f_00000-0-0 loss: 1.201297  [   32/  126]
train() client id: f_00000-0-1 loss: 0.989290  [   64/  126]
train() client id: f_00000-0-2 loss: 1.028515  [   96/  126]
train() client id: f_00000-1-0 loss: 0.903245  [   32/  126]
train() client id: f_00000-1-1 loss: 1.068806  [   64/  126]
train() client id: f_00000-1-2 loss: 0.999933  [   96/  126]
train() client id: f_00000-2-0 loss: 0.883015  [   32/  126]
train() client id: f_00000-2-1 loss: 1.033851  [   64/  126]
train() client id: f_00000-2-2 loss: 0.850528  [   96/  126]
train() client id: f_00000-3-0 loss: 1.044404  [   32/  126]
train() client id: f_00000-3-1 loss: 0.805226  [   64/  126]
train() client id: f_00000-3-2 loss: 0.790170  [   96/  126]
train() client id: f_00000-4-0 loss: 0.967200  [   32/  126]
train() client id: f_00000-4-1 loss: 0.830163  [   64/  126]
train() client id: f_00000-4-2 loss: 0.740679  [   96/  126]
train() client id: f_00000-5-0 loss: 0.910982  [   32/  126]
train() client id: f_00000-5-1 loss: 0.756750  [   64/  126]
train() client id: f_00000-5-2 loss: 0.828800  [   96/  126]
train() client id: f_00000-6-0 loss: 0.853073  [   32/  126]
train() client id: f_00000-6-1 loss: 0.799362  [   64/  126]
train() client id: f_00000-6-2 loss: 0.747389  [   96/  126]
train() client id: f_00000-7-0 loss: 0.771673  [   32/  126]
train() client id: f_00000-7-1 loss: 0.806994  [   64/  126]
train() client id: f_00000-7-2 loss: 0.765886  [   96/  126]
train() client id: f_00000-8-0 loss: 0.811678  [   32/  126]
train() client id: f_00000-8-1 loss: 0.794598  [   64/  126]
train() client id: f_00000-8-2 loss: 0.760991  [   96/  126]
train() client id: f_00000-9-0 loss: 0.701469  [   32/  126]
train() client id: f_00000-9-1 loss: 0.889105  [   64/  126]
train() client id: f_00000-9-2 loss: 0.810749  [   96/  126]
train() client id: f_00000-10-0 loss: 0.846087  [   32/  126]
train() client id: f_00000-10-1 loss: 0.800403  [   64/  126]
train() client id: f_00000-10-2 loss: 0.745041  [   96/  126]
train() client id: f_00000-11-0 loss: 0.906427  [   32/  126]
train() client id: f_00000-11-1 loss: 0.770943  [   64/  126]
train() client id: f_00000-11-2 loss: 0.726493  [   96/  126]
train() client id: f_00000-12-0 loss: 0.810920  [   32/  126]
train() client id: f_00000-12-1 loss: 0.775216  [   64/  126]
train() client id: f_00000-12-2 loss: 0.814727  [   96/  126]
train() client id: f_00001-0-0 loss: 0.672556  [   32/  265]
train() client id: f_00001-0-1 loss: 0.693963  [   64/  265]
train() client id: f_00001-0-2 loss: 0.652553  [   96/  265]
train() client id: f_00001-0-3 loss: 0.621435  [  128/  265]
train() client id: f_00001-0-4 loss: 0.656033  [  160/  265]
train() client id: f_00001-0-5 loss: 0.655492  [  192/  265]
train() client id: f_00001-0-6 loss: 0.561874  [  224/  265]
train() client id: f_00001-0-7 loss: 0.612103  [  256/  265]
train() client id: f_00001-1-0 loss: 0.591083  [   32/  265]
train() client id: f_00001-1-1 loss: 0.655697  [   64/  265]
train() client id: f_00001-1-2 loss: 0.581103  [   96/  265]
train() client id: f_00001-1-3 loss: 0.734516  [  128/  265]
train() client id: f_00001-1-4 loss: 0.622461  [  160/  265]
train() client id: f_00001-1-5 loss: 0.617600  [  192/  265]
train() client id: f_00001-1-6 loss: 0.552905  [  224/  265]
train() client id: f_00001-1-7 loss: 0.585343  [  256/  265]
train() client id: f_00001-2-0 loss: 0.589862  [   32/  265]
train() client id: f_00001-2-1 loss: 0.663295  [   64/  265]
train() client id: f_00001-2-2 loss: 0.556297  [   96/  265]
train() client id: f_00001-2-3 loss: 0.637338  [  128/  265]
train() client id: f_00001-2-4 loss: 0.597581  [  160/  265]
train() client id: f_00001-2-5 loss: 0.610833  [  192/  265]
train() client id: f_00001-2-6 loss: 0.598525  [  224/  265]
train() client id: f_00001-2-7 loss: 0.531709  [  256/  265]
train() client id: f_00001-3-0 loss: 0.524400  [   32/  265]
train() client id: f_00001-3-1 loss: 0.571120  [   64/  265]
train() client id: f_00001-3-2 loss: 0.607641  [   96/  265]
train() client id: f_00001-3-3 loss: 0.583109  [  128/  265]
train() client id: f_00001-3-4 loss: 0.611910  [  160/  265]
train() client id: f_00001-3-5 loss: 0.562315  [  192/  265]
train() client id: f_00001-3-6 loss: 0.575803  [  224/  265]
train() client id: f_00001-3-7 loss: 0.602222  [  256/  265]
train() client id: f_00001-4-0 loss: 0.623335  [   32/  265]
train() client id: f_00001-4-1 loss: 0.640014  [   64/  265]
train() client id: f_00001-4-2 loss: 0.625735  [   96/  265]
train() client id: f_00001-4-3 loss: 0.547520  [  128/  265]
train() client id: f_00001-4-4 loss: 0.487608  [  160/  265]
train() client id: f_00001-4-5 loss: 0.569912  [  192/  265]
train() client id: f_00001-4-6 loss: 0.611725  [  224/  265]
train() client id: f_00001-4-7 loss: 0.501983  [  256/  265]
train() client id: f_00001-5-0 loss: 0.542122  [   32/  265]
train() client id: f_00001-5-1 loss: 0.605815  [   64/  265]
train() client id: f_00001-5-2 loss: 0.570756  [   96/  265]
train() client id: f_00001-5-3 loss: 0.563411  [  128/  265]
train() client id: f_00001-5-4 loss: 0.555148  [  160/  265]
train() client id: f_00001-5-5 loss: 0.584276  [  192/  265]
train() client id: f_00001-5-6 loss: 0.576693  [  224/  265]
train() client id: f_00001-5-7 loss: 0.556830  [  256/  265]
train() client id: f_00001-6-0 loss: 0.580681  [   32/  265]
train() client id: f_00001-6-1 loss: 0.585684  [   64/  265]
train() client id: f_00001-6-2 loss: 0.498015  [   96/  265]
train() client id: f_00001-6-3 loss: 0.594624  [  128/  265]
train() client id: f_00001-6-4 loss: 0.489430  [  160/  265]
train() client id: f_00001-6-5 loss: 0.574993  [  192/  265]
train() client id: f_00001-6-6 loss: 0.490611  [  224/  265]
train() client id: f_00001-6-7 loss: 0.695408  [  256/  265]
train() client id: f_00001-7-0 loss: 0.536623  [   32/  265]
train() client id: f_00001-7-1 loss: 0.506020  [   64/  265]
train() client id: f_00001-7-2 loss: 0.567402  [   96/  265]
train() client id: f_00001-7-3 loss: 0.621977  [  128/  265]
train() client id: f_00001-7-4 loss: 0.556388  [  160/  265]
train() client id: f_00001-7-5 loss: 0.501886  [  192/  265]
train() client id: f_00001-7-6 loss: 0.507871  [  224/  265]
train() client id: f_00001-7-7 loss: 0.624972  [  256/  265]
train() client id: f_00001-8-0 loss: 0.488782  [   32/  265]
train() client id: f_00001-8-1 loss: 0.499070  [   64/  265]
train() client id: f_00001-8-2 loss: 0.510873  [   96/  265]
train() client id: f_00001-8-3 loss: 0.581464  [  128/  265]
train() client id: f_00001-8-4 loss: 0.519023  [  160/  265]
train() client id: f_00001-8-5 loss: 0.648485  [  192/  265]
train() client id: f_00001-8-6 loss: 0.635855  [  224/  265]
train() client id: f_00001-8-7 loss: 0.590581  [  256/  265]
train() client id: f_00001-9-0 loss: 0.491949  [   32/  265]
train() client id: f_00001-9-1 loss: 0.488103  [   64/  265]
train() client id: f_00001-9-2 loss: 0.549450  [   96/  265]
train() client id: f_00001-9-3 loss: 0.515530  [  128/  265]
train() client id: f_00001-9-4 loss: 0.533580  [  160/  265]
train() client id: f_00001-9-5 loss: 0.578526  [  192/  265]
train() client id: f_00001-9-6 loss: 0.616147  [  224/  265]
train() client id: f_00001-9-7 loss: 0.674122  [  256/  265]
train() client id: f_00001-10-0 loss: 0.548365  [   32/  265]
train() client id: f_00001-10-1 loss: 0.522348  [   64/  265]
train() client id: f_00001-10-2 loss: 0.514830  [   96/  265]
train() client id: f_00001-10-3 loss: 0.517551  [  128/  265]
train() client id: f_00001-10-4 loss: 0.662450  [  160/  265]
train() client id: f_00001-10-5 loss: 0.624710  [  192/  265]
train() client id: f_00001-10-6 loss: 0.549462  [  224/  265]
train() client id: f_00001-10-7 loss: 0.505132  [  256/  265]
train() client id: f_00001-11-0 loss: 0.577605  [   32/  265]
train() client id: f_00001-11-1 loss: 0.647001  [   64/  265]
train() client id: f_00001-11-2 loss: 0.603564  [   96/  265]
train() client id: f_00001-11-3 loss: 0.465337  [  128/  265]
train() client id: f_00001-11-4 loss: 0.509582  [  160/  265]
train() client id: f_00001-11-5 loss: 0.508524  [  192/  265]
train() client id: f_00001-11-6 loss: 0.538210  [  224/  265]
train() client id: f_00001-11-7 loss: 0.548347  [  256/  265]
train() client id: f_00001-12-0 loss: 0.617427  [   32/  265]
train() client id: f_00001-12-1 loss: 0.537905  [   64/  265]
train() client id: f_00001-12-2 loss: 0.527921  [   96/  265]
train() client id: f_00001-12-3 loss: 0.654040  [  128/  265]
train() client id: f_00001-12-4 loss: 0.595791  [  160/  265]
train() client id: f_00001-12-5 loss: 0.473283  [  192/  265]
train() client id: f_00001-12-6 loss: 0.520644  [  224/  265]
train() client id: f_00001-12-7 loss: 0.522952  [  256/  265]
train() client id: f_00002-0-0 loss: 1.265905  [   32/  124]
train() client id: f_00002-0-1 loss: 1.285407  [   64/  124]
train() client id: f_00002-0-2 loss: 1.118496  [   96/  124]
train() client id: f_00002-1-0 loss: 1.200069  [   32/  124]
train() client id: f_00002-1-1 loss: 1.106546  [   64/  124]
train() client id: f_00002-1-2 loss: 1.172007  [   96/  124]
train() client id: f_00002-2-0 loss: 1.155984  [   32/  124]
train() client id: f_00002-2-1 loss: 1.114049  [   64/  124]
train() client id: f_00002-2-2 loss: 1.082012  [   96/  124]
train() client id: f_00002-3-0 loss: 1.100508  [   32/  124]
train() client id: f_00002-3-1 loss: 1.115259  [   64/  124]
train() client id: f_00002-3-2 loss: 1.146977  [   96/  124]
train() client id: f_00002-4-0 loss: 1.131854  [   32/  124]
train() client id: f_00002-4-1 loss: 1.107911  [   64/  124]
train() client id: f_00002-4-2 loss: 1.124602  [   96/  124]
train() client id: f_00002-5-0 loss: 1.112589  [   32/  124]
train() client id: f_00002-5-1 loss: 1.108659  [   64/  124]
train() client id: f_00002-5-2 loss: 1.119491  [   96/  124]
train() client id: f_00002-6-0 loss: 1.086926  [   32/  124]
train() client id: f_00002-6-1 loss: 1.026161  [   64/  124]
train() client id: f_00002-6-2 loss: 1.097872  [   96/  124]
train() client id: f_00002-7-0 loss: 1.151246  [   32/  124]
train() client id: f_00002-7-1 loss: 1.069839  [   64/  124]
train() client id: f_00002-7-2 loss: 1.005308  [   96/  124]
train() client id: f_00002-8-0 loss: 1.047304  [   32/  124]
train() client id: f_00002-8-1 loss: 1.091876  [   64/  124]
train() client id: f_00002-8-2 loss: 1.079190  [   96/  124]
train() client id: f_00002-9-0 loss: 1.065580  [   32/  124]
train() client id: f_00002-9-1 loss: 1.023086  [   64/  124]
train() client id: f_00002-9-2 loss: 1.042259  [   96/  124]
train() client id: f_00002-10-0 loss: 1.077964  [   32/  124]
train() client id: f_00002-10-1 loss: 1.002367  [   64/  124]
train() client id: f_00002-10-2 loss: 1.095884  [   96/  124]
train() client id: f_00002-11-0 loss: 1.169204  [   32/  124]
train() client id: f_00002-11-1 loss: 1.092857  [   64/  124]
train() client id: f_00002-11-2 loss: 1.001619  [   96/  124]
train() client id: f_00002-12-0 loss: 0.994761  [   32/  124]
train() client id: f_00002-12-1 loss: 1.080892  [   64/  124]
train() client id: f_00002-12-2 loss: 1.027098  [   96/  124]
train() client id: f_00003-0-0 loss: 1.019261  [   32/   43]
train() client id: f_00003-1-0 loss: 0.873916  [   32/   43]
train() client id: f_00003-2-0 loss: 0.901982  [   32/   43]
train() client id: f_00003-3-0 loss: 1.102418  [   32/   43]
train() client id: f_00003-4-0 loss: 0.996209  [   32/   43]
train() client id: f_00003-5-0 loss: 0.959900  [   32/   43]
train() client id: f_00003-6-0 loss: 1.018841  [   32/   43]
train() client id: f_00003-7-0 loss: 1.096284  [   32/   43]
train() client id: f_00003-8-0 loss: 1.063813  [   32/   43]
train() client id: f_00003-9-0 loss: 0.918858  [   32/   43]
train() client id: f_00003-10-0 loss: 1.035758  [   32/   43]
train() client id: f_00003-11-0 loss: 0.960344  [   32/   43]
train() client id: f_00003-12-0 loss: 0.968323  [   32/   43]
train() client id: f_00004-0-0 loss: 1.034560  [   32/  306]
train() client id: f_00004-0-1 loss: 0.969532  [   64/  306]
train() client id: f_00004-0-2 loss: 0.864440  [   96/  306]
train() client id: f_00004-0-3 loss: 0.988369  [  128/  306]
train() client id: f_00004-0-4 loss: 1.007303  [  160/  306]
train() client id: f_00004-0-5 loss: 0.987619  [  192/  306]
train() client id: f_00004-0-6 loss: 0.929757  [  224/  306]
train() client id: f_00004-0-7 loss: 1.032423  [  256/  306]
train() client id: f_00004-0-8 loss: 1.130497  [  288/  306]
train() client id: f_00004-1-0 loss: 0.856264  [   32/  306]
train() client id: f_00004-1-1 loss: 0.971625  [   64/  306]
train() client id: f_00004-1-2 loss: 0.967315  [   96/  306]
train() client id: f_00004-1-3 loss: 0.959660  [  128/  306]
train() client id: f_00004-1-4 loss: 0.951570  [  160/  306]
train() client id: f_00004-1-5 loss: 1.075065  [  192/  306]
train() client id: f_00004-1-6 loss: 0.942958  [  224/  306]
train() client id: f_00004-1-7 loss: 0.953114  [  256/  306]
train() client id: f_00004-1-8 loss: 1.125203  [  288/  306]
train() client id: f_00004-2-0 loss: 0.898707  [   32/  306]
train() client id: f_00004-2-1 loss: 0.824462  [   64/  306]
train() client id: f_00004-2-2 loss: 0.990041  [   96/  306]
train() client id: f_00004-2-3 loss: 1.070300  [  128/  306]
train() client id: f_00004-2-4 loss: 1.084875  [  160/  306]
train() client id: f_00004-2-5 loss: 1.036076  [  192/  306]
train() client id: f_00004-2-6 loss: 1.007419  [  224/  306]
train() client id: f_00004-2-7 loss: 1.044749  [  256/  306]
train() client id: f_00004-2-8 loss: 0.906114  [  288/  306]
train() client id: f_00004-3-0 loss: 0.872224  [   32/  306]
train() client id: f_00004-3-1 loss: 1.106013  [   64/  306]
train() client id: f_00004-3-2 loss: 1.048218  [   96/  306]
train() client id: f_00004-3-3 loss: 0.928111  [  128/  306]
train() client id: f_00004-3-4 loss: 0.983214  [  160/  306]
train() client id: f_00004-3-5 loss: 0.857517  [  192/  306]
train() client id: f_00004-3-6 loss: 1.024488  [  224/  306]
train() client id: f_00004-3-7 loss: 1.027941  [  256/  306]
train() client id: f_00004-3-8 loss: 0.924980  [  288/  306]
train() client id: f_00004-4-0 loss: 0.969157  [   32/  306]
train() client id: f_00004-4-1 loss: 0.886416  [   64/  306]
train() client id: f_00004-4-2 loss: 1.016827  [   96/  306]
train() client id: f_00004-4-3 loss: 0.951670  [  128/  306]
train() client id: f_00004-4-4 loss: 0.934366  [  160/  306]
train() client id: f_00004-4-5 loss: 1.018100  [  192/  306]
train() client id: f_00004-4-6 loss: 0.999208  [  224/  306]
train() client id: f_00004-4-7 loss: 0.958375  [  256/  306]
train() client id: f_00004-4-8 loss: 1.000434  [  288/  306]
train() client id: f_00004-5-0 loss: 0.966610  [   32/  306]
train() client id: f_00004-5-1 loss: 0.942326  [   64/  306]
train() client id: f_00004-5-2 loss: 0.935047  [   96/  306]
train() client id: f_00004-5-3 loss: 0.931505  [  128/  306]
train() client id: f_00004-5-4 loss: 1.034562  [  160/  306]
train() client id: f_00004-5-5 loss: 0.865940  [  192/  306]
train() client id: f_00004-5-6 loss: 1.083750  [  224/  306]
train() client id: f_00004-5-7 loss: 0.972276  [  256/  306]
train() client id: f_00004-5-8 loss: 0.999435  [  288/  306]
train() client id: f_00004-6-0 loss: 0.989251  [   32/  306]
train() client id: f_00004-6-1 loss: 0.938470  [   64/  306]
train() client id: f_00004-6-2 loss: 1.045799  [   96/  306]
train() client id: f_00004-6-3 loss: 0.887384  [  128/  306]
train() client id: f_00004-6-4 loss: 0.996138  [  160/  306]
train() client id: f_00004-6-5 loss: 0.914342  [  192/  306]
train() client id: f_00004-6-6 loss: 1.027139  [  224/  306]
train() client id: f_00004-6-7 loss: 0.915613  [  256/  306]
train() client id: f_00004-6-8 loss: 0.963403  [  288/  306]
train() client id: f_00004-7-0 loss: 0.888249  [   32/  306]
train() client id: f_00004-7-1 loss: 1.151389  [   64/  306]
train() client id: f_00004-7-2 loss: 0.908838  [   96/  306]
train() client id: f_00004-7-3 loss: 0.885617  [  128/  306]
train() client id: f_00004-7-4 loss: 0.876999  [  160/  306]
train() client id: f_00004-7-5 loss: 0.816759  [  192/  306]
train() client id: f_00004-7-6 loss: 1.050677  [  224/  306]
train() client id: f_00004-7-7 loss: 1.128067  [  256/  306]
train() client id: f_00004-7-8 loss: 0.934570  [  288/  306]
train() client id: f_00004-8-0 loss: 1.032997  [   32/  306]
train() client id: f_00004-8-1 loss: 1.003188  [   64/  306]
train() client id: f_00004-8-2 loss: 0.940152  [   96/  306]
train() client id: f_00004-8-3 loss: 0.858250  [  128/  306]
train() client id: f_00004-8-4 loss: 0.957578  [  160/  306]
train() client id: f_00004-8-5 loss: 0.870203  [  192/  306]
train() client id: f_00004-8-6 loss: 0.953931  [  224/  306]
train() client id: f_00004-8-7 loss: 0.958839  [  256/  306]
train() client id: f_00004-8-8 loss: 0.989925  [  288/  306]
train() client id: f_00004-9-0 loss: 1.037073  [   32/  306]
train() client id: f_00004-9-1 loss: 1.115741  [   64/  306]
train() client id: f_00004-9-2 loss: 0.895419  [   96/  306]
train() client id: f_00004-9-3 loss: 0.870845  [  128/  306]
train() client id: f_00004-9-4 loss: 0.910365  [  160/  306]
train() client id: f_00004-9-5 loss: 0.995707  [  192/  306]
train() client id: f_00004-9-6 loss: 0.928793  [  224/  306]
train() client id: f_00004-9-7 loss: 0.972878  [  256/  306]
train() client id: f_00004-9-8 loss: 0.974102  [  288/  306]
train() client id: f_00004-10-0 loss: 0.974392  [   32/  306]
train() client id: f_00004-10-1 loss: 1.030759  [   64/  306]
train() client id: f_00004-10-2 loss: 0.909745  [   96/  306]
train() client id: f_00004-10-3 loss: 0.861803  [  128/  306]
train() client id: f_00004-10-4 loss: 0.912664  [  160/  306]
train() client id: f_00004-10-5 loss: 0.993332  [  192/  306]
train() client id: f_00004-10-6 loss: 0.907107  [  224/  306]
train() client id: f_00004-10-7 loss: 0.988422  [  256/  306]
train() client id: f_00004-10-8 loss: 0.962986  [  288/  306]
train() client id: f_00004-11-0 loss: 0.984709  [   32/  306]
train() client id: f_00004-11-1 loss: 0.910881  [   64/  306]
train() client id: f_00004-11-2 loss: 0.916027  [   96/  306]
train() client id: f_00004-11-3 loss: 0.963880  [  128/  306]
train() client id: f_00004-11-4 loss: 0.914215  [  160/  306]
train() client id: f_00004-11-5 loss: 1.003919  [  192/  306]
train() client id: f_00004-11-6 loss: 0.897445  [  224/  306]
train() client id: f_00004-11-7 loss: 0.900842  [  256/  306]
train() client id: f_00004-11-8 loss: 1.061916  [  288/  306]
train() client id: f_00004-12-0 loss: 0.932709  [   32/  306]
train() client id: f_00004-12-1 loss: 0.814319  [   64/  306]
train() client id: f_00004-12-2 loss: 0.940936  [   96/  306]
train() client id: f_00004-12-3 loss: 1.015359  [  128/  306]
train() client id: f_00004-12-4 loss: 1.007813  [  160/  306]
train() client id: f_00004-12-5 loss: 0.919493  [  192/  306]
train() client id: f_00004-12-6 loss: 1.010796  [  224/  306]
train() client id: f_00004-12-7 loss: 0.945169  [  256/  306]
train() client id: f_00004-12-8 loss: 0.985562  [  288/  306]
train() client id: f_00005-0-0 loss: 0.694978  [   32/  146]
train() client id: f_00005-0-1 loss: 0.587339  [   64/  146]
train() client id: f_00005-0-2 loss: 0.825561  [   96/  146]
train() client id: f_00005-0-3 loss: 0.697617  [  128/  146]
train() client id: f_00005-1-0 loss: 0.715384  [   32/  146]
train() client id: f_00005-1-1 loss: 0.523688  [   64/  146]
train() client id: f_00005-1-2 loss: 0.792940  [   96/  146]
train() client id: f_00005-1-3 loss: 0.718734  [  128/  146]
train() client id: f_00005-2-0 loss: 0.715813  [   32/  146]
train() client id: f_00005-2-1 loss: 0.595937  [   64/  146]
train() client id: f_00005-2-2 loss: 0.505315  [   96/  146]
train() client id: f_00005-2-3 loss: 0.772458  [  128/  146]
train() client id: f_00005-3-0 loss: 0.645049  [   32/  146]
train() client id: f_00005-3-1 loss: 0.680968  [   64/  146]
train() client id: f_00005-3-2 loss: 0.593279  [   96/  146]
train() client id: f_00005-3-3 loss: 0.725256  [  128/  146]
train() client id: f_00005-4-0 loss: 0.661922  [   32/  146]
train() client id: f_00005-4-1 loss: 0.702469  [   64/  146]
train() client id: f_00005-4-2 loss: 0.499705  [   96/  146]
train() client id: f_00005-4-3 loss: 0.645698  [  128/  146]
train() client id: f_00005-5-0 loss: 0.553539  [   32/  146]
train() client id: f_00005-5-1 loss: 0.630727  [   64/  146]
train() client id: f_00005-5-2 loss: 0.567506  [   96/  146]
train() client id: f_00005-5-3 loss: 0.680529  [  128/  146]
train() client id: f_00005-6-0 loss: 0.581420  [   32/  146]
train() client id: f_00005-6-1 loss: 0.539808  [   64/  146]
train() client id: f_00005-6-2 loss: 0.651355  [   96/  146]
train() client id: f_00005-6-3 loss: 0.620073  [  128/  146]
train() client id: f_00005-7-0 loss: 0.564005  [   32/  146]
train() client id: f_00005-7-1 loss: 0.523892  [   64/  146]
train() client id: f_00005-7-2 loss: 0.662277  [   96/  146]
train() client id: f_00005-7-3 loss: 0.529350  [  128/  146]
train() client id: f_00005-8-0 loss: 0.578684  [   32/  146]
train() client id: f_00005-8-1 loss: 0.537626  [   64/  146]
train() client id: f_00005-8-2 loss: 0.487143  [   96/  146]
train() client id: f_00005-8-3 loss: 0.748729  [  128/  146]
train() client id: f_00005-9-0 loss: 0.404588  [   32/  146]
train() client id: f_00005-9-1 loss: 0.649604  [   64/  146]
train() client id: f_00005-9-2 loss: 0.653605  [   96/  146]
train() client id: f_00005-9-3 loss: 0.621029  [  128/  146]
train() client id: f_00005-10-0 loss: 0.546849  [   32/  146]
train() client id: f_00005-10-1 loss: 0.588789  [   64/  146]
train() client id: f_00005-10-2 loss: 0.585590  [   96/  146]
train() client id: f_00005-10-3 loss: 0.607066  [  128/  146]
train() client id: f_00005-11-0 loss: 0.626164  [   32/  146]
train() client id: f_00005-11-1 loss: 0.517514  [   64/  146]
train() client id: f_00005-11-2 loss: 0.573869  [   96/  146]
train() client id: f_00005-11-3 loss: 0.515134  [  128/  146]
train() client id: f_00005-12-0 loss: 0.558399  [   32/  146]
train() client id: f_00005-12-1 loss: 0.438756  [   64/  146]
train() client id: f_00005-12-2 loss: 0.488368  [   96/  146]
train() client id: f_00005-12-3 loss: 0.663948  [  128/  146]
train() client id: f_00006-0-0 loss: 0.856548  [   32/   54]
train() client id: f_00006-1-0 loss: 0.840200  [   32/   54]
train() client id: f_00006-2-0 loss: 0.830140  [   32/   54]
train() client id: f_00006-3-0 loss: 0.847647  [   32/   54]
train() client id: f_00006-4-0 loss: 0.827252  [   32/   54]
train() client id: f_00006-5-0 loss: 0.815142  [   32/   54]
train() client id: f_00006-6-0 loss: 0.855078  [   32/   54]
train() client id: f_00006-7-0 loss: 0.865860  [   32/   54]
train() client id: f_00006-8-0 loss: 0.849093  [   32/   54]
train() client id: f_00006-9-0 loss: 0.837578  [   32/   54]
train() client id: f_00006-10-0 loss: 0.888672  [   32/   54]
train() client id: f_00006-11-0 loss: 0.849106  [   32/   54]
train() client id: f_00006-12-0 loss: 0.855399  [   32/   54]
train() client id: f_00007-0-0 loss: 0.635394  [   32/  179]
train() client id: f_00007-0-1 loss: 0.736025  [   64/  179]
train() client id: f_00007-0-2 loss: 0.723540  [   96/  179]
train() client id: f_00007-0-3 loss: 0.600606  [  128/  179]
train() client id: f_00007-0-4 loss: 0.672341  [  160/  179]
train() client id: f_00007-1-0 loss: 0.675838  [   32/  179]
train() client id: f_00007-1-1 loss: 0.570206  [   64/  179]
train() client id: f_00007-1-2 loss: 0.747514  [   96/  179]
train() client id: f_00007-1-3 loss: 0.642381  [  128/  179]
train() client id: f_00007-1-4 loss: 0.638443  [  160/  179]
train() client id: f_00007-2-0 loss: 0.583479  [   32/  179]
train() client id: f_00007-2-1 loss: 0.656091  [   64/  179]
train() client id: f_00007-2-2 loss: 0.690441  [   96/  179]
train() client id: f_00007-2-3 loss: 0.546233  [  128/  179]
train() client id: f_00007-2-4 loss: 0.648600  [  160/  179]
train() client id: f_00007-3-0 loss: 0.511885  [   32/  179]
train() client id: f_00007-3-1 loss: 0.552603  [   64/  179]
train() client id: f_00007-3-2 loss: 0.527398  [   96/  179]
train() client id: f_00007-3-3 loss: 0.684906  [  128/  179]
train() client id: f_00007-3-4 loss: 0.736946  [  160/  179]
train() client id: f_00007-4-0 loss: 0.499086  [   32/  179]
train() client id: f_00007-4-1 loss: 0.518685  [   64/  179]
train() client id: f_00007-4-2 loss: 0.668101  [   96/  179]
train() client id: f_00007-4-3 loss: 0.530990  [  128/  179]
train() client id: f_00007-4-4 loss: 0.727758  [  160/  179]
train() client id: f_00007-5-0 loss: 0.549622  [   32/  179]
train() client id: f_00007-5-1 loss: 0.532911  [   64/  179]
train() client id: f_00007-5-2 loss: 0.558622  [   96/  179]
train() client id: f_00007-5-3 loss: 0.601436  [  128/  179]
train() client id: f_00007-5-4 loss: 0.746382  [  160/  179]
train() client id: f_00007-6-0 loss: 0.625659  [   32/  179]
train() client id: f_00007-6-1 loss: 0.534032  [   64/  179]
train() client id: f_00007-6-2 loss: 0.506259  [   96/  179]
train() client id: f_00007-6-3 loss: 0.695351  [  128/  179]
train() client id: f_00007-6-4 loss: 0.584259  [  160/  179]
train() client id: f_00007-7-0 loss: 0.690390  [   32/  179]
train() client id: f_00007-7-1 loss: 0.536836  [   64/  179]
train() client id: f_00007-7-2 loss: 0.608019  [   96/  179]
train() client id: f_00007-7-3 loss: 0.467449  [  128/  179]
train() client id: f_00007-7-4 loss: 0.486435  [  160/  179]
train() client id: f_00007-8-0 loss: 0.529324  [   32/  179]
train() client id: f_00007-8-1 loss: 0.525879  [   64/  179]
train() client id: f_00007-8-2 loss: 0.531450  [   96/  179]
train() client id: f_00007-8-3 loss: 0.511510  [  128/  179]
train() client id: f_00007-8-4 loss: 0.647515  [  160/  179]
train() client id: f_00007-9-0 loss: 0.539621  [   32/  179]
train() client id: f_00007-9-1 loss: 0.532160  [   64/  179]
train() client id: f_00007-9-2 loss: 0.640779  [   96/  179]
train() client id: f_00007-9-3 loss: 0.554864  [  128/  179]
train() client id: f_00007-9-4 loss: 0.554923  [  160/  179]
train() client id: f_00007-10-0 loss: 0.555305  [   32/  179]
train() client id: f_00007-10-1 loss: 0.583191  [   64/  179]
train() client id: f_00007-10-2 loss: 0.615645  [   96/  179]
train() client id: f_00007-10-3 loss: 0.502031  [  128/  179]
train() client id: f_00007-10-4 loss: 0.509278  [  160/  179]
train() client id: f_00007-11-0 loss: 0.586567  [   32/  179]
train() client id: f_00007-11-1 loss: 0.524531  [   64/  179]
train() client id: f_00007-11-2 loss: 0.818422  [   96/  179]
train() client id: f_00007-11-3 loss: 0.412855  [  128/  179]
train() client id: f_00007-11-4 loss: 0.454508  [  160/  179]
train() client id: f_00007-12-0 loss: 0.585802  [   32/  179]
train() client id: f_00007-12-1 loss: 0.517953  [   64/  179]
train() client id: f_00007-12-2 loss: 0.466551  [   96/  179]
train() client id: f_00007-12-3 loss: 0.614735  [  128/  179]
train() client id: f_00007-12-4 loss: 0.628661  [  160/  179]
train() client id: f_00008-0-0 loss: 0.922615  [   32/  130]
train() client id: f_00008-0-1 loss: 0.868635  [   64/  130]
train() client id: f_00008-0-2 loss: 0.860422  [   96/  130]
train() client id: f_00008-0-3 loss: 0.988682  [  128/  130]
train() client id: f_00008-1-0 loss: 0.941011  [   32/  130]
train() client id: f_00008-1-1 loss: 0.903996  [   64/  130]
train() client id: f_00008-1-2 loss: 0.828161  [   96/  130]
train() client id: f_00008-1-3 loss: 0.958975  [  128/  130]
train() client id: f_00008-2-0 loss: 0.939593  [   32/  130]
train() client id: f_00008-2-1 loss: 0.901040  [   64/  130]
train() client id: f_00008-2-2 loss: 0.923282  [   96/  130]
train() client id: f_00008-2-3 loss: 0.892785  [  128/  130]
train() client id: f_00008-3-0 loss: 0.871372  [   32/  130]
train() client id: f_00008-3-1 loss: 0.978308  [   64/  130]
train() client id: f_00008-3-2 loss: 0.879930  [   96/  130]
train() client id: f_00008-3-3 loss: 0.911908  [  128/  130]
train() client id: f_00008-4-0 loss: 0.925794  [   32/  130]
train() client id: f_00008-4-1 loss: 0.863315  [   64/  130]
train() client id: f_00008-4-2 loss: 0.922486  [   96/  130]
train() client id: f_00008-4-3 loss: 0.913544  [  128/  130]
train() client id: f_00008-5-0 loss: 0.890363  [   32/  130]
train() client id: f_00008-5-1 loss: 0.888826  [   64/  130]
train() client id: f_00008-5-2 loss: 0.986060  [   96/  130]
train() client id: f_00008-5-3 loss: 0.876039  [  128/  130]
train() client id: f_00008-6-0 loss: 0.874647  [   32/  130]
train() client id: f_00008-6-1 loss: 0.934959  [   64/  130]
train() client id: f_00008-6-2 loss: 0.868793  [   96/  130]
train() client id: f_00008-6-3 loss: 0.962806  [  128/  130]
train() client id: f_00008-7-0 loss: 0.954597  [   32/  130]
train() client id: f_00008-7-1 loss: 0.738734  [   64/  130]
train() client id: f_00008-7-2 loss: 1.061437  [   96/  130]
train() client id: f_00008-7-3 loss: 0.898758  [  128/  130]
train() client id: f_00008-8-0 loss: 0.865713  [   32/  130]
train() client id: f_00008-8-1 loss: 0.928471  [   64/  130]
train() client id: f_00008-8-2 loss: 0.895860  [   96/  130]
train() client id: f_00008-8-3 loss: 0.969414  [  128/  130]
train() client id: f_00008-9-0 loss: 0.871810  [   32/  130]
train() client id: f_00008-9-1 loss: 0.951199  [   64/  130]
train() client id: f_00008-9-2 loss: 0.864506  [   96/  130]
train() client id: f_00008-9-3 loss: 0.958210  [  128/  130]
train() client id: f_00008-10-0 loss: 0.880772  [   32/  130]
train() client id: f_00008-10-1 loss: 0.808576  [   64/  130]
train() client id: f_00008-10-2 loss: 1.000477  [   96/  130]
train() client id: f_00008-10-3 loss: 0.933985  [  128/  130]
train() client id: f_00008-11-0 loss: 0.879998  [   32/  130]
train() client id: f_00008-11-1 loss: 0.964447  [   64/  130]
train() client id: f_00008-11-2 loss: 0.790114  [   96/  130]
train() client id: f_00008-11-3 loss: 1.027243  [  128/  130]
train() client id: f_00008-12-0 loss: 0.961623  [   32/  130]
train() client id: f_00008-12-1 loss: 0.869036  [   64/  130]
train() client id: f_00008-12-2 loss: 0.889485  [   96/  130]
train() client id: f_00008-12-3 loss: 0.907408  [  128/  130]
train() client id: f_00009-0-0 loss: 1.203095  [   32/  118]
train() client id: f_00009-0-1 loss: 1.206258  [   64/  118]
train() client id: f_00009-0-2 loss: 1.136329  [   96/  118]
train() client id: f_00009-1-0 loss: 1.183435  [   32/  118]
train() client id: f_00009-1-1 loss: 1.149639  [   64/  118]
train() client id: f_00009-1-2 loss: 1.092394  [   96/  118]
train() client id: f_00009-2-0 loss: 1.075161  [   32/  118]
train() client id: f_00009-2-1 loss: 1.127628  [   64/  118]
train() client id: f_00009-2-2 loss: 1.127430  [   96/  118]
train() client id: f_00009-3-0 loss: 1.132207  [   32/  118]
train() client id: f_00009-3-1 loss: 1.055949  [   64/  118]
train() client id: f_00009-3-2 loss: 1.082917  [   96/  118]
train() client id: f_00009-4-0 loss: 1.091710  [   32/  118]
train() client id: f_00009-4-1 loss: 1.071679  [   64/  118]
train() client id: f_00009-4-2 loss: 1.035689  [   96/  118]
train() client id: f_00009-5-0 loss: 1.048923  [   32/  118]
train() client id: f_00009-5-1 loss: 1.025567  [   64/  118]
train() client id: f_00009-5-2 loss: 1.037226  [   96/  118]
train() client id: f_00009-6-0 loss: 1.053069  [   32/  118]
train() client id: f_00009-6-1 loss: 1.008472  [   64/  118]
train() client id: f_00009-6-2 loss: 0.987758  [   96/  118]
train() client id: f_00009-7-0 loss: 0.956218  [   32/  118]
train() client id: f_00009-7-1 loss: 1.026468  [   64/  118]
train() client id: f_00009-7-2 loss: 1.006881  [   96/  118]
train() client id: f_00009-8-0 loss: 0.983422  [   32/  118]
train() client id: f_00009-8-1 loss: 1.018875  [   64/  118]
train() client id: f_00009-8-2 loss: 0.961613  [   96/  118]
train() client id: f_00009-9-0 loss: 0.952678  [   32/  118]
train() client id: f_00009-9-1 loss: 1.041115  [   64/  118]
train() client id: f_00009-9-2 loss: 0.942494  [   96/  118]
train() client id: f_00009-10-0 loss: 1.112729  [   32/  118]
train() client id: f_00009-10-1 loss: 0.907640  [   64/  118]
train() client id: f_00009-10-2 loss: 0.970870  [   96/  118]
train() client id: f_00009-11-0 loss: 1.089827  [   32/  118]
train() client id: f_00009-11-1 loss: 0.859324  [   64/  118]
train() client id: f_00009-11-2 loss: 0.974538  [   96/  118]
train() client id: f_00009-12-0 loss: 1.016827  [   32/  118]
train() client id: f_00009-12-1 loss: 1.022453  [   64/  118]
train() client id: f_00009-12-2 loss: 0.972393  [   96/  118]
At round 7 accuracy: 0.6312997347480106
At round 7 training accuracy: 0.5747820254862508
At round 7 training loss: 0.8812206227421467
gradient difference: 0.39410749077796936
train() client id: f_00000-0-0 loss: 1.154832  [   32/  126]
train() client id: f_00000-0-1 loss: 1.154441  [   64/  126]
train() client id: f_00000-0-2 loss: 0.968579  [   96/  126]
train() client id: f_00000-1-0 loss: 1.075660  [   32/  126]
train() client id: f_00000-1-1 loss: 0.928906  [   64/  126]
train() client id: f_00000-1-2 loss: 0.933458  [   96/  126]
train() client id: f_00000-2-0 loss: 0.971065  [   32/  126]
train() client id: f_00000-2-1 loss: 0.869585  [   64/  126]
train() client id: f_00000-2-2 loss: 0.887908  [   96/  126]
train() client id: f_00000-3-0 loss: 0.963193  [   32/  126]
train() client id: f_00000-3-1 loss: 0.913780  [   64/  126]
train() client id: f_00000-3-2 loss: 0.878178  [   96/  126]
train() client id: f_00000-4-0 loss: 0.827849  [   32/  126]
train() client id: f_00000-4-1 loss: 0.859246  [   64/  126]
train() client id: f_00000-4-2 loss: 0.887063  [   96/  126]
train() client id: f_00000-5-0 loss: 0.831246  [   32/  126]
train() client id: f_00000-5-1 loss: 0.857826  [   64/  126]
train() client id: f_00000-5-2 loss: 0.877722  [   96/  126]
train() client id: f_00000-6-0 loss: 0.823627  [   32/  126]
train() client id: f_00000-6-1 loss: 0.839729  [   64/  126]
train() client id: f_00000-6-2 loss: 0.760887  [   96/  126]
train() client id: f_00000-7-0 loss: 0.835412  [   32/  126]
train() client id: f_00000-7-1 loss: 0.853223  [   64/  126]
train() client id: f_00000-7-2 loss: 0.839320  [   96/  126]
train() client id: f_00000-8-0 loss: 0.784216  [   32/  126]
train() client id: f_00000-8-1 loss: 0.973756  [   64/  126]
train() client id: f_00000-8-2 loss: 0.756065  [   96/  126]
train() client id: f_00000-9-0 loss: 0.788032  [   32/  126]
train() client id: f_00000-9-1 loss: 0.877563  [   64/  126]
train() client id: f_00000-9-2 loss: 0.940125  [   96/  126]
train() client id: f_00000-10-0 loss: 0.923759  [   32/  126]
train() client id: f_00000-10-1 loss: 0.690601  [   64/  126]
train() client id: f_00000-10-2 loss: 0.905733  [   96/  126]
train() client id: f_00000-11-0 loss: 0.756482  [   32/  126]
train() client id: f_00000-11-1 loss: 0.927526  [   64/  126]
train() client id: f_00000-11-2 loss: 0.799235  [   96/  126]
train() client id: f_00000-12-0 loss: 0.936314  [   32/  126]
train() client id: f_00000-12-1 loss: 0.841622  [   64/  126]
train() client id: f_00000-12-2 loss: 0.652084  [   96/  126]
train() client id: f_00001-0-0 loss: 0.562139  [   32/  265]
train() client id: f_00001-0-1 loss: 0.651923  [   64/  265]
train() client id: f_00001-0-2 loss: 0.628600  [   96/  265]
train() client id: f_00001-0-3 loss: 0.576991  [  128/  265]
train() client id: f_00001-0-4 loss: 0.597471  [  160/  265]
train() client id: f_00001-0-5 loss: 0.555515  [  192/  265]
train() client id: f_00001-0-6 loss: 0.618782  [  224/  265]
train() client id: f_00001-0-7 loss: 0.541264  [  256/  265]
train() client id: f_00001-1-0 loss: 0.574442  [   32/  265]
train() client id: f_00001-1-1 loss: 0.543258  [   64/  265]
train() client id: f_00001-1-2 loss: 0.521566  [   96/  265]
train() client id: f_00001-1-3 loss: 0.503834  [  128/  265]
train() client id: f_00001-1-4 loss: 0.574429  [  160/  265]
train() client id: f_00001-1-5 loss: 0.607396  [  192/  265]
train() client id: f_00001-1-6 loss: 0.626266  [  224/  265]
train() client id: f_00001-1-7 loss: 0.630390  [  256/  265]
train() client id: f_00001-2-0 loss: 0.522049  [   32/  265]
train() client id: f_00001-2-1 loss: 0.542316  [   64/  265]
train() client id: f_00001-2-2 loss: 0.592391  [   96/  265]
train() client id: f_00001-2-3 loss: 0.536924  [  128/  265]
train() client id: f_00001-2-4 loss: 0.557835  [  160/  265]
train() client id: f_00001-2-5 loss: 0.574801  [  192/  265]
train() client id: f_00001-2-6 loss: 0.475824  [  224/  265]
train() client id: f_00001-2-7 loss: 0.643985  [  256/  265]
train() client id: f_00001-3-0 loss: 0.529906  [   32/  265]
train() client id: f_00001-3-1 loss: 0.554227  [   64/  265]
train() client id: f_00001-3-2 loss: 0.591061  [   96/  265]
train() client id: f_00001-3-3 loss: 0.528696  [  128/  265]
train() client id: f_00001-3-4 loss: 0.484826  [  160/  265]
train() client id: f_00001-3-5 loss: 0.484158  [  192/  265]
train() client id: f_00001-3-6 loss: 0.567069  [  224/  265]
train() client id: f_00001-3-7 loss: 0.546589  [  256/  265]
train() client id: f_00001-4-0 loss: 0.567760  [   32/  265]
train() client id: f_00001-4-1 loss: 0.569013  [   64/  265]
train() client id: f_00001-4-2 loss: 0.551900  [   96/  265]
train() client id: f_00001-4-3 loss: 0.453576  [  128/  265]
train() client id: f_00001-4-4 loss: 0.541543  [  160/  265]
train() client id: f_00001-4-5 loss: 0.476117  [  192/  265]
train() client id: f_00001-4-6 loss: 0.598052  [  224/  265]
train() client id: f_00001-4-7 loss: 0.526235  [  256/  265]
train() client id: f_00001-5-0 loss: 0.560803  [   32/  265]
train() client id: f_00001-5-1 loss: 0.527590  [   64/  265]
train() client id: f_00001-5-2 loss: 0.490361  [   96/  265]
train() client id: f_00001-5-3 loss: 0.572803  [  128/  265]
train() client id: f_00001-5-4 loss: 0.482585  [  160/  265]
train() client id: f_00001-5-5 loss: 0.575574  [  192/  265]
train() client id: f_00001-5-6 loss: 0.550719  [  224/  265]
train() client id: f_00001-5-7 loss: 0.499857  [  256/  265]
train() client id: f_00001-6-0 loss: 0.495970  [   32/  265]
train() client id: f_00001-6-1 loss: 0.436851  [   64/  265]
train() client id: f_00001-6-2 loss: 0.596450  [   96/  265]
train() client id: f_00001-6-3 loss: 0.589462  [  128/  265]
train() client id: f_00001-6-4 loss: 0.552467  [  160/  265]
train() client id: f_00001-6-5 loss: 0.455961  [  192/  265]
train() client id: f_00001-6-6 loss: 0.530586  [  224/  265]
train() client id: f_00001-6-7 loss: 0.560552  [  256/  265]
train() client id: f_00001-7-0 loss: 0.461158  [   32/  265]
train() client id: f_00001-7-1 loss: 0.534357  [   64/  265]
train() client id: f_00001-7-2 loss: 0.451947  [   96/  265]
train() client id: f_00001-7-3 loss: 0.508592  [  128/  265]
train() client id: f_00001-7-4 loss: 0.535870  [  160/  265]
train() client id: f_00001-7-5 loss: 0.571010  [  192/  265]
train() client id: f_00001-7-6 loss: 0.499247  [  224/  265]
train() client id: f_00001-7-7 loss: 0.543618  [  256/  265]
train() client id: f_00001-8-0 loss: 0.659468  [   32/  265]
train() client id: f_00001-8-1 loss: 0.487592  [   64/  265]
train() client id: f_00001-8-2 loss: 0.470568  [   96/  265]
train() client id: f_00001-8-3 loss: 0.510959  [  128/  265]
train() client id: f_00001-8-4 loss: 0.448273  [  160/  265]
train() client id: f_00001-8-5 loss: 0.569256  [  192/  265]
train() client id: f_00001-8-6 loss: 0.536244  [  224/  265]
train() client id: f_00001-8-7 loss: 0.452630  [  256/  265]
train() client id: f_00001-9-0 loss: 0.460696  [   32/  265]
train() client id: f_00001-9-1 loss: 0.478942  [   64/  265]
train() client id: f_00001-9-2 loss: 0.576646  [   96/  265]
train() client id: f_00001-9-3 loss: 0.492813  [  128/  265]
train() client id: f_00001-9-4 loss: 0.540376  [  160/  265]
train() client id: f_00001-9-5 loss: 0.498966  [  192/  265]
train() client id: f_00001-9-6 loss: 0.603610  [  224/  265]
train() client id: f_00001-9-7 loss: 0.526781  [  256/  265]
train() client id: f_00001-10-0 loss: 0.494561  [   32/  265]
train() client id: f_00001-10-1 loss: 0.560414  [   64/  265]
train() client id: f_00001-10-2 loss: 0.503476  [   96/  265]
train() client id: f_00001-10-3 loss: 0.465982  [  128/  265]
train() client id: f_00001-10-4 loss: 0.552847  [  160/  265]
train() client id: f_00001-10-5 loss: 0.499588  [  192/  265]
train() client id: f_00001-10-6 loss: 0.455090  [  224/  265]
train() client id: f_00001-10-7 loss: 0.644887  [  256/  265]
train() client id: f_00001-11-0 loss: 0.582124  [   32/  265]
train() client id: f_00001-11-1 loss: 0.570808  [   64/  265]
train() client id: f_00001-11-2 loss: 0.473997  [   96/  265]
train() client id: f_00001-11-3 loss: 0.464351  [  128/  265]
train() client id: f_00001-11-4 loss: 0.638669  [  160/  265]
train() client id: f_00001-11-5 loss: 0.489021  [  192/  265]
train() client id: f_00001-11-6 loss: 0.435007  [  224/  265]
train() client id: f_00001-11-7 loss: 0.438071  [  256/  265]
train() client id: f_00001-12-0 loss: 0.452269  [   32/  265]
train() client id: f_00001-12-1 loss: 0.549666  [   64/  265]
train() client id: f_00001-12-2 loss: 0.477825  [   96/  265]
train() client id: f_00001-12-3 loss: 0.485296  [  128/  265]
train() client id: f_00001-12-4 loss: 0.443863  [  160/  265]
train() client id: f_00001-12-5 loss: 0.485197  [  192/  265]
train() client id: f_00001-12-6 loss: 0.473691  [  224/  265]
train() client id: f_00001-12-7 loss: 0.738179  [  256/  265]
train() client id: f_00002-0-0 loss: 1.387126  [   32/  124]
train() client id: f_00002-0-1 loss: 1.277328  [   64/  124]
train() client id: f_00002-0-2 loss: 1.300863  [   96/  124]
train() client id: f_00002-1-0 loss: 1.294300  [   32/  124]
train() client id: f_00002-1-1 loss: 1.232917  [   64/  124]
train() client id: f_00002-1-2 loss: 1.331045  [   96/  124]
train() client id: f_00002-2-0 loss: 1.240587  [   32/  124]
train() client id: f_00002-2-1 loss: 1.221859  [   64/  124]
train() client id: f_00002-2-2 loss: 1.179379  [   96/  124]
train() client id: f_00002-3-0 loss: 1.176272  [   32/  124]
train() client id: f_00002-3-1 loss: 1.238457  [   64/  124]
train() client id: f_00002-3-2 loss: 1.183485  [   96/  124]
train() client id: f_00002-4-0 loss: 1.128182  [   32/  124]
train() client id: f_00002-4-1 loss: 1.280716  [   64/  124]
train() client id: f_00002-4-2 loss: 1.149014  [   96/  124]
train() client id: f_00002-5-0 loss: 1.172770  [   32/  124]
train() client id: f_00002-5-1 loss: 1.127573  [   64/  124]
train() client id: f_00002-5-2 loss: 1.124774  [   96/  124]
train() client id: f_00002-6-0 loss: 1.228438  [   32/  124]
train() client id: f_00002-6-1 loss: 1.173839  [   64/  124]
train() client id: f_00002-6-2 loss: 1.013931  [   96/  124]
train() client id: f_00002-7-0 loss: 1.161213  [   32/  124]
train() client id: f_00002-7-1 loss: 1.172081  [   64/  124]
train() client id: f_00002-7-2 loss: 1.013754  [   96/  124]
train() client id: f_00002-8-0 loss: 1.125157  [   32/  124]
train() client id: f_00002-8-1 loss: 1.231031  [   64/  124]
train() client id: f_00002-8-2 loss: 1.029312  [   96/  124]
train() client id: f_00002-9-0 loss: 0.984635  [   32/  124]
train() client id: f_00002-9-1 loss: 1.125649  [   64/  124]
train() client id: f_00002-9-2 loss: 1.143026  [   96/  124]
train() client id: f_00002-10-0 loss: 1.047100  [   32/  124]
train() client id: f_00002-10-1 loss: 1.130670  [   64/  124]
train() client id: f_00002-10-2 loss: 1.041753  [   96/  124]
train() client id: f_00002-11-0 loss: 1.023488  [   32/  124]
train() client id: f_00002-11-1 loss: 1.095594  [   64/  124]
train() client id: f_00002-11-2 loss: 1.107631  [   96/  124]
train() client id: f_00002-12-0 loss: 1.160238  [   32/  124]
train() client id: f_00002-12-1 loss: 1.006096  [   64/  124]
train() client id: f_00002-12-2 loss: 1.098040  [   96/  124]
train() client id: f_00003-0-0 loss: 0.915808  [   32/   43]
train() client id: f_00003-1-0 loss: 0.971439  [   32/   43]
train() client id: f_00003-2-0 loss: 0.978713  [   32/   43]
train() client id: f_00003-3-0 loss: 0.994950  [   32/   43]
train() client id: f_00003-4-0 loss: 1.022048  [   32/   43]
train() client id: f_00003-5-0 loss: 1.014574  [   32/   43]
train() client id: f_00003-6-0 loss: 0.886948  [   32/   43]
train() client id: f_00003-7-0 loss: 0.978931  [   32/   43]
train() client id: f_00003-8-0 loss: 0.925435  [   32/   43]
train() client id: f_00003-9-0 loss: 0.917640  [   32/   43]
train() client id: f_00003-10-0 loss: 1.057937  [   32/   43]
train() client id: f_00003-11-0 loss: 0.920781  [   32/   43]
train() client id: f_00003-12-0 loss: 0.998614  [   32/   43]
train() client id: f_00004-0-0 loss: 0.926325  [   32/  306]
train() client id: f_00004-0-1 loss: 0.812381  [   64/  306]
train() client id: f_00004-0-2 loss: 0.855587  [   96/  306]
train() client id: f_00004-0-3 loss: 0.824219  [  128/  306]
train() client id: f_00004-0-4 loss: 0.906213  [  160/  306]
train() client id: f_00004-0-5 loss: 0.972236  [  192/  306]
train() client id: f_00004-0-6 loss: 0.849668  [  224/  306]
train() client id: f_00004-0-7 loss: 0.850218  [  256/  306]
train() client id: f_00004-0-8 loss: 0.816887  [  288/  306]
train() client id: f_00004-1-0 loss: 0.831832  [   32/  306]
train() client id: f_00004-1-1 loss: 0.752022  [   64/  306]
train() client id: f_00004-1-2 loss: 0.916268  [   96/  306]
train() client id: f_00004-1-3 loss: 0.763451  [  128/  306]
train() client id: f_00004-1-4 loss: 0.916675  [  160/  306]
train() client id: f_00004-1-5 loss: 0.833914  [  192/  306]
train() client id: f_00004-1-6 loss: 0.855274  [  224/  306]
train() client id: f_00004-1-7 loss: 0.930946  [  256/  306]
train() client id: f_00004-1-8 loss: 0.992442  [  288/  306]
train() client id: f_00004-2-0 loss: 0.952129  [   32/  306]
train() client id: f_00004-2-1 loss: 0.839324  [   64/  306]
train() client id: f_00004-2-2 loss: 0.942619  [   96/  306]
train() client id: f_00004-2-3 loss: 0.816687  [  128/  306]
train() client id: f_00004-2-4 loss: 0.771265  [  160/  306]
train() client id: f_00004-2-5 loss: 0.791596  [  192/  306]
train() client id: f_00004-2-6 loss: 0.893872  [  224/  306]
train() client id: f_00004-2-7 loss: 1.023241  [  256/  306]
train() client id: f_00004-2-8 loss: 0.791831  [  288/  306]
train() client id: f_00004-3-0 loss: 0.857777  [   32/  306]
train() client id: f_00004-3-1 loss: 0.880299  [   64/  306]
train() client id: f_00004-3-2 loss: 0.928403  [   96/  306]
train() client id: f_00004-3-3 loss: 0.697971  [  128/  306]
train() client id: f_00004-3-4 loss: 0.929763  [  160/  306]
train() client id: f_00004-3-5 loss: 0.865383  [  192/  306]
train() client id: f_00004-3-6 loss: 0.950800  [  224/  306]
train() client id: f_00004-3-7 loss: 0.780620  [  256/  306]
train() client id: f_00004-3-8 loss: 0.823170  [  288/  306]
train() client id: f_00004-4-0 loss: 0.709241  [   32/  306]
train() client id: f_00004-4-1 loss: 0.887861  [   64/  306]
train() client id: f_00004-4-2 loss: 0.839112  [   96/  306]
train() client id: f_00004-4-3 loss: 0.901212  [  128/  306]
train() client id: f_00004-4-4 loss: 0.955285  [  160/  306]
train() client id: f_00004-4-5 loss: 0.946549  [  192/  306]
train() client id: f_00004-4-6 loss: 0.813008  [  224/  306]
train() client id: f_00004-4-7 loss: 0.814996  [  256/  306]
train() client id: f_00004-4-8 loss: 0.904323  [  288/  306]
train() client id: f_00004-5-0 loss: 0.890464  [   32/  306]
train() client id: f_00004-5-1 loss: 0.798974  [   64/  306]
train() client id: f_00004-5-2 loss: 0.955440  [   96/  306]
train() client id: f_00004-5-3 loss: 0.921383  [  128/  306]
train() client id: f_00004-5-4 loss: 0.860769  [  160/  306]
train() client id: f_00004-5-5 loss: 0.791873  [  192/  306]
train() client id: f_00004-5-6 loss: 0.851139  [  224/  306]
train() client id: f_00004-5-7 loss: 0.825873  [  256/  306]
train() client id: f_00004-5-8 loss: 0.915277  [  288/  306]
train() client id: f_00004-6-0 loss: 0.904296  [   32/  306]
train() client id: f_00004-6-1 loss: 0.817168  [   64/  306]
train() client id: f_00004-6-2 loss: 0.917293  [   96/  306]
train() client id: f_00004-6-3 loss: 0.849296  [  128/  306]
train() client id: f_00004-6-4 loss: 0.911027  [  160/  306]
train() client id: f_00004-6-5 loss: 0.779931  [  192/  306]
train() client id: f_00004-6-6 loss: 0.866637  [  224/  306]
train() client id: f_00004-6-7 loss: 0.924906  [  256/  306]
train() client id: f_00004-6-8 loss: 0.847306  [  288/  306]
train() client id: f_00004-7-0 loss: 0.790781  [   32/  306]
train() client id: f_00004-7-1 loss: 0.924534  [   64/  306]
train() client id: f_00004-7-2 loss: 0.839667  [   96/  306]
train() client id: f_00004-7-3 loss: 0.884200  [  128/  306]
train() client id: f_00004-7-4 loss: 0.821855  [  160/  306]
train() client id: f_00004-7-5 loss: 0.849948  [  192/  306]
train() client id: f_00004-7-6 loss: 0.912912  [  224/  306]
train() client id: f_00004-7-7 loss: 0.887311  [  256/  306]
train() client id: f_00004-7-8 loss: 0.878957  [  288/  306]
train() client id: f_00004-8-0 loss: 0.832963  [   32/  306]
train() client id: f_00004-8-1 loss: 0.835356  [   64/  306]
train() client id: f_00004-8-2 loss: 0.876383  [   96/  306]
train() client id: f_00004-8-3 loss: 0.875201  [  128/  306]
train() client id: f_00004-8-4 loss: 0.879987  [  160/  306]
train() client id: f_00004-8-5 loss: 0.859763  [  192/  306]
train() client id: f_00004-8-6 loss: 0.920849  [  224/  306]
train() client id: f_00004-8-7 loss: 0.800037  [  256/  306]
train() client id: f_00004-8-8 loss: 0.827595  [  288/  306]
train() client id: f_00004-9-0 loss: 0.791210  [   32/  306]
train() client id: f_00004-9-1 loss: 0.940742  [   64/  306]
train() client id: f_00004-9-2 loss: 0.921090  [   96/  306]
train() client id: f_00004-9-3 loss: 0.871920  [  128/  306]
train() client id: f_00004-9-4 loss: 0.893242  [  160/  306]
train() client id: f_00004-9-5 loss: 0.817269  [  192/  306]
train() client id: f_00004-9-6 loss: 0.753939  [  224/  306]
train() client id: f_00004-9-7 loss: 0.838395  [  256/  306]
train() client id: f_00004-9-8 loss: 0.934609  [  288/  306]
train() client id: f_00004-10-0 loss: 0.849510  [   32/  306]
train() client id: f_00004-10-1 loss: 0.868613  [   64/  306]
train() client id: f_00004-10-2 loss: 0.866064  [   96/  306]
train() client id: f_00004-10-3 loss: 0.753852  [  128/  306]
train() client id: f_00004-10-4 loss: 0.929600  [  160/  306]
train() client id: f_00004-10-5 loss: 0.826651  [  192/  306]
train() client id: f_00004-10-6 loss: 0.956125  [  224/  306]
train() client id: f_00004-10-7 loss: 0.844595  [  256/  306]
train() client id: f_00004-10-8 loss: 0.852063  [  288/  306]
train() client id: f_00004-11-0 loss: 0.830673  [   32/  306]
train() client id: f_00004-11-1 loss: 1.045185  [   64/  306]
train() client id: f_00004-11-2 loss: 0.786274  [   96/  306]
train() client id: f_00004-11-3 loss: 0.779894  [  128/  306]
train() client id: f_00004-11-4 loss: 0.755305  [  160/  306]
train() client id: f_00004-11-5 loss: 0.787365  [  192/  306]
train() client id: f_00004-11-6 loss: 0.923896  [  224/  306]
train() client id: f_00004-11-7 loss: 0.780449  [  256/  306]
train() client id: f_00004-11-8 loss: 1.015835  [  288/  306]
train() client id: f_00004-12-0 loss: 0.869756  [   32/  306]
train() client id: f_00004-12-1 loss: 0.895175  [   64/  306]
train() client id: f_00004-12-2 loss: 0.816371  [   96/  306]
train() client id: f_00004-12-3 loss: 0.820299  [  128/  306]
train() client id: f_00004-12-4 loss: 0.828905  [  160/  306]
train() client id: f_00004-12-5 loss: 0.803203  [  192/  306]
train() client id: f_00004-12-6 loss: 0.771712  [  224/  306]
train() client id: f_00004-12-7 loss: 0.881830  [  256/  306]
train() client id: f_00004-12-8 loss: 1.012797  [  288/  306]
train() client id: f_00005-0-0 loss: 0.709048  [   32/  146]
train() client id: f_00005-0-1 loss: 0.731189  [   64/  146]
train() client id: f_00005-0-2 loss: 0.922935  [   96/  146]
train() client id: f_00005-0-3 loss: 0.809734  [  128/  146]
train() client id: f_00005-1-0 loss: 0.704519  [   32/  146]
train() client id: f_00005-1-1 loss: 0.939753  [   64/  146]
train() client id: f_00005-1-2 loss: 0.693481  [   96/  146]
train() client id: f_00005-1-3 loss: 0.720085  [  128/  146]
train() client id: f_00005-2-0 loss: 0.851424  [   32/  146]
train() client id: f_00005-2-1 loss: 0.715089  [   64/  146]
train() client id: f_00005-2-2 loss: 0.726654  [   96/  146]
train() client id: f_00005-2-3 loss: 0.749998  [  128/  146]
train() client id: f_00005-3-0 loss: 0.780220  [   32/  146]
train() client id: f_00005-3-1 loss: 0.651468  [   64/  146]
train() client id: f_00005-3-2 loss: 0.834260  [   96/  146]
train() client id: f_00005-3-3 loss: 0.760375  [  128/  146]
train() client id: f_00005-4-0 loss: 0.739904  [   32/  146]
train() client id: f_00005-4-1 loss: 0.639701  [   64/  146]
train() client id: f_00005-4-2 loss: 0.745361  [   96/  146]
train() client id: f_00005-4-3 loss: 0.851187  [  128/  146]
train() client id: f_00005-5-0 loss: 0.769238  [   32/  146]
train() client id: f_00005-5-1 loss: 0.621146  [   64/  146]
train() client id: f_00005-5-2 loss: 0.627384  [   96/  146]
train() client id: f_00005-5-3 loss: 0.721204  [  128/  146]
train() client id: f_00005-6-0 loss: 0.716951  [   32/  146]
train() client id: f_00005-6-1 loss: 0.627933  [   64/  146]
train() client id: f_00005-6-2 loss: 0.756427  [   96/  146]
train() client id: f_00005-6-3 loss: 0.771960  [  128/  146]
train() client id: f_00005-7-0 loss: 0.707573  [   32/  146]
train() client id: f_00005-7-1 loss: 0.687732  [   64/  146]
train() client id: f_00005-7-2 loss: 0.635972  [   96/  146]
train() client id: f_00005-7-3 loss: 0.656100  [  128/  146]
train() client id: f_00005-8-0 loss: 0.724388  [   32/  146]
train() client id: f_00005-8-1 loss: 0.678430  [   64/  146]
train() client id: f_00005-8-2 loss: 0.599206  [   96/  146]
train() client id: f_00005-8-3 loss: 0.786222  [  128/  146]
train() client id: f_00005-9-0 loss: 0.706410  [   32/  146]
train() client id: f_00005-9-1 loss: 0.706867  [   64/  146]
train() client id: f_00005-9-2 loss: 0.680875  [   96/  146]
train() client id: f_00005-9-3 loss: 0.619411  [  128/  146]
train() client id: f_00005-10-0 loss: 0.776922  [   32/  146]
train() client id: f_00005-10-1 loss: 0.577842  [   64/  146]
train() client id: f_00005-10-2 loss: 0.620988  [   96/  146]
train() client id: f_00005-10-3 loss: 0.838803  [  128/  146]
train() client id: f_00005-11-0 loss: 0.684696  [   32/  146]
train() client id: f_00005-11-1 loss: 0.716876  [   64/  146]
train() client id: f_00005-11-2 loss: 0.395984  [   96/  146]
train() client id: f_00005-11-3 loss: 0.767708  [  128/  146]
train() client id: f_00005-12-0 loss: 0.578084  [   32/  146]
train() client id: f_00005-12-1 loss: 0.773669  [   64/  146]
train() client id: f_00005-12-2 loss: 0.735336  [   96/  146]
train() client id: f_00005-12-3 loss: 0.636992  [  128/  146]
train() client id: f_00006-0-0 loss: 0.799725  [   32/   54]
train() client id: f_00006-1-0 loss: 0.793502  [   32/   54]
train() client id: f_00006-2-0 loss: 0.765923  [   32/   54]
train() client id: f_00006-3-0 loss: 0.755352  [   32/   54]
train() client id: f_00006-4-0 loss: 0.765237  [   32/   54]
train() client id: f_00006-5-0 loss: 0.775342  [   32/   54]
train() client id: f_00006-6-0 loss: 0.785726  [   32/   54]
train() client id: f_00006-7-0 loss: 0.781227  [   32/   54]
train() client id: f_00006-8-0 loss: 0.776349  [   32/   54]
train() client id: f_00006-9-0 loss: 0.789456  [   32/   54]
train() client id: f_00006-10-0 loss: 0.751620  [   32/   54]
train() client id: f_00006-11-0 loss: 0.807407  [   32/   54]
train() client id: f_00006-12-0 loss: 0.781083  [   32/   54]
train() client id: f_00007-0-0 loss: 0.612044  [   32/  179]
train() client id: f_00007-0-1 loss: 0.611251  [   64/  179]
train() client id: f_00007-0-2 loss: 0.565836  [   96/  179]
train() client id: f_00007-0-3 loss: 0.526320  [  128/  179]
train() client id: f_00007-0-4 loss: 0.729765  [  160/  179]
train() client id: f_00007-1-0 loss: 0.511436  [   32/  179]
train() client id: f_00007-1-1 loss: 0.569717  [   64/  179]
train() client id: f_00007-1-2 loss: 0.745326  [   96/  179]
train() client id: f_00007-1-3 loss: 0.602911  [  128/  179]
train() client id: f_00007-1-4 loss: 0.565554  [  160/  179]
train() client id: f_00007-2-0 loss: 0.628552  [   32/  179]
train() client id: f_00007-2-1 loss: 0.496221  [   64/  179]
train() client id: f_00007-2-2 loss: 0.611273  [   96/  179]
train() client id: f_00007-2-3 loss: 0.579720  [  128/  179]
train() client id: f_00007-2-4 loss: 0.543707  [  160/  179]
train() client id: f_00007-3-0 loss: 0.769688  [   32/  179]
train() client id: f_00007-3-1 loss: 0.516757  [   64/  179]
train() client id: f_00007-3-2 loss: 0.496933  [   96/  179]
train() client id: f_00007-3-3 loss: 0.585675  [  128/  179]
train() client id: f_00007-3-4 loss: 0.514508  [  160/  179]
train() client id: f_00007-4-0 loss: 0.515344  [   32/  179]
train() client id: f_00007-4-1 loss: 0.702740  [   64/  179]
train() client id: f_00007-4-2 loss: 0.598307  [   96/  179]
train() client id: f_00007-4-3 loss: 0.423850  [  128/  179]
train() client id: f_00007-4-4 loss: 0.566424  [  160/  179]
train() client id: f_00007-5-0 loss: 0.576620  [   32/  179]
train() client id: f_00007-5-1 loss: 0.530077  [   64/  179]
train() client id: f_00007-5-2 loss: 0.547985  [   96/  179]
train() client id: f_00007-5-3 loss: 0.568656  [  128/  179]
train() client id: f_00007-5-4 loss: 0.551426  [  160/  179]
train() client id: f_00007-6-0 loss: 0.584894  [   32/  179]
train() client id: f_00007-6-1 loss: 0.780603  [   64/  179]
train() client id: f_00007-6-2 loss: 0.467675  [   96/  179]
train() client id: f_00007-6-3 loss: 0.489347  [  128/  179]
train() client id: f_00007-6-4 loss: 0.428932  [  160/  179]
train() client id: f_00007-7-0 loss: 0.430279  [   32/  179]
train() client id: f_00007-7-1 loss: 0.557573  [   64/  179]
train() client id: f_00007-7-2 loss: 0.560193  [   96/  179]
train() client id: f_00007-7-3 loss: 0.396310  [  128/  179]
train() client id: f_00007-7-4 loss: 0.645020  [  160/  179]
train() client id: f_00007-8-0 loss: 0.494108  [   32/  179]
train() client id: f_00007-8-1 loss: 0.472877  [   64/  179]
train() client id: f_00007-8-2 loss: 0.422667  [   96/  179]
train() client id: f_00007-8-3 loss: 0.535505  [  128/  179]
train() client id: f_00007-8-4 loss: 0.558324  [  160/  179]
train() client id: f_00007-9-0 loss: 0.494562  [   32/  179]
train() client id: f_00007-9-1 loss: 0.542141  [   64/  179]
train() client id: f_00007-9-2 loss: 0.408569  [   96/  179]
train() client id: f_00007-9-3 loss: 0.596761  [  128/  179]
train() client id: f_00007-9-4 loss: 0.619478  [  160/  179]
train() client id: f_00007-10-0 loss: 0.403781  [   32/  179]
train() client id: f_00007-10-1 loss: 0.498538  [   64/  179]
train() client id: f_00007-10-2 loss: 0.409817  [   96/  179]
train() client id: f_00007-10-3 loss: 0.574717  [  128/  179]
train() client id: f_00007-10-4 loss: 0.714797  [  160/  179]
train() client id: f_00007-11-0 loss: 0.488859  [   32/  179]
train() client id: f_00007-11-1 loss: 0.407912  [   64/  179]
train() client id: f_00007-11-2 loss: 0.533229  [   96/  179]
train() client id: f_00007-11-3 loss: 0.691149  [  128/  179]
train() client id: f_00007-11-4 loss: 0.461001  [  160/  179]
train() client id: f_00007-12-0 loss: 0.391680  [   32/  179]
train() client id: f_00007-12-1 loss: 0.475524  [   64/  179]
train() client id: f_00007-12-2 loss: 0.384422  [   96/  179]
train() client id: f_00007-12-3 loss: 0.632473  [  128/  179]
train() client id: f_00007-12-4 loss: 0.676781  [  160/  179]
train() client id: f_00008-0-0 loss: 0.804508  [   32/  130]
train() client id: f_00008-0-1 loss: 0.874596  [   64/  130]
train() client id: f_00008-0-2 loss: 0.927145  [   96/  130]
train() client id: f_00008-0-3 loss: 0.841994  [  128/  130]
train() client id: f_00008-1-0 loss: 0.886921  [   32/  130]
train() client id: f_00008-1-1 loss: 0.769153  [   64/  130]
train() client id: f_00008-1-2 loss: 0.894495  [   96/  130]
train() client id: f_00008-1-3 loss: 0.880126  [  128/  130]
train() client id: f_00008-2-0 loss: 0.838469  [   32/  130]
train() client id: f_00008-2-1 loss: 0.836701  [   64/  130]
train() client id: f_00008-2-2 loss: 0.962883  [   96/  130]
train() client id: f_00008-2-3 loss: 0.792911  [  128/  130]
train() client id: f_00008-3-0 loss: 0.902442  [   32/  130]
train() client id: f_00008-3-1 loss: 0.763716  [   64/  130]
train() client id: f_00008-3-2 loss: 0.814445  [   96/  130]
train() client id: f_00008-3-3 loss: 0.937910  [  128/  130]
train() client id: f_00008-4-0 loss: 0.830581  [   32/  130]
train() client id: f_00008-4-1 loss: 0.812805  [   64/  130]
train() client id: f_00008-4-2 loss: 0.877344  [   96/  130]
train() client id: f_00008-4-3 loss: 0.870646  [  128/  130]
train() client id: f_00008-5-0 loss: 0.806396  [   32/  130]
train() client id: f_00008-5-1 loss: 0.840051  [   64/  130]
train() client id: f_00008-5-2 loss: 0.865516  [   96/  130]
train() client id: f_00008-5-3 loss: 0.880561  [  128/  130]
train() client id: f_00008-6-0 loss: 0.843765  [   32/  130]
train() client id: f_00008-6-1 loss: 0.777652  [   64/  130]
train() client id: f_00008-6-2 loss: 0.816849  [   96/  130]
train() client id: f_00008-6-3 loss: 0.943103  [  128/  130]
train() client id: f_00008-7-0 loss: 0.826040  [   32/  130]
train() client id: f_00008-7-1 loss: 0.891753  [   64/  130]
train() client id: f_00008-7-2 loss: 0.759716  [   96/  130]
train() client id: f_00008-7-3 loss: 0.940855  [  128/  130]
train() client id: f_00008-8-0 loss: 0.755417  [   32/  130]
train() client id: f_00008-8-1 loss: 0.787193  [   64/  130]
train() client id: f_00008-8-2 loss: 1.033770  [   96/  130]
train() client id: f_00008-8-3 loss: 0.810283  [  128/  130]
train() client id: f_00008-9-0 loss: 0.909566  [   32/  130]
train() client id: f_00008-9-1 loss: 0.921984  [   64/  130]
train() client id: f_00008-9-2 loss: 0.823160  [   96/  130]
train() client id: f_00008-9-3 loss: 0.748458  [  128/  130]
train() client id: f_00008-10-0 loss: 0.916091  [   32/  130]
train() client id: f_00008-10-1 loss: 0.800605  [   64/  130]
train() client id: f_00008-10-2 loss: 0.927590  [   96/  130]
train() client id: f_00008-10-3 loss: 0.775990  [  128/  130]
train() client id: f_00008-11-0 loss: 0.784087  [   32/  130]
train() client id: f_00008-11-1 loss: 0.822185  [   64/  130]
train() client id: f_00008-11-2 loss: 0.978590  [   96/  130]
train() client id: f_00008-11-3 loss: 0.807835  [  128/  130]
train() client id: f_00008-12-0 loss: 0.767980  [   32/  130]
train() client id: f_00008-12-1 loss: 0.858866  [   64/  130]
train() client id: f_00008-12-2 loss: 0.922981  [   96/  130]
train() client id: f_00008-12-3 loss: 0.867692  [  128/  130]
train() client id: f_00009-0-0 loss: 1.156210  [   32/  118]
train() client id: f_00009-0-1 loss: 1.147572  [   64/  118]
train() client id: f_00009-0-2 loss: 1.211675  [   96/  118]
train() client id: f_00009-1-0 loss: 1.188090  [   32/  118]
train() client id: f_00009-1-1 loss: 1.062083  [   64/  118]
train() client id: f_00009-1-2 loss: 1.137375  [   96/  118]
train() client id: f_00009-2-0 loss: 1.077423  [   32/  118]
train() client id: f_00009-2-1 loss: 1.156071  [   64/  118]
train() client id: f_00009-2-2 loss: 1.099114  [   96/  118]
train() client id: f_00009-3-0 loss: 1.102407  [   32/  118]
train() client id: f_00009-3-1 loss: 1.038662  [   64/  118]
train() client id: f_00009-3-2 loss: 1.046471  [   96/  118]
train() client id: f_00009-4-0 loss: 1.011279  [   32/  118]
train() client id: f_00009-4-1 loss: 1.081147  [   64/  118]
train() client id: f_00009-4-2 loss: 0.989659  [   96/  118]
train() client id: f_00009-5-0 loss: 1.045196  [   32/  118]
train() client id: f_00009-5-1 loss: 0.978299  [   64/  118]
train() client id: f_00009-5-2 loss: 1.026282  [   96/  118]
train() client id: f_00009-6-0 loss: 0.986879  [   32/  118]
train() client id: f_00009-6-1 loss: 0.988481  [   64/  118]
train() client id: f_00009-6-2 loss: 1.004791  [   96/  118]
train() client id: f_00009-7-0 loss: 0.995794  [   32/  118]
train() client id: f_00009-7-1 loss: 0.964444  [   64/  118]
train() client id: f_00009-7-2 loss: 1.014152  [   96/  118]
train() client id: f_00009-8-0 loss: 0.970244  [   32/  118]
train() client id: f_00009-8-1 loss: 1.017793  [   64/  118]
train() client id: f_00009-8-2 loss: 0.944713  [   96/  118]
train() client id: f_00009-9-0 loss: 1.002618  [   32/  118]
train() client id: f_00009-9-1 loss: 1.053774  [   64/  118]
train() client id: f_00009-9-2 loss: 0.879333  [   96/  118]
train() client id: f_00009-10-0 loss: 0.931177  [   32/  118]
train() client id: f_00009-10-1 loss: 0.971760  [   64/  118]
train() client id: f_00009-10-2 loss: 0.918354  [   96/  118]
train() client id: f_00009-11-0 loss: 0.950342  [   32/  118]
train() client id: f_00009-11-1 loss: 0.886767  [   64/  118]
train() client id: f_00009-11-2 loss: 0.947061  [   96/  118]
train() client id: f_00009-12-0 loss: 0.990061  [   32/  118]
train() client id: f_00009-12-1 loss: 0.926720  [   64/  118]
train() client id: f_00009-12-2 loss: 0.927668  [   96/  118]
At round 8 accuracy: 0.6339522546419099
At round 8 training accuracy: 0.5788061703554661
At round 8 training loss: 0.8690279528750168
gradient difference: 0.4468730390071869
train() client id: f_00000-0-0 loss: 1.023376  [   32/  126]
train() client id: f_00000-0-1 loss: 1.170789  [   64/  126]
train() client id: f_00000-0-2 loss: 1.018126  [   96/  126]
train() client id: f_00000-1-0 loss: 1.066262  [   32/  126]
train() client id: f_00000-1-1 loss: 1.125224  [   64/  126]
train() client id: f_00000-1-2 loss: 0.952778  [   96/  126]
train() client id: f_00000-2-0 loss: 0.990767  [   32/  126]
train() client id: f_00000-2-1 loss: 0.973695  [   64/  126]
train() client id: f_00000-2-2 loss: 1.024626  [   96/  126]
train() client id: f_00000-3-0 loss: 1.120247  [   32/  126]
train() client id: f_00000-3-1 loss: 0.983251  [   64/  126]
train() client id: f_00000-3-2 loss: 0.972155  [   96/  126]
train() client id: f_00000-4-0 loss: 1.026403  [   32/  126]
train() client id: f_00000-4-1 loss: 1.039319  [   64/  126]
train() client id: f_00000-4-2 loss: 0.929194  [   96/  126]
train() client id: f_00000-5-0 loss: 0.929203  [   32/  126]
train() client id: f_00000-5-1 loss: 0.988282  [   64/  126]
train() client id: f_00000-5-2 loss: 1.021748  [   96/  126]
train() client id: f_00000-6-0 loss: 1.041727  [   32/  126]
train() client id: f_00000-6-1 loss: 0.915601  [   64/  126]
train() client id: f_00000-6-2 loss: 0.948977  [   96/  126]
train() client id: f_00000-7-0 loss: 0.997645  [   32/  126]
train() client id: f_00000-7-1 loss: 0.965011  [   64/  126]
train() client id: f_00000-7-2 loss: 1.009525  [   96/  126]
train() client id: f_00000-8-0 loss: 1.077066  [   32/  126]
train() client id: f_00000-8-1 loss: 0.912972  [   64/  126]
train() client id: f_00000-8-2 loss: 0.957104  [   96/  126]
train() client id: f_00000-9-0 loss: 0.835958  [   32/  126]
train() client id: f_00000-9-1 loss: 0.904141  [   64/  126]
train() client id: f_00000-9-2 loss: 1.080728  [   96/  126]
train() client id: f_00000-10-0 loss: 0.901111  [   32/  126]
train() client id: f_00000-10-1 loss: 1.133071  [   64/  126]
train() client id: f_00000-10-2 loss: 0.987475  [   96/  126]
train() client id: f_00000-11-0 loss: 0.926173  [   32/  126]
train() client id: f_00000-11-1 loss: 1.016171  [   64/  126]
train() client id: f_00000-11-2 loss: 1.052306  [   96/  126]
train() client id: f_00000-12-0 loss: 1.046236  [   32/  126]
train() client id: f_00000-12-1 loss: 1.042275  [   64/  126]
train() client id: f_00000-12-2 loss: 0.933118  [   96/  126]
train() client id: f_00001-0-0 loss: 0.526428  [   32/  265]
train() client id: f_00001-0-1 loss: 0.406421  [   64/  265]
train() client id: f_00001-0-2 loss: 0.382970  [   96/  265]
train() client id: f_00001-0-3 loss: 0.383769  [  128/  265]
train() client id: f_00001-0-4 loss: 0.407732  [  160/  265]
train() client id: f_00001-0-5 loss: 0.452507  [  192/  265]
train() client id: f_00001-0-6 loss: 0.341495  [  224/  265]
train() client id: f_00001-0-7 loss: 0.456726  [  256/  265]
train() client id: f_00001-1-0 loss: 0.442624  [   32/  265]
train() client id: f_00001-1-1 loss: 0.414168  [   64/  265]
train() client id: f_00001-1-2 loss: 0.487084  [   96/  265]
train() client id: f_00001-1-3 loss: 0.402122  [  128/  265]
train() client id: f_00001-1-4 loss: 0.388400  [  160/  265]
train() client id: f_00001-1-5 loss: 0.341710  [  192/  265]
train() client id: f_00001-1-6 loss: 0.322564  [  224/  265]
train() client id: f_00001-1-7 loss: 0.373054  [  256/  265]
train() client id: f_00001-2-0 loss: 0.413526  [   32/  265]
train() client id: f_00001-2-1 loss: 0.305765  [   64/  265]
train() client id: f_00001-2-2 loss: 0.334937  [   96/  265]
train() client id: f_00001-2-3 loss: 0.439053  [  128/  265]
train() client id: f_00001-2-4 loss: 0.303189  [  160/  265]
train() client id: f_00001-2-5 loss: 0.355177  [  192/  265]
train() client id: f_00001-2-6 loss: 0.419633  [  224/  265]
train() client id: f_00001-2-7 loss: 0.329986  [  256/  265]
train() client id: f_00001-3-0 loss: 0.313543  [   32/  265]
train() client id: f_00001-3-1 loss: 0.318179  [   64/  265]
train() client id: f_00001-3-2 loss: 0.349813  [   96/  265]
train() client id: f_00001-3-3 loss: 0.408884  [  128/  265]
train() client id: f_00001-3-4 loss: 0.282933  [  160/  265]
train() client id: f_00001-3-5 loss: 0.488295  [  192/  265]
train() client id: f_00001-3-6 loss: 0.337518  [  224/  265]
train() client id: f_00001-3-7 loss: 0.345966  [  256/  265]
train() client id: f_00001-4-0 loss: 0.433989  [   32/  265]
train() client id: f_00001-4-1 loss: 0.293313  [   64/  265]
train() client id: f_00001-4-2 loss: 0.299797  [   96/  265]
train() client id: f_00001-4-3 loss: 0.380643  [  128/  265]
train() client id: f_00001-4-4 loss: 0.392858  [  160/  265]
train() client id: f_00001-4-5 loss: 0.356406  [  192/  265]
train() client id: f_00001-4-6 loss: 0.319463  [  224/  265]
train() client id: f_00001-4-7 loss: 0.290953  [  256/  265]
train() client id: f_00001-5-0 loss: 0.392196  [   32/  265]
train() client id: f_00001-5-1 loss: 0.328470  [   64/  265]
train() client id: f_00001-5-2 loss: 0.384236  [   96/  265]
train() client id: f_00001-5-3 loss: 0.267825  [  128/  265]
train() client id: f_00001-5-4 loss: 0.284263  [  160/  265]
train() client id: f_00001-5-5 loss: 0.313766  [  192/  265]
train() client id: f_00001-5-6 loss: 0.248416  [  224/  265]
train() client id: f_00001-5-7 loss: 0.418708  [  256/  265]
train() client id: f_00001-6-0 loss: 0.255351  [   32/  265]
train() client id: f_00001-6-1 loss: 0.328966  [   64/  265]
train() client id: f_00001-6-2 loss: 0.345711  [   96/  265]
train() client id: f_00001-6-3 loss: 0.453217  [  128/  265]
train() client id: f_00001-6-4 loss: 0.289137  [  160/  265]
train() client id: f_00001-6-5 loss: 0.338535  [  192/  265]
train() client id: f_00001-6-6 loss: 0.273736  [  224/  265]
train() client id: f_00001-6-7 loss: 0.278811  [  256/  265]
train() client id: f_00001-7-0 loss: 0.312268  [   32/  265]
train() client id: f_00001-7-1 loss: 0.360778  [   64/  265]
train() client id: f_00001-7-2 loss: 0.348985  [   96/  265]
train() client id: f_00001-7-3 loss: 0.331353  [  128/  265]
train() client id: f_00001-7-4 loss: 0.365035  [  160/  265]
train() client id: f_00001-7-5 loss: 0.306135  [  192/  265]
train() client id: f_00001-7-6 loss: 0.244480  [  224/  265]
train() client id: f_00001-7-7 loss: 0.280080  [  256/  265]
train() client id: f_00001-8-0 loss: 0.250026  [   32/  265]
train() client id: f_00001-8-1 loss: 0.336330  [   64/  265]
train() client id: f_00001-8-2 loss: 0.312561  [   96/  265]
train() client id: f_00001-8-3 loss: 0.293870  [  128/  265]
train() client id: f_00001-8-4 loss: 0.396225  [  160/  265]
train() client id: f_00001-8-5 loss: 0.322404  [  192/  265]
train() client id: f_00001-8-6 loss: 0.345278  [  224/  265]
train() client id: f_00001-8-7 loss: 0.221120  [  256/  265]
train() client id: f_00001-9-0 loss: 0.287435  [   32/  265]
train() client id: f_00001-9-1 loss: 0.333458  [   64/  265]
train() client id: f_00001-9-2 loss: 0.236922  [   96/  265]
train() client id: f_00001-9-3 loss: 0.253806  [  128/  265]
train() client id: f_00001-9-4 loss: 0.276631  [  160/  265]
train() client id: f_00001-9-5 loss: 0.343051  [  192/  265]
train() client id: f_00001-9-6 loss: 0.225978  [  224/  265]
train() client id: f_00001-9-7 loss: 0.450083  [  256/  265]
train() client id: f_00001-10-0 loss: 0.265845  [   32/  265]
train() client id: f_00001-10-1 loss: 0.299091  [   64/  265]
train() client id: f_00001-10-2 loss: 0.373170  [   96/  265]
train() client id: f_00001-10-3 loss: 0.238959  [  128/  265]
train() client id: f_00001-10-4 loss: 0.317747  [  160/  265]
train() client id: f_00001-10-5 loss: 0.275717  [  192/  265]
train() client id: f_00001-10-6 loss: 0.262500  [  224/  265]
train() client id: f_00001-10-7 loss: 0.325945  [  256/  265]
train() client id: f_00001-11-0 loss: 0.323938  [   32/  265]
train() client id: f_00001-11-1 loss: 0.374217  [   64/  265]
train() client id: f_00001-11-2 loss: 0.219712  [   96/  265]
train() client id: f_00001-11-3 loss: 0.298078  [  128/  265]
train() client id: f_00001-11-4 loss: 0.305334  [  160/  265]
train() client id: f_00001-11-5 loss: 0.269341  [  192/  265]
train() client id: f_00001-11-6 loss: 0.346770  [  224/  265]
train() client id: f_00001-11-7 loss: 0.251642  [  256/  265]
train() client id: f_00001-12-0 loss: 0.348927  [   32/  265]
train() client id: f_00001-12-1 loss: 0.220828  [   64/  265]
train() client id: f_00001-12-2 loss: 0.404415  [   96/  265]
train() client id: f_00001-12-3 loss: 0.352276  [  128/  265]
train() client id: f_00001-12-4 loss: 0.281168  [  160/  265]
train() client id: f_00001-12-5 loss: 0.222852  [  192/  265]
train() client id: f_00001-12-6 loss: 0.321276  [  224/  265]
train() client id: f_00001-12-7 loss: 0.212805  [  256/  265]
train() client id: f_00002-0-0 loss: 1.410030  [   32/  124]
train() client id: f_00002-0-1 loss: 1.280107  [   64/  124]
train() client id: f_00002-0-2 loss: 1.302450  [   96/  124]
train() client id: f_00002-1-0 loss: 1.370335  [   32/  124]
train() client id: f_00002-1-1 loss: 1.221969  [   64/  124]
train() client id: f_00002-1-2 loss: 1.279130  [   96/  124]
train() client id: f_00002-2-0 loss: 1.343905  [   32/  124]
train() client id: f_00002-2-1 loss: 1.205514  [   64/  124]
train() client id: f_00002-2-2 loss: 1.201051  [   96/  124]
train() client id: f_00002-3-0 loss: 1.251732  [   32/  124]
train() client id: f_00002-3-1 loss: 1.179177  [   64/  124]
train() client id: f_00002-3-2 loss: 1.181649  [   96/  124]
train() client id: f_00002-4-0 loss: 1.165893  [   32/  124]
train() client id: f_00002-4-1 loss: 1.192976  [   64/  124]
train() client id: f_00002-4-2 loss: 1.176961  [   96/  124]
train() client id: f_00002-5-0 loss: 1.158654  [   32/  124]
train() client id: f_00002-5-1 loss: 1.191841  [   64/  124]
train() client id: f_00002-5-2 loss: 1.090994  [   96/  124]
train() client id: f_00002-6-0 loss: 1.071078  [   32/  124]
train() client id: f_00002-6-1 loss: 1.021203  [   64/  124]
train() client id: f_00002-6-2 loss: 1.203814  [   96/  124]
train() client id: f_00002-7-0 loss: 1.017005  [   32/  124]
train() client id: f_00002-7-1 loss: 1.110484  [   64/  124]
train() client id: f_00002-7-2 loss: 1.135041  [   96/  124]
train() client id: f_00002-8-0 loss: 1.040274  [   32/  124]
train() client id: f_00002-8-1 loss: 1.061162  [   64/  124]
train() client id: f_00002-8-2 loss: 1.107949  [   96/  124]
train() client id: f_00002-9-0 loss: 1.042989  [   32/  124]
train() client id: f_00002-9-1 loss: 1.114159  [   64/  124]
train() client id: f_00002-9-2 loss: 1.018038  [   96/  124]
train() client id: f_00002-10-0 loss: 1.062604  [   32/  124]
train() client id: f_00002-10-1 loss: 0.972013  [   64/  124]
train() client id: f_00002-10-2 loss: 1.074679  [   96/  124]
train() client id: f_00002-11-0 loss: 0.975472  [   32/  124]
train() client id: f_00002-11-1 loss: 1.097570  [   64/  124]
train() client id: f_00002-11-2 loss: 1.101875  [   96/  124]
train() client id: f_00002-12-0 loss: 1.019442  [   32/  124]
train() client id: f_00002-12-1 loss: 1.005698  [   64/  124]
train() client id: f_00002-12-2 loss: 1.053548  [   96/  124]
train() client id: f_00003-0-0 loss: 0.976061  [   32/   43]
train() client id: f_00003-1-0 loss: 0.956460  [   32/   43]
train() client id: f_00003-2-0 loss: 0.895422  [   32/   43]
train() client id: f_00003-3-0 loss: 0.843800  [   32/   43]
train() client id: f_00003-4-0 loss: 0.966936  [   32/   43]
train() client id: f_00003-5-0 loss: 0.822529  [   32/   43]
train() client id: f_00003-6-0 loss: 1.043956  [   32/   43]
train() client id: f_00003-7-0 loss: 0.950430  [   32/   43]
train() client id: f_00003-8-0 loss: 0.888057  [   32/   43]
train() client id: f_00003-9-0 loss: 0.904279  [   32/   43]
train() client id: f_00003-10-0 loss: 0.809069  [   32/   43]
train() client id: f_00003-11-0 loss: 0.936931  [   32/   43]
train() client id: f_00003-12-0 loss: 0.973299  [   32/   43]
train() client id: f_00004-0-0 loss: 0.679815  [   32/  306]
train() client id: f_00004-0-1 loss: 0.713065  [   64/  306]
train() client id: f_00004-0-2 loss: 0.796386  [   96/  306]
train() client id: f_00004-0-3 loss: 0.763953  [  128/  306]
train() client id: f_00004-0-4 loss: 0.777482  [  160/  306]
train() client id: f_00004-0-5 loss: 0.701095  [  192/  306]
train() client id: f_00004-0-6 loss: 0.713679  [  224/  306]
train() client id: f_00004-0-7 loss: 0.629860  [  256/  306]
train() client id: f_00004-0-8 loss: 0.767171  [  288/  306]
train() client id: f_00004-1-0 loss: 0.794385  [   32/  306]
train() client id: f_00004-1-1 loss: 0.670599  [   64/  306]
train() client id: f_00004-1-2 loss: 0.726785  [   96/  306]
train() client id: f_00004-1-3 loss: 0.916966  [  128/  306]
train() client id: f_00004-1-4 loss: 0.755095  [  160/  306]
train() client id: f_00004-1-5 loss: 0.671564  [  192/  306]
train() client id: f_00004-1-6 loss: 0.692256  [  224/  306]
train() client id: f_00004-1-7 loss: 0.719454  [  256/  306]
train() client id: f_00004-1-8 loss: 0.766464  [  288/  306]
train() client id: f_00004-2-0 loss: 0.647040  [   32/  306]
train() client id: f_00004-2-1 loss: 0.838731  [   64/  306]
train() client id: f_00004-2-2 loss: 0.820099  [   96/  306]
train() client id: f_00004-2-3 loss: 0.736080  [  128/  306]
train() client id: f_00004-2-4 loss: 0.759040  [  160/  306]
train() client id: f_00004-2-5 loss: 0.625619  [  192/  306]
train() client id: f_00004-2-6 loss: 0.716124  [  224/  306]
train() client id: f_00004-2-7 loss: 0.785982  [  256/  306]
train() client id: f_00004-2-8 loss: 0.712598  [  288/  306]
train() client id: f_00004-3-0 loss: 0.744098  [   32/  306]
train() client id: f_00004-3-1 loss: 0.643017  [   64/  306]
train() client id: f_00004-3-2 loss: 0.772462  [   96/  306]
train() client id: f_00004-3-3 loss: 0.706682  [  128/  306]
train() client id: f_00004-3-4 loss: 0.850515  [  160/  306]
train() client id: f_00004-3-5 loss: 0.716841  [  192/  306]
train() client id: f_00004-3-6 loss: 0.775014  [  224/  306]
train() client id: f_00004-3-7 loss: 0.667201  [  256/  306]
train() client id: f_00004-3-8 loss: 0.816115  [  288/  306]
train() client id: f_00004-4-0 loss: 0.730259  [   32/  306]
train() client id: f_00004-4-1 loss: 0.690439  [   64/  306]
train() client id: f_00004-4-2 loss: 0.744630  [   96/  306]
train() client id: f_00004-4-3 loss: 0.832163  [  128/  306]
train() client id: f_00004-4-4 loss: 0.766695  [  160/  306]
train() client id: f_00004-4-5 loss: 0.732539  [  192/  306]
train() client id: f_00004-4-6 loss: 0.691948  [  224/  306]
train() client id: f_00004-4-7 loss: 0.678991  [  256/  306]
train() client id: f_00004-4-8 loss: 0.770624  [  288/  306]
train() client id: f_00004-5-0 loss: 0.833048  [   32/  306]
train() client id: f_00004-5-1 loss: 0.791645  [   64/  306]
train() client id: f_00004-5-2 loss: 0.637620  [   96/  306]
train() client id: f_00004-5-3 loss: 0.631803  [  128/  306]
train() client id: f_00004-5-4 loss: 0.789603  [  160/  306]
train() client id: f_00004-5-5 loss: 0.677511  [  192/  306]
train() client id: f_00004-5-6 loss: 0.715547  [  224/  306]
train() client id: f_00004-5-7 loss: 0.721096  [  256/  306]
train() client id: f_00004-5-8 loss: 0.763709  [  288/  306]
train() client id: f_00004-6-0 loss: 0.755019  [   32/  306]
train() client id: f_00004-6-1 loss: 0.670893  [   64/  306]
train() client id: f_00004-6-2 loss: 0.760890  [   96/  306]
train() client id: f_00004-6-3 loss: 0.658475  [  128/  306]
train() client id: f_00004-6-4 loss: 0.637361  [  160/  306]
train() client id: f_00004-6-5 loss: 0.792301  [  192/  306]
train() client id: f_00004-6-6 loss: 0.806472  [  224/  306]
train() client id: f_00004-6-7 loss: 0.822679  [  256/  306]
train() client id: f_00004-6-8 loss: 0.763900  [  288/  306]
train() client id: f_00004-7-0 loss: 0.596808  [   32/  306]
train() client id: f_00004-7-1 loss: 0.643340  [   64/  306]
train() client id: f_00004-7-2 loss: 0.663728  [   96/  306]
train() client id: f_00004-7-3 loss: 0.855360  [  128/  306]
train() client id: f_00004-7-4 loss: 0.756834  [  160/  306]
train() client id: f_00004-7-5 loss: 0.763596  [  192/  306]
train() client id: f_00004-7-6 loss: 0.780032  [  224/  306]
train() client id: f_00004-7-7 loss: 0.790416  [  256/  306]
train() client id: f_00004-7-8 loss: 0.848813  [  288/  306]
train() client id: f_00004-8-0 loss: 0.680271  [   32/  306]
train() client id: f_00004-8-1 loss: 0.742497  [   64/  306]
train() client id: f_00004-8-2 loss: 0.793581  [   96/  306]
train() client id: f_00004-8-3 loss: 0.664656  [  128/  306]
train() client id: f_00004-8-4 loss: 0.755441  [  160/  306]
train() client id: f_00004-8-5 loss: 0.671280  [  192/  306]
train() client id: f_00004-8-6 loss: 0.751133  [  224/  306]
train() client id: f_00004-8-7 loss: 0.773107  [  256/  306]
train() client id: f_00004-8-8 loss: 0.868672  [  288/  306]
train() client id: f_00004-9-0 loss: 0.830218  [   32/  306]
train() client id: f_00004-9-1 loss: 0.745830  [   64/  306]
train() client id: f_00004-9-2 loss: 0.697259  [   96/  306]
train() client id: f_00004-9-3 loss: 0.703553  [  128/  306]
train() client id: f_00004-9-4 loss: 0.785016  [  160/  306]
train() client id: f_00004-9-5 loss: 0.738020  [  192/  306]
train() client id: f_00004-9-6 loss: 0.777920  [  224/  306]
train() client id: f_00004-9-7 loss: 0.816358  [  256/  306]
train() client id: f_00004-9-8 loss: 0.637484  [  288/  306]
train() client id: f_00004-10-0 loss: 0.788607  [   32/  306]
train() client id: f_00004-10-1 loss: 0.704085  [   64/  306]
train() client id: f_00004-10-2 loss: 0.654341  [   96/  306]
train() client id: f_00004-10-3 loss: 0.654308  [  128/  306]
train() client id: f_00004-10-4 loss: 0.755111  [  160/  306]
train() client id: f_00004-10-5 loss: 0.682430  [  192/  306]
train() client id: f_00004-10-6 loss: 0.853197  [  224/  306]
train() client id: f_00004-10-7 loss: 0.704831  [  256/  306]
train() client id: f_00004-10-8 loss: 0.848009  [  288/  306]
train() client id: f_00004-11-0 loss: 0.773921  [   32/  306]
train() client id: f_00004-11-1 loss: 0.681350  [   64/  306]
train() client id: f_00004-11-2 loss: 0.761960  [   96/  306]
train() client id: f_00004-11-3 loss: 0.817705  [  128/  306]
train() client id: f_00004-11-4 loss: 0.659598  [  160/  306]
train() client id: f_00004-11-5 loss: 0.659217  [  192/  306]
train() client id: f_00004-11-6 loss: 0.697609  [  224/  306]
train() client id: f_00004-11-7 loss: 0.768051  [  256/  306]
train() client id: f_00004-11-8 loss: 0.809238  [  288/  306]
train() client id: f_00004-12-0 loss: 0.698933  [   32/  306]
train() client id: f_00004-12-1 loss: 0.789167  [   64/  306]
train() client id: f_00004-12-2 loss: 0.685450  [   96/  306]
train() client id: f_00004-12-3 loss: 0.733862  [  128/  306]
train() client id: f_00004-12-4 loss: 0.705869  [  160/  306]
train() client id: f_00004-12-5 loss: 0.683376  [  192/  306]
train() client id: f_00004-12-6 loss: 0.739182  [  224/  306]
train() client id: f_00004-12-7 loss: 0.782327  [  256/  306]
train() client id: f_00004-12-8 loss: 0.874673  [  288/  306]
train() client id: f_00005-0-0 loss: 0.863322  [   32/  146]
train() client id: f_00005-0-1 loss: 0.963950  [   64/  146]
train() client id: f_00005-0-2 loss: 0.774398  [   96/  146]
train() client id: f_00005-0-3 loss: 0.738236  [  128/  146]
train() client id: f_00005-1-0 loss: 0.785566  [   32/  146]
train() client id: f_00005-1-1 loss: 0.837074  [   64/  146]
train() client id: f_00005-1-2 loss: 0.790881  [   96/  146]
train() client id: f_00005-1-3 loss: 0.872301  [  128/  146]
train() client id: f_00005-2-0 loss: 0.774177  [   32/  146]
train() client id: f_00005-2-1 loss: 0.910293  [   64/  146]
train() client id: f_00005-2-2 loss: 0.773925  [   96/  146]
train() client id: f_00005-2-3 loss: 0.897584  [  128/  146]
train() client id: f_00005-3-0 loss: 0.842713  [   32/  146]
train() client id: f_00005-3-1 loss: 0.914682  [   64/  146]
train() client id: f_00005-3-2 loss: 0.815480  [   96/  146]
train() client id: f_00005-3-3 loss: 0.714234  [  128/  146]
train() client id: f_00005-4-0 loss: 0.787287  [   32/  146]
train() client id: f_00005-4-1 loss: 0.810156  [   64/  146]
train() client id: f_00005-4-2 loss: 0.835806  [   96/  146]
train() client id: f_00005-4-3 loss: 0.754144  [  128/  146]
train() client id: f_00005-5-0 loss: 0.691480  [   32/  146]
train() client id: f_00005-5-1 loss: 0.892519  [   64/  146]
train() client id: f_00005-5-2 loss: 0.914440  [   96/  146]
train() client id: f_00005-5-3 loss: 0.769232  [  128/  146]
train() client id: f_00005-6-0 loss: 0.860440  [   32/  146]
train() client id: f_00005-6-1 loss: 0.714469  [   64/  146]
train() client id: f_00005-6-2 loss: 0.894139  [   96/  146]
train() client id: f_00005-6-3 loss: 0.714258  [  128/  146]
train() client id: f_00005-7-0 loss: 0.821104  [   32/  146]
train() client id: f_00005-7-1 loss: 0.958368  [   64/  146]
train() client id: f_00005-7-2 loss: 0.600522  [   96/  146]
train() client id: f_00005-7-3 loss: 0.930019  [  128/  146]
train() client id: f_00005-8-0 loss: 0.884437  [   32/  146]
train() client id: f_00005-8-1 loss: 0.683900  [   64/  146]
train() client id: f_00005-8-2 loss: 0.777760  [   96/  146]
train() client id: f_00005-8-3 loss: 0.924230  [  128/  146]
train() client id: f_00005-9-0 loss: 0.850905  [   32/  146]
train() client id: f_00005-9-1 loss: 0.772920  [   64/  146]
train() client id: f_00005-9-2 loss: 0.808475  [   96/  146]
train() client id: f_00005-9-3 loss: 0.868678  [  128/  146]
train() client id: f_00005-10-0 loss: 0.793808  [   32/  146]
train() client id: f_00005-10-1 loss: 0.730434  [   64/  146]
train() client id: f_00005-10-2 loss: 0.824915  [   96/  146]
train() client id: f_00005-10-3 loss: 0.896677  [  128/  146]
train() client id: f_00005-11-0 loss: 1.025435  [   32/  146]
train() client id: f_00005-11-1 loss: 0.840603  [   64/  146]
train() client id: f_00005-11-2 loss: 0.589396  [   96/  146]
train() client id: f_00005-11-3 loss: 0.771179  [  128/  146]
train() client id: f_00005-12-0 loss: 0.887119  [   32/  146]
train() client id: f_00005-12-1 loss: 0.845156  [   64/  146]
train() client id: f_00005-12-2 loss: 0.888860  [   96/  146]
train() client id: f_00005-12-3 loss: 0.669725  [  128/  146]
train() client id: f_00006-0-0 loss: 0.722062  [   32/   54]
train() client id: f_00006-1-0 loss: 0.782862  [   32/   54]
train() client id: f_00006-2-0 loss: 0.789374  [   32/   54]
train() client id: f_00006-3-0 loss: 0.719604  [   32/   54]
train() client id: f_00006-4-0 loss: 0.710668  [   32/   54]
train() client id: f_00006-5-0 loss: 0.746501  [   32/   54]
train() client id: f_00006-6-0 loss: 0.756939  [   32/   54]
train() client id: f_00006-7-0 loss: 0.707857  [   32/   54]
train() client id: f_00006-8-0 loss: 0.768912  [   32/   54]
train() client id: f_00006-9-0 loss: 0.758136  [   32/   54]
train() client id: f_00006-10-0 loss: 0.771155  [   32/   54]
train() client id: f_00006-11-0 loss: 0.783781  [   32/   54]
train() client id: f_00006-12-0 loss: 0.772891  [   32/   54]
train() client id: f_00007-0-0 loss: 0.527078  [   32/  179]
train() client id: f_00007-0-1 loss: 0.542445  [   64/  179]
train() client id: f_00007-0-2 loss: 0.488243  [   96/  179]
train() client id: f_00007-0-3 loss: 0.522044  [  128/  179]
train() client id: f_00007-0-4 loss: 0.628548  [  160/  179]
train() client id: f_00007-1-0 loss: 0.496713  [   32/  179]
train() client id: f_00007-1-1 loss: 0.531336  [   64/  179]
train() client id: f_00007-1-2 loss: 0.469688  [   96/  179]
train() client id: f_00007-1-3 loss: 0.602520  [  128/  179]
train() client id: f_00007-1-4 loss: 0.580313  [  160/  179]
train() client id: f_00007-2-0 loss: 0.439982  [   32/  179]
train() client id: f_00007-2-1 loss: 0.409049  [   64/  179]
train() client id: f_00007-2-2 loss: 0.552976  [   96/  179]
train() client id: f_00007-2-3 loss: 0.647535  [  128/  179]
train() client id: f_00007-2-4 loss: 0.503512  [  160/  179]
train() client id: f_00007-3-0 loss: 0.647297  [   32/  179]
train() client id: f_00007-3-1 loss: 0.428090  [   64/  179]
train() client id: f_00007-3-2 loss: 0.409089  [   96/  179]
train() client id: f_00007-3-3 loss: 0.351827  [  128/  179]
train() client id: f_00007-3-4 loss: 0.636816  [  160/  179]
train() client id: f_00007-4-0 loss: 0.510705  [   32/  179]
train() client id: f_00007-4-1 loss: 0.549187  [   64/  179]
train() client id: f_00007-4-2 loss: 0.478382  [   96/  179]
train() client id: f_00007-4-3 loss: 0.366844  [  128/  179]
train() client id: f_00007-4-4 loss: 0.496782  [  160/  179]
train() client id: f_00007-5-0 loss: 0.580565  [   32/  179]
train() client id: f_00007-5-1 loss: 0.553168  [   64/  179]
train() client id: f_00007-5-2 loss: 0.538106  [   96/  179]
train() client id: f_00007-5-3 loss: 0.374353  [  128/  179]
train() client id: f_00007-5-4 loss: 0.403630  [  160/  179]
train() client id: f_00007-6-0 loss: 0.481697  [   32/  179]
train() client id: f_00007-6-1 loss: 0.371369  [   64/  179]
train() client id: f_00007-6-2 loss: 0.611283  [   96/  179]
train() client id: f_00007-6-3 loss: 0.333161  [  128/  179]
train() client id: f_00007-6-4 loss: 0.444109  [  160/  179]
train() client id: f_00007-7-0 loss: 0.402895  [   32/  179]
train() client id: f_00007-7-1 loss: 0.353440  [   64/  179]
train() client id: f_00007-7-2 loss: 0.489212  [   96/  179]
train() client id: f_00007-7-3 loss: 0.336326  [  128/  179]
train() client id: f_00007-7-4 loss: 0.714008  [  160/  179]
train() client id: f_00007-8-0 loss: 0.391206  [   32/  179]
train() client id: f_00007-8-1 loss: 0.427786  [   64/  179]
train() client id: f_00007-8-2 loss: 0.621365  [   96/  179]
train() client id: f_00007-8-3 loss: 0.412567  [  128/  179]
train() client id: f_00007-8-4 loss: 0.480246  [  160/  179]
train() client id: f_00007-9-0 loss: 0.558128  [   32/  179]
train() client id: f_00007-9-1 loss: 0.379429  [   64/  179]
train() client id: f_00007-9-2 loss: 0.347013  [   96/  179]
train() client id: f_00007-9-3 loss: 0.534938  [  128/  179]
train() client id: f_00007-9-4 loss: 0.493619  [  160/  179]
train() client id: f_00007-10-0 loss: 0.610580  [   32/  179]
train() client id: f_00007-10-1 loss: 0.410983  [   64/  179]
train() client id: f_00007-10-2 loss: 0.384220  [   96/  179]
train() client id: f_00007-10-3 loss: 0.332000  [  128/  179]
train() client id: f_00007-10-4 loss: 0.404617  [  160/  179]
train() client id: f_00007-11-0 loss: 0.462962  [   32/  179]
train() client id: f_00007-11-1 loss: 0.428570  [   64/  179]
train() client id: f_00007-11-2 loss: 0.422990  [   96/  179]
train() client id: f_00007-11-3 loss: 0.539724  [  128/  179]
train() client id: f_00007-11-4 loss: 0.468185  [  160/  179]
train() client id: f_00007-12-0 loss: 0.469760  [   32/  179]
train() client id: f_00007-12-1 loss: 0.628102  [   64/  179]
train() client id: f_00007-12-2 loss: 0.315113  [   96/  179]
train() client id: f_00007-12-3 loss: 0.318727  [  128/  179]
train() client id: f_00007-12-4 loss: 0.398902  [  160/  179]
train() client id: f_00008-0-0 loss: 0.894907  [   32/  130]
train() client id: f_00008-0-1 loss: 0.802848  [   64/  130]
train() client id: f_00008-0-2 loss: 0.810702  [   96/  130]
train() client id: f_00008-0-3 loss: 0.838785  [  128/  130]
train() client id: f_00008-1-0 loss: 0.815103  [   32/  130]
train() client id: f_00008-1-1 loss: 0.852409  [   64/  130]
train() client id: f_00008-1-2 loss: 0.768925  [   96/  130]
train() client id: f_00008-1-3 loss: 0.931526  [  128/  130]
train() client id: f_00008-2-0 loss: 0.843851  [   32/  130]
train() client id: f_00008-2-1 loss: 0.772357  [   64/  130]
train() client id: f_00008-2-2 loss: 0.876846  [   96/  130]
train() client id: f_00008-2-3 loss: 0.870451  [  128/  130]
train() client id: f_00008-3-0 loss: 0.787883  [   32/  130]
train() client id: f_00008-3-1 loss: 0.759747  [   64/  130]
train() client id: f_00008-3-2 loss: 0.887548  [   96/  130]
train() client id: f_00008-3-3 loss: 0.891526  [  128/  130]
train() client id: f_00008-4-0 loss: 0.907132  [   32/  130]
train() client id: f_00008-4-1 loss: 0.781632  [   64/  130]
train() client id: f_00008-4-2 loss: 0.763330  [   96/  130]
train() client id: f_00008-4-3 loss: 0.882888  [  128/  130]
train() client id: f_00008-5-0 loss: 0.909183  [   32/  130]
train() client id: f_00008-5-1 loss: 0.713132  [   64/  130]
train() client id: f_00008-5-2 loss: 0.864366  [   96/  130]
train() client id: f_00008-5-3 loss: 0.839073  [  128/  130]
train() client id: f_00008-6-0 loss: 0.793748  [   32/  130]
train() client id: f_00008-6-1 loss: 0.796554  [   64/  130]
train() client id: f_00008-6-2 loss: 0.878301  [   96/  130]
train() client id: f_00008-6-3 loss: 0.885578  [  128/  130]
train() client id: f_00008-7-0 loss: 0.930273  [   32/  130]
train() client id: f_00008-7-1 loss: 0.858124  [   64/  130]
train() client id: f_00008-7-2 loss: 0.739559  [   96/  130]
train() client id: f_00008-7-3 loss: 0.797688  [  128/  130]
train() client id: f_00008-8-0 loss: 0.704072  [   32/  130]
train() client id: f_00008-8-1 loss: 0.828912  [   64/  130]
train() client id: f_00008-8-2 loss: 0.998417  [   96/  130]
train() client id: f_00008-8-3 loss: 0.834442  [  128/  130]
train() client id: f_00008-9-0 loss: 0.925007  [   32/  130]
train() client id: f_00008-9-1 loss: 0.759582  [   64/  130]
train() client id: f_00008-9-2 loss: 0.894224  [   96/  130]
train() client id: f_00008-9-3 loss: 0.759952  [  128/  130]
train() client id: f_00008-10-0 loss: 0.946356  [   32/  130]
train() client id: f_00008-10-1 loss: 0.778797  [   64/  130]
train() client id: f_00008-10-2 loss: 0.741859  [   96/  130]
train() client id: f_00008-10-3 loss: 0.871202  [  128/  130]
train() client id: f_00008-11-0 loss: 0.858642  [   32/  130]
train() client id: f_00008-11-1 loss: 0.798428  [   64/  130]
train() client id: f_00008-11-2 loss: 0.821903  [   96/  130]
train() client id: f_00008-11-3 loss: 0.880422  [  128/  130]
train() client id: f_00008-12-0 loss: 0.943751  [   32/  130]
train() client id: f_00008-12-1 loss: 0.759964  [   64/  130]
train() client id: f_00008-12-2 loss: 0.875016  [   96/  130]
train() client id: f_00008-12-3 loss: 0.791285  [  128/  130]
train() client id: f_00009-0-0 loss: 1.173144  [   32/  118]
train() client id: f_00009-0-1 loss: 1.296777  [   64/  118]
train() client id: f_00009-0-2 loss: 1.182922  [   96/  118]
train() client id: f_00009-1-0 loss: 1.129458  [   32/  118]
train() client id: f_00009-1-1 loss: 1.248889  [   64/  118]
train() client id: f_00009-1-2 loss: 1.092075  [   96/  118]
train() client id: f_00009-2-0 loss: 1.182137  [   32/  118]
train() client id: f_00009-2-1 loss: 1.046794  [   64/  118]
train() client id: f_00009-2-2 loss: 1.138147  [   96/  118]
train() client id: f_00009-3-0 loss: 1.100554  [   32/  118]
train() client id: f_00009-3-1 loss: 1.096898  [   64/  118]
train() client id: f_00009-3-2 loss: 1.080609  [   96/  118]
train() client id: f_00009-4-0 loss: 1.091691  [   32/  118]
train() client id: f_00009-4-1 loss: 1.110538  [   64/  118]
train() client id: f_00009-4-2 loss: 1.037440  [   96/  118]
train() client id: f_00009-5-0 loss: 1.033427  [   32/  118]
train() client id: f_00009-5-1 loss: 1.051583  [   64/  118]
train() client id: f_00009-5-2 loss: 1.035683  [   96/  118]
train() client id: f_00009-6-0 loss: 1.049855  [   32/  118]
train() client id: f_00009-6-1 loss: 1.059114  [   64/  118]
train() client id: f_00009-6-2 loss: 0.965437  [   96/  118]
train() client id: f_00009-7-0 loss: 1.058643  [   32/  118]
train() client id: f_00009-7-1 loss: 0.882592  [   64/  118]
train() client id: f_00009-7-2 loss: 1.042138  [   96/  118]
train() client id: f_00009-8-0 loss: 1.041975  [   32/  118]
train() client id: f_00009-8-1 loss: 0.918788  [   64/  118]
train() client id: f_00009-8-2 loss: 1.033293  [   96/  118]
train() client id: f_00009-9-0 loss: 1.009145  [   32/  118]
train() client id: f_00009-9-1 loss: 0.981069  [   64/  118]
train() client id: f_00009-9-2 loss: 0.952982  [   96/  118]
train() client id: f_00009-10-0 loss: 0.930459  [   32/  118]
train() client id: f_00009-10-1 loss: 0.972048  [   64/  118]
train() client id: f_00009-10-2 loss: 1.005009  [   96/  118]
train() client id: f_00009-11-0 loss: 1.032497  [   32/  118]
train() client id: f_00009-11-1 loss: 0.986702  [   64/  118]
train() client id: f_00009-11-2 loss: 0.981843  [   96/  118]
train() client id: f_00009-12-0 loss: 0.875502  [   32/  118]
train() client id: f_00009-12-1 loss: 1.093626  [   64/  118]
train() client id: f_00009-12-2 loss: 0.967780  [   96/  118]
At round 9 accuracy: 0.6339522546419099
At round 9 training accuracy: 0.5788061703554661
At round 9 training loss: 0.8654017136310428
gradient difference: 0.4521729350090027
train() client id: f_00000-0-0 loss: 1.339817  [   32/  126]
train() client id: f_00000-0-1 loss: 1.105136  [   64/  126]
train() client id: f_00000-0-2 loss: 1.047363  [   96/  126]
train() client id: f_00000-1-0 loss: 1.217578  [   32/  126]
train() client id: f_00000-1-1 loss: 1.076236  [   64/  126]
train() client id: f_00000-1-2 loss: 1.019146  [   96/  126]
train() client id: f_00000-2-0 loss: 1.064571  [   32/  126]
train() client id: f_00000-2-1 loss: 1.072762  [   64/  126]
train() client id: f_00000-2-2 loss: 1.073739  [   96/  126]
train() client id: f_00000-3-0 loss: 1.000868  [   32/  126]
train() client id: f_00000-3-1 loss: 1.051760  [   64/  126]
train() client id: f_00000-3-2 loss: 0.919280  [   96/  126]
train() client id: f_00000-4-0 loss: 1.002938  [   32/  126]
train() client id: f_00000-4-1 loss: 0.924846  [   64/  126]
train() client id: f_00000-4-2 loss: 0.980393  [   96/  126]
train() client id: f_00000-5-0 loss: 0.923047  [   32/  126]
train() client id: f_00000-5-1 loss: 0.898278  [   64/  126]
train() client id: f_00000-5-2 loss: 0.987612  [   96/  126]
train() client id: f_00000-6-0 loss: 0.903824  [   32/  126]
train() client id: f_00000-6-1 loss: 0.981564  [   64/  126]
train() client id: f_00000-6-2 loss: 0.974755  [   96/  126]
train() client id: f_00000-7-0 loss: 1.008716  [   32/  126]
train() client id: f_00000-7-1 loss: 0.812119  [   64/  126]
train() client id: f_00000-7-2 loss: 0.897908  [   96/  126]
train() client id: f_00000-8-0 loss: 0.987068  [   32/  126]
train() client id: f_00000-8-1 loss: 0.879451  [   64/  126]
train() client id: f_00000-8-2 loss: 0.825872  [   96/  126]
train() client id: f_00000-9-0 loss: 0.914106  [   32/  126]
train() client id: f_00000-9-1 loss: 0.961600  [   64/  126]
train() client id: f_00000-9-2 loss: 0.969445  [   96/  126]
train() client id: f_00000-10-0 loss: 0.938989  [   32/  126]
train() client id: f_00000-10-1 loss: 0.869731  [   64/  126]
train() client id: f_00000-10-2 loss: 0.876174  [   96/  126]
train() client id: f_00000-11-0 loss: 0.913152  [   32/  126]
train() client id: f_00000-11-1 loss: 0.937173  [   64/  126]
train() client id: f_00000-11-2 loss: 0.941839  [   96/  126]
train() client id: f_00000-12-0 loss: 0.788112  [   32/  126]
train() client id: f_00000-12-1 loss: 1.107064  [   64/  126]
train() client id: f_00000-12-2 loss: 0.860888  [   96/  126]
train() client id: f_00001-0-0 loss: 0.671739  [   32/  265]
train() client id: f_00001-0-1 loss: 0.594013  [   64/  265]
train() client id: f_00001-0-2 loss: 0.546566  [   96/  265]
train() client id: f_00001-0-3 loss: 0.521182  [  128/  265]
train() client id: f_00001-0-4 loss: 0.531110  [  160/  265]
train() client id: f_00001-0-5 loss: 0.647555  [  192/  265]
train() client id: f_00001-0-6 loss: 0.590857  [  224/  265]
train() client id: f_00001-0-7 loss: 0.568733  [  256/  265]
train() client id: f_00001-1-0 loss: 0.559148  [   32/  265]
train() client id: f_00001-1-1 loss: 0.606940  [   64/  265]
train() client id: f_00001-1-2 loss: 0.689077  [   96/  265]
train() client id: f_00001-1-3 loss: 0.601990  [  128/  265]
train() client id: f_00001-1-4 loss: 0.489618  [  160/  265]
train() client id: f_00001-1-5 loss: 0.509450  [  192/  265]
train() client id: f_00001-1-6 loss: 0.549283  [  224/  265]
train() client id: f_00001-1-7 loss: 0.578246  [  256/  265]
train() client id: f_00001-2-0 loss: 0.519588  [   32/  265]
train() client id: f_00001-2-1 loss: 0.581337  [   64/  265]
train() client id: f_00001-2-2 loss: 0.530544  [   96/  265]
train() client id: f_00001-2-3 loss: 0.542049  [  128/  265]
train() client id: f_00001-2-4 loss: 0.502120  [  160/  265]
train() client id: f_00001-2-5 loss: 0.620484  [  192/  265]
train() client id: f_00001-2-6 loss: 0.637264  [  224/  265]
train() client id: f_00001-2-7 loss: 0.569261  [  256/  265]
train() client id: f_00001-3-0 loss: 0.570260  [   32/  265]
train() client id: f_00001-3-1 loss: 0.525442  [   64/  265]
train() client id: f_00001-3-2 loss: 0.536309  [   96/  265]
train() client id: f_00001-3-3 loss: 0.536334  [  128/  265]
train() client id: f_00001-3-4 loss: 0.622648  [  160/  265]
train() client id: f_00001-3-5 loss: 0.659813  [  192/  265]
train() client id: f_00001-3-6 loss: 0.489535  [  224/  265]
train() client id: f_00001-3-7 loss: 0.510380  [  256/  265]
train() client id: f_00001-4-0 loss: 0.722977  [   32/  265]
train() client id: f_00001-4-1 loss: 0.541064  [   64/  265]
train() client id: f_00001-4-2 loss: 0.557544  [   96/  265]
train() client id: f_00001-4-3 loss: 0.467725  [  128/  265]
train() client id: f_00001-4-4 loss: 0.541042  [  160/  265]
train() client id: f_00001-4-5 loss: 0.523407  [  192/  265]
train() client id: f_00001-4-6 loss: 0.508870  [  224/  265]
train() client id: f_00001-4-7 loss: 0.523494  [  256/  265]
train() client id: f_00001-5-0 loss: 0.553437  [   32/  265]
train() client id: f_00001-5-1 loss: 0.662230  [   64/  265]
train() client id: f_00001-5-2 loss: 0.510782  [   96/  265]
train() client id: f_00001-5-3 loss: 0.513733  [  128/  265]
train() client id: f_00001-5-4 loss: 0.485855  [  160/  265]
train() client id: f_00001-5-5 loss: 0.606002  [  192/  265]
train() client id: f_00001-5-6 loss: 0.499152  [  224/  265]
train() client id: f_00001-5-7 loss: 0.544509  [  256/  265]
train() client id: f_00001-6-0 loss: 0.562747  [   32/  265]
train() client id: f_00001-6-1 loss: 0.527366  [   64/  265]
train() client id: f_00001-6-2 loss: 0.462640  [   96/  265]
train() client id: f_00001-6-3 loss: 0.524524  [  128/  265]
train() client id: f_00001-6-4 loss: 0.555969  [  160/  265]
train() client id: f_00001-6-5 loss: 0.536820  [  192/  265]
train() client id: f_00001-6-6 loss: 0.573444  [  224/  265]
train() client id: f_00001-6-7 loss: 0.606427  [  256/  265]
train() client id: f_00001-7-0 loss: 0.636875  [   32/  265]
train() client id: f_00001-7-1 loss: 0.579323  [   64/  265]
train() client id: f_00001-7-2 loss: 0.513105  [   96/  265]
train() client id: f_00001-7-3 loss: 0.546776  [  128/  265]
train() client id: f_00001-7-4 loss: 0.553531  [  160/  265]
train() client id: f_00001-7-5 loss: 0.465335  [  192/  265]
train() client id: f_00001-7-6 loss: 0.519579  [  224/  265]
train() client id: f_00001-7-7 loss: 0.514109  [  256/  265]
train() client id: f_00001-8-0 loss: 0.449393  [   32/  265]
train() client id: f_00001-8-1 loss: 0.483087  [   64/  265]
train() client id: f_00001-8-2 loss: 0.789496  [   96/  265]
train() client id: f_00001-8-3 loss: 0.537414  [  128/  265]
train() client id: f_00001-8-4 loss: 0.490475  [  160/  265]
train() client id: f_00001-8-5 loss: 0.512075  [  192/  265]
train() client id: f_00001-8-6 loss: 0.495372  [  224/  265]
train() client id: f_00001-8-7 loss: 0.566459  [  256/  265]
train() client id: f_00001-9-0 loss: 0.488807  [   32/  265]
train() client id: f_00001-9-1 loss: 0.600319  [   64/  265]
train() client id: f_00001-9-2 loss: 0.566651  [   96/  265]
train() client id: f_00001-9-3 loss: 0.528184  [  128/  265]
train() client id: f_00001-9-4 loss: 0.487620  [  160/  265]
train() client id: f_00001-9-5 loss: 0.465410  [  192/  265]
train() client id: f_00001-9-6 loss: 0.498244  [  224/  265]
train() client id: f_00001-9-7 loss: 0.697738  [  256/  265]
train() client id: f_00001-10-0 loss: 0.497439  [   32/  265]
train() client id: f_00001-10-1 loss: 0.606551  [   64/  265]
train() client id: f_00001-10-2 loss: 0.474019  [   96/  265]
train() client id: f_00001-10-3 loss: 0.628991  [  128/  265]
train() client id: f_00001-10-4 loss: 0.492297  [  160/  265]
train() client id: f_00001-10-5 loss: 0.629282  [  192/  265]
train() client id: f_00001-10-6 loss: 0.489460  [  224/  265]
train() client id: f_00001-10-7 loss: 0.469379  [  256/  265]
train() client id: f_00001-11-0 loss: 0.534888  [   32/  265]
train() client id: f_00001-11-1 loss: 0.588529  [   64/  265]
train() client id: f_00001-11-2 loss: 0.489864  [   96/  265]
train() client id: f_00001-11-3 loss: 0.454901  [  128/  265]
train() client id: f_00001-11-4 loss: 0.492230  [  160/  265]
train() client id: f_00001-11-5 loss: 0.708459  [  192/  265]
train() client id: f_00001-11-6 loss: 0.589706  [  224/  265]
train() client id: f_00001-11-7 loss: 0.469754  [  256/  265]
train() client id: f_00001-12-0 loss: 0.470164  [   32/  265]
train() client id: f_00001-12-1 loss: 0.552933  [   64/  265]
train() client id: f_00001-12-2 loss: 0.517786  [   96/  265]
train() client id: f_00001-12-3 loss: 0.448865  [  128/  265]
train() client id: f_00001-12-4 loss: 0.527445  [  160/  265]
train() client id: f_00001-12-5 loss: 0.576288  [  192/  265]
train() client id: f_00001-12-6 loss: 0.626693  [  224/  265]
train() client id: f_00001-12-7 loss: 0.549711  [  256/  265]
train() client id: f_00002-0-0 loss: 1.304163  [   32/  124]
train() client id: f_00002-0-1 loss: 1.246715  [   64/  124]
train() client id: f_00002-0-2 loss: 1.226014  [   96/  124]
train() client id: f_00002-1-0 loss: 1.243344  [   32/  124]
train() client id: f_00002-1-1 loss: 1.140803  [   64/  124]
train() client id: f_00002-1-2 loss: 1.112070  [   96/  124]
train() client id: f_00002-2-0 loss: 1.161546  [   32/  124]
train() client id: f_00002-2-1 loss: 1.145674  [   64/  124]
train() client id: f_00002-2-2 loss: 1.104608  [   96/  124]
train() client id: f_00002-3-0 loss: 1.183852  [   32/  124]
train() client id: f_00002-3-1 loss: 1.111228  [   64/  124]
train() client id: f_00002-3-2 loss: 1.127140  [   96/  124]
train() client id: f_00002-4-0 loss: 1.015563  [   32/  124]
train() client id: f_00002-4-1 loss: 1.069705  [   64/  124]
train() client id: f_00002-4-2 loss: 1.175991  [   96/  124]
train() client id: f_00002-5-0 loss: 1.028468  [   32/  124]
train() client id: f_00002-5-1 loss: 1.041056  [   64/  124]
train() client id: f_00002-5-2 loss: 1.043665  [   96/  124]
train() client id: f_00002-6-0 loss: 1.034792  [   32/  124]
train() client id: f_00002-6-1 loss: 1.062274  [   64/  124]
train() client id: f_00002-6-2 loss: 1.092678  [   96/  124]
train() client id: f_00002-7-0 loss: 1.024385  [   32/  124]
train() client id: f_00002-7-1 loss: 0.987156  [   64/  124]
train() client id: f_00002-7-2 loss: 1.021981  [   96/  124]
train() client id: f_00002-8-0 loss: 0.951101  [   32/  124]
train() client id: f_00002-8-1 loss: 0.996852  [   64/  124]
train() client id: f_00002-8-2 loss: 1.066107  [   96/  124]
train() client id: f_00002-9-0 loss: 1.042339  [   32/  124]
train() client id: f_00002-9-1 loss: 0.939981  [   64/  124]
train() client id: f_00002-9-2 loss: 1.021104  [   96/  124]
train() client id: f_00002-10-0 loss: 0.880508  [   32/  124]
train() client id: f_00002-10-1 loss: 1.120945  [   64/  124]
train() client id: f_00002-10-2 loss: 0.915982  [   96/  124]
train() client id: f_00002-11-0 loss: 0.942064  [   32/  124]
train() client id: f_00002-11-1 loss: 1.038997  [   64/  124]
train() client id: f_00002-11-2 loss: 0.985734  [   96/  124]
train() client id: f_00002-12-0 loss: 1.029449  [   32/  124]
train() client id: f_00002-12-1 loss: 1.057673  [   64/  124]
train() client id: f_00002-12-2 loss: 0.852923  [   96/  124]
train() client id: f_00003-0-0 loss: 0.726026  [   32/   43]
train() client id: f_00003-1-0 loss: 0.924963  [   32/   43]
train() client id: f_00003-2-0 loss: 0.727232  [   32/   43]
train() client id: f_00003-3-0 loss: 0.839883  [   32/   43]
train() client id: f_00003-4-0 loss: 0.926517  [   32/   43]
train() client id: f_00003-5-0 loss: 0.908195  [   32/   43]
train() client id: f_00003-6-0 loss: 1.023708  [   32/   43]
train() client id: f_00003-7-0 loss: 0.785450  [   32/   43]
train() client id: f_00003-8-0 loss: 0.860321  [   32/   43]
train() client id: f_00003-9-0 loss: 0.957978  [   32/   43]
train() client id: f_00003-10-0 loss: 0.836129  [   32/   43]
train() client id: f_00003-11-0 loss: 0.921923  [   32/   43]
train() client id: f_00003-12-0 loss: 0.813628  [   32/   43]
train() client id: f_00004-0-0 loss: 0.810405  [   32/  306]
train() client id: f_00004-0-1 loss: 0.743019  [   64/  306]
train() client id: f_00004-0-2 loss: 0.726121  [   96/  306]
train() client id: f_00004-0-3 loss: 0.650589  [  128/  306]
train() client id: f_00004-0-4 loss: 0.681340  [  160/  306]
train() client id: f_00004-0-5 loss: 0.673324  [  192/  306]
train() client id: f_00004-0-6 loss: 0.912006  [  224/  306]
train() client id: f_00004-0-7 loss: 0.655762  [  256/  306]
train() client id: f_00004-0-8 loss: 0.744038  [  288/  306]
train() client id: f_00004-1-0 loss: 0.787323  [   32/  306]
train() client id: f_00004-1-1 loss: 0.819742  [   64/  306]
train() client id: f_00004-1-2 loss: 0.772835  [   96/  306]
train() client id: f_00004-1-3 loss: 0.576847  [  128/  306]
train() client id: f_00004-1-4 loss: 0.739656  [  160/  306]
train() client id: f_00004-1-5 loss: 0.768902  [  192/  306]
train() client id: f_00004-1-6 loss: 0.690847  [  224/  306]
train() client id: f_00004-1-7 loss: 0.769866  [  256/  306]
train() client id: f_00004-1-8 loss: 0.703928  [  288/  306]
train() client id: f_00004-2-0 loss: 0.678194  [   32/  306]
train() client id: f_00004-2-1 loss: 0.710261  [   64/  306]
train() client id: f_00004-2-2 loss: 0.747986  [   96/  306]
train() client id: f_00004-2-3 loss: 0.723697  [  128/  306]
train() client id: f_00004-2-4 loss: 0.879953  [  160/  306]
train() client id: f_00004-2-5 loss: 0.640481  [  192/  306]
train() client id: f_00004-2-6 loss: 0.795064  [  224/  306]
train() client id: f_00004-2-7 loss: 0.719893  [  256/  306]
train() client id: f_00004-2-8 loss: 0.760835  [  288/  306]
train() client id: f_00004-3-0 loss: 0.671191  [   32/  306]
train() client id: f_00004-3-1 loss: 0.745429  [   64/  306]
train() client id: f_00004-3-2 loss: 0.742661  [   96/  306]
train() client id: f_00004-3-3 loss: 0.736270  [  128/  306]
train() client id: f_00004-3-4 loss: 0.780564  [  160/  306]
train() client id: f_00004-3-5 loss: 0.657831  [  192/  306]
train() client id: f_00004-3-6 loss: 0.717514  [  224/  306]
train() client id: f_00004-3-7 loss: 0.804103  [  256/  306]
train() client id: f_00004-3-8 loss: 0.841930  [  288/  306]
train() client id: f_00004-4-0 loss: 0.809260  [   32/  306]
train() client id: f_00004-4-1 loss: 0.890081  [   64/  306]
train() client id: f_00004-4-2 loss: 0.695418  [   96/  306]
train() client id: f_00004-4-3 loss: 0.790150  [  128/  306]
train() client id: f_00004-4-4 loss: 0.710373  [  160/  306]
train() client id: f_00004-4-5 loss: 0.753692  [  192/  306]
train() client id: f_00004-4-6 loss: 0.655988  [  224/  306]
train() client id: f_00004-4-7 loss: 0.695760  [  256/  306]
train() client id: f_00004-4-8 loss: 0.653862  [  288/  306]
train() client id: f_00004-5-0 loss: 0.699627  [   32/  306]
train() client id: f_00004-5-1 loss: 0.808739  [   64/  306]
train() client id: f_00004-5-2 loss: 0.824126  [   96/  306]
train() client id: f_00004-5-3 loss: 0.666997  [  128/  306]
train() client id: f_00004-5-4 loss: 0.675472  [  160/  306]
train() client id: f_00004-5-5 loss: 0.755150  [  192/  306]
train() client id: f_00004-5-6 loss: 0.724660  [  224/  306]
train() client id: f_00004-5-7 loss: 0.723888  [  256/  306]
train() client id: f_00004-5-8 loss: 0.838500  [  288/  306]
train() client id: f_00004-6-0 loss: 0.776901  [   32/  306]
train() client id: f_00004-6-1 loss: 0.714054  [   64/  306]
train() client id: f_00004-6-2 loss: 0.805290  [   96/  306]
train() client id: f_00004-6-3 loss: 0.852415  [  128/  306]
train() client id: f_00004-6-4 loss: 0.649415  [  160/  306]
train() client id: f_00004-6-5 loss: 0.755088  [  192/  306]
train() client id: f_00004-6-6 loss: 0.693943  [  224/  306]
train() client id: f_00004-6-7 loss: 0.781772  [  256/  306]
train() client id: f_00004-6-8 loss: 0.768652  [  288/  306]
train() client id: f_00004-7-0 loss: 0.789225  [   32/  306]
train() client id: f_00004-7-1 loss: 0.752929  [   64/  306]
train() client id: f_00004-7-2 loss: 0.756533  [   96/  306]
train() client id: f_00004-7-3 loss: 0.645815  [  128/  306]
train() client id: f_00004-7-4 loss: 0.801166  [  160/  306]
train() client id: f_00004-7-5 loss: 0.653939  [  192/  306]
train() client id: f_00004-7-6 loss: 0.674058  [  224/  306]
train() client id: f_00004-7-7 loss: 0.816451  [  256/  306]
train() client id: f_00004-7-8 loss: 0.898788  [  288/  306]
train() client id: f_00004-8-0 loss: 0.676533  [   32/  306]
train() client id: f_00004-8-1 loss: 0.810433  [   64/  306]
train() client id: f_00004-8-2 loss: 0.731137  [   96/  306]
train() client id: f_00004-8-3 loss: 0.741059  [  128/  306]
train() client id: f_00004-8-4 loss: 0.755476  [  160/  306]
train() client id: f_00004-8-5 loss: 0.848264  [  192/  306]
train() client id: f_00004-8-6 loss: 0.780361  [  224/  306]
train() client id: f_00004-8-7 loss: 0.746905  [  256/  306]
train() client id: f_00004-8-8 loss: 0.705162  [  288/  306]
train() client id: f_00004-9-0 loss: 0.710921  [   32/  306]
train() client id: f_00004-9-1 loss: 0.886112  [   64/  306]
train() client id: f_00004-9-2 loss: 0.825936  [   96/  306]
train() client id: f_00004-9-3 loss: 0.865117  [  128/  306]
train() client id: f_00004-9-4 loss: 0.794020  [  160/  306]
train() client id: f_00004-9-5 loss: 0.680528  [  192/  306]
train() client id: f_00004-9-6 loss: 0.724900  [  224/  306]
train() client id: f_00004-9-7 loss: 0.706785  [  256/  306]
train() client id: f_00004-9-8 loss: 0.620912  [  288/  306]
train() client id: f_00004-10-0 loss: 0.724950  [   32/  306]
train() client id: f_00004-10-1 loss: 0.731176  [   64/  306]
train() client id: f_00004-10-2 loss: 0.724065  [   96/  306]
train() client id: f_00004-10-3 loss: 0.774840  [  128/  306]
train() client id: f_00004-10-4 loss: 0.726283  [  160/  306]
train() client id: f_00004-10-5 loss: 0.818287  [  192/  306]
train() client id: f_00004-10-6 loss: 0.775854  [  224/  306]
train() client id: f_00004-10-7 loss: 0.761485  [  256/  306]
train() client id: f_00004-10-8 loss: 0.822777  [  288/  306]
train() client id: f_00004-11-0 loss: 0.722451  [   32/  306]
train() client id: f_00004-11-1 loss: 0.724753  [   64/  306]
train() client id: f_00004-11-2 loss: 0.799035  [   96/  306]
train() client id: f_00004-11-3 loss: 0.786281  [  128/  306]
train() client id: f_00004-11-4 loss: 0.807773  [  160/  306]
train() client id: f_00004-11-5 loss: 0.830730  [  192/  306]
train() client id: f_00004-11-6 loss: 0.723313  [  224/  306]
train() client id: f_00004-11-7 loss: 0.722546  [  256/  306]
train() client id: f_00004-11-8 loss: 0.718702  [  288/  306]
train() client id: f_00004-12-0 loss: 0.679870  [   32/  306]
train() client id: f_00004-12-1 loss: 0.659855  [   64/  306]
train() client id: f_00004-12-2 loss: 0.680105  [   96/  306]
train() client id: f_00004-12-3 loss: 0.759737  [  128/  306]
train() client id: f_00004-12-4 loss: 0.804512  [  160/  306]
train() client id: f_00004-12-5 loss: 0.762637  [  192/  306]
train() client id: f_00004-12-6 loss: 0.866316  [  224/  306]
train() client id: f_00004-12-7 loss: 0.771859  [  256/  306]
train() client id: f_00004-12-8 loss: 0.872797  [  288/  306]
train() client id: f_00005-0-0 loss: 0.807712  [   32/  146]
train() client id: f_00005-0-1 loss: 0.783096  [   64/  146]
train() client id: f_00005-0-2 loss: 0.901794  [   96/  146]
train() client id: f_00005-0-3 loss: 0.903849  [  128/  146]
train() client id: f_00005-1-0 loss: 1.043513  [   32/  146]
train() client id: f_00005-1-1 loss: 0.884184  [   64/  146]
train() client id: f_00005-1-2 loss: 0.904621  [   96/  146]
train() client id: f_00005-1-3 loss: 0.809567  [  128/  146]
train() client id: f_00005-2-0 loss: 0.968727  [   32/  146]
train() client id: f_00005-2-1 loss: 0.937567  [   64/  146]
train() client id: f_00005-2-2 loss: 0.785450  [   96/  146]
train() client id: f_00005-2-3 loss: 0.798486  [  128/  146]
train() client id: f_00005-3-0 loss: 0.965706  [   32/  146]
train() client id: f_00005-3-1 loss: 0.802997  [   64/  146]
train() client id: f_00005-3-2 loss: 0.877836  [   96/  146]
train() client id: f_00005-3-3 loss: 0.876665  [  128/  146]
train() client id: f_00005-4-0 loss: 0.690070  [   32/  146]
train() client id: f_00005-4-1 loss: 1.011198  [   64/  146]
train() client id: f_00005-4-2 loss: 0.963225  [   96/  146]
train() client id: f_00005-4-3 loss: 0.946381  [  128/  146]
train() client id: f_00005-5-0 loss: 1.135448  [   32/  146]
train() client id: f_00005-5-1 loss: 0.783915  [   64/  146]
train() client id: f_00005-5-2 loss: 0.694347  [   96/  146]
train() client id: f_00005-5-3 loss: 0.841181  [  128/  146]
train() client id: f_00005-6-0 loss: 0.850330  [   32/  146]
train() client id: f_00005-6-1 loss: 1.130694  [   64/  146]
train() client id: f_00005-6-2 loss: 0.838803  [   96/  146]
train() client id: f_00005-6-3 loss: 0.753116  [  128/  146]
train() client id: f_00005-7-0 loss: 0.744924  [   32/  146]
train() client id: f_00005-7-1 loss: 0.959203  [   64/  146]
train() client id: f_00005-7-2 loss: 0.760606  [   96/  146]
train() client id: f_00005-7-3 loss: 0.964548  [  128/  146]
train() client id: f_00005-8-0 loss: 0.758476  [   32/  146]
train() client id: f_00005-8-1 loss: 0.965258  [   64/  146]
train() client id: f_00005-8-2 loss: 0.904010  [   96/  146]
train() client id: f_00005-8-3 loss: 0.925896  [  128/  146]
train() client id: f_00005-9-0 loss: 0.743006  [   32/  146]
train() client id: f_00005-9-1 loss: 0.962323  [   64/  146]
train() client id: f_00005-9-2 loss: 0.869856  [   96/  146]
train() client id: f_00005-9-3 loss: 0.820366  [  128/  146]
train() client id: f_00005-10-0 loss: 0.883234  [   32/  146]
train() client id: f_00005-10-1 loss: 0.864912  [   64/  146]
train() client id: f_00005-10-2 loss: 0.721820  [   96/  146]
train() client id: f_00005-10-3 loss: 1.037490  [  128/  146]
train() client id: f_00005-11-0 loss: 0.698446  [   32/  146]
train() client id: f_00005-11-1 loss: 0.760016  [   64/  146]
train() client id: f_00005-11-2 loss: 0.801429  [   96/  146]
train() client id: f_00005-11-3 loss: 0.937703  [  128/  146]
train() client id: f_00005-12-0 loss: 1.070263  [   32/  146]
train() client id: f_00005-12-1 loss: 1.078308  [   64/  146]
train() client id: f_00005-12-2 loss: 0.657622  [   96/  146]
train() client id: f_00005-12-3 loss: 0.681422  [  128/  146]
train() client id: f_00006-0-0 loss: 0.709725  [   32/   54]
train() client id: f_00006-1-0 loss: 0.702806  [   32/   54]
train() client id: f_00006-2-0 loss: 0.644420  [   32/   54]
train() client id: f_00006-3-0 loss: 0.645527  [   32/   54]
train() client id: f_00006-4-0 loss: 0.653543  [   32/   54]
train() client id: f_00006-5-0 loss: 0.705351  [   32/   54]
train() client id: f_00006-6-0 loss: 0.704867  [   32/   54]
train() client id: f_00006-7-0 loss: 0.650277  [   32/   54]
train() client id: f_00006-8-0 loss: 0.720856  [   32/   54]
train() client id: f_00006-9-0 loss: 0.708710  [   32/   54]
train() client id: f_00006-10-0 loss: 0.679623  [   32/   54]
train() client id: f_00006-11-0 loss: 0.646864  [   32/   54]
train() client id: f_00006-12-0 loss: 0.680451  [   32/   54]
train() client id: f_00007-0-0 loss: 0.652264  [   32/  179]
train() client id: f_00007-0-1 loss: 0.875493  [   64/  179]
train() client id: f_00007-0-2 loss: 0.639915  [   96/  179]
train() client id: f_00007-0-3 loss: 0.719526  [  128/  179]
train() client id: f_00007-0-4 loss: 0.820716  [  160/  179]
train() client id: f_00007-1-0 loss: 0.765745  [   32/  179]
train() client id: f_00007-1-1 loss: 0.764648  [   64/  179]
train() client id: f_00007-1-2 loss: 0.646603  [   96/  179]
train() client id: f_00007-1-3 loss: 0.885216  [  128/  179]
train() client id: f_00007-1-4 loss: 0.621246  [  160/  179]
train() client id: f_00007-2-0 loss: 0.780213  [   32/  179]
train() client id: f_00007-2-1 loss: 0.687913  [   64/  179]
train() client id: f_00007-2-2 loss: 0.703301  [   96/  179]
train() client id: f_00007-2-3 loss: 0.669034  [  128/  179]
train() client id: f_00007-2-4 loss: 0.641268  [  160/  179]
train() client id: f_00007-3-0 loss: 0.731752  [   32/  179]
train() client id: f_00007-3-1 loss: 0.675847  [   64/  179]
train() client id: f_00007-3-2 loss: 0.612910  [   96/  179]
train() client id: f_00007-3-3 loss: 0.705784  [  128/  179]
train() client id: f_00007-3-4 loss: 0.603888  [  160/  179]
train() client id: f_00007-4-0 loss: 0.899406  [   32/  179]
train() client id: f_00007-4-1 loss: 0.658385  [   64/  179]
train() client id: f_00007-4-2 loss: 0.641219  [   96/  179]
train() client id: f_00007-4-3 loss: 0.549034  [  128/  179]
train() client id: f_00007-4-4 loss: 0.584600  [  160/  179]
train() client id: f_00007-5-0 loss: 0.714659  [   32/  179]
train() client id: f_00007-5-1 loss: 0.621101  [   64/  179]
train() client id: f_00007-5-2 loss: 0.650432  [   96/  179]
train() client id: f_00007-5-3 loss: 0.684626  [  128/  179]
train() client id: f_00007-5-4 loss: 0.706006  [  160/  179]
train() client id: f_00007-6-0 loss: 0.616576  [   32/  179]
train() client id: f_00007-6-1 loss: 0.735301  [   64/  179]
train() client id: f_00007-6-2 loss: 0.794489  [   96/  179]
train() client id: f_00007-6-3 loss: 0.633993  [  128/  179]
train() client id: f_00007-6-4 loss: 0.542918  [  160/  179]
train() client id: f_00007-7-0 loss: 0.799019  [   32/  179]
train() client id: f_00007-7-1 loss: 0.569597  [   64/  179]
train() client id: f_00007-7-2 loss: 0.688518  [   96/  179]
train() client id: f_00007-7-3 loss: 0.525183  [  128/  179]
train() client id: f_00007-7-4 loss: 0.679494  [  160/  179]
train() client id: f_00007-8-0 loss: 0.806097  [   32/  179]
train() client id: f_00007-8-1 loss: 0.620398  [   64/  179]
train() client id: f_00007-8-2 loss: 0.719762  [   96/  179]
train() client id: f_00007-8-3 loss: 0.630213  [  128/  179]
train() client id: f_00007-8-4 loss: 0.520753  [  160/  179]
train() client id: f_00007-9-0 loss: 0.717838  [   32/  179]
train() client id: f_00007-9-1 loss: 0.720855  [   64/  179]
train() client id: f_00007-9-2 loss: 0.605030  [   96/  179]
train() client id: f_00007-9-3 loss: 0.794987  [  128/  179]
train() client id: f_00007-9-4 loss: 0.535055  [  160/  179]
train() client id: f_00007-10-0 loss: 0.825231  [   32/  179]
train() client id: f_00007-10-1 loss: 0.648884  [   64/  179]
train() client id: f_00007-10-2 loss: 0.610608  [   96/  179]
train() client id: f_00007-10-3 loss: 0.766596  [  128/  179]
train() client id: f_00007-10-4 loss: 0.530156  [  160/  179]
train() client id: f_00007-11-0 loss: 0.523630  [   32/  179]
train() client id: f_00007-11-1 loss: 0.756258  [   64/  179]
train() client id: f_00007-11-2 loss: 0.843496  [   96/  179]
train() client id: f_00007-11-3 loss: 0.619630  [  128/  179]
train() client id: f_00007-11-4 loss: 0.632827  [  160/  179]
train() client id: f_00007-12-0 loss: 0.584931  [   32/  179]
train() client id: f_00007-12-1 loss: 0.669793  [   64/  179]
train() client id: f_00007-12-2 loss: 0.619827  [   96/  179]
train() client id: f_00007-12-3 loss: 0.616442  [  128/  179]
train() client id: f_00007-12-4 loss: 0.782911  [  160/  179]
train() client id: f_00008-0-0 loss: 0.900499  [   32/  130]
train() client id: f_00008-0-1 loss: 0.902980  [   64/  130]
train() client id: f_00008-0-2 loss: 0.817931  [   96/  130]
train() client id: f_00008-0-3 loss: 0.874044  [  128/  130]
train() client id: f_00008-1-0 loss: 0.912848  [   32/  130]
train() client id: f_00008-1-1 loss: 0.817631  [   64/  130]
train() client id: f_00008-1-2 loss: 0.867823  [   96/  130]
train() client id: f_00008-1-3 loss: 0.887763  [  128/  130]
train() client id: f_00008-2-0 loss: 0.889116  [   32/  130]
train() client id: f_00008-2-1 loss: 0.801667  [   64/  130]
train() client id: f_00008-2-2 loss: 0.877975  [   96/  130]
train() client id: f_00008-2-3 loss: 0.913950  [  128/  130]
train() client id: f_00008-3-0 loss: 0.951065  [   32/  130]
train() client id: f_00008-3-1 loss: 0.760906  [   64/  130]
train() client id: f_00008-3-2 loss: 0.888144  [   96/  130]
train() client id: f_00008-3-3 loss: 0.878106  [  128/  130]
train() client id: f_00008-4-0 loss: 0.897895  [   32/  130]
train() client id: f_00008-4-1 loss: 0.938640  [   64/  130]
train() client id: f_00008-4-2 loss: 0.861634  [   96/  130]
train() client id: f_00008-4-3 loss: 0.779667  [  128/  130]
train() client id: f_00008-5-0 loss: 0.938895  [   32/  130]
train() client id: f_00008-5-1 loss: 0.846750  [   64/  130]
train() client id: f_00008-5-2 loss: 0.849506  [   96/  130]
train() client id: f_00008-5-3 loss: 0.838035  [  128/  130]
train() client id: f_00008-6-0 loss: 0.835718  [   32/  130]
train() client id: f_00008-6-1 loss: 0.802855  [   64/  130]
train() client id: f_00008-6-2 loss: 0.943427  [   96/  130]
train() client id: f_00008-6-3 loss: 0.856209  [  128/  130]
train() client id: f_00008-7-0 loss: 0.816080  [   32/  130]
train() client id: f_00008-7-1 loss: 0.871460  [   64/  130]
train() client id: f_00008-7-2 loss: 0.967438  [   96/  130]
train() client id: f_00008-7-3 loss: 0.792471  [  128/  130]
train() client id: f_00008-8-0 loss: 0.873312  [   32/  130]
train() client id: f_00008-8-1 loss: 0.789939  [   64/  130]
train() client id: f_00008-8-2 loss: 0.881035  [   96/  130]
train() client id: f_00008-8-3 loss: 0.925811  [  128/  130]
train() client id: f_00008-9-0 loss: 0.899779  [   32/  130]
train() client id: f_00008-9-1 loss: 0.909203  [   64/  130]
train() client id: f_00008-9-2 loss: 0.764776  [   96/  130]
train() client id: f_00008-9-3 loss: 0.895484  [  128/  130]
train() client id: f_00008-10-0 loss: 0.962177  [   32/  130]
train() client id: f_00008-10-1 loss: 0.799411  [   64/  130]
train() client id: f_00008-10-2 loss: 0.883296  [   96/  130]
train() client id: f_00008-10-3 loss: 0.830493  [  128/  130]
train() client id: f_00008-11-0 loss: 0.748970  [   32/  130]
train() client id: f_00008-11-1 loss: 0.874418  [   64/  130]
train() client id: f_00008-11-2 loss: 0.846681  [   96/  130]
train() client id: f_00008-11-3 loss: 0.999538  [  128/  130]
train() client id: f_00008-12-0 loss: 0.840187  [   32/  130]
train() client id: f_00008-12-1 loss: 0.782497  [   64/  130]
train() client id: f_00008-12-2 loss: 0.920982  [   96/  130]
train() client id: f_00008-12-3 loss: 0.904113  [  128/  130]
train() client id: f_00009-0-0 loss: 1.152380  [   32/  118]
train() client id: f_00009-0-1 loss: 1.163514  [   64/  118]
train() client id: f_00009-0-2 loss: 1.111087  [   96/  118]
train() client id: f_00009-1-0 loss: 1.083459  [   32/  118]
train() client id: f_00009-1-1 loss: 1.166211  [   64/  118]
train() client id: f_00009-1-2 loss: 1.063262  [   96/  118]
train() client id: f_00009-2-0 loss: 1.069460  [   32/  118]
train() client id: f_00009-2-1 loss: 1.059898  [   64/  118]
train() client id: f_00009-2-2 loss: 1.050475  [   96/  118]
train() client id: f_00009-3-0 loss: 1.045532  [   32/  118]
train() client id: f_00009-3-1 loss: 0.953527  [   64/  118]
train() client id: f_00009-3-2 loss: 1.084800  [   96/  118]
train() client id: f_00009-4-0 loss: 0.987504  [   32/  118]
train() client id: f_00009-4-1 loss: 1.021591  [   64/  118]
train() client id: f_00009-4-2 loss: 0.960850  [   96/  118]
train() client id: f_00009-5-0 loss: 0.987660  [   32/  118]
train() client id: f_00009-5-1 loss: 1.108953  [   64/  118]
train() client id: f_00009-5-2 loss: 0.912321  [   96/  118]
train() client id: f_00009-6-0 loss: 0.980813  [   32/  118]
train() client id: f_00009-6-1 loss: 1.024476  [   64/  118]
train() client id: f_00009-6-2 loss: 0.910717  [   96/  118]
train() client id: f_00009-7-0 loss: 0.981623  [   32/  118]
train() client id: f_00009-7-1 loss: 0.969457  [   64/  118]
train() client id: f_00009-7-2 loss: 1.002219  [   96/  118]
train() client id: f_00009-8-0 loss: 0.964112  [   32/  118]
train() client id: f_00009-8-1 loss: 0.893211  [   64/  118]
train() client id: f_00009-8-2 loss: 0.953535  [   96/  118]
train() client id: f_00009-9-0 loss: 0.894923  [   32/  118]
train() client id: f_00009-9-1 loss: 0.921736  [   64/  118]
train() client id: f_00009-9-2 loss: 0.961657  [   96/  118]
train() client id: f_00009-10-0 loss: 0.892761  [   32/  118]
train() client id: f_00009-10-1 loss: 0.927718  [   64/  118]
train() client id: f_00009-10-2 loss: 0.981036  [   96/  118]
train() client id: f_00009-11-0 loss: 1.003130  [   32/  118]
train() client id: f_00009-11-1 loss: 0.914776  [   64/  118]
train() client id: f_00009-11-2 loss: 0.962967  [   96/  118]
train() client id: f_00009-12-0 loss: 0.897780  [   32/  118]
train() client id: f_00009-12-1 loss: 0.946346  [   64/  118]
train() client id: f_00009-12-2 loss: 0.962624  [   96/  118]
At round 10 accuracy: 0.6339522546419099
At round 10 training accuracy: 0.5781354795439303
At round 10 training loss: 0.861327588802219
gradient difference: 0.4173339903354645
train() client id: f_00000-0-0 loss: 1.296541  [   32/  126]
train() client id: f_00000-0-1 loss: 1.255597  [   64/  126]
train() client id: f_00000-0-2 loss: 1.312766  [   96/  126]
train() client id: f_00000-1-0 loss: 1.283597  [   32/  126]
train() client id: f_00000-1-1 loss: 1.269537  [   64/  126]
train() client id: f_00000-1-2 loss: 1.077335  [   96/  126]
train() client id: f_00000-2-0 loss: 1.197724  [   32/  126]
train() client id: f_00000-2-1 loss: 1.074907  [   64/  126]
train() client id: f_00000-2-2 loss: 1.059975  [   96/  126]
train() client id: f_00000-3-0 loss: 1.011127  [   32/  126]
train() client id: f_00000-3-1 loss: 1.066253  [   64/  126]
train() client id: f_00000-3-2 loss: 1.105372  [   96/  126]
train() client id: f_00000-4-0 loss: 1.096685  [   32/  126]
train() client id: f_00000-4-1 loss: 1.042682  [   64/  126]
train() client id: f_00000-4-2 loss: 0.960882  [   96/  126]
train() client id: f_00000-5-0 loss: 1.025723  [   32/  126]
train() client id: f_00000-5-1 loss: 0.967227  [   64/  126]
train() client id: f_00000-5-2 loss: 1.022559  [   96/  126]
train() client id: f_00000-6-0 loss: 0.962981  [   32/  126]
train() client id: f_00000-6-1 loss: 0.983935  [   64/  126]
train() client id: f_00000-6-2 loss: 0.980583  [   96/  126]
train() client id: f_00000-7-0 loss: 0.904079  [   32/  126]
train() client id: f_00000-7-1 loss: 0.891839  [   64/  126]
train() client id: f_00000-7-2 loss: 0.917609  [   96/  126]
train() client id: f_00000-8-0 loss: 0.878292  [   32/  126]
train() client id: f_00000-8-1 loss: 1.012337  [   64/  126]
train() client id: f_00000-8-2 loss: 0.845544  [   96/  126]
train() client id: f_00000-9-0 loss: 0.929147  [   32/  126]
train() client id: f_00000-9-1 loss: 0.980272  [   64/  126]
train() client id: f_00000-9-2 loss: 0.912211  [   96/  126]
train() client id: f_00000-10-0 loss: 0.956790  [   32/  126]
train() client id: f_00000-10-1 loss: 0.993798  [   64/  126]
train() client id: f_00000-10-2 loss: 0.854866  [   96/  126]
train() client id: f_00000-11-0 loss: 0.937383  [   32/  126]
train() client id: f_00000-11-1 loss: 0.908389  [   64/  126]
train() client id: f_00000-11-2 loss: 0.884284  [   96/  126]
train() client id: f_00000-12-0 loss: 0.863041  [   32/  126]
train() client id: f_00000-12-1 loss: 0.913946  [   64/  126]
train() client id: f_00000-12-2 loss: 0.887994  [   96/  126]
train() client id: f_00001-0-0 loss: 0.576035  [   32/  265]
train() client id: f_00001-0-1 loss: 0.478698  [   64/  265]
train() client id: f_00001-0-2 loss: 0.469658  [   96/  265]
train() client id: f_00001-0-3 loss: 0.475388  [  128/  265]
train() client id: f_00001-0-4 loss: 0.650951  [  160/  265]
train() client id: f_00001-0-5 loss: 0.536479  [  192/  265]
train() client id: f_00001-0-6 loss: 0.451752  [  224/  265]
train() client id: f_00001-0-7 loss: 0.477377  [  256/  265]
train() client id: f_00001-1-0 loss: 0.520205  [   32/  265]
train() client id: f_00001-1-1 loss: 0.441515  [   64/  265]
train() client id: f_00001-1-2 loss: 0.561687  [   96/  265]
train() client id: f_00001-1-3 loss: 0.555911  [  128/  265]
train() client id: f_00001-1-4 loss: 0.441776  [  160/  265]
train() client id: f_00001-1-5 loss: 0.439305  [  192/  265]
train() client id: f_00001-1-6 loss: 0.574457  [  224/  265]
train() client id: f_00001-1-7 loss: 0.469613  [  256/  265]
train() client id: f_00001-2-0 loss: 0.455984  [   32/  265]
train() client id: f_00001-2-1 loss: 0.474005  [   64/  265]
train() client id: f_00001-2-2 loss: 0.416659  [   96/  265]
train() client id: f_00001-2-3 loss: 0.500650  [  128/  265]
train() client id: f_00001-2-4 loss: 0.528568  [  160/  265]
train() client id: f_00001-2-5 loss: 0.572170  [  192/  265]
train() client id: f_00001-2-6 loss: 0.506367  [  224/  265]
train() client id: f_00001-2-7 loss: 0.433637  [  256/  265]
train() client id: f_00001-3-0 loss: 0.453768  [   32/  265]
train() client id: f_00001-3-1 loss: 0.507827  [   64/  265]
train() client id: f_00001-3-2 loss: 0.458742  [   96/  265]
train() client id: f_00001-3-3 loss: 0.494091  [  128/  265]
train() client id: f_00001-3-4 loss: 0.543314  [  160/  265]
train() client id: f_00001-3-5 loss: 0.509407  [  192/  265]
train() client id: f_00001-3-6 loss: 0.395470  [  224/  265]
train() client id: f_00001-3-7 loss: 0.430353  [  256/  265]
train() client id: f_00001-4-0 loss: 0.564028  [   32/  265]
train() client id: f_00001-4-1 loss: 0.460650  [   64/  265]
train() client id: f_00001-4-2 loss: 0.469749  [   96/  265]
train() client id: f_00001-4-3 loss: 0.508703  [  128/  265]
train() client id: f_00001-4-4 loss: 0.414101  [  160/  265]
train() client id: f_00001-4-5 loss: 0.480856  [  192/  265]
train() client id: f_00001-4-6 loss: 0.486388  [  224/  265]
train() client id: f_00001-4-7 loss: 0.407261  [  256/  265]
train() client id: f_00001-5-0 loss: 0.592153  [   32/  265]
train() client id: f_00001-5-1 loss: 0.426440  [   64/  265]
train() client id: f_00001-5-2 loss: 0.387267  [   96/  265]
train() client id: f_00001-5-3 loss: 0.418929  [  128/  265]
train() client id: f_00001-5-4 loss: 0.453765  [  160/  265]
train() client id: f_00001-5-5 loss: 0.425508  [  192/  265]
train() client id: f_00001-5-6 loss: 0.413374  [  224/  265]
train() client id: f_00001-5-7 loss: 0.568581  [  256/  265]
train() client id: f_00001-6-0 loss: 0.432042  [   32/  265]
train() client id: f_00001-6-1 loss: 0.466165  [   64/  265]
train() client id: f_00001-6-2 loss: 0.382379  [   96/  265]
train() client id: f_00001-6-3 loss: 0.538612  [  128/  265]
train() client id: f_00001-6-4 loss: 0.417863  [  160/  265]
train() client id: f_00001-6-5 loss: 0.428848  [  192/  265]
train() client id: f_00001-6-6 loss: 0.574470  [  224/  265]
train() client id: f_00001-6-7 loss: 0.470781  [  256/  265]
train() client id: f_00001-7-0 loss: 0.570716  [   32/  265]
train() client id: f_00001-7-1 loss: 0.471759  [   64/  265]
train() client id: f_00001-7-2 loss: 0.502691  [   96/  265]
train() client id: f_00001-7-3 loss: 0.407261  [  128/  265]
train() client id: f_00001-7-4 loss: 0.431079  [  160/  265]
train() client id: f_00001-7-5 loss: 0.476972  [  192/  265]
train() client id: f_00001-7-6 loss: 0.423274  [  224/  265]
train() client id: f_00001-7-7 loss: 0.403440  [  256/  265]
train() client id: f_00001-8-0 loss: 0.365581  [   32/  265]
train() client id: f_00001-8-1 loss: 0.423884  [   64/  265]
train() client id: f_00001-8-2 loss: 0.386466  [   96/  265]
train() client id: f_00001-8-3 loss: 0.538005  [  128/  265]
train() client id: f_00001-8-4 loss: 0.627484  [  160/  265]
train() client id: f_00001-8-5 loss: 0.448912  [  192/  265]
train() client id: f_00001-8-6 loss: 0.490155  [  224/  265]
train() client id: f_00001-8-7 loss: 0.411592  [  256/  265]
train() client id: f_00001-9-0 loss: 0.423027  [   32/  265]
train() client id: f_00001-9-1 loss: 0.456339  [   64/  265]
train() client id: f_00001-9-2 loss: 0.434025  [   96/  265]
train() client id: f_00001-9-3 loss: 0.450965  [  128/  265]
train() client id: f_00001-9-4 loss: 0.511183  [  160/  265]
train() client id: f_00001-9-5 loss: 0.442601  [  192/  265]
train() client id: f_00001-9-6 loss: 0.436562  [  224/  265]
train() client id: f_00001-9-7 loss: 0.427546  [  256/  265]
train() client id: f_00001-10-0 loss: 0.455537  [   32/  265]
train() client id: f_00001-10-1 loss: 0.620482  [   64/  265]
train() client id: f_00001-10-2 loss: 0.471567  [   96/  265]
train() client id: f_00001-10-3 loss: 0.380934  [  128/  265]
train() client id: f_00001-10-4 loss: 0.422564  [  160/  265]
train() client id: f_00001-10-5 loss: 0.386145  [  192/  265]
train() client id: f_00001-10-6 loss: 0.429172  [  224/  265]
train() client id: f_00001-10-7 loss: 0.395661  [  256/  265]
train() client id: f_00001-11-0 loss: 0.478802  [   32/  265]
train() client id: f_00001-11-1 loss: 0.364073  [   64/  265]
train() client id: f_00001-11-2 loss: 0.446861  [   96/  265]
train() client id: f_00001-11-3 loss: 0.397576  [  128/  265]
train() client id: f_00001-11-4 loss: 0.428133  [  160/  265]
train() client id: f_00001-11-5 loss: 0.598097  [  192/  265]
train() client id: f_00001-11-6 loss: 0.520133  [  224/  265]
train() client id: f_00001-11-7 loss: 0.428802  [  256/  265]
train() client id: f_00001-12-0 loss: 0.471269  [   32/  265]
train() client id: f_00001-12-1 loss: 0.428984  [   64/  265]
train() client id: f_00001-12-2 loss: 0.380476  [   96/  265]
train() client id: f_00001-12-3 loss: 0.480050  [  128/  265]
train() client id: f_00001-12-4 loss: 0.377678  [  160/  265]
train() client id: f_00001-12-5 loss: 0.579539  [  192/  265]
train() client id: f_00001-12-6 loss: 0.448945  [  224/  265]
train() client id: f_00001-12-7 loss: 0.503585  [  256/  265]
train() client id: f_00002-0-0 loss: 1.411926  [   32/  124]
train() client id: f_00002-0-1 loss: 1.386171  [   64/  124]
train() client id: f_00002-0-2 loss: 1.299582  [   96/  124]
train() client id: f_00002-1-0 loss: 1.292724  [   32/  124]
train() client id: f_00002-1-1 loss: 1.350709  [   64/  124]
train() client id: f_00002-1-2 loss: 1.315932  [   96/  124]
train() client id: f_00002-2-0 loss: 1.290590  [   32/  124]
train() client id: f_00002-2-1 loss: 1.300626  [   64/  124]
train() client id: f_00002-2-2 loss: 1.266752  [   96/  124]
train() client id: f_00002-3-0 loss: 1.166729  [   32/  124]
train() client id: f_00002-3-1 loss: 1.326860  [   64/  124]
train() client id: f_00002-3-2 loss: 1.301832  [   96/  124]
train() client id: f_00002-4-0 loss: 1.196761  [   32/  124]
train() client id: f_00002-4-1 loss: 1.195533  [   64/  124]
train() client id: f_00002-4-2 loss: 1.222221  [   96/  124]
train() client id: f_00002-5-0 loss: 1.204324  [   32/  124]
train() client id: f_00002-5-1 loss: 1.262621  [   64/  124]
train() client id: f_00002-5-2 loss: 1.150217  [   96/  124]
train() client id: f_00002-6-0 loss: 1.182124  [   32/  124]
train() client id: f_00002-6-1 loss: 1.236432  [   64/  124]
train() client id: f_00002-6-2 loss: 1.140950  [   96/  124]
train() client id: f_00002-7-0 loss: 1.186514  [   32/  124]
train() client id: f_00002-7-1 loss: 1.084117  [   64/  124]
train() client id: f_00002-7-2 loss: 1.225733  [   96/  124]
train() client id: f_00002-8-0 loss: 1.232641  [   32/  124]
train() client id: f_00002-8-1 loss: 1.129780  [   64/  124]
train() client id: f_00002-8-2 loss: 1.051223  [   96/  124]
train() client id: f_00002-9-0 loss: 1.125861  [   32/  124]
train() client id: f_00002-9-1 loss: 1.118290  [   64/  124]
train() client id: f_00002-9-2 loss: 1.161840  [   96/  124]
train() client id: f_00002-10-0 loss: 1.105059  [   32/  124]
train() client id: f_00002-10-1 loss: 1.075500  [   64/  124]
train() client id: f_00002-10-2 loss: 1.227107  [   96/  124]
train() client id: f_00002-11-0 loss: 1.126776  [   32/  124]
train() client id: f_00002-11-1 loss: 1.215307  [   64/  124]
train() client id: f_00002-11-2 loss: 1.253075  [   96/  124]
train() client id: f_00002-12-0 loss: 1.174066  [   32/  124]
train() client id: f_00002-12-1 loss: 1.128470  [   64/  124]
train() client id: f_00002-12-2 loss: 1.166940  [   96/  124]
train() client id: f_00003-0-0 loss: 0.960744  [   32/   43]
train() client id: f_00003-1-0 loss: 0.859638  [   32/   43]
train() client id: f_00003-2-0 loss: 0.958079  [   32/   43]
train() client id: f_00003-3-0 loss: 1.019698  [   32/   43]
train() client id: f_00003-4-0 loss: 0.789583  [   32/   43]
train() client id: f_00003-5-0 loss: 0.970792  [   32/   43]
train() client id: f_00003-6-0 loss: 0.911515  [   32/   43]
train() client id: f_00003-7-0 loss: 0.993874  [   32/   43]
train() client id: f_00003-8-0 loss: 0.875102  [   32/   43]
train() client id: f_00003-9-0 loss: 0.900844  [   32/   43]
train() client id: f_00003-10-0 loss: 0.960652  [   32/   43]
train() client id: f_00003-11-0 loss: 0.951411  [   32/   43]
train() client id: f_00003-12-0 loss: 1.000961  [   32/   43]
train() client id: f_00004-0-0 loss: 0.871128  [   32/  306]
train() client id: f_00004-0-1 loss: 0.758094  [   64/  306]
train() client id: f_00004-0-2 loss: 0.728683  [   96/  306]
train() client id: f_00004-0-3 loss: 0.954438  [  128/  306]
train() client id: f_00004-0-4 loss: 0.828846  [  160/  306]
train() client id: f_00004-0-5 loss: 0.710822  [  192/  306]
train() client id: f_00004-0-6 loss: 0.769803  [  224/  306]
train() client id: f_00004-0-7 loss: 0.789216  [  256/  306]
train() client id: f_00004-0-8 loss: 0.650733  [  288/  306]
train() client id: f_00004-1-0 loss: 0.832577  [   32/  306]
train() client id: f_00004-1-1 loss: 0.861689  [   64/  306]
train() client id: f_00004-1-2 loss: 0.798767  [   96/  306]
train() client id: f_00004-1-3 loss: 0.657539  [  128/  306]
train() client id: f_00004-1-4 loss: 0.692685  [  160/  306]
train() client id: f_00004-1-5 loss: 0.743358  [  192/  306]
train() client id: f_00004-1-6 loss: 0.791989  [  224/  306]
train() client id: f_00004-1-7 loss: 0.667481  [  256/  306]
train() client id: f_00004-1-8 loss: 0.825707  [  288/  306]
train() client id: f_00004-2-0 loss: 0.880161  [   32/  306]
train() client id: f_00004-2-1 loss: 0.769678  [   64/  306]
train() client id: f_00004-2-2 loss: 0.788422  [   96/  306]
train() client id: f_00004-2-3 loss: 0.677739  [  128/  306]
train() client id: f_00004-2-4 loss: 0.746743  [  160/  306]
train() client id: f_00004-2-5 loss: 0.731803  [  192/  306]
train() client id: f_00004-2-6 loss: 0.836705  [  224/  306]
train() client id: f_00004-2-7 loss: 0.852338  [  256/  306]
train() client id: f_00004-2-8 loss: 0.708860  [  288/  306]
train() client id: f_00004-3-0 loss: 0.621173  [   32/  306]
train() client id: f_00004-3-1 loss: 0.828810  [   64/  306]
train() client id: f_00004-3-2 loss: 0.709415  [   96/  306]
train() client id: f_00004-3-3 loss: 0.892125  [  128/  306]
train() client id: f_00004-3-4 loss: 0.810051  [  160/  306]
train() client id: f_00004-3-5 loss: 0.734724  [  192/  306]
train() client id: f_00004-3-6 loss: 0.826059  [  224/  306]
train() client id: f_00004-3-7 loss: 0.740066  [  256/  306]
train() client id: f_00004-3-8 loss: 0.853144  [  288/  306]
train() client id: f_00004-4-0 loss: 0.868604  [   32/  306]
train() client id: f_00004-4-1 loss: 0.755858  [   64/  306]
train() client id: f_00004-4-2 loss: 0.730913  [   96/  306]
train() client id: f_00004-4-3 loss: 0.760193  [  128/  306]
train() client id: f_00004-4-4 loss: 0.725545  [  160/  306]
train() client id: f_00004-4-5 loss: 0.640338  [  192/  306]
train() client id: f_00004-4-6 loss: 0.780521  [  224/  306]
train() client id: f_00004-4-7 loss: 0.919818  [  256/  306]
train() client id: f_00004-4-8 loss: 0.819300  [  288/  306]
train() client id: f_00004-5-0 loss: 0.747982  [   32/  306]
train() client id: f_00004-5-1 loss: 0.896167  [   64/  306]
train() client id: f_00004-5-2 loss: 0.683428  [   96/  306]
train() client id: f_00004-5-3 loss: 0.807974  [  128/  306]
train() client id: f_00004-5-4 loss: 0.715146  [  160/  306]
train() client id: f_00004-5-5 loss: 0.780184  [  192/  306]
train() client id: f_00004-5-6 loss: 0.745668  [  224/  306]
train() client id: f_00004-5-7 loss: 0.806333  [  256/  306]
train() client id: f_00004-5-8 loss: 0.727248  [  288/  306]
train() client id: f_00004-6-0 loss: 0.696335  [   32/  306]
train() client id: f_00004-6-1 loss: 0.756083  [   64/  306]
train() client id: f_00004-6-2 loss: 0.661567  [   96/  306]
train() client id: f_00004-6-3 loss: 0.833148  [  128/  306]
train() client id: f_00004-6-4 loss: 0.925033  [  160/  306]
train() client id: f_00004-6-5 loss: 0.715359  [  192/  306]
train() client id: f_00004-6-6 loss: 0.975673  [  224/  306]
train() client id: f_00004-6-7 loss: 0.690461  [  256/  306]
train() client id: f_00004-6-8 loss: 0.783338  [  288/  306]
train() client id: f_00004-7-0 loss: 0.697492  [   32/  306]
train() client id: f_00004-7-1 loss: 0.779637  [   64/  306]
train() client id: f_00004-7-2 loss: 0.758189  [   96/  306]
train() client id: f_00004-7-3 loss: 0.961803  [  128/  306]
train() client id: f_00004-7-4 loss: 0.656512  [  160/  306]
train() client id: f_00004-7-5 loss: 0.696628  [  192/  306]
train() client id: f_00004-7-6 loss: 0.893162  [  224/  306]
train() client id: f_00004-7-7 loss: 0.859704  [  256/  306]
train() client id: f_00004-7-8 loss: 0.777986  [  288/  306]
train() client id: f_00004-8-0 loss: 0.845792  [   32/  306]
train() client id: f_00004-8-1 loss: 0.766274  [   64/  306]
train() client id: f_00004-8-2 loss: 0.774388  [   96/  306]
train() client id: f_00004-8-3 loss: 0.742653  [  128/  306]
train() client id: f_00004-8-4 loss: 0.833016  [  160/  306]
train() client id: f_00004-8-5 loss: 0.794029  [  192/  306]
train() client id: f_00004-8-6 loss: 0.758741  [  224/  306]
train() client id: f_00004-8-7 loss: 0.797724  [  256/  306]
train() client id: f_00004-8-8 loss: 0.728486  [  288/  306]
train() client id: f_00004-9-0 loss: 0.842625  [   32/  306]
train() client id: f_00004-9-1 loss: 0.718475  [   64/  306]
train() client id: f_00004-9-2 loss: 0.797396  [   96/  306]
train() client id: f_00004-9-3 loss: 0.745843  [  128/  306]
train() client id: f_00004-9-4 loss: 0.752806  [  160/  306]
train() client id: f_00004-9-5 loss: 0.844635  [  192/  306]
train() client id: f_00004-9-6 loss: 0.795319  [  224/  306]
train() client id: f_00004-9-7 loss: 0.752274  [  256/  306]
train() client id: f_00004-9-8 loss: 0.769383  [  288/  306]
train() client id: f_00004-10-0 loss: 0.789717  [   32/  306]
train() client id: f_00004-10-1 loss: 0.829371  [   64/  306]
train() client id: f_00004-10-2 loss: 0.836887  [   96/  306]
train() client id: f_00004-10-3 loss: 0.682164  [  128/  306]
train() client id: f_00004-10-4 loss: 0.751568  [  160/  306]
train() client id: f_00004-10-5 loss: 0.881181  [  192/  306]
train() client id: f_00004-10-6 loss: 0.760466  [  224/  306]
train() client id: f_00004-10-7 loss: 0.838147  [  256/  306]
train() client id: f_00004-10-8 loss: 0.746363  [  288/  306]
train() client id: f_00004-11-0 loss: 1.007875  [   32/  306]
train() client id: f_00004-11-1 loss: 0.610454  [   64/  306]
train() client id: f_00004-11-2 loss: 0.877277  [   96/  306]
train() client id: f_00004-11-3 loss: 0.837722  [  128/  306]
train() client id: f_00004-11-4 loss: 0.869107  [  160/  306]
train() client id: f_00004-11-5 loss: 0.796355  [  192/  306]
train() client id: f_00004-11-6 loss: 0.721764  [  224/  306]
train() client id: f_00004-11-7 loss: 0.641144  [  256/  306]
train() client id: f_00004-11-8 loss: 0.772733  [  288/  306]
train() client id: f_00004-12-0 loss: 0.784495  [   32/  306]
train() client id: f_00004-12-1 loss: 0.788026  [   64/  306]
train() client id: f_00004-12-2 loss: 0.776827  [   96/  306]
train() client id: f_00004-12-3 loss: 0.791224  [  128/  306]
train() client id: f_00004-12-4 loss: 0.871452  [  160/  306]
train() client id: f_00004-12-5 loss: 0.735602  [  192/  306]
train() client id: f_00004-12-6 loss: 0.811936  [  224/  306]
train() client id: f_00004-12-7 loss: 0.786369  [  256/  306]
train() client id: f_00004-12-8 loss: 0.829400  [  288/  306]
train() client id: f_00005-0-0 loss: 1.107092  [   32/  146]
train() client id: f_00005-0-1 loss: 0.923634  [   64/  146]
train() client id: f_00005-0-2 loss: 0.858707  [   96/  146]
train() client id: f_00005-0-3 loss: 0.795061  [  128/  146]
train() client id: f_00005-1-0 loss: 1.168044  [   32/  146]
train() client id: f_00005-1-1 loss: 0.784443  [   64/  146]
train() client id: f_00005-1-2 loss: 0.812509  [   96/  146]
train() client id: f_00005-1-3 loss: 0.948860  [  128/  146]
train() client id: f_00005-2-0 loss: 0.967404  [   32/  146]
train() client id: f_00005-2-1 loss: 0.879038  [   64/  146]
train() client id: f_00005-2-2 loss: 0.784244  [   96/  146]
train() client id: f_00005-2-3 loss: 1.004137  [  128/  146]
train() client id: f_00005-3-0 loss: 1.099298  [   32/  146]
train() client id: f_00005-3-1 loss: 0.897409  [   64/  146]
train() client id: f_00005-3-2 loss: 0.994272  [   96/  146]
train() client id: f_00005-3-3 loss: 0.688650  [  128/  146]
train() client id: f_00005-4-0 loss: 0.901277  [   32/  146]
train() client id: f_00005-4-1 loss: 0.890971  [   64/  146]
train() client id: f_00005-4-2 loss: 0.994354  [   96/  146]
train() client id: f_00005-4-3 loss: 0.866010  [  128/  146]
train() client id: f_00005-5-0 loss: 0.838164  [   32/  146]
train() client id: f_00005-5-1 loss: 0.962038  [   64/  146]
train() client id: f_00005-5-2 loss: 1.180654  [   96/  146]
train() client id: f_00005-5-3 loss: 0.714161  [  128/  146]
train() client id: f_00005-6-0 loss: 0.915622  [   32/  146]
train() client id: f_00005-6-1 loss: 0.969188  [   64/  146]
train() client id: f_00005-6-2 loss: 1.042395  [   96/  146]
train() client id: f_00005-6-3 loss: 0.913998  [  128/  146]
train() client id: f_00005-7-0 loss: 0.977184  [   32/  146]
train() client id: f_00005-7-1 loss: 0.763828  [   64/  146]
train() client id: f_00005-7-2 loss: 0.943946  [   96/  146]
train() client id: f_00005-7-3 loss: 1.065173  [  128/  146]
train() client id: f_00005-8-0 loss: 0.808756  [   32/  146]
train() client id: f_00005-8-1 loss: 0.999430  [   64/  146]
train() client id: f_00005-8-2 loss: 0.815452  [   96/  146]
train() client id: f_00005-8-3 loss: 0.814772  [  128/  146]
train() client id: f_00005-9-0 loss: 0.763877  [   32/  146]
train() client id: f_00005-9-1 loss: 1.095511  [   64/  146]
train() client id: f_00005-9-2 loss: 0.990482  [   96/  146]
train() client id: f_00005-9-3 loss: 0.940000  [  128/  146]
train() client id: f_00005-10-0 loss: 1.035836  [   32/  146]
train() client id: f_00005-10-1 loss: 0.964135  [   64/  146]
train() client id: f_00005-10-2 loss: 0.783146  [   96/  146]
train() client id: f_00005-10-3 loss: 0.895254  [  128/  146]
train() client id: f_00005-11-0 loss: 0.916172  [   32/  146]
train() client id: f_00005-11-1 loss: 0.966663  [   64/  146]
train() client id: f_00005-11-2 loss: 0.921262  [   96/  146]
train() client id: f_00005-11-3 loss: 0.918712  [  128/  146]
train() client id: f_00005-12-0 loss: 0.775265  [   32/  146]
train() client id: f_00005-12-1 loss: 0.963939  [   64/  146]
train() client id: f_00005-12-2 loss: 0.993530  [   96/  146]
train() client id: f_00005-12-3 loss: 1.079039  [  128/  146]
train() client id: f_00006-0-0 loss: 0.722228  [   32/   54]
train() client id: f_00006-1-0 loss: 0.719478  [   32/   54]
train() client id: f_00006-2-0 loss: 0.683290  [   32/   54]
train() client id: f_00006-3-0 loss: 0.655411  [   32/   54]
train() client id: f_00006-4-0 loss: 0.682895  [   32/   54]
train() client id: f_00006-5-0 loss: 0.680139  [   32/   54]
train() client id: f_00006-6-0 loss: 0.713484  [   32/   54]
train() client id: f_00006-7-0 loss: 0.732866  [   32/   54]
train() client id: f_00006-8-0 loss: 0.691108  [   32/   54]
train() client id: f_00006-9-0 loss: 0.683358  [   32/   54]
train() client id: f_00006-10-0 loss: 0.691252  [   32/   54]
train() client id: f_00006-11-0 loss: 0.678905  [   32/   54]
train() client id: f_00006-12-0 loss: 0.686932  [   32/   54]
train() client id: f_00007-0-0 loss: 0.528144  [   32/  179]
train() client id: f_00007-0-1 loss: 0.563894  [   64/  179]
train() client id: f_00007-0-2 loss: 0.523139  [   96/  179]
train() client id: f_00007-0-3 loss: 0.768925  [  128/  179]
train() client id: f_00007-0-4 loss: 0.562407  [  160/  179]
train() client id: f_00007-1-0 loss: 0.581056  [   32/  179]
train() client id: f_00007-1-1 loss: 0.541645  [   64/  179]
train() client id: f_00007-1-2 loss: 0.634507  [   96/  179]
train() client id: f_00007-1-3 loss: 0.544907  [  128/  179]
train() client id: f_00007-1-4 loss: 0.437788  [  160/  179]
train() client id: f_00007-2-0 loss: 0.541522  [   32/  179]
train() client id: f_00007-2-1 loss: 0.483472  [   64/  179]
train() client id: f_00007-2-2 loss: 0.590917  [   96/  179]
train() client id: f_00007-2-3 loss: 0.431695  [  128/  179]
train() client id: f_00007-2-4 loss: 0.551796  [  160/  179]
train() client id: f_00007-3-0 loss: 0.436908  [   32/  179]
train() client id: f_00007-3-1 loss: 0.604405  [   64/  179]
train() client id: f_00007-3-2 loss: 0.547624  [   96/  179]
train() client id: f_00007-3-3 loss: 0.524086  [  128/  179]
train() client id: f_00007-3-4 loss: 0.514365  [  160/  179]
train() client id: f_00007-4-0 loss: 0.428033  [   32/  179]
train() client id: f_00007-4-1 loss: 0.510557  [   64/  179]
train() client id: f_00007-4-2 loss: 0.548762  [   96/  179]
train() client id: f_00007-4-3 loss: 0.642351  [  128/  179]
train() client id: f_00007-4-4 loss: 0.418339  [  160/  179]
train() client id: f_00007-5-0 loss: 0.700071  [   32/  179]
train() client id: f_00007-5-1 loss: 0.424606  [   64/  179]
train() client id: f_00007-5-2 loss: 0.521512  [   96/  179]
train() client id: f_00007-5-3 loss: 0.521154  [  128/  179]
train() client id: f_00007-5-4 loss: 0.380309  [  160/  179]
train() client id: f_00007-6-0 loss: 0.493919  [   32/  179]
train() client id: f_00007-6-1 loss: 0.457732  [   64/  179]
train() client id: f_00007-6-2 loss: 0.455869  [   96/  179]
train() client id: f_00007-6-3 loss: 0.680297  [  128/  179]
train() client id: f_00007-6-4 loss: 0.459730  [  160/  179]
train() client id: f_00007-7-0 loss: 0.438264  [   32/  179]
train() client id: f_00007-7-1 loss: 0.603552  [   64/  179]
train() client id: f_00007-7-2 loss: 0.391399  [   96/  179]
train() client id: f_00007-7-3 loss: 0.540893  [  128/  179]
train() client id: f_00007-7-4 loss: 0.457411  [  160/  179]
train() client id: f_00007-8-0 loss: 0.473868  [   32/  179]
train() client id: f_00007-8-1 loss: 0.584267  [   64/  179]
train() client id: f_00007-8-2 loss: 0.392648  [   96/  179]
train() client id: f_00007-8-3 loss: 0.355315  [  128/  179]
train() client id: f_00007-8-4 loss: 0.597524  [  160/  179]
train() client id: f_00007-9-0 loss: 0.500837  [   32/  179]
train() client id: f_00007-9-1 loss: 0.396952  [   64/  179]
train() client id: f_00007-9-2 loss: 0.457918  [   96/  179]
train() client id: f_00007-9-3 loss: 0.484097  [  128/  179]
train() client id: f_00007-9-4 loss: 0.520444  [  160/  179]
train() client id: f_00007-10-0 loss: 0.544176  [   32/  179]
train() client id: f_00007-10-1 loss: 0.578663  [   64/  179]
train() client id: f_00007-10-2 loss: 0.502726  [   96/  179]
train() client id: f_00007-10-3 loss: 0.371708  [  128/  179]
train() client id: f_00007-10-4 loss: 0.413599  [  160/  179]
train() client id: f_00007-11-0 loss: 0.538236  [   32/  179]
train() client id: f_00007-11-1 loss: 0.560894  [   64/  179]
train() client id: f_00007-11-2 loss: 0.447251  [   96/  179]
train() client id: f_00007-11-3 loss: 0.471464  [  128/  179]
train() client id: f_00007-11-4 loss: 0.583229  [  160/  179]
train() client id: f_00007-12-0 loss: 0.463732  [   32/  179]
train() client id: f_00007-12-1 loss: 0.756457  [   64/  179]
train() client id: f_00007-12-2 loss: 0.369327  [   96/  179]
train() client id: f_00007-12-3 loss: 0.464412  [  128/  179]
train() client id: f_00007-12-4 loss: 0.453510  [  160/  179]
train() client id: f_00008-0-0 loss: 0.813567  [   32/  130]
train() client id: f_00008-0-1 loss: 0.606140  [   64/  130]
train() client id: f_00008-0-2 loss: 0.910013  [   96/  130]
train() client id: f_00008-0-3 loss: 0.792305  [  128/  130]
train() client id: f_00008-1-0 loss: 0.875474  [   32/  130]
train() client id: f_00008-1-1 loss: 0.692799  [   64/  130]
train() client id: f_00008-1-2 loss: 0.625518  [   96/  130]
train() client id: f_00008-1-3 loss: 0.912002  [  128/  130]
train() client id: f_00008-2-0 loss: 0.732460  [   32/  130]
train() client id: f_00008-2-1 loss: 0.724016  [   64/  130]
train() client id: f_00008-2-2 loss: 0.752814  [   96/  130]
train() client id: f_00008-2-3 loss: 0.863232  [  128/  130]
train() client id: f_00008-3-0 loss: 0.800845  [   32/  130]
train() client id: f_00008-3-1 loss: 0.925500  [   64/  130]
train() client id: f_00008-3-2 loss: 0.641095  [   96/  130]
train() client id: f_00008-3-3 loss: 0.737636  [  128/  130]
train() client id: f_00008-4-0 loss: 0.687622  [   32/  130]
train() client id: f_00008-4-1 loss: 0.784020  [   64/  130]
train() client id: f_00008-4-2 loss: 0.904770  [   96/  130]
train() client id: f_00008-4-3 loss: 0.693491  [  128/  130]
train() client id: f_00008-5-0 loss: 0.900960  [   32/  130]
train() client id: f_00008-5-1 loss: 0.852620  [   64/  130]
train() client id: f_00008-5-2 loss: 0.702653  [   96/  130]
train() client id: f_00008-5-3 loss: 0.653970  [  128/  130]
train() client id: f_00008-6-0 loss: 0.777685  [   32/  130]
train() client id: f_00008-6-1 loss: 0.691414  [   64/  130]
train() client id: f_00008-6-2 loss: 0.739800  [   96/  130]
train() client id: f_00008-6-3 loss: 0.882363  [  128/  130]
train() client id: f_00008-7-0 loss: 0.716380  [   32/  130]
train() client id: f_00008-7-1 loss: 0.812523  [   64/  130]
train() client id: f_00008-7-2 loss: 0.789213  [   96/  130]
train() client id: f_00008-7-3 loss: 0.704848  [  128/  130]
train() client id: f_00008-8-0 loss: 0.855488  [   32/  130]
train() client id: f_00008-8-1 loss: 0.795815  [   64/  130]
train() client id: f_00008-8-2 loss: 0.750929  [   96/  130]
train() client id: f_00008-8-3 loss: 0.684280  [  128/  130]
train() client id: f_00008-9-0 loss: 0.832120  [   32/  130]
train() client id: f_00008-9-1 loss: 0.666870  [   64/  130]
train() client id: f_00008-9-2 loss: 0.811204  [   96/  130]
train() client id: f_00008-9-3 loss: 0.744732  [  128/  130]
train() client id: f_00008-10-0 loss: 0.734733  [   32/  130]
train() client id: f_00008-10-1 loss: 0.792932  [   64/  130]
train() client id: f_00008-10-2 loss: 0.747948  [   96/  130]
train() client id: f_00008-10-3 loss: 0.804316  [  128/  130]
train() client id: f_00008-11-0 loss: 0.727568  [   32/  130]
train() client id: f_00008-11-1 loss: 0.848246  [   64/  130]
train() client id: f_00008-11-2 loss: 0.797554  [   96/  130]
train() client id: f_00008-11-3 loss: 0.700667  [  128/  130]
train() client id: f_00008-12-0 loss: 0.813802  [   32/  130]
train() client id: f_00008-12-1 loss: 0.693087  [   64/  130]
train() client id: f_00008-12-2 loss: 0.814133  [   96/  130]
train() client id: f_00008-12-3 loss: 0.724249  [  128/  130]
train() client id: f_00009-0-0 loss: 1.225761  [   32/  118]
train() client id: f_00009-0-1 loss: 1.177294  [   64/  118]
train() client id: f_00009-0-2 loss: 1.150069  [   96/  118]
train() client id: f_00009-1-0 loss: 1.065942  [   32/  118]
train() client id: f_00009-1-1 loss: 1.113907  [   64/  118]
train() client id: f_00009-1-2 loss: 1.161292  [   96/  118]
train() client id: f_00009-2-0 loss: 1.092207  [   32/  118]
train() client id: f_00009-2-1 loss: 0.959301  [   64/  118]
train() client id: f_00009-2-2 loss: 1.053122  [   96/  118]
train() client id: f_00009-3-0 loss: 1.058038  [   32/  118]
train() client id: f_00009-3-1 loss: 0.986154  [   64/  118]
train() client id: f_00009-3-2 loss: 1.022807  [   96/  118]
train() client id: f_00009-4-0 loss: 0.974060  [   32/  118]
train() client id: f_00009-4-1 loss: 1.028351  [   64/  118]
train() client id: f_00009-4-2 loss: 0.944734  [   96/  118]
train() client id: f_00009-5-0 loss: 1.018217  [   32/  118]
train() client id: f_00009-5-1 loss: 0.950890  [   64/  118]
train() client id: f_00009-5-2 loss: 0.933918  [   96/  118]
train() client id: f_00009-6-0 loss: 0.949522  [   32/  118]
train() client id: f_00009-6-1 loss: 0.933612  [   64/  118]
train() client id: f_00009-6-2 loss: 0.972077  [   96/  118]
train() client id: f_00009-7-0 loss: 0.937297  [   32/  118]
train() client id: f_00009-7-1 loss: 0.862011  [   64/  118]
train() client id: f_00009-7-2 loss: 0.898536  [   96/  118]
train() client id: f_00009-8-0 loss: 0.931398  [   32/  118]
train() client id: f_00009-8-1 loss: 0.943807  [   64/  118]
train() client id: f_00009-8-2 loss: 0.815486  [   96/  118]
train() client id: f_00009-9-0 loss: 0.891068  [   32/  118]
train() client id: f_00009-9-1 loss: 0.791073  [   64/  118]
train() client id: f_00009-9-2 loss: 0.936998  [   96/  118]
train() client id: f_00009-10-0 loss: 0.965499  [   32/  118]
train() client id: f_00009-10-1 loss: 0.834160  [   64/  118]
train() client id: f_00009-10-2 loss: 0.908435  [   96/  118]
train() client id: f_00009-11-0 loss: 0.904954  [   32/  118]
train() client id: f_00009-11-1 loss: 0.862626  [   64/  118]
train() client id: f_00009-11-2 loss: 0.970768  [   96/  118]
train() client id: f_00009-12-0 loss: 0.889500  [   32/  118]
train() client id: f_00009-12-1 loss: 0.971088  [   64/  118]
train() client id: f_00009-12-2 loss: 0.859232  [   96/  118]
At round 11 accuracy: 0.6339522546419099
At round 11 training accuracy: 0.5754527162977867
At round 11 training loss: 0.8671701445131194
gradient difference: 0.4416208863258362
train() client id: f_00000-0-0 loss: 0.943525  [   32/  126]
train() client id: f_00000-0-1 loss: 1.067652  [   64/  126]
train() client id: f_00000-0-2 loss: 1.094177  [   96/  126]
train() client id: f_00000-1-0 loss: 1.002825  [   32/  126]
train() client id: f_00000-1-1 loss: 0.991443  [   64/  126]
train() client id: f_00000-1-2 loss: 0.915400  [   96/  126]
train() client id: f_00000-2-0 loss: 1.062016  [   32/  126]
train() client id: f_00000-2-1 loss: 1.015828  [   64/  126]
train() client id: f_00000-2-2 loss: 0.855424  [   96/  126]
train() client id: f_00000-3-0 loss: 1.021632  [   32/  126]
train() client id: f_00000-3-1 loss: 0.875587  [   64/  126]
train() client id: f_00000-3-2 loss: 0.864226  [   96/  126]
train() client id: f_00000-4-0 loss: 0.833370  [   32/  126]
train() client id: f_00000-4-1 loss: 0.768037  [   64/  126]
train() client id: f_00000-4-2 loss: 0.894673  [   96/  126]
train() client id: f_00000-5-0 loss: 0.799042  [   32/  126]
train() client id: f_00000-5-1 loss: 0.903601  [   64/  126]
train() client id: f_00000-5-2 loss: 0.823972  [   96/  126]
train() client id: f_00000-6-0 loss: 0.923991  [   32/  126]
train() client id: f_00000-6-1 loss: 0.789893  [   64/  126]
train() client id: f_00000-6-2 loss: 0.887113  [   96/  126]
train() client id: f_00000-7-0 loss: 0.905412  [   32/  126]
train() client id: f_00000-7-1 loss: 0.842393  [   64/  126]
train() client id: f_00000-7-2 loss: 0.841211  [   96/  126]
train() client id: f_00000-8-0 loss: 0.788326  [   32/  126]
train() client id: f_00000-8-1 loss: 0.992116  [   64/  126]
train() client id: f_00000-8-2 loss: 0.742285  [   96/  126]
train() client id: f_00000-9-0 loss: 0.857825  [   32/  126]
train() client id: f_00000-9-1 loss: 0.742435  [   64/  126]
train() client id: f_00000-9-2 loss: 1.020385  [   96/  126]
train() client id: f_00000-10-0 loss: 0.845060  [   32/  126]
train() client id: f_00000-10-1 loss: 0.976503  [   64/  126]
train() client id: f_00000-10-2 loss: 0.712942  [   96/  126]
train() client id: f_00000-11-0 loss: 0.862216  [   32/  126]
train() client id: f_00000-11-1 loss: 0.731984  [   64/  126]
train() client id: f_00000-11-2 loss: 0.988023  [   96/  126]
train() client id: f_00000-12-0 loss: 0.859021  [   32/  126]
train() client id: f_00000-12-1 loss: 0.721287  [   64/  126]
train() client id: f_00000-12-2 loss: 0.924963  [   96/  126]
train() client id: f_00001-0-0 loss: 0.539641  [   32/  265]
train() client id: f_00001-0-1 loss: 0.560583  [   64/  265]
train() client id: f_00001-0-2 loss: 0.480832  [   96/  265]
train() client id: f_00001-0-3 loss: 0.534994  [  128/  265]
train() client id: f_00001-0-4 loss: 0.454580  [  160/  265]
train() client id: f_00001-0-5 loss: 0.477705  [  192/  265]
train() client id: f_00001-0-6 loss: 0.411680  [  224/  265]
train() client id: f_00001-0-7 loss: 0.550587  [  256/  265]
train() client id: f_00001-1-0 loss: 0.557936  [   32/  265]
train() client id: f_00001-1-1 loss: 0.473063  [   64/  265]
train() client id: f_00001-1-2 loss: 0.534076  [   96/  265]
train() client id: f_00001-1-3 loss: 0.466651  [  128/  265]
train() client id: f_00001-1-4 loss: 0.437212  [  160/  265]
train() client id: f_00001-1-5 loss: 0.515389  [  192/  265]
train() client id: f_00001-1-6 loss: 0.418402  [  224/  265]
train() client id: f_00001-1-7 loss: 0.470178  [  256/  265]
train() client id: f_00001-2-0 loss: 0.450932  [   32/  265]
train() client id: f_00001-2-1 loss: 0.594708  [   64/  265]
train() client id: f_00001-2-2 loss: 0.500387  [   96/  265]
train() client id: f_00001-2-3 loss: 0.424982  [  128/  265]
train() client id: f_00001-2-4 loss: 0.507432  [  160/  265]
train() client id: f_00001-2-5 loss: 0.392239  [  192/  265]
train() client id: f_00001-2-6 loss: 0.438571  [  224/  265]
train() client id: f_00001-2-7 loss: 0.480632  [  256/  265]
train() client id: f_00001-3-0 loss: 0.436549  [   32/  265]
train() client id: f_00001-3-1 loss: 0.590080  [   64/  265]
train() client id: f_00001-3-2 loss: 0.384860  [   96/  265]
train() client id: f_00001-3-3 loss: 0.557440  [  128/  265]
train() client id: f_00001-3-4 loss: 0.445822  [  160/  265]
train() client id: f_00001-3-5 loss: 0.406415  [  192/  265]
train() client id: f_00001-3-6 loss: 0.376303  [  224/  265]
train() client id: f_00001-3-7 loss: 0.504870  [  256/  265]
train() client id: f_00001-4-0 loss: 0.576489  [   32/  265]
train() client id: f_00001-4-1 loss: 0.401400  [   64/  265]
train() client id: f_00001-4-2 loss: 0.378880  [   96/  265]
train() client id: f_00001-4-3 loss: 0.531891  [  128/  265]
train() client id: f_00001-4-4 loss: 0.450526  [  160/  265]
train() client id: f_00001-4-5 loss: 0.526463  [  192/  265]
train() client id: f_00001-4-6 loss: 0.394781  [  224/  265]
train() client id: f_00001-4-7 loss: 0.373036  [  256/  265]
train() client id: f_00001-5-0 loss: 0.403530  [   32/  265]
train() client id: f_00001-5-1 loss: 0.407826  [   64/  265]
train() client id: f_00001-5-2 loss: 0.480031  [   96/  265]
train() client id: f_00001-5-3 loss: 0.635202  [  128/  265]
train() client id: f_00001-5-4 loss: 0.419330  [  160/  265]
train() client id: f_00001-5-5 loss: 0.473523  [  192/  265]
train() client id: f_00001-5-6 loss: 0.422670  [  224/  265]
train() client id: f_00001-5-7 loss: 0.361544  [  256/  265]
train() client id: f_00001-6-0 loss: 0.371548  [   32/  265]
train() client id: f_00001-6-1 loss: 0.484764  [   64/  265]
train() client id: f_00001-6-2 loss: 0.428302  [   96/  265]
train() client id: f_00001-6-3 loss: 0.484842  [  128/  265]
train() client id: f_00001-6-4 loss: 0.420273  [  160/  265]
train() client id: f_00001-6-5 loss: 0.524497  [  192/  265]
train() client id: f_00001-6-6 loss: 0.463077  [  224/  265]
train() client id: f_00001-6-7 loss: 0.397475  [  256/  265]
train() client id: f_00001-7-0 loss: 0.388571  [   32/  265]
train() client id: f_00001-7-1 loss: 0.449530  [   64/  265]
train() client id: f_00001-7-2 loss: 0.488637  [   96/  265]
train() client id: f_00001-7-3 loss: 0.407057  [  128/  265]
train() client id: f_00001-7-4 loss: 0.507643  [  160/  265]
train() client id: f_00001-7-5 loss: 0.356103  [  192/  265]
train() client id: f_00001-7-6 loss: 0.444028  [  224/  265]
train() client id: f_00001-7-7 loss: 0.422108  [  256/  265]
train() client id: f_00001-8-0 loss: 0.402927  [   32/  265]
train() client id: f_00001-8-1 loss: 0.569327  [   64/  265]
train() client id: f_00001-8-2 loss: 0.436452  [   96/  265]
train() client id: f_00001-8-3 loss: 0.368879  [  128/  265]
train() client id: f_00001-8-4 loss: 0.481197  [  160/  265]
train() client id: f_00001-8-5 loss: 0.489005  [  192/  265]
train() client id: f_00001-8-6 loss: 0.392417  [  224/  265]
train() client id: f_00001-8-7 loss: 0.343837  [  256/  265]
train() client id: f_00001-9-0 loss: 0.441111  [   32/  265]
train() client id: f_00001-9-1 loss: 0.422627  [   64/  265]
train() client id: f_00001-9-2 loss: 0.407769  [   96/  265]
train() client id: f_00001-9-3 loss: 0.445270  [  128/  265]
train() client id: f_00001-9-4 loss: 0.408552  [  160/  265]
train() client id: f_00001-9-5 loss: 0.419708  [  192/  265]
train() client id: f_00001-9-6 loss: 0.566472  [  224/  265]
train() client id: f_00001-9-7 loss: 0.398214  [  256/  265]
train() client id: f_00001-10-0 loss: 0.448103  [   32/  265]
train() client id: f_00001-10-1 loss: 0.343046  [   64/  265]
train() client id: f_00001-10-2 loss: 0.440210  [   96/  265]
train() client id: f_00001-10-3 loss: 0.502353  [  128/  265]
train() client id: f_00001-10-4 loss: 0.349877  [  160/  265]
train() client id: f_00001-10-5 loss: 0.503094  [  192/  265]
train() client id: f_00001-10-6 loss: 0.409927  [  224/  265]
train() client id: f_00001-10-7 loss: 0.493732  [  256/  265]
train() client id: f_00001-11-0 loss: 0.455741  [   32/  265]
train() client id: f_00001-11-1 loss: 0.577928  [   64/  265]
train() client id: f_00001-11-2 loss: 0.482005  [   96/  265]
train() client id: f_00001-11-3 loss: 0.369768  [  128/  265]
train() client id: f_00001-11-4 loss: 0.388190  [  160/  265]
train() client id: f_00001-11-5 loss: 0.446701  [  192/  265]
train() client id: f_00001-11-6 loss: 0.357064  [  224/  265]
train() client id: f_00001-11-7 loss: 0.350310  [  256/  265]
train() client id: f_00001-12-0 loss: 0.380470  [   32/  265]
train() client id: f_00001-12-1 loss: 0.437789  [   64/  265]
train() client id: f_00001-12-2 loss: 0.405942  [   96/  265]
train() client id: f_00001-12-3 loss: 0.446190  [  128/  265]
train() client id: f_00001-12-4 loss: 0.484512  [  160/  265]
train() client id: f_00001-12-5 loss: 0.424518  [  192/  265]
train() client id: f_00001-12-6 loss: 0.396021  [  224/  265]
train() client id: f_00001-12-7 loss: 0.499693  [  256/  265]
train() client id: f_00002-0-0 loss: 1.329829  [   32/  124]
train() client id: f_00002-0-1 loss: 1.275547  [   64/  124]
train() client id: f_00002-0-2 loss: 1.180762  [   96/  124]
train() client id: f_00002-1-0 loss: 1.236212  [   32/  124]
train() client id: f_00002-1-1 loss: 1.227916  [   64/  124]
train() client id: f_00002-1-2 loss: 1.208369  [   96/  124]
train() client id: f_00002-2-0 loss: 1.176904  [   32/  124]
train() client id: f_00002-2-1 loss: 1.195654  [   64/  124]
train() client id: f_00002-2-2 loss: 1.118134  [   96/  124]
train() client id: f_00002-3-0 loss: 1.222853  [   32/  124]
train() client id: f_00002-3-1 loss: 1.070178  [   64/  124]
train() client id: f_00002-3-2 loss: 1.093308  [   96/  124]
train() client id: f_00002-4-0 loss: 1.084368  [   32/  124]
train() client id: f_00002-4-1 loss: 1.142003  [   64/  124]
train() client id: f_00002-4-2 loss: 1.063204  [   96/  124]
train() client id: f_00002-5-0 loss: 1.075409  [   32/  124]
train() client id: f_00002-5-1 loss: 1.060943  [   64/  124]
train() client id: f_00002-5-2 loss: 1.136566  [   96/  124]
train() client id: f_00002-6-0 loss: 1.154602  [   32/  124]
train() client id: f_00002-6-1 loss: 0.972302  [   64/  124]
train() client id: f_00002-6-2 loss: 0.998221  [   96/  124]
train() client id: f_00002-7-0 loss: 1.211246  [   32/  124]
train() client id: f_00002-7-1 loss: 0.987185  [   64/  124]
train() client id: f_00002-7-2 loss: 1.042087  [   96/  124]
train() client id: f_00002-8-0 loss: 1.142819  [   32/  124]
train() client id: f_00002-8-1 loss: 1.016391  [   64/  124]
train() client id: f_00002-8-2 loss: 0.972993  [   96/  124]
train() client id: f_00002-9-0 loss: 1.045366  [   32/  124]
train() client id: f_00002-9-1 loss: 1.000981  [   64/  124]
train() client id: f_00002-9-2 loss: 1.008471  [   96/  124]
train() client id: f_00002-10-0 loss: 0.987116  [   32/  124]
train() client id: f_00002-10-1 loss: 0.969474  [   64/  124]
train() client id: f_00002-10-2 loss: 1.079323  [   96/  124]
train() client id: f_00002-11-0 loss: 1.127504  [   32/  124]
train() client id: f_00002-11-1 loss: 0.897652  [   64/  124]
train() client id: f_00002-11-2 loss: 1.139621  [   96/  124]
train() client id: f_00002-12-0 loss: 1.045269  [   32/  124]
train() client id: f_00002-12-1 loss: 1.061995  [   64/  124]
train() client id: f_00002-12-2 loss: 1.026771  [   96/  124]
train() client id: f_00003-0-0 loss: 0.765146  [   32/   43]
train() client id: f_00003-1-0 loss: 0.899857  [   32/   43]
train() client id: f_00003-2-0 loss: 0.928271  [   32/   43]
train() client id: f_00003-3-0 loss: 0.781434  [   32/   43]
train() client id: f_00003-4-0 loss: 0.851375  [   32/   43]
train() client id: f_00003-5-0 loss: 0.780656  [   32/   43]
train() client id: f_00003-6-0 loss: 0.784465  [   32/   43]
train() client id: f_00003-7-0 loss: 0.990988  [   32/   43]
train() client id: f_00003-8-0 loss: 0.753397  [   32/   43]
train() client id: f_00003-9-0 loss: 0.832869  [   32/   43]
train() client id: f_00003-10-0 loss: 0.740159  [   32/   43]
train() client id: f_00003-11-0 loss: 0.815198  [   32/   43]
train() client id: f_00003-12-0 loss: 0.837664  [   32/   43]
train() client id: f_00004-0-0 loss: 0.874915  [   32/  306]
train() client id: f_00004-0-1 loss: 0.773956  [   64/  306]
train() client id: f_00004-0-2 loss: 0.897366  [   96/  306]
train() client id: f_00004-0-3 loss: 0.896886  [  128/  306]
train() client id: f_00004-0-4 loss: 0.787926  [  160/  306]
train() client id: f_00004-0-5 loss: 0.963132  [  192/  306]
train() client id: f_00004-0-6 loss: 0.783078  [  224/  306]
train() client id: f_00004-0-7 loss: 0.855272  [  256/  306]
train() client id: f_00004-0-8 loss: 0.819053  [  288/  306]
train() client id: f_00004-1-0 loss: 0.864971  [   32/  306]
train() client id: f_00004-1-1 loss: 0.903749  [   64/  306]
train() client id: f_00004-1-2 loss: 0.880829  [   96/  306]
train() client id: f_00004-1-3 loss: 0.913133  [  128/  306]
train() client id: f_00004-1-4 loss: 0.876361  [  160/  306]
train() client id: f_00004-1-5 loss: 0.969664  [  192/  306]
train() client id: f_00004-1-6 loss: 0.819252  [  224/  306]
train() client id: f_00004-1-7 loss: 0.788001  [  256/  306]
train() client id: f_00004-1-8 loss: 0.786870  [  288/  306]
train() client id: f_00004-2-0 loss: 0.940591  [   32/  306]
train() client id: f_00004-2-1 loss: 0.788405  [   64/  306]
train() client id: f_00004-2-2 loss: 0.837670  [   96/  306]
train() client id: f_00004-2-3 loss: 0.851337  [  128/  306]
train() client id: f_00004-2-4 loss: 0.926547  [  160/  306]
train() client id: f_00004-2-5 loss: 0.821478  [  192/  306]
train() client id: f_00004-2-6 loss: 0.845006  [  224/  306]
train() client id: f_00004-2-7 loss: 0.835756  [  256/  306]
train() client id: f_00004-2-8 loss: 0.860234  [  288/  306]
train() client id: f_00004-3-0 loss: 0.848494  [   32/  306]
train() client id: f_00004-3-1 loss: 0.849106  [   64/  306]
train() client id: f_00004-3-2 loss: 0.907299  [   96/  306]
train() client id: f_00004-3-3 loss: 0.922157  [  128/  306]
train() client id: f_00004-3-4 loss: 0.815039  [  160/  306]
train() client id: f_00004-3-5 loss: 0.830700  [  192/  306]
train() client id: f_00004-3-6 loss: 0.849502  [  224/  306]
train() client id: f_00004-3-7 loss: 0.904431  [  256/  306]
train() client id: f_00004-3-8 loss: 0.775559  [  288/  306]
train() client id: f_00004-4-0 loss: 0.818721  [   32/  306]
train() client id: f_00004-4-1 loss: 0.895140  [   64/  306]
train() client id: f_00004-4-2 loss: 0.806499  [   96/  306]
train() client id: f_00004-4-3 loss: 0.776776  [  128/  306]
train() client id: f_00004-4-4 loss: 0.931112  [  160/  306]
train() client id: f_00004-4-5 loss: 0.889645  [  192/  306]
train() client id: f_00004-4-6 loss: 0.817141  [  224/  306]
train() client id: f_00004-4-7 loss: 0.934933  [  256/  306]
train() client id: f_00004-4-8 loss: 0.953375  [  288/  306]
train() client id: f_00004-5-0 loss: 0.832141  [   32/  306]
train() client id: f_00004-5-1 loss: 0.797968  [   64/  306]
train() client id: f_00004-5-2 loss: 0.788921  [   96/  306]
train() client id: f_00004-5-3 loss: 0.796038  [  128/  306]
train() client id: f_00004-5-4 loss: 0.951657  [  160/  306]
train() client id: f_00004-5-5 loss: 0.886337  [  192/  306]
train() client id: f_00004-5-6 loss: 0.984111  [  224/  306]
train() client id: f_00004-5-7 loss: 0.951379  [  256/  306]
train() client id: f_00004-5-8 loss: 0.757580  [  288/  306]
train() client id: f_00004-6-0 loss: 0.772106  [   32/  306]
train() client id: f_00004-6-1 loss: 0.876291  [   64/  306]
train() client id: f_00004-6-2 loss: 0.991557  [   96/  306]
train() client id: f_00004-6-3 loss: 0.897019  [  128/  306]
train() client id: f_00004-6-4 loss: 0.770538  [  160/  306]
train() client id: f_00004-6-5 loss: 0.802955  [  192/  306]
train() client id: f_00004-6-6 loss: 0.831808  [  224/  306]
train() client id: f_00004-6-7 loss: 0.843618  [  256/  306]
train() client id: f_00004-6-8 loss: 0.871119  [  288/  306]
train() client id: f_00004-7-0 loss: 0.788335  [   32/  306]
train() client id: f_00004-7-1 loss: 0.818496  [   64/  306]
train() client id: f_00004-7-2 loss: 0.740353  [   96/  306]
train() client id: f_00004-7-3 loss: 1.019105  [  128/  306]
train() client id: f_00004-7-4 loss: 0.895806  [  160/  306]
train() client id: f_00004-7-5 loss: 0.818536  [  192/  306]
train() client id: f_00004-7-6 loss: 0.903232  [  224/  306]
train() client id: f_00004-7-7 loss: 0.874539  [  256/  306]
train() client id: f_00004-7-8 loss: 0.906798  [  288/  306]
train() client id: f_00004-8-0 loss: 0.941808  [   32/  306]
train() client id: f_00004-8-1 loss: 0.869665  [   64/  306]
train() client id: f_00004-8-2 loss: 0.916170  [   96/  306]
train() client id: f_00004-8-3 loss: 0.817402  [  128/  306]
train() client id: f_00004-8-4 loss: 0.961895  [  160/  306]
train() client id: f_00004-8-5 loss: 0.702007  [  192/  306]
train() client id: f_00004-8-6 loss: 0.835176  [  224/  306]
train() client id: f_00004-8-7 loss: 0.827401  [  256/  306]
train() client id: f_00004-8-8 loss: 0.850893  [  288/  306]
train() client id: f_00004-9-0 loss: 0.933222  [   32/  306]
train() client id: f_00004-9-1 loss: 0.882407  [   64/  306]
train() client id: f_00004-9-2 loss: 0.904310  [   96/  306]
train() client id: f_00004-9-3 loss: 0.950780  [  128/  306]
train() client id: f_00004-9-4 loss: 0.780761  [  160/  306]
train() client id: f_00004-9-5 loss: 0.850158  [  192/  306]
train() client id: f_00004-9-6 loss: 0.716556  [  224/  306]
train() client id: f_00004-9-7 loss: 0.815820  [  256/  306]
train() client id: f_00004-9-8 loss: 0.909984  [  288/  306]
train() client id: f_00004-10-0 loss: 0.887968  [   32/  306]
train() client id: f_00004-10-1 loss: 0.777068  [   64/  306]
train() client id: f_00004-10-2 loss: 0.780743  [   96/  306]
train() client id: f_00004-10-3 loss: 1.029041  [  128/  306]
train() client id: f_00004-10-4 loss: 0.958690  [  160/  306]
train() client id: f_00004-10-5 loss: 0.849550  [  192/  306]
train() client id: f_00004-10-6 loss: 0.852691  [  224/  306]
train() client id: f_00004-10-7 loss: 0.821444  [  256/  306]
train() client id: f_00004-10-8 loss: 0.839979  [  288/  306]
train() client id: f_00004-11-0 loss: 0.912544  [   32/  306]
train() client id: f_00004-11-1 loss: 0.730023  [   64/  306]
train() client id: f_00004-11-2 loss: 0.830706  [   96/  306]
train() client id: f_00004-11-3 loss: 0.895552  [  128/  306]
train() client id: f_00004-11-4 loss: 0.984588  [  160/  306]
train() client id: f_00004-11-5 loss: 0.816175  [  192/  306]
train() client id: f_00004-11-6 loss: 0.739121  [  224/  306]
train() client id: f_00004-11-7 loss: 0.816608  [  256/  306]
train() client id: f_00004-11-8 loss: 0.873778  [  288/  306]
train() client id: f_00004-12-0 loss: 1.014929  [   32/  306]
train() client id: f_00004-12-1 loss: 0.846850  [   64/  306]
train() client id: f_00004-12-2 loss: 0.938438  [   96/  306]
train() client id: f_00004-12-3 loss: 0.751147  [  128/  306]
train() client id: f_00004-12-4 loss: 0.857459  [  160/  306]
train() client id: f_00004-12-5 loss: 0.840385  [  192/  306]
train() client id: f_00004-12-6 loss: 0.818115  [  224/  306]
train() client id: f_00004-12-7 loss: 0.864192  [  256/  306]
train() client id: f_00004-12-8 loss: 0.871188  [  288/  306]
train() client id: f_00005-0-0 loss: 0.713483  [   32/  146]
train() client id: f_00005-0-1 loss: 0.727207  [   64/  146]
train() client id: f_00005-0-2 loss: 0.794642  [   96/  146]
train() client id: f_00005-0-3 loss: 0.539611  [  128/  146]
train() client id: f_00005-1-0 loss: 0.524021  [   32/  146]
train() client id: f_00005-1-1 loss: 0.753946  [   64/  146]
train() client id: f_00005-1-2 loss: 0.695527  [   96/  146]
train() client id: f_00005-1-3 loss: 0.595124  [  128/  146]
train() client id: f_00005-2-0 loss: 0.582580  [   32/  146]
train() client id: f_00005-2-1 loss: 0.771089  [   64/  146]
train() client id: f_00005-2-2 loss: 0.549667  [   96/  146]
train() client id: f_00005-2-3 loss: 0.758509  [  128/  146]
train() client id: f_00005-3-0 loss: 0.521432  [   32/  146]
train() client id: f_00005-3-1 loss: 0.545384  [   64/  146]
train() client id: f_00005-3-2 loss: 0.811204  [   96/  146]
train() client id: f_00005-3-3 loss: 0.701040  [  128/  146]
train() client id: f_00005-4-0 loss: 0.658507  [   32/  146]
train() client id: f_00005-4-1 loss: 0.769962  [   64/  146]
train() client id: f_00005-4-2 loss: 0.668426  [   96/  146]
train() client id: f_00005-4-3 loss: 0.443232  [  128/  146]
train() client id: f_00005-5-0 loss: 0.567093  [   32/  146]
train() client id: f_00005-5-1 loss: 0.630499  [   64/  146]
train() client id: f_00005-5-2 loss: 0.708604  [   96/  146]
train() client id: f_00005-5-3 loss: 0.677787  [  128/  146]
train() client id: f_00005-6-0 loss: 0.880931  [   32/  146]
train() client id: f_00005-6-1 loss: 0.602643  [   64/  146]
train() client id: f_00005-6-2 loss: 0.374291  [   96/  146]
train() client id: f_00005-6-3 loss: 0.641200  [  128/  146]
train() client id: f_00005-7-0 loss: 0.660907  [   32/  146]
train() client id: f_00005-7-1 loss: 0.651277  [   64/  146]
train() client id: f_00005-7-2 loss: 0.636100  [   96/  146]
train() client id: f_00005-7-3 loss: 0.552581  [  128/  146]
train() client id: f_00005-8-0 loss: 0.500783  [   32/  146]
train() client id: f_00005-8-1 loss: 0.898666  [   64/  146]
train() client id: f_00005-8-2 loss: 0.554391  [   96/  146]
train() client id: f_00005-8-3 loss: 0.674127  [  128/  146]
train() client id: f_00005-9-0 loss: 0.800104  [   32/  146]
train() client id: f_00005-9-1 loss: 0.495538  [   64/  146]
train() client id: f_00005-9-2 loss: 0.705701  [   96/  146]
train() client id: f_00005-9-3 loss: 0.600192  [  128/  146]
train() client id: f_00005-10-0 loss: 0.670411  [   32/  146]
train() client id: f_00005-10-1 loss: 0.558578  [   64/  146]
train() client id: f_00005-10-2 loss: 0.867477  [   96/  146]
train() client id: f_00005-10-3 loss: 0.518283  [  128/  146]
train() client id: f_00005-11-0 loss: 0.725345  [   32/  146]
train() client id: f_00005-11-1 loss: 0.752966  [   64/  146]
train() client id: f_00005-11-2 loss: 0.471344  [   96/  146]
train() client id: f_00005-11-3 loss: 0.614380  [  128/  146]
train() client id: f_00005-12-0 loss: 0.803915  [   32/  146]
train() client id: f_00005-12-1 loss: 0.449014  [   64/  146]
train() client id: f_00005-12-2 loss: 0.556815  [   96/  146]
train() client id: f_00005-12-3 loss: 0.520616  [  128/  146]
train() client id: f_00006-0-0 loss: 0.622701  [   32/   54]
train() client id: f_00006-1-0 loss: 0.670088  [   32/   54]
train() client id: f_00006-2-0 loss: 0.699485  [   32/   54]
train() client id: f_00006-3-0 loss: 0.701976  [   32/   54]
train() client id: f_00006-4-0 loss: 0.667179  [   32/   54]
train() client id: f_00006-5-0 loss: 0.701637  [   32/   54]
train() client id: f_00006-6-0 loss: 0.687520  [   32/   54]
train() client id: f_00006-7-0 loss: 0.699939  [   32/   54]
train() client id: f_00006-8-0 loss: 0.668183  [   32/   54]
train() client id: f_00006-9-0 loss: 0.661794  [   32/   54]
train() client id: f_00006-10-0 loss: 0.662151  [   32/   54]
train() client id: f_00006-11-0 loss: 0.679095  [   32/   54]
train() client id: f_00006-12-0 loss: 0.699290  [   32/   54]
train() client id: f_00007-0-0 loss: 0.772707  [   32/  179]
train() client id: f_00007-0-1 loss: 0.644503  [   64/  179]
train() client id: f_00007-0-2 loss: 0.740336  [   96/  179]
train() client id: f_00007-0-3 loss: 0.663089  [  128/  179]
train() client id: f_00007-0-4 loss: 0.590668  [  160/  179]
train() client id: f_00007-1-0 loss: 0.841609  [   32/  179]
train() client id: f_00007-1-1 loss: 0.661195  [   64/  179]
train() client id: f_00007-1-2 loss: 0.641617  [   96/  179]
train() client id: f_00007-1-3 loss: 0.612550  [  128/  179]
train() client id: f_00007-1-4 loss: 0.590164  [  160/  179]
train() client id: f_00007-2-0 loss: 0.545775  [   32/  179]
train() client id: f_00007-2-1 loss: 0.608377  [   64/  179]
train() client id: f_00007-2-2 loss: 0.615974  [   96/  179]
train() client id: f_00007-2-3 loss: 0.620549  [  128/  179]
train() client id: f_00007-2-4 loss: 0.652134  [  160/  179]
train() client id: f_00007-3-0 loss: 0.609038  [   32/  179]
train() client id: f_00007-3-1 loss: 0.685387  [   64/  179]
train() client id: f_00007-3-2 loss: 0.560962  [   96/  179]
train() client id: f_00007-3-3 loss: 0.614890  [  128/  179]
train() client id: f_00007-3-4 loss: 0.727308  [  160/  179]
train() client id: f_00007-4-0 loss: 0.623551  [   32/  179]
train() client id: f_00007-4-1 loss: 0.717250  [   64/  179]
train() client id: f_00007-4-2 loss: 0.682155  [   96/  179]
train() client id: f_00007-4-3 loss: 0.459989  [  128/  179]
train() client id: f_00007-4-4 loss: 0.722697  [  160/  179]
train() client id: f_00007-5-0 loss: 0.683367  [   32/  179]
train() client id: f_00007-5-1 loss: 0.718350  [   64/  179]
train() client id: f_00007-5-2 loss: 0.494976  [   96/  179]
train() client id: f_00007-5-3 loss: 0.709268  [  128/  179]
train() client id: f_00007-5-4 loss: 0.563216  [  160/  179]
train() client id: f_00007-6-0 loss: 0.507823  [   32/  179]
train() client id: f_00007-6-1 loss: 0.634362  [   64/  179]
train() client id: f_00007-6-2 loss: 0.594606  [   96/  179]
train() client id: f_00007-6-3 loss: 0.763043  [  128/  179]
train() client id: f_00007-6-4 loss: 0.559263  [  160/  179]
train() client id: f_00007-7-0 loss: 0.489420  [   32/  179]
train() client id: f_00007-7-1 loss: 0.570586  [   64/  179]
train() client id: f_00007-7-2 loss: 0.557034  [   96/  179]
train() client id: f_00007-7-3 loss: 0.846222  [  128/  179]
train() client id: f_00007-7-4 loss: 0.661032  [  160/  179]
train() client id: f_00007-8-0 loss: 0.585461  [   32/  179]
train() client id: f_00007-8-1 loss: 0.561435  [   64/  179]
train() client id: f_00007-8-2 loss: 0.584637  [   96/  179]
train() client id: f_00007-8-3 loss: 0.634550  [  128/  179]
train() client id: f_00007-8-4 loss: 0.757998  [  160/  179]
train() client id: f_00007-9-0 loss: 0.570802  [   32/  179]
train() client id: f_00007-9-1 loss: 0.634595  [   64/  179]
train() client id: f_00007-9-2 loss: 0.723616  [   96/  179]
train() client id: f_00007-9-3 loss: 0.571780  [  128/  179]
train() client id: f_00007-9-4 loss: 0.494290  [  160/  179]
train() client id: f_00007-10-0 loss: 0.698903  [   32/  179]
train() client id: f_00007-10-1 loss: 0.911377  [   64/  179]
train() client id: f_00007-10-2 loss: 0.461821  [   96/  179]
train() client id: f_00007-10-3 loss: 0.559156  [  128/  179]
train() client id: f_00007-10-4 loss: 0.483462  [  160/  179]
train() client id: f_00007-11-0 loss: 0.483514  [   32/  179]
train() client id: f_00007-11-1 loss: 0.596851  [   64/  179]
train() client id: f_00007-11-2 loss: 0.655019  [   96/  179]
train() client id: f_00007-11-3 loss: 0.708264  [  128/  179]
train() client id: f_00007-11-4 loss: 0.582122  [  160/  179]
train() client id: f_00007-12-0 loss: 0.589315  [   32/  179]
train() client id: f_00007-12-1 loss: 0.727676  [   64/  179]
train() client id: f_00007-12-2 loss: 0.489357  [   96/  179]
train() client id: f_00007-12-3 loss: 0.557044  [  128/  179]
train() client id: f_00007-12-4 loss: 0.594012  [  160/  179]
train() client id: f_00008-0-0 loss: 0.771155  [   32/  130]
train() client id: f_00008-0-1 loss: 0.901722  [   64/  130]
train() client id: f_00008-0-2 loss: 0.937696  [   96/  130]
train() client id: f_00008-0-3 loss: 0.789261  [  128/  130]
train() client id: f_00008-1-0 loss: 0.718609  [   32/  130]
train() client id: f_00008-1-1 loss: 0.965169  [   64/  130]
train() client id: f_00008-1-2 loss: 0.947089  [   96/  130]
train() client id: f_00008-1-3 loss: 0.791982  [  128/  130]
train() client id: f_00008-2-0 loss: 0.846267  [   32/  130]
train() client id: f_00008-2-1 loss: 0.877984  [   64/  130]
train() client id: f_00008-2-2 loss: 0.761072  [   96/  130]
train() client id: f_00008-2-3 loss: 0.902524  [  128/  130]
train() client id: f_00008-3-0 loss: 0.779752  [   32/  130]
train() client id: f_00008-3-1 loss: 0.902616  [   64/  130]
train() client id: f_00008-3-2 loss: 0.901509  [   96/  130]
train() client id: f_00008-3-3 loss: 0.813543  [  128/  130]
train() client id: f_00008-4-0 loss: 0.922242  [   32/  130]
train() client id: f_00008-4-1 loss: 0.884870  [   64/  130]
train() client id: f_00008-4-2 loss: 0.785775  [   96/  130]
train() client id: f_00008-4-3 loss: 0.791945  [  128/  130]
train() client id: f_00008-5-0 loss: 0.803111  [   32/  130]
train() client id: f_00008-5-1 loss: 0.927958  [   64/  130]
train() client id: f_00008-5-2 loss: 0.808526  [   96/  130]
train() client id: f_00008-5-3 loss: 0.826742  [  128/  130]
train() client id: f_00008-6-0 loss: 0.779689  [   32/  130]
train() client id: f_00008-6-1 loss: 0.858792  [   64/  130]
train() client id: f_00008-6-2 loss: 0.842452  [   96/  130]
train() client id: f_00008-6-3 loss: 0.882133  [  128/  130]
train() client id: f_00008-7-0 loss: 0.859799  [   32/  130]
train() client id: f_00008-7-1 loss: 0.813465  [   64/  130]
train() client id: f_00008-7-2 loss: 0.910773  [   96/  130]
train() client id: f_00008-7-3 loss: 0.794441  [  128/  130]
train() client id: f_00008-8-0 loss: 0.745938  [   32/  130]
train() client id: f_00008-8-1 loss: 0.851029  [   64/  130]
train() client id: f_00008-8-2 loss: 0.852831  [   96/  130]
train() client id: f_00008-8-3 loss: 0.912678  [  128/  130]
train() client id: f_00008-9-0 loss: 0.756376  [   32/  130]
train() client id: f_00008-9-1 loss: 0.837321  [   64/  130]
train() client id: f_00008-9-2 loss: 0.796673  [   96/  130]
train() client id: f_00008-9-3 loss: 1.005648  [  128/  130]
train() client id: f_00008-10-0 loss: 0.847216  [   32/  130]
train() client id: f_00008-10-1 loss: 0.837568  [   64/  130]
train() client id: f_00008-10-2 loss: 0.825753  [   96/  130]
train() client id: f_00008-10-3 loss: 0.872229  [  128/  130]
train() client id: f_00008-11-0 loss: 0.703656  [   32/  130]
train() client id: f_00008-11-1 loss: 0.791833  [   64/  130]
train() client id: f_00008-11-2 loss: 0.928562  [   96/  130]
train() client id: f_00008-11-3 loss: 0.897568  [  128/  130]
train() client id: f_00008-12-0 loss: 0.899562  [   32/  130]
train() client id: f_00008-12-1 loss: 0.756472  [   64/  130]
train() client id: f_00008-12-2 loss: 0.884583  [   96/  130]
train() client id: f_00008-12-3 loss: 0.850837  [  128/  130]
train() client id: f_00009-0-0 loss: 1.198470  [   32/  118]
train() client id: f_00009-0-1 loss: 1.269428  [   64/  118]
train() client id: f_00009-0-2 loss: 1.230232  [   96/  118]
train() client id: f_00009-1-0 loss: 1.202749  [   32/  118]
train() client id: f_00009-1-1 loss: 1.101523  [   64/  118]
train() client id: f_00009-1-2 loss: 1.177476  [   96/  118]
train() client id: f_00009-2-0 loss: 1.122842  [   32/  118]
train() client id: f_00009-2-1 loss: 1.144301  [   64/  118]
train() client id: f_00009-2-2 loss: 1.090578  [   96/  118]
train() client id: f_00009-3-0 loss: 1.066396  [   32/  118]
train() client id: f_00009-3-1 loss: 1.169363  [   64/  118]
train() client id: f_00009-3-2 loss: 1.076855  [   96/  118]
train() client id: f_00009-4-0 loss: 1.043344  [   32/  118]
train() client id: f_00009-4-1 loss: 1.023561  [   64/  118]
train() client id: f_00009-4-2 loss: 1.000169  [   96/  118]
train() client id: f_00009-5-0 loss: 1.071258  [   32/  118]
train() client id: f_00009-5-1 loss: 0.978925  [   64/  118]
train() client id: f_00009-5-2 loss: 1.016158  [   96/  118]
train() client id: f_00009-6-0 loss: 0.991011  [   32/  118]
train() client id: f_00009-6-1 loss: 1.007172  [   64/  118]
train() client id: f_00009-6-2 loss: 0.971588  [   96/  118]
train() client id: f_00009-7-0 loss: 0.883039  [   32/  118]
train() client id: f_00009-7-1 loss: 0.976642  [   64/  118]
train() client id: f_00009-7-2 loss: 1.040404  [   96/  118]
train() client id: f_00009-8-0 loss: 0.934595  [   32/  118]
train() client id: f_00009-8-1 loss: 0.935520  [   64/  118]
train() client id: f_00009-8-2 loss: 0.952912  [   96/  118]
train() client id: f_00009-9-0 loss: 0.931562  [   32/  118]
train() client id: f_00009-9-1 loss: 0.940244  [   64/  118]
train() client id: f_00009-9-2 loss: 0.966196  [   96/  118]
train() client id: f_00009-10-0 loss: 0.925586  [   32/  118]
train() client id: f_00009-10-1 loss: 0.863348  [   64/  118]
train() client id: f_00009-10-2 loss: 0.994413  [   96/  118]
train() client id: f_00009-11-0 loss: 0.976686  [   32/  118]
train() client id: f_00009-11-1 loss: 0.983545  [   64/  118]
train() client id: f_00009-11-2 loss: 0.913218  [   96/  118]
train() client id: f_00009-12-0 loss: 0.874817  [   32/  118]
train() client id: f_00009-12-1 loss: 0.901881  [   64/  118]
train() client id: f_00009-12-2 loss: 0.894191  [   96/  118]
At round 12 accuracy: 0.6339522546419099
At round 12 training accuracy: 0.5814889336016097
At round 12 training loss: 0.8618923727272209
gradient difference: 0.39899173378944397
train() client id: f_00000-0-0 loss: 1.382086  [   32/  126]
train() client id: f_00000-0-1 loss: 1.144741  [   64/  126]
train() client id: f_00000-0-2 loss: 1.067288  [   96/  126]
train() client id: f_00000-1-0 loss: 1.105170  [   32/  126]
train() client id: f_00000-1-1 loss: 1.059509  [   64/  126]
train() client id: f_00000-1-2 loss: 1.032287  [   96/  126]
train() client id: f_00000-2-0 loss: 1.161539  [   32/  126]
train() client id: f_00000-2-1 loss: 1.019085  [   64/  126]
train() client id: f_00000-2-2 loss: 0.829509  [   96/  126]
train() client id: f_00000-3-0 loss: 0.866881  [   32/  126]
train() client id: f_00000-3-1 loss: 1.030738  [   64/  126]
train() client id: f_00000-3-2 loss: 0.953776  [   96/  126]
train() client id: f_00000-4-0 loss: 0.959468  [   32/  126]
train() client id: f_00000-4-1 loss: 0.855353  [   64/  126]
train() client id: f_00000-4-2 loss: 0.862911  [   96/  126]
train() client id: f_00000-5-0 loss: 0.898473  [   32/  126]
train() client id: f_00000-5-1 loss: 0.967384  [   64/  126]
train() client id: f_00000-5-2 loss: 0.778561  [   96/  126]
train() client id: f_00000-6-0 loss: 0.795677  [   32/  126]
train() client id: f_00000-6-1 loss: 0.868109  [   64/  126]
train() client id: f_00000-6-2 loss: 0.885036  [   96/  126]
train() client id: f_00000-7-0 loss: 0.846292  [   32/  126]
train() client id: f_00000-7-1 loss: 0.768971  [   64/  126]
train() client id: f_00000-7-2 loss: 0.830572  [   96/  126]
train() client id: f_00000-8-0 loss: 0.798842  [   32/  126]
train() client id: f_00000-8-1 loss: 0.772356  [   64/  126]
train() client id: f_00000-8-2 loss: 0.821465  [   96/  126]
train() client id: f_00000-9-0 loss: 0.774352  [   32/  126]
train() client id: f_00000-9-1 loss: 0.848596  [   64/  126]
train() client id: f_00000-9-2 loss: 0.692020  [   96/  126]
train() client id: f_00000-10-0 loss: 0.838162  [   32/  126]
train() client id: f_00000-10-1 loss: 0.681261  [   64/  126]
train() client id: f_00000-10-2 loss: 0.794606  [   96/  126]
train() client id: f_00000-11-0 loss: 0.786827  [   32/  126]
train() client id: f_00000-11-1 loss: 0.732518  [   64/  126]
train() client id: f_00000-11-2 loss: 0.787132  [   96/  126]
train() client id: f_00000-12-0 loss: 0.936159  [   32/  126]
train() client id: f_00000-12-1 loss: 0.621088  [   64/  126]
train() client id: f_00000-12-2 loss: 0.729858  [   96/  126]
train() client id: f_00001-0-0 loss: 0.471203  [   32/  265]
train() client id: f_00001-0-1 loss: 0.537814  [   64/  265]
train() client id: f_00001-0-2 loss: 0.462004  [   96/  265]
train() client id: f_00001-0-3 loss: 0.415837  [  128/  265]
train() client id: f_00001-0-4 loss: 0.576801  [  160/  265]
train() client id: f_00001-0-5 loss: 0.566167  [  192/  265]
train() client id: f_00001-0-6 loss: 0.496463  [  224/  265]
train() client id: f_00001-0-7 loss: 0.446003  [  256/  265]
train() client id: f_00001-1-0 loss: 0.452158  [   32/  265]
train() client id: f_00001-1-1 loss: 0.446113  [   64/  265]
train() client id: f_00001-1-2 loss: 0.466283  [   96/  265]
train() client id: f_00001-1-3 loss: 0.496536  [  128/  265]
train() client id: f_00001-1-4 loss: 0.501850  [  160/  265]
train() client id: f_00001-1-5 loss: 0.524849  [  192/  265]
train() client id: f_00001-1-6 loss: 0.523585  [  224/  265]
train() client id: f_00001-1-7 loss: 0.464823  [  256/  265]
train() client id: f_00001-2-0 loss: 0.452747  [   32/  265]
train() client id: f_00001-2-1 loss: 0.595199  [   64/  265]
train() client id: f_00001-2-2 loss: 0.415626  [   96/  265]
train() client id: f_00001-2-3 loss: 0.512555  [  128/  265]
train() client id: f_00001-2-4 loss: 0.511520  [  160/  265]
train() client id: f_00001-2-5 loss: 0.462089  [  192/  265]
train() client id: f_00001-2-6 loss: 0.463180  [  224/  265]
train() client id: f_00001-2-7 loss: 0.398401  [  256/  265]
train() client id: f_00001-3-0 loss: 0.534559  [   32/  265]
train() client id: f_00001-3-1 loss: 0.547777  [   64/  265]
train() client id: f_00001-3-2 loss: 0.423222  [   96/  265]
train() client id: f_00001-3-3 loss: 0.396206  [  128/  265]
train() client id: f_00001-3-4 loss: 0.458344  [  160/  265]
train() client id: f_00001-3-5 loss: 0.479902  [  192/  265]
train() client id: f_00001-3-6 loss: 0.435475  [  224/  265]
train() client id: f_00001-3-7 loss: 0.431186  [  256/  265]
train() client id: f_00001-4-0 loss: 0.503280  [   32/  265]
train() client id: f_00001-4-1 loss: 0.533461  [   64/  265]
train() client id: f_00001-4-2 loss: 0.482111  [   96/  265]
train() client id: f_00001-4-3 loss: 0.382511  [  128/  265]
train() client id: f_00001-4-4 loss: 0.411629  [  160/  265]
train() client id: f_00001-4-5 loss: 0.391103  [  192/  265]
train() client id: f_00001-4-6 loss: 0.500312  [  224/  265]
train() client id: f_00001-4-7 loss: 0.461574  [  256/  265]
train() client id: f_00001-5-0 loss: 0.513661  [   32/  265]
train() client id: f_00001-5-1 loss: 0.378736  [   64/  265]
train() client id: f_00001-5-2 loss: 0.384192  [   96/  265]
train() client id: f_00001-5-3 loss: 0.384658  [  128/  265]
train() client id: f_00001-5-4 loss: 0.500912  [  160/  265]
train() client id: f_00001-5-5 loss: 0.415581  [  192/  265]
train() client id: f_00001-5-6 loss: 0.466832  [  224/  265]
train() client id: f_00001-5-7 loss: 0.590343  [  256/  265]
train() client id: f_00001-6-0 loss: 0.541578  [   32/  265]
train() client id: f_00001-6-1 loss: 0.433606  [   64/  265]
train() client id: f_00001-6-2 loss: 0.487285  [   96/  265]
train() client id: f_00001-6-3 loss: 0.483885  [  128/  265]
train() client id: f_00001-6-4 loss: 0.389689  [  160/  265]
train() client id: f_00001-6-5 loss: 0.427350  [  192/  265]
train() client id: f_00001-6-6 loss: 0.472905  [  224/  265]
train() client id: f_00001-6-7 loss: 0.400592  [  256/  265]
train() client id: f_00001-7-0 loss: 0.382703  [   32/  265]
train() client id: f_00001-7-1 loss: 0.394474  [   64/  265]
train() client id: f_00001-7-2 loss: 0.457583  [   96/  265]
train() client id: f_00001-7-3 loss: 0.393161  [  128/  265]
train() client id: f_00001-7-4 loss: 0.506338  [  160/  265]
train() client id: f_00001-7-5 loss: 0.519576  [  192/  265]
train() client id: f_00001-7-6 loss: 0.512776  [  224/  265]
train() client id: f_00001-7-7 loss: 0.436464  [  256/  265]
train() client id: f_00001-8-0 loss: 0.393001  [   32/  265]
train() client id: f_00001-8-1 loss: 0.533809  [   64/  265]
train() client id: f_00001-8-2 loss: 0.523740  [   96/  265]
train() client id: f_00001-8-3 loss: 0.521613  [  128/  265]
train() client id: f_00001-8-4 loss: 0.444108  [  160/  265]
train() client id: f_00001-8-5 loss: 0.366796  [  192/  265]
train() client id: f_00001-8-6 loss: 0.419572  [  224/  265]
train() client id: f_00001-8-7 loss: 0.375821  [  256/  265]
train() client id: f_00001-9-0 loss: 0.355593  [   32/  265]
train() client id: f_00001-9-1 loss: 0.358335  [   64/  265]
train() client id: f_00001-9-2 loss: 0.462141  [   96/  265]
train() client id: f_00001-9-3 loss: 0.499773  [  128/  265]
train() client id: f_00001-9-4 loss: 0.422391  [  160/  265]
train() client id: f_00001-9-5 loss: 0.536050  [  192/  265]
train() client id: f_00001-9-6 loss: 0.518913  [  224/  265]
train() client id: f_00001-9-7 loss: 0.417373  [  256/  265]
train() client id: f_00001-10-0 loss: 0.459641  [   32/  265]
train() client id: f_00001-10-1 loss: 0.399667  [   64/  265]
train() client id: f_00001-10-2 loss: 0.434659  [   96/  265]
train() client id: f_00001-10-3 loss: 0.443438  [  128/  265]
train() client id: f_00001-10-4 loss: 0.467377  [  160/  265]
train() client id: f_00001-10-5 loss: 0.491506  [  192/  265]
train() client id: f_00001-10-6 loss: 0.411927  [  224/  265]
train() client id: f_00001-10-7 loss: 0.461238  [  256/  265]
train() client id: f_00001-11-0 loss: 0.431374  [   32/  265]
train() client id: f_00001-11-1 loss: 0.510939  [   64/  265]
train() client id: f_00001-11-2 loss: 0.567916  [   96/  265]
train() client id: f_00001-11-3 loss: 0.370693  [  128/  265]
train() client id: f_00001-11-4 loss: 0.347340  [  160/  265]
train() client id: f_00001-11-5 loss: 0.472201  [  192/  265]
train() client id: f_00001-11-6 loss: 0.416135  [  224/  265]
train() client id: f_00001-11-7 loss: 0.453238  [  256/  265]
train() client id: f_00001-12-0 loss: 0.415257  [   32/  265]
train() client id: f_00001-12-1 loss: 0.391516  [   64/  265]
train() client id: f_00001-12-2 loss: 0.442638  [   96/  265]
train() client id: f_00001-12-3 loss: 0.401227  [  128/  265]
train() client id: f_00001-12-4 loss: 0.370287  [  160/  265]
train() client id: f_00001-12-5 loss: 0.397105  [  192/  265]
train() client id: f_00001-12-6 loss: 0.525452  [  224/  265]
train() client id: f_00001-12-7 loss: 0.535420  [  256/  265]
train() client id: f_00002-0-0 loss: 1.223572  [   32/  124]
train() client id: f_00002-0-1 loss: 1.254233  [   64/  124]
train() client id: f_00002-0-2 loss: 1.205861  [   96/  124]
train() client id: f_00002-1-0 loss: 1.187308  [   32/  124]
train() client id: f_00002-1-1 loss: 1.242043  [   64/  124]
train() client id: f_00002-1-2 loss: 1.242429  [   96/  124]
train() client id: f_00002-2-0 loss: 1.148234  [   32/  124]
train() client id: f_00002-2-1 loss: 1.199465  [   64/  124]
train() client id: f_00002-2-2 loss: 1.137195  [   96/  124]
train() client id: f_00002-3-0 loss: 1.066980  [   32/  124]
train() client id: f_00002-3-1 loss: 1.212113  [   64/  124]
train() client id: f_00002-3-2 loss: 1.147780  [   96/  124]
train() client id: f_00002-4-0 loss: 1.201443  [   32/  124]
train() client id: f_00002-4-1 loss: 1.065719  [   64/  124]
train() client id: f_00002-4-2 loss: 1.030729  [   96/  124]
train() client id: f_00002-5-0 loss: 1.050752  [   32/  124]
train() client id: f_00002-5-1 loss: 1.196534  [   64/  124]
train() client id: f_00002-5-2 loss: 0.990199  [   96/  124]
train() client id: f_00002-6-0 loss: 1.045918  [   32/  124]
train() client id: f_00002-6-1 loss: 1.038412  [   64/  124]
train() client id: f_00002-6-2 loss: 1.134327  [   96/  124]
train() client id: f_00002-7-0 loss: 0.986051  [   32/  124]
train() client id: f_00002-7-1 loss: 1.003452  [   64/  124]
train() client id: f_00002-7-2 loss: 1.107518  [   96/  124]
train() client id: f_00002-8-0 loss: 1.032131  [   32/  124]
train() client id: f_00002-8-1 loss: 1.044046  [   64/  124]
train() client id: f_00002-8-2 loss: 1.029624  [   96/  124]
train() client id: f_00002-9-0 loss: 1.142079  [   32/  124]
train() client id: f_00002-9-1 loss: 0.876512  [   64/  124]
train() client id: f_00002-9-2 loss: 1.035269  [   96/  124]
train() client id: f_00002-10-0 loss: 1.003116  [   32/  124]
train() client id: f_00002-10-1 loss: 1.036349  [   64/  124]
train() client id: f_00002-10-2 loss: 0.963003  [   96/  124]
train() client id: f_00002-11-0 loss: 0.960124  [   32/  124]
train() client id: f_00002-11-1 loss: 1.004625  [   64/  124]
train() client id: f_00002-11-2 loss: 1.004590  [   96/  124]
train() client id: f_00002-12-0 loss: 0.925849  [   32/  124]
train() client id: f_00002-12-1 loss: 1.100922  [   64/  124]
train() client id: f_00002-12-2 loss: 0.984102  [   96/  124]
train() client id: f_00003-0-0 loss: 0.780668  [   32/   43]
train() client id: f_00003-1-0 loss: 0.877233  [   32/   43]
train() client id: f_00003-2-0 loss: 0.772601  [   32/   43]
train() client id: f_00003-3-0 loss: 0.863420  [   32/   43]
train() client id: f_00003-4-0 loss: 0.785187  [   32/   43]
train() client id: f_00003-5-0 loss: 0.804662  [   32/   43]
train() client id: f_00003-6-0 loss: 0.846458  [   32/   43]
train() client id: f_00003-7-0 loss: 0.826638  [   32/   43]
train() client id: f_00003-8-0 loss: 0.766260  [   32/   43]
train() client id: f_00003-9-0 loss: 0.916292  [   32/   43]
train() client id: f_00003-10-0 loss: 0.815967  [   32/   43]
train() client id: f_00003-11-0 loss: 0.918396  [   32/   43]
train() client id: f_00003-12-0 loss: 0.747031  [   32/   43]
train() client id: f_00004-0-0 loss: 0.849886  [   32/  306]
train() client id: f_00004-0-1 loss: 1.021779  [   64/  306]
train() client id: f_00004-0-2 loss: 1.022713  [   96/  306]
train() client id: f_00004-0-3 loss: 0.986670  [  128/  306]
train() client id: f_00004-0-4 loss: 0.853830  [  160/  306]
train() client id: f_00004-0-5 loss: 0.779774  [  192/  306]
train() client id: f_00004-0-6 loss: 0.926625  [  224/  306]
train() client id: f_00004-0-7 loss: 0.880977  [  256/  306]
train() client id: f_00004-0-8 loss: 0.965526  [  288/  306]
train() client id: f_00004-1-0 loss: 0.721701  [   32/  306]
train() client id: f_00004-1-1 loss: 0.843384  [   64/  306]
train() client id: f_00004-1-2 loss: 1.005437  [   96/  306]
train() client id: f_00004-1-3 loss: 0.951635  [  128/  306]
train() client id: f_00004-1-4 loss: 0.778064  [  160/  306]
train() client id: f_00004-1-5 loss: 0.884126  [  192/  306]
train() client id: f_00004-1-6 loss: 1.049070  [  224/  306]
train() client id: f_00004-1-7 loss: 0.875993  [  256/  306]
train() client id: f_00004-1-8 loss: 1.009729  [  288/  306]
train() client id: f_00004-2-0 loss: 0.920299  [   32/  306]
train() client id: f_00004-2-1 loss: 0.891329  [   64/  306]
train() client id: f_00004-2-2 loss: 0.970777  [   96/  306]
train() client id: f_00004-2-3 loss: 0.895336  [  128/  306]
train() client id: f_00004-2-4 loss: 0.896673  [  160/  306]
train() client id: f_00004-2-5 loss: 0.869639  [  192/  306]
train() client id: f_00004-2-6 loss: 0.785772  [  224/  306]
train() client id: f_00004-2-7 loss: 0.896865  [  256/  306]
train() client id: f_00004-2-8 loss: 0.965241  [  288/  306]
train() client id: f_00004-3-0 loss: 1.007106  [   32/  306]
train() client id: f_00004-3-1 loss: 0.887767  [   64/  306]
train() client id: f_00004-3-2 loss: 1.006180  [   96/  306]
train() client id: f_00004-3-3 loss: 0.880985  [  128/  306]
train() client id: f_00004-3-4 loss: 0.788481  [  160/  306]
train() client id: f_00004-3-5 loss: 0.874173  [  192/  306]
train() client id: f_00004-3-6 loss: 0.879175  [  224/  306]
train() client id: f_00004-3-7 loss: 0.947498  [  256/  306]
train() client id: f_00004-3-8 loss: 0.854833  [  288/  306]
train() client id: f_00004-4-0 loss: 0.930703  [   32/  306]
train() client id: f_00004-4-1 loss: 0.826962  [   64/  306]
train() client id: f_00004-4-2 loss: 0.950914  [   96/  306]
train() client id: f_00004-4-3 loss: 0.933318  [  128/  306]
train() client id: f_00004-4-4 loss: 0.847724  [  160/  306]
train() client id: f_00004-4-5 loss: 0.909327  [  192/  306]
train() client id: f_00004-4-6 loss: 0.834203  [  224/  306]
train() client id: f_00004-4-7 loss: 0.929095  [  256/  306]
train() client id: f_00004-4-8 loss: 0.939601  [  288/  306]
train() client id: f_00004-5-0 loss: 0.826447  [   32/  306]
train() client id: f_00004-5-1 loss: 0.943511  [   64/  306]
train() client id: f_00004-5-2 loss: 0.743381  [   96/  306]
train() client id: f_00004-5-3 loss: 0.931887  [  128/  306]
train() client id: f_00004-5-4 loss: 0.986326  [  160/  306]
train() client id: f_00004-5-5 loss: 0.844636  [  192/  306]
train() client id: f_00004-5-6 loss: 0.911344  [  224/  306]
train() client id: f_00004-5-7 loss: 0.897761  [  256/  306]
train() client id: f_00004-5-8 loss: 1.035301  [  288/  306]
train() client id: f_00004-6-0 loss: 0.867640  [   32/  306]
train() client id: f_00004-6-1 loss: 0.772437  [   64/  306]
train() client id: f_00004-6-2 loss: 0.920349  [   96/  306]
train() client id: f_00004-6-3 loss: 0.914184  [  128/  306]
train() client id: f_00004-6-4 loss: 0.809491  [  160/  306]
train() client id: f_00004-6-5 loss: 0.942176  [  192/  306]
train() client id: f_00004-6-6 loss: 0.864014  [  224/  306]
train() client id: f_00004-6-7 loss: 0.905686  [  256/  306]
train() client id: f_00004-6-8 loss: 1.030256  [  288/  306]
train() client id: f_00004-7-0 loss: 0.831319  [   32/  306]
train() client id: f_00004-7-1 loss: 0.862806  [   64/  306]
train() client id: f_00004-7-2 loss: 0.994794  [   96/  306]
train() client id: f_00004-7-3 loss: 0.945430  [  128/  306]
train() client id: f_00004-7-4 loss: 0.956398  [  160/  306]
train() client id: f_00004-7-5 loss: 0.783177  [  192/  306]
train() client id: f_00004-7-6 loss: 0.830022  [  224/  306]
train() client id: f_00004-7-7 loss: 0.884573  [  256/  306]
train() client id: f_00004-7-8 loss: 1.057786  [  288/  306]
train() client id: f_00004-8-0 loss: 0.976415  [   32/  306]
train() client id: f_00004-8-1 loss: 1.050056  [   64/  306]
train() client id: f_00004-8-2 loss: 0.910765  [   96/  306]
train() client id: f_00004-8-3 loss: 0.968097  [  128/  306]
train() client id: f_00004-8-4 loss: 0.781866  [  160/  306]
train() client id: f_00004-8-5 loss: 0.820908  [  192/  306]
train() client id: f_00004-8-6 loss: 0.895977  [  224/  306]
train() client id: f_00004-8-7 loss: 0.858966  [  256/  306]
train() client id: f_00004-8-8 loss: 0.908490  [  288/  306]
train() client id: f_00004-9-0 loss: 1.092275  [   32/  306]
train() client id: f_00004-9-1 loss: 0.878706  [   64/  306]
train() client id: f_00004-9-2 loss: 0.843177  [   96/  306]
train() client id: f_00004-9-3 loss: 0.972125  [  128/  306]
train() client id: f_00004-9-4 loss: 0.809276  [  160/  306]
train() client id: f_00004-9-5 loss: 0.884866  [  192/  306]
train() client id: f_00004-9-6 loss: 0.842400  [  224/  306]
train() client id: f_00004-9-7 loss: 0.894797  [  256/  306]
train() client id: f_00004-9-8 loss: 0.885780  [  288/  306]
train() client id: f_00004-10-0 loss: 0.888503  [   32/  306]
train() client id: f_00004-10-1 loss: 0.889946  [   64/  306]
train() client id: f_00004-10-2 loss: 0.973102  [   96/  306]
train() client id: f_00004-10-3 loss: 0.871055  [  128/  306]
train() client id: f_00004-10-4 loss: 0.817359  [  160/  306]
train() client id: f_00004-10-5 loss: 1.049441  [  192/  306]
train() client id: f_00004-10-6 loss: 0.937608  [  224/  306]
train() client id: f_00004-10-7 loss: 0.833767  [  256/  306]
train() client id: f_00004-10-8 loss: 0.841274  [  288/  306]
train() client id: f_00004-11-0 loss: 0.931582  [   32/  306]
train() client id: f_00004-11-1 loss: 0.871827  [   64/  306]
train() client id: f_00004-11-2 loss: 0.855007  [   96/  306]
train() client id: f_00004-11-3 loss: 0.937432  [  128/  306]
train() client id: f_00004-11-4 loss: 0.844404  [  160/  306]
train() client id: f_00004-11-5 loss: 0.993462  [  192/  306]
train() client id: f_00004-11-6 loss: 0.898857  [  224/  306]
train() client id: f_00004-11-7 loss: 0.843871  [  256/  306]
train() client id: f_00004-11-8 loss: 0.943526  [  288/  306]
train() client id: f_00004-12-0 loss: 0.849651  [   32/  306]
train() client id: f_00004-12-1 loss: 0.991766  [   64/  306]
train() client id: f_00004-12-2 loss: 0.974836  [   96/  306]
train() client id: f_00004-12-3 loss: 0.798971  [  128/  306]
train() client id: f_00004-12-4 loss: 0.895605  [  160/  306]
train() client id: f_00004-12-5 loss: 0.911000  [  192/  306]
train() client id: f_00004-12-6 loss: 0.889751  [  224/  306]
train() client id: f_00004-12-7 loss: 0.837055  [  256/  306]
train() client id: f_00004-12-8 loss: 0.885461  [  288/  306]
train() client id: f_00005-0-0 loss: 0.790955  [   32/  146]
train() client id: f_00005-0-1 loss: 0.755279  [   64/  146]
train() client id: f_00005-0-2 loss: 0.708417  [   96/  146]
train() client id: f_00005-0-3 loss: 1.129323  [  128/  146]
train() client id: f_00005-1-0 loss: 0.845579  [   32/  146]
train() client id: f_00005-1-1 loss: 0.806792  [   64/  146]
train() client id: f_00005-1-2 loss: 0.742360  [   96/  146]
train() client id: f_00005-1-3 loss: 0.957774  [  128/  146]
train() client id: f_00005-2-0 loss: 1.052716  [   32/  146]
train() client id: f_00005-2-1 loss: 0.717673  [   64/  146]
train() client id: f_00005-2-2 loss: 0.770492  [   96/  146]
train() client id: f_00005-2-3 loss: 0.806160  [  128/  146]
train() client id: f_00005-3-0 loss: 0.798147  [   32/  146]
train() client id: f_00005-3-1 loss: 0.820286  [   64/  146]
train() client id: f_00005-3-2 loss: 0.892641  [   96/  146]
train() client id: f_00005-3-3 loss: 0.972470  [  128/  146]
train() client id: f_00005-4-0 loss: 0.943769  [   32/  146]
train() client id: f_00005-4-1 loss: 0.868607  [   64/  146]
train() client id: f_00005-4-2 loss: 0.763930  [   96/  146]
train() client id: f_00005-4-3 loss: 0.750706  [  128/  146]
train() client id: f_00005-5-0 loss: 0.905385  [   32/  146]
train() client id: f_00005-5-1 loss: 0.642745  [   64/  146]
train() client id: f_00005-5-2 loss: 0.896735  [   96/  146]
train() client id: f_00005-5-3 loss: 0.841661  [  128/  146]
train() client id: f_00005-6-0 loss: 0.867616  [   32/  146]
train() client id: f_00005-6-1 loss: 0.942496  [   64/  146]
train() client id: f_00005-6-2 loss: 0.734718  [   96/  146]
train() client id: f_00005-6-3 loss: 0.814199  [  128/  146]
train() client id: f_00005-7-0 loss: 0.706578  [   32/  146]
train() client id: f_00005-7-1 loss: 0.852102  [   64/  146]
train() client id: f_00005-7-2 loss: 0.991363  [   96/  146]
train() client id: f_00005-7-3 loss: 0.858371  [  128/  146]
train() client id: f_00005-8-0 loss: 0.748621  [   32/  146]
train() client id: f_00005-8-1 loss: 0.679697  [   64/  146]
train() client id: f_00005-8-2 loss: 0.786886  [   96/  146]
train() client id: f_00005-8-3 loss: 1.002834  [  128/  146]
train() client id: f_00005-9-0 loss: 0.747976  [   32/  146]
train() client id: f_00005-9-1 loss: 0.954310  [   64/  146]
train() client id: f_00005-9-2 loss: 0.889816  [   96/  146]
train() client id: f_00005-9-3 loss: 0.810565  [  128/  146]
train() client id: f_00005-10-0 loss: 0.794943  [   32/  146]
train() client id: f_00005-10-1 loss: 0.891489  [   64/  146]
train() client id: f_00005-10-2 loss: 0.595256  [   96/  146]
train() client id: f_00005-10-3 loss: 0.941022  [  128/  146]
train() client id: f_00005-11-0 loss: 0.845361  [   32/  146]
train() client id: f_00005-11-1 loss: 0.768050  [   64/  146]
train() client id: f_00005-11-2 loss: 0.704736  [   96/  146]
train() client id: f_00005-11-3 loss: 0.767105  [  128/  146]
train() client id: f_00005-12-0 loss: 0.872838  [   32/  146]
train() client id: f_00005-12-1 loss: 0.654563  [   64/  146]
train() client id: f_00005-12-2 loss: 0.901833  [   96/  146]
train() client id: f_00005-12-3 loss: 0.865146  [  128/  146]
train() client id: f_00006-0-0 loss: 0.639658  [   32/   54]
train() client id: f_00006-1-0 loss: 0.563562  [   32/   54]
train() client id: f_00006-2-0 loss: 0.579650  [   32/   54]
train() client id: f_00006-3-0 loss: 0.646107  [   32/   54]
train() client id: f_00006-4-0 loss: 0.611040  [   32/   54]
train() client id: f_00006-5-0 loss: 0.613660  [   32/   54]
train() client id: f_00006-6-0 loss: 0.632200  [   32/   54]
train() client id: f_00006-7-0 loss: 0.563135  [   32/   54]
train() client id: f_00006-8-0 loss: 0.613068  [   32/   54]
train() client id: f_00006-9-0 loss: 0.603976  [   32/   54]
train() client id: f_00006-10-0 loss: 0.608515  [   32/   54]
train() client id: f_00006-11-0 loss: 0.594496  [   32/   54]
train() client id: f_00006-12-0 loss: 0.595996  [   32/   54]
train() client id: f_00007-0-0 loss: 0.659917  [   32/  179]
train() client id: f_00007-0-1 loss: 0.687501  [   64/  179]
train() client id: f_00007-0-2 loss: 0.634699  [   96/  179]
train() client id: f_00007-0-3 loss: 0.773024  [  128/  179]
train() client id: f_00007-0-4 loss: 0.527286  [  160/  179]
train() client id: f_00007-1-0 loss: 0.616087  [   32/  179]
train() client id: f_00007-1-1 loss: 0.583442  [   64/  179]
train() client id: f_00007-1-2 loss: 0.575984  [   96/  179]
train() client id: f_00007-1-3 loss: 0.832738  [  128/  179]
train() client id: f_00007-1-4 loss: 0.751826  [  160/  179]
train() client id: f_00007-2-0 loss: 0.569723  [   32/  179]
train() client id: f_00007-2-1 loss: 0.660343  [   64/  179]
train() client id: f_00007-2-2 loss: 0.806958  [   96/  179]
train() client id: f_00007-2-3 loss: 0.591869  [  128/  179]
train() client id: f_00007-2-4 loss: 0.659081  [  160/  179]
train() client id: f_00007-3-0 loss: 0.643752  [   32/  179]
train() client id: f_00007-3-1 loss: 0.761221  [   64/  179]
train() client id: f_00007-3-2 loss: 0.514263  [   96/  179]
train() client id: f_00007-3-3 loss: 0.748471  [  128/  179]
train() client id: f_00007-3-4 loss: 0.508523  [  160/  179]
train() client id: f_00007-4-0 loss: 0.644087  [   32/  179]
train() client id: f_00007-4-1 loss: 0.807998  [   64/  179]
train() client id: f_00007-4-2 loss: 0.501995  [   96/  179]
train() client id: f_00007-4-3 loss: 0.584342  [  128/  179]
train() client id: f_00007-4-4 loss: 0.683347  [  160/  179]
train() client id: f_00007-5-0 loss: 0.535754  [   32/  179]
train() client id: f_00007-5-1 loss: 0.550615  [   64/  179]
train() client id: f_00007-5-2 loss: 0.497985  [   96/  179]
train() client id: f_00007-5-3 loss: 0.812465  [  128/  179]
train() client id: f_00007-5-4 loss: 0.722456  [  160/  179]
train() client id: f_00007-6-0 loss: 0.614634  [   32/  179]
train() client id: f_00007-6-1 loss: 0.692586  [   64/  179]
train() client id: f_00007-6-2 loss: 0.498175  [   96/  179]
train() client id: f_00007-6-3 loss: 0.638743  [  128/  179]
train() client id: f_00007-6-4 loss: 0.668178  [  160/  179]
train() client id: f_00007-7-0 loss: 0.474062  [   32/  179]
train() client id: f_00007-7-1 loss: 0.835521  [   64/  179]
train() client id: f_00007-7-2 loss: 0.589284  [   96/  179]
train() client id: f_00007-7-3 loss: 0.493004  [  128/  179]
train() client id: f_00007-7-4 loss: 0.627576  [  160/  179]
train() client id: f_00007-8-0 loss: 0.556662  [   32/  179]
train() client id: f_00007-8-1 loss: 0.551621  [   64/  179]
train() client id: f_00007-8-2 loss: 0.519967  [   96/  179]
train() client id: f_00007-8-3 loss: 0.762945  [  128/  179]
train() client id: f_00007-8-4 loss: 0.693481  [  160/  179]
train() client id: f_00007-9-0 loss: 0.514721  [   32/  179]
train() client id: f_00007-9-1 loss: 0.565671  [   64/  179]
train() client id: f_00007-9-2 loss: 0.817696  [   96/  179]
train() client id: f_00007-9-3 loss: 0.490306  [  128/  179]
train() client id: f_00007-9-4 loss: 0.611365  [  160/  179]
train() client id: f_00007-10-0 loss: 0.502060  [   32/  179]
train() client id: f_00007-10-1 loss: 0.753534  [   64/  179]
train() client id: f_00007-10-2 loss: 0.670886  [   96/  179]
train() client id: f_00007-10-3 loss: 0.516684  [  128/  179]
train() client id: f_00007-10-4 loss: 0.557364  [  160/  179]
train() client id: f_00007-11-0 loss: 0.585814  [   32/  179]
train() client id: f_00007-11-1 loss: 0.474102  [   64/  179]
train() client id: f_00007-11-2 loss: 0.861994  [   96/  179]
train() client id: f_00007-11-3 loss: 0.477223  [  128/  179]
train() client id: f_00007-11-4 loss: 0.746777  [  160/  179]
train() client id: f_00007-12-0 loss: 0.555948  [   32/  179]
train() client id: f_00007-12-1 loss: 0.720733  [   64/  179]
train() client id: f_00007-12-2 loss: 0.700191  [   96/  179]
train() client id: f_00007-12-3 loss: 0.582147  [  128/  179]
train() client id: f_00007-12-4 loss: 0.614286  [  160/  179]
train() client id: f_00008-0-0 loss: 0.791518  [   32/  130]
train() client id: f_00008-0-1 loss: 0.801649  [   64/  130]
train() client id: f_00008-0-2 loss: 0.747218  [   96/  130]
train() client id: f_00008-0-3 loss: 0.839826  [  128/  130]
train() client id: f_00008-1-0 loss: 0.935151  [   32/  130]
train() client id: f_00008-1-1 loss: 0.744462  [   64/  130]
train() client id: f_00008-1-2 loss: 0.755424  [   96/  130]
train() client id: f_00008-1-3 loss: 0.783543  [  128/  130]
train() client id: f_00008-2-0 loss: 0.740944  [   32/  130]
train() client id: f_00008-2-1 loss: 0.813232  [   64/  130]
train() client id: f_00008-2-2 loss: 0.813071  [   96/  130]
train() client id: f_00008-2-3 loss: 0.839438  [  128/  130]
train() client id: f_00008-3-0 loss: 0.800896  [   32/  130]
train() client id: f_00008-3-1 loss: 0.871059  [   64/  130]
train() client id: f_00008-3-2 loss: 0.754286  [   96/  130]
train() client id: f_00008-3-3 loss: 0.776856  [  128/  130]
train() client id: f_00008-4-0 loss: 0.757330  [   32/  130]
train() client id: f_00008-4-1 loss: 0.854142  [   64/  130]
train() client id: f_00008-4-2 loss: 0.806696  [   96/  130]
train() client id: f_00008-4-3 loss: 0.788164  [  128/  130]
train() client id: f_00008-5-0 loss: 0.726931  [   32/  130]
train() client id: f_00008-5-1 loss: 0.690472  [   64/  130]
train() client id: f_00008-5-2 loss: 0.976019  [   96/  130]
train() client id: f_00008-5-3 loss: 0.777485  [  128/  130]
train() client id: f_00008-6-0 loss: 0.814773  [   32/  130]
train() client id: f_00008-6-1 loss: 0.887944  [   64/  130]
train() client id: f_00008-6-2 loss: 0.771502  [   96/  130]
train() client id: f_00008-6-3 loss: 0.712557  [  128/  130]
train() client id: f_00008-7-0 loss: 0.765079  [   32/  130]
train() client id: f_00008-7-1 loss: 0.757182  [   64/  130]
train() client id: f_00008-7-2 loss: 0.886187  [   96/  130]
train() client id: f_00008-7-3 loss: 0.746352  [  128/  130]
train() client id: f_00008-8-0 loss: 0.893975  [   32/  130]
train() client id: f_00008-8-1 loss: 0.823189  [   64/  130]
train() client id: f_00008-8-2 loss: 0.792819  [   96/  130]
train() client id: f_00008-8-3 loss: 0.670705  [  128/  130]
train() client id: f_00008-9-0 loss: 0.883554  [   32/  130]
train() client id: f_00008-9-1 loss: 0.749571  [   64/  130]
train() client id: f_00008-9-2 loss: 0.792844  [   96/  130]
train() client id: f_00008-9-3 loss: 0.726193  [  128/  130]
train() client id: f_00008-10-0 loss: 0.847264  [   32/  130]
train() client id: f_00008-10-1 loss: 0.691416  [   64/  130]
train() client id: f_00008-10-2 loss: 0.714689  [   96/  130]
train() client id: f_00008-10-3 loss: 0.932951  [  128/  130]
train() client id: f_00008-11-0 loss: 0.716936  [   32/  130]
train() client id: f_00008-11-1 loss: 0.870399  [   64/  130]
train() client id: f_00008-11-2 loss: 0.862096  [   96/  130]
train() client id: f_00008-11-3 loss: 0.726019  [  128/  130]
train() client id: f_00008-12-0 loss: 0.880541  [   32/  130]
train() client id: f_00008-12-1 loss: 0.769002  [   64/  130]
train() client id: f_00008-12-2 loss: 0.660254  [   96/  130]
train() client id: f_00008-12-3 loss: 0.844105  [  128/  130]
train() client id: f_00009-0-0 loss: 1.224995  [   32/  118]
train() client id: f_00009-0-1 loss: 1.249469  [   64/  118]
train() client id: f_00009-0-2 loss: 1.139075  [   96/  118]
train() client id: f_00009-1-0 loss: 1.190988  [   32/  118]
train() client id: f_00009-1-1 loss: 1.214338  [   64/  118]
train() client id: f_00009-1-2 loss: 1.117299  [   96/  118]
train() client id: f_00009-2-0 loss: 1.132871  [   32/  118]
train() client id: f_00009-2-1 loss: 0.950721  [   64/  118]
train() client id: f_00009-2-2 loss: 1.221197  [   96/  118]
train() client id: f_00009-3-0 loss: 1.111338  [   32/  118]
train() client id: f_00009-3-1 loss: 1.053229  [   64/  118]
train() client id: f_00009-3-2 loss: 1.040994  [   96/  118]
train() client id: f_00009-4-0 loss: 1.041647  [   32/  118]
train() client id: f_00009-4-1 loss: 1.176958  [   64/  118]
train() client id: f_00009-4-2 loss: 0.985899  [   96/  118]
train() client id: f_00009-5-0 loss: 0.995847  [   32/  118]
train() client id: f_00009-5-1 loss: 1.011072  [   64/  118]
train() client id: f_00009-5-2 loss: 1.026230  [   96/  118]
train() client id: f_00009-6-0 loss: 1.041796  [   32/  118]
train() client id: f_00009-6-1 loss: 0.946146  [   64/  118]
train() client id: f_00009-6-2 loss: 1.031943  [   96/  118]
train() client id: f_00009-7-0 loss: 1.050496  [   32/  118]
train() client id: f_00009-7-1 loss: 0.970921  [   64/  118]
train() client id: f_00009-7-2 loss: 0.955712  [   96/  118]
train() client id: f_00009-8-0 loss: 1.006207  [   32/  118]
train() client id: f_00009-8-1 loss: 0.891354  [   64/  118]
train() client id: f_00009-8-2 loss: 0.931414  [   96/  118]
train() client id: f_00009-9-0 loss: 0.913639  [   32/  118]
train() client id: f_00009-9-1 loss: 1.038156  [   64/  118]
train() client id: f_00009-9-2 loss: 0.872043  [   96/  118]
train() client id: f_00009-10-0 loss: 0.896258  [   32/  118]
train() client id: f_00009-10-1 loss: 0.977241  [   64/  118]
train() client id: f_00009-10-2 loss: 0.957991  [   96/  118]
train() client id: f_00009-11-0 loss: 1.033315  [   32/  118]
train() client id: f_00009-11-1 loss: 0.869604  [   64/  118]
train() client id: f_00009-11-2 loss: 0.866944  [   96/  118]
train() client id: f_00009-12-0 loss: 1.006623  [   32/  118]
train() client id: f_00009-12-1 loss: 0.929648  [   64/  118]
train() client id: f_00009-12-2 loss: 0.851839  [   96/  118]
At round 13 accuracy: 0.6339522546419099
At round 13 training accuracy: 0.5848423876592891
At round 13 training loss: 0.8506021282242737
gradient difference: 0.3899441659450531
train() client id: f_00000-0-0 loss: 1.392240  [   32/  126]
train() client id: f_00000-0-1 loss: 1.335411  [   64/  126]
train() client id: f_00000-0-2 loss: 1.158381  [   96/  126]
train() client id: f_00000-1-0 loss: 1.292079  [   32/  126]
train() client id: f_00000-1-1 loss: 1.337629  [   64/  126]
train() client id: f_00000-1-2 loss: 1.042993  [   96/  126]
train() client id: f_00000-2-0 loss: 1.177069  [   32/  126]
train() client id: f_00000-2-1 loss: 1.064610  [   64/  126]
train() client id: f_00000-2-2 loss: 1.139371  [   96/  126]
train() client id: f_00000-3-0 loss: 1.004256  [   32/  126]
train() client id: f_00000-3-1 loss: 1.023831  [   64/  126]
train() client id: f_00000-3-2 loss: 1.133420  [   96/  126]
train() client id: f_00000-4-0 loss: 0.984285  [   32/  126]
train() client id: f_00000-4-1 loss: 1.058889  [   64/  126]
train() client id: f_00000-4-2 loss: 0.996132  [   96/  126]
train() client id: f_00000-5-0 loss: 1.065990  [   32/  126]
train() client id: f_00000-5-1 loss: 0.873317  [   64/  126]
train() client id: f_00000-5-2 loss: 1.031688  [   96/  126]
train() client id: f_00000-6-0 loss: 0.941002  [   32/  126]
train() client id: f_00000-6-1 loss: 0.909031  [   64/  126]
train() client id: f_00000-6-2 loss: 0.950243  [   96/  126]
train() client id: f_00000-7-0 loss: 0.932111  [   32/  126]
train() client id: f_00000-7-1 loss: 0.969074  [   64/  126]
train() client id: f_00000-7-2 loss: 0.837168  [   96/  126]
train() client id: f_00000-8-0 loss: 0.873401  [   32/  126]
train() client id: f_00000-8-1 loss: 0.876762  [   64/  126]
train() client id: f_00000-8-2 loss: 0.935900  [   96/  126]
train() client id: f_00000-9-0 loss: 0.928269  [   32/  126]
train() client id: f_00000-9-1 loss: 0.858608  [   64/  126]
train() client id: f_00000-9-2 loss: 0.962659  [   96/  126]
train() client id: f_00000-10-0 loss: 0.871162  [   32/  126]
train() client id: f_00000-10-1 loss: 0.892245  [   64/  126]
train() client id: f_00000-10-2 loss: 0.873322  [   96/  126]
train() client id: f_00000-11-0 loss: 0.938569  [   32/  126]
train() client id: f_00000-11-1 loss: 0.799253  [   64/  126]
train() client id: f_00000-11-2 loss: 0.768518  [   96/  126]
train() client id: f_00000-12-0 loss: 0.886738  [   32/  126]
train() client id: f_00000-12-1 loss: 0.904706  [   64/  126]
train() client id: f_00000-12-2 loss: 0.904316  [   96/  126]
train() client id: f_00001-0-0 loss: 0.516915  [   32/  265]
train() client id: f_00001-0-1 loss: 0.358237  [   64/  265]
train() client id: f_00001-0-2 loss: 0.425579  [   96/  265]
train() client id: f_00001-0-3 loss: 0.471671  [  128/  265]
train() client id: f_00001-0-4 loss: 0.507113  [  160/  265]
train() client id: f_00001-0-5 loss: 0.432722  [  192/  265]
train() client id: f_00001-0-6 loss: 0.447635  [  224/  265]
train() client id: f_00001-0-7 loss: 0.413036  [  256/  265]
train() client id: f_00001-1-0 loss: 0.413696  [   32/  265]
train() client id: f_00001-1-1 loss: 0.369569  [   64/  265]
train() client id: f_00001-1-2 loss: 0.387255  [   96/  265]
train() client id: f_00001-1-3 loss: 0.398509  [  128/  265]
train() client id: f_00001-1-4 loss: 0.461459  [  160/  265]
train() client id: f_00001-1-5 loss: 0.467600  [  192/  265]
train() client id: f_00001-1-6 loss: 0.389861  [  224/  265]
train() client id: f_00001-1-7 loss: 0.419016  [  256/  265]
train() client id: f_00001-2-0 loss: 0.412152  [   32/  265]
train() client id: f_00001-2-1 loss: 0.410673  [   64/  265]
train() client id: f_00001-2-2 loss: 0.406033  [   96/  265]
train() client id: f_00001-2-3 loss: 0.373259  [  128/  265]
train() client id: f_00001-2-4 loss: 0.438660  [  160/  265]
train() client id: f_00001-2-5 loss: 0.419722  [  192/  265]
train() client id: f_00001-2-6 loss: 0.492701  [  224/  265]
train() client id: f_00001-2-7 loss: 0.406791  [  256/  265]
train() client id: f_00001-3-0 loss: 0.398559  [   32/  265]
train() client id: f_00001-3-1 loss: 0.448350  [   64/  265]
train() client id: f_00001-3-2 loss: 0.343053  [   96/  265]
train() client id: f_00001-3-3 loss: 0.446091  [  128/  265]
train() client id: f_00001-3-4 loss: 0.383598  [  160/  265]
train() client id: f_00001-3-5 loss: 0.349224  [  192/  265]
train() client id: f_00001-3-6 loss: 0.459466  [  224/  265]
train() client id: f_00001-3-7 loss: 0.418548  [  256/  265]
train() client id: f_00001-4-0 loss: 0.341430  [   32/  265]
train() client id: f_00001-4-1 loss: 0.342211  [   64/  265]
train() client id: f_00001-4-2 loss: 0.412241  [   96/  265]
train() client id: f_00001-4-3 loss: 0.517717  [  128/  265]
train() client id: f_00001-4-4 loss: 0.487705  [  160/  265]
train() client id: f_00001-4-5 loss: 0.459349  [  192/  265]
train() client id: f_00001-4-6 loss: 0.347207  [  224/  265]
train() client id: f_00001-4-7 loss: 0.326734  [  256/  265]
train() client id: f_00001-5-0 loss: 0.580640  [   32/  265]
train() client id: f_00001-5-1 loss: 0.334772  [   64/  265]
train() client id: f_00001-5-2 loss: 0.446774  [   96/  265]
train() client id: f_00001-5-3 loss: 0.314627  [  128/  265]
train() client id: f_00001-5-4 loss: 0.313710  [  160/  265]
train() client id: f_00001-5-5 loss: 0.376971  [  192/  265]
train() client id: f_00001-5-6 loss: 0.402611  [  224/  265]
train() client id: f_00001-5-7 loss: 0.354737  [  256/  265]
train() client id: f_00001-6-0 loss: 0.306594  [   32/  265]
train() client id: f_00001-6-1 loss: 0.335760  [   64/  265]
train() client id: f_00001-6-2 loss: 0.389897  [   96/  265]
train() client id: f_00001-6-3 loss: 0.364987  [  128/  265]
train() client id: f_00001-6-4 loss: 0.466253  [  160/  265]
train() client id: f_00001-6-5 loss: 0.312449  [  192/  265]
train() client id: f_00001-6-6 loss: 0.497036  [  224/  265]
train() client id: f_00001-6-7 loss: 0.417362  [  256/  265]
train() client id: f_00001-7-0 loss: 0.348738  [   32/  265]
train() client id: f_00001-7-1 loss: 0.455865  [   64/  265]
train() client id: f_00001-7-2 loss: 0.322595  [   96/  265]
train() client id: f_00001-7-3 loss: 0.411958  [  128/  265]
train() client id: f_00001-7-4 loss: 0.341452  [  160/  265]
train() client id: f_00001-7-5 loss: 0.377647  [  192/  265]
train() client id: f_00001-7-6 loss: 0.475212  [  224/  265]
train() client id: f_00001-7-7 loss: 0.311586  [  256/  265]
train() client id: f_00001-8-0 loss: 0.327377  [   32/  265]
train() client id: f_00001-8-1 loss: 0.310868  [   64/  265]
train() client id: f_00001-8-2 loss: 0.442817  [   96/  265]
train() client id: f_00001-8-3 loss: 0.472156  [  128/  265]
train() client id: f_00001-8-4 loss: 0.418265  [  160/  265]
train() client id: f_00001-8-5 loss: 0.349505  [  192/  265]
train() client id: f_00001-8-6 loss: 0.350060  [  224/  265]
train() client id: f_00001-8-7 loss: 0.362148  [  256/  265]
train() client id: f_00001-9-0 loss: 0.433928  [   32/  265]
train() client id: f_00001-9-1 loss: 0.447423  [   64/  265]
train() client id: f_00001-9-2 loss: 0.347931  [   96/  265]
train() client id: f_00001-9-3 loss: 0.323464  [  128/  265]
train() client id: f_00001-9-4 loss: 0.315442  [  160/  265]
train() client id: f_00001-9-5 loss: 0.387468  [  192/  265]
train() client id: f_00001-9-6 loss: 0.418303  [  224/  265]
train() client id: f_00001-9-7 loss: 0.401370  [  256/  265]
train() client id: f_00001-10-0 loss: 0.399962  [   32/  265]
train() client id: f_00001-10-1 loss: 0.370209  [   64/  265]
train() client id: f_00001-10-2 loss: 0.380722  [   96/  265]
train() client id: f_00001-10-3 loss: 0.318964  [  128/  265]
train() client id: f_00001-10-4 loss: 0.378560  [  160/  265]
train() client id: f_00001-10-5 loss: 0.343952  [  192/  265]
train() client id: f_00001-10-6 loss: 0.405418  [  224/  265]
train() client id: f_00001-10-7 loss: 0.345959  [  256/  265]
train() client id: f_00001-11-0 loss: 0.500512  [   32/  265]
train() client id: f_00001-11-1 loss: 0.370205  [   64/  265]
train() client id: f_00001-11-2 loss: 0.288634  [   96/  265]
train() client id: f_00001-11-3 loss: 0.397100  [  128/  265]
train() client id: f_00001-11-4 loss: 0.324935  [  160/  265]
train() client id: f_00001-11-5 loss: 0.434740  [  192/  265]
train() client id: f_00001-11-6 loss: 0.386422  [  224/  265]
train() client id: f_00001-11-7 loss: 0.367918  [  256/  265]
train() client id: f_00001-12-0 loss: 0.361957  [   32/  265]
train() client id: f_00001-12-1 loss: 0.504190  [   64/  265]
train() client id: f_00001-12-2 loss: 0.359047  [   96/  265]
train() client id: f_00001-12-3 loss: 0.384137  [  128/  265]
train() client id: f_00001-12-4 loss: 0.436923  [  160/  265]
train() client id: f_00001-12-5 loss: 0.297129  [  192/  265]
train() client id: f_00001-12-6 loss: 0.362748  [  224/  265]
train() client id: f_00001-12-7 loss: 0.336730  [  256/  265]
train() client id: f_00002-0-0 loss: 1.415994  [   32/  124]
train() client id: f_00002-0-1 loss: 1.110963  [   64/  124]
train() client id: f_00002-0-2 loss: 1.364287  [   96/  124]
train() client id: f_00002-1-0 loss: 1.374875  [   32/  124]
train() client id: f_00002-1-1 loss: 1.236400  [   64/  124]
train() client id: f_00002-1-2 loss: 1.209578  [   96/  124]
train() client id: f_00002-2-0 loss: 1.292239  [   32/  124]
train() client id: f_00002-2-1 loss: 1.249483  [   64/  124]
train() client id: f_00002-2-2 loss: 1.087181  [   96/  124]
train() client id: f_00002-3-0 loss: 1.207554  [   32/  124]
train() client id: f_00002-3-1 loss: 1.072731  [   64/  124]
train() client id: f_00002-3-2 loss: 1.175140  [   96/  124]
train() client id: f_00002-4-0 loss: 1.097340  [   32/  124]
train() client id: f_00002-4-1 loss: 1.171713  [   64/  124]
train() client id: f_00002-4-2 loss: 1.084260  [   96/  124]
train() client id: f_00002-5-0 loss: 1.005996  [   32/  124]
train() client id: f_00002-5-1 loss: 1.162820  [   64/  124]
train() client id: f_00002-5-2 loss: 1.137098  [   96/  124]
train() client id: f_00002-6-0 loss: 1.210474  [   32/  124]
train() client id: f_00002-6-1 loss: 1.098115  [   64/  124]
train() client id: f_00002-6-2 loss: 1.069173  [   96/  124]
train() client id: f_00002-7-0 loss: 1.057865  [   32/  124]
train() client id: f_00002-7-1 loss: 1.080643  [   64/  124]
train() client id: f_00002-7-2 loss: 1.108653  [   96/  124]
train() client id: f_00002-8-0 loss: 1.081045  [   32/  124]
train() client id: f_00002-8-1 loss: 1.245731  [   64/  124]
train() client id: f_00002-8-2 loss: 0.942543  [   96/  124]
train() client id: f_00002-9-0 loss: 0.979101  [   32/  124]
train() client id: f_00002-9-1 loss: 1.183988  [   64/  124]
train() client id: f_00002-9-2 loss: 0.979074  [   96/  124]
train() client id: f_00002-10-0 loss: 0.938593  [   32/  124]
train() client id: f_00002-10-1 loss: 1.011080  [   64/  124]
train() client id: f_00002-10-2 loss: 0.986365  [   96/  124]
train() client id: f_00002-11-0 loss: 1.023815  [   32/  124]
train() client id: f_00002-11-1 loss: 1.011550  [   64/  124]
train() client id: f_00002-11-2 loss: 1.126365  [   96/  124]
train() client id: f_00002-12-0 loss: 0.991290  [   32/  124]
train() client id: f_00002-12-1 loss: 0.921601  [   64/  124]
train() client id: f_00002-12-2 loss: 1.110524  [   96/  124]
train() client id: f_00003-0-0 loss: 0.852252  [   32/   43]
train() client id: f_00003-1-0 loss: 1.075109  [   32/   43]
train() client id: f_00003-2-0 loss: 0.893364  [   32/   43]
train() client id: f_00003-3-0 loss: 0.909997  [   32/   43]
train() client id: f_00003-4-0 loss: 0.964404  [   32/   43]
train() client id: f_00003-5-0 loss: 0.843293  [   32/   43]
train() client id: f_00003-6-0 loss: 0.870262  [   32/   43]
train() client id: f_00003-7-0 loss: 0.965767  [   32/   43]
train() client id: f_00003-8-0 loss: 0.896437  [   32/   43]
train() client id: f_00003-9-0 loss: 0.932585  [   32/   43]
train() client id: f_00003-10-0 loss: 0.972115  [   32/   43]
train() client id: f_00003-11-0 loss: 0.814746  [   32/   43]
train() client id: f_00003-12-0 loss: 0.876172  [   32/   43]
train() client id: f_00004-0-0 loss: 0.795544  [   32/  306]
train() client id: f_00004-0-1 loss: 0.839808  [   64/  306]
train() client id: f_00004-0-2 loss: 1.005317  [   96/  306]
train() client id: f_00004-0-3 loss: 0.889521  [  128/  306]
train() client id: f_00004-0-4 loss: 0.865853  [  160/  306]
train() client id: f_00004-0-5 loss: 0.825649  [  192/  306]
train() client id: f_00004-0-6 loss: 0.769757  [  224/  306]
train() client id: f_00004-0-7 loss: 0.980755  [  256/  306]
train() client id: f_00004-0-8 loss: 1.035021  [  288/  306]
train() client id: f_00004-1-0 loss: 0.916247  [   32/  306]
train() client id: f_00004-1-1 loss: 1.021994  [   64/  306]
train() client id: f_00004-1-2 loss: 0.818196  [   96/  306]
train() client id: f_00004-1-3 loss: 0.733716  [  128/  306]
train() client id: f_00004-1-4 loss: 0.926792  [  160/  306]
train() client id: f_00004-1-5 loss: 0.941268  [  192/  306]
train() client id: f_00004-1-6 loss: 0.934178  [  224/  306]
train() client id: f_00004-1-7 loss: 0.851107  [  256/  306]
train() client id: f_00004-1-8 loss: 0.839786  [  288/  306]
train() client id: f_00004-2-0 loss: 0.954823  [   32/  306]
train() client id: f_00004-2-1 loss: 0.861732  [   64/  306]
train() client id: f_00004-2-2 loss: 0.917107  [   96/  306]
train() client id: f_00004-2-3 loss: 0.881129  [  128/  306]
train() client id: f_00004-2-4 loss: 0.910943  [  160/  306]
train() client id: f_00004-2-5 loss: 0.853812  [  192/  306]
train() client id: f_00004-2-6 loss: 0.986353  [  224/  306]
train() client id: f_00004-2-7 loss: 0.804951  [  256/  306]
train() client id: f_00004-2-8 loss: 0.871509  [  288/  306]
train() client id: f_00004-3-0 loss: 0.887700  [   32/  306]
train() client id: f_00004-3-1 loss: 0.937957  [   64/  306]
train() client id: f_00004-3-2 loss: 0.910140  [   96/  306]
train() client id: f_00004-3-3 loss: 0.866859  [  128/  306]
train() client id: f_00004-3-4 loss: 0.828806  [  160/  306]
train() client id: f_00004-3-5 loss: 0.815375  [  192/  306]
train() client id: f_00004-3-6 loss: 0.984321  [  224/  306]
train() client id: f_00004-3-7 loss: 0.851523  [  256/  306]
train() client id: f_00004-3-8 loss: 0.869394  [  288/  306]
train() client id: f_00004-4-0 loss: 0.927853  [   32/  306]
train() client id: f_00004-4-1 loss: 0.836808  [   64/  306]
train() client id: f_00004-4-2 loss: 0.886063  [   96/  306]
train() client id: f_00004-4-3 loss: 0.894328  [  128/  306]
train() client id: f_00004-4-4 loss: 0.864181  [  160/  306]
train() client id: f_00004-4-5 loss: 0.827897  [  192/  306]
train() client id: f_00004-4-6 loss: 0.935956  [  224/  306]
train() client id: f_00004-4-7 loss: 0.882246  [  256/  306]
train() client id: f_00004-4-8 loss: 0.856063  [  288/  306]
train() client id: f_00004-5-0 loss: 1.000015  [   32/  306]
train() client id: f_00004-5-1 loss: 0.735019  [   64/  306]
train() client id: f_00004-5-2 loss: 0.935523  [   96/  306]
train() client id: f_00004-5-3 loss: 0.804445  [  128/  306]
train() client id: f_00004-5-4 loss: 1.098664  [  160/  306]
train() client id: f_00004-5-5 loss: 0.833806  [  192/  306]
train() client id: f_00004-5-6 loss: 0.840765  [  224/  306]
train() client id: f_00004-5-7 loss: 0.743744  [  256/  306]
train() client id: f_00004-5-8 loss: 0.909149  [  288/  306]
train() client id: f_00004-6-0 loss: 0.969073  [   32/  306]
train() client id: f_00004-6-1 loss: 0.771574  [   64/  306]
train() client id: f_00004-6-2 loss: 0.819235  [   96/  306]
train() client id: f_00004-6-3 loss: 0.894448  [  128/  306]
train() client id: f_00004-6-4 loss: 0.799514  [  160/  306]
train() client id: f_00004-6-5 loss: 0.873290  [  192/  306]
train() client id: f_00004-6-6 loss: 0.943844  [  224/  306]
train() client id: f_00004-6-7 loss: 0.855092  [  256/  306]
train() client id: f_00004-6-8 loss: 0.971814  [  288/  306]
train() client id: f_00004-7-0 loss: 0.963673  [   32/  306]
train() client id: f_00004-7-1 loss: 0.785961  [   64/  306]
train() client id: f_00004-7-2 loss: 0.930073  [   96/  306]
train() client id: f_00004-7-3 loss: 0.893137  [  128/  306]
train() client id: f_00004-7-4 loss: 0.904925  [  160/  306]
train() client id: f_00004-7-5 loss: 0.912663  [  192/  306]
train() client id: f_00004-7-6 loss: 0.918633  [  224/  306]
train() client id: f_00004-7-7 loss: 0.805536  [  256/  306]
train() client id: f_00004-7-8 loss: 0.825176  [  288/  306]
train() client id: f_00004-8-0 loss: 0.945591  [   32/  306]
train() client id: f_00004-8-1 loss: 0.919647  [   64/  306]
train() client id: f_00004-8-2 loss: 0.763053  [   96/  306]
train() client id: f_00004-8-3 loss: 1.020177  [  128/  306]
train() client id: f_00004-8-4 loss: 0.944470  [  160/  306]
train() client id: f_00004-8-5 loss: 0.852648  [  192/  306]
train() client id: f_00004-8-6 loss: 0.787466  [  224/  306]
train() client id: f_00004-8-7 loss: 0.783146  [  256/  306]
train() client id: f_00004-8-8 loss: 0.836963  [  288/  306]
train() client id: f_00004-9-0 loss: 0.837920  [   32/  306]
train() client id: f_00004-9-1 loss: 0.887714  [   64/  306]
train() client id: f_00004-9-2 loss: 0.914605  [   96/  306]
train() client id: f_00004-9-3 loss: 0.832270  [  128/  306]
train() client id: f_00004-9-4 loss: 0.749380  [  160/  306]
train() client id: f_00004-9-5 loss: 0.922803  [  192/  306]
train() client id: f_00004-9-6 loss: 0.951866  [  224/  306]
train() client id: f_00004-9-7 loss: 0.883621  [  256/  306]
train() client id: f_00004-9-8 loss: 0.838154  [  288/  306]
train() client id: f_00004-10-0 loss: 0.894298  [   32/  306]
train() client id: f_00004-10-1 loss: 0.849208  [   64/  306]
train() client id: f_00004-10-2 loss: 0.930171  [   96/  306]
train() client id: f_00004-10-3 loss: 0.807166  [  128/  306]
train() client id: f_00004-10-4 loss: 0.915437  [  160/  306]
train() client id: f_00004-10-5 loss: 0.864297  [  192/  306]
train() client id: f_00004-10-6 loss: 0.955350  [  224/  306]
train() client id: f_00004-10-7 loss: 0.809715  [  256/  306]
train() client id: f_00004-10-8 loss: 0.789642  [  288/  306]
train() client id: f_00004-11-0 loss: 0.954467  [   32/  306]
train() client id: f_00004-11-1 loss: 0.854741  [   64/  306]
train() client id: f_00004-11-2 loss: 0.867687  [   96/  306]
train() client id: f_00004-11-3 loss: 0.849327  [  128/  306]
train() client id: f_00004-11-4 loss: 0.974321  [  160/  306]
train() client id: f_00004-11-5 loss: 0.835008  [  192/  306]
train() client id: f_00004-11-6 loss: 0.944285  [  224/  306]
train() client id: f_00004-11-7 loss: 0.765564  [  256/  306]
train() client id: f_00004-11-8 loss: 0.798067  [  288/  306]
train() client id: f_00004-12-0 loss: 0.865945  [   32/  306]
train() client id: f_00004-12-1 loss: 0.902421  [   64/  306]
train() client id: f_00004-12-2 loss: 0.796636  [   96/  306]
train() client id: f_00004-12-3 loss: 0.905917  [  128/  306]
train() client id: f_00004-12-4 loss: 0.814501  [  160/  306]
train() client id: f_00004-12-5 loss: 0.845589  [  192/  306]
train() client id: f_00004-12-6 loss: 0.890886  [  224/  306]
train() client id: f_00004-12-7 loss: 0.924485  [  256/  306]
train() client id: f_00004-12-8 loss: 0.936883  [  288/  306]
train() client id: f_00005-0-0 loss: 0.541536  [   32/  146]
train() client id: f_00005-0-1 loss: 0.767140  [   64/  146]
train() client id: f_00005-0-2 loss: 0.657694  [   96/  146]
train() client id: f_00005-0-3 loss: 0.818302  [  128/  146]
train() client id: f_00005-1-0 loss: 0.763744  [   32/  146]
train() client id: f_00005-1-1 loss: 0.596149  [   64/  146]
train() client id: f_00005-1-2 loss: 0.665870  [   96/  146]
train() client id: f_00005-1-3 loss: 0.798019  [  128/  146]
train() client id: f_00005-2-0 loss: 0.625443  [   32/  146]
train() client id: f_00005-2-1 loss: 0.743578  [   64/  146]
train() client id: f_00005-2-2 loss: 0.558107  [   96/  146]
train() client id: f_00005-2-3 loss: 0.690340  [  128/  146]
train() client id: f_00005-3-0 loss: 0.607028  [   32/  146]
train() client id: f_00005-3-1 loss: 0.609320  [   64/  146]
train() client id: f_00005-3-2 loss: 0.715940  [   96/  146]
train() client id: f_00005-3-3 loss: 0.807093  [  128/  146]
train() client id: f_00005-4-0 loss: 0.661419  [   32/  146]
train() client id: f_00005-4-1 loss: 0.662877  [   64/  146]
train() client id: f_00005-4-2 loss: 0.732068  [   96/  146]
train() client id: f_00005-4-3 loss: 0.671363  [  128/  146]
train() client id: f_00005-5-0 loss: 0.717619  [   32/  146]
train() client id: f_00005-5-1 loss: 0.628097  [   64/  146]
train() client id: f_00005-5-2 loss: 0.651920  [   96/  146]
train() client id: f_00005-5-3 loss: 0.763022  [  128/  146]
train() client id: f_00005-6-0 loss: 0.620672  [   32/  146]
train() client id: f_00005-6-1 loss: 0.606360  [   64/  146]
train() client id: f_00005-6-2 loss: 0.715547  [   96/  146]
train() client id: f_00005-6-3 loss: 0.769567  [  128/  146]
train() client id: f_00005-7-0 loss: 0.790260  [   32/  146]
train() client id: f_00005-7-1 loss: 0.653549  [   64/  146]
train() client id: f_00005-7-2 loss: 0.618552  [   96/  146]
train() client id: f_00005-7-3 loss: 0.492128  [  128/  146]
train() client id: f_00005-8-0 loss: 0.629475  [   32/  146]
train() client id: f_00005-8-1 loss: 0.799941  [   64/  146]
train() client id: f_00005-8-2 loss: 0.659776  [   96/  146]
train() client id: f_00005-8-3 loss: 0.749002  [  128/  146]
train() client id: f_00005-9-0 loss: 0.744846  [   32/  146]
train() client id: f_00005-9-1 loss: 0.583715  [   64/  146]
train() client id: f_00005-9-2 loss: 0.782804  [   96/  146]
train() client id: f_00005-9-3 loss: 0.581998  [  128/  146]
train() client id: f_00005-10-0 loss: 0.599853  [   32/  146]
train() client id: f_00005-10-1 loss: 0.673679  [   64/  146]
train() client id: f_00005-10-2 loss: 0.630252  [   96/  146]
train() client id: f_00005-10-3 loss: 0.821173  [  128/  146]
train() client id: f_00005-11-0 loss: 0.748552  [   32/  146]
train() client id: f_00005-11-1 loss: 0.656503  [   64/  146]
train() client id: f_00005-11-2 loss: 0.607909  [   96/  146]
train() client id: f_00005-11-3 loss: 0.594517  [  128/  146]
train() client id: f_00005-12-0 loss: 0.596595  [   32/  146]
train() client id: f_00005-12-1 loss: 0.608469  [   64/  146]
train() client id: f_00005-12-2 loss: 0.611828  [   96/  146]
train() client id: f_00005-12-3 loss: 0.976927  [  128/  146]
train() client id: f_00006-0-0 loss: 0.647035  [   32/   54]
train() client id: f_00006-1-0 loss: 0.618647  [   32/   54]
train() client id: f_00006-2-0 loss: 0.570242  [   32/   54]
train() client id: f_00006-3-0 loss: 0.616474  [   32/   54]
train() client id: f_00006-4-0 loss: 0.651622  [   32/   54]
train() client id: f_00006-5-0 loss: 0.650059  [   32/   54]
train() client id: f_00006-6-0 loss: 0.621761  [   32/   54]
train() client id: f_00006-7-0 loss: 0.663814  [   32/   54]
train() client id: f_00006-8-0 loss: 0.606037  [   32/   54]
train() client id: f_00006-9-0 loss: 0.650473  [   32/   54]
train() client id: f_00006-10-0 loss: 0.610048  [   32/   54]
train() client id: f_00006-11-0 loss: 0.582638  [   32/   54]
train() client id: f_00006-12-0 loss: 0.613663  [   32/   54]
train() client id: f_00007-0-0 loss: 0.763552  [   32/  179]
train() client id: f_00007-0-1 loss: 0.602536  [   64/  179]
train() client id: f_00007-0-2 loss: 0.669452  [   96/  179]
train() client id: f_00007-0-3 loss: 0.567992  [  128/  179]
train() client id: f_00007-0-4 loss: 0.687800  [  160/  179]
train() client id: f_00007-1-0 loss: 0.590595  [   32/  179]
train() client id: f_00007-1-1 loss: 0.647764  [   64/  179]
train() client id: f_00007-1-2 loss: 0.691955  [   96/  179]
train() client id: f_00007-1-3 loss: 0.602819  [  128/  179]
train() client id: f_00007-1-4 loss: 0.631509  [  160/  179]
train() client id: f_00007-2-0 loss: 0.559396  [   32/  179]
train() client id: f_00007-2-1 loss: 0.749438  [   64/  179]
train() client id: f_00007-2-2 loss: 0.609231  [   96/  179]
train() client id: f_00007-2-3 loss: 0.502596  [  128/  179]
train() client id: f_00007-2-4 loss: 0.692534  [  160/  179]
train() client id: f_00007-3-0 loss: 0.756279  [   32/  179]
train() client id: f_00007-3-1 loss: 0.667693  [   64/  179]
train() client id: f_00007-3-2 loss: 0.527441  [   96/  179]
train() client id: f_00007-3-3 loss: 0.615722  [  128/  179]
train() client id: f_00007-3-4 loss: 0.661602  [  160/  179]
train() client id: f_00007-4-0 loss: 0.626778  [   32/  179]
train() client id: f_00007-4-1 loss: 0.617643  [   64/  179]
train() client id: f_00007-4-2 loss: 0.587572  [   96/  179]
train() client id: f_00007-4-3 loss: 0.541591  [  128/  179]
train() client id: f_00007-4-4 loss: 0.613714  [  160/  179]
train() client id: f_00007-5-0 loss: 0.514620  [   32/  179]
train() client id: f_00007-5-1 loss: 0.756532  [   64/  179]
train() client id: f_00007-5-2 loss: 0.645067  [   96/  179]
train() client id: f_00007-5-3 loss: 0.551377  [  128/  179]
train() client id: f_00007-5-4 loss: 0.735192  [  160/  179]
train() client id: f_00007-6-0 loss: 0.833058  [   32/  179]
train() client id: f_00007-6-1 loss: 0.480659  [   64/  179]
train() client id: f_00007-6-2 loss: 0.582935  [   96/  179]
train() client id: f_00007-6-3 loss: 0.673198  [  128/  179]
train() client id: f_00007-6-4 loss: 0.521450  [  160/  179]
train() client id: f_00007-7-0 loss: 0.585404  [   32/  179]
train() client id: f_00007-7-1 loss: 0.502207  [   64/  179]
train() client id: f_00007-7-2 loss: 0.672464  [   96/  179]
train() client id: f_00007-7-3 loss: 0.622047  [  128/  179]
train() client id: f_00007-7-4 loss: 0.623045  [  160/  179]
train() client id: f_00007-8-0 loss: 0.756770  [   32/  179]
train() client id: f_00007-8-1 loss: 0.660941  [   64/  179]
train() client id: f_00007-8-2 loss: 0.578163  [   96/  179]
train() client id: f_00007-8-3 loss: 0.585590  [  128/  179]
train() client id: f_00007-8-4 loss: 0.650679  [  160/  179]
train() client id: f_00007-9-0 loss: 0.500594  [   32/  179]
train() client id: f_00007-9-1 loss: 0.926300  [   64/  179]
train() client id: f_00007-9-2 loss: 0.578004  [   96/  179]
train() client id: f_00007-9-3 loss: 0.508768  [  128/  179]
train() client id: f_00007-9-4 loss: 0.649780  [  160/  179]
train() client id: f_00007-10-0 loss: 0.755357  [   32/  179]
train() client id: f_00007-10-1 loss: 0.562049  [   64/  179]
train() client id: f_00007-10-2 loss: 0.499189  [   96/  179]
train() client id: f_00007-10-3 loss: 0.841669  [  128/  179]
train() client id: f_00007-10-4 loss: 0.482327  [  160/  179]
train() client id: f_00007-11-0 loss: 0.787605  [   32/  179]
train() client id: f_00007-11-1 loss: 0.679027  [   64/  179]
train() client id: f_00007-11-2 loss: 0.486647  [   96/  179]
train() client id: f_00007-11-3 loss: 0.526004  [  128/  179]
train() client id: f_00007-11-4 loss: 0.691030  [  160/  179]
train() client id: f_00007-12-0 loss: 0.895511  [   32/  179]
train() client id: f_00007-12-1 loss: 0.525557  [   64/  179]
train() client id: f_00007-12-2 loss: 0.661930  [   96/  179]
train() client id: f_00007-12-3 loss: 0.495766  [  128/  179]
train() client id: f_00007-12-4 loss: 0.680705  [  160/  179]
train() client id: f_00008-0-0 loss: 0.823353  [   32/  130]
train() client id: f_00008-0-1 loss: 0.675034  [   64/  130]
train() client id: f_00008-0-2 loss: 0.802678  [   96/  130]
train() client id: f_00008-0-3 loss: 0.802008  [  128/  130]
train() client id: f_00008-1-0 loss: 0.798202  [   32/  130]
train() client id: f_00008-1-1 loss: 0.843310  [   64/  130]
train() client id: f_00008-1-2 loss: 0.708089  [   96/  130]
train() client id: f_00008-1-3 loss: 0.746408  [  128/  130]
train() client id: f_00008-2-0 loss: 0.769365  [   32/  130]
train() client id: f_00008-2-1 loss: 0.711788  [   64/  130]
train() client id: f_00008-2-2 loss: 0.723727  [   96/  130]
train() client id: f_00008-2-3 loss: 0.888540  [  128/  130]
train() client id: f_00008-3-0 loss: 0.866909  [   32/  130]
train() client id: f_00008-3-1 loss: 0.769988  [   64/  130]
train() client id: f_00008-3-2 loss: 0.706738  [   96/  130]
train() client id: f_00008-3-3 loss: 0.720714  [  128/  130]
train() client id: f_00008-4-0 loss: 0.689499  [   32/  130]
train() client id: f_00008-4-1 loss: 0.879001  [   64/  130]
train() client id: f_00008-4-2 loss: 0.800452  [   96/  130]
train() client id: f_00008-4-3 loss: 0.728035  [  128/  130]
train() client id: f_00008-5-0 loss: 0.861185  [   32/  130]
train() client id: f_00008-5-1 loss: 0.743046  [   64/  130]
train() client id: f_00008-5-2 loss: 0.728052  [   96/  130]
train() client id: f_00008-5-3 loss: 0.757290  [  128/  130]
train() client id: f_00008-6-0 loss: 0.801684  [   32/  130]
train() client id: f_00008-6-1 loss: 0.775206  [   64/  130]
train() client id: f_00008-6-2 loss: 0.703753  [   96/  130]
train() client id: f_00008-6-3 loss: 0.808493  [  128/  130]
train() client id: f_00008-7-0 loss: 0.846185  [   32/  130]
train() client id: f_00008-7-1 loss: 0.727000  [   64/  130]
train() client id: f_00008-7-2 loss: 0.749423  [   96/  130]
train() client id: f_00008-7-3 loss: 0.715482  [  128/  130]
train() client id: f_00008-8-0 loss: 0.668557  [   32/  130]
train() client id: f_00008-8-1 loss: 0.837803  [   64/  130]
train() client id: f_00008-8-2 loss: 0.784046  [   96/  130]
train() client id: f_00008-8-3 loss: 0.807397  [  128/  130]
train() client id: f_00008-9-0 loss: 0.804839  [   32/  130]
train() client id: f_00008-9-1 loss: 0.804168  [   64/  130]
train() client id: f_00008-9-2 loss: 0.748884  [   96/  130]
train() client id: f_00008-9-3 loss: 0.736624  [  128/  130]
train() client id: f_00008-10-0 loss: 0.760893  [   32/  130]
train() client id: f_00008-10-1 loss: 0.735469  [   64/  130]
train() client id: f_00008-10-2 loss: 0.851110  [   96/  130]
train() client id: f_00008-10-3 loss: 0.742644  [  128/  130]
train() client id: f_00008-11-0 loss: 0.844663  [   32/  130]
train() client id: f_00008-11-1 loss: 0.821644  [   64/  130]
train() client id: f_00008-11-2 loss: 0.620418  [   96/  130]
train() client id: f_00008-11-3 loss: 0.741725  [  128/  130]
train() client id: f_00008-12-0 loss: 0.782372  [   32/  130]
train() client id: f_00008-12-1 loss: 0.795332  [   64/  130]
train() client id: f_00008-12-2 loss: 0.680376  [   96/  130]
train() client id: f_00008-12-3 loss: 0.792516  [  128/  130]
train() client id: f_00009-0-0 loss: 1.190682  [   32/  118]
train() client id: f_00009-0-1 loss: 1.262185  [   64/  118]
train() client id: f_00009-0-2 loss: 1.112685  [   96/  118]
train() client id: f_00009-1-0 loss: 1.269910  [   32/  118]
train() client id: f_00009-1-1 loss: 1.123658  [   64/  118]
train() client id: f_00009-1-2 loss: 1.112926  [   96/  118]
train() client id: f_00009-2-0 loss: 1.046609  [   32/  118]
train() client id: f_00009-2-1 loss: 1.164165  [   64/  118]
train() client id: f_00009-2-2 loss: 1.100292  [   96/  118]
train() client id: f_00009-3-0 loss: 1.172031  [   32/  118]
train() client id: f_00009-3-1 loss: 1.044495  [   64/  118]
train() client id: f_00009-3-2 loss: 1.024128  [   96/  118]
train() client id: f_00009-4-0 loss: 1.145514  [   32/  118]
train() client id: f_00009-4-1 loss: 0.994176  [   64/  118]
train() client id: f_00009-4-2 loss: 1.034989  [   96/  118]
train() client id: f_00009-5-0 loss: 0.982889  [   32/  118]
train() client id: f_00009-5-1 loss: 1.120036  [   64/  118]
train() client id: f_00009-5-2 loss: 1.007841  [   96/  118]
train() client id: f_00009-6-0 loss: 1.019643  [   32/  118]
train() client id: f_00009-6-1 loss: 0.992135  [   64/  118]
train() client id: f_00009-6-2 loss: 1.011003  [   96/  118]
train() client id: f_00009-7-0 loss: 1.056189  [   32/  118]
train() client id: f_00009-7-1 loss: 0.886403  [   64/  118]
train() client id: f_00009-7-2 loss: 0.992735  [   96/  118]
train() client id: f_00009-8-0 loss: 1.069922  [   32/  118]
train() client id: f_00009-8-1 loss: 0.915046  [   64/  118]
train() client id: f_00009-8-2 loss: 0.972387  [   96/  118]
train() client id: f_00009-9-0 loss: 1.003783  [   32/  118]
train() client id: f_00009-9-1 loss: 0.942955  [   64/  118]
train() client id: f_00009-9-2 loss: 0.913596  [   96/  118]
train() client id: f_00009-10-0 loss: 0.905222  [   32/  118]
train() client id: f_00009-10-1 loss: 0.971397  [   64/  118]
train() client id: f_00009-10-2 loss: 0.970742  [   96/  118]
train() client id: f_00009-11-0 loss: 0.942624  [   32/  118]
train() client id: f_00009-11-1 loss: 1.057953  [   64/  118]
train() client id: f_00009-11-2 loss: 0.941100  [   96/  118]
train() client id: f_00009-12-0 loss: 0.974377  [   32/  118]
train() client id: f_00009-12-1 loss: 0.981791  [   64/  118]
train() client id: f_00009-12-2 loss: 0.955544  [   96/  118]
At round 14 accuracy: 0.6339522546419099
At round 14 training accuracy: 0.5808182427900738
At round 14 training loss: 0.8476924348225297
gradient difference: 0.38762378692626953
train() client id: f_00000-0-0 loss: 1.266403  [   32/  126]
train() client id: f_00000-0-1 loss: 1.387771  [   64/  126]
train() client id: f_00000-0-2 loss: 1.309268  [   96/  126]
train() client id: f_00000-1-0 loss: 1.217363  [   32/  126]
train() client id: f_00000-1-1 loss: 1.116312  [   64/  126]
train() client id: f_00000-1-2 loss: 1.246279  [   96/  126]
train() client id: f_00000-2-0 loss: 1.025534  [   32/  126]
train() client id: f_00000-2-1 loss: 1.132421  [   64/  126]
train() client id: f_00000-2-2 loss: 1.097502  [   96/  126]
train() client id: f_00000-3-0 loss: 1.050623  [   32/  126]
train() client id: f_00000-3-1 loss: 1.041450  [   64/  126]
train() client id: f_00000-3-2 loss: 1.003590  [   96/  126]
train() client id: f_00000-4-0 loss: 1.011512  [   32/  126]
train() client id: f_00000-4-1 loss: 0.895560  [   64/  126]
train() client id: f_00000-4-2 loss: 1.017871  [   96/  126]
train() client id: f_00000-5-0 loss: 0.990533  [   32/  126]
train() client id: f_00000-5-1 loss: 0.846471  [   64/  126]
train() client id: f_00000-5-2 loss: 0.984413  [   96/  126]
train() client id: f_00000-6-0 loss: 0.993610  [   32/  126]
train() client id: f_00000-6-1 loss: 0.905657  [   64/  126]
train() client id: f_00000-6-2 loss: 0.965845  [   96/  126]
train() client id: f_00000-7-0 loss: 0.823404  [   32/  126]
train() client id: f_00000-7-1 loss: 0.889903  [   64/  126]
train() client id: f_00000-7-2 loss: 0.939842  [   96/  126]
train() client id: f_00000-8-0 loss: 0.855551  [   32/  126]
train() client id: f_00000-8-1 loss: 0.883239  [   64/  126]
train() client id: f_00000-8-2 loss: 0.820608  [   96/  126]
train() client id: f_00000-9-0 loss: 0.863423  [   32/  126]
train() client id: f_00000-9-1 loss: 0.897866  [   64/  126]
train() client id: f_00000-9-2 loss: 0.772405  [   96/  126]
train() client id: f_00000-10-0 loss: 0.850462  [   32/  126]
train() client id: f_00000-10-1 loss: 0.864749  [   64/  126]
train() client id: f_00000-10-2 loss: 0.831203  [   96/  126]
train() client id: f_00000-11-0 loss: 0.821899  [   32/  126]
train() client id: f_00000-11-1 loss: 0.807907  [   64/  126]
train() client id: f_00000-11-2 loss: 0.792682  [   96/  126]
train() client id: f_00000-12-0 loss: 0.859021  [   32/  126]
train() client id: f_00000-12-1 loss: 0.780849  [   64/  126]
train() client id: f_00000-12-2 loss: 0.792452  [   96/  126]
train() client id: f_00001-0-0 loss: 0.575255  [   32/  265]
train() client id: f_00001-0-1 loss: 0.530158  [   64/  265]
train() client id: f_00001-0-2 loss: 0.517411  [   96/  265]
train() client id: f_00001-0-3 loss: 0.488449  [  128/  265]
train() client id: f_00001-0-4 loss: 0.621785  [  160/  265]
train() client id: f_00001-0-5 loss: 0.492365  [  192/  265]
train() client id: f_00001-0-6 loss: 0.472479  [  224/  265]
train() client id: f_00001-0-7 loss: 0.553351  [  256/  265]
train() client id: f_00001-1-0 loss: 0.608639  [   32/  265]
train() client id: f_00001-1-1 loss: 0.495317  [   64/  265]
train() client id: f_00001-1-2 loss: 0.560333  [   96/  265]
train() client id: f_00001-1-3 loss: 0.548339  [  128/  265]
train() client id: f_00001-1-4 loss: 0.498756  [  160/  265]
train() client id: f_00001-1-5 loss: 0.505349  [  192/  265]
train() client id: f_00001-1-6 loss: 0.498004  [  224/  265]
train() client id: f_00001-1-7 loss: 0.437456  [  256/  265]
train() client id: f_00001-2-0 loss: 0.475763  [   32/  265]
train() client id: f_00001-2-1 loss: 0.530999  [   64/  265]
train() client id: f_00001-2-2 loss: 0.431480  [   96/  265]
train() client id: f_00001-2-3 loss: 0.589082  [  128/  265]
train() client id: f_00001-2-4 loss: 0.525049  [  160/  265]
train() client id: f_00001-2-5 loss: 0.675840  [  192/  265]
train() client id: f_00001-2-6 loss: 0.465634  [  224/  265]
train() client id: f_00001-2-7 loss: 0.441073  [  256/  265]
train() client id: f_00001-3-0 loss: 0.510141  [   32/  265]
train() client id: f_00001-3-1 loss: 0.535303  [   64/  265]
train() client id: f_00001-3-2 loss: 0.574365  [   96/  265]
train() client id: f_00001-3-3 loss: 0.454135  [  128/  265]
train() client id: f_00001-3-4 loss: 0.544219  [  160/  265]
train() client id: f_00001-3-5 loss: 0.445423  [  192/  265]
train() client id: f_00001-3-6 loss: 0.542520  [  224/  265]
train() client id: f_00001-3-7 loss: 0.502210  [  256/  265]
train() client id: f_00001-4-0 loss: 0.432241  [   32/  265]
train() client id: f_00001-4-1 loss: 0.568046  [   64/  265]
train() client id: f_00001-4-2 loss: 0.571274  [   96/  265]
train() client id: f_00001-4-3 loss: 0.519328  [  128/  265]
train() client id: f_00001-4-4 loss: 0.486538  [  160/  265]
train() client id: f_00001-4-5 loss: 0.534937  [  192/  265]
train() client id: f_00001-4-6 loss: 0.525693  [  224/  265]
train() client id: f_00001-4-7 loss: 0.425835  [  256/  265]
train() client id: f_00001-5-0 loss: 0.536787  [   32/  265]
train() client id: f_00001-5-1 loss: 0.465456  [   64/  265]
train() client id: f_00001-5-2 loss: 0.534905  [   96/  265]
train() client id: f_00001-5-3 loss: 0.490233  [  128/  265]
train() client id: f_00001-5-4 loss: 0.539380  [  160/  265]
train() client id: f_00001-5-5 loss: 0.443757  [  192/  265]
train() client id: f_00001-5-6 loss: 0.520593  [  224/  265]
train() client id: f_00001-5-7 loss: 0.510780  [  256/  265]
train() client id: f_00001-6-0 loss: 0.543478  [   32/  265]
train() client id: f_00001-6-1 loss: 0.522291  [   64/  265]
train() client id: f_00001-6-2 loss: 0.500389  [   96/  265]
train() client id: f_00001-6-3 loss: 0.513364  [  128/  265]
train() client id: f_00001-6-4 loss: 0.449923  [  160/  265]
train() client id: f_00001-6-5 loss: 0.428121  [  192/  265]
train() client id: f_00001-6-6 loss: 0.553130  [  224/  265]
train() client id: f_00001-6-7 loss: 0.514937  [  256/  265]
train() client id: f_00001-7-0 loss: 0.509470  [   32/  265]
train() client id: f_00001-7-1 loss: 0.631814  [   64/  265]
train() client id: f_00001-7-2 loss: 0.518169  [   96/  265]
train() client id: f_00001-7-3 loss: 0.480431  [  128/  265]
train() client id: f_00001-7-4 loss: 0.458643  [  160/  265]
train() client id: f_00001-7-5 loss: 0.547062  [  192/  265]
train() client id: f_00001-7-6 loss: 0.449297  [  224/  265]
train() client id: f_00001-7-7 loss: 0.418195  [  256/  265]
train() client id: f_00001-8-0 loss: 0.427814  [   32/  265]
train() client id: f_00001-8-1 loss: 0.613531  [   64/  265]
train() client id: f_00001-8-2 loss: 0.402995  [   96/  265]
train() client id: f_00001-8-3 loss: 0.427965  [  128/  265]
train() client id: f_00001-8-4 loss: 0.547186  [  160/  265]
train() client id: f_00001-8-5 loss: 0.485624  [  192/  265]
train() client id: f_00001-8-6 loss: 0.483211  [  224/  265]
train() client id: f_00001-8-7 loss: 0.627897  [  256/  265]
train() client id: f_00001-9-0 loss: 0.646054  [   32/  265]
train() client id: f_00001-9-1 loss: 0.427295  [   64/  265]
train() client id: f_00001-9-2 loss: 0.488331  [   96/  265]
train() client id: f_00001-9-3 loss: 0.504538  [  128/  265]
train() client id: f_00001-9-4 loss: 0.418480  [  160/  265]
train() client id: f_00001-9-5 loss: 0.456139  [  192/  265]
train() client id: f_00001-9-6 loss: 0.467733  [  224/  265]
train() client id: f_00001-9-7 loss: 0.583286  [  256/  265]
train() client id: f_00001-10-0 loss: 0.701305  [   32/  265]
train() client id: f_00001-10-1 loss: 0.421843  [   64/  265]
train() client id: f_00001-10-2 loss: 0.475540  [   96/  265]
train() client id: f_00001-10-3 loss: 0.398317  [  128/  265]
train() client id: f_00001-10-4 loss: 0.504997  [  160/  265]
train() client id: f_00001-10-5 loss: 0.523499  [  192/  265]
train() client id: f_00001-10-6 loss: 0.465938  [  224/  265]
train() client id: f_00001-10-7 loss: 0.463202  [  256/  265]
train() client id: f_00001-11-0 loss: 0.505640  [   32/  265]
train() client id: f_00001-11-1 loss: 0.417501  [   64/  265]
train() client id: f_00001-11-2 loss: 0.464021  [   96/  265]
train() client id: f_00001-11-3 loss: 0.432736  [  128/  265]
train() client id: f_00001-11-4 loss: 0.631648  [  160/  265]
train() client id: f_00001-11-5 loss: 0.472454  [  192/  265]
train() client id: f_00001-11-6 loss: 0.485893  [  224/  265]
train() client id: f_00001-11-7 loss: 0.604255  [  256/  265]
train() client id: f_00001-12-0 loss: 0.631711  [   32/  265]
train() client id: f_00001-12-1 loss: 0.417349  [   64/  265]
train() client id: f_00001-12-2 loss: 0.510910  [   96/  265]
train() client id: f_00001-12-3 loss: 0.432684  [  128/  265]
train() client id: f_00001-12-4 loss: 0.557022  [  160/  265]
train() client id: f_00001-12-5 loss: 0.485931  [  192/  265]
train() client id: f_00001-12-6 loss: 0.472195  [  224/  265]
train() client id: f_00001-12-7 loss: 0.496864  [  256/  265]
train() client id: f_00002-0-0 loss: 1.177579  [   32/  124]
train() client id: f_00002-0-1 loss: 1.284127  [   64/  124]
train() client id: f_00002-0-2 loss: 1.196607  [   96/  124]
train() client id: f_00002-1-0 loss: 1.213583  [   32/  124]
train() client id: f_00002-1-1 loss: 1.241058  [   64/  124]
train() client id: f_00002-1-2 loss: 1.085546  [   96/  124]
train() client id: f_00002-2-0 loss: 1.116349  [   32/  124]
train() client id: f_00002-2-1 loss: 1.051917  [   64/  124]
train() client id: f_00002-2-2 loss: 1.175496  [   96/  124]
train() client id: f_00002-3-0 loss: 1.076283  [   32/  124]
train() client id: f_00002-3-1 loss: 1.036826  [   64/  124]
train() client id: f_00002-3-2 loss: 1.138129  [   96/  124]
train() client id: f_00002-4-0 loss: 0.941847  [   32/  124]
train() client id: f_00002-4-1 loss: 1.133675  [   64/  124]
train() client id: f_00002-4-2 loss: 1.034556  [   96/  124]
train() client id: f_00002-5-0 loss: 1.134668  [   32/  124]
train() client id: f_00002-5-1 loss: 1.001691  [   64/  124]
train() client id: f_00002-5-2 loss: 0.956050  [   96/  124]
train() client id: f_00002-6-0 loss: 0.963496  [   32/  124]
train() client id: f_00002-6-1 loss: 1.155895  [   64/  124]
train() client id: f_00002-6-2 loss: 0.955951  [   96/  124]
train() client id: f_00002-7-0 loss: 0.988415  [   32/  124]
train() client id: f_00002-7-1 loss: 1.053875  [   64/  124]
train() client id: f_00002-7-2 loss: 0.953496  [   96/  124]
train() client id: f_00002-8-0 loss: 0.931508  [   32/  124]
train() client id: f_00002-8-1 loss: 0.962805  [   64/  124]
train() client id: f_00002-8-2 loss: 1.040672  [   96/  124]
train() client id: f_00002-9-0 loss: 0.897257  [   32/  124]
train() client id: f_00002-9-1 loss: 0.901075  [   64/  124]
train() client id: f_00002-9-2 loss: 1.052248  [   96/  124]
train() client id: f_00002-10-0 loss: 0.948581  [   32/  124]
train() client id: f_00002-10-1 loss: 0.975820  [   64/  124]
train() client id: f_00002-10-2 loss: 0.844898  [   96/  124]
train() client id: f_00002-11-0 loss: 0.876742  [   32/  124]
train() client id: f_00002-11-1 loss: 1.007166  [   64/  124]
train() client id: f_00002-11-2 loss: 0.982426  [   96/  124]
train() client id: f_00002-12-0 loss: 1.044902  [   32/  124]
train() client id: f_00002-12-1 loss: 0.948893  [   64/  124]
train() client id: f_00002-12-2 loss: 0.875824  [   96/  124]
train() client id: f_00003-0-0 loss: 0.924156  [   32/   43]
train() client id: f_00003-1-0 loss: 0.822191  [   32/   43]
train() client id: f_00003-2-0 loss: 0.912912  [   32/   43]
train() client id: f_00003-3-0 loss: 0.919699  [   32/   43]
train() client id: f_00003-4-0 loss: 0.776728  [   32/   43]
train() client id: f_00003-5-0 loss: 0.801279  [   32/   43]
train() client id: f_00003-6-0 loss: 0.779335  [   32/   43]
train() client id: f_00003-7-0 loss: 0.753975  [   32/   43]
train() client id: f_00003-8-0 loss: 0.733200  [   32/   43]
train() client id: f_00003-9-0 loss: 0.848632  [   32/   43]
train() client id: f_00003-10-0 loss: 0.907363  [   32/   43]
train() client id: f_00003-11-0 loss: 0.723640  [   32/   43]
train() client id: f_00003-12-0 loss: 0.809801  [   32/   43]
train() client id: f_00004-0-0 loss: 0.869812  [   32/  306]
train() client id: f_00004-0-1 loss: 0.998228  [   64/  306]
train() client id: f_00004-0-2 loss: 0.797700  [   96/  306]
train() client id: f_00004-0-3 loss: 0.779952  [  128/  306]
train() client id: f_00004-0-4 loss: 0.723206  [  160/  306]
train() client id: f_00004-0-5 loss: 0.925023  [  192/  306]
train() client id: f_00004-0-6 loss: 0.870697  [  224/  306]
train() client id: f_00004-0-7 loss: 0.992707  [  256/  306]
train() client id: f_00004-0-8 loss: 0.843396  [  288/  306]
train() client id: f_00004-1-0 loss: 0.887233  [   32/  306]
train() client id: f_00004-1-1 loss: 0.980535  [   64/  306]
train() client id: f_00004-1-2 loss: 0.801930  [   96/  306]
train() client id: f_00004-1-3 loss: 0.799003  [  128/  306]
train() client id: f_00004-1-4 loss: 0.820030  [  160/  306]
train() client id: f_00004-1-5 loss: 0.871788  [  192/  306]
train() client id: f_00004-1-6 loss: 0.839143  [  224/  306]
train() client id: f_00004-1-7 loss: 0.827182  [  256/  306]
train() client id: f_00004-1-8 loss: 0.868360  [  288/  306]
train() client id: f_00004-2-0 loss: 0.842986  [   32/  306]
train() client id: f_00004-2-1 loss: 0.867463  [   64/  306]
train() client id: f_00004-2-2 loss: 0.768243  [   96/  306]
train() client id: f_00004-2-3 loss: 0.831221  [  128/  306]
train() client id: f_00004-2-4 loss: 0.848671  [  160/  306]
train() client id: f_00004-2-5 loss: 0.975269  [  192/  306]
train() client id: f_00004-2-6 loss: 1.001753  [  224/  306]
train() client id: f_00004-2-7 loss: 0.864101  [  256/  306]
train() client id: f_00004-2-8 loss: 0.767598  [  288/  306]
train() client id: f_00004-3-0 loss: 0.904181  [   32/  306]
train() client id: f_00004-3-1 loss: 0.724584  [   64/  306]
train() client id: f_00004-3-2 loss: 0.822257  [   96/  306]
train() client id: f_00004-3-3 loss: 1.006342  [  128/  306]
train() client id: f_00004-3-4 loss: 0.908130  [  160/  306]
train() client id: f_00004-3-5 loss: 0.850559  [  192/  306]
train() client id: f_00004-3-6 loss: 0.869343  [  224/  306]
train() client id: f_00004-3-7 loss: 0.821520  [  256/  306]
train() client id: f_00004-3-8 loss: 0.843670  [  288/  306]
train() client id: f_00004-4-0 loss: 0.805874  [   32/  306]
train() client id: f_00004-4-1 loss: 0.869380  [   64/  306]
train() client id: f_00004-4-2 loss: 0.804358  [   96/  306]
train() client id: f_00004-4-3 loss: 0.796639  [  128/  306]
train() client id: f_00004-4-4 loss: 0.920146  [  160/  306]
train() client id: f_00004-4-5 loss: 0.833976  [  192/  306]
train() client id: f_00004-4-6 loss: 0.783602  [  224/  306]
train() client id: f_00004-4-7 loss: 0.918806  [  256/  306]
train() client id: f_00004-4-8 loss: 0.905322  [  288/  306]
train() client id: f_00004-5-0 loss: 0.854414  [   32/  306]
train() client id: f_00004-5-1 loss: 0.904925  [   64/  306]
train() client id: f_00004-5-2 loss: 0.840852  [   96/  306]
train() client id: f_00004-5-3 loss: 0.772419  [  128/  306]
train() client id: f_00004-5-4 loss: 0.866561  [  160/  306]
train() client id: f_00004-5-5 loss: 0.807512  [  192/  306]
train() client id: f_00004-5-6 loss: 0.842704  [  224/  306]
train() client id: f_00004-5-7 loss: 0.949914  [  256/  306]
train() client id: f_00004-5-8 loss: 0.839073  [  288/  306]
train() client id: f_00004-6-0 loss: 0.912149  [   32/  306]
train() client id: f_00004-6-1 loss: 0.766022  [   64/  306]
train() client id: f_00004-6-2 loss: 0.970379  [   96/  306]
train() client id: f_00004-6-3 loss: 0.750135  [  128/  306]
train() client id: f_00004-6-4 loss: 0.871248  [  160/  306]
train() client id: f_00004-6-5 loss: 0.909065  [  192/  306]
train() client id: f_00004-6-6 loss: 0.868989  [  224/  306]
train() client id: f_00004-6-7 loss: 0.789319  [  256/  306]
train() client id: f_00004-6-8 loss: 0.849088  [  288/  306]
train() client id: f_00004-7-0 loss: 0.896421  [   32/  306]
train() client id: f_00004-7-1 loss: 0.767241  [   64/  306]
train() client id: f_00004-7-2 loss: 0.866510  [   96/  306]
train() client id: f_00004-7-3 loss: 0.902108  [  128/  306]
train() client id: f_00004-7-4 loss: 0.866189  [  160/  306]
train() client id: f_00004-7-5 loss: 0.929056  [  192/  306]
train() client id: f_00004-7-6 loss: 0.776723  [  224/  306]
train() client id: f_00004-7-7 loss: 0.857633  [  256/  306]
train() client id: f_00004-7-8 loss: 0.889202  [  288/  306]
train() client id: f_00004-8-0 loss: 0.704374  [   32/  306]
train() client id: f_00004-8-1 loss: 0.819462  [   64/  306]
train() client id: f_00004-8-2 loss: 0.847499  [   96/  306]
train() client id: f_00004-8-3 loss: 0.912947  [  128/  306]
train() client id: f_00004-8-4 loss: 0.802949  [  160/  306]
train() client id: f_00004-8-5 loss: 0.906565  [  192/  306]
train() client id: f_00004-8-6 loss: 0.921028  [  224/  306]
train() client id: f_00004-8-7 loss: 0.825723  [  256/  306]
train() client id: f_00004-8-8 loss: 0.946747  [  288/  306]
train() client id: f_00004-9-0 loss: 0.881755  [   32/  306]
train() client id: f_00004-9-1 loss: 0.892019  [   64/  306]
train() client id: f_00004-9-2 loss: 0.865086  [   96/  306]
train() client id: f_00004-9-3 loss: 0.898024  [  128/  306]
train() client id: f_00004-9-4 loss: 0.932027  [  160/  306]
train() client id: f_00004-9-5 loss: 0.770891  [  192/  306]
train() client id: f_00004-9-6 loss: 0.858353  [  224/  306]
train() client id: f_00004-9-7 loss: 0.871173  [  256/  306]
train() client id: f_00004-9-8 loss: 0.814073  [  288/  306]
train() client id: f_00004-10-0 loss: 0.967931  [   32/  306]
train() client id: f_00004-10-1 loss: 0.914724  [   64/  306]
train() client id: f_00004-10-2 loss: 0.888759  [   96/  306]
train() client id: f_00004-10-3 loss: 0.856466  [  128/  306]
train() client id: f_00004-10-4 loss: 0.785481  [  160/  306]
train() client id: f_00004-10-5 loss: 0.788654  [  192/  306]
train() client id: f_00004-10-6 loss: 0.839111  [  224/  306]
train() client id: f_00004-10-7 loss: 0.814869  [  256/  306]
train() client id: f_00004-10-8 loss: 0.862058  [  288/  306]
train() client id: f_00004-11-0 loss: 0.934709  [   32/  306]
train() client id: f_00004-11-1 loss: 0.808867  [   64/  306]
train() client id: f_00004-11-2 loss: 0.878984  [   96/  306]
train() client id: f_00004-11-3 loss: 0.799874  [  128/  306]
train() client id: f_00004-11-4 loss: 0.885879  [  160/  306]
train() client id: f_00004-11-5 loss: 0.793482  [  192/  306]
train() client id: f_00004-11-6 loss: 0.836365  [  224/  306]
train() client id: f_00004-11-7 loss: 0.909487  [  256/  306]
train() client id: f_00004-11-8 loss: 0.883691  [  288/  306]
train() client id: f_00004-12-0 loss: 0.826838  [   32/  306]
train() client id: f_00004-12-1 loss: 0.819428  [   64/  306]
train() client id: f_00004-12-2 loss: 0.762336  [   96/  306]
train() client id: f_00004-12-3 loss: 0.929682  [  128/  306]
train() client id: f_00004-12-4 loss: 0.813625  [  160/  306]
train() client id: f_00004-12-5 loss: 0.868816  [  192/  306]
train() client id: f_00004-12-6 loss: 0.985323  [  224/  306]
train() client id: f_00004-12-7 loss: 0.874722  [  256/  306]
train() client id: f_00004-12-8 loss: 0.784330  [  288/  306]
train() client id: f_00005-0-0 loss: 0.471863  [   32/  146]
train() client id: f_00005-0-1 loss: 0.662197  [   64/  146]
train() client id: f_00005-0-2 loss: 0.362577  [   96/  146]
train() client id: f_00005-0-3 loss: 0.300841  [  128/  146]
train() client id: f_00005-1-0 loss: 0.469628  [   32/  146]
train() client id: f_00005-1-1 loss: 0.487906  [   64/  146]
train() client id: f_00005-1-2 loss: 0.461857  [   96/  146]
train() client id: f_00005-1-3 loss: 0.352114  [  128/  146]
train() client id: f_00005-2-0 loss: 0.486070  [   32/  146]
train() client id: f_00005-2-1 loss: 0.338115  [   64/  146]
train() client id: f_00005-2-2 loss: 0.652383  [   96/  146]
train() client id: f_00005-2-3 loss: 0.215051  [  128/  146]
train() client id: f_00005-3-0 loss: 0.357498  [   32/  146]
train() client id: f_00005-3-1 loss: 0.376036  [   64/  146]
train() client id: f_00005-3-2 loss: 0.642202  [   96/  146]
train() client id: f_00005-3-3 loss: 0.312450  [  128/  146]
train() client id: f_00005-4-0 loss: 0.323355  [   32/  146]
train() client id: f_00005-4-1 loss: 0.450620  [   64/  146]
train() client id: f_00005-4-2 loss: 0.535349  [   96/  146]
train() client id: f_00005-4-3 loss: 0.485388  [  128/  146]
train() client id: f_00005-5-0 loss: 0.345113  [   32/  146]
train() client id: f_00005-5-1 loss: 0.288533  [   64/  146]
train() client id: f_00005-5-2 loss: 0.389715  [   96/  146]
train() client id: f_00005-5-3 loss: 0.576391  [  128/  146]
train() client id: f_00005-6-0 loss: 0.435050  [   32/  146]
train() client id: f_00005-6-1 loss: 0.397912  [   64/  146]
train() client id: f_00005-6-2 loss: 0.389456  [   96/  146]
train() client id: f_00005-6-3 loss: 0.451659  [  128/  146]
train() client id: f_00005-7-0 loss: 0.539040  [   32/  146]
train() client id: f_00005-7-1 loss: 0.394573  [   64/  146]
train() client id: f_00005-7-2 loss: 0.465400  [   96/  146]
train() client id: f_00005-7-3 loss: 0.307590  [  128/  146]
train() client id: f_00005-8-0 loss: 0.291515  [   32/  146]
train() client id: f_00005-8-1 loss: 0.391665  [   64/  146]
train() client id: f_00005-8-2 loss: 0.521179  [   96/  146]
train() client id: f_00005-8-3 loss: 0.485049  [  128/  146]
train() client id: f_00005-9-0 loss: 0.324335  [   32/  146]
train() client id: f_00005-9-1 loss: 0.559045  [   64/  146]
train() client id: f_00005-9-2 loss: 0.432009  [   96/  146]
train() client id: f_00005-9-3 loss: 0.291757  [  128/  146]
train() client id: f_00005-10-0 loss: 0.555912  [   32/  146]
train() client id: f_00005-10-1 loss: 0.405934  [   64/  146]
train() client id: f_00005-10-2 loss: 0.207386  [   96/  146]
train() client id: f_00005-10-3 loss: 0.422466  [  128/  146]
train() client id: f_00005-11-0 loss: 0.302378  [   32/  146]
train() client id: f_00005-11-1 loss: 0.455508  [   64/  146]
train() client id: f_00005-11-2 loss: 0.434586  [   96/  146]
train() client id: f_00005-11-3 loss: 0.383601  [  128/  146]
train() client id: f_00005-12-0 loss: 0.396966  [   32/  146]
train() client id: f_00005-12-1 loss: 0.448314  [   64/  146]
train() client id: f_00005-12-2 loss: 0.348115  [   96/  146]
train() client id: f_00005-12-3 loss: 0.215251  [  128/  146]
train() client id: f_00006-0-0 loss: 0.608002  [   32/   54]
train() client id: f_00006-1-0 loss: 0.561016  [   32/   54]
train() client id: f_00006-2-0 loss: 0.648013  [   32/   54]
train() client id: f_00006-3-0 loss: 0.611071  [   32/   54]
train() client id: f_00006-4-0 loss: 0.600163  [   32/   54]
train() client id: f_00006-5-0 loss: 0.597785  [   32/   54]
train() client id: f_00006-6-0 loss: 0.636509  [   32/   54]
train() client id: f_00006-7-0 loss: 0.593806  [   32/   54]
train() client id: f_00006-8-0 loss: 0.612853  [   32/   54]
train() client id: f_00006-9-0 loss: 0.602217  [   32/   54]
train() client id: f_00006-10-0 loss: 0.600963  [   32/   54]
train() client id: f_00006-11-0 loss: 0.637845  [   32/   54]
train() client id: f_00006-12-0 loss: 0.653397  [   32/   54]
train() client id: f_00007-0-0 loss: 0.618672  [   32/  179]
train() client id: f_00007-0-1 loss: 0.525419  [   64/  179]
train() client id: f_00007-0-2 loss: 0.620035  [   96/  179]
train() client id: f_00007-0-3 loss: 0.570423  [  128/  179]
train() client id: f_00007-0-4 loss: 0.646095  [  160/  179]
train() client id: f_00007-1-0 loss: 0.550410  [   32/  179]
train() client id: f_00007-1-1 loss: 0.491091  [   64/  179]
train() client id: f_00007-1-2 loss: 0.554942  [   96/  179]
train() client id: f_00007-1-3 loss: 0.599222  [  128/  179]
train() client id: f_00007-1-4 loss: 0.643769  [  160/  179]
train() client id: f_00007-2-0 loss: 0.512348  [   32/  179]
train() client id: f_00007-2-1 loss: 0.662763  [   64/  179]
train() client id: f_00007-2-2 loss: 0.543757  [   96/  179]
train() client id: f_00007-2-3 loss: 0.661226  [  128/  179]
train() client id: f_00007-2-4 loss: 0.448228  [  160/  179]
train() client id: f_00007-3-0 loss: 0.575787  [   32/  179]
train() client id: f_00007-3-1 loss: 0.516842  [   64/  179]
train() client id: f_00007-3-2 loss: 0.615582  [   96/  179]
train() client id: f_00007-3-3 loss: 0.520980  [  128/  179]
train() client id: f_00007-3-4 loss: 0.507061  [  160/  179]
train() client id: f_00007-4-0 loss: 0.542243  [   32/  179]
train() client id: f_00007-4-1 loss: 0.492068  [   64/  179]
train() client id: f_00007-4-2 loss: 0.575652  [   96/  179]
train() client id: f_00007-4-3 loss: 0.625704  [  128/  179]
train() client id: f_00007-4-4 loss: 0.489451  [  160/  179]
train() client id: f_00007-5-0 loss: 0.776732  [   32/  179]
train() client id: f_00007-5-1 loss: 0.467851  [   64/  179]
train() client id: f_00007-5-2 loss: 0.389032  [   96/  179]
train() client id: f_00007-5-3 loss: 0.520120  [  128/  179]
train() client id: f_00007-5-4 loss: 0.437893  [  160/  179]
train() client id: f_00007-6-0 loss: 0.625694  [   32/  179]
train() client id: f_00007-6-1 loss: 0.397502  [   64/  179]
train() client id: f_00007-6-2 loss: 0.725250  [   96/  179]
train() client id: f_00007-6-3 loss: 0.512561  [  128/  179]
train() client id: f_00007-6-4 loss: 0.376705  [  160/  179]
train() client id: f_00007-7-0 loss: 0.479031  [   32/  179]
train() client id: f_00007-7-1 loss: 0.533282  [   64/  179]
train() client id: f_00007-7-2 loss: 0.515169  [   96/  179]
train() client id: f_00007-7-3 loss: 0.488803  [  128/  179]
train() client id: f_00007-7-4 loss: 0.717177  [  160/  179]
train() client id: f_00007-8-0 loss: 0.515417  [   32/  179]
train() client id: f_00007-8-1 loss: 0.576220  [   64/  179]
train() client id: f_00007-8-2 loss: 0.691215  [   96/  179]
train() client id: f_00007-8-3 loss: 0.532491  [  128/  179]
train() client id: f_00007-8-4 loss: 0.402319  [  160/  179]
train() client id: f_00007-9-0 loss: 0.725848  [   32/  179]
train() client id: f_00007-9-1 loss: 0.537932  [   64/  179]
train() client id: f_00007-9-2 loss: 0.378254  [   96/  179]
train() client id: f_00007-9-3 loss: 0.575760  [  128/  179]
train() client id: f_00007-9-4 loss: 0.374167  [  160/  179]
train() client id: f_00007-10-0 loss: 0.465848  [   32/  179]
train() client id: f_00007-10-1 loss: 0.742614  [   64/  179]
train() client id: f_00007-10-2 loss: 0.447506  [   96/  179]
train() client id: f_00007-10-3 loss: 0.481172  [  128/  179]
train() client id: f_00007-10-4 loss: 0.438321  [  160/  179]
train() client id: f_00007-11-0 loss: 0.597076  [   32/  179]
train() client id: f_00007-11-1 loss: 0.615709  [   64/  179]
train() client id: f_00007-11-2 loss: 0.385003  [   96/  179]
train() client id: f_00007-11-3 loss: 0.540127  [  128/  179]
train() client id: f_00007-11-4 loss: 0.537974  [  160/  179]
train() client id: f_00007-12-0 loss: 0.364270  [   32/  179]
train() client id: f_00007-12-1 loss: 0.672685  [   64/  179]
train() client id: f_00007-12-2 loss: 0.484737  [   96/  179]
train() client id: f_00007-12-3 loss: 0.390948  [  128/  179]
train() client id: f_00007-12-4 loss: 0.644126  [  160/  179]
train() client id: f_00008-0-0 loss: 0.792487  [   32/  130]
train() client id: f_00008-0-1 loss: 0.870521  [   64/  130]
train() client id: f_00008-0-2 loss: 0.744768  [   96/  130]
train() client id: f_00008-0-3 loss: 0.695817  [  128/  130]
train() client id: f_00008-1-0 loss: 0.833484  [   32/  130]
train() client id: f_00008-1-1 loss: 0.839053  [   64/  130]
train() client id: f_00008-1-2 loss: 0.767674  [   96/  130]
train() client id: f_00008-1-3 loss: 0.643488  [  128/  130]
train() client id: f_00008-2-0 loss: 0.803026  [   32/  130]
train() client id: f_00008-2-1 loss: 0.722117  [   64/  130]
train() client id: f_00008-2-2 loss: 0.718463  [   96/  130]
train() client id: f_00008-2-3 loss: 0.836034  [  128/  130]
train() client id: f_00008-3-0 loss: 0.711710  [   32/  130]
train() client id: f_00008-3-1 loss: 0.736870  [   64/  130]
train() client id: f_00008-3-2 loss: 0.863883  [   96/  130]
train() client id: f_00008-3-3 loss: 0.753675  [  128/  130]
train() client id: f_00008-4-0 loss: 0.679695  [   32/  130]
train() client id: f_00008-4-1 loss: 0.859891  [   64/  130]
train() client id: f_00008-4-2 loss: 0.857784  [   96/  130]
train() client id: f_00008-4-3 loss: 0.684448  [  128/  130]
train() client id: f_00008-5-0 loss: 0.817259  [   32/  130]
train() client id: f_00008-5-1 loss: 0.760364  [   64/  130]
train() client id: f_00008-5-2 loss: 0.780331  [   96/  130]
train() client id: f_00008-5-3 loss: 0.712947  [  128/  130]
train() client id: f_00008-6-0 loss: 0.851807  [   32/  130]
train() client id: f_00008-6-1 loss: 0.773009  [   64/  130]
train() client id: f_00008-6-2 loss: 0.779047  [   96/  130]
train() client id: f_00008-6-3 loss: 0.672902  [  128/  130]
train() client id: f_00008-7-0 loss: 0.732622  [   32/  130]
train() client id: f_00008-7-1 loss: 0.830863  [   64/  130]
train() client id: f_00008-7-2 loss: 0.784821  [   96/  130]
train() client id: f_00008-7-3 loss: 0.722473  [  128/  130]
train() client id: f_00008-8-0 loss: 0.663169  [   32/  130]
train() client id: f_00008-8-1 loss: 0.734819  [   64/  130]
train() client id: f_00008-8-2 loss: 0.815387  [   96/  130]
train() client id: f_00008-8-3 loss: 0.851061  [  128/  130]
train() client id: f_00008-9-0 loss: 0.874567  [   32/  130]
train() client id: f_00008-9-1 loss: 0.814699  [   64/  130]
train() client id: f_00008-9-2 loss: 0.662126  [   96/  130]
train() client id: f_00008-9-3 loss: 0.716580  [  128/  130]
train() client id: f_00008-10-0 loss: 0.678866  [   32/  130]
train() client id: f_00008-10-1 loss: 0.788034  [   64/  130]
train() client id: f_00008-10-2 loss: 0.764652  [   96/  130]
train() client id: f_00008-10-3 loss: 0.829004  [  128/  130]
train() client id: f_00008-11-0 loss: 0.921421  [   32/  130]
train() client id: f_00008-11-1 loss: 0.762772  [   64/  130]
train() client id: f_00008-11-2 loss: 0.660145  [   96/  130]
train() client id: f_00008-11-3 loss: 0.715488  [  128/  130]
train() client id: f_00008-12-0 loss: 0.746018  [   32/  130]
train() client id: f_00008-12-1 loss: 0.720071  [   64/  130]
train() client id: f_00008-12-2 loss: 0.776393  [   96/  130]
train() client id: f_00008-12-3 loss: 0.819031  [  128/  130]
train() client id: f_00009-0-0 loss: 1.026175  [   32/  118]
train() client id: f_00009-0-1 loss: 1.202326  [   64/  118]
train() client id: f_00009-0-2 loss: 1.040088  [   96/  118]
train() client id: f_00009-1-0 loss: 1.070650  [   32/  118]
train() client id: f_00009-1-1 loss: 1.107888  [   64/  118]
train() client id: f_00009-1-2 loss: 1.062425  [   96/  118]
train() client id: f_00009-2-0 loss: 1.015809  [   32/  118]
train() client id: f_00009-2-1 loss: 0.970980  [   64/  118]
train() client id: f_00009-2-2 loss: 1.028895  [   96/  118]
train() client id: f_00009-3-0 loss: 1.004704  [   32/  118]
train() client id: f_00009-3-1 loss: 0.966680  [   64/  118]
train() client id: f_00009-3-2 loss: 0.952448  [   96/  118]
train() client id: f_00009-4-0 loss: 0.919434  [   32/  118]
train() client id: f_00009-4-1 loss: 0.862160  [   64/  118]
train() client id: f_00009-4-2 loss: 1.025289  [   96/  118]
train() client id: f_00009-5-0 loss: 1.007745  [   32/  118]
train() client id: f_00009-5-1 loss: 0.914441  [   64/  118]
train() client id: f_00009-5-2 loss: 0.888024  [   96/  118]
train() client id: f_00009-6-0 loss: 0.993428  [   32/  118]
train() client id: f_00009-6-1 loss: 0.918621  [   64/  118]
train() client id: f_00009-6-2 loss: 0.889099  [   96/  118]
train() client id: f_00009-7-0 loss: 0.973807  [   32/  118]
train() client id: f_00009-7-1 loss: 0.808109  [   64/  118]
train() client id: f_00009-7-2 loss: 0.872060  [   96/  118]
train() client id: f_00009-8-0 loss: 0.931466  [   32/  118]
train() client id: f_00009-8-1 loss: 0.929773  [   64/  118]
train() client id: f_00009-8-2 loss: 0.854656  [   96/  118]
train() client id: f_00009-9-0 loss: 0.835732  [   32/  118]
train() client id: f_00009-9-1 loss: 0.870366  [   64/  118]
train() client id: f_00009-9-2 loss: 0.983578  [   96/  118]
train() client id: f_00009-10-0 loss: 0.931176  [   32/  118]
train() client id: f_00009-10-1 loss: 0.891416  [   64/  118]
train() client id: f_00009-10-2 loss: 0.886253  [   96/  118]
train() client id: f_00009-11-0 loss: 0.814171  [   32/  118]
train() client id: f_00009-11-1 loss: 0.941970  [   64/  118]
train() client id: f_00009-11-2 loss: 0.947657  [   96/  118]
train() client id: f_00009-12-0 loss: 0.924088  [   32/  118]
train() client id: f_00009-12-1 loss: 0.909946  [   64/  118]
train() client id: f_00009-12-2 loss: 0.902222  [   96/  118]
At round 15 accuracy: 0.636604774535809
At round 15 training accuracy: 0.5841716968477532
At round 15 training loss: 0.8515938725346636
gradient difference: 0.41673094034194946
train() client id: f_00000-0-0 loss: 1.323049  [   32/  126]
train() client id: f_00000-0-1 loss: 1.200996  [   64/  126]
train() client id: f_00000-0-2 loss: 1.187725  [   96/  126]
train() client id: f_00000-1-0 loss: 1.206944  [   32/  126]
train() client id: f_00000-1-1 loss: 1.045469  [   64/  126]
train() client id: f_00000-1-2 loss: 1.007555  [   96/  126]
train() client id: f_00000-2-0 loss: 0.984568  [   32/  126]
train() client id: f_00000-2-1 loss: 0.908266  [   64/  126]
train() client id: f_00000-2-2 loss: 1.094149  [   96/  126]
train() client id: f_00000-3-0 loss: 1.014546  [   32/  126]
train() client id: f_00000-3-1 loss: 1.077987  [   64/  126]
train() client id: f_00000-3-2 loss: 0.864136  [   96/  126]
train() client id: f_00000-4-0 loss: 0.978200  [   32/  126]
train() client id: f_00000-4-1 loss: 0.944953  [   64/  126]
train() client id: f_00000-4-2 loss: 0.962696  [   96/  126]
train() client id: f_00000-5-0 loss: 0.805796  [   32/  126]
train() client id: f_00000-5-1 loss: 0.867196  [   64/  126]
train() client id: f_00000-5-2 loss: 0.923486  [   96/  126]
train() client id: f_00000-6-0 loss: 0.798384  [   32/  126]
train() client id: f_00000-6-1 loss: 0.893778  [   64/  126]
train() client id: f_00000-6-2 loss: 1.023767  [   96/  126]
train() client id: f_00000-7-0 loss: 0.801163  [   32/  126]
train() client id: f_00000-7-1 loss: 0.943790  [   64/  126]
train() client id: f_00000-7-2 loss: 0.831347  [   96/  126]
train() client id: f_00000-8-0 loss: 0.892086  [   32/  126]
train() client id: f_00000-8-1 loss: 0.796474  [   64/  126]
train() client id: f_00000-8-2 loss: 0.963969  [   96/  126]
train() client id: f_00000-9-0 loss: 0.892566  [   32/  126]
train() client id: f_00000-9-1 loss: 0.788418  [   64/  126]
train() client id: f_00000-9-2 loss: 0.882064  [   96/  126]
train() client id: f_00000-10-0 loss: 0.845465  [   32/  126]
train() client id: f_00000-10-1 loss: 0.898280  [   64/  126]
train() client id: f_00000-10-2 loss: 0.887933  [   96/  126]
train() client id: f_00000-11-0 loss: 0.807555  [   32/  126]
train() client id: f_00000-11-1 loss: 0.977631  [   64/  126]
train() client id: f_00000-11-2 loss: 0.756093  [   96/  126]
train() client id: f_00000-12-0 loss: 0.843750  [   32/  126]
train() client id: f_00000-12-1 loss: 0.791367  [   64/  126]
train() client id: f_00000-12-2 loss: 0.805802  [   96/  126]
train() client id: f_00001-0-0 loss: 0.447007  [   32/  265]
train() client id: f_00001-0-1 loss: 0.510762  [   64/  265]
train() client id: f_00001-0-2 loss: 0.451386  [   96/  265]
train() client id: f_00001-0-3 loss: 0.523833  [  128/  265]
train() client id: f_00001-0-4 loss: 0.409973  [  160/  265]
train() client id: f_00001-0-5 loss: 0.499123  [  192/  265]
train() client id: f_00001-0-6 loss: 0.364904  [  224/  265]
train() client id: f_00001-0-7 loss: 0.429202  [  256/  265]
train() client id: f_00001-1-0 loss: 0.411681  [   32/  265]
train() client id: f_00001-1-1 loss: 0.438493  [   64/  265]
train() client id: f_00001-1-2 loss: 0.607059  [   96/  265]
train() client id: f_00001-1-3 loss: 0.396559  [  128/  265]
train() client id: f_00001-1-4 loss: 0.383525  [  160/  265]
train() client id: f_00001-1-5 loss: 0.505563  [  192/  265]
train() client id: f_00001-1-6 loss: 0.458133  [  224/  265]
train() client id: f_00001-1-7 loss: 0.407582  [  256/  265]
train() client id: f_00001-2-0 loss: 0.512085  [   32/  265]
train() client id: f_00001-2-1 loss: 0.361628  [   64/  265]
train() client id: f_00001-2-2 loss: 0.388838  [   96/  265]
train() client id: f_00001-2-3 loss: 0.440622  [  128/  265]
train() client id: f_00001-2-4 loss: 0.410131  [  160/  265]
train() client id: f_00001-2-5 loss: 0.376210  [  192/  265]
train() client id: f_00001-2-6 loss: 0.468216  [  224/  265]
train() client id: f_00001-2-7 loss: 0.532592  [  256/  265]
train() client id: f_00001-3-0 loss: 0.486057  [   32/  265]
train() client id: f_00001-3-1 loss: 0.480527  [   64/  265]
train() client id: f_00001-3-2 loss: 0.479781  [   96/  265]
train() client id: f_00001-3-3 loss: 0.393782  [  128/  265]
train() client id: f_00001-3-4 loss: 0.360653  [  160/  265]
train() client id: f_00001-3-5 loss: 0.421037  [  192/  265]
train() client id: f_00001-3-6 loss: 0.454038  [  224/  265]
train() client id: f_00001-3-7 loss: 0.396375  [  256/  265]
train() client id: f_00001-4-0 loss: 0.330387  [   32/  265]
train() client id: f_00001-4-1 loss: 0.399743  [   64/  265]
train() client id: f_00001-4-2 loss: 0.413434  [   96/  265]
train() client id: f_00001-4-3 loss: 0.584207  [  128/  265]
train() client id: f_00001-4-4 loss: 0.423158  [  160/  265]
train() client id: f_00001-4-5 loss: 0.433871  [  192/  265]
train() client id: f_00001-4-6 loss: 0.443034  [  224/  265]
train() client id: f_00001-4-7 loss: 0.414554  [  256/  265]
train() client id: f_00001-5-0 loss: 0.451579  [   32/  265]
train() client id: f_00001-5-1 loss: 0.338507  [   64/  265]
train() client id: f_00001-5-2 loss: 0.440854  [   96/  265]
train() client id: f_00001-5-3 loss: 0.486454  [  128/  265]
train() client id: f_00001-5-4 loss: 0.382535  [  160/  265]
train() client id: f_00001-5-5 loss: 0.527195  [  192/  265]
train() client id: f_00001-5-6 loss: 0.406617  [  224/  265]
train() client id: f_00001-5-7 loss: 0.378242  [  256/  265]
train() client id: f_00001-6-0 loss: 0.342556  [   32/  265]
train() client id: f_00001-6-1 loss: 0.446192  [   64/  265]
train() client id: f_00001-6-2 loss: 0.596465  [   96/  265]
train() client id: f_00001-6-3 loss: 0.351979  [  128/  265]
train() client id: f_00001-6-4 loss: 0.415202  [  160/  265]
train() client id: f_00001-6-5 loss: 0.391703  [  192/  265]
train() client id: f_00001-6-6 loss: 0.394344  [  224/  265]
train() client id: f_00001-6-7 loss: 0.431859  [  256/  265]
train() client id: f_00001-7-0 loss: 0.431760  [   32/  265]
train() client id: f_00001-7-1 loss: 0.333568  [   64/  265]
train() client id: f_00001-7-2 loss: 0.385208  [   96/  265]
train() client id: f_00001-7-3 loss: 0.370105  [  128/  265]
train() client id: f_00001-7-4 loss: 0.406231  [  160/  265]
train() client id: f_00001-7-5 loss: 0.414204  [  192/  265]
train() client id: f_00001-7-6 loss: 0.545648  [  224/  265]
train() client id: f_00001-7-7 loss: 0.486933  [  256/  265]
train() client id: f_00001-8-0 loss: 0.392847  [   32/  265]
train() client id: f_00001-8-1 loss: 0.349815  [   64/  265]
train() client id: f_00001-8-2 loss: 0.483268  [   96/  265]
train() client id: f_00001-8-3 loss: 0.408458  [  128/  265]
train() client id: f_00001-8-4 loss: 0.344172  [  160/  265]
train() client id: f_00001-8-5 loss: 0.445919  [  192/  265]
train() client id: f_00001-8-6 loss: 0.384382  [  224/  265]
train() client id: f_00001-8-7 loss: 0.425533  [  256/  265]
train() client id: f_00001-9-0 loss: 0.515132  [   32/  265]
train() client id: f_00001-9-1 loss: 0.365205  [   64/  265]
train() client id: f_00001-9-2 loss: 0.444850  [   96/  265]
train() client id: f_00001-9-3 loss: 0.322266  [  128/  265]
train() client id: f_00001-9-4 loss: 0.379831  [  160/  265]
train() client id: f_00001-9-5 loss: 0.364818  [  192/  265]
train() client id: f_00001-9-6 loss: 0.408031  [  224/  265]
train() client id: f_00001-9-7 loss: 0.537111  [  256/  265]
train() client id: f_00001-10-0 loss: 0.334397  [   32/  265]
train() client id: f_00001-10-1 loss: 0.417667  [   64/  265]
train() client id: f_00001-10-2 loss: 0.358497  [   96/  265]
train() client id: f_00001-10-3 loss: 0.453089  [  128/  265]
train() client id: f_00001-10-4 loss: 0.433962  [  160/  265]
train() client id: f_00001-10-5 loss: 0.448963  [  192/  265]
train() client id: f_00001-10-6 loss: 0.386554  [  224/  265]
train() client id: f_00001-10-7 loss: 0.408885  [  256/  265]
train() client id: f_00001-11-0 loss: 0.386857  [   32/  265]
train() client id: f_00001-11-1 loss: 0.441485  [   64/  265]
train() client id: f_00001-11-2 loss: 0.353385  [   96/  265]
train() client id: f_00001-11-3 loss: 0.392519  [  128/  265]
train() client id: f_00001-11-4 loss: 0.390003  [  160/  265]
train() client id: f_00001-11-5 loss: 0.462027  [  192/  265]
train() client id: f_00001-11-6 loss: 0.434605  [  224/  265]
train() client id: f_00001-11-7 loss: 0.395576  [  256/  265]
train() client id: f_00001-12-0 loss: 0.531569  [   32/  265]
train() client id: f_00001-12-1 loss: 0.343050  [   64/  265]
train() client id: f_00001-12-2 loss: 0.547061  [   96/  265]
train() client id: f_00001-12-3 loss: 0.365665  [  128/  265]
train() client id: f_00001-12-4 loss: 0.383860  [  160/  265]
train() client id: f_00001-12-5 loss: 0.449603  [  192/  265]
train() client id: f_00001-12-6 loss: 0.384699  [  224/  265]
train() client id: f_00001-12-7 loss: 0.330500  [  256/  265]
train() client id: f_00002-0-0 loss: 1.190461  [   32/  124]
train() client id: f_00002-0-1 loss: 1.209640  [   64/  124]
train() client id: f_00002-0-2 loss: 1.283855  [   96/  124]
train() client id: f_00002-1-0 loss: 1.307167  [   32/  124]
train() client id: f_00002-1-1 loss: 1.217900  [   64/  124]
train() client id: f_00002-1-2 loss: 1.165640  [   96/  124]
train() client id: f_00002-2-0 loss: 1.198462  [   32/  124]
train() client id: f_00002-2-1 loss: 1.181459  [   64/  124]
train() client id: f_00002-2-2 loss: 1.228685  [   96/  124]
train() client id: f_00002-3-0 loss: 1.074579  [   32/  124]
train() client id: f_00002-3-1 loss: 1.174862  [   64/  124]
train() client id: f_00002-3-2 loss: 1.068893  [   96/  124]
train() client id: f_00002-4-0 loss: 1.206683  [   32/  124]
train() client id: f_00002-4-1 loss: 1.204798  [   64/  124]
train() client id: f_00002-4-2 loss: 1.028555  [   96/  124]
train() client id: f_00002-5-0 loss: 1.179816  [   32/  124]
train() client id: f_00002-5-1 loss: 1.088733  [   64/  124]
train() client id: f_00002-5-2 loss: 1.003420  [   96/  124]
train() client id: f_00002-6-0 loss: 1.205958  [   32/  124]
train() client id: f_00002-6-1 loss: 1.012770  [   64/  124]
train() client id: f_00002-6-2 loss: 0.971377  [   96/  124]
train() client id: f_00002-7-0 loss: 1.071001  [   32/  124]
train() client id: f_00002-7-1 loss: 1.068802  [   64/  124]
train() client id: f_00002-7-2 loss: 1.055580  [   96/  124]
train() client id: f_00002-8-0 loss: 1.036494  [   32/  124]
train() client id: f_00002-8-1 loss: 0.976851  [   64/  124]
train() client id: f_00002-8-2 loss: 1.165450  [   96/  124]
train() client id: f_00002-9-0 loss: 0.987132  [   32/  124]
train() client id: f_00002-9-1 loss: 1.184792  [   64/  124]
train() client id: f_00002-9-2 loss: 1.054228  [   96/  124]
train() client id: f_00002-10-0 loss: 0.969370  [   32/  124]
train() client id: f_00002-10-1 loss: 1.208247  [   64/  124]
train() client id: f_00002-10-2 loss: 0.957775  [   96/  124]
train() client id: f_00002-11-0 loss: 1.132246  [   32/  124]
train() client id: f_00002-11-1 loss: 0.996044  [   64/  124]
train() client id: f_00002-11-2 loss: 1.089642  [   96/  124]
train() client id: f_00002-12-0 loss: 1.028367  [   32/  124]
train() client id: f_00002-12-1 loss: 0.940484  [   64/  124]
train() client id: f_00002-12-2 loss: 1.107879  [   96/  124]
train() client id: f_00003-0-0 loss: 0.789376  [   32/   43]
train() client id: f_00003-1-0 loss: 0.815859  [   32/   43]
train() client id: f_00003-2-0 loss: 0.833825  [   32/   43]
train() client id: f_00003-3-0 loss: 0.825249  [   32/   43]
train() client id: f_00003-4-0 loss: 0.905527  [   32/   43]
train() client id: f_00003-5-0 loss: 0.808497  [   32/   43]
train() client id: f_00003-6-0 loss: 0.793745  [   32/   43]
train() client id: f_00003-7-0 loss: 0.927950  [   32/   43]
train() client id: f_00003-8-0 loss: 0.909889  [   32/   43]
train() client id: f_00003-9-0 loss: 0.803946  [   32/   43]
train() client id: f_00003-10-0 loss: 0.823480  [   32/   43]
train() client id: f_00003-11-0 loss: 0.787732  [   32/   43]
train() client id: f_00003-12-0 loss: 0.868389  [   32/   43]
train() client id: f_00004-0-0 loss: 0.952508  [   32/  306]
train() client id: f_00004-0-1 loss: 1.096993  [   64/  306]
train() client id: f_00004-0-2 loss: 0.991414  [   96/  306]
train() client id: f_00004-0-3 loss: 0.900221  [  128/  306]
train() client id: f_00004-0-4 loss: 0.672284  [  160/  306]
train() client id: f_00004-0-5 loss: 0.986989  [  192/  306]
train() client id: f_00004-0-6 loss: 0.932066  [  224/  306]
train() client id: f_00004-0-7 loss: 0.932856  [  256/  306]
train() client id: f_00004-0-8 loss: 0.968367  [  288/  306]
train() client id: f_00004-1-0 loss: 0.976022  [   32/  306]
train() client id: f_00004-1-1 loss: 0.928603  [   64/  306]
train() client id: f_00004-1-2 loss: 0.856937  [   96/  306]
train() client id: f_00004-1-3 loss: 0.973043  [  128/  306]
train() client id: f_00004-1-4 loss: 0.819989  [  160/  306]
train() client id: f_00004-1-5 loss: 0.947265  [  192/  306]
train() client id: f_00004-1-6 loss: 1.045826  [  224/  306]
train() client id: f_00004-1-7 loss: 0.920308  [  256/  306]
train() client id: f_00004-1-8 loss: 0.958857  [  288/  306]
train() client id: f_00004-2-0 loss: 0.998261  [   32/  306]
train() client id: f_00004-2-1 loss: 1.004027  [   64/  306]
train() client id: f_00004-2-2 loss: 0.867939  [   96/  306]
train() client id: f_00004-2-3 loss: 0.928768  [  128/  306]
train() client id: f_00004-2-4 loss: 0.921871  [  160/  306]
train() client id: f_00004-2-5 loss: 0.807021  [  192/  306]
train() client id: f_00004-2-6 loss: 1.011338  [  224/  306]
train() client id: f_00004-2-7 loss: 0.997489  [  256/  306]
train() client id: f_00004-2-8 loss: 0.952559  [  288/  306]
train() client id: f_00004-3-0 loss: 0.917863  [   32/  306]
train() client id: f_00004-3-1 loss: 1.013602  [   64/  306]
train() client id: f_00004-3-2 loss: 1.019864  [   96/  306]
train() client id: f_00004-3-3 loss: 0.931068  [  128/  306]
train() client id: f_00004-3-4 loss: 0.903216  [  160/  306]
train() client id: f_00004-3-5 loss: 0.947185  [  192/  306]
train() client id: f_00004-3-6 loss: 0.912477  [  224/  306]
train() client id: f_00004-3-7 loss: 0.930876  [  256/  306]
train() client id: f_00004-3-8 loss: 0.849255  [  288/  306]
train() client id: f_00004-4-0 loss: 0.991976  [   32/  306]
train() client id: f_00004-4-1 loss: 0.903481  [   64/  306]
train() client id: f_00004-4-2 loss: 0.934172  [   96/  306]
train() client id: f_00004-4-3 loss: 0.925180  [  128/  306]
train() client id: f_00004-4-4 loss: 0.905150  [  160/  306]
train() client id: f_00004-4-5 loss: 1.013853  [  192/  306]
train() client id: f_00004-4-6 loss: 0.871203  [  224/  306]
train() client id: f_00004-4-7 loss: 0.967787  [  256/  306]
train() client id: f_00004-4-8 loss: 0.914476  [  288/  306]
train() client id: f_00004-5-0 loss: 0.917820  [   32/  306]
train() client id: f_00004-5-1 loss: 1.033160  [   64/  306]
train() client id: f_00004-5-2 loss: 0.913347  [   96/  306]
train() client id: f_00004-5-3 loss: 0.710463  [  128/  306]
train() client id: f_00004-5-4 loss: 0.895256  [  160/  306]
train() client id: f_00004-5-5 loss: 0.975273  [  192/  306]
train() client id: f_00004-5-6 loss: 1.140544  [  224/  306]
train() client id: f_00004-5-7 loss: 0.935006  [  256/  306]
train() client id: f_00004-5-8 loss: 0.943632  [  288/  306]
train() client id: f_00004-6-0 loss: 0.946987  [   32/  306]
train() client id: f_00004-6-1 loss: 0.908464  [   64/  306]
train() client id: f_00004-6-2 loss: 0.951099  [   96/  306]
train() client id: f_00004-6-3 loss: 0.997020  [  128/  306]
train() client id: f_00004-6-4 loss: 0.862055  [  160/  306]
train() client id: f_00004-6-5 loss: 0.985425  [  192/  306]
train() client id: f_00004-6-6 loss: 1.063201  [  224/  306]
train() client id: f_00004-6-7 loss: 0.833939  [  256/  306]
train() client id: f_00004-6-8 loss: 0.998200  [  288/  306]
train() client id: f_00004-7-0 loss: 0.960529  [   32/  306]
train() client id: f_00004-7-1 loss: 0.880819  [   64/  306]
train() client id: f_00004-7-2 loss: 0.925264  [   96/  306]
train() client id: f_00004-7-3 loss: 1.009199  [  128/  306]
train() client id: f_00004-7-4 loss: 0.993213  [  160/  306]
train() client id: f_00004-7-5 loss: 0.991829  [  192/  306]
train() client id: f_00004-7-6 loss: 0.887433  [  224/  306]
train() client id: f_00004-7-7 loss: 0.881577  [  256/  306]
train() client id: f_00004-7-8 loss: 0.976090  [  288/  306]
train() client id: f_00004-8-0 loss: 1.075304  [   32/  306]
train() client id: f_00004-8-1 loss: 0.869311  [   64/  306]
train() client id: f_00004-8-2 loss: 0.845156  [   96/  306]
train() client id: f_00004-8-3 loss: 0.821007  [  128/  306]
train() client id: f_00004-8-4 loss: 0.895668  [  160/  306]
train() client id: f_00004-8-5 loss: 0.992181  [  192/  306]
train() client id: f_00004-8-6 loss: 1.038046  [  224/  306]
train() client id: f_00004-8-7 loss: 0.995427  [  256/  306]
train() client id: f_00004-8-8 loss: 0.983458  [  288/  306]
train() client id: f_00004-9-0 loss: 0.935892  [   32/  306]
train() client id: f_00004-9-1 loss: 0.875500  [   64/  306]
train() client id: f_00004-9-2 loss: 0.964603  [   96/  306]
train() client id: f_00004-9-3 loss: 0.989850  [  128/  306]
train() client id: f_00004-9-4 loss: 0.966384  [  160/  306]
train() client id: f_00004-9-5 loss: 0.848357  [  192/  306]
train() client id: f_00004-9-6 loss: 1.045978  [  224/  306]
train() client id: f_00004-9-7 loss: 1.006331  [  256/  306]
train() client id: f_00004-9-8 loss: 0.872287  [  288/  306]
train() client id: f_00004-10-0 loss: 0.867717  [   32/  306]
train() client id: f_00004-10-1 loss: 0.945115  [   64/  306]
train() client id: f_00004-10-2 loss: 1.009441  [   96/  306]
train() client id: f_00004-10-3 loss: 0.910069  [  128/  306]
train() client id: f_00004-10-4 loss: 0.850175  [  160/  306]
train() client id: f_00004-10-5 loss: 0.998490  [  192/  306]
train() client id: f_00004-10-6 loss: 0.863654  [  224/  306]
train() client id: f_00004-10-7 loss: 1.067238  [  256/  306]
train() client id: f_00004-10-8 loss: 0.931967  [  288/  306]
train() client id: f_00004-11-0 loss: 0.868195  [   32/  306]
train() client id: f_00004-11-1 loss: 1.010638  [   64/  306]
train() client id: f_00004-11-2 loss: 0.953181  [   96/  306]
train() client id: f_00004-11-3 loss: 0.955037  [  128/  306]
train() client id: f_00004-11-4 loss: 0.935372  [  160/  306]
train() client id: f_00004-11-5 loss: 0.893201  [  192/  306]
train() client id: f_00004-11-6 loss: 0.855483  [  224/  306]
train() client id: f_00004-11-7 loss: 0.965827  [  256/  306]
train() client id: f_00004-11-8 loss: 1.019272  [  288/  306]
train() client id: f_00004-12-0 loss: 1.041422  [   32/  306]
train() client id: f_00004-12-1 loss: 0.913196  [   64/  306]
train() client id: f_00004-12-2 loss: 0.864991  [   96/  306]
train() client id: f_00004-12-3 loss: 0.926288  [  128/  306]
train() client id: f_00004-12-4 loss: 0.921950  [  160/  306]
train() client id: f_00004-12-5 loss: 0.949560  [  192/  306]
train() client id: f_00004-12-6 loss: 1.001952  [  224/  306]
train() client id: f_00004-12-7 loss: 0.934866  [  256/  306]
train() client id: f_00004-12-8 loss: 0.959666  [  288/  306]
train() client id: f_00005-0-0 loss: 0.786306  [   32/  146]
train() client id: f_00005-0-1 loss: 0.864200  [   64/  146]
train() client id: f_00005-0-2 loss: 0.851299  [   96/  146]
train() client id: f_00005-0-3 loss: 0.983001  [  128/  146]
train() client id: f_00005-1-0 loss: 0.765449  [   32/  146]
train() client id: f_00005-1-1 loss: 0.797009  [   64/  146]
train() client id: f_00005-1-2 loss: 0.796946  [   96/  146]
train() client id: f_00005-1-3 loss: 0.924981  [  128/  146]
train() client id: f_00005-2-0 loss: 0.693529  [   32/  146]
train() client id: f_00005-2-1 loss: 1.021538  [   64/  146]
train() client id: f_00005-2-2 loss: 0.758294  [   96/  146]
train() client id: f_00005-2-3 loss: 0.815641  [  128/  146]
train() client id: f_00005-3-0 loss: 0.797430  [   32/  146]
train() client id: f_00005-3-1 loss: 0.715048  [   64/  146]
train() client id: f_00005-3-2 loss: 0.878698  [   96/  146]
train() client id: f_00005-3-3 loss: 0.987711  [  128/  146]
train() client id: f_00005-4-0 loss: 0.881619  [   32/  146]
train() client id: f_00005-4-1 loss: 0.867176  [   64/  146]
train() client id: f_00005-4-2 loss: 0.708681  [   96/  146]
train() client id: f_00005-4-3 loss: 0.789894  [  128/  146]
train() client id: f_00005-5-0 loss: 0.848533  [   32/  146]
train() client id: f_00005-5-1 loss: 0.897380  [   64/  146]
train() client id: f_00005-5-2 loss: 0.825461  [   96/  146]
train() client id: f_00005-5-3 loss: 0.900143  [  128/  146]
train() client id: f_00005-6-0 loss: 0.784747  [   32/  146]
train() client id: f_00005-6-1 loss: 0.811669  [   64/  146]
train() client id: f_00005-6-2 loss: 0.807447  [   96/  146]
train() client id: f_00005-6-3 loss: 0.962130  [  128/  146]
train() client id: f_00005-7-0 loss: 1.086575  [   32/  146]
train() client id: f_00005-7-1 loss: 0.807279  [   64/  146]
train() client id: f_00005-7-2 loss: 0.664243  [   96/  146]
train() client id: f_00005-7-3 loss: 0.712331  [  128/  146]
train() client id: f_00005-8-0 loss: 0.803155  [   32/  146]
train() client id: f_00005-8-1 loss: 0.756862  [   64/  146]
train() client id: f_00005-8-2 loss: 0.814390  [   96/  146]
train() client id: f_00005-8-3 loss: 0.865645  [  128/  146]
train() client id: f_00005-9-0 loss: 0.737753  [   32/  146]
train() client id: f_00005-9-1 loss: 0.924586  [   64/  146]
train() client id: f_00005-9-2 loss: 0.848811  [   96/  146]
train() client id: f_00005-9-3 loss: 0.742242  [  128/  146]
train() client id: f_00005-10-0 loss: 0.764862  [   32/  146]
train() client id: f_00005-10-1 loss: 0.686821  [   64/  146]
train() client id: f_00005-10-2 loss: 1.099886  [   96/  146]
train() client id: f_00005-10-3 loss: 0.882747  [  128/  146]
train() client id: f_00005-11-0 loss: 0.662860  [   32/  146]
train() client id: f_00005-11-1 loss: 0.625093  [   64/  146]
train() client id: f_00005-11-2 loss: 1.097038  [   96/  146]
train() client id: f_00005-11-3 loss: 0.982779  [  128/  146]
train() client id: f_00005-12-0 loss: 0.724781  [   32/  146]
train() client id: f_00005-12-1 loss: 0.922803  [   64/  146]
train() client id: f_00005-12-2 loss: 0.802626  [   96/  146]
train() client id: f_00005-12-3 loss: 0.916446  [  128/  146]
train() client id: f_00006-0-0 loss: 0.596602  [   32/   54]
train() client id: f_00006-1-0 loss: 0.602264  [   32/   54]
train() client id: f_00006-2-0 loss: 0.552078  [   32/   54]
train() client id: f_00006-3-0 loss: 0.509097  [   32/   54]
train() client id: f_00006-4-0 loss: 0.604994  [   32/   54]
train() client id: f_00006-5-0 loss: 0.551942  [   32/   54]
train() client id: f_00006-6-0 loss: 0.593814  [   32/   54]
train() client id: f_00006-7-0 loss: 0.561414  [   32/   54]
train() client id: f_00006-8-0 loss: 0.551073  [   32/   54]
train() client id: f_00006-9-0 loss: 0.522714  [   32/   54]
train() client id: f_00006-10-0 loss: 0.612685  [   32/   54]
train() client id: f_00006-11-0 loss: 0.590850  [   32/   54]
train() client id: f_00006-12-0 loss: 0.566959  [   32/   54]
train() client id: f_00007-0-0 loss: 0.437807  [   32/  179]
train() client id: f_00007-0-1 loss: 0.574433  [   64/  179]
train() client id: f_00007-0-2 loss: 0.614353  [   96/  179]
train() client id: f_00007-0-3 loss: 0.587255  [  128/  179]
train() client id: f_00007-0-4 loss: 0.501894  [  160/  179]
train() client id: f_00007-1-0 loss: 0.509287  [   32/  179]
train() client id: f_00007-1-1 loss: 0.338946  [   64/  179]
train() client id: f_00007-1-2 loss: 0.556803  [   96/  179]
train() client id: f_00007-1-3 loss: 0.558318  [  128/  179]
train() client id: f_00007-1-4 loss: 0.575411  [  160/  179]
train() client id: f_00007-2-0 loss: 0.473419  [   32/  179]
train() client id: f_00007-2-1 loss: 0.451249  [   64/  179]
train() client id: f_00007-2-2 loss: 0.606273  [   96/  179]
train() client id: f_00007-2-3 loss: 0.521904  [  128/  179]
train() client id: f_00007-2-4 loss: 0.524288  [  160/  179]
train() client id: f_00007-3-0 loss: 0.349972  [   32/  179]
train() client id: f_00007-3-1 loss: 0.741922  [   64/  179]
train() client id: f_00007-3-2 loss: 0.476468  [   96/  179]
train() client id: f_00007-3-3 loss: 0.501396  [  128/  179]
train() client id: f_00007-3-4 loss: 0.363557  [  160/  179]
train() client id: f_00007-4-0 loss: 0.503263  [   32/  179]
train() client id: f_00007-4-1 loss: 0.324946  [   64/  179]
train() client id: f_00007-4-2 loss: 0.466350  [   96/  179]
train() client id: f_00007-4-3 loss: 0.638737  [  128/  179]
train() client id: f_00007-4-4 loss: 0.517406  [  160/  179]
train() client id: f_00007-5-0 loss: 0.617827  [   32/  179]
train() client id: f_00007-5-1 loss: 0.496226  [   64/  179]
train() client id: f_00007-5-2 loss: 0.459051  [   96/  179]
train() client id: f_00007-5-3 loss: 0.321962  [  128/  179]
train() client id: f_00007-5-4 loss: 0.424849  [  160/  179]
train() client id: f_00007-6-0 loss: 0.357240  [   32/  179]
train() client id: f_00007-6-1 loss: 0.486581  [   64/  179]
train() client id: f_00007-6-2 loss: 0.516959  [   96/  179]
train() client id: f_00007-6-3 loss: 0.539728  [  128/  179]
train() client id: f_00007-6-4 loss: 0.413549  [  160/  179]
train() client id: f_00007-7-0 loss: 0.314727  [   32/  179]
train() client id: f_00007-7-1 loss: 0.481278  [   64/  179]
train() client id: f_00007-7-2 loss: 0.491280  [   96/  179]
train() client id: f_00007-7-3 loss: 0.583191  [  128/  179]
train() client id: f_00007-7-4 loss: 0.502796  [  160/  179]
train() client id: f_00007-8-0 loss: 0.635992  [   32/  179]
train() client id: f_00007-8-1 loss: 0.552596  [   64/  179]
train() client id: f_00007-8-2 loss: 0.357406  [   96/  179]
train() client id: f_00007-8-3 loss: 0.389659  [  128/  179]
train() client id: f_00007-8-4 loss: 0.337356  [  160/  179]
train() client id: f_00007-9-0 loss: 0.545661  [   32/  179]
train() client id: f_00007-9-1 loss: 0.402879  [   64/  179]
train() client id: f_00007-9-2 loss: 0.431745  [   96/  179]
train() client id: f_00007-9-3 loss: 0.388456  [  128/  179]
train() client id: f_00007-9-4 loss: 0.550669  [  160/  179]
train() client id: f_00007-10-0 loss: 0.480922  [   32/  179]
train() client id: f_00007-10-1 loss: 0.518891  [   64/  179]
train() client id: f_00007-10-2 loss: 0.482230  [   96/  179]
train() client id: f_00007-10-3 loss: 0.527721  [  128/  179]
train() client id: f_00007-10-4 loss: 0.315674  [  160/  179]
train() client id: f_00007-11-0 loss: 0.446992  [   32/  179]
train() client id: f_00007-11-1 loss: 0.525485  [   64/  179]
train() client id: f_00007-11-2 loss: 0.302302  [   96/  179]
train() client id: f_00007-11-3 loss: 0.410744  [  128/  179]
train() client id: f_00007-11-4 loss: 0.418098  [  160/  179]
train() client id: f_00007-12-0 loss: 0.466167  [   32/  179]
train() client id: f_00007-12-1 loss: 0.408237  [   64/  179]
train() client id: f_00007-12-2 loss: 0.456684  [   96/  179]
train() client id: f_00007-12-3 loss: 0.290586  [  128/  179]
train() client id: f_00007-12-4 loss: 0.604917  [  160/  179]
train() client id: f_00008-0-0 loss: 0.719065  [   32/  130]
train() client id: f_00008-0-1 loss: 0.793338  [   64/  130]
train() client id: f_00008-0-2 loss: 0.730914  [   96/  130]
train() client id: f_00008-0-3 loss: 0.740153  [  128/  130]
train() client id: f_00008-1-0 loss: 0.702686  [   32/  130]
train() client id: f_00008-1-1 loss: 0.774632  [   64/  130]
train() client id: f_00008-1-2 loss: 0.784263  [   96/  130]
train() client id: f_00008-1-3 loss: 0.717376  [  128/  130]
train() client id: f_00008-2-0 loss: 0.669394  [   32/  130]
train() client id: f_00008-2-1 loss: 0.715476  [   64/  130]
train() client id: f_00008-2-2 loss: 0.853139  [   96/  130]
train() client id: f_00008-2-3 loss: 0.723078  [  128/  130]
train() client id: f_00008-3-0 loss: 0.903491  [   32/  130]
train() client id: f_00008-3-1 loss: 0.663375  [   64/  130]
train() client id: f_00008-3-2 loss: 0.637996  [   96/  130]
train() client id: f_00008-3-3 loss: 0.763739  [  128/  130]
train() client id: f_00008-4-0 loss: 0.822402  [   32/  130]
train() client id: f_00008-4-1 loss: 0.740347  [   64/  130]
train() client id: f_00008-4-2 loss: 0.723202  [   96/  130]
train() client id: f_00008-4-3 loss: 0.678933  [  128/  130]
train() client id: f_00008-5-0 loss: 0.844058  [   32/  130]
train() client id: f_00008-5-1 loss: 0.702873  [   64/  130]
train() client id: f_00008-5-2 loss: 0.762168  [   96/  130]
train() client id: f_00008-5-3 loss: 0.646282  [  128/  130]
train() client id: f_00008-6-0 loss: 0.612632  [   32/  130]
train() client id: f_00008-6-1 loss: 0.669302  [   64/  130]
train() client id: f_00008-6-2 loss: 0.857468  [   96/  130]
train() client id: f_00008-6-3 loss: 0.808877  [  128/  130]
train() client id: f_00008-7-0 loss: 0.835870  [   32/  130]
train() client id: f_00008-7-1 loss: 0.648546  [   64/  130]
train() client id: f_00008-7-2 loss: 0.784415  [   96/  130]
train() client id: f_00008-7-3 loss: 0.685352  [  128/  130]
train() client id: f_00008-8-0 loss: 0.739162  [   32/  130]
train() client id: f_00008-8-1 loss: 0.752614  [   64/  130]
train() client id: f_00008-8-2 loss: 0.716613  [   96/  130]
train() client id: f_00008-8-3 loss: 0.688762  [  128/  130]
train() client id: f_00008-9-0 loss: 0.726896  [   32/  130]
train() client id: f_00008-9-1 loss: 0.617591  [   64/  130]
train() client id: f_00008-9-2 loss: 0.764582  [   96/  130]
train() client id: f_00008-9-3 loss: 0.837432  [  128/  130]
train() client id: f_00008-10-0 loss: 0.779039  [   32/  130]
train() client id: f_00008-10-1 loss: 0.661701  [   64/  130]
train() client id: f_00008-10-2 loss: 0.736733  [   96/  130]
train() client id: f_00008-10-3 loss: 0.737163  [  128/  130]
train() client id: f_00008-11-0 loss: 0.777355  [   32/  130]
train() client id: f_00008-11-1 loss: 0.693653  [   64/  130]
train() client id: f_00008-11-2 loss: 0.709273  [   96/  130]
train() client id: f_00008-11-3 loss: 0.738476  [  128/  130]
train() client id: f_00008-12-0 loss: 0.679198  [   32/  130]
train() client id: f_00008-12-1 loss: 0.692441  [   64/  130]
train() client id: f_00008-12-2 loss: 0.707022  [   96/  130]
train() client id: f_00008-12-3 loss: 0.860011  [  128/  130]
train() client id: f_00009-0-0 loss: 1.198692  [   32/  118]
train() client id: f_00009-0-1 loss: 1.136172  [   64/  118]
train() client id: f_00009-0-2 loss: 1.076399  [   96/  118]
train() client id: f_00009-1-0 loss: 1.085585  [   32/  118]
train() client id: f_00009-1-1 loss: 1.223333  [   64/  118]
train() client id: f_00009-1-2 loss: 1.018019  [   96/  118]
train() client id: f_00009-2-0 loss: 1.036802  [   32/  118]
train() client id: f_00009-2-1 loss: 1.062864  [   64/  118]
train() client id: f_00009-2-2 loss: 1.065155  [   96/  118]
train() client id: f_00009-3-0 loss: 1.046864  [   32/  118]
train() client id: f_00009-3-1 loss: 0.956499  [   64/  118]
train() client id: f_00009-3-2 loss: 1.073056  [   96/  118]
train() client id: f_00009-4-0 loss: 0.940342  [   32/  118]
train() client id: f_00009-4-1 loss: 1.010706  [   64/  118]
train() client id: f_00009-4-2 loss: 1.061594  [   96/  118]
train() client id: f_00009-5-0 loss: 0.858085  [   32/  118]
train() client id: f_00009-5-1 loss: 0.899799  [   64/  118]
train() client id: f_00009-5-2 loss: 1.091537  [   96/  118]
train() client id: f_00009-6-0 loss: 1.010313  [   32/  118]
train() client id: f_00009-6-1 loss: 1.001425  [   64/  118]
train() client id: f_00009-6-2 loss: 0.814375  [   96/  118]
train() client id: f_00009-7-0 loss: 0.907039  [   32/  118]
train() client id: f_00009-7-1 loss: 0.862540  [   64/  118]
train() client id: f_00009-7-2 loss: 1.040678  [   96/  118]
train() client id: f_00009-8-0 loss: 0.936220  [   32/  118]
train() client id: f_00009-8-1 loss: 0.940910  [   64/  118]
train() client id: f_00009-8-2 loss: 0.887548  [   96/  118]
train() client id: f_00009-9-0 loss: 0.778482  [   32/  118]
train() client id: f_00009-9-1 loss: 1.004344  [   64/  118]
train() client id: f_00009-9-2 loss: 0.965053  [   96/  118]
train() client id: f_00009-10-0 loss: 0.940374  [   32/  118]
train() client id: f_00009-10-1 loss: 0.830527  [   64/  118]
train() client id: f_00009-10-2 loss: 0.873377  [   96/  118]
train() client id: f_00009-11-0 loss: 0.920035  [   32/  118]
train() client id: f_00009-11-1 loss: 0.910937  [   64/  118]
train() client id: f_00009-11-2 loss: 0.865556  [   96/  118]
train() client id: f_00009-12-0 loss: 0.905187  [   32/  118]
train() client id: f_00009-12-1 loss: 0.927227  [   64/  118]
train() client id: f_00009-12-2 loss: 0.874404  [   96/  118]
At round 16 accuracy: 0.636604774535809
At round 16 training accuracy: 0.5808182427900738
At round 16 training loss: 0.8472608948958859
gradient difference: 0.42177024483680725
train() client id: f_00000-0-0 loss: 1.034492  [   32/  126]
train() client id: f_00000-0-1 loss: 1.148727  [   64/  126]
train() client id: f_00000-0-2 loss: 1.172517  [   96/  126]
train() client id: f_00000-1-0 loss: 1.022128  [   32/  126]
train() client id: f_00000-1-1 loss: 1.019005  [   64/  126]
train() client id: f_00000-1-2 loss: 1.296909  [   96/  126]
train() client id: f_00000-2-0 loss: 0.880131  [   32/  126]
train() client id: f_00000-2-1 loss: 0.989908  [   64/  126]
train() client id: f_00000-2-2 loss: 0.963870  [   96/  126]
train() client id: f_00000-3-0 loss: 0.919942  [   32/  126]
train() client id: f_00000-3-1 loss: 0.997107  [   64/  126]
train() client id: f_00000-3-2 loss: 1.010533  [   96/  126]
train() client id: f_00000-4-0 loss: 1.002575  [   32/  126]
train() client id: f_00000-4-1 loss: 0.908361  [   64/  126]
train() client id: f_00000-4-2 loss: 0.872510  [   96/  126]
train() client id: f_00000-5-0 loss: 0.948524  [   32/  126]
train() client id: f_00000-5-1 loss: 1.007852  [   64/  126]
train() client id: f_00000-5-2 loss: 0.802743  [   96/  126]
train() client id: f_00000-6-0 loss: 0.978996  [   32/  126]
train() client id: f_00000-6-1 loss: 0.814557  [   64/  126]
train() client id: f_00000-6-2 loss: 0.890300  [   96/  126]
train() client id: f_00000-7-0 loss: 0.917653  [   32/  126]
train() client id: f_00000-7-1 loss: 0.827631  [   64/  126]
train() client id: f_00000-7-2 loss: 0.925741  [   96/  126]
train() client id: f_00000-8-0 loss: 0.852457  [   32/  126]
train() client id: f_00000-8-1 loss: 0.811723  [   64/  126]
train() client id: f_00000-8-2 loss: 0.904835  [   96/  126]
train() client id: f_00000-9-0 loss: 0.972661  [   32/  126]
train() client id: f_00000-9-1 loss: 0.881087  [   64/  126]
train() client id: f_00000-9-2 loss: 0.774003  [   96/  126]
train() client id: f_00000-10-0 loss: 0.907883  [   32/  126]
train() client id: f_00000-10-1 loss: 0.868403  [   64/  126]
train() client id: f_00000-10-2 loss: 0.963617  [   96/  126]
train() client id: f_00000-11-0 loss: 0.857642  [   32/  126]
train() client id: f_00000-11-1 loss: 0.883912  [   64/  126]
train() client id: f_00000-11-2 loss: 0.776545  [   96/  126]
train() client id: f_00000-12-0 loss: 0.886895  [   32/  126]
train() client id: f_00000-12-1 loss: 0.864014  [   64/  126]
train() client id: f_00000-12-2 loss: 0.933024  [   96/  126]
train() client id: f_00001-0-0 loss: 0.454916  [   32/  265]
train() client id: f_00001-0-1 loss: 0.481451  [   64/  265]
train() client id: f_00001-0-2 loss: 0.612041  [   96/  265]
train() client id: f_00001-0-3 loss: 0.531113  [  128/  265]
train() client id: f_00001-0-4 loss: 0.459366  [  160/  265]
train() client id: f_00001-0-5 loss: 0.481642  [  192/  265]
train() client id: f_00001-0-6 loss: 0.621902  [  224/  265]
train() client id: f_00001-0-7 loss: 0.589082  [  256/  265]
train() client id: f_00001-1-0 loss: 0.533893  [   32/  265]
train() client id: f_00001-1-1 loss: 0.479044  [   64/  265]
train() client id: f_00001-1-2 loss: 0.560191  [   96/  265]
train() client id: f_00001-1-3 loss: 0.517983  [  128/  265]
train() client id: f_00001-1-4 loss: 0.507779  [  160/  265]
train() client id: f_00001-1-5 loss: 0.603386  [  192/  265]
train() client id: f_00001-1-6 loss: 0.528574  [  224/  265]
train() client id: f_00001-1-7 loss: 0.445666  [  256/  265]
train() client id: f_00001-2-0 loss: 0.578834  [   32/  265]
train() client id: f_00001-2-1 loss: 0.519740  [   64/  265]
train() client id: f_00001-2-2 loss: 0.519904  [   96/  265]
train() client id: f_00001-2-3 loss: 0.564210  [  128/  265]
train() client id: f_00001-2-4 loss: 0.506784  [  160/  265]
train() client id: f_00001-2-5 loss: 0.526529  [  192/  265]
train() client id: f_00001-2-6 loss: 0.493666  [  224/  265]
train() client id: f_00001-2-7 loss: 0.437204  [  256/  265]
train() client id: f_00001-3-0 loss: 0.530523  [   32/  265]
train() client id: f_00001-3-1 loss: 0.460299  [   64/  265]
train() client id: f_00001-3-2 loss: 0.593215  [   96/  265]
train() client id: f_00001-3-3 loss: 0.435533  [  128/  265]
train() client id: f_00001-3-4 loss: 0.432120  [  160/  265]
train() client id: f_00001-3-5 loss: 0.511626  [  192/  265]
train() client id: f_00001-3-6 loss: 0.678426  [  224/  265]
train() client id: f_00001-3-7 loss: 0.430240  [  256/  265]
train() client id: f_00001-4-0 loss: 0.501249  [   32/  265]
train() client id: f_00001-4-1 loss: 0.459648  [   64/  265]
train() client id: f_00001-4-2 loss: 0.549801  [   96/  265]
train() client id: f_00001-4-3 loss: 0.502297  [  128/  265]
train() client id: f_00001-4-4 loss: 0.499855  [  160/  265]
train() client id: f_00001-4-5 loss: 0.521330  [  192/  265]
train() client id: f_00001-4-6 loss: 0.429362  [  224/  265]
train() client id: f_00001-4-7 loss: 0.464115  [  256/  265]
train() client id: f_00001-5-0 loss: 0.438666  [   32/  265]
train() client id: f_00001-5-1 loss: 0.524077  [   64/  265]
train() client id: f_00001-5-2 loss: 0.464209  [   96/  265]
train() client id: f_00001-5-3 loss: 0.625703  [  128/  265]
train() client id: f_00001-5-4 loss: 0.496396  [  160/  265]
train() client id: f_00001-5-5 loss: 0.521216  [  192/  265]
train() client id: f_00001-5-6 loss: 0.517096  [  224/  265]
train() client id: f_00001-5-7 loss: 0.500824  [  256/  265]
train() client id: f_00001-6-0 loss: 0.499312  [   32/  265]
train() client id: f_00001-6-1 loss: 0.513762  [   64/  265]
train() client id: f_00001-6-2 loss: 0.560577  [   96/  265]
train() client id: f_00001-6-3 loss: 0.433389  [  128/  265]
train() client id: f_00001-6-4 loss: 0.549570  [  160/  265]
train() client id: f_00001-6-5 loss: 0.569925  [  192/  265]
train() client id: f_00001-6-6 loss: 0.449649  [  224/  265]
train() client id: f_00001-6-7 loss: 0.512804  [  256/  265]
train() client id: f_00001-7-0 loss: 0.438480  [   32/  265]
train() client id: f_00001-7-1 loss: 0.428469  [   64/  265]
train() client id: f_00001-7-2 loss: 0.466963  [   96/  265]
train() client id: f_00001-7-3 loss: 0.463427  [  128/  265]
train() client id: f_00001-7-4 loss: 0.547361  [  160/  265]
train() client id: f_00001-7-5 loss: 0.569206  [  192/  265]
train() client id: f_00001-7-6 loss: 0.593058  [  224/  265]
train() client id: f_00001-7-7 loss: 0.559163  [  256/  265]
train() client id: f_00001-8-0 loss: 0.551674  [   32/  265]
train() client id: f_00001-8-1 loss: 0.432794  [   64/  265]
train() client id: f_00001-8-2 loss: 0.554519  [   96/  265]
train() client id: f_00001-8-3 loss: 0.414558  [  128/  265]
train() client id: f_00001-8-4 loss: 0.512147  [  160/  265]
train() client id: f_00001-8-5 loss: 0.564163  [  192/  265]
train() client id: f_00001-8-6 loss: 0.564868  [  224/  265]
train() client id: f_00001-8-7 loss: 0.479892  [  256/  265]
train() client id: f_00001-9-0 loss: 0.431528  [   32/  265]
train() client id: f_00001-9-1 loss: 0.495652  [   64/  265]
train() client id: f_00001-9-2 loss: 0.619320  [   96/  265]
train() client id: f_00001-9-3 loss: 0.497810  [  128/  265]
train() client id: f_00001-9-4 loss: 0.443997  [  160/  265]
train() client id: f_00001-9-5 loss: 0.461508  [  192/  265]
train() client id: f_00001-9-6 loss: 0.517772  [  224/  265]
train() client id: f_00001-9-7 loss: 0.601017  [  256/  265]
train() client id: f_00001-10-0 loss: 0.580190  [   32/  265]
train() client id: f_00001-10-1 loss: 0.572906  [   64/  265]
train() client id: f_00001-10-2 loss: 0.407603  [   96/  265]
train() client id: f_00001-10-3 loss: 0.488118  [  128/  265]
train() client id: f_00001-10-4 loss: 0.565128  [  160/  265]
train() client id: f_00001-10-5 loss: 0.432404  [  192/  265]
train() client id: f_00001-10-6 loss: 0.539492  [  224/  265]
train() client id: f_00001-10-7 loss: 0.484322  [  256/  265]
train() client id: f_00001-11-0 loss: 0.448723  [   32/  265]
train() client id: f_00001-11-1 loss: 0.503722  [   64/  265]
train() client id: f_00001-11-2 loss: 0.572605  [   96/  265]
train() client id: f_00001-11-3 loss: 0.514656  [  128/  265]
train() client id: f_00001-11-4 loss: 0.559627  [  160/  265]
train() client id: f_00001-11-5 loss: 0.472213  [  192/  265]
train() client id: f_00001-11-6 loss: 0.434835  [  224/  265]
train() client id: f_00001-11-7 loss: 0.530820  [  256/  265]
train() client id: f_00001-12-0 loss: 0.454279  [   32/  265]
train() client id: f_00001-12-1 loss: 0.605537  [   64/  265]
train() client id: f_00001-12-2 loss: 0.478950  [   96/  265]
train() client id: f_00001-12-3 loss: 0.492242  [  128/  265]
train() client id: f_00001-12-4 loss: 0.543952  [  160/  265]
train() client id: f_00001-12-5 loss: 0.479733  [  192/  265]
train() client id: f_00001-12-6 loss: 0.455237  [  224/  265]
train() client id: f_00001-12-7 loss: 0.421274  [  256/  265]
train() client id: f_00002-0-0 loss: 1.212033  [   32/  124]
train() client id: f_00002-0-1 loss: 1.246845  [   64/  124]
train() client id: f_00002-0-2 loss: 1.337318  [   96/  124]
train() client id: f_00002-1-0 loss: 1.217546  [   32/  124]
train() client id: f_00002-1-1 loss: 1.335535  [   64/  124]
train() client id: f_00002-1-2 loss: 1.169491  [   96/  124]
train() client id: f_00002-2-0 loss: 1.184140  [   32/  124]
train() client id: f_00002-2-1 loss: 1.067210  [   64/  124]
train() client id: f_00002-2-2 loss: 1.148506  [   96/  124]
train() client id: f_00002-3-0 loss: 1.138593  [   32/  124]
train() client id: f_00002-3-1 loss: 1.142443  [   64/  124]
train() client id: f_00002-3-2 loss: 1.126032  [   96/  124]
train() client id: f_00002-4-0 loss: 1.138164  [   32/  124]
train() client id: f_00002-4-1 loss: 1.119792  [   64/  124]
train() client id: f_00002-4-2 loss: 1.039256  [   96/  124]
train() client id: f_00002-5-0 loss: 1.188211  [   32/  124]
train() client id: f_00002-5-1 loss: 0.961604  [   64/  124]
train() client id: f_00002-5-2 loss: 1.005433  [   96/  124]
train() client id: f_00002-6-0 loss: 0.902117  [   32/  124]
train() client id: f_00002-6-1 loss: 1.009568  [   64/  124]
train() client id: f_00002-6-2 loss: 1.219039  [   96/  124]
train() client id: f_00002-7-0 loss: 1.026609  [   32/  124]
train() client id: f_00002-7-1 loss: 0.975993  [   64/  124]
train() client id: f_00002-7-2 loss: 0.991425  [   96/  124]
train() client id: f_00002-8-0 loss: 0.983191  [   32/  124]
train() client id: f_00002-8-1 loss: 0.970926  [   64/  124]
train() client id: f_00002-8-2 loss: 1.065848  [   96/  124]
train() client id: f_00002-9-0 loss: 0.939758  [   32/  124]
train() client id: f_00002-9-1 loss: 0.931026  [   64/  124]
train() client id: f_00002-9-2 loss: 1.046574  [   96/  124]
train() client id: f_00002-10-0 loss: 0.964860  [   32/  124]
train() client id: f_00002-10-1 loss: 0.875302  [   64/  124]
train() client id: f_00002-10-2 loss: 0.895874  [   96/  124]
train() client id: f_00002-11-0 loss: 0.899670  [   32/  124]
train() client id: f_00002-11-1 loss: 0.859809  [   64/  124]
train() client id: f_00002-11-2 loss: 1.088114  [   96/  124]
train() client id: f_00002-12-0 loss: 0.997262  [   32/  124]
train() client id: f_00002-12-1 loss: 0.913973  [   64/  124]
train() client id: f_00002-12-2 loss: 0.961795  [   96/  124]
train() client id: f_00003-0-0 loss: 0.773204  [   32/   43]
train() client id: f_00003-1-0 loss: 0.824202  [   32/   43]
train() client id: f_00003-2-0 loss: 0.899334  [   32/   43]
train() client id: f_00003-3-0 loss: 0.817359  [   32/   43]
train() client id: f_00003-4-0 loss: 0.931752  [   32/   43]
train() client id: f_00003-5-0 loss: 0.753685  [   32/   43]
train() client id: f_00003-6-0 loss: 0.878100  [   32/   43]
train() client id: f_00003-7-0 loss: 0.818169  [   32/   43]
train() client id: f_00003-8-0 loss: 0.728843  [   32/   43]
train() client id: f_00003-9-0 loss: 0.827408  [   32/   43]
train() client id: f_00003-10-0 loss: 0.779135  [   32/   43]
train() client id: f_00003-11-0 loss: 0.642334  [   32/   43]
train() client id: f_00003-12-0 loss: 0.757017  [   32/   43]
train() client id: f_00004-0-0 loss: 0.863610  [   32/  306]
train() client id: f_00004-0-1 loss: 0.851474  [   64/  306]
train() client id: f_00004-0-2 loss: 0.999161  [   96/  306]
train() client id: f_00004-0-3 loss: 0.865040  [  128/  306]
train() client id: f_00004-0-4 loss: 0.722191  [  160/  306]
train() client id: f_00004-0-5 loss: 0.982792  [  192/  306]
train() client id: f_00004-0-6 loss: 0.956335  [  224/  306]
train() client id: f_00004-0-7 loss: 0.829734  [  256/  306]
train() client id: f_00004-0-8 loss: 0.975676  [  288/  306]
train() client id: f_00004-1-0 loss: 0.929676  [   32/  306]
train() client id: f_00004-1-1 loss: 0.699272  [   64/  306]
train() client id: f_00004-1-2 loss: 0.845386  [   96/  306]
train() client id: f_00004-1-3 loss: 0.959753  [  128/  306]
train() client id: f_00004-1-4 loss: 1.035672  [  160/  306]
train() client id: f_00004-1-5 loss: 0.825404  [  192/  306]
train() client id: f_00004-1-6 loss: 0.984286  [  224/  306]
train() client id: f_00004-1-7 loss: 0.740426  [  256/  306]
train() client id: f_00004-1-8 loss: 0.963803  [  288/  306]
train() client id: f_00004-2-0 loss: 0.901728  [   32/  306]
train() client id: f_00004-2-1 loss: 0.793527  [   64/  306]
train() client id: f_00004-2-2 loss: 0.783836  [   96/  306]
train() client id: f_00004-2-3 loss: 0.982424  [  128/  306]
train() client id: f_00004-2-4 loss: 0.855636  [  160/  306]
train() client id: f_00004-2-5 loss: 0.967183  [  192/  306]
train() client id: f_00004-2-6 loss: 0.894978  [  224/  306]
train() client id: f_00004-2-7 loss: 0.940450  [  256/  306]
train() client id: f_00004-2-8 loss: 0.879477  [  288/  306]
train() client id: f_00004-3-0 loss: 0.936387  [   32/  306]
train() client id: f_00004-3-1 loss: 0.839488  [   64/  306]
train() client id: f_00004-3-2 loss: 0.941687  [   96/  306]
train() client id: f_00004-3-3 loss: 0.769083  [  128/  306]
train() client id: f_00004-3-4 loss: 0.983224  [  160/  306]
train() client id: f_00004-3-5 loss: 0.810892  [  192/  306]
train() client id: f_00004-3-6 loss: 0.931491  [  224/  306]
train() client id: f_00004-3-7 loss: 0.896675  [  256/  306]
train() client id: f_00004-3-8 loss: 0.879441  [  288/  306]
train() client id: f_00004-4-0 loss: 0.868627  [   32/  306]
train() client id: f_00004-4-1 loss: 0.895134  [   64/  306]
train() client id: f_00004-4-2 loss: 0.813923  [   96/  306]
train() client id: f_00004-4-3 loss: 0.877367  [  128/  306]
train() client id: f_00004-4-4 loss: 0.923656  [  160/  306]
train() client id: f_00004-4-5 loss: 0.841129  [  192/  306]
train() client id: f_00004-4-6 loss: 0.977476  [  224/  306]
train() client id: f_00004-4-7 loss: 0.876323  [  256/  306]
train() client id: f_00004-4-8 loss: 0.895636  [  288/  306]
train() client id: f_00004-5-0 loss: 0.800887  [   32/  306]
train() client id: f_00004-5-1 loss: 0.909165  [   64/  306]
train() client id: f_00004-5-2 loss: 0.835983  [   96/  306]
train() client id: f_00004-5-3 loss: 0.917673  [  128/  306]
train() client id: f_00004-5-4 loss: 0.803284  [  160/  306]
train() client id: f_00004-5-5 loss: 0.971223  [  192/  306]
train() client id: f_00004-5-6 loss: 0.800046  [  224/  306]
train() client id: f_00004-5-7 loss: 0.884364  [  256/  306]
train() client id: f_00004-5-8 loss: 0.870833  [  288/  306]
train() client id: f_00004-6-0 loss: 0.856869  [   32/  306]
train() client id: f_00004-6-1 loss: 0.742617  [   64/  306]
train() client id: f_00004-6-2 loss: 1.084728  [   96/  306]
train() client id: f_00004-6-3 loss: 0.846560  [  128/  306]
train() client id: f_00004-6-4 loss: 0.926048  [  160/  306]
train() client id: f_00004-6-5 loss: 0.889376  [  192/  306]
train() client id: f_00004-6-6 loss: 0.830523  [  224/  306]
train() client id: f_00004-6-7 loss: 0.938905  [  256/  306]
train() client id: f_00004-6-8 loss: 0.823220  [  288/  306]
train() client id: f_00004-7-0 loss: 0.940995  [   32/  306]
train() client id: f_00004-7-1 loss: 0.940409  [   64/  306]
train() client id: f_00004-7-2 loss: 0.912350  [   96/  306]
train() client id: f_00004-7-3 loss: 0.908049  [  128/  306]
train() client id: f_00004-7-4 loss: 0.877287  [  160/  306]
train() client id: f_00004-7-5 loss: 0.751785  [  192/  306]
train() client id: f_00004-7-6 loss: 0.862729  [  224/  306]
train() client id: f_00004-7-7 loss: 0.828034  [  256/  306]
train() client id: f_00004-7-8 loss: 0.920818  [  288/  306]
train() client id: f_00004-8-0 loss: 0.946155  [   32/  306]
train() client id: f_00004-8-1 loss: 0.833140  [   64/  306]
train() client id: f_00004-8-2 loss: 0.865373  [   96/  306]
train() client id: f_00004-8-3 loss: 0.826942  [  128/  306]
train() client id: f_00004-8-4 loss: 1.046166  [  160/  306]
train() client id: f_00004-8-5 loss: 0.853478  [  192/  306]
train() client id: f_00004-8-6 loss: 0.838457  [  224/  306]
train() client id: f_00004-8-7 loss: 0.814093  [  256/  306]
train() client id: f_00004-8-8 loss: 0.840160  [  288/  306]
train() client id: f_00004-9-0 loss: 0.963064  [   32/  306]
train() client id: f_00004-9-1 loss: 0.840492  [   64/  306]
train() client id: f_00004-9-2 loss: 0.826967  [   96/  306]
train() client id: f_00004-9-3 loss: 0.740899  [  128/  306]
train() client id: f_00004-9-4 loss: 1.044600  [  160/  306]
train() client id: f_00004-9-5 loss: 0.978500  [  192/  306]
train() client id: f_00004-9-6 loss: 0.824756  [  224/  306]
train() client id: f_00004-9-7 loss: 0.905266  [  256/  306]
train() client id: f_00004-9-8 loss: 0.827310  [  288/  306]
train() client id: f_00004-10-0 loss: 0.889484  [   32/  306]
train() client id: f_00004-10-1 loss: 0.881948  [   64/  306]
train() client id: f_00004-10-2 loss: 0.836689  [   96/  306]
train() client id: f_00004-10-3 loss: 0.820362  [  128/  306]
train() client id: f_00004-10-4 loss: 0.828429  [  160/  306]
train() client id: f_00004-10-5 loss: 0.941875  [  192/  306]
train() client id: f_00004-10-6 loss: 0.946703  [  224/  306]
train() client id: f_00004-10-7 loss: 0.830007  [  256/  306]
train() client id: f_00004-10-8 loss: 0.838003  [  288/  306]
train() client id: f_00004-11-0 loss: 0.812330  [   32/  306]
train() client id: f_00004-11-1 loss: 0.825212  [   64/  306]
train() client id: f_00004-11-2 loss: 0.824561  [   96/  306]
train() client id: f_00004-11-3 loss: 0.848928  [  128/  306]
train() client id: f_00004-11-4 loss: 0.841613  [  160/  306]
train() client id: f_00004-11-5 loss: 0.998162  [  192/  306]
train() client id: f_00004-11-6 loss: 0.849429  [  224/  306]
train() client id: f_00004-11-7 loss: 0.977374  [  256/  306]
train() client id: f_00004-11-8 loss: 0.836145  [  288/  306]
train() client id: f_00004-12-0 loss: 0.787761  [   32/  306]
train() client id: f_00004-12-1 loss: 0.853087  [   64/  306]
train() client id: f_00004-12-2 loss: 0.881479  [   96/  306]
train() client id: f_00004-12-3 loss: 0.954490  [  128/  306]
train() client id: f_00004-12-4 loss: 0.822527  [  160/  306]
train() client id: f_00004-12-5 loss: 0.885757  [  192/  306]
train() client id: f_00004-12-6 loss: 0.800285  [  224/  306]
train() client id: f_00004-12-7 loss: 0.868432  [  256/  306]
train() client id: f_00004-12-8 loss: 0.956900  [  288/  306]
train() client id: f_00005-0-0 loss: 0.496944  [   32/  146]
train() client id: f_00005-0-1 loss: 0.739656  [   64/  146]
train() client id: f_00005-0-2 loss: 0.616171  [   96/  146]
train() client id: f_00005-0-3 loss: 0.675467  [  128/  146]
train() client id: f_00005-1-0 loss: 0.843029  [   32/  146]
train() client id: f_00005-1-1 loss: 0.540177  [   64/  146]
train() client id: f_00005-1-2 loss: 0.603566  [   96/  146]
train() client id: f_00005-1-3 loss: 0.585863  [  128/  146]
train() client id: f_00005-2-0 loss: 0.618469  [   32/  146]
train() client id: f_00005-2-1 loss: 0.702466  [   64/  146]
train() client id: f_00005-2-2 loss: 0.711396  [   96/  146]
train() client id: f_00005-2-3 loss: 0.628661  [  128/  146]
train() client id: f_00005-3-0 loss: 0.537262  [   32/  146]
train() client id: f_00005-3-1 loss: 0.701805  [   64/  146]
train() client id: f_00005-3-2 loss: 0.546855  [   96/  146]
train() client id: f_00005-3-3 loss: 0.836571  [  128/  146]
train() client id: f_00005-4-0 loss: 0.681292  [   32/  146]
train() client id: f_00005-4-1 loss: 0.632837  [   64/  146]
train() client id: f_00005-4-2 loss: 0.549701  [   96/  146]
train() client id: f_00005-4-3 loss: 0.597065  [  128/  146]
train() client id: f_00005-5-0 loss: 0.570023  [   32/  146]
train() client id: f_00005-5-1 loss: 0.843619  [   64/  146]
train() client id: f_00005-5-2 loss: 0.675842  [   96/  146]
train() client id: f_00005-5-3 loss: 0.498001  [  128/  146]
train() client id: f_00005-6-0 loss: 0.652190  [   32/  146]
train() client id: f_00005-6-1 loss: 0.618981  [   64/  146]
train() client id: f_00005-6-2 loss: 0.550166  [   96/  146]
train() client id: f_00005-6-3 loss: 0.757095  [  128/  146]
train() client id: f_00005-7-0 loss: 0.737064  [   32/  146]
train() client id: f_00005-7-1 loss: 0.566116  [   64/  146]
train() client id: f_00005-7-2 loss: 0.571408  [   96/  146]
train() client id: f_00005-7-3 loss: 0.658115  [  128/  146]
train() client id: f_00005-8-0 loss: 0.664008  [   32/  146]
train() client id: f_00005-8-1 loss: 0.640930  [   64/  146]
train() client id: f_00005-8-2 loss: 0.688974  [   96/  146]
train() client id: f_00005-8-3 loss: 0.710066  [  128/  146]
train() client id: f_00005-9-0 loss: 0.608859  [   32/  146]
train() client id: f_00005-9-1 loss: 0.631550  [   64/  146]
train() client id: f_00005-9-2 loss: 0.610519  [   96/  146]
train() client id: f_00005-9-3 loss: 0.789907  [  128/  146]
train() client id: f_00005-10-0 loss: 0.704502  [   32/  146]
train() client id: f_00005-10-1 loss: 0.519765  [   64/  146]
train() client id: f_00005-10-2 loss: 0.672194  [   96/  146]
train() client id: f_00005-10-3 loss: 0.686360  [  128/  146]
train() client id: f_00005-11-0 loss: 0.548375  [   32/  146]
train() client id: f_00005-11-1 loss: 0.721684  [   64/  146]
train() client id: f_00005-11-2 loss: 0.637503  [   96/  146]
train() client id: f_00005-11-3 loss: 0.541033  [  128/  146]
train() client id: f_00005-12-0 loss: 0.665840  [   32/  146]
train() client id: f_00005-12-1 loss: 0.431938  [   64/  146]
train() client id: f_00005-12-2 loss: 0.677851  [   96/  146]
train() client id: f_00005-12-3 loss: 0.751476  [  128/  146]
train() client id: f_00006-0-0 loss: 0.629927  [   32/   54]
train() client id: f_00006-1-0 loss: 0.643957  [   32/   54]
train() client id: f_00006-2-0 loss: 0.614879  [   32/   54]
train() client id: f_00006-3-0 loss: 0.657785  [   32/   54]
train() client id: f_00006-4-0 loss: 0.651941  [   32/   54]
train() client id: f_00006-5-0 loss: 0.614205  [   32/   54]
train() client id: f_00006-6-0 loss: 0.596452  [   32/   54]
train() client id: f_00006-7-0 loss: 0.639842  [   32/   54]
train() client id: f_00006-8-0 loss: 0.650771  [   32/   54]
train() client id: f_00006-9-0 loss: 0.612964  [   32/   54]
train() client id: f_00006-10-0 loss: 0.569441  [   32/   54]
train() client id: f_00006-11-0 loss: 0.618704  [   32/   54]
train() client id: f_00006-12-0 loss: 0.605610  [   32/   54]
train() client id: f_00007-0-0 loss: 0.454424  [   32/  179]
train() client id: f_00007-0-1 loss: 0.480930  [   64/  179]
train() client id: f_00007-0-2 loss: 0.331654  [   96/  179]
train() client id: f_00007-0-3 loss: 0.579157  [  128/  179]
train() client id: f_00007-0-4 loss: 0.658752  [  160/  179]
train() client id: f_00007-1-0 loss: 0.454724  [   32/  179]
train() client id: f_00007-1-1 loss: 0.414821  [   64/  179]
train() client id: f_00007-1-2 loss: 0.460845  [   96/  179]
train() client id: f_00007-1-3 loss: 0.598435  [  128/  179]
train() client id: f_00007-1-4 loss: 0.417747  [  160/  179]
train() client id: f_00007-2-0 loss: 0.560355  [   32/  179]
train() client id: f_00007-2-1 loss: 0.618724  [   64/  179]
train() client id: f_00007-2-2 loss: 0.449358  [   96/  179]
train() client id: f_00007-2-3 loss: 0.423001  [  128/  179]
train() client id: f_00007-2-4 loss: 0.329536  [  160/  179]
train() client id: f_00007-3-0 loss: 0.483783  [   32/  179]
train() client id: f_00007-3-1 loss: 0.397179  [   64/  179]
train() client id: f_00007-3-2 loss: 0.524619  [   96/  179]
train() client id: f_00007-3-3 loss: 0.393991  [  128/  179]
train() client id: f_00007-3-4 loss: 0.538580  [  160/  179]
train() client id: f_00007-4-0 loss: 0.413230  [   32/  179]
train() client id: f_00007-4-1 loss: 0.516128  [   64/  179]
train() client id: f_00007-4-2 loss: 0.551031  [   96/  179]
train() client id: f_00007-4-3 loss: 0.329942  [  128/  179]
train() client id: f_00007-4-4 loss: 0.506907  [  160/  179]
train() client id: f_00007-5-0 loss: 0.401635  [   32/  179]
train() client id: f_00007-5-1 loss: 0.415910  [   64/  179]
train() client id: f_00007-5-2 loss: 0.299783  [   96/  179]
train() client id: f_00007-5-3 loss: 0.495009  [  128/  179]
train() client id: f_00007-5-4 loss: 0.650597  [  160/  179]
train() client id: f_00007-6-0 loss: 0.377942  [   32/  179]
train() client id: f_00007-6-1 loss: 0.385894  [   64/  179]
train() client id: f_00007-6-2 loss: 0.458244  [   96/  179]
train() client id: f_00007-6-3 loss: 0.409702  [  128/  179]
train() client id: f_00007-6-4 loss: 0.459120  [  160/  179]
train() client id: f_00007-7-0 loss: 0.530538  [   32/  179]
train() client id: f_00007-7-1 loss: 0.316305  [   64/  179]
train() client id: f_00007-7-2 loss: 0.473155  [   96/  179]
train() client id: f_00007-7-3 loss: 0.268318  [  128/  179]
train() client id: f_00007-7-4 loss: 0.449073  [  160/  179]
train() client id: f_00007-8-0 loss: 0.339463  [   32/  179]
train() client id: f_00007-8-1 loss: 0.468962  [   64/  179]
train() client id: f_00007-8-2 loss: 0.559126  [   96/  179]
train() client id: f_00007-8-3 loss: 0.285868  [  128/  179]
train() client id: f_00007-8-4 loss: 0.450770  [  160/  179]
train() client id: f_00007-9-0 loss: 0.537408  [   32/  179]
train() client id: f_00007-9-1 loss: 0.370527  [   64/  179]
train() client id: f_00007-9-2 loss: 0.605756  [   96/  179]
train() client id: f_00007-9-3 loss: 0.420128  [  128/  179]
train() client id: f_00007-9-4 loss: 0.239296  [  160/  179]
train() client id: f_00007-10-0 loss: 0.397902  [   32/  179]
train() client id: f_00007-10-1 loss: 0.472492  [   64/  179]
train() client id: f_00007-10-2 loss: 0.522434  [   96/  179]
train() client id: f_00007-10-3 loss: 0.343984  [  128/  179]
train() client id: f_00007-10-4 loss: 0.423353  [  160/  179]
train() client id: f_00007-11-0 loss: 0.449406  [   32/  179]
train() client id: f_00007-11-1 loss: 0.515716  [   64/  179]
train() client id: f_00007-11-2 loss: 0.282449  [   96/  179]
train() client id: f_00007-11-3 loss: 0.245133  [  128/  179]
train() client id: f_00007-11-4 loss: 0.484804  [  160/  179]
train() client id: f_00007-12-0 loss: 0.541835  [   32/  179]
train() client id: f_00007-12-1 loss: 0.263102  [   64/  179]
train() client id: f_00007-12-2 loss: 0.434636  [   96/  179]
train() client id: f_00007-12-3 loss: 0.506153  [  128/  179]
train() client id: f_00007-12-4 loss: 0.366776  [  160/  179]
train() client id: f_00008-0-0 loss: 0.649145  [   32/  130]
train() client id: f_00008-0-1 loss: 0.685403  [   64/  130]
train() client id: f_00008-0-2 loss: 0.622478  [   96/  130]
train() client id: f_00008-0-3 loss: 0.716422  [  128/  130]
train() client id: f_00008-1-0 loss: 0.642188  [   32/  130]
train() client id: f_00008-1-1 loss: 0.628003  [   64/  130]
train() client id: f_00008-1-2 loss: 0.706333  [   96/  130]
train() client id: f_00008-1-3 loss: 0.716655  [  128/  130]
train() client id: f_00008-2-0 loss: 0.795107  [   32/  130]
train() client id: f_00008-2-1 loss: 0.621386  [   64/  130]
train() client id: f_00008-2-2 loss: 0.562497  [   96/  130]
train() client id: f_00008-2-3 loss: 0.673464  [  128/  130]
train() client id: f_00008-3-0 loss: 0.739893  [   32/  130]
train() client id: f_00008-3-1 loss: 0.530708  [   64/  130]
train() client id: f_00008-3-2 loss: 0.660525  [   96/  130]
train() client id: f_00008-3-3 loss: 0.721088  [  128/  130]
train() client id: f_00008-4-0 loss: 0.607751  [   32/  130]
train() client id: f_00008-4-1 loss: 0.653803  [   64/  130]
train() client id: f_00008-4-2 loss: 0.621213  [   96/  130]
train() client id: f_00008-4-3 loss: 0.730902  [  128/  130]
train() client id: f_00008-5-0 loss: 0.628984  [   32/  130]
train() client id: f_00008-5-1 loss: 0.813687  [   64/  130]
train() client id: f_00008-5-2 loss: 0.601023  [   96/  130]
train() client id: f_00008-5-3 loss: 0.636385  [  128/  130]
train() client id: f_00008-6-0 loss: 0.617204  [   32/  130]
train() client id: f_00008-6-1 loss: 0.567293  [   64/  130]
train() client id: f_00008-6-2 loss: 0.814256  [   96/  130]
train() client id: f_00008-6-3 loss: 0.635009  [  128/  130]
train() client id: f_00008-7-0 loss: 0.700023  [   32/  130]
train() client id: f_00008-7-1 loss: 0.704428  [   64/  130]
train() client id: f_00008-7-2 loss: 0.629858  [   96/  130]
train() client id: f_00008-7-3 loss: 0.640866  [  128/  130]
train() client id: f_00008-8-0 loss: 0.706422  [   32/  130]
train() client id: f_00008-8-1 loss: 0.580103  [   64/  130]
train() client id: f_00008-8-2 loss: 0.739954  [   96/  130]
train() client id: f_00008-8-3 loss: 0.643202  [  128/  130]
train() client id: f_00008-9-0 loss: 0.710800  [   32/  130]
train() client id: f_00008-9-1 loss: 0.644076  [   64/  130]
train() client id: f_00008-9-2 loss: 0.659593  [   96/  130]
train() client id: f_00008-9-3 loss: 0.662677  [  128/  130]
train() client id: f_00008-10-0 loss: 0.638354  [   32/  130]
train() client id: f_00008-10-1 loss: 0.794512  [   64/  130]
train() client id: f_00008-10-2 loss: 0.602700  [   96/  130]
train() client id: f_00008-10-3 loss: 0.619241  [  128/  130]
train() client id: f_00008-11-0 loss: 0.728187  [   32/  130]
train() client id: f_00008-11-1 loss: 0.747970  [   64/  130]
train() client id: f_00008-11-2 loss: 0.677583  [   96/  130]
train() client id: f_00008-11-3 loss: 0.514996  [  128/  130]
train() client id: f_00008-12-0 loss: 0.667966  [   32/  130]
train() client id: f_00008-12-1 loss: 0.669313  [   64/  130]
train() client id: f_00008-12-2 loss: 0.763242  [   96/  130]
train() client id: f_00008-12-3 loss: 0.569837  [  128/  130]
train() client id: f_00009-0-0 loss: 1.141792  [   32/  118]
train() client id: f_00009-0-1 loss: 1.189185  [   64/  118]
train() client id: f_00009-0-2 loss: 1.151724  [   96/  118]
train() client id: f_00009-1-0 loss: 1.215246  [   32/  118]
train() client id: f_00009-1-1 loss: 1.153656  [   64/  118]
train() client id: f_00009-1-2 loss: 1.051030  [   96/  118]
train() client id: f_00009-2-0 loss: 1.027749  [   32/  118]
train() client id: f_00009-2-1 loss: 1.146813  [   64/  118]
train() client id: f_00009-2-2 loss: 1.029490  [   96/  118]
train() client id: f_00009-3-0 loss: 1.002510  [   32/  118]
train() client id: f_00009-3-1 loss: 1.054842  [   64/  118]
train() client id: f_00009-3-2 loss: 1.036177  [   96/  118]
train() client id: f_00009-4-0 loss: 0.925794  [   32/  118]
train() client id: f_00009-4-1 loss: 1.036282  [   64/  118]
train() client id: f_00009-4-2 loss: 0.945573  [   96/  118]
train() client id: f_00009-5-0 loss: 0.953441  [   32/  118]
train() client id: f_00009-5-1 loss: 1.027945  [   64/  118]
train() client id: f_00009-5-2 loss: 0.960561  [   96/  118]
train() client id: f_00009-6-0 loss: 1.023618  [   32/  118]
train() client id: f_00009-6-1 loss: 0.935492  [   64/  118]
train() client id: f_00009-6-2 loss: 1.027595  [   96/  118]
train() client id: f_00009-7-0 loss: 0.881998  [   32/  118]
train() client id: f_00009-7-1 loss: 0.950502  [   64/  118]
train() client id: f_00009-7-2 loss: 0.961151  [   96/  118]
train() client id: f_00009-8-0 loss: 0.933979  [   32/  118]
train() client id: f_00009-8-1 loss: 0.979695  [   64/  118]
train() client id: f_00009-8-2 loss: 0.865239  [   96/  118]
train() client id: f_00009-9-0 loss: 1.023099  [   32/  118]
train() client id: f_00009-9-1 loss: 0.792773  [   64/  118]
train() client id: f_00009-9-2 loss: 0.992523  [   96/  118]
train() client id: f_00009-10-0 loss: 0.930770  [   32/  118]
train() client id: f_00009-10-1 loss: 0.897322  [   64/  118]
train() client id: f_00009-10-2 loss: 0.951096  [   96/  118]
train() client id: f_00009-11-0 loss: 0.894300  [   32/  118]
train() client id: f_00009-11-1 loss: 0.909165  [   64/  118]
train() client id: f_00009-11-2 loss: 0.845413  [   96/  118]
train() client id: f_00009-12-0 loss: 0.960622  [   32/  118]
train() client id: f_00009-12-1 loss: 0.767219  [   64/  118]
train() client id: f_00009-12-2 loss: 0.929257  [   96/  118]
At round 17 accuracy: 0.636604774535809
At round 17 training accuracy: 0.5814889336016097
At round 17 training loss: 0.8446167746909826
gradient difference: 0.4267001152038574
train() client id: f_00000-0-0 loss: 1.311405  [   32/  126]
train() client id: f_00000-0-1 loss: 0.980067  [   64/  126]
train() client id: f_00000-0-2 loss: 1.255991  [   96/  126]
train() client id: f_00000-1-0 loss: 1.166497  [   32/  126]
train() client id: f_00000-1-1 loss: 1.006052  [   64/  126]
train() client id: f_00000-1-2 loss: 1.131056  [   96/  126]
train() client id: f_00000-2-0 loss: 0.958761  [   32/  126]
train() client id: f_00000-2-1 loss: 1.046909  [   64/  126]
train() client id: f_00000-2-2 loss: 1.040685  [   96/  126]
train() client id: f_00000-3-0 loss: 1.017416  [   32/  126]
train() client id: f_00000-3-1 loss: 0.926192  [   64/  126]
train() client id: f_00000-3-2 loss: 0.871024  [   96/  126]
train() client id: f_00000-4-0 loss: 0.904745  [   32/  126]
train() client id: f_00000-4-1 loss: 1.065800  [   64/  126]
train() client id: f_00000-4-2 loss: 0.842628  [   96/  126]
train() client id: f_00000-5-0 loss: 0.856808  [   32/  126]
train() client id: f_00000-5-1 loss: 0.873530  [   64/  126]
train() client id: f_00000-5-2 loss: 0.916348  [   96/  126]
train() client id: f_00000-6-0 loss: 0.776699  [   32/  126]
train() client id: f_00000-6-1 loss: 0.904420  [   64/  126]
train() client id: f_00000-6-2 loss: 0.886391  [   96/  126]
train() client id: f_00000-7-0 loss: 0.824954  [   32/  126]
train() client id: f_00000-7-1 loss: 0.807420  [   64/  126]
train() client id: f_00000-7-2 loss: 0.789607  [   96/  126]
train() client id: f_00000-8-0 loss: 0.757668  [   32/  126]
train() client id: f_00000-8-1 loss: 0.891905  [   64/  126]
train() client id: f_00000-8-2 loss: 0.804368  [   96/  126]
train() client id: f_00000-9-0 loss: 0.790781  [   32/  126]
train() client id: f_00000-9-1 loss: 0.736356  [   64/  126]
train() client id: f_00000-9-2 loss: 0.833512  [   96/  126]
train() client id: f_00000-10-0 loss: 0.748080  [   32/  126]
train() client id: f_00000-10-1 loss: 0.791007  [   64/  126]
train() client id: f_00000-10-2 loss: 0.717539  [   96/  126]
train() client id: f_00000-11-0 loss: 0.878225  [   32/  126]
train() client id: f_00000-11-1 loss: 0.797020  [   64/  126]
train() client id: f_00000-11-2 loss: 0.767332  [   96/  126]
train() client id: f_00000-12-0 loss: 0.746658  [   32/  126]
train() client id: f_00000-12-1 loss: 0.747534  [   64/  126]
train() client id: f_00000-12-2 loss: 0.870007  [   96/  126]
train() client id: f_00001-0-0 loss: 0.626950  [   32/  265]
train() client id: f_00001-0-1 loss: 0.516697  [   64/  265]
train() client id: f_00001-0-2 loss: 0.433749  [   96/  265]
train() client id: f_00001-0-3 loss: 0.466680  [  128/  265]
train() client id: f_00001-0-4 loss: 0.517025  [  160/  265]
train() client id: f_00001-0-5 loss: 0.474355  [  192/  265]
train() client id: f_00001-0-6 loss: 0.548681  [  224/  265]
train() client id: f_00001-0-7 loss: 0.607707  [  256/  265]
train() client id: f_00001-1-0 loss: 0.507697  [   32/  265]
train() client id: f_00001-1-1 loss: 0.499804  [   64/  265]
train() client id: f_00001-1-2 loss: 0.492518  [   96/  265]
train() client id: f_00001-1-3 loss: 0.479216  [  128/  265]
train() client id: f_00001-1-4 loss: 0.646145  [  160/  265]
train() client id: f_00001-1-5 loss: 0.464230  [  192/  265]
train() client id: f_00001-1-6 loss: 0.610759  [  224/  265]
train() client id: f_00001-1-7 loss: 0.508935  [  256/  265]
train() client id: f_00001-2-0 loss: 0.528021  [   32/  265]
train() client id: f_00001-2-1 loss: 0.509434  [   64/  265]
train() client id: f_00001-2-2 loss: 0.435075  [   96/  265]
train() client id: f_00001-2-3 loss: 0.498652  [  128/  265]
train() client id: f_00001-2-4 loss: 0.473898  [  160/  265]
train() client id: f_00001-2-5 loss: 0.597650  [  192/  265]
train() client id: f_00001-2-6 loss: 0.578696  [  224/  265]
train() client id: f_00001-2-7 loss: 0.540242  [  256/  265]
train() client id: f_00001-3-0 loss: 0.554383  [   32/  265]
train() client id: f_00001-3-1 loss: 0.553897  [   64/  265]
train() client id: f_00001-3-2 loss: 0.490940  [   96/  265]
train() client id: f_00001-3-3 loss: 0.438918  [  128/  265]
train() client id: f_00001-3-4 loss: 0.611138  [  160/  265]
train() client id: f_00001-3-5 loss: 0.523158  [  192/  265]
train() client id: f_00001-3-6 loss: 0.483339  [  224/  265]
train() client id: f_00001-3-7 loss: 0.487351  [  256/  265]
train() client id: f_00001-4-0 loss: 0.532100  [   32/  265]
train() client id: f_00001-4-1 loss: 0.414778  [   64/  265]
train() client id: f_00001-4-2 loss: 0.443536  [   96/  265]
train() client id: f_00001-4-3 loss: 0.560308  [  128/  265]
train() client id: f_00001-4-4 loss: 0.517008  [  160/  265]
train() client id: f_00001-4-5 loss: 0.657677  [  192/  265]
train() client id: f_00001-4-6 loss: 0.508641  [  224/  265]
train() client id: f_00001-4-7 loss: 0.477096  [  256/  265]
train() client id: f_00001-5-0 loss: 0.410778  [   32/  265]
train() client id: f_00001-5-1 loss: 0.483798  [   64/  265]
train() client id: f_00001-5-2 loss: 0.489681  [   96/  265]
train() client id: f_00001-5-3 loss: 0.634370  [  128/  265]
train() client id: f_00001-5-4 loss: 0.509267  [  160/  265]
train() client id: f_00001-5-5 loss: 0.490977  [  192/  265]
train() client id: f_00001-5-6 loss: 0.436463  [  224/  265]
train() client id: f_00001-5-7 loss: 0.628035  [  256/  265]
train() client id: f_00001-6-0 loss: 0.570593  [   32/  265]
train() client id: f_00001-6-1 loss: 0.468399  [   64/  265]
train() client id: f_00001-6-2 loss: 0.431829  [   96/  265]
train() client id: f_00001-6-3 loss: 0.631492  [  128/  265]
train() client id: f_00001-6-4 loss: 0.455457  [  160/  265]
train() client id: f_00001-6-5 loss: 0.501856  [  192/  265]
train() client id: f_00001-6-6 loss: 0.429273  [  224/  265]
train() client id: f_00001-6-7 loss: 0.525471  [  256/  265]
train() client id: f_00001-7-0 loss: 0.619287  [   32/  265]
train() client id: f_00001-7-1 loss: 0.406558  [   64/  265]
train() client id: f_00001-7-2 loss: 0.429522  [   96/  265]
train() client id: f_00001-7-3 loss: 0.423026  [  128/  265]
train() client id: f_00001-7-4 loss: 0.615838  [  160/  265]
train() client id: f_00001-7-5 loss: 0.510706  [  192/  265]
train() client id: f_00001-7-6 loss: 0.511550  [  224/  265]
train() client id: f_00001-7-7 loss: 0.564342  [  256/  265]
train() client id: f_00001-8-0 loss: 0.549683  [   32/  265]
train() client id: f_00001-8-1 loss: 0.413042  [   64/  265]
train() client id: f_00001-8-2 loss: 0.488441  [   96/  265]
train() client id: f_00001-8-3 loss: 0.493446  [  128/  265]
train() client id: f_00001-8-4 loss: 0.428425  [  160/  265]
train() client id: f_00001-8-5 loss: 0.692940  [  192/  265]
train() client id: f_00001-8-6 loss: 0.513555  [  224/  265]
train() client id: f_00001-8-7 loss: 0.482183  [  256/  265]
train() client id: f_00001-9-0 loss: 0.430041  [   32/  265]
train() client id: f_00001-9-1 loss: 0.556993  [   64/  265]
train() client id: f_00001-9-2 loss: 0.557880  [   96/  265]
train() client id: f_00001-9-3 loss: 0.424225  [  128/  265]
train() client id: f_00001-9-4 loss: 0.539868  [  160/  265]
train() client id: f_00001-9-5 loss: 0.426450  [  192/  265]
train() client id: f_00001-9-6 loss: 0.556818  [  224/  265]
train() client id: f_00001-9-7 loss: 0.569364  [  256/  265]
train() client id: f_00001-10-0 loss: 0.504269  [   32/  265]
train() client id: f_00001-10-1 loss: 0.495384  [   64/  265]
train() client id: f_00001-10-2 loss: 0.510706  [   96/  265]
train() client id: f_00001-10-3 loss: 0.619432  [  128/  265]
train() client id: f_00001-10-4 loss: 0.467250  [  160/  265]
train() client id: f_00001-10-5 loss: 0.495713  [  192/  265]
train() client id: f_00001-10-6 loss: 0.426615  [  224/  265]
train() client id: f_00001-10-7 loss: 0.438116  [  256/  265]
train() client id: f_00001-11-0 loss: 0.551341  [   32/  265]
train() client id: f_00001-11-1 loss: 0.518964  [   64/  265]
train() client id: f_00001-11-2 loss: 0.593464  [   96/  265]
train() client id: f_00001-11-3 loss: 0.441949  [  128/  265]
train() client id: f_00001-11-4 loss: 0.497869  [  160/  265]
train() client id: f_00001-11-5 loss: 0.495471  [  192/  265]
train() client id: f_00001-11-6 loss: 0.516641  [  224/  265]
train() client id: f_00001-11-7 loss: 0.427759  [  256/  265]
train() client id: f_00001-12-0 loss: 0.509976  [   32/  265]
train() client id: f_00001-12-1 loss: 0.684732  [   64/  265]
train() client id: f_00001-12-2 loss: 0.524027  [   96/  265]
train() client id: f_00001-12-3 loss: 0.403046  [  128/  265]
train() client id: f_00001-12-4 loss: 0.430996  [  160/  265]
train() client id: f_00001-12-5 loss: 0.504580  [  192/  265]
train() client id: f_00001-12-6 loss: 0.610156  [  224/  265]
train() client id: f_00001-12-7 loss: 0.417053  [  256/  265]
train() client id: f_00002-0-0 loss: 1.215850  [   32/  124]
train() client id: f_00002-0-1 loss: 1.313053  [   64/  124]
train() client id: f_00002-0-2 loss: 1.168635  [   96/  124]
train() client id: f_00002-1-0 loss: 1.260917  [   32/  124]
train() client id: f_00002-1-1 loss: 1.223045  [   64/  124]
train() client id: f_00002-1-2 loss: 1.154175  [   96/  124]
train() client id: f_00002-2-0 loss: 1.258336  [   32/  124]
train() client id: f_00002-2-1 loss: 1.072203  [   64/  124]
train() client id: f_00002-2-2 loss: 1.149153  [   96/  124]
train() client id: f_00002-3-0 loss: 1.097534  [   32/  124]
train() client id: f_00002-3-1 loss: 1.118700  [   64/  124]
train() client id: f_00002-3-2 loss: 1.100152  [   96/  124]
train() client id: f_00002-4-0 loss: 1.062793  [   32/  124]
train() client id: f_00002-4-1 loss: 1.063890  [   64/  124]
train() client id: f_00002-4-2 loss: 1.117876  [   96/  124]
train() client id: f_00002-5-0 loss: 1.063593  [   32/  124]
train() client id: f_00002-5-1 loss: 0.976522  [   64/  124]
train() client id: f_00002-5-2 loss: 1.048512  [   96/  124]
train() client id: f_00002-6-0 loss: 1.068266  [   32/  124]
train() client id: f_00002-6-1 loss: 1.128803  [   64/  124]
train() client id: f_00002-6-2 loss: 0.949079  [   96/  124]
train() client id: f_00002-7-0 loss: 1.038481  [   32/  124]
train() client id: f_00002-7-1 loss: 1.006844  [   64/  124]
train() client id: f_00002-7-2 loss: 0.911759  [   96/  124]
train() client id: f_00002-8-0 loss: 1.044387  [   32/  124]
train() client id: f_00002-8-1 loss: 0.960136  [   64/  124]
train() client id: f_00002-8-2 loss: 0.955275  [   96/  124]
train() client id: f_00002-9-0 loss: 1.064924  [   32/  124]
train() client id: f_00002-9-1 loss: 0.983004  [   64/  124]
train() client id: f_00002-9-2 loss: 1.011728  [   96/  124]
train() client id: f_00002-10-0 loss: 0.969087  [   32/  124]
train() client id: f_00002-10-1 loss: 1.056041  [   64/  124]
train() client id: f_00002-10-2 loss: 0.858169  [   96/  124]
train() client id: f_00002-11-0 loss: 1.008609  [   32/  124]
train() client id: f_00002-11-1 loss: 0.893319  [   64/  124]
train() client id: f_00002-11-2 loss: 1.019753  [   96/  124]
train() client id: f_00002-12-0 loss: 0.965716  [   32/  124]
train() client id: f_00002-12-1 loss: 0.944034  [   64/  124]
train() client id: f_00002-12-2 loss: 1.071606  [   96/  124]
train() client id: f_00003-0-0 loss: 0.713742  [   32/   43]
train() client id: f_00003-1-0 loss: 0.786692  [   32/   43]
train() client id: f_00003-2-0 loss: 0.995123  [   32/   43]
train() client id: f_00003-3-0 loss: 0.692211  [   32/   43]
train() client id: f_00003-4-0 loss: 0.823150  [   32/   43]
train() client id: f_00003-5-0 loss: 0.915503  [   32/   43]
train() client id: f_00003-6-0 loss: 0.935217  [   32/   43]
train() client id: f_00003-7-0 loss: 0.861578  [   32/   43]
train() client id: f_00003-8-0 loss: 0.755534  [   32/   43]
train() client id: f_00003-9-0 loss: 0.849017  [   32/   43]
train() client id: f_00003-10-0 loss: 0.717529  [   32/   43]
train() client id: f_00003-11-0 loss: 0.734756  [   32/   43]
train() client id: f_00003-12-0 loss: 0.841094  [   32/   43]
train() client id: f_00004-0-0 loss: 0.697212  [   32/  306]
train() client id: f_00004-0-1 loss: 0.609278  [   64/  306]
train() client id: f_00004-0-2 loss: 0.785970  [   96/  306]
train() client id: f_00004-0-3 loss: 0.731850  [  128/  306]
train() client id: f_00004-0-4 loss: 0.720166  [  160/  306]
train() client id: f_00004-0-5 loss: 0.909158  [  192/  306]
train() client id: f_00004-0-6 loss: 0.745006  [  224/  306]
train() client id: f_00004-0-7 loss: 0.704258  [  256/  306]
train() client id: f_00004-0-8 loss: 0.838715  [  288/  306]
train() client id: f_00004-1-0 loss: 0.790132  [   32/  306]
train() client id: f_00004-1-1 loss: 0.723132  [   64/  306]
train() client id: f_00004-1-2 loss: 0.649735  [   96/  306]
train() client id: f_00004-1-3 loss: 0.749555  [  128/  306]
train() client id: f_00004-1-4 loss: 0.868415  [  160/  306]
train() client id: f_00004-1-5 loss: 0.763230  [  192/  306]
train() client id: f_00004-1-6 loss: 0.730730  [  224/  306]
train() client id: f_00004-1-7 loss: 0.589772  [  256/  306]
train() client id: f_00004-1-8 loss: 0.848558  [  288/  306]
train() client id: f_00004-2-0 loss: 0.828892  [   32/  306]
train() client id: f_00004-2-1 loss: 0.777982  [   64/  306]
train() client id: f_00004-2-2 loss: 0.819662  [   96/  306]
train() client id: f_00004-2-3 loss: 0.650816  [  128/  306]
train() client id: f_00004-2-4 loss: 0.749938  [  160/  306]
train() client id: f_00004-2-5 loss: 0.708105  [  192/  306]
train() client id: f_00004-2-6 loss: 0.707363  [  224/  306]
train() client id: f_00004-2-7 loss: 0.842631  [  256/  306]
train() client id: f_00004-2-8 loss: 0.670014  [  288/  306]
train() client id: f_00004-3-0 loss: 0.834165  [   32/  306]
train() client id: f_00004-3-1 loss: 0.820691  [   64/  306]
train() client id: f_00004-3-2 loss: 0.768814  [   96/  306]
train() client id: f_00004-3-3 loss: 0.781987  [  128/  306]
train() client id: f_00004-3-4 loss: 0.732074  [  160/  306]
train() client id: f_00004-3-5 loss: 0.765879  [  192/  306]
train() client id: f_00004-3-6 loss: 0.690107  [  224/  306]
train() client id: f_00004-3-7 loss: 0.736811  [  256/  306]
train() client id: f_00004-3-8 loss: 0.718257  [  288/  306]
train() client id: f_00004-4-0 loss: 0.831012  [   32/  306]
train() client id: f_00004-4-1 loss: 0.801710  [   64/  306]
train() client id: f_00004-4-2 loss: 0.782480  [   96/  306]
train() client id: f_00004-4-3 loss: 0.709195  [  128/  306]
train() client id: f_00004-4-4 loss: 0.674487  [  160/  306]
train() client id: f_00004-4-5 loss: 0.756914  [  192/  306]
train() client id: f_00004-4-6 loss: 0.817179  [  224/  306]
train() client id: f_00004-4-7 loss: 0.813016  [  256/  306]
train() client id: f_00004-4-8 loss: 0.660525  [  288/  306]
train() client id: f_00004-5-0 loss: 0.836923  [   32/  306]
train() client id: f_00004-5-1 loss: 0.835039  [   64/  306]
train() client id: f_00004-5-2 loss: 0.652014  [   96/  306]
train() client id: f_00004-5-3 loss: 0.744839  [  128/  306]
train() client id: f_00004-5-4 loss: 0.688478  [  160/  306]
train() client id: f_00004-5-5 loss: 0.747109  [  192/  306]
train() client id: f_00004-5-6 loss: 0.686138  [  224/  306]
train() client id: f_00004-5-7 loss: 0.787304  [  256/  306]
train() client id: f_00004-5-8 loss: 0.879416  [  288/  306]
train() client id: f_00004-6-0 loss: 0.814484  [   32/  306]
train() client id: f_00004-6-1 loss: 0.724124  [   64/  306]
train() client id: f_00004-6-2 loss: 0.919091  [   96/  306]
train() client id: f_00004-6-3 loss: 0.747986  [  128/  306]
train() client id: f_00004-6-4 loss: 0.696765  [  160/  306]
train() client id: f_00004-6-5 loss: 0.746770  [  192/  306]
train() client id: f_00004-6-6 loss: 0.712114  [  224/  306]
train() client id: f_00004-6-7 loss: 0.643783  [  256/  306]
train() client id: f_00004-6-8 loss: 0.797241  [  288/  306]
train() client id: f_00004-7-0 loss: 0.785486  [   32/  306]
train() client id: f_00004-7-1 loss: 0.785004  [   64/  306]
train() client id: f_00004-7-2 loss: 0.913767  [   96/  306]
train() client id: f_00004-7-3 loss: 0.793796  [  128/  306]
train() client id: f_00004-7-4 loss: 0.700879  [  160/  306]
train() client id: f_00004-7-5 loss: 0.695414  [  192/  306]
train() client id: f_00004-7-6 loss: 0.729512  [  224/  306]
train() client id: f_00004-7-7 loss: 0.739208  [  256/  306]
train() client id: f_00004-7-8 loss: 0.669165  [  288/  306]
train() client id: f_00004-8-0 loss: 0.625125  [   32/  306]
train() client id: f_00004-8-1 loss: 0.816862  [   64/  306]
train() client id: f_00004-8-2 loss: 0.783497  [   96/  306]
train() client id: f_00004-8-3 loss: 0.689910  [  128/  306]
train() client id: f_00004-8-4 loss: 0.896561  [  160/  306]
train() client id: f_00004-8-5 loss: 0.807812  [  192/  306]
train() client id: f_00004-8-6 loss: 0.755319  [  224/  306]
train() client id: f_00004-8-7 loss: 0.687967  [  256/  306]
train() client id: f_00004-8-8 loss: 0.809735  [  288/  306]
train() client id: f_00004-9-0 loss: 0.819897  [   32/  306]
train() client id: f_00004-9-1 loss: 0.772985  [   64/  306]
train() client id: f_00004-9-2 loss: 0.793102  [   96/  306]
train() client id: f_00004-9-3 loss: 0.796202  [  128/  306]
train() client id: f_00004-9-4 loss: 0.871547  [  160/  306]
train() client id: f_00004-9-5 loss: 0.697912  [  192/  306]
train() client id: f_00004-9-6 loss: 0.759748  [  224/  306]
train() client id: f_00004-9-7 loss: 0.712711  [  256/  306]
train() client id: f_00004-9-8 loss: 0.670551  [  288/  306]
train() client id: f_00004-10-0 loss: 0.832546  [   32/  306]
train() client id: f_00004-10-1 loss: 0.759215  [   64/  306]
train() client id: f_00004-10-2 loss: 0.651500  [   96/  306]
train() client id: f_00004-10-3 loss: 0.735343  [  128/  306]
train() client id: f_00004-10-4 loss: 0.818560  [  160/  306]
train() client id: f_00004-10-5 loss: 0.766367  [  192/  306]
train() client id: f_00004-10-6 loss: 0.816802  [  224/  306]
train() client id: f_00004-10-7 loss: 0.817198  [  256/  306]
train() client id: f_00004-10-8 loss: 0.751573  [  288/  306]
train() client id: f_00004-11-0 loss: 0.841778  [   32/  306]
train() client id: f_00004-11-1 loss: 0.809511  [   64/  306]
train() client id: f_00004-11-2 loss: 0.705847  [   96/  306]
train() client id: f_00004-11-3 loss: 0.732326  [  128/  306]
train() client id: f_00004-11-4 loss: 0.696578  [  160/  306]
train() client id: f_00004-11-5 loss: 0.685059  [  192/  306]
train() client id: f_00004-11-6 loss: 0.698083  [  224/  306]
train() client id: f_00004-11-7 loss: 0.867717  [  256/  306]
train() client id: f_00004-11-8 loss: 0.869513  [  288/  306]
train() client id: f_00004-12-0 loss: 0.703316  [   32/  306]
train() client id: f_00004-12-1 loss: 0.850444  [   64/  306]
train() client id: f_00004-12-2 loss: 0.828793  [   96/  306]
train() client id: f_00004-12-3 loss: 0.804596  [  128/  306]
train() client id: f_00004-12-4 loss: 0.645444  [  160/  306]
train() client id: f_00004-12-5 loss: 0.794984  [  192/  306]
train() client id: f_00004-12-6 loss: 0.724559  [  224/  306]
train() client id: f_00004-12-7 loss: 0.758839  [  256/  306]
train() client id: f_00004-12-8 loss: 0.900381  [  288/  306]
train() client id: f_00005-0-0 loss: 0.593862  [   32/  146]
train() client id: f_00005-0-1 loss: 0.401466  [   64/  146]
train() client id: f_00005-0-2 loss: 0.753219  [   96/  146]
train() client id: f_00005-0-3 loss: 0.671451  [  128/  146]
train() client id: f_00005-1-0 loss: 0.679027  [   32/  146]
train() client id: f_00005-1-1 loss: 0.573690  [   64/  146]
train() client id: f_00005-1-2 loss: 0.494082  [   96/  146]
train() client id: f_00005-1-3 loss: 0.570588  [  128/  146]
train() client id: f_00005-2-0 loss: 0.609752  [   32/  146]
train() client id: f_00005-2-1 loss: 0.644072  [   64/  146]
train() client id: f_00005-2-2 loss: 0.531222  [   96/  146]
train() client id: f_00005-2-3 loss: 0.645396  [  128/  146]
train() client id: f_00005-3-0 loss: 0.824125  [   32/  146]
train() client id: f_00005-3-1 loss: 0.444416  [   64/  146]
train() client id: f_00005-3-2 loss: 0.511159  [   96/  146]
train() client id: f_00005-3-3 loss: 0.521074  [  128/  146]
train() client id: f_00005-4-0 loss: 0.676081  [   32/  146]
train() client id: f_00005-4-1 loss: 0.617698  [   64/  146]
train() client id: f_00005-4-2 loss: 0.422927  [   96/  146]
train() client id: f_00005-4-3 loss: 0.499845  [  128/  146]
train() client id: f_00005-5-0 loss: 0.636929  [   32/  146]
train() client id: f_00005-5-1 loss: 0.523975  [   64/  146]
train() client id: f_00005-5-2 loss: 0.658844  [   96/  146]
train() client id: f_00005-5-3 loss: 0.470448  [  128/  146]
train() client id: f_00005-6-0 loss: 0.529034  [   32/  146]
train() client id: f_00005-6-1 loss: 0.461444  [   64/  146]
train() client id: f_00005-6-2 loss: 0.537904  [   96/  146]
train() client id: f_00005-6-3 loss: 0.832171  [  128/  146]
train() client id: f_00005-7-0 loss: 0.533472  [   32/  146]
train() client id: f_00005-7-1 loss: 0.616967  [   64/  146]
train() client id: f_00005-7-2 loss: 0.769636  [   96/  146]
train() client id: f_00005-7-3 loss: 0.496954  [  128/  146]
train() client id: f_00005-8-0 loss: 0.570128  [   32/  146]
train() client id: f_00005-8-1 loss: 0.744851  [   64/  146]
train() client id: f_00005-8-2 loss: 0.438250  [   96/  146]
train() client id: f_00005-8-3 loss: 0.537205  [  128/  146]
train() client id: f_00005-9-0 loss: 0.600190  [   32/  146]
train() client id: f_00005-9-1 loss: 0.552918  [   64/  146]
train() client id: f_00005-9-2 loss: 0.570976  [   96/  146]
train() client id: f_00005-9-3 loss: 0.515310  [  128/  146]
train() client id: f_00005-10-0 loss: 0.462079  [   32/  146]
train() client id: f_00005-10-1 loss: 0.427841  [   64/  146]
train() client id: f_00005-10-2 loss: 0.553842  [   96/  146]
train() client id: f_00005-10-3 loss: 0.508524  [  128/  146]
train() client id: f_00005-11-0 loss: 0.551819  [   32/  146]
train() client id: f_00005-11-1 loss: 0.569003  [   64/  146]
train() client id: f_00005-11-2 loss: 0.298961  [   96/  146]
train() client id: f_00005-11-3 loss: 0.595048  [  128/  146]
train() client id: f_00005-12-0 loss: 0.539895  [   32/  146]
train() client id: f_00005-12-1 loss: 0.607217  [   64/  146]
train() client id: f_00005-12-2 loss: 0.650670  [   96/  146]
train() client id: f_00005-12-3 loss: 0.538928  [  128/  146]
train() client id: f_00006-0-0 loss: 0.578347  [   32/   54]
train() client id: f_00006-1-0 loss: 0.629184  [   32/   54]
train() client id: f_00006-2-0 loss: 0.589262  [   32/   54]
train() client id: f_00006-3-0 loss: 0.629547  [   32/   54]
train() client id: f_00006-4-0 loss: 0.591906  [   32/   54]
train() client id: f_00006-5-0 loss: 0.580115  [   32/   54]
train() client id: f_00006-6-0 loss: 0.577675  [   32/   54]
train() client id: f_00006-7-0 loss: 0.549001  [   32/   54]
train() client id: f_00006-8-0 loss: 0.625259  [   32/   54]
train() client id: f_00006-9-0 loss: 0.588841  [   32/   54]
train() client id: f_00006-10-0 loss: 0.594212  [   32/   54]
train() client id: f_00006-11-0 loss: 0.597797  [   32/   54]
train() client id: f_00006-12-0 loss: 0.626357  [   32/   54]
train() client id: f_00007-0-0 loss: 0.593692  [   32/  179]
train() client id: f_00007-0-1 loss: 0.643940  [   64/  179]
train() client id: f_00007-0-2 loss: 0.734473  [   96/  179]
train() client id: f_00007-0-3 loss: 0.700189  [  128/  179]
train() client id: f_00007-0-4 loss: 0.672083  [  160/  179]
train() client id: f_00007-1-0 loss: 0.780101  [   32/  179]
train() client id: f_00007-1-1 loss: 0.675776  [   64/  179]
train() client id: f_00007-1-2 loss: 0.682074  [   96/  179]
train() client id: f_00007-1-3 loss: 0.636559  [  128/  179]
train() client id: f_00007-1-4 loss: 0.654200  [  160/  179]
train() client id: f_00007-2-0 loss: 0.739570  [   32/  179]
train() client id: f_00007-2-1 loss: 0.703829  [   64/  179]
train() client id: f_00007-2-2 loss: 0.712614  [   96/  179]
train() client id: f_00007-2-3 loss: 0.547166  [  128/  179]
train() client id: f_00007-2-4 loss: 0.577151  [  160/  179]
train() client id: f_00007-3-0 loss: 0.679432  [   32/  179]
train() client id: f_00007-3-1 loss: 0.611001  [   64/  179]
train() client id: f_00007-3-2 loss: 0.685187  [   96/  179]
train() client id: f_00007-3-3 loss: 0.617964  [  128/  179]
train() client id: f_00007-3-4 loss: 0.710661  [  160/  179]
train() client id: f_00007-4-0 loss: 0.669909  [   32/  179]
train() client id: f_00007-4-1 loss: 0.618253  [   64/  179]
train() client id: f_00007-4-2 loss: 0.762316  [   96/  179]
train() client id: f_00007-4-3 loss: 0.500613  [  128/  179]
train() client id: f_00007-4-4 loss: 0.662578  [  160/  179]
train() client id: f_00007-5-0 loss: 0.652402  [   32/  179]
train() client id: f_00007-5-1 loss: 0.503010  [   64/  179]
train() client id: f_00007-5-2 loss: 0.821260  [   96/  179]
train() client id: f_00007-5-3 loss: 0.589631  [  128/  179]
train() client id: f_00007-5-4 loss: 0.683847  [  160/  179]
train() client id: f_00007-6-0 loss: 0.666892  [   32/  179]
train() client id: f_00007-6-1 loss: 0.820295  [   64/  179]
train() client id: f_00007-6-2 loss: 0.522044  [   96/  179]
train() client id: f_00007-6-3 loss: 0.567974  [  128/  179]
train() client id: f_00007-6-4 loss: 0.668770  [  160/  179]
train() client id: f_00007-7-0 loss: 0.875635  [   32/  179]
train() client id: f_00007-7-1 loss: 0.614194  [   64/  179]
train() client id: f_00007-7-2 loss: 0.490671  [   96/  179]
train() client id: f_00007-7-3 loss: 0.660203  [  128/  179]
train() client id: f_00007-7-4 loss: 0.582502  [  160/  179]
train() client id: f_00007-8-0 loss: 0.593089  [   32/  179]
train() client id: f_00007-8-1 loss: 0.515522  [   64/  179]
train() client id: f_00007-8-2 loss: 0.646256  [   96/  179]
train() client id: f_00007-8-3 loss: 0.781805  [  128/  179]
train() client id: f_00007-8-4 loss: 0.688594  [  160/  179]
train() client id: f_00007-9-0 loss: 0.704140  [   32/  179]
train() client id: f_00007-9-1 loss: 0.508974  [   64/  179]
train() client id: f_00007-9-2 loss: 0.565679  [   96/  179]
train() client id: f_00007-9-3 loss: 0.642678  [  128/  179]
train() client id: f_00007-9-4 loss: 0.467038  [  160/  179]
train() client id: f_00007-10-0 loss: 0.472640  [   32/  179]
train() client id: f_00007-10-1 loss: 0.661036  [   64/  179]
train() client id: f_00007-10-2 loss: 0.592110  [   96/  179]
train() client id: f_00007-10-3 loss: 0.623233  [  128/  179]
train() client id: f_00007-10-4 loss: 0.751359  [  160/  179]
train() client id: f_00007-11-0 loss: 0.488817  [   32/  179]
train() client id: f_00007-11-1 loss: 0.697999  [   64/  179]
train() client id: f_00007-11-2 loss: 0.483186  [   96/  179]
train() client id: f_00007-11-3 loss: 0.614722  [  128/  179]
train() client id: f_00007-11-4 loss: 0.750521  [  160/  179]
train() client id: f_00007-12-0 loss: 0.543045  [   32/  179]
train() client id: f_00007-12-1 loss: 0.583611  [   64/  179]
train() client id: f_00007-12-2 loss: 0.669910  [   96/  179]
train() client id: f_00007-12-3 loss: 0.593987  [  128/  179]
train() client id: f_00007-12-4 loss: 0.701236  [  160/  179]
train() client id: f_00008-0-0 loss: 0.891069  [   32/  130]
train() client id: f_00008-0-1 loss: 0.799453  [   64/  130]
train() client id: f_00008-0-2 loss: 0.791728  [   96/  130]
train() client id: f_00008-0-3 loss: 0.958634  [  128/  130]
train() client id: f_00008-1-0 loss: 0.876018  [   32/  130]
train() client id: f_00008-1-1 loss: 0.767769  [   64/  130]
train() client id: f_00008-1-2 loss: 0.797733  [   96/  130]
train() client id: f_00008-1-3 loss: 0.999489  [  128/  130]
train() client id: f_00008-2-0 loss: 0.896921  [   32/  130]
train() client id: f_00008-2-1 loss: 0.802130  [   64/  130]
train() client id: f_00008-2-2 loss: 0.822040  [   96/  130]
train() client id: f_00008-2-3 loss: 0.908089  [  128/  130]
train() client id: f_00008-3-0 loss: 0.876042  [   32/  130]
train() client id: f_00008-3-1 loss: 0.799964  [   64/  130]
train() client id: f_00008-3-2 loss: 0.889350  [   96/  130]
train() client id: f_00008-3-3 loss: 0.859355  [  128/  130]
train() client id: f_00008-4-0 loss: 0.969006  [   32/  130]
train() client id: f_00008-4-1 loss: 0.698004  [   64/  130]
train() client id: f_00008-4-2 loss: 0.824598  [   96/  130]
train() client id: f_00008-4-3 loss: 0.921739  [  128/  130]
train() client id: f_00008-5-0 loss: 0.937533  [   32/  130]
train() client id: f_00008-5-1 loss: 0.798980  [   64/  130]
train() client id: f_00008-5-2 loss: 0.863590  [   96/  130]
train() client id: f_00008-5-3 loss: 0.822454  [  128/  130]
train() client id: f_00008-6-0 loss: 0.708781  [   32/  130]
train() client id: f_00008-6-1 loss: 0.948783  [   64/  130]
train() client id: f_00008-6-2 loss: 0.854651  [   96/  130]
train() client id: f_00008-6-3 loss: 0.873580  [  128/  130]
train() client id: f_00008-7-0 loss: 0.839559  [   32/  130]
train() client id: f_00008-7-1 loss: 0.940485  [   64/  130]
train() client id: f_00008-7-2 loss: 0.859795  [   96/  130]
train() client id: f_00008-7-3 loss: 0.746809  [  128/  130]
train() client id: f_00008-8-0 loss: 0.836494  [   32/  130]
train() client id: f_00008-8-1 loss: 0.889054  [   64/  130]
train() client id: f_00008-8-2 loss: 0.728617  [   96/  130]
train() client id: f_00008-8-3 loss: 0.975246  [  128/  130]
train() client id: f_00008-9-0 loss: 0.899134  [   32/  130]
train() client id: f_00008-9-1 loss: 0.755485  [   64/  130]
train() client id: f_00008-9-2 loss: 0.851404  [   96/  130]
train() client id: f_00008-9-3 loss: 0.899519  [  128/  130]
train() client id: f_00008-10-0 loss: 0.713413  [   32/  130]
train() client id: f_00008-10-1 loss: 0.920698  [   64/  130]
train() client id: f_00008-10-2 loss: 0.907492  [   96/  130]
train() client id: f_00008-10-3 loss: 0.878755  [  128/  130]
train() client id: f_00008-11-0 loss: 0.814368  [   32/  130]
train() client id: f_00008-11-1 loss: 0.789832  [   64/  130]
train() client id: f_00008-11-2 loss: 0.860985  [   96/  130]
train() client id: f_00008-11-3 loss: 0.952994  [  128/  130]
train() client id: f_00008-12-0 loss: 1.030745  [   32/  130]
train() client id: f_00008-12-1 loss: 0.737797  [   64/  130]
train() client id: f_00008-12-2 loss: 0.904457  [   96/  130]
train() client id: f_00008-12-3 loss: 0.736662  [  128/  130]
train() client id: f_00009-0-0 loss: 1.169815  [   32/  118]
train() client id: f_00009-0-1 loss: 1.189211  [   64/  118]
train() client id: f_00009-0-2 loss: 1.101094  [   96/  118]
train() client id: f_00009-1-0 loss: 1.064970  [   32/  118]
train() client id: f_00009-1-1 loss: 1.034499  [   64/  118]
train() client id: f_00009-1-2 loss: 1.231933  [   96/  118]
train() client id: f_00009-2-0 loss: 1.015950  [   32/  118]
train() client id: f_00009-2-1 loss: 1.021237  [   64/  118]
train() client id: f_00009-2-2 loss: 1.145923  [   96/  118]
train() client id: f_00009-3-0 loss: 1.139141  [   32/  118]
train() client id: f_00009-3-1 loss: 0.922513  [   64/  118]
train() client id: f_00009-3-2 loss: 0.984252  [   96/  118]
train() client id: f_00009-4-0 loss: 0.862793  [   32/  118]
train() client id: f_00009-4-1 loss: 1.062350  [   64/  118]
train() client id: f_00009-4-2 loss: 0.935529  [   96/  118]
train() client id: f_00009-5-0 loss: 0.976725  [   32/  118]
train() client id: f_00009-5-1 loss: 0.950990  [   64/  118]
train() client id: f_00009-5-2 loss: 0.917918  [   96/  118]
train() client id: f_00009-6-0 loss: 0.896180  [   32/  118]
train() client id: f_00009-6-1 loss: 0.896105  [   64/  118]
train() client id: f_00009-6-2 loss: 0.980331  [   96/  118]
train() client id: f_00009-7-0 loss: 0.858558  [   32/  118]
train() client id: f_00009-7-1 loss: 1.009768  [   64/  118]
train() client id: f_00009-7-2 loss: 0.863965  [   96/  118]
train() client id: f_00009-8-0 loss: 0.882692  [   32/  118]
train() client id: f_00009-8-1 loss: 0.939578  [   64/  118]
train() client id: f_00009-8-2 loss: 0.855270  [   96/  118]
train() client id: f_00009-9-0 loss: 0.943175  [   32/  118]
train() client id: f_00009-9-1 loss: 0.871410  [   64/  118]
train() client id: f_00009-9-2 loss: 0.848322  [   96/  118]
train() client id: f_00009-10-0 loss: 0.881088  [   32/  118]
train() client id: f_00009-10-1 loss: 0.795210  [   64/  118]
train() client id: f_00009-10-2 loss: 0.991478  [   96/  118]
train() client id: f_00009-11-0 loss: 0.896807  [   32/  118]
train() client id: f_00009-11-1 loss: 0.842788  [   64/  118]
train() client id: f_00009-11-2 loss: 0.897659  [   96/  118]
train() client id: f_00009-12-0 loss: 0.933333  [   32/  118]
train() client id: f_00009-12-1 loss: 0.776598  [   64/  118]
train() client id: f_00009-12-2 loss: 0.874991  [   96/  118]
At round 18 accuracy: 0.636604774535809
At round 18 training accuracy: 0.5781354795439303
At round 18 training loss: 0.8526409194632955
gradient difference: 0.443250834941864
train() client id: f_00000-0-0 loss: 1.019637  [   32/  126]
train() client id: f_00000-0-1 loss: 1.143723  [   64/  126]
train() client id: f_00000-0-2 loss: 1.175249  [   96/  126]
train() client id: f_00000-1-0 loss: 1.168563  [   32/  126]
train() client id: f_00000-1-1 loss: 1.014842  [   64/  126]
train() client id: f_00000-1-2 loss: 0.884565  [   96/  126]
train() client id: f_00000-2-0 loss: 0.926908  [   32/  126]
train() client id: f_00000-2-1 loss: 0.945835  [   64/  126]
train() client id: f_00000-2-2 loss: 0.932637  [   96/  126]
train() client id: f_00000-3-0 loss: 0.968501  [   32/  126]
train() client id: f_00000-3-1 loss: 0.936866  [   64/  126]
train() client id: f_00000-3-2 loss: 0.910488  [   96/  126]
train() client id: f_00000-4-0 loss: 0.864695  [   32/  126]
train() client id: f_00000-4-1 loss: 0.840723  [   64/  126]
train() client id: f_00000-4-2 loss: 0.969797  [   96/  126]
train() client id: f_00000-5-0 loss: 0.864396  [   32/  126]
train() client id: f_00000-5-1 loss: 0.841935  [   64/  126]
train() client id: f_00000-5-2 loss: 0.753366  [   96/  126]
train() client id: f_00000-6-0 loss: 0.748390  [   32/  126]
train() client id: f_00000-6-1 loss: 0.782268  [   64/  126]
train() client id: f_00000-6-2 loss: 0.759870  [   96/  126]
train() client id: f_00000-7-0 loss: 0.745345  [   32/  126]
train() client id: f_00000-7-1 loss: 0.669495  [   64/  126]
train() client id: f_00000-7-2 loss: 0.880762  [   96/  126]
train() client id: f_00000-8-0 loss: 0.746082  [   32/  126]
train() client id: f_00000-8-1 loss: 0.793482  [   64/  126]
train() client id: f_00000-8-2 loss: 0.714903  [   96/  126]
train() client id: f_00000-9-0 loss: 0.753865  [   32/  126]
train() client id: f_00000-9-1 loss: 0.738050  [   64/  126]
train() client id: f_00000-9-2 loss: 0.814104  [   96/  126]
train() client id: f_00000-10-0 loss: 0.703469  [   32/  126]
train() client id: f_00000-10-1 loss: 0.740362  [   64/  126]
train() client id: f_00000-10-2 loss: 0.796729  [   96/  126]
train() client id: f_00000-11-0 loss: 0.773594  [   32/  126]
train() client id: f_00000-11-1 loss: 0.745004  [   64/  126]
train() client id: f_00000-11-2 loss: 0.794836  [   96/  126]
train() client id: f_00000-12-0 loss: 0.956054  [   32/  126]
train() client id: f_00000-12-1 loss: 0.649302  [   64/  126]
train() client id: f_00000-12-2 loss: 0.681293  [   96/  126]
train() client id: f_00001-0-0 loss: 0.454082  [   32/  265]
train() client id: f_00001-0-1 loss: 0.560981  [   64/  265]
train() client id: f_00001-0-2 loss: 0.453305  [   96/  265]
train() client id: f_00001-0-3 loss: 0.495755  [  128/  265]
train() client id: f_00001-0-4 loss: 0.507866  [  160/  265]
train() client id: f_00001-0-5 loss: 0.707848  [  192/  265]
train() client id: f_00001-0-6 loss: 0.495463  [  224/  265]
train() client id: f_00001-0-7 loss: 0.584435  [  256/  265]
train() client id: f_00001-1-0 loss: 0.513604  [   32/  265]
train() client id: f_00001-1-1 loss: 0.459004  [   64/  265]
train() client id: f_00001-1-2 loss: 0.511845  [   96/  265]
train() client id: f_00001-1-3 loss: 0.591156  [  128/  265]
train() client id: f_00001-1-4 loss: 0.518393  [  160/  265]
train() client id: f_00001-1-5 loss: 0.498004  [  192/  265]
train() client id: f_00001-1-6 loss: 0.594889  [  224/  265]
train() client id: f_00001-1-7 loss: 0.506589  [  256/  265]
train() client id: f_00001-2-0 loss: 0.520300  [   32/  265]
train() client id: f_00001-2-1 loss: 0.511320  [   64/  265]
train() client id: f_00001-2-2 loss: 0.550877  [   96/  265]
train() client id: f_00001-2-3 loss: 0.443789  [  128/  265]
train() client id: f_00001-2-4 loss: 0.546436  [  160/  265]
train() client id: f_00001-2-5 loss: 0.607944  [  192/  265]
train() client id: f_00001-2-6 loss: 0.507262  [  224/  265]
train() client id: f_00001-2-7 loss: 0.444476  [  256/  265]
train() client id: f_00001-3-0 loss: 0.526105  [   32/  265]
train() client id: f_00001-3-1 loss: 0.428379  [   64/  265]
train() client id: f_00001-3-2 loss: 0.542094  [   96/  265]
train() client id: f_00001-3-3 loss: 0.425219  [  128/  265]
train() client id: f_00001-3-4 loss: 0.650752  [  160/  265]
train() client id: f_00001-3-5 loss: 0.436427  [  192/  265]
train() client id: f_00001-3-6 loss: 0.535370  [  224/  265]
train() client id: f_00001-3-7 loss: 0.556683  [  256/  265]
train() client id: f_00001-4-0 loss: 0.508708  [   32/  265]
train() client id: f_00001-4-1 loss: 0.446074  [   64/  265]
train() client id: f_00001-4-2 loss: 0.493732  [   96/  265]
train() client id: f_00001-4-3 loss: 0.452803  [  128/  265]
train() client id: f_00001-4-4 loss: 0.523682  [  160/  265]
train() client id: f_00001-4-5 loss: 0.444817  [  192/  265]
train() client id: f_00001-4-6 loss: 0.635091  [  224/  265]
train() client id: f_00001-4-7 loss: 0.558994  [  256/  265]
train() client id: f_00001-5-0 loss: 0.529747  [   32/  265]
train() client id: f_00001-5-1 loss: 0.502052  [   64/  265]
train() client id: f_00001-5-2 loss: 0.511572  [   96/  265]
train() client id: f_00001-5-3 loss: 0.492236  [  128/  265]
train() client id: f_00001-5-4 loss: 0.495748  [  160/  265]
train() client id: f_00001-5-5 loss: 0.420088  [  192/  265]
train() client id: f_00001-5-6 loss: 0.621317  [  224/  265]
train() client id: f_00001-5-7 loss: 0.443004  [  256/  265]
train() client id: f_00001-6-0 loss: 0.622735  [   32/  265]
train() client id: f_00001-6-1 loss: 0.457209  [   64/  265]
train() client id: f_00001-6-2 loss: 0.478006  [   96/  265]
train() client id: f_00001-6-3 loss: 0.457962  [  128/  265]
train() client id: f_00001-6-4 loss: 0.536379  [  160/  265]
train() client id: f_00001-6-5 loss: 0.460090  [  192/  265]
train() client id: f_00001-6-6 loss: 0.563084  [  224/  265]
train() client id: f_00001-6-7 loss: 0.465203  [  256/  265]
train() client id: f_00001-7-0 loss: 0.701485  [   32/  265]
train() client id: f_00001-7-1 loss: 0.426730  [   64/  265]
train() client id: f_00001-7-2 loss: 0.505065  [   96/  265]
train() client id: f_00001-7-3 loss: 0.505584  [  128/  265]
train() client id: f_00001-7-4 loss: 0.497353  [  160/  265]
train() client id: f_00001-7-5 loss: 0.436170  [  192/  265]
train() client id: f_00001-7-6 loss: 0.413811  [  224/  265]
train() client id: f_00001-7-7 loss: 0.505209  [  256/  265]
train() client id: f_00001-8-0 loss: 0.522387  [   32/  265]
train() client id: f_00001-8-1 loss: 0.476076  [   64/  265]
train() client id: f_00001-8-2 loss: 0.438244  [   96/  265]
train() client id: f_00001-8-3 loss: 0.537463  [  128/  265]
train() client id: f_00001-8-4 loss: 0.511278  [  160/  265]
train() client id: f_00001-8-5 loss: 0.466223  [  192/  265]
train() client id: f_00001-8-6 loss: 0.453519  [  224/  265]
train() client id: f_00001-8-7 loss: 0.590744  [  256/  265]
train() client id: f_00001-9-0 loss: 0.566059  [   32/  265]
train() client id: f_00001-9-1 loss: 0.424143  [   64/  265]
train() client id: f_00001-9-2 loss: 0.482441  [   96/  265]
train() client id: f_00001-9-3 loss: 0.600009  [  128/  265]
train() client id: f_00001-9-4 loss: 0.404703  [  160/  265]
train() client id: f_00001-9-5 loss: 0.513146  [  192/  265]
train() client id: f_00001-9-6 loss: 0.447730  [  224/  265]
train() client id: f_00001-9-7 loss: 0.547667  [  256/  265]
train() client id: f_00001-10-0 loss: 0.563496  [   32/  265]
train() client id: f_00001-10-1 loss: 0.469624  [   64/  265]
train() client id: f_00001-10-2 loss: 0.503751  [   96/  265]
train() client id: f_00001-10-3 loss: 0.565520  [  128/  265]
train() client id: f_00001-10-4 loss: 0.574692  [  160/  265]
train() client id: f_00001-10-5 loss: 0.386768  [  192/  265]
train() client id: f_00001-10-6 loss: 0.532188  [  224/  265]
train() client id: f_00001-10-7 loss: 0.408272  [  256/  265]
train() client id: f_00001-11-0 loss: 0.624965  [   32/  265]
train() client id: f_00001-11-1 loss: 0.574028  [   64/  265]
train() client id: f_00001-11-2 loss: 0.440607  [   96/  265]
train() client id: f_00001-11-3 loss: 0.441753  [  128/  265]
train() client id: f_00001-11-4 loss: 0.493762  [  160/  265]
train() client id: f_00001-11-5 loss: 0.551124  [  192/  265]
train() client id: f_00001-11-6 loss: 0.441281  [  224/  265]
train() client id: f_00001-11-7 loss: 0.418083  [  256/  265]
train() client id: f_00001-12-0 loss: 0.457667  [   32/  265]
train() client id: f_00001-12-1 loss: 0.530840  [   64/  265]
train() client id: f_00001-12-2 loss: 0.559928  [   96/  265]
train() client id: f_00001-12-3 loss: 0.418726  [  128/  265]
train() client id: f_00001-12-4 loss: 0.610261  [  160/  265]
train() client id: f_00001-12-5 loss: 0.498252  [  192/  265]
train() client id: f_00001-12-6 loss: 0.495392  [  224/  265]
train() client id: f_00001-12-7 loss: 0.418766  [  256/  265]
train() client id: f_00002-0-0 loss: 1.177665  [   32/  124]
train() client id: f_00002-0-1 loss: 1.046029  [   64/  124]
train() client id: f_00002-0-2 loss: 1.079920  [   96/  124]
train() client id: f_00002-1-0 loss: 1.156942  [   32/  124]
train() client id: f_00002-1-1 loss: 0.953414  [   64/  124]
train() client id: f_00002-1-2 loss: 1.066438  [   96/  124]
train() client id: f_00002-2-0 loss: 1.133494  [   32/  124]
train() client id: f_00002-2-1 loss: 0.932053  [   64/  124]
train() client id: f_00002-2-2 loss: 0.907102  [   96/  124]
train() client id: f_00002-3-0 loss: 1.094642  [   32/  124]
train() client id: f_00002-3-1 loss: 0.933549  [   64/  124]
train() client id: f_00002-3-2 loss: 1.018964  [   96/  124]
train() client id: f_00002-4-0 loss: 0.966159  [   32/  124]
train() client id: f_00002-4-1 loss: 1.053348  [   64/  124]
train() client id: f_00002-4-2 loss: 0.947750  [   96/  124]
train() client id: f_00002-5-0 loss: 0.993623  [   32/  124]
train() client id: f_00002-5-1 loss: 1.174539  [   64/  124]
train() client id: f_00002-5-2 loss: 0.773282  [   96/  124]
train() client id: f_00002-6-0 loss: 1.004540  [   32/  124]
train() client id: f_00002-6-1 loss: 0.914913  [   64/  124]
train() client id: f_00002-6-2 loss: 0.868785  [   96/  124]
train() client id: f_00002-7-0 loss: 0.845175  [   32/  124]
train() client id: f_00002-7-1 loss: 0.908002  [   64/  124]
train() client id: f_00002-7-2 loss: 0.903348  [   96/  124]
train() client id: f_00002-8-0 loss: 0.875678  [   32/  124]
train() client id: f_00002-8-1 loss: 1.022818  [   64/  124]
train() client id: f_00002-8-2 loss: 0.783466  [   96/  124]
train() client id: f_00002-9-0 loss: 0.922642  [   32/  124]
train() client id: f_00002-9-1 loss: 0.817304  [   64/  124]
train() client id: f_00002-9-2 loss: 0.941230  [   96/  124]
train() client id: f_00002-10-0 loss: 0.774296  [   32/  124]
train() client id: f_00002-10-1 loss: 0.949203  [   64/  124]
train() client id: f_00002-10-2 loss: 0.862639  [   96/  124]
train() client id: f_00002-11-0 loss: 0.848782  [   32/  124]
train() client id: f_00002-11-1 loss: 0.840023  [   64/  124]
train() client id: f_00002-11-2 loss: 0.809364  [   96/  124]
train() client id: f_00002-12-0 loss: 0.957073  [   32/  124]
train() client id: f_00002-12-1 loss: 0.933116  [   64/  124]
train() client id: f_00002-12-2 loss: 0.729954  [   96/  124]
train() client id: f_00003-0-0 loss: 0.831790  [   32/   43]
train() client id: f_00003-1-0 loss: 0.749741  [   32/   43]
train() client id: f_00003-2-0 loss: 0.698973  [   32/   43]
train() client id: f_00003-3-0 loss: 0.721959  [   32/   43]
train() client id: f_00003-4-0 loss: 0.783195  [   32/   43]
train() client id: f_00003-5-0 loss: 0.804809  [   32/   43]
train() client id: f_00003-6-0 loss: 0.717024  [   32/   43]
train() client id: f_00003-7-0 loss: 0.714460  [   32/   43]
train() client id: f_00003-8-0 loss: 0.799230  [   32/   43]
train() client id: f_00003-9-0 loss: 0.796047  [   32/   43]
train() client id: f_00003-10-0 loss: 0.795128  [   32/   43]
train() client id: f_00003-11-0 loss: 0.762944  [   32/   43]
train() client id: f_00003-12-0 loss: 0.842433  [   32/   43]
train() client id: f_00004-0-0 loss: 0.785878  [   32/  306]
train() client id: f_00004-0-1 loss: 0.679318  [   64/  306]
train() client id: f_00004-0-2 loss: 0.694416  [   96/  306]
train() client id: f_00004-0-3 loss: 0.590683  [  128/  306]
train() client id: f_00004-0-4 loss: 0.761209  [  160/  306]
train() client id: f_00004-0-5 loss: 0.676125  [  192/  306]
train() client id: f_00004-0-6 loss: 0.797290  [  224/  306]
train() client id: f_00004-0-7 loss: 0.741725  [  256/  306]
train() client id: f_00004-0-8 loss: 0.823247  [  288/  306]
train() client id: f_00004-1-0 loss: 0.713540  [   32/  306]
train() client id: f_00004-1-1 loss: 0.810814  [   64/  306]
train() client id: f_00004-1-2 loss: 0.692278  [   96/  306]
train() client id: f_00004-1-3 loss: 0.691431  [  128/  306]
train() client id: f_00004-1-4 loss: 0.630641  [  160/  306]
train() client id: f_00004-1-5 loss: 0.786781  [  192/  306]
train() client id: f_00004-1-6 loss: 0.703402  [  224/  306]
train() client id: f_00004-1-7 loss: 0.853681  [  256/  306]
train() client id: f_00004-1-8 loss: 0.678508  [  288/  306]
train() client id: f_00004-2-0 loss: 0.785877  [   32/  306]
train() client id: f_00004-2-1 loss: 0.898848  [   64/  306]
train() client id: f_00004-2-2 loss: 0.698576  [   96/  306]
train() client id: f_00004-2-3 loss: 0.632675  [  128/  306]
train() client id: f_00004-2-4 loss: 0.625406  [  160/  306]
train() client id: f_00004-2-5 loss: 0.789053  [  192/  306]
train() client id: f_00004-2-6 loss: 0.632428  [  224/  306]
train() client id: f_00004-2-7 loss: 0.766300  [  256/  306]
train() client id: f_00004-2-8 loss: 0.621809  [  288/  306]
train() client id: f_00004-3-0 loss: 0.696428  [   32/  306]
train() client id: f_00004-3-1 loss: 0.644725  [   64/  306]
train() client id: f_00004-3-2 loss: 0.840432  [   96/  306]
train() client id: f_00004-3-3 loss: 0.859004  [  128/  306]
train() client id: f_00004-3-4 loss: 0.694094  [  160/  306]
train() client id: f_00004-3-5 loss: 0.607108  [  192/  306]
train() client id: f_00004-3-6 loss: 0.670278  [  224/  306]
train() client id: f_00004-3-7 loss: 0.720788  [  256/  306]
train() client id: f_00004-3-8 loss: 0.803823  [  288/  306]
train() client id: f_00004-4-0 loss: 0.700434  [   32/  306]
train() client id: f_00004-4-1 loss: 0.685589  [   64/  306]
train() client id: f_00004-4-2 loss: 0.707552  [   96/  306]
train() client id: f_00004-4-3 loss: 0.856744  [  128/  306]
train() client id: f_00004-4-4 loss: 0.795950  [  160/  306]
train() client id: f_00004-4-5 loss: 0.626516  [  192/  306]
train() client id: f_00004-4-6 loss: 0.705794  [  224/  306]
train() client id: f_00004-4-7 loss: 0.679866  [  256/  306]
train() client id: f_00004-4-8 loss: 0.722417  [  288/  306]
train() client id: f_00004-5-0 loss: 0.748885  [   32/  306]
train() client id: f_00004-5-1 loss: 0.807306  [   64/  306]
train() client id: f_00004-5-2 loss: 0.689663  [   96/  306]
train() client id: f_00004-5-3 loss: 0.739941  [  128/  306]
train() client id: f_00004-5-4 loss: 0.827668  [  160/  306]
train() client id: f_00004-5-5 loss: 0.600650  [  192/  306]
train() client id: f_00004-5-6 loss: 0.692678  [  224/  306]
train() client id: f_00004-5-7 loss: 0.817231  [  256/  306]
train() client id: f_00004-5-8 loss: 0.660437  [  288/  306]
train() client id: f_00004-6-0 loss: 0.703525  [   32/  306]
train() client id: f_00004-6-1 loss: 0.672049  [   64/  306]
train() client id: f_00004-6-2 loss: 0.617757  [   96/  306]
train() client id: f_00004-6-3 loss: 0.715845  [  128/  306]
train() client id: f_00004-6-4 loss: 0.883133  [  160/  306]
train() client id: f_00004-6-5 loss: 0.766251  [  192/  306]
train() client id: f_00004-6-6 loss: 0.809688  [  224/  306]
train() client id: f_00004-6-7 loss: 0.735174  [  256/  306]
train() client id: f_00004-6-8 loss: 0.735973  [  288/  306]
train() client id: f_00004-7-0 loss: 0.631362  [   32/  306]
train() client id: f_00004-7-1 loss: 0.756408  [   64/  306]
train() client id: f_00004-7-2 loss: 0.631154  [   96/  306]
train() client id: f_00004-7-3 loss: 0.803532  [  128/  306]
train() client id: f_00004-7-4 loss: 0.858217  [  160/  306]
train() client id: f_00004-7-5 loss: 0.737549  [  192/  306]
train() client id: f_00004-7-6 loss: 0.794868  [  224/  306]
train() client id: f_00004-7-7 loss: 0.793162  [  256/  306]
train() client id: f_00004-7-8 loss: 0.643795  [  288/  306]
train() client id: f_00004-8-0 loss: 0.790285  [   32/  306]
train() client id: f_00004-8-1 loss: 0.720585  [   64/  306]
train() client id: f_00004-8-2 loss: 0.611654  [   96/  306]
train() client id: f_00004-8-3 loss: 0.800440  [  128/  306]
train() client id: f_00004-8-4 loss: 0.760518  [  160/  306]
train() client id: f_00004-8-5 loss: 0.709232  [  192/  306]
train() client id: f_00004-8-6 loss: 0.779711  [  224/  306]
train() client id: f_00004-8-7 loss: 0.785394  [  256/  306]
train() client id: f_00004-8-8 loss: 0.701007  [  288/  306]
train() client id: f_00004-9-0 loss: 0.689533  [   32/  306]
train() client id: f_00004-9-1 loss: 0.705778  [   64/  306]
train() client id: f_00004-9-2 loss: 0.774335  [   96/  306]
train() client id: f_00004-9-3 loss: 0.629690  [  128/  306]
train() client id: f_00004-9-4 loss: 0.761485  [  160/  306]
train() client id: f_00004-9-5 loss: 0.628618  [  192/  306]
train() client id: f_00004-9-6 loss: 0.860517  [  224/  306]
train() client id: f_00004-9-7 loss: 0.705686  [  256/  306]
train() client id: f_00004-9-8 loss: 0.867830  [  288/  306]
train() client id: f_00004-10-0 loss: 0.715028  [   32/  306]
train() client id: f_00004-10-1 loss: 0.787302  [   64/  306]
train() client id: f_00004-10-2 loss: 0.718547  [   96/  306]
train() client id: f_00004-10-3 loss: 0.851345  [  128/  306]
train() client id: f_00004-10-4 loss: 0.615554  [  160/  306]
train() client id: f_00004-10-5 loss: 0.683638  [  192/  306]
train() client id: f_00004-10-6 loss: 0.665248  [  224/  306]
train() client id: f_00004-10-7 loss: 0.786599  [  256/  306]
train() client id: f_00004-10-8 loss: 0.749829  [  288/  306]
train() client id: f_00004-11-0 loss: 0.647880  [   32/  306]
train() client id: f_00004-11-1 loss: 0.684195  [   64/  306]
train() client id: f_00004-11-2 loss: 0.807241  [   96/  306]
train() client id: f_00004-11-3 loss: 0.702929  [  128/  306]
train() client id: f_00004-11-4 loss: 0.791385  [  160/  306]
train() client id: f_00004-11-5 loss: 0.772984  [  192/  306]
train() client id: f_00004-11-6 loss: 0.655318  [  224/  306]
train() client id: f_00004-11-7 loss: 0.766964  [  256/  306]
train() client id: f_00004-11-8 loss: 0.891628  [  288/  306]
train() client id: f_00004-12-0 loss: 0.815058  [   32/  306]
train() client id: f_00004-12-1 loss: 0.787188  [   64/  306]
train() client id: f_00004-12-2 loss: 0.620022  [   96/  306]
train() client id: f_00004-12-3 loss: 0.780724  [  128/  306]
train() client id: f_00004-12-4 loss: 0.714775  [  160/  306]
train() client id: f_00004-12-5 loss: 0.670889  [  192/  306]
train() client id: f_00004-12-6 loss: 0.730210  [  224/  306]
train() client id: f_00004-12-7 loss: 0.736124  [  256/  306]
train() client id: f_00004-12-8 loss: 0.764569  [  288/  306]
train() client id: f_00005-0-0 loss: 0.607794  [   32/  146]
train() client id: f_00005-0-1 loss: 0.832639  [   64/  146]
train() client id: f_00005-0-2 loss: 0.542867  [   96/  146]
train() client id: f_00005-0-3 loss: 0.663880  [  128/  146]
train() client id: f_00005-1-0 loss: 0.620181  [   32/  146]
train() client id: f_00005-1-1 loss: 0.793614  [   64/  146]
train() client id: f_00005-1-2 loss: 0.621587  [   96/  146]
train() client id: f_00005-1-3 loss: 0.573847  [  128/  146]
train() client id: f_00005-2-0 loss: 0.668781  [   32/  146]
train() client id: f_00005-2-1 loss: 0.545989  [   64/  146]
train() client id: f_00005-2-2 loss: 0.808641  [   96/  146]
train() client id: f_00005-2-3 loss: 0.556916  [  128/  146]
train() client id: f_00005-3-0 loss: 0.673640  [   32/  146]
train() client id: f_00005-3-1 loss: 0.783606  [   64/  146]
train() client id: f_00005-3-2 loss: 0.580778  [   96/  146]
train() client id: f_00005-3-3 loss: 0.678038  [  128/  146]
train() client id: f_00005-4-0 loss: 0.629284  [   32/  146]
train() client id: f_00005-4-1 loss: 0.372409  [   64/  146]
train() client id: f_00005-4-2 loss: 0.854509  [   96/  146]
train() client id: f_00005-4-3 loss: 0.738258  [  128/  146]
train() client id: f_00005-5-0 loss: 0.785499  [   32/  146]
train() client id: f_00005-5-1 loss: 0.544188  [   64/  146]
train() client id: f_00005-5-2 loss: 0.746683  [   96/  146]
train() client id: f_00005-5-3 loss: 0.601617  [  128/  146]
train() client id: f_00005-6-0 loss: 0.683206  [   32/  146]
train() client id: f_00005-6-1 loss: 0.599193  [   64/  146]
train() client id: f_00005-6-2 loss: 0.591126  [   96/  146]
train() client id: f_00005-6-3 loss: 0.759829  [  128/  146]
train() client id: f_00005-7-0 loss: 0.623775  [   32/  146]
train() client id: f_00005-7-1 loss: 0.569752  [   64/  146]
train() client id: f_00005-7-2 loss: 0.746845  [   96/  146]
train() client id: f_00005-7-3 loss: 0.791627  [  128/  146]
train() client id: f_00005-8-0 loss: 0.739656  [   32/  146]
train() client id: f_00005-8-1 loss: 0.658830  [   64/  146]
train() client id: f_00005-8-2 loss: 0.714359  [   96/  146]
train() client id: f_00005-8-3 loss: 0.622171  [  128/  146]
train() client id: f_00005-9-0 loss: 0.676241  [   32/  146]
train() client id: f_00005-9-1 loss: 1.078575  [   64/  146]
train() client id: f_00005-9-2 loss: 0.502396  [   96/  146]
train() client id: f_00005-9-3 loss: 0.562125  [  128/  146]
train() client id: f_00005-10-0 loss: 0.737282  [   32/  146]
train() client id: f_00005-10-1 loss: 0.691017  [   64/  146]
train() client id: f_00005-10-2 loss: 0.705832  [   96/  146]
train() client id: f_00005-10-3 loss: 0.564092  [  128/  146]
train() client id: f_00005-11-0 loss: 0.830671  [   32/  146]
train() client id: f_00005-11-1 loss: 0.389214  [   64/  146]
train() client id: f_00005-11-2 loss: 0.645558  [   96/  146]
train() client id: f_00005-11-3 loss: 0.721948  [  128/  146]
train() client id: f_00005-12-0 loss: 0.816155  [   32/  146]
train() client id: f_00005-12-1 loss: 0.591924  [   64/  146]
train() client id: f_00005-12-2 loss: 0.588597  [   96/  146]
train() client id: f_00005-12-3 loss: 0.644292  [  128/  146]
train() client id: f_00006-0-0 loss: 0.533798  [   32/   54]
train() client id: f_00006-1-0 loss: 0.526995  [   32/   54]
train() client id: f_00006-2-0 loss: 0.494415  [   32/   54]
train() client id: f_00006-3-0 loss: 0.537484  [   32/   54]
train() client id: f_00006-4-0 loss: 0.532859  [   32/   54]
train() client id: f_00006-5-0 loss: 0.539185  [   32/   54]
train() client id: f_00006-6-0 loss: 0.537453  [   32/   54]
train() client id: f_00006-7-0 loss: 0.523825  [   32/   54]
train() client id: f_00006-8-0 loss: 0.567003  [   32/   54]
train() client id: f_00006-9-0 loss: 0.574802  [   32/   54]
train() client id: f_00006-10-0 loss: 0.529461  [   32/   54]
train() client id: f_00006-11-0 loss: 0.502750  [   32/   54]
train() client id: f_00006-12-0 loss: 0.528917  [   32/   54]
train() client id: f_00007-0-0 loss: 0.548099  [   32/  179]
train() client id: f_00007-0-1 loss: 0.442087  [   64/  179]
train() client id: f_00007-0-2 loss: 0.392580  [   96/  179]
train() client id: f_00007-0-3 loss: 0.536859  [  128/  179]
train() client id: f_00007-0-4 loss: 0.715351  [  160/  179]
train() client id: f_00007-1-0 loss: 0.534167  [   32/  179]
train() client id: f_00007-1-1 loss: 0.408224  [   64/  179]
train() client id: f_00007-1-2 loss: 0.450554  [   96/  179]
train() client id: f_00007-1-3 loss: 0.635697  [  128/  179]
train() client id: f_00007-1-4 loss: 0.409927  [  160/  179]
train() client id: f_00007-2-0 loss: 0.454786  [   32/  179]
train() client id: f_00007-2-1 loss: 0.410389  [   64/  179]
train() client id: f_00007-2-2 loss: 0.425057  [   96/  179]
train() client id: f_00007-2-3 loss: 0.601643  [  128/  179]
train() client id: f_00007-2-4 loss: 0.635631  [  160/  179]
train() client id: f_00007-3-0 loss: 0.583432  [   32/  179]
train() client id: f_00007-3-1 loss: 0.357682  [   64/  179]
train() client id: f_00007-3-2 loss: 0.364555  [   96/  179]
train() client id: f_00007-3-3 loss: 0.567098  [  128/  179]
train() client id: f_00007-3-4 loss: 0.352634  [  160/  179]
train() client id: f_00007-4-0 loss: 0.485809  [   32/  179]
train() client id: f_00007-4-1 loss: 0.378347  [   64/  179]
train() client id: f_00007-4-2 loss: 0.553620  [   96/  179]
train() client id: f_00007-4-3 loss: 0.501173  [  128/  179]
train() client id: f_00007-4-4 loss: 0.421583  [  160/  179]
train() client id: f_00007-5-0 loss: 0.545149  [   32/  179]
train() client id: f_00007-5-1 loss: 0.420722  [   64/  179]
train() client id: f_00007-5-2 loss: 0.353606  [   96/  179]
train() client id: f_00007-5-3 loss: 0.570209  [  128/  179]
train() client id: f_00007-5-4 loss: 0.484679  [  160/  179]
train() client id: f_00007-6-0 loss: 0.373702  [   32/  179]
train() client id: f_00007-6-1 loss: 0.493850  [   64/  179]
train() client id: f_00007-6-2 loss: 0.575215  [   96/  179]
train() client id: f_00007-6-3 loss: 0.505139  [  128/  179]
train() client id: f_00007-6-4 loss: 0.304319  [  160/  179]
train() client id: f_00007-7-0 loss: 0.545069  [   32/  179]
train() client id: f_00007-7-1 loss: 0.414970  [   64/  179]
train() client id: f_00007-7-2 loss: 0.383650  [   96/  179]
train() client id: f_00007-7-3 loss: 0.461625  [  128/  179]
train() client id: f_00007-7-4 loss: 0.418834  [  160/  179]
train() client id: f_00007-8-0 loss: 0.349178  [   32/  179]
train() client id: f_00007-8-1 loss: 0.379745  [   64/  179]
train() client id: f_00007-8-2 loss: 0.657881  [   96/  179]
train() client id: f_00007-8-3 loss: 0.440835  [  128/  179]
train() client id: f_00007-8-4 loss: 0.278961  [  160/  179]
train() client id: f_00007-9-0 loss: 0.512289  [   32/  179]
train() client id: f_00007-9-1 loss: 0.634877  [   64/  179]
train() client id: f_00007-9-2 loss: 0.474014  [   96/  179]
train() client id: f_00007-9-3 loss: 0.402322  [  128/  179]
train() client id: f_00007-9-4 loss: 0.287073  [  160/  179]
train() client id: f_00007-10-0 loss: 0.491932  [   32/  179]
train() client id: f_00007-10-1 loss: 0.282793  [   64/  179]
train() client id: f_00007-10-2 loss: 0.270026  [   96/  179]
train() client id: f_00007-10-3 loss: 0.526970  [  128/  179]
train() client id: f_00007-10-4 loss: 0.509000  [  160/  179]
train() client id: f_00007-11-0 loss: 0.634124  [   32/  179]
train() client id: f_00007-11-1 loss: 0.362650  [   64/  179]
train() client id: f_00007-11-2 loss: 0.474099  [   96/  179]
train() client id: f_00007-11-3 loss: 0.415170  [  128/  179]
train() client id: f_00007-11-4 loss: 0.397972  [  160/  179]
train() client id: f_00007-12-0 loss: 0.453535  [   32/  179]
train() client id: f_00007-12-1 loss: 0.518013  [   64/  179]
train() client id: f_00007-12-2 loss: 0.399453  [   96/  179]
train() client id: f_00007-12-3 loss: 0.379338  [  128/  179]
train() client id: f_00007-12-4 loss: 0.509979  [  160/  179]
train() client id: f_00008-0-0 loss: 0.854250  [   32/  130]
train() client id: f_00008-0-1 loss: 0.834993  [   64/  130]
train() client id: f_00008-0-2 loss: 0.888537  [   96/  130]
train() client id: f_00008-0-3 loss: 0.848024  [  128/  130]
train() client id: f_00008-1-0 loss: 0.815221  [   32/  130]
train() client id: f_00008-1-1 loss: 0.852602  [   64/  130]
train() client id: f_00008-1-2 loss: 0.830641  [   96/  130]
train() client id: f_00008-1-3 loss: 0.910864  [  128/  130]
train() client id: f_00008-2-0 loss: 0.783725  [   32/  130]
train() client id: f_00008-2-1 loss: 0.841044  [   64/  130]
train() client id: f_00008-2-2 loss: 0.952890  [   96/  130]
train() client id: f_00008-2-3 loss: 0.825203  [  128/  130]
train() client id: f_00008-3-0 loss: 0.857831  [   32/  130]
train() client id: f_00008-3-1 loss: 0.876739  [   64/  130]
train() client id: f_00008-3-2 loss: 0.819741  [   96/  130]
train() client id: f_00008-3-3 loss: 0.872331  [  128/  130]
train() client id: f_00008-4-0 loss: 0.889188  [   32/  130]
train() client id: f_00008-4-1 loss: 0.994233  [   64/  130]
train() client id: f_00008-4-2 loss: 0.800489  [   96/  130]
train() client id: f_00008-4-3 loss: 0.728602  [  128/  130]
train() client id: f_00008-5-0 loss: 0.963919  [   32/  130]
train() client id: f_00008-5-1 loss: 0.683774  [   64/  130]
train() client id: f_00008-5-2 loss: 0.823428  [   96/  130]
train() client id: f_00008-5-3 loss: 0.948229  [  128/  130]
train() client id: f_00008-6-0 loss: 0.791241  [   32/  130]
train() client id: f_00008-6-1 loss: 0.959467  [   64/  130]
train() client id: f_00008-6-2 loss: 0.867110  [   96/  130]
train() client id: f_00008-6-3 loss: 0.807702  [  128/  130]
train() client id: f_00008-7-0 loss: 0.857903  [   32/  130]
train() client id: f_00008-7-1 loss: 0.795398  [   64/  130]
train() client id: f_00008-7-2 loss: 0.917395  [   96/  130]
train() client id: f_00008-7-3 loss: 0.828150  [  128/  130]
train() client id: f_00008-8-0 loss: 0.761215  [   32/  130]
train() client id: f_00008-8-1 loss: 0.834871  [   64/  130]
train() client id: f_00008-8-2 loss: 0.937481  [   96/  130]
train() client id: f_00008-8-3 loss: 0.884765  [  128/  130]
train() client id: f_00008-9-0 loss: 0.788919  [   32/  130]
train() client id: f_00008-9-1 loss: 0.825138  [   64/  130]
train() client id: f_00008-9-2 loss: 0.921772  [   96/  130]
train() client id: f_00008-9-3 loss: 0.857782  [  128/  130]
train() client id: f_00008-10-0 loss: 0.765594  [   32/  130]
train() client id: f_00008-10-1 loss: 0.917535  [   64/  130]
train() client id: f_00008-10-2 loss: 0.756734  [   96/  130]
train() client id: f_00008-10-3 loss: 0.930511  [  128/  130]
train() client id: f_00008-11-0 loss: 0.779035  [   32/  130]
train() client id: f_00008-11-1 loss: 0.988528  [   64/  130]
train() client id: f_00008-11-2 loss: 0.803030  [   96/  130]
train() client id: f_00008-11-3 loss: 0.851916  [  128/  130]
train() client id: f_00008-12-0 loss: 0.924932  [   32/  130]
train() client id: f_00008-12-1 loss: 0.771109  [   64/  130]
train() client id: f_00008-12-2 loss: 0.768441  [   96/  130]
train() client id: f_00008-12-3 loss: 0.951649  [  128/  130]
train() client id: f_00009-0-0 loss: 1.113583  [   32/  118]
train() client id: f_00009-0-1 loss: 1.270553  [   64/  118]
train() client id: f_00009-0-2 loss: 1.035159  [   96/  118]
train() client id: f_00009-1-0 loss: 1.106682  [   32/  118]
train() client id: f_00009-1-1 loss: 1.092589  [   64/  118]
train() client id: f_00009-1-2 loss: 1.130687  [   96/  118]
train() client id: f_00009-2-0 loss: 1.044213  [   32/  118]
train() client id: f_00009-2-1 loss: 1.104537  [   64/  118]
train() client id: f_00009-2-2 loss: 0.950102  [   96/  118]
train() client id: f_00009-3-0 loss: 1.056586  [   32/  118]
train() client id: f_00009-3-1 loss: 1.041563  [   64/  118]
train() client id: f_00009-3-2 loss: 1.011952  [   96/  118]
train() client id: f_00009-4-0 loss: 1.064678  [   32/  118]
train() client id: f_00009-4-1 loss: 0.905343  [   64/  118]
train() client id: f_00009-4-2 loss: 1.047649  [   96/  118]
train() client id: f_00009-5-0 loss: 0.895883  [   32/  118]
train() client id: f_00009-5-1 loss: 1.015137  [   64/  118]
train() client id: f_00009-5-2 loss: 0.922928  [   96/  118]
train() client id: f_00009-6-0 loss: 0.855535  [   32/  118]
train() client id: f_00009-6-1 loss: 0.932242  [   64/  118]
train() client id: f_00009-6-2 loss: 0.951827  [   96/  118]
train() client id: f_00009-7-0 loss: 0.885976  [   32/  118]
train() client id: f_00009-7-1 loss: 0.989531  [   64/  118]
train() client id: f_00009-7-2 loss: 0.816687  [   96/  118]
train() client id: f_00009-8-0 loss: 0.982148  [   32/  118]
train() client id: f_00009-8-1 loss: 0.886130  [   64/  118]
train() client id: f_00009-8-2 loss: 0.858106  [   96/  118]
train() client id: f_00009-9-0 loss: 0.974148  [   32/  118]
train() client id: f_00009-9-1 loss: 0.818010  [   64/  118]
train() client id: f_00009-9-2 loss: 0.874047  [   96/  118]
train() client id: f_00009-10-0 loss: 0.747623  [   32/  118]
train() client id: f_00009-10-1 loss: 0.975814  [   64/  118]
train() client id: f_00009-10-2 loss: 0.875646  [   96/  118]
train() client id: f_00009-11-0 loss: 0.773608  [   32/  118]
train() client id: f_00009-11-1 loss: 1.015842  [   64/  118]
train() client id: f_00009-11-2 loss: 0.900518  [   96/  118]
train() client id: f_00009-12-0 loss: 0.864480  [   32/  118]
train() client id: f_00009-12-1 loss: 0.838822  [   64/  118]
train() client id: f_00009-12-2 loss: 0.889476  [   96/  118]
At round 19 accuracy: 0.6339522546419099
At round 19 training accuracy: 0.5875251509054326
At round 19 training loss: 0.8380321714826378
gradient difference: 0.48339200019836426
train() client id: f_00000-0-0 loss: 1.049356  [   32/  126]
train() client id: f_00000-0-1 loss: 1.150709  [   64/  126]
train() client id: f_00000-0-2 loss: 1.103416  [   96/  126]
train() client id: f_00000-1-0 loss: 1.109356  [   32/  126]
train() client id: f_00000-1-1 loss: 0.999899  [   64/  126]
train() client id: f_00000-1-2 loss: 1.075162  [   96/  126]
train() client id: f_00000-2-0 loss: 1.038899  [   32/  126]
train() client id: f_00000-2-1 loss: 0.926691  [   64/  126]
train() client id: f_00000-2-2 loss: 1.114873  [   96/  126]
train() client id: f_00000-3-0 loss: 1.011952  [   32/  126]
train() client id: f_00000-3-1 loss: 0.866428  [   64/  126]
train() client id: f_00000-3-2 loss: 0.961368  [   96/  126]
train() client id: f_00000-4-0 loss: 0.970218  [   32/  126]
train() client id: f_00000-4-1 loss: 0.900534  [   64/  126]
train() client id: f_00000-4-2 loss: 0.960392  [   96/  126]
train() client id: f_00000-5-0 loss: 0.984704  [   32/  126]
train() client id: f_00000-5-1 loss: 0.949015  [   64/  126]
train() client id: f_00000-5-2 loss: 0.723845  [   96/  126]
train() client id: f_00000-6-0 loss: 0.764478  [   32/  126]
train() client id: f_00000-6-1 loss: 0.992254  [   64/  126]
train() client id: f_00000-6-2 loss: 0.974123  [   96/  126]
train() client id: f_00000-7-0 loss: 1.010698  [   32/  126]
train() client id: f_00000-7-1 loss: 0.820027  [   64/  126]
train() client id: f_00000-7-2 loss: 0.748012  [   96/  126]
train() client id: f_00000-8-0 loss: 0.842673  [   32/  126]
train() client id: f_00000-8-1 loss: 0.859864  [   64/  126]
train() client id: f_00000-8-2 loss: 0.921922  [   96/  126]
train() client id: f_00000-9-0 loss: 0.852564  [   32/  126]
train() client id: f_00000-9-1 loss: 0.889428  [   64/  126]
train() client id: f_00000-9-2 loss: 0.867378  [   96/  126]
train() client id: f_00000-10-0 loss: 0.840446  [   32/  126]
train() client id: f_00000-10-1 loss: 0.801206  [   64/  126]
train() client id: f_00000-10-2 loss: 0.948909  [   96/  126]
train() client id: f_00000-11-0 loss: 0.882700  [   32/  126]
train() client id: f_00000-11-1 loss: 0.772478  [   64/  126]
train() client id: f_00000-11-2 loss: 1.003746  [   96/  126]
train() client id: f_00000-12-0 loss: 0.862803  [   32/  126]
train() client id: f_00000-12-1 loss: 0.773621  [   64/  126]
train() client id: f_00000-12-2 loss: 1.001689  [   96/  126]
train() client id: f_00001-0-0 loss: 0.575833  [   32/  265]
train() client id: f_00001-0-1 loss: 0.601823  [   64/  265]
train() client id: f_00001-0-2 loss: 0.504156  [   96/  265]
train() client id: f_00001-0-3 loss: 0.511778  [  128/  265]
train() client id: f_00001-0-4 loss: 0.448793  [  160/  265]
train() client id: f_00001-0-5 loss: 0.563993  [  192/  265]
train() client id: f_00001-0-6 loss: 0.503386  [  224/  265]
train() client id: f_00001-0-7 loss: 0.490405  [  256/  265]
train() client id: f_00001-1-0 loss: 0.537789  [   32/  265]
train() client id: f_00001-1-1 loss: 0.525765  [   64/  265]
train() client id: f_00001-1-2 loss: 0.466755  [   96/  265]
train() client id: f_00001-1-3 loss: 0.464892  [  128/  265]
train() client id: f_00001-1-4 loss: 0.521262  [  160/  265]
train() client id: f_00001-1-5 loss: 0.668195  [  192/  265]
train() client id: f_00001-1-6 loss: 0.491190  [  224/  265]
train() client id: f_00001-1-7 loss: 0.536137  [  256/  265]
train() client id: f_00001-2-0 loss: 0.475582  [   32/  265]
train() client id: f_00001-2-1 loss: 0.496934  [   64/  265]
train() client id: f_00001-2-2 loss: 0.540425  [   96/  265]
train() client id: f_00001-2-3 loss: 0.588551  [  128/  265]
train() client id: f_00001-2-4 loss: 0.552354  [  160/  265]
train() client id: f_00001-2-5 loss: 0.510468  [  192/  265]
train() client id: f_00001-2-6 loss: 0.476049  [  224/  265]
train() client id: f_00001-2-7 loss: 0.511006  [  256/  265]
train() client id: f_00001-3-0 loss: 0.622889  [   32/  265]
train() client id: f_00001-3-1 loss: 0.464762  [   64/  265]
train() client id: f_00001-3-2 loss: 0.562457  [   96/  265]
train() client id: f_00001-3-3 loss: 0.449707  [  128/  265]
train() client id: f_00001-3-4 loss: 0.455173  [  160/  265]
train() client id: f_00001-3-5 loss: 0.487271  [  192/  265]
train() client id: f_00001-3-6 loss: 0.533099  [  224/  265]
train() client id: f_00001-3-7 loss: 0.474973  [  256/  265]
train() client id: f_00001-4-0 loss: 0.421885  [   32/  265]
train() client id: f_00001-4-1 loss: 0.707279  [   64/  265]
train() client id: f_00001-4-2 loss: 0.457296  [   96/  265]
train() client id: f_00001-4-3 loss: 0.490813  [  128/  265]
train() client id: f_00001-4-4 loss: 0.442608  [  160/  265]
train() client id: f_00001-4-5 loss: 0.461394  [  192/  265]
train() client id: f_00001-4-6 loss: 0.483008  [  224/  265]
train() client id: f_00001-4-7 loss: 0.639621  [  256/  265]
train() client id: f_00001-5-0 loss: 0.478478  [   32/  265]
train() client id: f_00001-5-1 loss: 0.513678  [   64/  265]
train() client id: f_00001-5-2 loss: 0.450888  [   96/  265]
train() client id: f_00001-5-3 loss: 0.588071  [  128/  265]
train() client id: f_00001-5-4 loss: 0.416757  [  160/  265]
train() client id: f_00001-5-5 loss: 0.598228  [  192/  265]
train() client id: f_00001-5-6 loss: 0.484569  [  224/  265]
train() client id: f_00001-5-7 loss: 0.554926  [  256/  265]
train() client id: f_00001-6-0 loss: 0.460853  [   32/  265]
train() client id: f_00001-6-1 loss: 0.580686  [   64/  265]
train() client id: f_00001-6-2 loss: 0.550232  [   96/  265]
train() client id: f_00001-6-3 loss: 0.523676  [  128/  265]
train() client id: f_00001-6-4 loss: 0.451230  [  160/  265]
train() client id: f_00001-6-5 loss: 0.484636  [  192/  265]
train() client id: f_00001-6-6 loss: 0.458477  [  224/  265]
train() client id: f_00001-6-7 loss: 0.548538  [  256/  265]
train() client id: f_00001-7-0 loss: 0.669284  [   32/  265]
train() client id: f_00001-7-1 loss: 0.445932  [   64/  265]
train() client id: f_00001-7-2 loss: 0.456392  [   96/  265]
train() client id: f_00001-7-3 loss: 0.402235  [  128/  265]
train() client id: f_00001-7-4 loss: 0.559820  [  160/  265]
train() client id: f_00001-7-5 loss: 0.572078  [  192/  265]
train() client id: f_00001-7-6 loss: 0.466144  [  224/  265]
train() client id: f_00001-7-7 loss: 0.498553  [  256/  265]
train() client id: f_00001-8-0 loss: 0.503315  [   32/  265]
train() client id: f_00001-8-1 loss: 0.471081  [   64/  265]
train() client id: f_00001-8-2 loss: 0.535278  [   96/  265]
train() client id: f_00001-8-3 loss: 0.468784  [  128/  265]
train() client id: f_00001-8-4 loss: 0.583088  [  160/  265]
train() client id: f_00001-8-5 loss: 0.426952  [  192/  265]
train() client id: f_00001-8-6 loss: 0.420878  [  224/  265]
train() client id: f_00001-8-7 loss: 0.642676  [  256/  265]
train() client id: f_00001-9-0 loss: 0.487949  [   32/  265]
train() client id: f_00001-9-1 loss: 0.547052  [   64/  265]
train() client id: f_00001-9-2 loss: 0.620490  [   96/  265]
train() client id: f_00001-9-3 loss: 0.570278  [  128/  265]
train() client id: f_00001-9-4 loss: 0.461222  [  160/  265]
train() client id: f_00001-9-5 loss: 0.484695  [  192/  265]
train() client id: f_00001-9-6 loss: 0.452920  [  224/  265]
train() client id: f_00001-9-7 loss: 0.427198  [  256/  265]
train() client id: f_00001-10-0 loss: 0.473164  [   32/  265]
train() client id: f_00001-10-1 loss: 0.439085  [   64/  265]
train() client id: f_00001-10-2 loss: 0.553157  [   96/  265]
train() client id: f_00001-10-3 loss: 0.721215  [  128/  265]
train() client id: f_00001-10-4 loss: 0.461280  [  160/  265]
train() client id: f_00001-10-5 loss: 0.509792  [  192/  265]
train() client id: f_00001-10-6 loss: 0.462873  [  224/  265]
train() client id: f_00001-10-7 loss: 0.445323  [  256/  265]
train() client id: f_00001-11-0 loss: 0.507436  [   32/  265]
train() client id: f_00001-11-1 loss: 0.471770  [   64/  265]
train() client id: f_00001-11-2 loss: 0.533211  [   96/  265]
train() client id: f_00001-11-3 loss: 0.538074  [  128/  265]
train() client id: f_00001-11-4 loss: 0.598038  [  160/  265]
train() client id: f_00001-11-5 loss: 0.401196  [  192/  265]
train() client id: f_00001-11-6 loss: 0.466947  [  224/  265]
train() client id: f_00001-11-7 loss: 0.489429  [  256/  265]
train() client id: f_00001-12-0 loss: 0.496285  [   32/  265]
train() client id: f_00001-12-1 loss: 0.469972  [   64/  265]
train() client id: f_00001-12-2 loss: 0.524589  [   96/  265]
train() client id: f_00001-12-3 loss: 0.429705  [  128/  265]
train() client id: f_00001-12-4 loss: 0.666673  [  160/  265]
train() client id: f_00001-12-5 loss: 0.443947  [  192/  265]
train() client id: f_00001-12-6 loss: 0.486654  [  224/  265]
train() client id: f_00001-12-7 loss: 0.469997  [  256/  265]
train() client id: f_00002-0-0 loss: 1.217142  [   32/  124]
train() client id: f_00002-0-1 loss: 1.430479  [   64/  124]
train() client id: f_00002-0-2 loss: 1.284904  [   96/  124]
train() client id: f_00002-1-0 loss: 1.270487  [   32/  124]
train() client id: f_00002-1-1 loss: 1.229033  [   64/  124]
train() client id: f_00002-1-2 loss: 1.262022  [   96/  124]
train() client id: f_00002-2-0 loss: 1.272743  [   32/  124]
train() client id: f_00002-2-1 loss: 1.283048  [   64/  124]
train() client id: f_00002-2-2 loss: 1.298497  [   96/  124]
train() client id: f_00002-3-0 loss: 1.278012  [   32/  124]
train() client id: f_00002-3-1 loss: 1.278528  [   64/  124]
train() client id: f_00002-3-2 loss: 1.083810  [   96/  124]
train() client id: f_00002-4-0 loss: 1.318588  [   32/  124]
train() client id: f_00002-4-1 loss: 1.196238  [   64/  124]
train() client id: f_00002-4-2 loss: 1.187259  [   96/  124]
train() client id: f_00002-5-0 loss: 1.122916  [   32/  124]
train() client id: f_00002-5-1 loss: 1.246449  [   64/  124]
train() client id: f_00002-5-2 loss: 1.254048  [   96/  124]
train() client id: f_00002-6-0 loss: 1.261274  [   32/  124]
train() client id: f_00002-6-1 loss: 1.203094  [   64/  124]
train() client id: f_00002-6-2 loss: 1.099054  [   96/  124]
train() client id: f_00002-7-0 loss: 1.230650  [   32/  124]
train() client id: f_00002-7-1 loss: 1.139360  [   64/  124]
train() client id: f_00002-7-2 loss: 1.048497  [   96/  124]
train() client id: f_00002-8-0 loss: 1.132767  [   32/  124]
train() client id: f_00002-8-1 loss: 1.107860  [   64/  124]
train() client id: f_00002-8-2 loss: 1.212666  [   96/  124]
train() client id: f_00002-9-0 loss: 1.269419  [   32/  124]
train() client id: f_00002-9-1 loss: 1.077847  [   64/  124]
train() client id: f_00002-9-2 loss: 1.095323  [   96/  124]
train() client id: f_00002-10-0 loss: 1.059688  [   32/  124]
train() client id: f_00002-10-1 loss: 1.263716  [   64/  124]
train() client id: f_00002-10-2 loss: 1.086061  [   96/  124]
train() client id: f_00002-11-0 loss: 1.074251  [   32/  124]
train() client id: f_00002-11-1 loss: 1.204244  [   64/  124]
train() client id: f_00002-11-2 loss: 1.145497  [   96/  124]
train() client id: f_00002-12-0 loss: 1.012310  [   32/  124]
train() client id: f_00002-12-1 loss: 1.343445  [   64/  124]
train() client id: f_00002-12-2 loss: 1.284096  [   96/  124]
train() client id: f_00003-0-0 loss: 0.607268  [   32/   43]
train() client id: f_00003-1-0 loss: 0.541300  [   32/   43]
train() client id: f_00003-2-0 loss: 0.522040  [   32/   43]
train() client id: f_00003-3-0 loss: 0.631817  [   32/   43]
train() client id: f_00003-4-0 loss: 0.661348  [   32/   43]
train() client id: f_00003-5-0 loss: 0.767381  [   32/   43]
train() client id: f_00003-6-0 loss: 0.564439  [   32/   43]
train() client id: f_00003-7-0 loss: 0.630028  [   32/   43]
train() client id: f_00003-8-0 loss: 0.638690  [   32/   43]
train() client id: f_00003-9-0 loss: 0.842165  [   32/   43]
train() client id: f_00003-10-0 loss: 0.572244  [   32/   43]
train() client id: f_00003-11-0 loss: 0.664019  [   32/   43]
train() client id: f_00003-12-0 loss: 0.758593  [   32/   43]
train() client id: f_00004-0-0 loss: 0.788100  [   32/  306]
train() client id: f_00004-0-1 loss: 0.942938  [   64/  306]
train() client id: f_00004-0-2 loss: 0.865492  [   96/  306]
train() client id: f_00004-0-3 loss: 0.860603  [  128/  306]
train() client id: f_00004-0-4 loss: 0.741017  [  160/  306]
train() client id: f_00004-0-5 loss: 0.876261  [  192/  306]
train() client id: f_00004-0-6 loss: 0.883881  [  224/  306]
train() client id: f_00004-0-7 loss: 0.877518  [  256/  306]
train() client id: f_00004-0-8 loss: 0.762264  [  288/  306]
train() client id: f_00004-1-0 loss: 0.888224  [   32/  306]
train() client id: f_00004-1-1 loss: 0.712403  [   64/  306]
train() client id: f_00004-1-2 loss: 0.825673  [   96/  306]
train() client id: f_00004-1-3 loss: 0.845419  [  128/  306]
train() client id: f_00004-1-4 loss: 0.811203  [  160/  306]
train() client id: f_00004-1-5 loss: 0.745714  [  192/  306]
train() client id: f_00004-1-6 loss: 0.842973  [  224/  306]
train() client id: f_00004-1-7 loss: 0.964317  [  256/  306]
train() client id: f_00004-1-8 loss: 0.941859  [  288/  306]
train() client id: f_00004-2-0 loss: 0.949591  [   32/  306]
train() client id: f_00004-2-1 loss: 0.869577  [   64/  306]
train() client id: f_00004-2-2 loss: 0.718022  [   96/  306]
train() client id: f_00004-2-3 loss: 0.776493  [  128/  306]
train() client id: f_00004-2-4 loss: 0.998150  [  160/  306]
train() client id: f_00004-2-5 loss: 0.749839  [  192/  306]
train() client id: f_00004-2-6 loss: 0.797121  [  224/  306]
train() client id: f_00004-2-7 loss: 0.917337  [  256/  306]
train() client id: f_00004-2-8 loss: 0.774966  [  288/  306]
train() client id: f_00004-3-0 loss: 0.836877  [   32/  306]
train() client id: f_00004-3-1 loss: 0.727616  [   64/  306]
train() client id: f_00004-3-2 loss: 0.838112  [   96/  306]
train() client id: f_00004-3-3 loss: 0.870590  [  128/  306]
train() client id: f_00004-3-4 loss: 0.851167  [  160/  306]
train() client id: f_00004-3-5 loss: 0.725728  [  192/  306]
train() client id: f_00004-3-6 loss: 0.960368  [  224/  306]
train() client id: f_00004-3-7 loss: 0.778594  [  256/  306]
train() client id: f_00004-3-8 loss: 0.946020  [  288/  306]
train() client id: f_00004-4-0 loss: 0.774491  [   32/  306]
train() client id: f_00004-4-1 loss: 0.837647  [   64/  306]
train() client id: f_00004-4-2 loss: 0.940777  [   96/  306]
train() client id: f_00004-4-3 loss: 0.806458  [  128/  306]
train() client id: f_00004-4-4 loss: 0.769208  [  160/  306]
train() client id: f_00004-4-5 loss: 0.889545  [  192/  306]
train() client id: f_00004-4-6 loss: 0.733642  [  224/  306]
train() client id: f_00004-4-7 loss: 0.753537  [  256/  306]
train() client id: f_00004-4-8 loss: 0.936531  [  288/  306]
train() client id: f_00004-5-0 loss: 0.780318  [   32/  306]
train() client id: f_00004-5-1 loss: 0.766916  [   64/  306]
train() client id: f_00004-5-2 loss: 0.884598  [   96/  306]
train() client id: f_00004-5-3 loss: 0.812981  [  128/  306]
train() client id: f_00004-5-4 loss: 0.778534  [  160/  306]
train() client id: f_00004-5-5 loss: 0.821004  [  192/  306]
train() client id: f_00004-5-6 loss: 0.936426  [  224/  306]
train() client id: f_00004-5-7 loss: 0.850194  [  256/  306]
train() client id: f_00004-5-8 loss: 0.937846  [  288/  306]
train() client id: f_00004-6-0 loss: 1.019110  [   32/  306]
train() client id: f_00004-6-1 loss: 0.743443  [   64/  306]
train() client id: f_00004-6-2 loss: 0.821671  [   96/  306]
train() client id: f_00004-6-3 loss: 0.755442  [  128/  306]
train() client id: f_00004-6-4 loss: 0.930063  [  160/  306]
train() client id: f_00004-6-5 loss: 0.917455  [  192/  306]
train() client id: f_00004-6-6 loss: 0.899804  [  224/  306]
train() client id: f_00004-6-7 loss: 0.810456  [  256/  306]
train() client id: f_00004-6-8 loss: 0.763435  [  288/  306]
train() client id: f_00004-7-0 loss: 0.831018  [   32/  306]
train() client id: f_00004-7-1 loss: 0.820265  [   64/  306]
train() client id: f_00004-7-2 loss: 0.843697  [   96/  306]
train() client id: f_00004-7-3 loss: 0.695645  [  128/  306]
train() client id: f_00004-7-4 loss: 0.756666  [  160/  306]
train() client id: f_00004-7-5 loss: 1.016738  [  192/  306]
train() client id: f_00004-7-6 loss: 0.842813  [  224/  306]
train() client id: f_00004-7-7 loss: 0.859402  [  256/  306]
train() client id: f_00004-7-8 loss: 0.901017  [  288/  306]
train() client id: f_00004-8-0 loss: 0.876039  [   32/  306]
train() client id: f_00004-8-1 loss: 0.891585  [   64/  306]
train() client id: f_00004-8-2 loss: 0.810764  [   96/  306]
train() client id: f_00004-8-3 loss: 0.793325  [  128/  306]
train() client id: f_00004-8-4 loss: 0.895403  [  160/  306]
train() client id: f_00004-8-5 loss: 0.898988  [  192/  306]
train() client id: f_00004-8-6 loss: 0.752701  [  224/  306]
train() client id: f_00004-8-7 loss: 0.857567  [  256/  306]
train() client id: f_00004-8-8 loss: 0.811781  [  288/  306]
train() client id: f_00004-9-0 loss: 0.705804  [   32/  306]
train() client id: f_00004-9-1 loss: 0.775710  [   64/  306]
train() client id: f_00004-9-2 loss: 0.857035  [   96/  306]
train() client id: f_00004-9-3 loss: 1.047277  [  128/  306]
train() client id: f_00004-9-4 loss: 0.813815  [  160/  306]
train() client id: f_00004-9-5 loss: 0.848592  [  192/  306]
train() client id: f_00004-9-6 loss: 0.846694  [  224/  306]
train() client id: f_00004-9-7 loss: 0.913802  [  256/  306]
train() client id: f_00004-9-8 loss: 0.798777  [  288/  306]
train() client id: f_00004-10-0 loss: 0.794817  [   32/  306]
train() client id: f_00004-10-1 loss: 0.875127  [   64/  306]
train() client id: f_00004-10-2 loss: 0.814246  [   96/  306]
train() client id: f_00004-10-3 loss: 0.777968  [  128/  306]
train() client id: f_00004-10-4 loss: 0.829944  [  160/  306]
train() client id: f_00004-10-5 loss: 0.856427  [  192/  306]
train() client id: f_00004-10-6 loss: 0.936605  [  224/  306]
train() client id: f_00004-10-7 loss: 0.936887  [  256/  306]
train() client id: f_00004-10-8 loss: 0.813297  [  288/  306]
train() client id: f_00004-11-0 loss: 0.839520  [   32/  306]
train() client id: f_00004-11-1 loss: 0.808699  [   64/  306]
train() client id: f_00004-11-2 loss: 0.782973  [   96/  306]
train() client id: f_00004-11-3 loss: 0.960678  [  128/  306]
train() client id: f_00004-11-4 loss: 0.901297  [  160/  306]
train() client id: f_00004-11-5 loss: 0.798456  [  192/  306]
train() client id: f_00004-11-6 loss: 0.842631  [  224/  306]
train() client id: f_00004-11-7 loss: 0.762010  [  256/  306]
train() client id: f_00004-11-8 loss: 0.860150  [  288/  306]
train() client id: f_00004-12-0 loss: 0.664983  [   32/  306]
train() client id: f_00004-12-1 loss: 0.736141  [   64/  306]
train() client id: f_00004-12-2 loss: 0.997611  [   96/  306]
train() client id: f_00004-12-3 loss: 0.783735  [  128/  306]
train() client id: f_00004-12-4 loss: 0.985676  [  160/  306]
train() client id: f_00004-12-5 loss: 0.854982  [  192/  306]
train() client id: f_00004-12-6 loss: 0.983514  [  224/  306]
train() client id: f_00004-12-7 loss: 0.785324  [  256/  306]
train() client id: f_00004-12-8 loss: 0.839553  [  288/  306]
train() client id: f_00005-0-0 loss: 0.654911  [   32/  146]
train() client id: f_00005-0-1 loss: 0.656284  [   64/  146]
train() client id: f_00005-0-2 loss: 0.705135  [   96/  146]
train() client id: f_00005-0-3 loss: 0.768459  [  128/  146]
train() client id: f_00005-1-0 loss: 0.714376  [   32/  146]
train() client id: f_00005-1-1 loss: 0.648158  [   64/  146]
train() client id: f_00005-1-2 loss: 0.710417  [   96/  146]
train() client id: f_00005-1-3 loss: 0.736283  [  128/  146]
train() client id: f_00005-2-0 loss: 0.633723  [   32/  146]
train() client id: f_00005-2-1 loss: 0.767443  [   64/  146]
train() client id: f_00005-2-2 loss: 0.874708  [   96/  146]
train() client id: f_00005-2-3 loss: 0.610977  [  128/  146]
train() client id: f_00005-3-0 loss: 0.807131  [   32/  146]
train() client id: f_00005-3-1 loss: 0.627915  [   64/  146]
train() client id: f_00005-3-2 loss: 0.804751  [   96/  146]
train() client id: f_00005-3-3 loss: 0.601003  [  128/  146]
train() client id: f_00005-4-0 loss: 0.735650  [   32/  146]
train() client id: f_00005-4-1 loss: 1.067387  [   64/  146]
train() client id: f_00005-4-2 loss: 0.485448  [   96/  146]
train() client id: f_00005-4-3 loss: 0.625816  [  128/  146]
train() client id: f_00005-5-0 loss: 0.725010  [   32/  146]
train() client id: f_00005-5-1 loss: 0.721977  [   64/  146]
train() client id: f_00005-5-2 loss: 0.705109  [   96/  146]
train() client id: f_00005-5-3 loss: 0.630680  [  128/  146]
train() client id: f_00005-6-0 loss: 1.105656  [   32/  146]
train() client id: f_00005-6-1 loss: 0.661344  [   64/  146]
train() client id: f_00005-6-2 loss: 0.557447  [   96/  146]
train() client id: f_00005-6-3 loss: 0.485108  [  128/  146]
train() client id: f_00005-7-0 loss: 0.821384  [   32/  146]
train() client id: f_00005-7-1 loss: 0.604915  [   64/  146]
train() client id: f_00005-7-2 loss: 0.804303  [   96/  146]
train() client id: f_00005-7-3 loss: 0.476155  [  128/  146]
train() client id: f_00005-8-0 loss: 0.646860  [   32/  146]
train() client id: f_00005-8-1 loss: 0.965634  [   64/  146]
train() client id: f_00005-8-2 loss: 0.581443  [   96/  146]
train() client id: f_00005-8-3 loss: 0.651050  [  128/  146]
train() client id: f_00005-9-0 loss: 0.612583  [   32/  146]
train() client id: f_00005-9-1 loss: 0.729220  [   64/  146]
train() client id: f_00005-9-2 loss: 0.601504  [   96/  146]
train() client id: f_00005-9-3 loss: 0.752365  [  128/  146]
train() client id: f_00005-10-0 loss: 0.759779  [   32/  146]
train() client id: f_00005-10-1 loss: 0.492733  [   64/  146]
train() client id: f_00005-10-2 loss: 0.694541  [   96/  146]
train() client id: f_00005-10-3 loss: 0.705587  [  128/  146]
train() client id: f_00005-11-0 loss: 0.645467  [   32/  146]
train() client id: f_00005-11-1 loss: 0.675337  [   64/  146]
train() client id: f_00005-11-2 loss: 0.732685  [   96/  146]
train() client id: f_00005-11-3 loss: 0.526603  [  128/  146]
train() client id: f_00005-12-0 loss: 0.725077  [   32/  146]
train() client id: f_00005-12-1 loss: 0.720412  [   64/  146]
train() client id: f_00005-12-2 loss: 0.743160  [   96/  146]
train() client id: f_00005-12-3 loss: 0.584004  [  128/  146]
train() client id: f_00006-0-0 loss: 0.570933  [   32/   54]
train() client id: f_00006-1-0 loss: 0.613875  [   32/   54]
train() client id: f_00006-2-0 loss: 0.614596  [   32/   54]
train() client id: f_00006-3-0 loss: 0.560843  [   32/   54]
train() client id: f_00006-4-0 loss: 0.573742  [   32/   54]
train() client id: f_00006-5-0 loss: 0.613765  [   32/   54]
train() client id: f_00006-6-0 loss: 0.554698  [   32/   54]
train() client id: f_00006-7-0 loss: 0.561331  [   32/   54]
train() client id: f_00006-8-0 loss: 0.632212  [   32/   54]
train() client id: f_00006-9-0 loss: 0.541826  [   32/   54]
train() client id: f_00006-10-0 loss: 0.532079  [   32/   54]
train() client id: f_00006-11-0 loss: 0.588200  [   32/   54]
train() client id: f_00006-12-0 loss: 0.562456  [   32/   54]
train() client id: f_00007-0-0 loss: 0.442899  [   32/  179]
train() client id: f_00007-0-1 loss: 0.647837  [   64/  179]
train() client id: f_00007-0-2 loss: 0.655728  [   96/  179]
train() client id: f_00007-0-3 loss: 0.445488  [  128/  179]
train() client id: f_00007-0-4 loss: 0.501683  [  160/  179]
train() client id: f_00007-1-0 loss: 0.510734  [   32/  179]
train() client id: f_00007-1-1 loss: 0.466733  [   64/  179]
train() client id: f_00007-1-2 loss: 0.653607  [   96/  179]
train() client id: f_00007-1-3 loss: 0.540643  [  128/  179]
train() client id: f_00007-1-4 loss: 0.521839  [  160/  179]
train() client id: f_00007-2-0 loss: 0.495958  [   32/  179]
train() client id: f_00007-2-1 loss: 0.424579  [   64/  179]
train() client id: f_00007-2-2 loss: 0.522605  [   96/  179]
train() client id: f_00007-2-3 loss: 0.613739  [  128/  179]
train() client id: f_00007-2-4 loss: 0.473585  [  160/  179]
train() client id: f_00007-3-0 loss: 0.490632  [   32/  179]
train() client id: f_00007-3-1 loss: 0.660299  [   64/  179]
train() client id: f_00007-3-2 loss: 0.528677  [   96/  179]
train() client id: f_00007-3-3 loss: 0.315665  [  128/  179]
train() client id: f_00007-3-4 loss: 0.459360  [  160/  179]
train() client id: f_00007-4-0 loss: 0.570546  [   32/  179]
train() client id: f_00007-4-1 loss: 0.418929  [   64/  179]
train() client id: f_00007-4-2 loss: 0.514451  [   96/  179]
train() client id: f_00007-4-3 loss: 0.458298  [  128/  179]
train() client id: f_00007-4-4 loss: 0.556870  [  160/  179]
train() client id: f_00007-5-0 loss: 0.452833  [   32/  179]
train() client id: f_00007-5-1 loss: 0.365284  [   64/  179]
train() client id: f_00007-5-2 loss: 0.576999  [   96/  179]
train() client id: f_00007-5-3 loss: 0.461208  [  128/  179]
train() client id: f_00007-5-4 loss: 0.638796  [  160/  179]
train() client id: f_00007-6-0 loss: 0.572339  [   32/  179]
train() client id: f_00007-6-1 loss: 0.522560  [   64/  179]
train() client id: f_00007-6-2 loss: 0.416525  [   96/  179]
train() client id: f_00007-6-3 loss: 0.448603  [  128/  179]
train() client id: f_00007-6-4 loss: 0.448964  [  160/  179]
train() client id: f_00007-7-0 loss: 0.312217  [   32/  179]
train() client id: f_00007-7-1 loss: 0.696673  [   64/  179]
train() client id: f_00007-7-2 loss: 0.426081  [   96/  179]
train() client id: f_00007-7-3 loss: 0.505431  [  128/  179]
train() client id: f_00007-7-4 loss: 0.541358  [  160/  179]
train() client id: f_00007-8-0 loss: 0.526791  [   32/  179]
train() client id: f_00007-8-1 loss: 0.695991  [   64/  179]
train() client id: f_00007-8-2 loss: 0.305455  [   96/  179]
train() client id: f_00007-8-3 loss: 0.467191  [  128/  179]
train() client id: f_00007-8-4 loss: 0.459311  [  160/  179]
train() client id: f_00007-9-0 loss: 0.515692  [   32/  179]
train() client id: f_00007-9-1 loss: 0.513480  [   64/  179]
train() client id: f_00007-9-2 loss: 0.423971  [   96/  179]
train() client id: f_00007-9-3 loss: 0.407143  [  128/  179]
train() client id: f_00007-9-4 loss: 0.398645  [  160/  179]
train() client id: f_00007-10-0 loss: 0.451767  [   32/  179]
train() client id: f_00007-10-1 loss: 0.535208  [   64/  179]
train() client id: f_00007-10-2 loss: 0.586384  [   96/  179]
train() client id: f_00007-10-3 loss: 0.386784  [  128/  179]
train() client id: f_00007-10-4 loss: 0.389290  [  160/  179]
train() client id: f_00007-11-0 loss: 0.551544  [   32/  179]
train() client id: f_00007-11-1 loss: 0.431132  [   64/  179]
train() client id: f_00007-11-2 loss: 0.596529  [   96/  179]
train() client id: f_00007-11-3 loss: 0.331486  [  128/  179]
train() client id: f_00007-11-4 loss: 0.334143  [  160/  179]
train() client id: f_00007-12-0 loss: 0.588117  [   32/  179]
train() client id: f_00007-12-1 loss: 0.560206  [   64/  179]
train() client id: f_00007-12-2 loss: 0.540735  [   96/  179]
train() client id: f_00007-12-3 loss: 0.341929  [  128/  179]
train() client id: f_00007-12-4 loss: 0.443306  [  160/  179]
train() client id: f_00008-0-0 loss: 0.781381  [   32/  130]
train() client id: f_00008-0-1 loss: 0.606188  [   64/  130]
train() client id: f_00008-0-2 loss: 0.709766  [   96/  130]
train() client id: f_00008-0-3 loss: 0.715196  [  128/  130]
train() client id: f_00008-1-0 loss: 0.804915  [   32/  130]
train() client id: f_00008-1-1 loss: 0.579491  [   64/  130]
train() client id: f_00008-1-2 loss: 0.678282  [   96/  130]
train() client id: f_00008-1-3 loss: 0.731779  [  128/  130]
train() client id: f_00008-2-0 loss: 0.792583  [   32/  130]
train() client id: f_00008-2-1 loss: 0.694322  [   64/  130]
train() client id: f_00008-2-2 loss: 0.592750  [   96/  130]
train() client id: f_00008-2-3 loss: 0.729269  [  128/  130]
train() client id: f_00008-3-0 loss: 0.734803  [   32/  130]
train() client id: f_00008-3-1 loss: 0.790167  [   64/  130]
train() client id: f_00008-3-2 loss: 0.679971  [   96/  130]
train() client id: f_00008-3-3 loss: 0.606020  [  128/  130]
train() client id: f_00008-4-0 loss: 0.543690  [   32/  130]
train() client id: f_00008-4-1 loss: 0.749491  [   64/  130]
train() client id: f_00008-4-2 loss: 0.814206  [   96/  130]
train() client id: f_00008-4-3 loss: 0.663256  [  128/  130]
train() client id: f_00008-5-0 loss: 0.819417  [   32/  130]
train() client id: f_00008-5-1 loss: 0.686463  [   64/  130]
train() client id: f_00008-5-2 loss: 0.555162  [   96/  130]
train() client id: f_00008-5-3 loss: 0.718195  [  128/  130]
train() client id: f_00008-6-0 loss: 0.827155  [   32/  130]
train() client id: f_00008-6-1 loss: 0.638942  [   64/  130]
train() client id: f_00008-6-2 loss: 0.646267  [   96/  130]
train() client id: f_00008-6-3 loss: 0.698049  [  128/  130]
train() client id: f_00008-7-0 loss: 0.670215  [   32/  130]
train() client id: f_00008-7-1 loss: 0.647862  [   64/  130]
train() client id: f_00008-7-2 loss: 0.657360  [   96/  130]
train() client id: f_00008-7-3 loss: 0.791043  [  128/  130]
train() client id: f_00008-8-0 loss: 0.653760  [   32/  130]
train() client id: f_00008-8-1 loss: 0.729371  [   64/  130]
train() client id: f_00008-8-2 loss: 0.807810  [   96/  130]
train() client id: f_00008-8-3 loss: 0.611313  [  128/  130]
train() client id: f_00008-9-0 loss: 0.675982  [   32/  130]
train() client id: f_00008-9-1 loss: 0.664777  [   64/  130]
train() client id: f_00008-9-2 loss: 0.735293  [   96/  130]
train() client id: f_00008-9-3 loss: 0.730383  [  128/  130]
train() client id: f_00008-10-0 loss: 0.653620  [   32/  130]
train() client id: f_00008-10-1 loss: 0.675413  [   64/  130]
train() client id: f_00008-10-2 loss: 0.806353  [   96/  130]
train() client id: f_00008-10-3 loss: 0.682755  [  128/  130]
train() client id: f_00008-11-0 loss: 0.756388  [   32/  130]
train() client id: f_00008-11-1 loss: 0.702403  [   64/  130]
train() client id: f_00008-11-2 loss: 0.668734  [   96/  130]
train() client id: f_00008-11-3 loss: 0.684993  [  128/  130]
train() client id: f_00008-12-0 loss: 0.715252  [   32/  130]
train() client id: f_00008-12-1 loss: 0.721894  [   64/  130]
train() client id: f_00008-12-2 loss: 0.778650  [   96/  130]
train() client id: f_00008-12-3 loss: 0.590758  [  128/  130]
train() client id: f_00009-0-0 loss: 1.247178  [   32/  118]
train() client id: f_00009-0-1 loss: 1.171744  [   64/  118]
train() client id: f_00009-0-2 loss: 1.212679  [   96/  118]
train() client id: f_00009-1-0 loss: 1.191560  [   32/  118]
train() client id: f_00009-1-1 loss: 1.085294  [   64/  118]
train() client id: f_00009-1-2 loss: 1.125046  [   96/  118]
train() client id: f_00009-2-0 loss: 1.110957  [   32/  118]
train() client id: f_00009-2-1 loss: 1.138066  [   64/  118]
train() client id: f_00009-2-2 loss: 1.036383  [   96/  118]
train() client id: f_00009-3-0 loss: 0.976046  [   32/  118]
train() client id: f_00009-3-1 loss: 1.079881  [   64/  118]
train() client id: f_00009-3-2 loss: 1.135286  [   96/  118]
train() client id: f_00009-4-0 loss: 1.047504  [   32/  118]
train() client id: f_00009-4-1 loss: 1.063361  [   64/  118]
train() client id: f_00009-4-2 loss: 1.007228  [   96/  118]
train() client id: f_00009-5-0 loss: 1.101699  [   32/  118]
train() client id: f_00009-5-1 loss: 0.980549  [   64/  118]
train() client id: f_00009-5-2 loss: 0.931558  [   96/  118]
train() client id: f_00009-6-0 loss: 0.947196  [   32/  118]
train() client id: f_00009-6-1 loss: 1.008070  [   64/  118]
train() client id: f_00009-6-2 loss: 0.949768  [   96/  118]
train() client id: f_00009-7-0 loss: 0.954751  [   32/  118]
train() client id: f_00009-7-1 loss: 1.003473  [   64/  118]
train() client id: f_00009-7-2 loss: 0.898130  [   96/  118]
train() client id: f_00009-8-0 loss: 0.884624  [   32/  118]
train() client id: f_00009-8-1 loss: 0.896879  [   64/  118]
train() client id: f_00009-8-2 loss: 0.961323  [   96/  118]
train() client id: f_00009-9-0 loss: 0.846016  [   32/  118]
train() client id: f_00009-9-1 loss: 0.924715  [   64/  118]
train() client id: f_00009-9-2 loss: 1.010569  [   96/  118]
train() client id: f_00009-10-0 loss: 0.891251  [   32/  118]
train() client id: f_00009-10-1 loss: 0.977071  [   64/  118]
train() client id: f_00009-10-2 loss: 0.903346  [   96/  118]
train() client id: f_00009-11-0 loss: 0.932110  [   32/  118]
train() client id: f_00009-11-1 loss: 0.954291  [   64/  118]
train() client id: f_00009-11-2 loss: 0.806303  [   96/  118]
train() client id: f_00009-12-0 loss: 0.862865  [   32/  118]
train() client id: f_00009-12-1 loss: 0.851367  [   64/  118]
train() client id: f_00009-12-2 loss: 0.964093  [   96/  118]
At round 20 accuracy: 0.6339522546419099
At round 20 training accuracy: 0.5868544600938967
At round 20 training loss: 0.8324716993222601
gradient difference: 0.4196510314941406
train() client id: f_00000-0-0 loss: 1.260342  [   32/  126]
train() client id: f_00000-0-1 loss: 1.333275  [   64/  126]
train() client id: f_00000-0-2 loss: 1.155006  [   96/  126]
train() client id: f_00000-1-0 loss: 1.043229  [   32/  126]
train() client id: f_00000-1-1 loss: 1.270013  [   64/  126]
train() client id: f_00000-1-2 loss: 1.209809  [   96/  126]
train() client id: f_00000-2-0 loss: 1.373576  [   32/  126]
train() client id: f_00000-2-1 loss: 1.005504  [   64/  126]
train() client id: f_00000-2-2 loss: 1.049446  [   96/  126]
train() client id: f_00000-3-0 loss: 1.054314  [   32/  126]
train() client id: f_00000-3-1 loss: 0.961697  [   64/  126]
train() client id: f_00000-3-2 loss: 0.996136  [   96/  126]
train() client id: f_00000-4-0 loss: 0.914063  [   32/  126]
train() client id: f_00000-4-1 loss: 0.893476  [   64/  126]
train() client id: f_00000-4-2 loss: 0.945569  [   96/  126]
train() client id: f_00000-5-0 loss: 0.791812  [   32/  126]
train() client id: f_00000-5-1 loss: 0.949226  [   64/  126]
train() client id: f_00000-5-2 loss: 0.860513  [   96/  126]
train() client id: f_00000-6-0 loss: 0.752703  [   32/  126]
train() client id: f_00000-6-1 loss: 0.882565  [   64/  126]
train() client id: f_00000-6-2 loss: 0.901899  [   96/  126]
train() client id: f_00000-7-0 loss: 0.856522  [   32/  126]
train() client id: f_00000-7-1 loss: 0.785619  [   64/  126]
train() client id: f_00000-7-2 loss: 0.742510  [   96/  126]
train() client id: f_00000-8-0 loss: 0.811558  [   32/  126]
train() client id: f_00000-8-1 loss: 0.833489  [   64/  126]
train() client id: f_00000-8-2 loss: 0.633479  [   96/  126]
train() client id: f_00000-9-0 loss: 0.704828  [   32/  126]
train() client id: f_00000-9-1 loss: 0.683406  [   64/  126]
train() client id: f_00000-9-2 loss: 0.743408  [   96/  126]
train() client id: f_00000-10-0 loss: 0.790935  [   32/  126]
train() client id: f_00000-10-1 loss: 0.653133  [   64/  126]
train() client id: f_00000-10-2 loss: 0.686895  [   96/  126]
train() client id: f_00000-11-0 loss: 0.671961  [   32/  126]
train() client id: f_00000-11-1 loss: 0.637698  [   64/  126]
train() client id: f_00000-11-2 loss: 0.751646  [   96/  126]
train() client id: f_00000-12-0 loss: 0.719044  [   32/  126]
train() client id: f_00000-12-1 loss: 0.634548  [   64/  126]
train() client id: f_00000-12-2 loss: 0.803601  [   96/  126]
train() client id: f_00001-0-0 loss: 0.580240  [   32/  265]
train() client id: f_00001-0-1 loss: 0.462281  [   64/  265]
train() client id: f_00001-0-2 loss: 0.532227  [   96/  265]
train() client id: f_00001-0-3 loss: 0.412384  [  128/  265]
train() client id: f_00001-0-4 loss: 0.638541  [  160/  265]
train() client id: f_00001-0-5 loss: 0.504191  [  192/  265]
train() client id: f_00001-0-6 loss: 0.404425  [  224/  265]
train() client id: f_00001-0-7 loss: 0.410032  [  256/  265]
train() client id: f_00001-1-0 loss: 0.545972  [   32/  265]
train() client id: f_00001-1-1 loss: 0.533949  [   64/  265]
train() client id: f_00001-1-2 loss: 0.503672  [   96/  265]
train() client id: f_00001-1-3 loss: 0.483817  [  128/  265]
train() client id: f_00001-1-4 loss: 0.380056  [  160/  265]
train() client id: f_00001-1-5 loss: 0.464713  [  192/  265]
train() client id: f_00001-1-6 loss: 0.493204  [  224/  265]
train() client id: f_00001-1-7 loss: 0.454253  [  256/  265]
train() client id: f_00001-2-0 loss: 0.520408  [   32/  265]
train() client id: f_00001-2-1 loss: 0.377322  [   64/  265]
train() client id: f_00001-2-2 loss: 0.376304  [   96/  265]
train() client id: f_00001-2-3 loss: 0.526094  [  128/  265]
train() client id: f_00001-2-4 loss: 0.561104  [  160/  265]
train() client id: f_00001-2-5 loss: 0.507200  [  192/  265]
train() client id: f_00001-2-6 loss: 0.482404  [  224/  265]
train() client id: f_00001-2-7 loss: 0.457006  [  256/  265]
train() client id: f_00001-3-0 loss: 0.573705  [   32/  265]
train() client id: f_00001-3-1 loss: 0.445882  [   64/  265]
train() client id: f_00001-3-2 loss: 0.439869  [   96/  265]
train() client id: f_00001-3-3 loss: 0.495151  [  128/  265]
train() client id: f_00001-3-4 loss: 0.544524  [  160/  265]
train() client id: f_00001-3-5 loss: 0.382666  [  192/  265]
train() client id: f_00001-3-6 loss: 0.467432  [  224/  265]
train() client id: f_00001-3-7 loss: 0.419051  [  256/  265]
train() client id: f_00001-4-0 loss: 0.393327  [   32/  265]
train() client id: f_00001-4-1 loss: 0.434394  [   64/  265]
train() client id: f_00001-4-2 loss: 0.514210  [   96/  265]
train() client id: f_00001-4-3 loss: 0.420346  [  128/  265]
train() client id: f_00001-4-4 loss: 0.528559  [  160/  265]
train() client id: f_00001-4-5 loss: 0.458553  [  192/  265]
train() client id: f_00001-4-6 loss: 0.468310  [  224/  265]
train() client id: f_00001-4-7 loss: 0.470628  [  256/  265]
train() client id: f_00001-5-0 loss: 0.380107  [   32/  265]
train() client id: f_00001-5-1 loss: 0.498496  [   64/  265]
train() client id: f_00001-5-2 loss: 0.446560  [   96/  265]
train() client id: f_00001-5-3 loss: 0.447795  [  128/  265]
train() client id: f_00001-5-4 loss: 0.552344  [  160/  265]
train() client id: f_00001-5-5 loss: 0.406954  [  192/  265]
train() client id: f_00001-5-6 loss: 0.460882  [  224/  265]
train() client id: f_00001-5-7 loss: 0.430431  [  256/  265]
train() client id: f_00001-6-0 loss: 0.377131  [   32/  265]
train() client id: f_00001-6-1 loss: 0.564249  [   64/  265]
train() client id: f_00001-6-2 loss: 0.383280  [   96/  265]
train() client id: f_00001-6-3 loss: 0.426303  [  128/  265]
train() client id: f_00001-6-4 loss: 0.354333  [  160/  265]
train() client id: f_00001-6-5 loss: 0.487357  [  192/  265]
train() client id: f_00001-6-6 loss: 0.577035  [  224/  265]
train() client id: f_00001-6-7 loss: 0.530900  [  256/  265]
train() client id: f_00001-7-0 loss: 0.651276  [   32/  265]
train() client id: f_00001-7-1 loss: 0.431503  [   64/  265]
train() client id: f_00001-7-2 loss: 0.466707  [   96/  265]
train() client id: f_00001-7-3 loss: 0.440560  [  128/  265]
train() client id: f_00001-7-4 loss: 0.469602  [  160/  265]
train() client id: f_00001-7-5 loss: 0.371567  [  192/  265]
train() client id: f_00001-7-6 loss: 0.383176  [  224/  265]
train() client id: f_00001-7-7 loss: 0.460050  [  256/  265]
train() client id: f_00001-8-0 loss: 0.536034  [   32/  265]
train() client id: f_00001-8-1 loss: 0.363156  [   64/  265]
train() client id: f_00001-8-2 loss: 0.498991  [   96/  265]
train() client id: f_00001-8-3 loss: 0.418382  [  128/  265]
train() client id: f_00001-8-4 loss: 0.432505  [  160/  265]
train() client id: f_00001-8-5 loss: 0.372967  [  192/  265]
train() client id: f_00001-8-6 loss: 0.395453  [  224/  265]
train() client id: f_00001-8-7 loss: 0.591524  [  256/  265]
train() client id: f_00001-9-0 loss: 0.415951  [   32/  265]
train() client id: f_00001-9-1 loss: 0.415612  [   64/  265]
train() client id: f_00001-9-2 loss: 0.636121  [   96/  265]
train() client id: f_00001-9-3 loss: 0.418990  [  128/  265]
train() client id: f_00001-9-4 loss: 0.433412  [  160/  265]
train() client id: f_00001-9-5 loss: 0.399635  [  192/  265]
train() client id: f_00001-9-6 loss: 0.464107  [  224/  265]
train() client id: f_00001-9-7 loss: 0.388513  [  256/  265]
train() client id: f_00001-10-0 loss: 0.354441  [   32/  265]
train() client id: f_00001-10-1 loss: 0.420611  [   64/  265]
train() client id: f_00001-10-2 loss: 0.455716  [   96/  265]
train() client id: f_00001-10-3 loss: 0.420745  [  128/  265]
train() client id: f_00001-10-4 loss: 0.491489  [  160/  265]
train() client id: f_00001-10-5 loss: 0.403546  [  192/  265]
train() client id: f_00001-10-6 loss: 0.508643  [  224/  265]
train() client id: f_00001-10-7 loss: 0.521793  [  256/  265]
train() client id: f_00001-11-0 loss: 0.615947  [   32/  265]
train() client id: f_00001-11-1 loss: 0.416324  [   64/  265]
train() client id: f_00001-11-2 loss: 0.483898  [   96/  265]
train() client id: f_00001-11-3 loss: 0.367627  [  128/  265]
train() client id: f_00001-11-4 loss: 0.421768  [  160/  265]
train() client id: f_00001-11-5 loss: 0.476085  [  192/  265]
train() client id: f_00001-11-6 loss: 0.502653  [  224/  265]
train() client id: f_00001-11-7 loss: 0.374453  [  256/  265]
train() client id: f_00001-12-0 loss: 0.498854  [   32/  265]
train() client id: f_00001-12-1 loss: 0.519535  [   64/  265]
train() client id: f_00001-12-2 loss: 0.351666  [   96/  265]
train() client id: f_00001-12-3 loss: 0.474464  [  128/  265]
train() client id: f_00001-12-4 loss: 0.448271  [  160/  265]
train() client id: f_00001-12-5 loss: 0.363433  [  192/  265]
train() client id: f_00001-12-6 loss: 0.423839  [  224/  265]
train() client id: f_00001-12-7 loss: 0.440908  [  256/  265]
train() client id: f_00002-0-0 loss: 1.175033  [   32/  124]
train() client id: f_00002-0-1 loss: 1.256666  [   64/  124]
train() client id: f_00002-0-2 loss: 1.036093  [   96/  124]
train() client id: f_00002-1-0 loss: 1.138280  [   32/  124]
train() client id: f_00002-1-1 loss: 0.993752  [   64/  124]
train() client id: f_00002-1-2 loss: 1.199197  [   96/  124]
train() client id: f_00002-2-0 loss: 1.074462  [   32/  124]
train() client id: f_00002-2-1 loss: 1.009606  [   64/  124]
train() client id: f_00002-2-2 loss: 1.040358  [   96/  124]
train() client id: f_00002-3-0 loss: 1.041089  [   32/  124]
train() client id: f_00002-3-1 loss: 1.074796  [   64/  124]
train() client id: f_00002-3-2 loss: 1.039074  [   96/  124]
train() client id: f_00002-4-0 loss: 1.009598  [   32/  124]
train() client id: f_00002-4-1 loss: 0.926873  [   64/  124]
train() client id: f_00002-4-2 loss: 1.062468  [   96/  124]
train() client id: f_00002-5-0 loss: 1.149525  [   32/  124]
train() client id: f_00002-5-1 loss: 0.831264  [   64/  124]
train() client id: f_00002-5-2 loss: 0.947904  [   96/  124]
train() client id: f_00002-6-0 loss: 0.906121  [   32/  124]
train() client id: f_00002-6-1 loss: 0.861157  [   64/  124]
train() client id: f_00002-6-2 loss: 0.980184  [   96/  124]
train() client id: f_00002-7-0 loss: 0.985566  [   32/  124]
train() client id: f_00002-7-1 loss: 0.858238  [   64/  124]
train() client id: f_00002-7-2 loss: 0.802845  [   96/  124]
train() client id: f_00002-8-0 loss: 0.869688  [   32/  124]
train() client id: f_00002-8-1 loss: 0.848441  [   64/  124]
train() client id: f_00002-8-2 loss: 0.958807  [   96/  124]
train() client id: f_00002-9-0 loss: 0.893368  [   32/  124]
train() client id: f_00002-9-1 loss: 0.840944  [   64/  124]
train() client id: f_00002-9-2 loss: 0.795515  [   96/  124]
train() client id: f_00002-10-0 loss: 0.900334  [   32/  124]
train() client id: f_00002-10-1 loss: 0.941474  [   64/  124]
train() client id: f_00002-10-2 loss: 0.814784  [   96/  124]
train() client id: f_00002-11-0 loss: 0.774637  [   32/  124]
train() client id: f_00002-11-1 loss: 1.025367  [   64/  124]
train() client id: f_00002-11-2 loss: 0.749276  [   96/  124]
train() client id: f_00002-12-0 loss: 0.826761  [   32/  124]
train() client id: f_00002-12-1 loss: 0.680219  [   64/  124]
train() client id: f_00002-12-2 loss: 0.949700  [   96/  124]
train() client id: f_00003-0-0 loss: 0.766915  [   32/   43]
train() client id: f_00003-1-0 loss: 0.466154  [   32/   43]
train() client id: f_00003-2-0 loss: 0.829959  [   32/   43]
train() client id: f_00003-3-0 loss: 0.703774  [   32/   43]
train() client id: f_00003-4-0 loss: 0.660376  [   32/   43]
train() client id: f_00003-5-0 loss: 0.666537  [   32/   43]
train() client id: f_00003-6-0 loss: 0.794466  [   32/   43]
train() client id: f_00003-7-0 loss: 0.582832  [   32/   43]
train() client id: f_00003-8-0 loss: 0.557088  [   32/   43]
train() client id: f_00003-9-0 loss: 0.619959  [   32/   43]
train() client id: f_00003-10-0 loss: 0.562873  [   32/   43]
train() client id: f_00003-11-0 loss: 0.617383  [   32/   43]
train() client id: f_00003-12-0 loss: 0.730637  [   32/   43]
train() client id: f_00004-0-0 loss: 0.858136  [   32/  306]
train() client id: f_00004-0-1 loss: 0.918919  [   64/  306]
train() client id: f_00004-0-2 loss: 0.786543  [   96/  306]
train() client id: f_00004-0-3 loss: 0.951526  [  128/  306]
train() client id: f_00004-0-4 loss: 0.724447  [  160/  306]
train() client id: f_00004-0-5 loss: 0.936873  [  192/  306]
train() client id: f_00004-0-6 loss: 0.944883  [  224/  306]
train() client id: f_00004-0-7 loss: 0.833451  [  256/  306]
train() client id: f_00004-0-8 loss: 0.790540  [  288/  306]
train() client id: f_00004-1-0 loss: 0.931310  [   32/  306]
train() client id: f_00004-1-1 loss: 0.742956  [   64/  306]
train() client id: f_00004-1-2 loss: 0.913175  [   96/  306]
train() client id: f_00004-1-3 loss: 0.976963  [  128/  306]
train() client id: f_00004-1-4 loss: 0.768798  [  160/  306]
train() client id: f_00004-1-5 loss: 0.863872  [  192/  306]
train() client id: f_00004-1-6 loss: 0.733869  [  224/  306]
train() client id: f_00004-1-7 loss: 0.926574  [  256/  306]
train() client id: f_00004-1-8 loss: 0.883624  [  288/  306]
train() client id: f_00004-2-0 loss: 0.836941  [   32/  306]
train() client id: f_00004-2-1 loss: 0.867171  [   64/  306]
train() client id: f_00004-2-2 loss: 0.942131  [   96/  306]
train() client id: f_00004-2-3 loss: 0.914965  [  128/  306]
train() client id: f_00004-2-4 loss: 0.895026  [  160/  306]
train() client id: f_00004-2-5 loss: 0.822504  [  192/  306]
train() client id: f_00004-2-6 loss: 0.847259  [  224/  306]
train() client id: f_00004-2-7 loss: 0.777929  [  256/  306]
train() client id: f_00004-2-8 loss: 0.838090  [  288/  306]
train() client id: f_00004-3-0 loss: 0.861284  [   32/  306]
train() client id: f_00004-3-1 loss: 0.870943  [   64/  306]
train() client id: f_00004-3-2 loss: 0.853934  [   96/  306]
train() client id: f_00004-3-3 loss: 0.941721  [  128/  306]
train() client id: f_00004-3-4 loss: 0.853366  [  160/  306]
train() client id: f_00004-3-5 loss: 0.835736  [  192/  306]
train() client id: f_00004-3-6 loss: 0.962978  [  224/  306]
train() client id: f_00004-3-7 loss: 0.770380  [  256/  306]
train() client id: f_00004-3-8 loss: 0.788184  [  288/  306]
train() client id: f_00004-4-0 loss: 0.961467  [   32/  306]
train() client id: f_00004-4-1 loss: 0.790109  [   64/  306]
train() client id: f_00004-4-2 loss: 0.838897  [   96/  306]
train() client id: f_00004-4-3 loss: 0.850133  [  128/  306]
train() client id: f_00004-4-4 loss: 0.901794  [  160/  306]
train() client id: f_00004-4-5 loss: 0.850153  [  192/  306]
train() client id: f_00004-4-6 loss: 0.802310  [  224/  306]
train() client id: f_00004-4-7 loss: 0.887380  [  256/  306]
train() client id: f_00004-4-8 loss: 0.779958  [  288/  306]
train() client id: f_00004-5-0 loss: 0.787378  [   32/  306]
train() client id: f_00004-5-1 loss: 0.953504  [   64/  306]
train() client id: f_00004-5-2 loss: 0.762419  [   96/  306]
train() client id: f_00004-5-3 loss: 0.916548  [  128/  306]
train() client id: f_00004-5-4 loss: 0.883641  [  160/  306]
train() client id: f_00004-5-5 loss: 0.793857  [  192/  306]
train() client id: f_00004-5-6 loss: 0.781147  [  224/  306]
train() client id: f_00004-5-7 loss: 0.939181  [  256/  306]
train() client id: f_00004-5-8 loss: 0.837007  [  288/  306]
train() client id: f_00004-6-0 loss: 0.804957  [   32/  306]
train() client id: f_00004-6-1 loss: 0.882539  [   64/  306]
train() client id: f_00004-6-2 loss: 0.956704  [   96/  306]
train() client id: f_00004-6-3 loss: 0.877320  [  128/  306]
train() client id: f_00004-6-4 loss: 0.870149  [  160/  306]
train() client id: f_00004-6-5 loss: 0.871017  [  192/  306]
train() client id: f_00004-6-6 loss: 0.816439  [  224/  306]
train() client id: f_00004-6-7 loss: 0.812456  [  256/  306]
train() client id: f_00004-6-8 loss: 0.841744  [  288/  306]
train() client id: f_00004-7-0 loss: 0.967851  [   32/  306]
train() client id: f_00004-7-1 loss: 0.833166  [   64/  306]
train() client id: f_00004-7-2 loss: 0.888428  [   96/  306]
train() client id: f_00004-7-3 loss: 0.762982  [  128/  306]
train() client id: f_00004-7-4 loss: 0.724584  [  160/  306]
train() client id: f_00004-7-5 loss: 0.841650  [  192/  306]
train() client id: f_00004-7-6 loss: 0.968275  [  224/  306]
train() client id: f_00004-7-7 loss: 0.889869  [  256/  306]
train() client id: f_00004-7-8 loss: 0.833240  [  288/  306]
train() client id: f_00004-8-0 loss: 0.832038  [   32/  306]
train() client id: f_00004-8-1 loss: 0.941902  [   64/  306]
train() client id: f_00004-8-2 loss: 0.731443  [   96/  306]
train() client id: f_00004-8-3 loss: 0.829711  [  128/  306]
train() client id: f_00004-8-4 loss: 0.862994  [  160/  306]
train() client id: f_00004-8-5 loss: 0.841729  [  192/  306]
train() client id: f_00004-8-6 loss: 0.947210  [  224/  306]
train() client id: f_00004-8-7 loss: 0.862831  [  256/  306]
train() client id: f_00004-8-8 loss: 0.948888  [  288/  306]
train() client id: f_00004-9-0 loss: 0.871304  [   32/  306]
train() client id: f_00004-9-1 loss: 0.797642  [   64/  306]
train() client id: f_00004-9-2 loss: 0.903833  [   96/  306]
train() client id: f_00004-9-3 loss: 0.843981  [  128/  306]
train() client id: f_00004-9-4 loss: 0.873973  [  160/  306]
train() client id: f_00004-9-5 loss: 0.863412  [  192/  306]
train() client id: f_00004-9-6 loss: 0.831704  [  224/  306]
train() client id: f_00004-9-7 loss: 1.011617  [  256/  306]
train() client id: f_00004-9-8 loss: 0.781570  [  288/  306]
train() client id: f_00004-10-0 loss: 0.770484  [   32/  306]
train() client id: f_00004-10-1 loss: 0.788353  [   64/  306]
train() client id: f_00004-10-2 loss: 0.961523  [   96/  306]
train() client id: f_00004-10-3 loss: 0.898303  [  128/  306]
train() client id: f_00004-10-4 loss: 0.728177  [  160/  306]
train() client id: f_00004-10-5 loss: 0.972351  [  192/  306]
train() client id: f_00004-10-6 loss: 0.920289  [  224/  306]
train() client id: f_00004-10-7 loss: 0.937733  [  256/  306]
train() client id: f_00004-10-8 loss: 0.760283  [  288/  306]
train() client id: f_00004-11-0 loss: 0.820439  [   32/  306]
train() client id: f_00004-11-1 loss: 0.814910  [   64/  306]
train() client id: f_00004-11-2 loss: 0.750764  [   96/  306]
train() client id: f_00004-11-3 loss: 1.006350  [  128/  306]
train() client id: f_00004-11-4 loss: 0.825068  [  160/  306]
train() client id: f_00004-11-5 loss: 0.846171  [  192/  306]
train() client id: f_00004-11-6 loss: 0.791852  [  224/  306]
train() client id: f_00004-11-7 loss: 0.901279  [  256/  306]
train() client id: f_00004-11-8 loss: 1.010437  [  288/  306]
train() client id: f_00004-12-0 loss: 0.809070  [   32/  306]
train() client id: f_00004-12-1 loss: 0.810148  [   64/  306]
train() client id: f_00004-12-2 loss: 0.817567  [   96/  306]
train() client id: f_00004-12-3 loss: 0.875812  [  128/  306]
train() client id: f_00004-12-4 loss: 0.842708  [  160/  306]
train() client id: f_00004-12-5 loss: 0.900834  [  192/  306]
train() client id: f_00004-12-6 loss: 0.902098  [  224/  306]
train() client id: f_00004-12-7 loss: 0.789104  [  256/  306]
train() client id: f_00004-12-8 loss: 0.877471  [  288/  306]
train() client id: f_00005-0-0 loss: 0.942850  [   32/  146]
train() client id: f_00005-0-1 loss: 0.742750  [   64/  146]
train() client id: f_00005-0-2 loss: 0.747775  [   96/  146]
train() client id: f_00005-0-3 loss: 0.662153  [  128/  146]
train() client id: f_00005-1-0 loss: 0.800057  [   32/  146]
train() client id: f_00005-1-1 loss: 0.622505  [   64/  146]
train() client id: f_00005-1-2 loss: 0.907236  [   96/  146]
train() client id: f_00005-1-3 loss: 0.777422  [  128/  146]
train() client id: f_00005-2-0 loss: 0.713037  [   32/  146]
train() client id: f_00005-2-1 loss: 0.892944  [   64/  146]
train() client id: f_00005-2-2 loss: 0.856926  [   96/  146]
train() client id: f_00005-2-3 loss: 0.565159  [  128/  146]
train() client id: f_00005-3-0 loss: 0.818099  [   32/  146]
train() client id: f_00005-3-1 loss: 0.877384  [   64/  146]
train() client id: f_00005-3-2 loss: 0.761606  [   96/  146]
train() client id: f_00005-3-3 loss: 0.601104  [  128/  146]
train() client id: f_00005-4-0 loss: 0.913231  [   32/  146]
train() client id: f_00005-4-1 loss: 0.645228  [   64/  146]
train() client id: f_00005-4-2 loss: 0.882461  [   96/  146]
train() client id: f_00005-4-3 loss: 0.754682  [  128/  146]
train() client id: f_00005-5-0 loss: 0.914585  [   32/  146]
train() client id: f_00005-5-1 loss: 0.753145  [   64/  146]
train() client id: f_00005-5-2 loss: 0.773582  [   96/  146]
train() client id: f_00005-5-3 loss: 0.648684  [  128/  146]
train() client id: f_00005-6-0 loss: 0.751328  [   32/  146]
train() client id: f_00005-6-1 loss: 0.782271  [   64/  146]
train() client id: f_00005-6-2 loss: 0.754110  [   96/  146]
train() client id: f_00005-6-3 loss: 0.670001  [  128/  146]
train() client id: f_00005-7-0 loss: 0.826551  [   32/  146]
train() client id: f_00005-7-1 loss: 0.871515  [   64/  146]
train() client id: f_00005-7-2 loss: 0.768767  [   96/  146]
train() client id: f_00005-7-3 loss: 0.630787  [  128/  146]
train() client id: f_00005-8-0 loss: 0.978964  [   32/  146]
train() client id: f_00005-8-1 loss: 0.525989  [   64/  146]
train() client id: f_00005-8-2 loss: 0.673828  [   96/  146]
train() client id: f_00005-8-3 loss: 0.903149  [  128/  146]
train() client id: f_00005-9-0 loss: 1.026622  [   32/  146]
train() client id: f_00005-9-1 loss: 0.783959  [   64/  146]
train() client id: f_00005-9-2 loss: 0.748357  [   96/  146]
train() client id: f_00005-9-3 loss: 0.563316  [  128/  146]
train() client id: f_00005-10-0 loss: 0.999826  [   32/  146]
train() client id: f_00005-10-1 loss: 0.774478  [   64/  146]
train() client id: f_00005-10-2 loss: 0.606440  [   96/  146]
train() client id: f_00005-10-3 loss: 0.642721  [  128/  146]
train() client id: f_00005-11-0 loss: 0.469103  [   32/  146]
train() client id: f_00005-11-1 loss: 0.682438  [   64/  146]
train() client id: f_00005-11-2 loss: 0.544864  [   96/  146]
train() client id: f_00005-11-3 loss: 0.959935  [  128/  146]
train() client id: f_00005-12-0 loss: 0.661143  [   32/  146]
train() client id: f_00005-12-1 loss: 0.739091  [   64/  146]
train() client id: f_00005-12-2 loss: 0.629105  [   96/  146]
train() client id: f_00005-12-3 loss: 0.920303  [  128/  146]
train() client id: f_00006-0-0 loss: 0.623841  [   32/   54]
train() client id: f_00006-1-0 loss: 0.565497  [   32/   54]
train() client id: f_00006-2-0 loss: 0.608427  [   32/   54]
train() client id: f_00006-3-0 loss: 0.567079  [   32/   54]
train() client id: f_00006-4-0 loss: 0.599640  [   32/   54]
train() client id: f_00006-5-0 loss: 0.525064  [   32/   54]
train() client id: f_00006-6-0 loss: 0.509927  [   32/   54]
train() client id: f_00006-7-0 loss: 0.612893  [   32/   54]
train() client id: f_00006-8-0 loss: 0.529920  [   32/   54]
train() client id: f_00006-9-0 loss: 0.609989  [   32/   54]
train() client id: f_00006-10-0 loss: 0.558815  [   32/   54]
train() client id: f_00006-11-0 loss: 0.564042  [   32/   54]
train() client id: f_00006-12-0 loss: 0.610747  [   32/   54]
train() client id: f_00007-0-0 loss: 0.586726  [   32/  179]
train() client id: f_00007-0-1 loss: 0.552748  [   64/  179]
train() client id: f_00007-0-2 loss: 0.731723  [   96/  179]
train() client id: f_00007-0-3 loss: 0.718226  [  128/  179]
train() client id: f_00007-0-4 loss: 0.682065  [  160/  179]
train() client id: f_00007-1-0 loss: 0.555492  [   32/  179]
train() client id: f_00007-1-1 loss: 0.890537  [   64/  179]
train() client id: f_00007-1-2 loss: 0.572833  [   96/  179]
train() client id: f_00007-1-3 loss: 0.493791  [  128/  179]
train() client id: f_00007-1-4 loss: 0.593949  [  160/  179]
train() client id: f_00007-2-0 loss: 0.792558  [   32/  179]
train() client id: f_00007-2-1 loss: 0.513012  [   64/  179]
train() client id: f_00007-2-2 loss: 0.700749  [   96/  179]
train() client id: f_00007-2-3 loss: 0.682121  [  128/  179]
train() client id: f_00007-2-4 loss: 0.469819  [  160/  179]
train() client id: f_00007-3-0 loss: 0.632379  [   32/  179]
train() client id: f_00007-3-1 loss: 0.530114  [   64/  179]
train() client id: f_00007-3-2 loss: 0.528361  [   96/  179]
train() client id: f_00007-3-3 loss: 0.718517  [  128/  179]
train() client id: f_00007-3-4 loss: 0.688297  [  160/  179]
train() client id: f_00007-4-0 loss: 0.617794  [   32/  179]
train() client id: f_00007-4-1 loss: 0.457311  [   64/  179]
train() client id: f_00007-4-2 loss: 0.747825  [   96/  179]
train() client id: f_00007-4-3 loss: 0.471912  [  128/  179]
train() client id: f_00007-4-4 loss: 0.631555  [  160/  179]
train() client id: f_00007-5-0 loss: 0.781788  [   32/  179]
train() client id: f_00007-5-1 loss: 0.736608  [   64/  179]
train() client id: f_00007-5-2 loss: 0.443222  [   96/  179]
train() client id: f_00007-5-3 loss: 0.540599  [  128/  179]
train() client id: f_00007-5-4 loss: 0.458970  [  160/  179]
train() client id: f_00007-6-0 loss: 0.529988  [   32/  179]
train() client id: f_00007-6-1 loss: 0.700049  [   64/  179]
train() client id: f_00007-6-2 loss: 0.626890  [   96/  179]
train() client id: f_00007-6-3 loss: 0.446097  [  128/  179]
train() client id: f_00007-6-4 loss: 0.723931  [  160/  179]
train() client id: f_00007-7-0 loss: 0.529305  [   32/  179]
train() client id: f_00007-7-1 loss: 0.616802  [   64/  179]
train() client id: f_00007-7-2 loss: 0.517970  [   96/  179]
train() client id: f_00007-7-3 loss: 0.572740  [  128/  179]
train() client id: f_00007-7-4 loss: 0.796027  [  160/  179]
train() client id: f_00007-8-0 loss: 0.523249  [   32/  179]
train() client id: f_00007-8-1 loss: 0.942532  [   64/  179]
train() client id: f_00007-8-2 loss: 0.496329  [   96/  179]
train() client id: f_00007-8-3 loss: 0.436826  [  128/  179]
train() client id: f_00007-8-4 loss: 0.604611  [  160/  179]
train() client id: f_00007-9-0 loss: 0.428144  [   32/  179]
train() client id: f_00007-9-1 loss: 0.434252  [   64/  179]
train() client id: f_00007-9-2 loss: 0.984758  [   96/  179]
train() client id: f_00007-9-3 loss: 0.555316  [  128/  179]
train() client id: f_00007-9-4 loss: 0.539972  [  160/  179]
train() client id: f_00007-10-0 loss: 0.719024  [   32/  179]
train() client id: f_00007-10-1 loss: 0.458283  [   64/  179]
train() client id: f_00007-10-2 loss: 0.663205  [   96/  179]
train() client id: f_00007-10-3 loss: 0.429013  [  128/  179]
train() client id: f_00007-10-4 loss: 0.685259  [  160/  179]
train() client id: f_00007-11-0 loss: 0.504785  [   32/  179]
train() client id: f_00007-11-1 loss: 0.626893  [   64/  179]
train() client id: f_00007-11-2 loss: 0.536494  [   96/  179]
train() client id: f_00007-11-3 loss: 0.651617  [  128/  179]
train() client id: f_00007-11-4 loss: 0.683950  [  160/  179]
train() client id: f_00007-12-0 loss: 0.407176  [   32/  179]
train() client id: f_00007-12-1 loss: 0.758254  [   64/  179]
train() client id: f_00007-12-2 loss: 0.551816  [   96/  179]
train() client id: f_00007-12-3 loss: 0.576991  [  128/  179]
train() client id: f_00007-12-4 loss: 0.621645  [  160/  179]
train() client id: f_00008-0-0 loss: 0.778149  [   32/  130]
train() client id: f_00008-0-1 loss: 0.725671  [   64/  130]
train() client id: f_00008-0-2 loss: 0.791140  [   96/  130]
train() client id: f_00008-0-3 loss: 0.892118  [  128/  130]
train() client id: f_00008-1-0 loss: 0.914374  [   32/  130]
train() client id: f_00008-1-1 loss: 0.795264  [   64/  130]
train() client id: f_00008-1-2 loss: 0.771612  [   96/  130]
train() client id: f_00008-1-3 loss: 0.753606  [  128/  130]
train() client id: f_00008-2-0 loss: 0.797941  [   32/  130]
train() client id: f_00008-2-1 loss: 0.798502  [   64/  130]
train() client id: f_00008-2-2 loss: 0.865947  [   96/  130]
train() client id: f_00008-2-3 loss: 0.725465  [  128/  130]
train() client id: f_00008-3-0 loss: 0.807981  [   32/  130]
train() client id: f_00008-3-1 loss: 0.824709  [   64/  130]
train() client id: f_00008-3-2 loss: 0.840955  [   96/  130]
train() client id: f_00008-3-3 loss: 0.760281  [  128/  130]
train() client id: f_00008-4-0 loss: 0.773250  [   32/  130]
train() client id: f_00008-4-1 loss: 0.762685  [   64/  130]
train() client id: f_00008-4-2 loss: 0.809254  [   96/  130]
train() client id: f_00008-4-3 loss: 0.797531  [  128/  130]
train() client id: f_00008-5-0 loss: 0.707309  [   32/  130]
train() client id: f_00008-5-1 loss: 0.845251  [   64/  130]
train() client id: f_00008-5-2 loss: 0.803586  [   96/  130]
train() client id: f_00008-5-3 loss: 0.858161  [  128/  130]
train() client id: f_00008-6-0 loss: 0.681134  [   32/  130]
train() client id: f_00008-6-1 loss: 0.946934  [   64/  130]
train() client id: f_00008-6-2 loss: 0.827308  [   96/  130]
train() client id: f_00008-6-3 loss: 0.768977  [  128/  130]
train() client id: f_00008-7-0 loss: 0.778725  [   32/  130]
train() client id: f_00008-7-1 loss: 0.856435  [   64/  130]
train() client id: f_00008-7-2 loss: 0.722791  [   96/  130]
train() client id: f_00008-7-3 loss: 0.866739  [  128/  130]
train() client id: f_00008-8-0 loss: 0.756026  [   32/  130]
train() client id: f_00008-8-1 loss: 0.911598  [   64/  130]
train() client id: f_00008-8-2 loss: 0.776280  [   96/  130]
train() client id: f_00008-8-3 loss: 0.748659  [  128/  130]
train() client id: f_00008-9-0 loss: 0.751251  [   32/  130]
train() client id: f_00008-9-1 loss: 0.894896  [   64/  130]
train() client id: f_00008-9-2 loss: 0.753260  [   96/  130]
train() client id: f_00008-9-3 loss: 0.795306  [  128/  130]
train() client id: f_00008-10-0 loss: 0.840698  [   32/  130]
train() client id: f_00008-10-1 loss: 0.809605  [   64/  130]
train() client id: f_00008-10-2 loss: 0.780133  [   96/  130]
train() client id: f_00008-10-3 loss: 0.790238  [  128/  130]
train() client id: f_00008-11-0 loss: 0.692940  [   32/  130]
train() client id: f_00008-11-1 loss: 0.863325  [   64/  130]
train() client id: f_00008-11-2 loss: 0.866757  [   96/  130]
train() client id: f_00008-11-3 loss: 0.802099  [  128/  130]
train() client id: f_00008-12-0 loss: 0.792636  [   32/  130]
train() client id: f_00008-12-1 loss: 0.893542  [   64/  130]
train() client id: f_00008-12-2 loss: 0.760572  [   96/  130]
train() client id: f_00008-12-3 loss: 0.777279  [  128/  130]
train() client id: f_00009-0-0 loss: 1.120140  [   32/  118]
train() client id: f_00009-0-1 loss: 1.019960  [   64/  118]
train() client id: f_00009-0-2 loss: 0.962296  [   96/  118]
train() client id: f_00009-1-0 loss: 0.935028  [   32/  118]
train() client id: f_00009-1-1 loss: 1.030605  [   64/  118]
train() client id: f_00009-1-2 loss: 0.970520  [   96/  118]
train() client id: f_00009-2-0 loss: 1.000265  [   32/  118]
train() client id: f_00009-2-1 loss: 0.956881  [   64/  118]
train() client id: f_00009-2-2 loss: 0.906164  [   96/  118]
train() client id: f_00009-3-0 loss: 0.925329  [   32/  118]
train() client id: f_00009-3-1 loss: 0.878287  [   64/  118]
train() client id: f_00009-3-2 loss: 0.920670  [   96/  118]
train() client id: f_00009-4-0 loss: 0.859038  [   32/  118]
train() client id: f_00009-4-1 loss: 0.901341  [   64/  118]
train() client id: f_00009-4-2 loss: 0.848309  [   96/  118]
train() client id: f_00009-5-0 loss: 0.853975  [   32/  118]
train() client id: f_00009-5-1 loss: 0.788893  [   64/  118]
train() client id: f_00009-5-2 loss: 0.901029  [   96/  118]
train() client id: f_00009-6-0 loss: 0.809961  [   32/  118]
train() client id: f_00009-6-1 loss: 0.851702  [   64/  118]
train() client id: f_00009-6-2 loss: 0.840262  [   96/  118]
train() client id: f_00009-7-0 loss: 0.765070  [   32/  118]
train() client id: f_00009-7-1 loss: 0.871335  [   64/  118]
train() client id: f_00009-7-2 loss: 0.798435  [   96/  118]
train() client id: f_00009-8-0 loss: 0.855965  [   32/  118]
train() client id: f_00009-8-1 loss: 0.762415  [   64/  118]
train() client id: f_00009-8-2 loss: 0.872006  [   96/  118]
train() client id: f_00009-9-0 loss: 0.845248  [   32/  118]
train() client id: f_00009-9-1 loss: 0.713155  [   64/  118]
train() client id: f_00009-9-2 loss: 0.747740  [   96/  118]
train() client id: f_00009-10-0 loss: 0.843811  [   32/  118]
train() client id: f_00009-10-1 loss: 0.715042  [   64/  118]
train() client id: f_00009-10-2 loss: 0.803097  [   96/  118]
train() client id: f_00009-11-0 loss: 0.837990  [   32/  118]
train() client id: f_00009-11-1 loss: 0.737260  [   64/  118]
train() client id: f_00009-11-2 loss: 0.801907  [   96/  118]
train() client id: f_00009-12-0 loss: 0.760128  [   32/  118]
train() client id: f_00009-12-1 loss: 0.773612  [   64/  118]
train() client id: f_00009-12-2 loss: 0.818429  [   96/  118]
At round 21 accuracy: 0.636604774535809
At round 21 training accuracy: 0.5828303152246814
At round 21 training loss: 0.8404784521188361
gradient difference: 0.4287092685699463
train() client id: f_00000-0-0 loss: 0.982523  [   32/  126]
train() client id: f_00000-0-1 loss: 0.830550  [   64/  126]
train() client id: f_00000-0-2 loss: 1.137085  [   96/  126]
train() client id: f_00000-1-0 loss: 0.931122  [   32/  126]
train() client id: f_00000-1-1 loss: 0.779130  [   64/  126]
train() client id: f_00000-1-2 loss: 1.096448  [   96/  126]
train() client id: f_00000-2-0 loss: 0.956361  [   32/  126]
train() client id: f_00000-2-1 loss: 1.105835  [   64/  126]
train() client id: f_00000-2-2 loss: 0.768285  [   96/  126]
train() client id: f_00000-3-0 loss: 0.754164  [   32/  126]
train() client id: f_00000-3-1 loss: 0.838888  [   64/  126]
train() client id: f_00000-3-2 loss: 0.891207  [   96/  126]
train() client id: f_00000-4-0 loss: 0.874095  [   32/  126]
train() client id: f_00000-4-1 loss: 0.691002  [   64/  126]
train() client id: f_00000-4-2 loss: 0.782435  [   96/  126]
train() client id: f_00000-5-0 loss: 0.814274  [   32/  126]
train() client id: f_00000-5-1 loss: 0.752157  [   64/  126]
train() client id: f_00000-5-2 loss: 0.754327  [   96/  126]
train() client id: f_00000-6-0 loss: 0.797086  [   32/  126]
train() client id: f_00000-6-1 loss: 0.732998  [   64/  126]
train() client id: f_00000-6-2 loss: 0.762076  [   96/  126]
train() client id: f_00000-7-0 loss: 0.869393  [   32/  126]
train() client id: f_00000-7-1 loss: 0.662469  [   64/  126]
train() client id: f_00000-7-2 loss: 0.766297  [   96/  126]
train() client id: f_00000-8-0 loss: 0.747425  [   32/  126]
train() client id: f_00000-8-1 loss: 0.696881  [   64/  126]
train() client id: f_00000-8-2 loss: 0.740078  [   96/  126]
train() client id: f_00000-9-0 loss: 0.723258  [   32/  126]
train() client id: f_00000-9-1 loss: 0.713552  [   64/  126]
train() client id: f_00000-9-2 loss: 0.741441  [   96/  126]
train() client id: f_00000-10-0 loss: 0.767371  [   32/  126]
train() client id: f_00000-10-1 loss: 0.670581  [   64/  126]
train() client id: f_00000-10-2 loss: 0.737021  [   96/  126]
train() client id: f_00000-11-0 loss: 0.690881  [   32/  126]
train() client id: f_00000-11-1 loss: 0.821788  [   64/  126]
train() client id: f_00000-11-2 loss: 0.758156  [   96/  126]
train() client id: f_00000-12-0 loss: 0.622037  [   32/  126]
train() client id: f_00000-12-1 loss: 0.702637  [   64/  126]
train() client id: f_00000-12-2 loss: 0.848273  [   96/  126]
train() client id: f_00001-0-0 loss: 0.450455  [   32/  265]
train() client id: f_00001-0-1 loss: 0.396464  [   64/  265]
train() client id: f_00001-0-2 loss: 0.547225  [   96/  265]
train() client id: f_00001-0-3 loss: 0.397275  [  128/  265]
train() client id: f_00001-0-4 loss: 0.502077  [  160/  265]
train() client id: f_00001-0-5 loss: 0.429363  [  192/  265]
train() client id: f_00001-0-6 loss: 0.580831  [  224/  265]
train() client id: f_00001-0-7 loss: 0.435057  [  256/  265]
train() client id: f_00001-1-0 loss: 0.373986  [   32/  265]
train() client id: f_00001-1-1 loss: 0.479885  [   64/  265]
train() client id: f_00001-1-2 loss: 0.420629  [   96/  265]
train() client id: f_00001-1-3 loss: 0.451226  [  128/  265]
train() client id: f_00001-1-4 loss: 0.498612  [  160/  265]
train() client id: f_00001-1-5 loss: 0.537640  [  192/  265]
train() client id: f_00001-1-6 loss: 0.421185  [  224/  265]
train() client id: f_00001-1-7 loss: 0.540722  [  256/  265]
train() client id: f_00001-2-0 loss: 0.424921  [   32/  265]
train() client id: f_00001-2-1 loss: 0.534123  [   64/  265]
train() client id: f_00001-2-2 loss: 0.400535  [   96/  265]
train() client id: f_00001-2-3 loss: 0.560884  [  128/  265]
train() client id: f_00001-2-4 loss: 0.511577  [  160/  265]
train() client id: f_00001-2-5 loss: 0.417015  [  192/  265]
train() client id: f_00001-2-6 loss: 0.457562  [  224/  265]
train() client id: f_00001-2-7 loss: 0.361291  [  256/  265]
train() client id: f_00001-3-0 loss: 0.453922  [   32/  265]
train() client id: f_00001-3-1 loss: 0.547403  [   64/  265]
train() client id: f_00001-3-2 loss: 0.462507  [   96/  265]
train() client id: f_00001-3-3 loss: 0.392361  [  128/  265]
train() client id: f_00001-3-4 loss: 0.519207  [  160/  265]
train() client id: f_00001-3-5 loss: 0.372108  [  192/  265]
train() client id: f_00001-3-6 loss: 0.351403  [  224/  265]
train() client id: f_00001-3-7 loss: 0.438753  [  256/  265]
train() client id: f_00001-4-0 loss: 0.480330  [   32/  265]
train() client id: f_00001-4-1 loss: 0.460985  [   64/  265]
train() client id: f_00001-4-2 loss: 0.360260  [   96/  265]
train() client id: f_00001-4-3 loss: 0.376656  [  128/  265]
train() client id: f_00001-4-4 loss: 0.615093  [  160/  265]
train() client id: f_00001-4-5 loss: 0.472939  [  192/  265]
train() client id: f_00001-4-6 loss: 0.356496  [  224/  265]
train() client id: f_00001-4-7 loss: 0.443030  [  256/  265]
train() client id: f_00001-5-0 loss: 0.569875  [   32/  265]
train() client id: f_00001-5-1 loss: 0.431501  [   64/  265]
train() client id: f_00001-5-2 loss: 0.386790  [   96/  265]
train() client id: f_00001-5-3 loss: 0.362518  [  128/  265]
train() client id: f_00001-5-4 loss: 0.425495  [  160/  265]
train() client id: f_00001-5-5 loss: 0.380580  [  192/  265]
train() client id: f_00001-5-6 loss: 0.426601  [  224/  265]
train() client id: f_00001-5-7 loss: 0.529542  [  256/  265]
train() client id: f_00001-6-0 loss: 0.369255  [   32/  265]
train() client id: f_00001-6-1 loss: 0.377463  [   64/  265]
train() client id: f_00001-6-2 loss: 0.404580  [   96/  265]
train() client id: f_00001-6-3 loss: 0.576689  [  128/  265]
train() client id: f_00001-6-4 loss: 0.450293  [  160/  265]
train() client id: f_00001-6-5 loss: 0.537121  [  192/  265]
train() client id: f_00001-6-6 loss: 0.392330  [  224/  265]
train() client id: f_00001-6-7 loss: 0.387999  [  256/  265]
train() client id: f_00001-7-0 loss: 0.519921  [   32/  265]
train() client id: f_00001-7-1 loss: 0.467624  [   64/  265]
train() client id: f_00001-7-2 loss: 0.428137  [   96/  265]
train() client id: f_00001-7-3 loss: 0.458383  [  128/  265]
train() client id: f_00001-7-4 loss: 0.371244  [  160/  265]
train() client id: f_00001-7-5 loss: 0.461712  [  192/  265]
train() client id: f_00001-7-6 loss: 0.353666  [  224/  265]
train() client id: f_00001-7-7 loss: 0.419661  [  256/  265]
train() client id: f_00001-8-0 loss: 0.360183  [   32/  265]
train() client id: f_00001-8-1 loss: 0.370721  [   64/  265]
train() client id: f_00001-8-2 loss: 0.419018  [   96/  265]
train() client id: f_00001-8-3 loss: 0.357810  [  128/  265]
train() client id: f_00001-8-4 loss: 0.434156  [  160/  265]
train() client id: f_00001-8-5 loss: 0.516248  [  192/  265]
train() client id: f_00001-8-6 loss: 0.574744  [  224/  265]
train() client id: f_00001-8-7 loss: 0.498445  [  256/  265]
train() client id: f_00001-9-0 loss: 0.424383  [   32/  265]
train() client id: f_00001-9-1 loss: 0.439895  [   64/  265]
train() client id: f_00001-9-2 loss: 0.481827  [   96/  265]
train() client id: f_00001-9-3 loss: 0.434627  [  128/  265]
train() client id: f_00001-9-4 loss: 0.498709  [  160/  265]
train() client id: f_00001-9-5 loss: 0.336609  [  192/  265]
train() client id: f_00001-9-6 loss: 0.447613  [  224/  265]
train() client id: f_00001-9-7 loss: 0.410257  [  256/  265]
train() client id: f_00001-10-0 loss: 0.371958  [   32/  265]
train() client id: f_00001-10-1 loss: 0.415549  [   64/  265]
train() client id: f_00001-10-2 loss: 0.409869  [   96/  265]
train() client id: f_00001-10-3 loss: 0.396764  [  128/  265]
train() client id: f_00001-10-4 loss: 0.533583  [  160/  265]
train() client id: f_00001-10-5 loss: 0.458714  [  192/  265]
train() client id: f_00001-10-6 loss: 0.578684  [  224/  265]
train() client id: f_00001-10-7 loss: 0.355407  [  256/  265]
train() client id: f_00001-11-0 loss: 0.354947  [   32/  265]
train() client id: f_00001-11-1 loss: 0.364828  [   64/  265]
train() client id: f_00001-11-2 loss: 0.357026  [   96/  265]
train() client id: f_00001-11-3 loss: 0.414995  [  128/  265]
train() client id: f_00001-11-4 loss: 0.504562  [  160/  265]
train() client id: f_00001-11-5 loss: 0.337606  [  192/  265]
train() client id: f_00001-11-6 loss: 0.597441  [  224/  265]
train() client id: f_00001-11-7 loss: 0.536134  [  256/  265]
train() client id: f_00001-12-0 loss: 0.411968  [   32/  265]
train() client id: f_00001-12-1 loss: 0.414497  [   64/  265]
train() client id: f_00001-12-2 loss: 0.418616  [   96/  265]
train() client id: f_00001-12-3 loss: 0.401059  [  128/  265]
train() client id: f_00001-12-4 loss: 0.457517  [  160/  265]
train() client id: f_00001-12-5 loss: 0.353470  [  192/  265]
train() client id: f_00001-12-6 loss: 0.567212  [  224/  265]
train() client id: f_00001-12-7 loss: 0.447337  [  256/  265]
train() client id: f_00002-0-0 loss: 1.273062  [   32/  124]
train() client id: f_00002-0-1 loss: 1.089250  [   64/  124]
train() client id: f_00002-0-2 loss: 0.973911  [   96/  124]
train() client id: f_00002-1-0 loss: 1.015760  [   32/  124]
train() client id: f_00002-1-1 loss: 1.029459  [   64/  124]
train() client id: f_00002-1-2 loss: 1.123667  [   96/  124]
train() client id: f_00002-2-0 loss: 1.252461  [   32/  124]
train() client id: f_00002-2-1 loss: 0.907244  [   64/  124]
train() client id: f_00002-2-2 loss: 0.936085  [   96/  124]
train() client id: f_00002-3-0 loss: 1.058688  [   32/  124]
train() client id: f_00002-3-1 loss: 0.898207  [   64/  124]
train() client id: f_00002-3-2 loss: 1.166679  [   96/  124]
train() client id: f_00002-4-0 loss: 0.941292  [   32/  124]
train() client id: f_00002-4-1 loss: 0.955003  [   64/  124]
train() client id: f_00002-4-2 loss: 0.890727  [   96/  124]
train() client id: f_00002-5-0 loss: 0.898119  [   32/  124]
train() client id: f_00002-5-1 loss: 0.995271  [   64/  124]
train() client id: f_00002-5-2 loss: 1.038737  [   96/  124]
train() client id: f_00002-6-0 loss: 0.934540  [   32/  124]
train() client id: f_00002-6-1 loss: 0.994234  [   64/  124]
train() client id: f_00002-6-2 loss: 0.880522  [   96/  124]
train() client id: f_00002-7-0 loss: 0.892776  [   32/  124]
train() client id: f_00002-7-1 loss: 1.000010  [   64/  124]
train() client id: f_00002-7-2 loss: 0.943244  [   96/  124]
train() client id: f_00002-8-0 loss: 0.906523  [   32/  124]
train() client id: f_00002-8-1 loss: 1.017621  [   64/  124]
train() client id: f_00002-8-2 loss: 0.833224  [   96/  124]
train() client id: f_00002-9-0 loss: 0.886394  [   32/  124]
train() client id: f_00002-9-1 loss: 0.958485  [   64/  124]
train() client id: f_00002-9-2 loss: 0.899594  [   96/  124]
train() client id: f_00002-10-0 loss: 0.874232  [   32/  124]
train() client id: f_00002-10-1 loss: 0.844076  [   64/  124]
train() client id: f_00002-10-2 loss: 0.861867  [   96/  124]
train() client id: f_00002-11-0 loss: 1.106462  [   32/  124]
train() client id: f_00002-11-1 loss: 0.843292  [   64/  124]
train() client id: f_00002-11-2 loss: 0.814836  [   96/  124]
train() client id: f_00002-12-0 loss: 0.963496  [   32/  124]
train() client id: f_00002-12-1 loss: 0.786105  [   64/  124]
train() client id: f_00002-12-2 loss: 0.908218  [   96/  124]
train() client id: f_00003-0-0 loss: 0.722011  [   32/   43]
train() client id: f_00003-1-0 loss: 0.626525  [   32/   43]
train() client id: f_00003-2-0 loss: 0.727807  [   32/   43]
train() client id: f_00003-3-0 loss: 0.678969  [   32/   43]
train() client id: f_00003-4-0 loss: 0.669299  [   32/   43]
train() client id: f_00003-5-0 loss: 0.752845  [   32/   43]
train() client id: f_00003-6-0 loss: 0.692716  [   32/   43]
train() client id: f_00003-7-0 loss: 0.639995  [   32/   43]
train() client id: f_00003-8-0 loss: 0.688478  [   32/   43]
train() client id: f_00003-9-0 loss: 0.702628  [   32/   43]
train() client id: f_00003-10-0 loss: 0.621332  [   32/   43]
train() client id: f_00003-11-0 loss: 0.590625  [   32/   43]
train() client id: f_00003-12-0 loss: 0.731613  [   32/   43]
train() client id: f_00004-0-0 loss: 0.833136  [   32/  306]
train() client id: f_00004-0-1 loss: 0.860572  [   64/  306]
train() client id: f_00004-0-2 loss: 0.986925  [   96/  306]
train() client id: f_00004-0-3 loss: 0.891392  [  128/  306]
train() client id: f_00004-0-4 loss: 0.963556  [  160/  306]
train() client id: f_00004-0-5 loss: 0.970065  [  192/  306]
train() client id: f_00004-0-6 loss: 0.821494  [  224/  306]
train() client id: f_00004-0-7 loss: 0.861271  [  256/  306]
train() client id: f_00004-0-8 loss: 0.850395  [  288/  306]
train() client id: f_00004-1-0 loss: 0.896482  [   32/  306]
train() client id: f_00004-1-1 loss: 1.001962  [   64/  306]
train() client id: f_00004-1-2 loss: 0.842099  [   96/  306]
train() client id: f_00004-1-3 loss: 0.858845  [  128/  306]
train() client id: f_00004-1-4 loss: 0.936298  [  160/  306]
train() client id: f_00004-1-5 loss: 0.764096  [  192/  306]
train() client id: f_00004-1-6 loss: 0.798811  [  224/  306]
train() client id: f_00004-1-7 loss: 0.919912  [  256/  306]
train() client id: f_00004-1-8 loss: 0.897538  [  288/  306]
train() client id: f_00004-2-0 loss: 0.991388  [   32/  306]
train() client id: f_00004-2-1 loss: 0.890924  [   64/  306]
train() client id: f_00004-2-2 loss: 0.791070  [   96/  306]
train() client id: f_00004-2-3 loss: 1.031971  [  128/  306]
train() client id: f_00004-2-4 loss: 0.800926  [  160/  306]
train() client id: f_00004-2-5 loss: 0.896492  [  192/  306]
train() client id: f_00004-2-6 loss: 0.793694  [  224/  306]
train() client id: f_00004-2-7 loss: 0.929332  [  256/  306]
train() client id: f_00004-2-8 loss: 0.863510  [  288/  306]
train() client id: f_00004-3-0 loss: 0.847779  [   32/  306]
train() client id: f_00004-3-1 loss: 0.885747  [   64/  306]
train() client id: f_00004-3-2 loss: 0.860500  [   96/  306]
train() client id: f_00004-3-3 loss: 0.917375  [  128/  306]
train() client id: f_00004-3-4 loss: 0.784021  [  160/  306]
train() client id: f_00004-3-5 loss: 0.929058  [  192/  306]
train() client id: f_00004-3-6 loss: 0.882702  [  224/  306]
train() client id: f_00004-3-7 loss: 0.932046  [  256/  306]
train() client id: f_00004-3-8 loss: 0.944909  [  288/  306]
train() client id: f_00004-4-0 loss: 0.892652  [   32/  306]
train() client id: f_00004-4-1 loss: 0.824623  [   64/  306]
train() client id: f_00004-4-2 loss: 0.872383  [   96/  306]
train() client id: f_00004-4-3 loss: 0.839487  [  128/  306]
train() client id: f_00004-4-4 loss: 0.778404  [  160/  306]
train() client id: f_00004-4-5 loss: 0.850199  [  192/  306]
train() client id: f_00004-4-6 loss: 0.920678  [  224/  306]
train() client id: f_00004-4-7 loss: 0.901469  [  256/  306]
train() client id: f_00004-4-8 loss: 0.969589  [  288/  306]
train() client id: f_00004-5-0 loss: 0.842402  [   32/  306]
train() client id: f_00004-5-1 loss: 0.799476  [   64/  306]
train() client id: f_00004-5-2 loss: 0.923752  [   96/  306]
train() client id: f_00004-5-3 loss: 0.940597  [  128/  306]
train() client id: f_00004-5-4 loss: 0.796092  [  160/  306]
train() client id: f_00004-5-5 loss: 0.978466  [  192/  306]
train() client id: f_00004-5-6 loss: 0.805105  [  224/  306]
train() client id: f_00004-5-7 loss: 0.866751  [  256/  306]
train() client id: f_00004-5-8 loss: 0.926368  [  288/  306]
train() client id: f_00004-6-0 loss: 0.934751  [   32/  306]
train() client id: f_00004-6-1 loss: 0.937567  [   64/  306]
train() client id: f_00004-6-2 loss: 0.926419  [   96/  306]
train() client id: f_00004-6-3 loss: 0.848906  [  128/  306]
train() client id: f_00004-6-4 loss: 0.854113  [  160/  306]
train() client id: f_00004-6-5 loss: 0.749734  [  192/  306]
train() client id: f_00004-6-6 loss: 0.892346  [  224/  306]
train() client id: f_00004-6-7 loss: 0.976222  [  256/  306]
train() client id: f_00004-6-8 loss: 0.896839  [  288/  306]
train() client id: f_00004-7-0 loss: 0.842608  [   32/  306]
train() client id: f_00004-7-1 loss: 0.919942  [   64/  306]
train() client id: f_00004-7-2 loss: 0.823859  [   96/  306]
train() client id: f_00004-7-3 loss: 0.926797  [  128/  306]
train() client id: f_00004-7-4 loss: 0.854856  [  160/  306]
train() client id: f_00004-7-5 loss: 0.895913  [  192/  306]
train() client id: f_00004-7-6 loss: 0.882865  [  224/  306]
train() client id: f_00004-7-7 loss: 0.927174  [  256/  306]
train() client id: f_00004-7-8 loss: 0.889502  [  288/  306]
train() client id: f_00004-8-0 loss: 0.858672  [   32/  306]
train() client id: f_00004-8-1 loss: 0.920907  [   64/  306]
train() client id: f_00004-8-2 loss: 0.760380  [   96/  306]
train() client id: f_00004-8-3 loss: 0.966347  [  128/  306]
train() client id: f_00004-8-4 loss: 0.932291  [  160/  306]
train() client id: f_00004-8-5 loss: 0.830046  [  192/  306]
train() client id: f_00004-8-6 loss: 0.869826  [  224/  306]
train() client id: f_00004-8-7 loss: 0.871997  [  256/  306]
train() client id: f_00004-8-8 loss: 0.851742  [  288/  306]
train() client id: f_00004-9-0 loss: 0.934638  [   32/  306]
train() client id: f_00004-9-1 loss: 0.802343  [   64/  306]
train() client id: f_00004-9-2 loss: 0.938439  [   96/  306]
train() client id: f_00004-9-3 loss: 0.947143  [  128/  306]
train() client id: f_00004-9-4 loss: 0.862085  [  160/  306]
train() client id: f_00004-9-5 loss: 0.923269  [  192/  306]
train() client id: f_00004-9-6 loss: 0.846404  [  224/  306]
train() client id: f_00004-9-7 loss: 0.834321  [  256/  306]
train() client id: f_00004-9-8 loss: 0.827705  [  288/  306]
train() client id: f_00004-10-0 loss: 0.842032  [   32/  306]
train() client id: f_00004-10-1 loss: 0.936561  [   64/  306]
train() client id: f_00004-10-2 loss: 0.900896  [   96/  306]
train() client id: f_00004-10-3 loss: 0.833630  [  128/  306]
train() client id: f_00004-10-4 loss: 0.921970  [  160/  306]
train() client id: f_00004-10-5 loss: 0.801779  [  192/  306]
train() client id: f_00004-10-6 loss: 0.780597  [  224/  306]
train() client id: f_00004-10-7 loss: 0.955914  [  256/  306]
train() client id: f_00004-10-8 loss: 0.974709  [  288/  306]
train() client id: f_00004-11-0 loss: 0.938772  [   32/  306]
train() client id: f_00004-11-1 loss: 0.768089  [   64/  306]
train() client id: f_00004-11-2 loss: 1.029512  [   96/  306]
train() client id: f_00004-11-3 loss: 0.874472  [  128/  306]
train() client id: f_00004-11-4 loss: 0.840545  [  160/  306]
train() client id: f_00004-11-5 loss: 0.854634  [  192/  306]
train() client id: f_00004-11-6 loss: 0.974564  [  224/  306]
train() client id: f_00004-11-7 loss: 0.780822  [  256/  306]
train() client id: f_00004-11-8 loss: 0.888805  [  288/  306]
train() client id: f_00004-12-0 loss: 0.830807  [   32/  306]
train() client id: f_00004-12-1 loss: 0.953069  [   64/  306]
train() client id: f_00004-12-2 loss: 0.850114  [   96/  306]
train() client id: f_00004-12-3 loss: 0.956804  [  128/  306]
train() client id: f_00004-12-4 loss: 0.883516  [  160/  306]
train() client id: f_00004-12-5 loss: 0.884708  [  192/  306]
train() client id: f_00004-12-6 loss: 0.895933  [  224/  306]
train() client id: f_00004-12-7 loss: 0.957499  [  256/  306]
train() client id: f_00004-12-8 loss: 0.765772  [  288/  306]
train() client id: f_00005-0-0 loss: 0.439909  [   32/  146]
train() client id: f_00005-0-1 loss: 0.437737  [   64/  146]
train() client id: f_00005-0-2 loss: 0.487172  [   96/  146]
train() client id: f_00005-0-3 loss: 0.883286  [  128/  146]
train() client id: f_00005-1-0 loss: 0.407842  [   32/  146]
train() client id: f_00005-1-1 loss: 0.566947  [   64/  146]
train() client id: f_00005-1-2 loss: 0.695340  [   96/  146]
train() client id: f_00005-1-3 loss: 0.584823  [  128/  146]
train() client id: f_00005-2-0 loss: 0.573779  [   32/  146]
train() client id: f_00005-2-1 loss: 0.417131  [   64/  146]
train() client id: f_00005-2-2 loss: 0.463183  [   96/  146]
train() client id: f_00005-2-3 loss: 0.667216  [  128/  146]
train() client id: f_00005-3-0 loss: 0.656146  [   32/  146]
train() client id: f_00005-3-1 loss: 0.468052  [   64/  146]
train() client id: f_00005-3-2 loss: 0.523783  [   96/  146]
train() client id: f_00005-3-3 loss: 0.332216  [  128/  146]
train() client id: f_00005-4-0 loss: 0.617582  [   32/  146]
train() client id: f_00005-4-1 loss: 0.341600  [   64/  146]
train() client id: f_00005-4-2 loss: 0.671177  [   96/  146]
train() client id: f_00005-4-3 loss: 0.605457  [  128/  146]
train() client id: f_00005-5-0 loss: 0.686721  [   32/  146]
train() client id: f_00005-5-1 loss: 0.514852  [   64/  146]
train() client id: f_00005-5-2 loss: 0.533511  [   96/  146]
train() client id: f_00005-5-3 loss: 0.461515  [  128/  146]
train() client id: f_00005-6-0 loss: 0.746152  [   32/  146]
train() client id: f_00005-6-1 loss: 0.493045  [   64/  146]
train() client id: f_00005-6-2 loss: 0.348695  [   96/  146]
train() client id: f_00005-6-3 loss: 0.433886  [  128/  146]
train() client id: f_00005-7-0 loss: 0.639813  [   32/  146]
train() client id: f_00005-7-1 loss: 0.423960  [   64/  146]
train() client id: f_00005-7-2 loss: 0.543697  [   96/  146]
train() client id: f_00005-7-3 loss: 0.365955  [  128/  146]
train() client id: f_00005-8-0 loss: 0.499729  [   32/  146]
train() client id: f_00005-8-1 loss: 0.692461  [   64/  146]
train() client id: f_00005-8-2 loss: 0.518346  [   96/  146]
train() client id: f_00005-8-3 loss: 0.340515  [  128/  146]
train() client id: f_00005-9-0 loss: 0.477504  [   32/  146]
train() client id: f_00005-9-1 loss: 0.510648  [   64/  146]
train() client id: f_00005-9-2 loss: 0.722843  [   96/  146]
train() client id: f_00005-9-3 loss: 0.304498  [  128/  146]
train() client id: f_00005-10-0 loss: 0.495788  [   32/  146]
train() client id: f_00005-10-1 loss: 0.544392  [   64/  146]
train() client id: f_00005-10-2 loss: 0.509482  [   96/  146]
train() client id: f_00005-10-3 loss: 0.393786  [  128/  146]
train() client id: f_00005-11-0 loss: 0.689661  [   32/  146]
train() client id: f_00005-11-1 loss: 0.504961  [   64/  146]
train() client id: f_00005-11-2 loss: 0.340434  [   96/  146]
train() client id: f_00005-11-3 loss: 0.575041  [  128/  146]
train() client id: f_00005-12-0 loss: 0.433446  [   32/  146]
train() client id: f_00005-12-1 loss: 0.420591  [   64/  146]
train() client id: f_00005-12-2 loss: 0.423663  [   96/  146]
train() client id: f_00005-12-3 loss: 0.672417  [  128/  146]
train() client id: f_00006-0-0 loss: 0.518245  [   32/   54]
train() client id: f_00006-1-0 loss: 0.555761  [   32/   54]
train() client id: f_00006-2-0 loss: 0.571056  [   32/   54]
train() client id: f_00006-3-0 loss: 0.549348  [   32/   54]
train() client id: f_00006-4-0 loss: 0.502262  [   32/   54]
train() client id: f_00006-5-0 loss: 0.555207  [   32/   54]
train() client id: f_00006-6-0 loss: 0.531850  [   32/   54]
train() client id: f_00006-7-0 loss: 0.506246  [   32/   54]
train() client id: f_00006-8-0 loss: 0.514973  [   32/   54]
train() client id: f_00006-9-0 loss: 0.520103  [   32/   54]
train() client id: f_00006-10-0 loss: 0.476382  [   32/   54]
train() client id: f_00006-11-0 loss: 0.496664  [   32/   54]
train() client id: f_00006-12-0 loss: 0.520029  [   32/   54]
train() client id: f_00007-0-0 loss: 0.659588  [   32/  179]
train() client id: f_00007-0-1 loss: 0.509586  [   64/  179]
train() client id: f_00007-0-2 loss: 0.528820  [   96/  179]
train() client id: f_00007-0-3 loss: 0.603989  [  128/  179]
train() client id: f_00007-0-4 loss: 0.442191  [  160/  179]
train() client id: f_00007-1-0 loss: 0.593858  [   32/  179]
train() client id: f_00007-1-1 loss: 0.661612  [   64/  179]
train() client id: f_00007-1-2 loss: 0.431132  [   96/  179]
train() client id: f_00007-1-3 loss: 0.439613  [  128/  179]
train() client id: f_00007-1-4 loss: 0.645444  [  160/  179]
train() client id: f_00007-2-0 loss: 0.696341  [   32/  179]
train() client id: f_00007-2-1 loss: 0.553274  [   64/  179]
train() client id: f_00007-2-2 loss: 0.442884  [   96/  179]
train() client id: f_00007-2-3 loss: 0.615835  [  128/  179]
train() client id: f_00007-2-4 loss: 0.434262  [  160/  179]
train() client id: f_00007-3-0 loss: 0.459313  [   32/  179]
train() client id: f_00007-3-1 loss: 0.473271  [   64/  179]
train() client id: f_00007-3-2 loss: 0.560156  [   96/  179]
train() client id: f_00007-3-3 loss: 0.535169  [  128/  179]
train() client id: f_00007-3-4 loss: 0.464992  [  160/  179]
train() client id: f_00007-4-0 loss: 0.552070  [   32/  179]
train() client id: f_00007-4-1 loss: 0.616051  [   64/  179]
train() client id: f_00007-4-2 loss: 0.380913  [   96/  179]
train() client id: f_00007-4-3 loss: 0.392132  [  128/  179]
train() client id: f_00007-4-4 loss: 0.617446  [  160/  179]
train() client id: f_00007-5-0 loss: 0.581030  [   32/  179]
train() client id: f_00007-5-1 loss: 0.562125  [   64/  179]
train() client id: f_00007-5-2 loss: 0.655289  [   96/  179]
train() client id: f_00007-5-3 loss: 0.358454  [  128/  179]
train() client id: f_00007-5-4 loss: 0.494255  [  160/  179]
train() client id: f_00007-6-0 loss: 0.526008  [   32/  179]
train() client id: f_00007-6-1 loss: 0.450576  [   64/  179]
train() client id: f_00007-6-2 loss: 0.672457  [   96/  179]
train() client id: f_00007-6-3 loss: 0.397260  [  128/  179]
train() client id: f_00007-6-4 loss: 0.472702  [  160/  179]
train() client id: f_00007-7-0 loss: 0.355172  [   32/  179]
train() client id: f_00007-7-1 loss: 0.795927  [   64/  179]
train() client id: f_00007-7-2 loss: 0.448708  [   96/  179]
train() client id: f_00007-7-3 loss: 0.451023  [  128/  179]
train() client id: f_00007-7-4 loss: 0.550503  [  160/  179]
train() client id: f_00007-8-0 loss: 0.591614  [   32/  179]
train() client id: f_00007-8-1 loss: 0.455388  [   64/  179]
train() client id: f_00007-8-2 loss: 0.446383  [   96/  179]
train() client id: f_00007-8-3 loss: 0.345192  [  128/  179]
train() client id: f_00007-8-4 loss: 0.624066  [  160/  179]
train() client id: f_00007-9-0 loss: 0.456813  [   32/  179]
train() client id: f_00007-9-1 loss: 0.448655  [   64/  179]
train() client id: f_00007-9-2 loss: 0.535584  [   96/  179]
train() client id: f_00007-9-3 loss: 0.443349  [  128/  179]
train() client id: f_00007-9-4 loss: 0.449737  [  160/  179]
train() client id: f_00007-10-0 loss: 0.404653  [   32/  179]
train() client id: f_00007-10-1 loss: 0.524710  [   64/  179]
train() client id: f_00007-10-2 loss: 0.474982  [   96/  179]
train() client id: f_00007-10-3 loss: 0.368274  [  128/  179]
train() client id: f_00007-10-4 loss: 0.672026  [  160/  179]
train() client id: f_00007-11-0 loss: 0.619211  [   32/  179]
train() client id: f_00007-11-1 loss: 0.528460  [   64/  179]
train() client id: f_00007-11-2 loss: 0.453989  [   96/  179]
train() client id: f_00007-11-3 loss: 0.606570  [  128/  179]
train() client id: f_00007-11-4 loss: 0.355668  [  160/  179]
train() client id: f_00007-12-0 loss: 0.546054  [   32/  179]
train() client id: f_00007-12-1 loss: 0.343714  [   64/  179]
train() client id: f_00007-12-2 loss: 0.346374  [   96/  179]
train() client id: f_00007-12-3 loss: 0.600623  [  128/  179]
train() client id: f_00007-12-4 loss: 0.562350  [  160/  179]
train() client id: f_00008-0-0 loss: 0.824267  [   32/  130]
train() client id: f_00008-0-1 loss: 0.801913  [   64/  130]
train() client id: f_00008-0-2 loss: 0.873878  [   96/  130]
train() client id: f_00008-0-3 loss: 0.699261  [  128/  130]
train() client id: f_00008-1-0 loss: 0.918158  [   32/  130]
train() client id: f_00008-1-1 loss: 0.717605  [   64/  130]
train() client id: f_00008-1-2 loss: 0.751444  [   96/  130]
train() client id: f_00008-1-3 loss: 0.803172  [  128/  130]
train() client id: f_00008-2-0 loss: 0.745337  [   32/  130]
train() client id: f_00008-2-1 loss: 0.713075  [   64/  130]
train() client id: f_00008-2-2 loss: 0.845945  [   96/  130]
train() client id: f_00008-2-3 loss: 0.884507  [  128/  130]
train() client id: f_00008-3-0 loss: 0.857863  [   32/  130]
train() client id: f_00008-3-1 loss: 0.666841  [   64/  130]
train() client id: f_00008-3-2 loss: 0.689610  [   96/  130]
train() client id: f_00008-3-3 loss: 0.979055  [  128/  130]
train() client id: f_00008-4-0 loss: 0.792307  [   32/  130]
train() client id: f_00008-4-1 loss: 0.780680  [   64/  130]
train() client id: f_00008-4-2 loss: 0.793435  [   96/  130]
train() client id: f_00008-4-3 loss: 0.806404  [  128/  130]
train() client id: f_00008-5-0 loss: 0.830571  [   32/  130]
train() client id: f_00008-5-1 loss: 0.833740  [   64/  130]
train() client id: f_00008-5-2 loss: 0.703859  [   96/  130]
train() client id: f_00008-5-3 loss: 0.824571  [  128/  130]
train() client id: f_00008-6-0 loss: 0.844636  [   32/  130]
train() client id: f_00008-6-1 loss: 0.846689  [   64/  130]
train() client id: f_00008-6-2 loss: 0.774828  [   96/  130]
train() client id: f_00008-6-3 loss: 0.723473  [  128/  130]
train() client id: f_00008-7-0 loss: 0.750603  [   32/  130]
train() client id: f_00008-7-1 loss: 0.969219  [   64/  130]
train() client id: f_00008-7-2 loss: 0.740952  [   96/  130]
train() client id: f_00008-7-3 loss: 0.725556  [  128/  130]
train() client id: f_00008-8-0 loss: 0.935328  [   32/  130]
train() client id: f_00008-8-1 loss: 0.749120  [   64/  130]
train() client id: f_00008-8-2 loss: 0.720088  [   96/  130]
train() client id: f_00008-8-3 loss: 0.782141  [  128/  130]
train() client id: f_00008-9-0 loss: 0.960793  [   32/  130]
train() client id: f_00008-9-1 loss: 0.736632  [   64/  130]
train() client id: f_00008-9-2 loss: 0.718375  [   96/  130]
train() client id: f_00008-9-3 loss: 0.772213  [  128/  130]
train() client id: f_00008-10-0 loss: 0.766556  [   32/  130]
train() client id: f_00008-10-1 loss: 0.918459  [   64/  130]
train() client id: f_00008-10-2 loss: 0.850300  [   96/  130]
train() client id: f_00008-10-3 loss: 0.649405  [  128/  130]
train() client id: f_00008-11-0 loss: 0.789712  [   32/  130]
train() client id: f_00008-11-1 loss: 0.720139  [   64/  130]
train() client id: f_00008-11-2 loss: 0.725566  [   96/  130]
train() client id: f_00008-11-3 loss: 0.950175  [  128/  130]
train() client id: f_00008-12-0 loss: 0.769613  [   32/  130]
train() client id: f_00008-12-1 loss: 0.820655  [   64/  130]
train() client id: f_00008-12-2 loss: 0.805666  [   96/  130]
train() client id: f_00008-12-3 loss: 0.762157  [  128/  130]
train() client id: f_00009-0-0 loss: 1.176422  [   32/  118]
train() client id: f_00009-0-1 loss: 0.933107  [   64/  118]
train() client id: f_00009-0-2 loss: 1.140091  [   96/  118]
train() client id: f_00009-1-0 loss: 0.873235  [   32/  118]
train() client id: f_00009-1-1 loss: 1.041365  [   64/  118]
train() client id: f_00009-1-2 loss: 1.085389  [   96/  118]
train() client id: f_00009-2-0 loss: 1.000109  [   32/  118]
train() client id: f_00009-2-1 loss: 0.954298  [   64/  118]
train() client id: f_00009-2-2 loss: 0.994776  [   96/  118]
train() client id: f_00009-3-0 loss: 0.912395  [   32/  118]
train() client id: f_00009-3-1 loss: 0.944599  [   64/  118]
train() client id: f_00009-3-2 loss: 0.882840  [   96/  118]
train() client id: f_00009-4-0 loss: 0.834090  [   32/  118]
train() client id: f_00009-4-1 loss: 0.954850  [   64/  118]
train() client id: f_00009-4-2 loss: 0.853313  [   96/  118]
train() client id: f_00009-5-0 loss: 0.917738  [   32/  118]
train() client id: f_00009-5-1 loss: 0.924776  [   64/  118]
train() client id: f_00009-5-2 loss: 0.776564  [   96/  118]
train() client id: f_00009-6-0 loss: 0.905078  [   32/  118]
train() client id: f_00009-6-1 loss: 0.844580  [   64/  118]
train() client id: f_00009-6-2 loss: 0.780811  [   96/  118]
train() client id: f_00009-7-0 loss: 0.826521  [   32/  118]
train() client id: f_00009-7-1 loss: 0.793989  [   64/  118]
train() client id: f_00009-7-2 loss: 0.780777  [   96/  118]
train() client id: f_00009-8-0 loss: 0.860527  [   32/  118]
train() client id: f_00009-8-1 loss: 0.812360  [   64/  118]
train() client id: f_00009-8-2 loss: 0.788638  [   96/  118]
train() client id: f_00009-9-0 loss: 0.738962  [   32/  118]
train() client id: f_00009-9-1 loss: 0.727233  [   64/  118]
train() client id: f_00009-9-2 loss: 0.835093  [   96/  118]
train() client id: f_00009-10-0 loss: 0.692220  [   32/  118]
train() client id: f_00009-10-1 loss: 0.798096  [   64/  118]
train() client id: f_00009-10-2 loss: 0.844483  [   96/  118]
train() client id: f_00009-11-0 loss: 0.729963  [   32/  118]
train() client id: f_00009-11-1 loss: 0.845753  [   64/  118]
train() client id: f_00009-11-2 loss: 0.862221  [   96/  118]
train() client id: f_00009-12-0 loss: 0.700066  [   32/  118]
train() client id: f_00009-12-1 loss: 0.870030  [   64/  118]
train() client id: f_00009-12-2 loss: 0.846277  [   96/  118]
At round 22 accuracy: 0.636604774535809
At round 22 training accuracy: 0.5855130784708249
At round 22 training loss: 0.8406720306045546
gradient difference: 0.42708438634872437
train() client id: f_00000-0-0 loss: 1.252356  [   32/  126]
train() client id: f_00000-0-1 loss: 1.502967  [   64/  126]
train() client id: f_00000-0-2 loss: 1.199692  [   96/  126]
train() client id: f_00000-1-0 loss: 1.335479  [   32/  126]
train() client id: f_00000-1-1 loss: 1.231096  [   64/  126]
train() client id: f_00000-1-2 loss: 1.109637  [   96/  126]
train() client id: f_00000-2-0 loss: 0.928528  [   32/  126]
train() client id: f_00000-2-1 loss: 1.049016  [   64/  126]
train() client id: f_00000-2-2 loss: 1.282277  [   96/  126]
train() client id: f_00000-3-0 loss: 1.097131  [   32/  126]
train() client id: f_00000-3-1 loss: 0.910010  [   64/  126]
train() client id: f_00000-3-2 loss: 1.014539  [   96/  126]
train() client id: f_00000-4-0 loss: 0.989123  [   32/  126]
train() client id: f_00000-4-1 loss: 0.906724  [   64/  126]
train() client id: f_00000-4-2 loss: 0.879943  [   96/  126]
train() client id: f_00000-5-0 loss: 0.764609  [   32/  126]
train() client id: f_00000-5-1 loss: 0.993392  [   64/  126]
train() client id: f_00000-5-2 loss: 0.855596  [   96/  126]
train() client id: f_00000-6-0 loss: 0.924535  [   32/  126]
train() client id: f_00000-6-1 loss: 0.767422  [   64/  126]
train() client id: f_00000-6-2 loss: 0.855002  [   96/  126]
train() client id: f_00000-7-0 loss: 0.800847  [   32/  126]
train() client id: f_00000-7-1 loss: 0.776915  [   64/  126]
train() client id: f_00000-7-2 loss: 0.760522  [   96/  126]
train() client id: f_00000-8-0 loss: 0.779583  [   32/  126]
train() client id: f_00000-8-1 loss: 0.851333  [   64/  126]
train() client id: f_00000-8-2 loss: 0.849021  [   96/  126]
train() client id: f_00000-9-0 loss: 0.918315  [   32/  126]
train() client id: f_00000-9-1 loss: 0.821198  [   64/  126]
train() client id: f_00000-9-2 loss: 0.764051  [   96/  126]
train() client id: f_00000-10-0 loss: 0.736887  [   32/  126]
train() client id: f_00000-10-1 loss: 0.723222  [   64/  126]
train() client id: f_00000-10-2 loss: 0.681972  [   96/  126]
train() client id: f_00000-11-0 loss: 0.728366  [   32/  126]
train() client id: f_00000-11-1 loss: 0.788517  [   64/  126]
train() client id: f_00000-11-2 loss: 0.713106  [   96/  126]
train() client id: f_00000-12-0 loss: 0.726238  [   32/  126]
train() client id: f_00000-12-1 loss: 0.727775  [   64/  126]
train() client id: f_00000-12-2 loss: 0.743779  [   96/  126]
train() client id: f_00001-0-0 loss: 0.478423  [   32/  265]
train() client id: f_00001-0-1 loss: 0.444732  [   64/  265]
train() client id: f_00001-0-2 loss: 0.422438  [   96/  265]
train() client id: f_00001-0-3 loss: 0.407691  [  128/  265]
train() client id: f_00001-0-4 loss: 0.488025  [  160/  265]
train() client id: f_00001-0-5 loss: 0.412400  [  192/  265]
train() client id: f_00001-0-6 loss: 0.498392  [  224/  265]
train() client id: f_00001-0-7 loss: 0.390284  [  256/  265]
train() client id: f_00001-1-0 loss: 0.439638  [   32/  265]
train() client id: f_00001-1-1 loss: 0.364387  [   64/  265]
train() client id: f_00001-1-2 loss: 0.414220  [   96/  265]
train() client id: f_00001-1-3 loss: 0.464340  [  128/  265]
train() client id: f_00001-1-4 loss: 0.467517  [  160/  265]
train() client id: f_00001-1-5 loss: 0.361674  [  192/  265]
train() client id: f_00001-1-6 loss: 0.502533  [  224/  265]
train() client id: f_00001-1-7 loss: 0.480968  [  256/  265]
train() client id: f_00001-2-0 loss: 0.461992  [   32/  265]
train() client id: f_00001-2-1 loss: 0.387216  [   64/  265]
train() client id: f_00001-2-2 loss: 0.489613  [   96/  265]
train() client id: f_00001-2-3 loss: 0.349294  [  128/  265]
train() client id: f_00001-2-4 loss: 0.422597  [  160/  265]
train() client id: f_00001-2-5 loss: 0.406205  [  192/  265]
train() client id: f_00001-2-6 loss: 0.450475  [  224/  265]
train() client id: f_00001-2-7 loss: 0.427081  [  256/  265]
train() client id: f_00001-3-0 loss: 0.342794  [   32/  265]
train() client id: f_00001-3-1 loss: 0.353786  [   64/  265]
train() client id: f_00001-3-2 loss: 0.356133  [   96/  265]
train() client id: f_00001-3-3 loss: 0.330542  [  128/  265]
train() client id: f_00001-3-4 loss: 0.360165  [  160/  265]
train() client id: f_00001-3-5 loss: 0.640493  [  192/  265]
train() client id: f_00001-3-6 loss: 0.485815  [  224/  265]
train() client id: f_00001-3-7 loss: 0.487903  [  256/  265]
train() client id: f_00001-4-0 loss: 0.362052  [   32/  265]
train() client id: f_00001-4-1 loss: 0.339135  [   64/  265]
train() client id: f_00001-4-2 loss: 0.471549  [   96/  265]
train() client id: f_00001-4-3 loss: 0.385534  [  128/  265]
train() client id: f_00001-4-4 loss: 0.414794  [  160/  265]
train() client id: f_00001-4-5 loss: 0.392104  [  192/  265]
train() client id: f_00001-4-6 loss: 0.514232  [  224/  265]
train() client id: f_00001-4-7 loss: 0.493603  [  256/  265]
train() client id: f_00001-5-0 loss: 0.352638  [   32/  265]
train() client id: f_00001-5-1 loss: 0.476955  [   64/  265]
train() client id: f_00001-5-2 loss: 0.342476  [   96/  265]
train() client id: f_00001-5-3 loss: 0.474526  [  128/  265]
train() client id: f_00001-5-4 loss: 0.396492  [  160/  265]
train() client id: f_00001-5-5 loss: 0.450213  [  192/  265]
train() client id: f_00001-5-6 loss: 0.495156  [  224/  265]
train() client id: f_00001-5-7 loss: 0.340195  [  256/  265]
train() client id: f_00001-6-0 loss: 0.505694  [   32/  265]
train() client id: f_00001-6-1 loss: 0.415062  [   64/  265]
train() client id: f_00001-6-2 loss: 0.290676  [   96/  265]
train() client id: f_00001-6-3 loss: 0.418108  [  128/  265]
train() client id: f_00001-6-4 loss: 0.497659  [  160/  265]
train() client id: f_00001-6-5 loss: 0.391061  [  192/  265]
train() client id: f_00001-6-6 loss: 0.440813  [  224/  265]
train() client id: f_00001-6-7 loss: 0.348921  [  256/  265]
train() client id: f_00001-7-0 loss: 0.405327  [   32/  265]
train() client id: f_00001-7-1 loss: 0.497800  [   64/  265]
train() client id: f_00001-7-2 loss: 0.459563  [   96/  265]
train() client id: f_00001-7-3 loss: 0.365951  [  128/  265]
train() client id: f_00001-7-4 loss: 0.337044  [  160/  265]
train() client id: f_00001-7-5 loss: 0.455788  [  192/  265]
train() client id: f_00001-7-6 loss: 0.370097  [  224/  265]
train() client id: f_00001-7-7 loss: 0.397517  [  256/  265]
train() client id: f_00001-8-0 loss: 0.418918  [   32/  265]
train() client id: f_00001-8-1 loss: 0.326203  [   64/  265]
train() client id: f_00001-8-2 loss: 0.506035  [   96/  265]
train() client id: f_00001-8-3 loss: 0.400389  [  128/  265]
train() client id: f_00001-8-4 loss: 0.325960  [  160/  265]
train() client id: f_00001-8-5 loss: 0.393994  [  192/  265]
train() client id: f_00001-8-6 loss: 0.439988  [  224/  265]
train() client id: f_00001-8-7 loss: 0.397616  [  256/  265]
train() client id: f_00001-9-0 loss: 0.387129  [   32/  265]
train() client id: f_00001-9-1 loss: 0.423116  [   64/  265]
train() client id: f_00001-9-2 loss: 0.491018  [   96/  265]
train() client id: f_00001-9-3 loss: 0.408496  [  128/  265]
train() client id: f_00001-9-4 loss: 0.381531  [  160/  265]
train() client id: f_00001-9-5 loss: 0.400232  [  192/  265]
train() client id: f_00001-9-6 loss: 0.422219  [  224/  265]
train() client id: f_00001-9-7 loss: 0.353363  [  256/  265]
train() client id: f_00001-10-0 loss: 0.387893  [   32/  265]
train() client id: f_00001-10-1 loss: 0.450223  [   64/  265]
train() client id: f_00001-10-2 loss: 0.380287  [   96/  265]
train() client id: f_00001-10-3 loss: 0.322089  [  128/  265]
train() client id: f_00001-10-4 loss: 0.371534  [  160/  265]
train() client id: f_00001-10-5 loss: 0.480993  [  192/  265]
train() client id: f_00001-10-6 loss: 0.411177  [  224/  265]
train() client id: f_00001-10-7 loss: 0.368561  [  256/  265]
train() client id: f_00001-11-0 loss: 0.434325  [   32/  265]
train() client id: f_00001-11-1 loss: 0.535458  [   64/  265]
train() client id: f_00001-11-2 loss: 0.346082  [   96/  265]
train() client id: f_00001-11-3 loss: 0.309379  [  128/  265]
train() client id: f_00001-11-4 loss: 0.313069  [  160/  265]
train() client id: f_00001-11-5 loss: 0.391126  [  192/  265]
train() client id: f_00001-11-6 loss: 0.458895  [  224/  265]
train() client id: f_00001-11-7 loss: 0.447601  [  256/  265]
train() client id: f_00001-12-0 loss: 0.351185  [   32/  265]
train() client id: f_00001-12-1 loss: 0.403606  [   64/  265]
train() client id: f_00001-12-2 loss: 0.318956  [   96/  265]
train() client id: f_00001-12-3 loss: 0.365696  [  128/  265]
train() client id: f_00001-12-4 loss: 0.306804  [  160/  265]
train() client id: f_00001-12-5 loss: 0.443028  [  192/  265]
train() client id: f_00001-12-6 loss: 0.401342  [  224/  265]
train() client id: f_00001-12-7 loss: 0.568999  [  256/  265]
train() client id: f_00002-0-0 loss: 1.141121  [   32/  124]
train() client id: f_00002-0-1 loss: 1.087260  [   64/  124]
train() client id: f_00002-0-2 loss: 1.226542  [   96/  124]
train() client id: f_00002-1-0 loss: 1.050972  [   32/  124]
train() client id: f_00002-1-1 loss: 1.046168  [   64/  124]
train() client id: f_00002-1-2 loss: 1.277972  [   96/  124]
train() client id: f_00002-2-0 loss: 1.069219  [   32/  124]
train() client id: f_00002-2-1 loss: 1.050447  [   64/  124]
train() client id: f_00002-2-2 loss: 1.059711  [   96/  124]
train() client id: f_00002-3-0 loss: 1.087517  [   32/  124]
train() client id: f_00002-3-1 loss: 0.898472  [   64/  124]
train() client id: f_00002-3-2 loss: 1.140912  [   96/  124]
train() client id: f_00002-4-0 loss: 1.007429  [   32/  124]
train() client id: f_00002-4-1 loss: 1.036240  [   64/  124]
train() client id: f_00002-4-2 loss: 1.011963  [   96/  124]
train() client id: f_00002-5-0 loss: 0.851840  [   32/  124]
train() client id: f_00002-5-1 loss: 1.088338  [   64/  124]
train() client id: f_00002-5-2 loss: 0.998486  [   96/  124]
train() client id: f_00002-6-0 loss: 1.003983  [   32/  124]
train() client id: f_00002-6-1 loss: 1.090142  [   64/  124]
train() client id: f_00002-6-2 loss: 1.010260  [   96/  124]
train() client id: f_00002-7-0 loss: 1.028327  [   32/  124]
train() client id: f_00002-7-1 loss: 1.023633  [   64/  124]
train() client id: f_00002-7-2 loss: 0.940739  [   96/  124]
train() client id: f_00002-8-0 loss: 1.029179  [   32/  124]
train() client id: f_00002-8-1 loss: 0.885267  [   64/  124]
train() client id: f_00002-8-2 loss: 1.005159  [   96/  124]
train() client id: f_00002-9-0 loss: 1.038161  [   32/  124]
train() client id: f_00002-9-1 loss: 0.934760  [   64/  124]
train() client id: f_00002-9-2 loss: 0.950178  [   96/  124]
train() client id: f_00002-10-0 loss: 1.035326  [   32/  124]
train() client id: f_00002-10-1 loss: 0.921297  [   64/  124]
train() client id: f_00002-10-2 loss: 0.911427  [   96/  124]
train() client id: f_00002-11-0 loss: 0.804024  [   32/  124]
train() client id: f_00002-11-1 loss: 0.923088  [   64/  124]
train() client id: f_00002-11-2 loss: 1.049497  [   96/  124]
train() client id: f_00002-12-0 loss: 0.952119  [   32/  124]
train() client id: f_00002-12-1 loss: 1.018234  [   64/  124]
train() client id: f_00002-12-2 loss: 0.878283  [   96/  124]
train() client id: f_00003-0-0 loss: 0.713152  [   32/   43]
train() client id: f_00003-1-0 loss: 0.494619  [   32/   43]
train() client id: f_00003-2-0 loss: 0.641488  [   32/   43]
train() client id: f_00003-3-0 loss: 0.726010  [   32/   43]
train() client id: f_00003-4-0 loss: 0.511524  [   32/   43]
train() client id: f_00003-5-0 loss: 0.846291  [   32/   43]
train() client id: f_00003-6-0 loss: 0.738499  [   32/   43]
train() client id: f_00003-7-0 loss: 0.775990  [   32/   43]
train() client id: f_00003-8-0 loss: 0.697949  [   32/   43]
train() client id: f_00003-9-0 loss: 0.640099  [   32/   43]
train() client id: f_00003-10-0 loss: 0.727628  [   32/   43]
train() client id: f_00003-11-0 loss: 0.586393  [   32/   43]
train() client id: f_00003-12-0 loss: 0.705393  [   32/   43]
train() client id: f_00004-0-0 loss: 1.082421  [   32/  306]
train() client id: f_00004-0-1 loss: 1.019005  [   64/  306]
train() client id: f_00004-0-2 loss: 0.896516  [   96/  306]
train() client id: f_00004-0-3 loss: 1.000386  [  128/  306]
train() client id: f_00004-0-4 loss: 0.916403  [  160/  306]
train() client id: f_00004-0-5 loss: 1.100402  [  192/  306]
train() client id: f_00004-0-6 loss: 1.055948  [  224/  306]
train() client id: f_00004-0-7 loss: 0.959667  [  256/  306]
train() client id: f_00004-0-8 loss: 0.855336  [  288/  306]
train() client id: f_00004-1-0 loss: 0.966358  [   32/  306]
train() client id: f_00004-1-1 loss: 0.997077  [   64/  306]
train() client id: f_00004-1-2 loss: 0.925267  [   96/  306]
train() client id: f_00004-1-3 loss: 0.965952  [  128/  306]
train() client id: f_00004-1-4 loss: 0.909129  [  160/  306]
train() client id: f_00004-1-5 loss: 0.933651  [  192/  306]
train() client id: f_00004-1-6 loss: 1.028223  [  224/  306]
train() client id: f_00004-1-7 loss: 0.922376  [  256/  306]
train() client id: f_00004-1-8 loss: 1.074968  [  288/  306]
train() client id: f_00004-2-0 loss: 1.001715  [   32/  306]
train() client id: f_00004-2-1 loss: 0.870995  [   64/  306]
train() client id: f_00004-2-2 loss: 0.963538  [   96/  306]
train() client id: f_00004-2-3 loss: 1.059158  [  128/  306]
train() client id: f_00004-2-4 loss: 0.964868  [  160/  306]
train() client id: f_00004-2-5 loss: 1.023782  [  192/  306]
train() client id: f_00004-2-6 loss: 1.052625  [  224/  306]
train() client id: f_00004-2-7 loss: 0.836279  [  256/  306]
train() client id: f_00004-2-8 loss: 0.965883  [  288/  306]
train() client id: f_00004-3-0 loss: 0.957520  [   32/  306]
train() client id: f_00004-3-1 loss: 0.885213  [   64/  306]
train() client id: f_00004-3-2 loss: 1.038213  [   96/  306]
train() client id: f_00004-3-3 loss: 0.921509  [  128/  306]
train() client id: f_00004-3-4 loss: 1.139175  [  160/  306]
train() client id: f_00004-3-5 loss: 0.930235  [  192/  306]
train() client id: f_00004-3-6 loss: 0.865713  [  224/  306]
train() client id: f_00004-3-7 loss: 0.885876  [  256/  306]
train() client id: f_00004-3-8 loss: 1.063801  [  288/  306]
train() client id: f_00004-4-0 loss: 1.110459  [   32/  306]
train() client id: f_00004-4-1 loss: 1.003638  [   64/  306]
train() client id: f_00004-4-2 loss: 0.918335  [   96/  306]
train() client id: f_00004-4-3 loss: 0.839266  [  128/  306]
train() client id: f_00004-4-4 loss: 0.925094  [  160/  306]
train() client id: f_00004-4-5 loss: 1.000065  [  192/  306]
train() client id: f_00004-4-6 loss: 0.891432  [  224/  306]
train() client id: f_00004-4-7 loss: 0.942012  [  256/  306]
train() client id: f_00004-4-8 loss: 1.103841  [  288/  306]
train() client id: f_00004-5-0 loss: 0.922210  [   32/  306]
train() client id: f_00004-5-1 loss: 1.040995  [   64/  306]
train() client id: f_00004-5-2 loss: 0.888605  [   96/  306]
train() client id: f_00004-5-3 loss: 1.030766  [  128/  306]
train() client id: f_00004-5-4 loss: 0.969948  [  160/  306]
train() client id: f_00004-5-5 loss: 0.943646  [  192/  306]
train() client id: f_00004-5-6 loss: 0.966080  [  224/  306]
train() client id: f_00004-5-7 loss: 0.952695  [  256/  306]
train() client id: f_00004-5-8 loss: 1.065788  [  288/  306]
train() client id: f_00004-6-0 loss: 0.890047  [   32/  306]
train() client id: f_00004-6-1 loss: 1.056059  [   64/  306]
train() client id: f_00004-6-2 loss: 0.992544  [   96/  306]
train() client id: f_00004-6-3 loss: 0.979205  [  128/  306]
train() client id: f_00004-6-4 loss: 0.928695  [  160/  306]
train() client id: f_00004-6-5 loss: 0.972226  [  192/  306]
train() client id: f_00004-6-6 loss: 1.002754  [  224/  306]
train() client id: f_00004-6-7 loss: 1.090328  [  256/  306]
train() client id: f_00004-6-8 loss: 0.846759  [  288/  306]
train() client id: f_00004-7-0 loss: 0.995086  [   32/  306]
train() client id: f_00004-7-1 loss: 1.031283  [   64/  306]
train() client id: f_00004-7-2 loss: 0.994933  [   96/  306]
train() client id: f_00004-7-3 loss: 0.959484  [  128/  306]
train() client id: f_00004-7-4 loss: 1.037721  [  160/  306]
train() client id: f_00004-7-5 loss: 0.843148  [  192/  306]
train() client id: f_00004-7-6 loss: 0.962012  [  224/  306]
train() client id: f_00004-7-7 loss: 0.896437  [  256/  306]
train() client id: f_00004-7-8 loss: 0.949897  [  288/  306]
train() client id: f_00004-8-0 loss: 0.922971  [   32/  306]
train() client id: f_00004-8-1 loss: 0.944944  [   64/  306]
train() client id: f_00004-8-2 loss: 1.022545  [   96/  306]
train() client id: f_00004-8-3 loss: 1.017743  [  128/  306]
train() client id: f_00004-8-4 loss: 0.952712  [  160/  306]
train() client id: f_00004-8-5 loss: 1.009090  [  192/  306]
train() client id: f_00004-8-6 loss: 0.830830  [  224/  306]
train() client id: f_00004-8-7 loss: 1.116837  [  256/  306]
train() client id: f_00004-8-8 loss: 0.874444  [  288/  306]
train() client id: f_00004-9-0 loss: 0.873507  [   32/  306]
train() client id: f_00004-9-1 loss: 0.975665  [   64/  306]
train() client id: f_00004-9-2 loss: 0.969890  [   96/  306]
train() client id: f_00004-9-3 loss: 1.040867  [  128/  306]
train() client id: f_00004-9-4 loss: 0.861190  [  160/  306]
train() client id: f_00004-9-5 loss: 0.913492  [  192/  306]
train() client id: f_00004-9-6 loss: 1.093900  [  224/  306]
train() client id: f_00004-9-7 loss: 1.039902  [  256/  306]
train() client id: f_00004-9-8 loss: 0.925480  [  288/  306]
train() client id: f_00004-10-0 loss: 0.986988  [   32/  306]
train() client id: f_00004-10-1 loss: 0.875178  [   64/  306]
train() client id: f_00004-10-2 loss: 0.985258  [   96/  306]
train() client id: f_00004-10-3 loss: 0.947325  [  128/  306]
train() client id: f_00004-10-4 loss: 1.010792  [  160/  306]
train() client id: f_00004-10-5 loss: 1.122947  [  192/  306]
train() client id: f_00004-10-6 loss: 0.899861  [  224/  306]
train() client id: f_00004-10-7 loss: 0.899342  [  256/  306]
train() client id: f_00004-10-8 loss: 1.025406  [  288/  306]
train() client id: f_00004-11-0 loss: 0.999580  [   32/  306]
train() client id: f_00004-11-1 loss: 0.880472  [   64/  306]
train() client id: f_00004-11-2 loss: 0.918029  [   96/  306]
train() client id: f_00004-11-3 loss: 1.039378  [  128/  306]
train() client id: f_00004-11-4 loss: 0.973584  [  160/  306]
train() client id: f_00004-11-5 loss: 1.005248  [  192/  306]
train() client id: f_00004-11-6 loss: 0.957309  [  224/  306]
train() client id: f_00004-11-7 loss: 0.925686  [  256/  306]
train() client id: f_00004-11-8 loss: 0.983585  [  288/  306]
train() client id: f_00004-12-0 loss: 0.879955  [   32/  306]
train() client id: f_00004-12-1 loss: 1.004857  [   64/  306]
train() client id: f_00004-12-2 loss: 0.858014  [   96/  306]
train() client id: f_00004-12-3 loss: 1.002713  [  128/  306]
train() client id: f_00004-12-4 loss: 1.067064  [  160/  306]
train() client id: f_00004-12-5 loss: 0.943866  [  192/  306]
train() client id: f_00004-12-6 loss: 1.092679  [  224/  306]
train() client id: f_00004-12-7 loss: 0.841966  [  256/  306]
train() client id: f_00004-12-8 loss: 0.935782  [  288/  306]
train() client id: f_00005-0-0 loss: 0.449778  [   32/  146]
train() client id: f_00005-0-1 loss: 0.445543  [   64/  146]
train() client id: f_00005-0-2 loss: 0.653887  [   96/  146]
train() client id: f_00005-0-3 loss: 0.540571  [  128/  146]
train() client id: f_00005-1-0 loss: 0.518956  [   32/  146]
train() client id: f_00005-1-1 loss: 0.689248  [   64/  146]
train() client id: f_00005-1-2 loss: 0.589033  [   96/  146]
train() client id: f_00005-1-3 loss: 0.517466  [  128/  146]
train() client id: f_00005-2-0 loss: 0.727917  [   32/  146]
train() client id: f_00005-2-1 loss: 0.640112  [   64/  146]
train() client id: f_00005-2-2 loss: 0.242118  [   96/  146]
train() client id: f_00005-2-3 loss: 0.507108  [  128/  146]
train() client id: f_00005-3-0 loss: 0.722197  [   32/  146]
train() client id: f_00005-3-1 loss: 0.386392  [   64/  146]
train() client id: f_00005-3-2 loss: 0.371975  [   96/  146]
train() client id: f_00005-3-3 loss: 0.535616  [  128/  146]
train() client id: f_00005-4-0 loss: 0.426770  [   32/  146]
train() client id: f_00005-4-1 loss: 0.692529  [   64/  146]
train() client id: f_00005-4-2 loss: 0.384247  [   96/  146]
train() client id: f_00005-4-3 loss: 0.391063  [  128/  146]
train() client id: f_00005-5-0 loss: 0.532822  [   32/  146]
train() client id: f_00005-5-1 loss: 0.351988  [   64/  146]
train() client id: f_00005-5-2 loss: 0.646297  [   96/  146]
train() client id: f_00005-5-3 loss: 0.388157  [  128/  146]
train() client id: f_00005-6-0 loss: 0.401721  [   32/  146]
train() client id: f_00005-6-1 loss: 0.536340  [   64/  146]
train() client id: f_00005-6-2 loss: 0.393393  [   96/  146]
train() client id: f_00005-6-3 loss: 0.823162  [  128/  146]
train() client id: f_00005-7-0 loss: 0.382196  [   32/  146]
train() client id: f_00005-7-1 loss: 0.717136  [   64/  146]
train() client id: f_00005-7-2 loss: 0.553061  [   96/  146]
train() client id: f_00005-7-3 loss: 0.489395  [  128/  146]
train() client id: f_00005-8-0 loss: 0.510844  [   32/  146]
train() client id: f_00005-8-1 loss: 0.307997  [   64/  146]
train() client id: f_00005-8-2 loss: 0.648735  [   96/  146]
train() client id: f_00005-8-3 loss: 0.498962  [  128/  146]
train() client id: f_00005-9-0 loss: 0.516547  [   32/  146]
train() client id: f_00005-9-1 loss: 0.501849  [   64/  146]
train() client id: f_00005-9-2 loss: 0.455521  [   96/  146]
train() client id: f_00005-9-3 loss: 0.531662  [  128/  146]
train() client id: f_00005-10-0 loss: 0.516150  [   32/  146]
train() client id: f_00005-10-1 loss: 0.262873  [   64/  146]
train() client id: f_00005-10-2 loss: 0.454685  [   96/  146]
train() client id: f_00005-10-3 loss: 0.560518  [  128/  146]
train() client id: f_00005-11-0 loss: 0.341630  [   32/  146]
train() client id: f_00005-11-1 loss: 0.431788  [   64/  146]
train() client id: f_00005-11-2 loss: 0.722417  [   96/  146]
train() client id: f_00005-11-3 loss: 0.675667  [  128/  146]
train() client id: f_00005-12-0 loss: 0.324841  [   32/  146]
train() client id: f_00005-12-1 loss: 0.872663  [   64/  146]
train() client id: f_00005-12-2 loss: 0.395562  [   96/  146]
train() client id: f_00005-12-3 loss: 0.464082  [  128/  146]
train() client id: f_00006-0-0 loss: 0.543936  [   32/   54]
train() client id: f_00006-1-0 loss: 0.600918  [   32/   54]
train() client id: f_00006-2-0 loss: 0.558378  [   32/   54]
train() client id: f_00006-3-0 loss: 0.565038  [   32/   54]
train() client id: f_00006-4-0 loss: 0.563467  [   32/   54]
train() client id: f_00006-5-0 loss: 0.571211  [   32/   54]
train() client id: f_00006-6-0 loss: 0.519422  [   32/   54]
train() client id: f_00006-7-0 loss: 0.608467  [   32/   54]
train() client id: f_00006-8-0 loss: 0.501318  [   32/   54]
train() client id: f_00006-9-0 loss: 0.567033  [   32/   54]
train() client id: f_00006-10-0 loss: 0.557995  [   32/   54]
train() client id: f_00006-11-0 loss: 0.567924  [   32/   54]
train() client id: f_00006-12-0 loss: 0.604530  [   32/   54]
train() client id: f_00007-0-0 loss: 0.632518  [   32/  179]
train() client id: f_00007-0-1 loss: 0.427521  [   64/  179]
train() client id: f_00007-0-2 loss: 0.504110  [   96/  179]
train() client id: f_00007-0-3 loss: 0.733030  [  128/  179]
train() client id: f_00007-0-4 loss: 0.636580  [  160/  179]
train() client id: f_00007-1-0 loss: 0.535108  [   32/  179]
train() client id: f_00007-1-1 loss: 0.523488  [   64/  179]
train() client id: f_00007-1-2 loss: 0.656582  [   96/  179]
train() client id: f_00007-1-3 loss: 0.435765  [  128/  179]
train() client id: f_00007-1-4 loss: 0.504737  [  160/  179]
train() client id: f_00007-2-0 loss: 0.375296  [   32/  179]
train() client id: f_00007-2-1 loss: 0.757457  [   64/  179]
train() client id: f_00007-2-2 loss: 0.539819  [   96/  179]
train() client id: f_00007-2-3 loss: 0.464275  [  128/  179]
train() client id: f_00007-2-4 loss: 0.513601  [  160/  179]
train() client id: f_00007-3-0 loss: 0.420647  [   32/  179]
train() client id: f_00007-3-1 loss: 0.634266  [   64/  179]
train() client id: f_00007-3-2 loss: 0.763899  [   96/  179]
train() client id: f_00007-3-3 loss: 0.408138  [  128/  179]
train() client id: f_00007-3-4 loss: 0.387272  [  160/  179]
train() client id: f_00007-4-0 loss: 0.560948  [   32/  179]
train() client id: f_00007-4-1 loss: 0.353995  [   64/  179]
train() client id: f_00007-4-2 loss: 0.496460  [   96/  179]
train() client id: f_00007-4-3 loss: 0.581763  [  128/  179]
train() client id: f_00007-4-4 loss: 0.410665  [  160/  179]
train() client id: f_00007-5-0 loss: 0.359369  [   32/  179]
train() client id: f_00007-5-1 loss: 0.361420  [   64/  179]
train() client id: f_00007-5-2 loss: 0.448182  [   96/  179]
train() client id: f_00007-5-3 loss: 0.539159  [  128/  179]
train() client id: f_00007-5-4 loss: 0.794740  [  160/  179]
train() client id: f_00007-6-0 loss: 0.454679  [   32/  179]
train() client id: f_00007-6-1 loss: 0.394163  [   64/  179]
train() client id: f_00007-6-2 loss: 0.522722  [   96/  179]
train() client id: f_00007-6-3 loss: 0.422894  [  128/  179]
train() client id: f_00007-6-4 loss: 0.582587  [  160/  179]
train() client id: f_00007-7-0 loss: 0.727737  [   32/  179]
train() client id: f_00007-7-1 loss: 0.367259  [   64/  179]
train() client id: f_00007-7-2 loss: 0.371561  [   96/  179]
train() client id: f_00007-7-3 loss: 0.328193  [  128/  179]
train() client id: f_00007-7-4 loss: 0.619097  [  160/  179]
train() client id: f_00007-8-0 loss: 0.356318  [   32/  179]
train() client id: f_00007-8-1 loss: 0.709190  [   64/  179]
train() client id: f_00007-8-2 loss: 0.449058  [   96/  179]
train() client id: f_00007-8-3 loss: 0.623212  [  128/  179]
train() client id: f_00007-8-4 loss: 0.445802  [  160/  179]
train() client id: f_00007-9-0 loss: 0.454474  [   32/  179]
train() client id: f_00007-9-1 loss: 0.462939  [   64/  179]
train() client id: f_00007-9-2 loss: 0.336709  [   96/  179]
train() client id: f_00007-9-3 loss: 0.334318  [  128/  179]
train() client id: f_00007-9-4 loss: 0.798335  [  160/  179]
train() client id: f_00007-10-0 loss: 0.565255  [   32/  179]
train() client id: f_00007-10-1 loss: 0.462280  [   64/  179]
train() client id: f_00007-10-2 loss: 0.517266  [   96/  179]
train() client id: f_00007-10-3 loss: 0.463603  [  128/  179]
train() client id: f_00007-10-4 loss: 0.538954  [  160/  179]
train() client id: f_00007-11-0 loss: 0.603090  [   32/  179]
train() client id: f_00007-11-1 loss: 0.494826  [   64/  179]
train() client id: f_00007-11-2 loss: 0.339990  [   96/  179]
train() client id: f_00007-11-3 loss: 0.371379  [  128/  179]
train() client id: f_00007-11-4 loss: 0.629170  [  160/  179]
train() client id: f_00007-12-0 loss: 0.521658  [   32/  179]
train() client id: f_00007-12-1 loss: 0.561656  [   64/  179]
train() client id: f_00007-12-2 loss: 0.446550  [   96/  179]
train() client id: f_00007-12-3 loss: 0.543913  [  128/  179]
train() client id: f_00007-12-4 loss: 0.440132  [  160/  179]
train() client id: f_00008-0-0 loss: 0.811576  [   32/  130]
train() client id: f_00008-0-1 loss: 0.855040  [   64/  130]
train() client id: f_00008-0-2 loss: 0.761476  [   96/  130]
train() client id: f_00008-0-3 loss: 0.797412  [  128/  130]
train() client id: f_00008-1-0 loss: 0.691901  [   32/  130]
train() client id: f_00008-1-1 loss: 0.877946  [   64/  130]
train() client id: f_00008-1-2 loss: 0.765259  [   96/  130]
train() client id: f_00008-1-3 loss: 0.909075  [  128/  130]
train() client id: f_00008-2-0 loss: 0.765672  [   32/  130]
train() client id: f_00008-2-1 loss: 0.818369  [   64/  130]
train() client id: f_00008-2-2 loss: 0.790088  [   96/  130]
train() client id: f_00008-2-3 loss: 0.873867  [  128/  130]
train() client id: f_00008-3-0 loss: 0.853066  [   32/  130]
train() client id: f_00008-3-1 loss: 0.722487  [   64/  130]
train() client id: f_00008-3-2 loss: 0.865648  [   96/  130]
train() client id: f_00008-3-3 loss: 0.805801  [  128/  130]
train() client id: f_00008-4-0 loss: 0.756453  [   32/  130]
train() client id: f_00008-4-1 loss: 0.835018  [   64/  130]
train() client id: f_00008-4-2 loss: 0.773476  [   96/  130]
train() client id: f_00008-4-3 loss: 0.822965  [  128/  130]
train() client id: f_00008-5-0 loss: 0.954786  [   32/  130]
train() client id: f_00008-5-1 loss: 0.795322  [   64/  130]
train() client id: f_00008-5-2 loss: 0.624409  [   96/  130]
train() client id: f_00008-5-3 loss: 0.867131  [  128/  130]
train() client id: f_00008-6-0 loss: 0.989193  [   32/  130]
train() client id: f_00008-6-1 loss: 0.703525  [   64/  130]
train() client id: f_00008-6-2 loss: 0.769007  [   96/  130]
train() client id: f_00008-6-3 loss: 0.779662  [  128/  130]
train() client id: f_00008-7-0 loss: 0.755080  [   32/  130]
train() client id: f_00008-7-1 loss: 0.871938  [   64/  130]
train() client id: f_00008-7-2 loss: 0.788264  [   96/  130]
train() client id: f_00008-7-3 loss: 0.825588  [  128/  130]
train() client id: f_00008-8-0 loss: 0.781724  [   32/  130]
train() client id: f_00008-8-1 loss: 0.843475  [   64/  130]
train() client id: f_00008-8-2 loss: 0.780668  [   96/  130]
train() client id: f_00008-8-3 loss: 0.813854  [  128/  130]
train() client id: f_00008-9-0 loss: 0.939909  [   32/  130]
train() client id: f_00008-9-1 loss: 0.771971  [   64/  130]
train() client id: f_00008-9-2 loss: 0.794830  [   96/  130]
train() client id: f_00008-9-3 loss: 0.700056  [  128/  130]
train() client id: f_00008-10-0 loss: 0.804843  [   32/  130]
train() client id: f_00008-10-1 loss: 0.808510  [   64/  130]
train() client id: f_00008-10-2 loss: 0.892860  [   96/  130]
train() client id: f_00008-10-3 loss: 0.724100  [  128/  130]
train() client id: f_00008-11-0 loss: 0.816874  [   32/  130]
train() client id: f_00008-11-1 loss: 0.745499  [   64/  130]
train() client id: f_00008-11-2 loss: 0.797937  [   96/  130]
train() client id: f_00008-11-3 loss: 0.859106  [  128/  130]
train() client id: f_00008-12-0 loss: 0.818420  [   32/  130]
train() client id: f_00008-12-1 loss: 0.749261  [   64/  130]
train() client id: f_00008-12-2 loss: 0.811167  [   96/  130]
train() client id: f_00008-12-3 loss: 0.834852  [  128/  130]
train() client id: f_00009-0-0 loss: 1.197207  [   32/  118]
train() client id: f_00009-0-1 loss: 1.177633  [   64/  118]
train() client id: f_00009-0-2 loss: 1.122199  [   96/  118]
train() client id: f_00009-1-0 loss: 1.101726  [   32/  118]
train() client id: f_00009-1-1 loss: 1.060742  [   64/  118]
train() client id: f_00009-1-2 loss: 1.232500  [   96/  118]
train() client id: f_00009-2-0 loss: 1.086630  [   32/  118]
train() client id: f_00009-2-1 loss: 0.991472  [   64/  118]
train() client id: f_00009-2-2 loss: 1.091872  [   96/  118]
train() client id: f_00009-3-0 loss: 1.107377  [   32/  118]
train() client id: f_00009-3-1 loss: 0.991646  [   64/  118]
train() client id: f_00009-3-2 loss: 0.918099  [   96/  118]
train() client id: f_00009-4-0 loss: 1.051051  [   32/  118]
train() client id: f_00009-4-1 loss: 0.880377  [   64/  118]
train() client id: f_00009-4-2 loss: 1.006414  [   96/  118]
train() client id: f_00009-5-0 loss: 0.956309  [   32/  118]
train() client id: f_00009-5-1 loss: 0.955866  [   64/  118]
train() client id: f_00009-5-2 loss: 0.959762  [   96/  118]
train() client id: f_00009-6-0 loss: 0.824217  [   32/  118]
train() client id: f_00009-6-1 loss: 0.974982  [   64/  118]
train() client id: f_00009-6-2 loss: 0.982628  [   96/  118]
train() client id: f_00009-7-0 loss: 0.856274  [   32/  118]
train() client id: f_00009-7-1 loss: 0.812037  [   64/  118]
train() client id: f_00009-7-2 loss: 1.000416  [   96/  118]
train() client id: f_00009-8-0 loss: 0.913840  [   32/  118]
train() client id: f_00009-8-1 loss: 0.861451  [   64/  118]
train() client id: f_00009-8-2 loss: 0.913325  [   96/  118]
train() client id: f_00009-9-0 loss: 0.820705  [   32/  118]
train() client id: f_00009-9-1 loss: 0.953463  [   64/  118]
train() client id: f_00009-9-2 loss: 0.912490  [   96/  118]
train() client id: f_00009-10-0 loss: 0.772336  [   32/  118]
train() client id: f_00009-10-1 loss: 0.902730  [   64/  118]
train() client id: f_00009-10-2 loss: 0.863519  [   96/  118]
train() client id: f_00009-11-0 loss: 0.834304  [   32/  118]
train() client id: f_00009-11-1 loss: 0.951894  [   64/  118]
train() client id: f_00009-11-2 loss: 0.789816  [   96/  118]
train() client id: f_00009-12-0 loss: 0.954387  [   32/  118]
train() client id: f_00009-12-1 loss: 0.830902  [   64/  118]
train() client id: f_00009-12-2 loss: 0.776316  [   96/  118]
At round 23 accuracy: 0.636604774535809
At round 23 training accuracy: 0.5895372233400402
At round 23 training loss: 0.8422347776235322
gradient difference: 0.41631731390953064
train() client id: f_00000-0-0 loss: 0.937459  [   32/  126]
train() client id: f_00000-0-1 loss: 1.165215  [   64/  126]
train() client id: f_00000-0-2 loss: 1.147277  [   96/  126]
train() client id: f_00000-1-0 loss: 0.891059  [   32/  126]
train() client id: f_00000-1-1 loss: 1.025976  [   64/  126]
train() client id: f_00000-1-2 loss: 1.114578  [   96/  126]
train() client id: f_00000-2-0 loss: 1.090186  [   32/  126]
train() client id: f_00000-2-1 loss: 0.961063  [   64/  126]
train() client id: f_00000-2-2 loss: 0.778937  [   96/  126]
train() client id: f_00000-3-0 loss: 0.966241  [   32/  126]
train() client id: f_00000-3-1 loss: 0.869815  [   64/  126]
train() client id: f_00000-3-2 loss: 0.878133  [   96/  126]
train() client id: f_00000-4-0 loss: 0.942154  [   32/  126]
train() client id: f_00000-4-1 loss: 0.742360  [   64/  126]
train() client id: f_00000-4-2 loss: 0.878365  [   96/  126]
train() client id: f_00000-5-0 loss: 0.804635  [   32/  126]
train() client id: f_00000-5-1 loss: 0.835058  [   64/  126]
train() client id: f_00000-5-2 loss: 0.882752  [   96/  126]
train() client id: f_00000-6-0 loss: 0.688839  [   32/  126]
train() client id: f_00000-6-1 loss: 0.959747  [   64/  126]
train() client id: f_00000-6-2 loss: 0.873078  [   96/  126]
train() client id: f_00000-7-0 loss: 0.814667  [   32/  126]
train() client id: f_00000-7-1 loss: 0.724203  [   64/  126]
train() client id: f_00000-7-2 loss: 0.834289  [   96/  126]
train() client id: f_00000-8-0 loss: 0.892499  [   32/  126]
train() client id: f_00000-8-1 loss: 0.750353  [   64/  126]
train() client id: f_00000-8-2 loss: 0.599121  [   96/  126]
train() client id: f_00000-9-0 loss: 0.781524  [   32/  126]
train() client id: f_00000-9-1 loss: 0.843959  [   64/  126]
train() client id: f_00000-9-2 loss: 0.699920  [   96/  126]
train() client id: f_00000-10-0 loss: 0.756841  [   32/  126]
train() client id: f_00000-10-1 loss: 0.721365  [   64/  126]
train() client id: f_00000-10-2 loss: 0.862369  [   96/  126]
train() client id: f_00000-11-0 loss: 0.823396  [   32/  126]
train() client id: f_00000-11-1 loss: 0.834770  [   64/  126]
train() client id: f_00000-11-2 loss: 0.740829  [   96/  126]
train() client id: f_00000-12-0 loss: 0.695740  [   32/  126]
train() client id: f_00000-12-1 loss: 0.825467  [   64/  126]
train() client id: f_00000-12-2 loss: 0.724030  [   96/  126]
train() client id: f_00001-0-0 loss: 0.402706  [   32/  265]
train() client id: f_00001-0-1 loss: 0.481143  [   64/  265]
train() client id: f_00001-0-2 loss: 0.279795  [   96/  265]
train() client id: f_00001-0-3 loss: 0.413963  [  128/  265]
train() client id: f_00001-0-4 loss: 0.378598  [  160/  265]
train() client id: f_00001-0-5 loss: 0.276350  [  192/  265]
train() client id: f_00001-0-6 loss: 0.350995  [  224/  265]
train() client id: f_00001-0-7 loss: 0.273959  [  256/  265]
train() client id: f_00001-1-0 loss: 0.278231  [   32/  265]
train() client id: f_00001-1-1 loss: 0.393193  [   64/  265]
train() client id: f_00001-1-2 loss: 0.361771  [   96/  265]
train() client id: f_00001-1-3 loss: 0.346465  [  128/  265]
train() client id: f_00001-1-4 loss: 0.332571  [  160/  265]
train() client id: f_00001-1-5 loss: 0.351707  [  192/  265]
train() client id: f_00001-1-6 loss: 0.319219  [  224/  265]
train() client id: f_00001-1-7 loss: 0.331050  [  256/  265]
train() client id: f_00001-2-0 loss: 0.411217  [   32/  265]
train() client id: f_00001-2-1 loss: 0.328458  [   64/  265]
train() client id: f_00001-2-2 loss: 0.258883  [   96/  265]
train() client id: f_00001-2-3 loss: 0.321339  [  128/  265]
train() client id: f_00001-2-4 loss: 0.370882  [  160/  265]
train() client id: f_00001-2-5 loss: 0.352599  [  192/  265]
train() client id: f_00001-2-6 loss: 0.279944  [  224/  265]
train() client id: f_00001-2-7 loss: 0.290856  [  256/  265]
train() client id: f_00001-3-0 loss: 0.321326  [   32/  265]
train() client id: f_00001-3-1 loss: 0.252777  [   64/  265]
train() client id: f_00001-3-2 loss: 0.428744  [   96/  265]
train() client id: f_00001-3-3 loss: 0.382070  [  128/  265]
train() client id: f_00001-3-4 loss: 0.349424  [  160/  265]
train() client id: f_00001-3-5 loss: 0.351155  [  192/  265]
train() client id: f_00001-3-6 loss: 0.272815  [  224/  265]
train() client id: f_00001-3-7 loss: 0.257664  [  256/  265]
train() client id: f_00001-4-0 loss: 0.362377  [   32/  265]
train() client id: f_00001-4-1 loss: 0.305101  [   64/  265]
train() client id: f_00001-4-2 loss: 0.263266  [   96/  265]
train() client id: f_00001-4-3 loss: 0.302787  [  128/  265]
train() client id: f_00001-4-4 loss: 0.366176  [  160/  265]
train() client id: f_00001-4-5 loss: 0.334619  [  192/  265]
train() client id: f_00001-4-6 loss: 0.304485  [  224/  265]
train() client id: f_00001-4-7 loss: 0.364376  [  256/  265]
train() client id: f_00001-5-0 loss: 0.286268  [   32/  265]
train() client id: f_00001-5-1 loss: 0.353493  [   64/  265]
train() client id: f_00001-5-2 loss: 0.234020  [   96/  265]
train() client id: f_00001-5-3 loss: 0.426630  [  128/  265]
train() client id: f_00001-5-4 loss: 0.396082  [  160/  265]
train() client id: f_00001-5-5 loss: 0.293755  [  192/  265]
train() client id: f_00001-5-6 loss: 0.277729  [  224/  265]
train() client id: f_00001-5-7 loss: 0.286457  [  256/  265]
train() client id: f_00001-6-0 loss: 0.222895  [   32/  265]
train() client id: f_00001-6-1 loss: 0.243712  [   64/  265]
train() client id: f_00001-6-2 loss: 0.262688  [   96/  265]
train() client id: f_00001-6-3 loss: 0.283702  [  128/  265]
train() client id: f_00001-6-4 loss: 0.424059  [  160/  265]
train() client id: f_00001-6-5 loss: 0.367972  [  192/  265]
train() client id: f_00001-6-6 loss: 0.299231  [  224/  265]
train() client id: f_00001-6-7 loss: 0.424810  [  256/  265]
train() client id: f_00001-7-0 loss: 0.313666  [   32/  265]
train() client id: f_00001-7-1 loss: 0.312117  [   64/  265]
train() client id: f_00001-7-2 loss: 0.266531  [   96/  265]
train() client id: f_00001-7-3 loss: 0.308000  [  128/  265]
train() client id: f_00001-7-4 loss: 0.325758  [  160/  265]
train() client id: f_00001-7-5 loss: 0.282204  [  192/  265]
train() client id: f_00001-7-6 loss: 0.357312  [  224/  265]
train() client id: f_00001-7-7 loss: 0.339442  [  256/  265]
train() client id: f_00001-8-0 loss: 0.272102  [   32/  265]
train() client id: f_00001-8-1 loss: 0.293227  [   64/  265]
train() client id: f_00001-8-2 loss: 0.332090  [   96/  265]
train() client id: f_00001-8-3 loss: 0.245307  [  128/  265]
train() client id: f_00001-8-4 loss: 0.221290  [  160/  265]
train() client id: f_00001-8-5 loss: 0.266655  [  192/  265]
train() client id: f_00001-8-6 loss: 0.353641  [  224/  265]
train() client id: f_00001-8-7 loss: 0.515136  [  256/  265]
train() client id: f_00001-9-0 loss: 0.318241  [   32/  265]
train() client id: f_00001-9-1 loss: 0.283881  [   64/  265]
train() client id: f_00001-9-2 loss: 0.338129  [   96/  265]
train() client id: f_00001-9-3 loss: 0.252173  [  128/  265]
train() client id: f_00001-9-4 loss: 0.376971  [  160/  265]
train() client id: f_00001-9-5 loss: 0.294664  [  192/  265]
train() client id: f_00001-9-6 loss: 0.302231  [  224/  265]
train() client id: f_00001-9-7 loss: 0.234303  [  256/  265]
train() client id: f_00001-10-0 loss: 0.300228  [   32/  265]
train() client id: f_00001-10-1 loss: 0.286897  [   64/  265]
train() client id: f_00001-10-2 loss: 0.264155  [   96/  265]
train() client id: f_00001-10-3 loss: 0.309166  [  128/  265]
train() client id: f_00001-10-4 loss: 0.333457  [  160/  265]
train() client id: f_00001-10-5 loss: 0.332682  [  192/  265]
train() client id: f_00001-10-6 loss: 0.261698  [  224/  265]
train() client id: f_00001-10-7 loss: 0.239288  [  256/  265]
train() client id: f_00001-11-0 loss: 0.502335  [   32/  265]
train() client id: f_00001-11-1 loss: 0.262735  [   64/  265]
train() client id: f_00001-11-2 loss: 0.343536  [   96/  265]
train() client id: f_00001-11-3 loss: 0.283489  [  128/  265]
train() client id: f_00001-11-4 loss: 0.220303  [  160/  265]
train() client id: f_00001-11-5 loss: 0.209996  [  192/  265]
train() client id: f_00001-11-6 loss: 0.217741  [  224/  265]
train() client id: f_00001-11-7 loss: 0.320929  [  256/  265]
train() client id: f_00001-12-0 loss: 0.251170  [   32/  265]
train() client id: f_00001-12-1 loss: 0.317541  [   64/  265]
train() client id: f_00001-12-2 loss: 0.373428  [   96/  265]
train() client id: f_00001-12-3 loss: 0.231192  [  128/  265]
train() client id: f_00001-12-4 loss: 0.404696  [  160/  265]
train() client id: f_00001-12-5 loss: 0.433262  [  192/  265]
train() client id: f_00001-12-6 loss: 0.213403  [  224/  265]
train() client id: f_00001-12-7 loss: 0.211929  [  256/  265]
train() client id: f_00002-0-0 loss: 1.080145  [   32/  124]
train() client id: f_00002-0-1 loss: 1.236852  [   64/  124]
train() client id: f_00002-0-2 loss: 1.248405  [   96/  124]
train() client id: f_00002-1-0 loss: 1.177753  [   32/  124]
train() client id: f_00002-1-1 loss: 1.203442  [   64/  124]
train() client id: f_00002-1-2 loss: 1.274021  [   96/  124]
train() client id: f_00002-2-0 loss: 1.196470  [   32/  124]
train() client id: f_00002-2-1 loss: 1.067889  [   64/  124]
train() client id: f_00002-2-2 loss: 1.228022  [   96/  124]
train() client id: f_00002-3-0 loss: 1.155236  [   32/  124]
train() client id: f_00002-3-1 loss: 1.143123  [   64/  124]
train() client id: f_00002-3-2 loss: 1.170108  [   96/  124]
train() client id: f_00002-4-0 loss: 1.140248  [   32/  124]
train() client id: f_00002-4-1 loss: 1.105839  [   64/  124]
train() client id: f_00002-4-2 loss: 1.086854  [   96/  124]
train() client id: f_00002-5-0 loss: 1.244878  [   32/  124]
train() client id: f_00002-5-1 loss: 1.093270  [   64/  124]
train() client id: f_00002-5-2 loss: 1.031882  [   96/  124]
train() client id: f_00002-6-0 loss: 1.055471  [   32/  124]
train() client id: f_00002-6-1 loss: 1.118033  [   64/  124]
train() client id: f_00002-6-2 loss: 1.037846  [   96/  124]
train() client id: f_00002-7-0 loss: 0.993575  [   32/  124]
train() client id: f_00002-7-1 loss: 1.027525  [   64/  124]
train() client id: f_00002-7-2 loss: 1.079015  [   96/  124]
train() client id: f_00002-8-0 loss: 1.005341  [   32/  124]
train() client id: f_00002-8-1 loss: 1.033080  [   64/  124]
train() client id: f_00002-8-2 loss: 1.073258  [   96/  124]
train() client id: f_00002-9-0 loss: 1.006878  [   32/  124]
train() client id: f_00002-9-1 loss: 1.047411  [   64/  124]
train() client id: f_00002-9-2 loss: 1.225512  [   96/  124]
train() client id: f_00002-10-0 loss: 1.119654  [   32/  124]
train() client id: f_00002-10-1 loss: 1.041960  [   64/  124]
train() client id: f_00002-10-2 loss: 1.012869  [   96/  124]
train() client id: f_00002-11-0 loss: 1.160342  [   32/  124]
train() client id: f_00002-11-1 loss: 1.130293  [   64/  124]
train() client id: f_00002-11-2 loss: 1.032923  [   96/  124]
train() client id: f_00002-12-0 loss: 1.129721  [   32/  124]
train() client id: f_00002-12-1 loss: 1.003711  [   64/  124]
train() client id: f_00002-12-2 loss: 0.978673  [   96/  124]
train() client id: f_00003-0-0 loss: 0.719318  [   32/   43]
train() client id: f_00003-1-0 loss: 0.628169  [   32/   43]
train() client id: f_00003-2-0 loss: 0.627684  [   32/   43]
train() client id: f_00003-3-0 loss: 0.776287  [   32/   43]
train() client id: f_00003-4-0 loss: 0.635103  [   32/   43]
train() client id: f_00003-5-0 loss: 0.641286  [   32/   43]
train() client id: f_00003-6-0 loss: 0.907176  [   32/   43]
train() client id: f_00003-7-0 loss: 0.599968  [   32/   43]
train() client id: f_00003-8-0 loss: 0.591673  [   32/   43]
train() client id: f_00003-9-0 loss: 0.712496  [   32/   43]
train() client id: f_00003-10-0 loss: 0.673043  [   32/   43]
train() client id: f_00003-11-0 loss: 0.806299  [   32/   43]
train() client id: f_00003-12-0 loss: 0.686202  [   32/   43]
train() client id: f_00004-0-0 loss: 0.943378  [   32/  306]
train() client id: f_00004-0-1 loss: 0.907281  [   64/  306]
train() client id: f_00004-0-2 loss: 0.885079  [   96/  306]
train() client id: f_00004-0-3 loss: 0.806180  [  128/  306]
train() client id: f_00004-0-4 loss: 0.744196  [  160/  306]
train() client id: f_00004-0-5 loss: 0.889389  [  192/  306]
train() client id: f_00004-0-6 loss: 0.774490  [  224/  306]
train() client id: f_00004-0-7 loss: 0.674245  [  256/  306]
train() client id: f_00004-0-8 loss: 0.763249  [  288/  306]
train() client id: f_00004-1-0 loss: 0.879325  [   32/  306]
train() client id: f_00004-1-1 loss: 0.813576  [   64/  306]
train() client id: f_00004-1-2 loss: 0.777846  [   96/  306]
train() client id: f_00004-1-3 loss: 0.943438  [  128/  306]
train() client id: f_00004-1-4 loss: 0.747251  [  160/  306]
train() client id: f_00004-1-5 loss: 0.797579  [  192/  306]
train() client id: f_00004-1-6 loss: 0.822560  [  224/  306]
train() client id: f_00004-1-7 loss: 0.821245  [  256/  306]
train() client id: f_00004-1-8 loss: 0.855736  [  288/  306]
train() client id: f_00004-2-0 loss: 0.828938  [   32/  306]
train() client id: f_00004-2-1 loss: 0.911815  [   64/  306]
train() client id: f_00004-2-2 loss: 0.703033  [   96/  306]
train() client id: f_00004-2-3 loss: 0.921236  [  128/  306]
train() client id: f_00004-2-4 loss: 0.918940  [  160/  306]
train() client id: f_00004-2-5 loss: 0.650719  [  192/  306]
train() client id: f_00004-2-6 loss: 0.907238  [  224/  306]
train() client id: f_00004-2-7 loss: 0.831879  [  256/  306]
train() client id: f_00004-2-8 loss: 0.852688  [  288/  306]
train() client id: f_00004-3-0 loss: 0.890238  [   32/  306]
train() client id: f_00004-3-1 loss: 0.821235  [   64/  306]
train() client id: f_00004-3-2 loss: 0.725223  [   96/  306]
train() client id: f_00004-3-3 loss: 0.941779  [  128/  306]
train() client id: f_00004-3-4 loss: 0.784667  [  160/  306]
train() client id: f_00004-3-5 loss: 0.845681  [  192/  306]
train() client id: f_00004-3-6 loss: 0.869209  [  224/  306]
train() client id: f_00004-3-7 loss: 0.760780  [  256/  306]
train() client id: f_00004-3-8 loss: 0.864200  [  288/  306]
train() client id: f_00004-4-0 loss: 0.895138  [   32/  306]
train() client id: f_00004-4-1 loss: 0.800930  [   64/  306]
train() client id: f_00004-4-2 loss: 0.791834  [   96/  306]
train() client id: f_00004-4-3 loss: 0.898060  [  128/  306]
train() client id: f_00004-4-4 loss: 0.833784  [  160/  306]
train() client id: f_00004-4-5 loss: 0.690483  [  192/  306]
train() client id: f_00004-4-6 loss: 0.911712  [  224/  306]
train() client id: f_00004-4-7 loss: 0.841004  [  256/  306]
train() client id: f_00004-4-8 loss: 0.818254  [  288/  306]
train() client id: f_00004-5-0 loss: 0.835154  [   32/  306]
train() client id: f_00004-5-1 loss: 0.840202  [   64/  306]
train() client id: f_00004-5-2 loss: 0.935031  [   96/  306]
train() client id: f_00004-5-3 loss: 0.880787  [  128/  306]
train() client id: f_00004-5-4 loss: 0.779956  [  160/  306]
train() client id: f_00004-5-5 loss: 0.827314  [  192/  306]
train() client id: f_00004-5-6 loss: 0.799842  [  224/  306]
train() client id: f_00004-5-7 loss: 0.716730  [  256/  306]
train() client id: f_00004-5-8 loss: 0.910815  [  288/  306]
train() client id: f_00004-6-0 loss: 0.807706  [   32/  306]
train() client id: f_00004-6-1 loss: 0.720308  [   64/  306]
train() client id: f_00004-6-2 loss: 0.790887  [   96/  306]
train() client id: f_00004-6-3 loss: 0.874624  [  128/  306]
train() client id: f_00004-6-4 loss: 0.917841  [  160/  306]
train() client id: f_00004-6-5 loss: 0.815685  [  192/  306]
train() client id: f_00004-6-6 loss: 0.852298  [  224/  306]
train() client id: f_00004-6-7 loss: 0.819526  [  256/  306]
train() client id: f_00004-6-8 loss: 0.880276  [  288/  306]
train() client id: f_00004-7-0 loss: 0.740071  [   32/  306]
train() client id: f_00004-7-1 loss: 0.859023  [   64/  306]
train() client id: f_00004-7-2 loss: 0.817706  [   96/  306]
train() client id: f_00004-7-3 loss: 0.770457  [  128/  306]
train() client id: f_00004-7-4 loss: 0.810157  [  160/  306]
train() client id: f_00004-7-5 loss: 0.939104  [  192/  306]
train() client id: f_00004-7-6 loss: 0.811767  [  224/  306]
train() client id: f_00004-7-7 loss: 0.947413  [  256/  306]
train() client id: f_00004-7-8 loss: 0.808715  [  288/  306]
train() client id: f_00004-8-0 loss: 0.775413  [   32/  306]
train() client id: f_00004-8-1 loss: 0.874533  [   64/  306]
train() client id: f_00004-8-2 loss: 0.897169  [   96/  306]
train() client id: f_00004-8-3 loss: 0.833995  [  128/  306]
train() client id: f_00004-8-4 loss: 0.768513  [  160/  306]
train() client id: f_00004-8-5 loss: 0.858933  [  192/  306]
train() client id: f_00004-8-6 loss: 0.849583  [  224/  306]
train() client id: f_00004-8-7 loss: 0.939503  [  256/  306]
train() client id: f_00004-8-8 loss: 0.709380  [  288/  306]
train() client id: f_00004-9-0 loss: 0.683908  [   32/  306]
train() client id: f_00004-9-1 loss: 0.919107  [   64/  306]
train() client id: f_00004-9-2 loss: 0.966538  [   96/  306]
train() client id: f_00004-9-3 loss: 0.838965  [  128/  306]
train() client id: f_00004-9-4 loss: 0.892144  [  160/  306]
train() client id: f_00004-9-5 loss: 0.742313  [  192/  306]
train() client id: f_00004-9-6 loss: 0.898466  [  224/  306]
train() client id: f_00004-9-7 loss: 0.688724  [  256/  306]
train() client id: f_00004-9-8 loss: 0.899650  [  288/  306]
train() client id: f_00004-10-0 loss: 0.844501  [   32/  306]
train() client id: f_00004-10-1 loss: 0.785534  [   64/  306]
train() client id: f_00004-10-2 loss: 0.845396  [   96/  306]
train() client id: f_00004-10-3 loss: 0.883225  [  128/  306]
train() client id: f_00004-10-4 loss: 0.911065  [  160/  306]
train() client id: f_00004-10-5 loss: 0.781533  [  192/  306]
train() client id: f_00004-10-6 loss: 0.774656  [  224/  306]
train() client id: f_00004-10-7 loss: 0.979274  [  256/  306]
train() client id: f_00004-10-8 loss: 0.802100  [  288/  306]
train() client id: f_00004-11-0 loss: 0.819016  [   32/  306]
train() client id: f_00004-11-1 loss: 0.742363  [   64/  306]
train() client id: f_00004-11-2 loss: 0.968399  [   96/  306]
train() client id: f_00004-11-3 loss: 0.837935  [  128/  306]
train() client id: f_00004-11-4 loss: 0.940807  [  160/  306]
train() client id: f_00004-11-5 loss: 0.761973  [  192/  306]
train() client id: f_00004-11-6 loss: 0.822812  [  224/  306]
train() client id: f_00004-11-7 loss: 0.825933  [  256/  306]
train() client id: f_00004-11-8 loss: 0.840214  [  288/  306]
train() client id: f_00004-12-0 loss: 0.760863  [   32/  306]
train() client id: f_00004-12-1 loss: 0.716576  [   64/  306]
train() client id: f_00004-12-2 loss: 0.866825  [   96/  306]
train() client id: f_00004-12-3 loss: 0.818459  [  128/  306]
train() client id: f_00004-12-4 loss: 0.794742  [  160/  306]
train() client id: f_00004-12-5 loss: 0.937589  [  192/  306]
train() client id: f_00004-12-6 loss: 0.800120  [  224/  306]
train() client id: f_00004-12-7 loss: 0.926167  [  256/  306]
train() client id: f_00004-12-8 loss: 0.859263  [  288/  306]
train() client id: f_00005-0-0 loss: 0.708913  [   32/  146]
train() client id: f_00005-0-1 loss: 0.767140  [   64/  146]
train() client id: f_00005-0-2 loss: 0.689202  [   96/  146]
train() client id: f_00005-0-3 loss: 0.594376  [  128/  146]
train() client id: f_00005-1-0 loss: 0.797460  [   32/  146]
train() client id: f_00005-1-1 loss: 0.850437  [   64/  146]
train() client id: f_00005-1-2 loss: 0.688751  [   96/  146]
train() client id: f_00005-1-3 loss: 0.454022  [  128/  146]
train() client id: f_00005-2-0 loss: 0.616227  [   32/  146]
train() client id: f_00005-2-1 loss: 0.662177  [   64/  146]
train() client id: f_00005-2-2 loss: 0.944742  [   96/  146]
train() client id: f_00005-2-3 loss: 0.519806  [  128/  146]
train() client id: f_00005-3-0 loss: 0.633304  [   32/  146]
train() client id: f_00005-3-1 loss: 0.524010  [   64/  146]
train() client id: f_00005-3-2 loss: 0.620800  [   96/  146]
train() client id: f_00005-3-3 loss: 0.957661  [  128/  146]
train() client id: f_00005-4-0 loss: 0.681415  [   32/  146]
train() client id: f_00005-4-1 loss: 0.769815  [   64/  146]
train() client id: f_00005-4-2 loss: 0.699473  [   96/  146]
train() client id: f_00005-4-3 loss: 0.577310  [  128/  146]
train() client id: f_00005-5-0 loss: 0.632635  [   32/  146]
train() client id: f_00005-5-1 loss: 0.684735  [   64/  146]
train() client id: f_00005-5-2 loss: 0.539197  [   96/  146]
train() client id: f_00005-5-3 loss: 0.617139  [  128/  146]
train() client id: f_00005-6-0 loss: 0.589195  [   32/  146]
train() client id: f_00005-6-1 loss: 0.822664  [   64/  146]
train() client id: f_00005-6-2 loss: 0.767527  [   96/  146]
train() client id: f_00005-6-3 loss: 0.697464  [  128/  146]
train() client id: f_00005-7-0 loss: 0.670288  [   32/  146]
train() client id: f_00005-7-1 loss: 0.683721  [   64/  146]
train() client id: f_00005-7-2 loss: 0.657349  [   96/  146]
train() client id: f_00005-7-3 loss: 0.703157  [  128/  146]
train() client id: f_00005-8-0 loss: 0.689186  [   32/  146]
train() client id: f_00005-8-1 loss: 0.802781  [   64/  146]
train() client id: f_00005-8-2 loss: 0.528086  [   96/  146]
train() client id: f_00005-8-3 loss: 0.587454  [  128/  146]
train() client id: f_00005-9-0 loss: 0.461568  [   32/  146]
train() client id: f_00005-9-1 loss: 0.953904  [   64/  146]
train() client id: f_00005-9-2 loss: 0.736334  [   96/  146]
train() client id: f_00005-9-3 loss: 0.664593  [  128/  146]
train() client id: f_00005-10-0 loss: 0.679444  [   32/  146]
train() client id: f_00005-10-1 loss: 0.695998  [   64/  146]
train() client id: f_00005-10-2 loss: 0.689648  [   96/  146]
train() client id: f_00005-10-3 loss: 0.583876  [  128/  146]
train() client id: f_00005-11-0 loss: 1.114212  [   32/  146]
train() client id: f_00005-11-1 loss: 0.590078  [   64/  146]
train() client id: f_00005-11-2 loss: 0.377284  [   96/  146]
train() client id: f_00005-11-3 loss: 0.676287  [  128/  146]
train() client id: f_00005-12-0 loss: 0.630899  [   32/  146]
train() client id: f_00005-12-1 loss: 0.649463  [   64/  146]
train() client id: f_00005-12-2 loss: 0.669243  [   96/  146]
train() client id: f_00005-12-3 loss: 0.874888  [  128/  146]
train() client id: f_00006-0-0 loss: 0.511943  [   32/   54]
train() client id: f_00006-1-0 loss: 0.469212  [   32/   54]
train() client id: f_00006-2-0 loss: 0.470978  [   32/   54]
train() client id: f_00006-3-0 loss: 0.536080  [   32/   54]
train() client id: f_00006-4-0 loss: 0.536899  [   32/   54]
train() client id: f_00006-5-0 loss: 0.480693  [   32/   54]
train() client id: f_00006-6-0 loss: 0.486980  [   32/   54]
train() client id: f_00006-7-0 loss: 0.495121  [   32/   54]
train() client id: f_00006-8-0 loss: 0.554006  [   32/   54]
train() client id: f_00006-9-0 loss: 0.458999  [   32/   54]
train() client id: f_00006-10-0 loss: 0.492500  [   32/   54]
train() client id: f_00006-11-0 loss: 0.454354  [   32/   54]
train() client id: f_00006-12-0 loss: 0.504905  [   32/   54]
train() client id: f_00007-0-0 loss: 0.713722  [   32/  179]
train() client id: f_00007-0-1 loss: 0.659586  [   64/  179]
train() client id: f_00007-0-2 loss: 0.748507  [   96/  179]
train() client id: f_00007-0-3 loss: 0.612217  [  128/  179]
train() client id: f_00007-0-4 loss: 0.524531  [  160/  179]
train() client id: f_00007-1-0 loss: 0.597507  [   32/  179]
train() client id: f_00007-1-1 loss: 0.605107  [   64/  179]
train() client id: f_00007-1-2 loss: 0.559870  [   96/  179]
train() client id: f_00007-1-3 loss: 0.595716  [  128/  179]
train() client id: f_00007-1-4 loss: 0.743405  [  160/  179]
train() client id: f_00007-2-0 loss: 0.636518  [   32/  179]
train() client id: f_00007-2-1 loss: 0.613764  [   64/  179]
train() client id: f_00007-2-2 loss: 0.579291  [   96/  179]
train() client id: f_00007-2-3 loss: 0.782767  [  128/  179]
train() client id: f_00007-2-4 loss: 0.512763  [  160/  179]
train() client id: f_00007-3-0 loss: 0.538757  [   32/  179]
train() client id: f_00007-3-1 loss: 0.541021  [   64/  179]
train() client id: f_00007-3-2 loss: 0.644695  [   96/  179]
train() client id: f_00007-3-3 loss: 0.580686  [  128/  179]
train() client id: f_00007-3-4 loss: 0.742803  [  160/  179]
train() client id: f_00007-4-0 loss: 0.731756  [   32/  179]
train() client id: f_00007-4-1 loss: 0.526306  [   64/  179]
train() client id: f_00007-4-2 loss: 0.521444  [   96/  179]
train() client id: f_00007-4-3 loss: 0.636616  [  128/  179]
train() client id: f_00007-4-4 loss: 0.476187  [  160/  179]
train() client id: f_00007-5-0 loss: 0.488510  [   32/  179]
train() client id: f_00007-5-1 loss: 0.496762  [   64/  179]
train() client id: f_00007-5-2 loss: 0.709285  [   96/  179]
train() client id: f_00007-5-3 loss: 0.828971  [  128/  179]
train() client id: f_00007-5-4 loss: 0.434024  [  160/  179]
train() client id: f_00007-6-0 loss: 0.487240  [   32/  179]
train() client id: f_00007-6-1 loss: 0.723413  [   64/  179]
train() client id: f_00007-6-2 loss: 0.683656  [   96/  179]
train() client id: f_00007-6-3 loss: 0.718739  [  128/  179]
train() client id: f_00007-6-4 loss: 0.441597  [  160/  179]
train() client id: f_00007-7-0 loss: 0.536562  [   32/  179]
train() client id: f_00007-7-1 loss: 0.453241  [   64/  179]
train() client id: f_00007-7-2 loss: 0.512859  [   96/  179]
train() client id: f_00007-7-3 loss: 0.609577  [  128/  179]
train() client id: f_00007-7-4 loss: 0.711057  [  160/  179]
train() client id: f_00007-8-0 loss: 0.553851  [   32/  179]
train() client id: f_00007-8-1 loss: 0.437286  [   64/  179]
train() client id: f_00007-8-2 loss: 0.879659  [   96/  179]
train() client id: f_00007-8-3 loss: 0.707962  [  128/  179]
train() client id: f_00007-8-4 loss: 0.414153  [  160/  179]
train() client id: f_00007-9-0 loss: 0.614321  [   32/  179]
train() client id: f_00007-9-1 loss: 0.554984  [   64/  179]
train() client id: f_00007-9-2 loss: 0.823231  [   96/  179]
train() client id: f_00007-9-3 loss: 0.521252  [  128/  179]
train() client id: f_00007-9-4 loss: 0.405946  [  160/  179]
train() client id: f_00007-10-0 loss: 0.550742  [   32/  179]
train() client id: f_00007-10-1 loss: 0.644094  [   64/  179]
train() client id: f_00007-10-2 loss: 0.621857  [   96/  179]
train() client id: f_00007-10-3 loss: 0.628435  [  128/  179]
train() client id: f_00007-10-4 loss: 0.527865  [  160/  179]
train() client id: f_00007-11-0 loss: 0.593954  [   32/  179]
train() client id: f_00007-11-1 loss: 0.765066  [   64/  179]
train() client id: f_00007-11-2 loss: 0.501274  [   96/  179]
train() client id: f_00007-11-3 loss: 0.524929  [  128/  179]
train() client id: f_00007-11-4 loss: 0.580743  [  160/  179]
train() client id: f_00007-12-0 loss: 0.447386  [   32/  179]
train() client id: f_00007-12-1 loss: 0.627403  [   64/  179]
train() client id: f_00007-12-2 loss: 0.689716  [   96/  179]
train() client id: f_00007-12-3 loss: 0.659947  [  128/  179]
train() client id: f_00007-12-4 loss: 0.451214  [  160/  179]
train() client id: f_00008-0-0 loss: 0.592111  [   32/  130]
train() client id: f_00008-0-1 loss: 0.759819  [   64/  130]
train() client id: f_00008-0-2 loss: 0.808930  [   96/  130]
train() client id: f_00008-0-3 loss: 0.698536  [  128/  130]
train() client id: f_00008-1-0 loss: 0.807680  [   32/  130]
train() client id: f_00008-1-1 loss: 0.706509  [   64/  130]
train() client id: f_00008-1-2 loss: 0.629135  [   96/  130]
train() client id: f_00008-1-3 loss: 0.706454  [  128/  130]
train() client id: f_00008-2-0 loss: 0.718446  [   32/  130]
train() client id: f_00008-2-1 loss: 0.685543  [   64/  130]
train() client id: f_00008-2-2 loss: 0.719181  [   96/  130]
train() client id: f_00008-2-3 loss: 0.732182  [  128/  130]
train() client id: f_00008-3-0 loss: 0.621130  [   32/  130]
train() client id: f_00008-3-1 loss: 0.805564  [   64/  130]
train() client id: f_00008-3-2 loss: 0.742811  [   96/  130]
train() client id: f_00008-3-3 loss: 0.672073  [  128/  130]
train() client id: f_00008-4-0 loss: 0.699583  [   32/  130]
train() client id: f_00008-4-1 loss: 0.721667  [   64/  130]
train() client id: f_00008-4-2 loss: 0.798949  [   96/  130]
train() client id: f_00008-4-3 loss: 0.619526  [  128/  130]
train() client id: f_00008-5-0 loss: 0.698835  [   32/  130]
train() client id: f_00008-5-1 loss: 0.683816  [   64/  130]
train() client id: f_00008-5-2 loss: 0.657530  [   96/  130]
train() client id: f_00008-5-3 loss: 0.807898  [  128/  130]
train() client id: f_00008-6-0 loss: 0.646013  [   32/  130]
train() client id: f_00008-6-1 loss: 0.611573  [   64/  130]
train() client id: f_00008-6-2 loss: 0.764360  [   96/  130]
train() client id: f_00008-6-3 loss: 0.798168  [  128/  130]
train() client id: f_00008-7-0 loss: 0.773671  [   32/  130]
train() client id: f_00008-7-1 loss: 0.765180  [   64/  130]
train() client id: f_00008-7-2 loss: 0.666856  [   96/  130]
train() client id: f_00008-7-3 loss: 0.640324  [  128/  130]
train() client id: f_00008-8-0 loss: 0.595305  [   32/  130]
train() client id: f_00008-8-1 loss: 0.744669  [   64/  130]
train() client id: f_00008-8-2 loss: 0.711339  [   96/  130]
train() client id: f_00008-8-3 loss: 0.790547  [  128/  130]
train() client id: f_00008-9-0 loss: 0.672754  [   32/  130]
train() client id: f_00008-9-1 loss: 0.667388  [   64/  130]
train() client id: f_00008-9-2 loss: 0.772210  [   96/  130]
train() client id: f_00008-9-3 loss: 0.686330  [  128/  130]
train() client id: f_00008-10-0 loss: 0.748934  [   32/  130]
train() client id: f_00008-10-1 loss: 0.686153  [   64/  130]
train() client id: f_00008-10-2 loss: 0.700152  [   96/  130]
train() client id: f_00008-10-3 loss: 0.671936  [  128/  130]
train() client id: f_00008-11-0 loss: 0.693875  [   32/  130]
train() client id: f_00008-11-1 loss: 0.781146  [   64/  130]
train() client id: f_00008-11-2 loss: 0.671538  [   96/  130]
train() client id: f_00008-11-3 loss: 0.690397  [  128/  130]
train() client id: f_00008-12-0 loss: 0.729127  [   32/  130]
train() client id: f_00008-12-1 loss: 0.659358  [   64/  130]
train() client id: f_00008-12-2 loss: 0.706826  [   96/  130]
train() client id: f_00008-12-3 loss: 0.733768  [  128/  130]
train() client id: f_00009-0-0 loss: 1.271421  [   32/  118]
train() client id: f_00009-0-1 loss: 1.302823  [   64/  118]
train() client id: f_00009-0-2 loss: 1.165942  [   96/  118]
train() client id: f_00009-1-0 loss: 1.215885  [   32/  118]
train() client id: f_00009-1-1 loss: 1.182053  [   64/  118]
train() client id: f_00009-1-2 loss: 1.169185  [   96/  118]
train() client id: f_00009-2-0 loss: 1.159888  [   32/  118]
train() client id: f_00009-2-1 loss: 0.997427  [   64/  118]
train() client id: f_00009-2-2 loss: 1.316134  [   96/  118]
train() client id: f_00009-3-0 loss: 1.033990  [   32/  118]
train() client id: f_00009-3-1 loss: 1.009925  [   64/  118]
train() client id: f_00009-3-2 loss: 1.178735  [   96/  118]
train() client id: f_00009-4-0 loss: 1.051534  [   32/  118]
train() client id: f_00009-4-1 loss: 1.051982  [   64/  118]
train() client id: f_00009-4-2 loss: 1.067513  [   96/  118]
train() client id: f_00009-5-0 loss: 0.960849  [   32/  118]
train() client id: f_00009-5-1 loss: 1.104359  [   64/  118]
train() client id: f_00009-5-2 loss: 1.022357  [   96/  118]
train() client id: f_00009-6-0 loss: 1.021041  [   32/  118]
train() client id: f_00009-6-1 loss: 0.991702  [   64/  118]
train() client id: f_00009-6-2 loss: 0.977586  [   96/  118]
train() client id: f_00009-7-0 loss: 1.075673  [   32/  118]
train() client id: f_00009-7-1 loss: 0.936386  [   64/  118]
train() client id: f_00009-7-2 loss: 0.956258  [   96/  118]
train() client id: f_00009-8-0 loss: 0.996965  [   32/  118]
train() client id: f_00009-8-1 loss: 0.916425  [   64/  118]
train() client id: f_00009-8-2 loss: 1.029999  [   96/  118]
train() client id: f_00009-9-0 loss: 1.045968  [   32/  118]
train() client id: f_00009-9-1 loss: 0.976053  [   64/  118]
train() client id: f_00009-9-2 loss: 0.894185  [   96/  118]
train() client id: f_00009-10-0 loss: 0.955492  [   32/  118]
train() client id: f_00009-10-1 loss: 1.065470  [   64/  118]
train() client id: f_00009-10-2 loss: 0.868829  [   96/  118]
train() client id: f_00009-11-0 loss: 0.920747  [   32/  118]
train() client id: f_00009-11-1 loss: 0.889473  [   64/  118]
train() client id: f_00009-11-2 loss: 0.983205  [   96/  118]
train() client id: f_00009-12-0 loss: 0.811879  [   32/  118]
train() client id: f_00009-12-1 loss: 0.990876  [   64/  118]
train() client id: f_00009-12-2 loss: 1.012929  [   96/  118]
At round 24 accuracy: 0.636604774535809
At round 24 training accuracy: 0.5841716968477532
At round 24 training loss: 0.8380157884287801
gradient difference: 0.41728347539901733
train() client id: f_00000-0-0 loss: 1.273825  [   32/  126]
train() client id: f_00000-0-1 loss: 1.301427  [   64/  126]
train() client id: f_00000-0-2 loss: 1.182675  [   96/  126]
train() client id: f_00000-1-0 loss: 1.344838  [   32/  126]
train() client id: f_00000-1-1 loss: 1.006277  [   64/  126]
train() client id: f_00000-1-2 loss: 1.030457  [   96/  126]
train() client id: f_00000-2-0 loss: 1.222820  [   32/  126]
train() client id: f_00000-2-1 loss: 1.070628  [   64/  126]
train() client id: f_00000-2-2 loss: 1.080028  [   96/  126]
train() client id: f_00000-3-0 loss: 1.063165  [   32/  126]
train() client id: f_00000-3-1 loss: 1.078890  [   64/  126]
train() client id: f_00000-3-2 loss: 0.984126  [   96/  126]
train() client id: f_00000-4-0 loss: 0.958054  [   32/  126]
train() client id: f_00000-4-1 loss: 1.109524  [   64/  126]
train() client id: f_00000-4-2 loss: 0.913744  [   96/  126]
train() client id: f_00000-5-0 loss: 0.903168  [   32/  126]
train() client id: f_00000-5-1 loss: 1.040431  [   64/  126]
train() client id: f_00000-5-2 loss: 0.908376  [   96/  126]
train() client id: f_00000-6-0 loss: 0.868365  [   32/  126]
train() client id: f_00000-6-1 loss: 0.910982  [   64/  126]
train() client id: f_00000-6-2 loss: 1.032645  [   96/  126]
train() client id: f_00000-7-0 loss: 0.893496  [   32/  126]
train() client id: f_00000-7-1 loss: 0.870538  [   64/  126]
train() client id: f_00000-7-2 loss: 0.889730  [   96/  126]
train() client id: f_00000-8-0 loss: 0.883872  [   32/  126]
train() client id: f_00000-8-1 loss: 0.890069  [   64/  126]
train() client id: f_00000-8-2 loss: 0.731295  [   96/  126]
train() client id: f_00000-9-0 loss: 0.959634  [   32/  126]
train() client id: f_00000-9-1 loss: 0.922866  [   64/  126]
train() client id: f_00000-9-2 loss: 0.736575  [   96/  126]
train() client id: f_00000-10-0 loss: 0.863187  [   32/  126]
train() client id: f_00000-10-1 loss: 0.782773  [   64/  126]
train() client id: f_00000-10-2 loss: 0.924416  [   96/  126]
train() client id: f_00000-11-0 loss: 0.769374  [   32/  126]
train() client id: f_00000-11-1 loss: 0.819136  [   64/  126]
train() client id: f_00000-11-2 loss: 0.983793  [   96/  126]
train() client id: f_00000-12-0 loss: 0.833518  [   32/  126]
train() client id: f_00000-12-1 loss: 0.927370  [   64/  126]
train() client id: f_00000-12-2 loss: 0.797388  [   96/  126]
train() client id: f_00001-0-0 loss: 0.486031  [   32/  265]
train() client id: f_00001-0-1 loss: 0.500044  [   64/  265]
train() client id: f_00001-0-2 loss: 0.608281  [   96/  265]
train() client id: f_00001-0-3 loss: 0.482177  [  128/  265]
train() client id: f_00001-0-4 loss: 0.634776  [  160/  265]
train() client id: f_00001-0-5 loss: 0.486193  [  192/  265]
train() client id: f_00001-0-6 loss: 0.507559  [  224/  265]
train() client id: f_00001-0-7 loss: 0.430262  [  256/  265]
train() client id: f_00001-1-0 loss: 0.591717  [   32/  265]
train() client id: f_00001-1-1 loss: 0.466085  [   64/  265]
train() client id: f_00001-1-2 loss: 0.414081  [   96/  265]
train() client id: f_00001-1-3 loss: 0.586377  [  128/  265]
train() client id: f_00001-1-4 loss: 0.517483  [  160/  265]
train() client id: f_00001-1-5 loss: 0.452351  [  192/  265]
train() client id: f_00001-1-6 loss: 0.492630  [  224/  265]
train() client id: f_00001-1-7 loss: 0.553985  [  256/  265]
train() client id: f_00001-2-0 loss: 0.419635  [   32/  265]
train() client id: f_00001-2-1 loss: 0.590783  [   64/  265]
train() client id: f_00001-2-2 loss: 0.555156  [   96/  265]
train() client id: f_00001-2-3 loss: 0.430371  [  128/  265]
train() client id: f_00001-2-4 loss: 0.640517  [  160/  265]
train() client id: f_00001-2-5 loss: 0.405369  [  192/  265]
train() client id: f_00001-2-6 loss: 0.478961  [  224/  265]
train() client id: f_00001-2-7 loss: 0.464162  [  256/  265]
train() client id: f_00001-3-0 loss: 0.677787  [   32/  265]
train() client id: f_00001-3-1 loss: 0.545175  [   64/  265]
train() client id: f_00001-3-2 loss: 0.406763  [   96/  265]
train() client id: f_00001-3-3 loss: 0.450986  [  128/  265]
train() client id: f_00001-3-4 loss: 0.509263  [  160/  265]
train() client id: f_00001-3-5 loss: 0.407089  [  192/  265]
train() client id: f_00001-3-6 loss: 0.416670  [  224/  265]
train() client id: f_00001-3-7 loss: 0.550170  [  256/  265]
train() client id: f_00001-4-0 loss: 0.526331  [   32/  265]
train() client id: f_00001-4-1 loss: 0.492653  [   64/  265]
train() client id: f_00001-4-2 loss: 0.441863  [   96/  265]
train() client id: f_00001-4-3 loss: 0.553327  [  128/  265]
train() client id: f_00001-4-4 loss: 0.513469  [  160/  265]
train() client id: f_00001-4-5 loss: 0.397565  [  192/  265]
train() client id: f_00001-4-6 loss: 0.474835  [  224/  265]
train() client id: f_00001-4-7 loss: 0.547913  [  256/  265]
train() client id: f_00001-5-0 loss: 0.456397  [   32/  265]
train() client id: f_00001-5-1 loss: 0.512775  [   64/  265]
train() client id: f_00001-5-2 loss: 0.548061  [   96/  265]
train() client id: f_00001-5-3 loss: 0.525149  [  128/  265]
train() client id: f_00001-5-4 loss: 0.503935  [  160/  265]
train() client id: f_00001-5-5 loss: 0.532361  [  192/  265]
train() client id: f_00001-5-6 loss: 0.462817  [  224/  265]
train() client id: f_00001-5-7 loss: 0.384653  [  256/  265]
train() client id: f_00001-6-0 loss: 0.519203  [   32/  265]
train() client id: f_00001-6-1 loss: 0.651468  [   64/  265]
train() client id: f_00001-6-2 loss: 0.407250  [   96/  265]
train() client id: f_00001-6-3 loss: 0.414722  [  128/  265]
train() client id: f_00001-6-4 loss: 0.514118  [  160/  265]
train() client id: f_00001-6-5 loss: 0.499371  [  192/  265]
train() client id: f_00001-6-6 loss: 0.425113  [  224/  265]
train() client id: f_00001-6-7 loss: 0.478926  [  256/  265]
train() client id: f_00001-7-0 loss: 0.540150  [   32/  265]
train() client id: f_00001-7-1 loss: 0.412206  [   64/  265]
train() client id: f_00001-7-2 loss: 0.488721  [   96/  265]
train() client id: f_00001-7-3 loss: 0.495996  [  128/  265]
train() client id: f_00001-7-4 loss: 0.471636  [  160/  265]
train() client id: f_00001-7-5 loss: 0.586534  [  192/  265]
train() client id: f_00001-7-6 loss: 0.380717  [  224/  265]
train() client id: f_00001-7-7 loss: 0.468259  [  256/  265]
train() client id: f_00001-8-0 loss: 0.639413  [   32/  265]
train() client id: f_00001-8-1 loss: 0.472621  [   64/  265]
train() client id: f_00001-8-2 loss: 0.490432  [   96/  265]
train() client id: f_00001-8-3 loss: 0.401314  [  128/  265]
train() client id: f_00001-8-4 loss: 0.477411  [  160/  265]
train() client id: f_00001-8-5 loss: 0.439937  [  192/  265]
train() client id: f_00001-8-6 loss: 0.504528  [  224/  265]
train() client id: f_00001-8-7 loss: 0.467900  [  256/  265]
train() client id: f_00001-9-0 loss: 0.407335  [   32/  265]
train() client id: f_00001-9-1 loss: 0.510197  [   64/  265]
train() client id: f_00001-9-2 loss: 0.526463  [   96/  265]
train() client id: f_00001-9-3 loss: 0.524507  [  128/  265]
train() client id: f_00001-9-4 loss: 0.376477  [  160/  265]
train() client id: f_00001-9-5 loss: 0.631813  [  192/  265]
train() client id: f_00001-9-6 loss: 0.448124  [  224/  265]
train() client id: f_00001-9-7 loss: 0.463564  [  256/  265]
train() client id: f_00001-10-0 loss: 0.502467  [   32/  265]
train() client id: f_00001-10-1 loss: 0.460288  [   64/  265]
train() client id: f_00001-10-2 loss: 0.676253  [   96/  265]
train() client id: f_00001-10-3 loss: 0.412048  [  128/  265]
train() client id: f_00001-10-4 loss: 0.461971  [  160/  265]
train() client id: f_00001-10-5 loss: 0.528710  [  192/  265]
train() client id: f_00001-10-6 loss: 0.379462  [  224/  265]
train() client id: f_00001-10-7 loss: 0.464700  [  256/  265]
train() client id: f_00001-11-0 loss: 0.471772  [   32/  265]
train() client id: f_00001-11-1 loss: 0.635648  [   64/  265]
train() client id: f_00001-11-2 loss: 0.459228  [   96/  265]
train() client id: f_00001-11-3 loss: 0.513102  [  128/  265]
train() client id: f_00001-11-4 loss: 0.577311  [  160/  265]
train() client id: f_00001-11-5 loss: 0.394259  [  192/  265]
train() client id: f_00001-11-6 loss: 0.378152  [  224/  265]
train() client id: f_00001-11-7 loss: 0.433783  [  256/  265]
train() client id: f_00001-12-0 loss: 0.654182  [   32/  265]
train() client id: f_00001-12-1 loss: 0.395635  [   64/  265]
train() client id: f_00001-12-2 loss: 0.475878  [   96/  265]
train() client id: f_00001-12-3 loss: 0.605941  [  128/  265]
train() client id: f_00001-12-4 loss: 0.391203  [  160/  265]
train() client id: f_00001-12-5 loss: 0.381391  [  192/  265]
train() client id: f_00001-12-6 loss: 0.480331  [  224/  265]
train() client id: f_00001-12-7 loss: 0.508251  [  256/  265]
train() client id: f_00002-0-0 loss: 1.320229  [   32/  124]
train() client id: f_00002-0-1 loss: 1.314301  [   64/  124]
train() client id: f_00002-0-2 loss: 1.157243  [   96/  124]
train() client id: f_00002-1-0 loss: 1.374754  [   32/  124]
train() client id: f_00002-1-1 loss: 1.327221  [   64/  124]
train() client id: f_00002-1-2 loss: 1.171791  [   96/  124]
train() client id: f_00002-2-0 loss: 1.152801  [   32/  124]
train() client id: f_00002-2-1 loss: 1.299005  [   64/  124]
train() client id: f_00002-2-2 loss: 1.081228  [   96/  124]
train() client id: f_00002-3-0 loss: 1.220948  [   32/  124]
train() client id: f_00002-3-1 loss: 1.149289  [   64/  124]
train() client id: f_00002-3-2 loss: 1.361093  [   96/  124]
train() client id: f_00002-4-0 loss: 1.066597  [   32/  124]
train() client id: f_00002-4-1 loss: 1.145258  [   64/  124]
train() client id: f_00002-4-2 loss: 1.171829  [   96/  124]
train() client id: f_00002-5-0 loss: 1.108808  [   32/  124]
train() client id: f_00002-5-1 loss: 1.159747  [   64/  124]
train() client id: f_00002-5-2 loss: 1.100713  [   96/  124]
train() client id: f_00002-6-0 loss: 1.212390  [   32/  124]
train() client id: f_00002-6-1 loss: 1.131727  [   64/  124]
train() client id: f_00002-6-2 loss: 1.094354  [   96/  124]
train() client id: f_00002-7-0 loss: 1.210605  [   32/  124]
train() client id: f_00002-7-1 loss: 1.020142  [   64/  124]
train() client id: f_00002-7-2 loss: 1.130895  [   96/  124]
train() client id: f_00002-8-0 loss: 1.160425  [   32/  124]
train() client id: f_00002-8-1 loss: 1.073576  [   64/  124]
train() client id: f_00002-8-2 loss: 1.132820  [   96/  124]
train() client id: f_00002-9-0 loss: 0.992451  [   32/  124]
train() client id: f_00002-9-1 loss: 1.124604  [   64/  124]
train() client id: f_00002-9-2 loss: 1.064769  [   96/  124]
train() client id: f_00002-10-0 loss: 1.103131  [   32/  124]
train() client id: f_00002-10-1 loss: 1.141670  [   64/  124]
train() client id: f_00002-10-2 loss: 1.045506  [   96/  124]
train() client id: f_00002-11-0 loss: 1.305080  [   32/  124]
train() client id: f_00002-11-1 loss: 0.991117  [   64/  124]
train() client id: f_00002-11-2 loss: 1.058368  [   96/  124]
train() client id: f_00002-12-0 loss: 1.136244  [   32/  124]
train() client id: f_00002-12-1 loss: 1.209260  [   64/  124]
train() client id: f_00002-12-2 loss: 0.893917  [   96/  124]
train() client id: f_00003-0-0 loss: 0.841528  [   32/   43]
train() client id: f_00003-1-0 loss: 0.684841  [   32/   43]
train() client id: f_00003-2-0 loss: 0.670921  [   32/   43]
train() client id: f_00003-3-0 loss: 0.722026  [   32/   43]
train() client id: f_00003-4-0 loss: 0.658546  [   32/   43]
train() client id: f_00003-5-0 loss: 1.017984  [   32/   43]
train() client id: f_00003-6-0 loss: 0.715214  [   32/   43]
train() client id: f_00003-7-0 loss: 0.777504  [   32/   43]
train() client id: f_00003-8-0 loss: 0.836797  [   32/   43]
train() client id: f_00003-9-0 loss: 0.789342  [   32/   43]
train() client id: f_00003-10-0 loss: 0.790351  [   32/   43]
train() client id: f_00003-11-0 loss: 0.800472  [   32/   43]
train() client id: f_00003-12-0 loss: 0.841848  [   32/   43]
train() client id: f_00004-0-0 loss: 0.840005  [   32/  306]
train() client id: f_00004-0-1 loss: 0.766192  [   64/  306]
train() client id: f_00004-0-2 loss: 0.941105  [   96/  306]
train() client id: f_00004-0-3 loss: 0.805433  [  128/  306]
train() client id: f_00004-0-4 loss: 0.717830  [  160/  306]
train() client id: f_00004-0-5 loss: 0.766505  [  192/  306]
train() client id: f_00004-0-6 loss: 0.770957  [  224/  306]
train() client id: f_00004-0-7 loss: 0.792811  [  256/  306]
train() client id: f_00004-0-8 loss: 0.928141  [  288/  306]
train() client id: f_00004-1-0 loss: 0.872483  [   32/  306]
train() client id: f_00004-1-1 loss: 0.714964  [   64/  306]
train() client id: f_00004-1-2 loss: 0.865343  [   96/  306]
train() client id: f_00004-1-3 loss: 0.766512  [  128/  306]
train() client id: f_00004-1-4 loss: 0.865420  [  160/  306]
train() client id: f_00004-1-5 loss: 0.841406  [  192/  306]
train() client id: f_00004-1-6 loss: 0.858553  [  224/  306]
train() client id: f_00004-1-7 loss: 0.897401  [  256/  306]
train() client id: f_00004-1-8 loss: 0.771587  [  288/  306]
train() client id: f_00004-2-0 loss: 0.904331  [   32/  306]
train() client id: f_00004-2-1 loss: 0.762799  [   64/  306]
train() client id: f_00004-2-2 loss: 0.718506  [   96/  306]
train() client id: f_00004-2-3 loss: 0.851634  [  128/  306]
train() client id: f_00004-2-4 loss: 0.696983  [  160/  306]
train() client id: f_00004-2-5 loss: 0.820858  [  192/  306]
train() client id: f_00004-2-6 loss: 0.995723  [  224/  306]
train() client id: f_00004-2-7 loss: 0.764178  [  256/  306]
train() client id: f_00004-2-8 loss: 0.893635  [  288/  306]
train() client id: f_00004-3-0 loss: 0.908558  [   32/  306]
train() client id: f_00004-3-1 loss: 0.780090  [   64/  306]
train() client id: f_00004-3-2 loss: 0.810685  [   96/  306]
train() client id: f_00004-3-3 loss: 0.833860  [  128/  306]
train() client id: f_00004-3-4 loss: 0.928084  [  160/  306]
train() client id: f_00004-3-5 loss: 0.687916  [  192/  306]
train() client id: f_00004-3-6 loss: 0.833948  [  224/  306]
train() client id: f_00004-3-7 loss: 0.751192  [  256/  306]
train() client id: f_00004-3-8 loss: 0.743740  [  288/  306]
train() client id: f_00004-4-0 loss: 0.810657  [   32/  306]
train() client id: f_00004-4-1 loss: 0.828805  [   64/  306]
train() client id: f_00004-4-2 loss: 0.761439  [   96/  306]
train() client id: f_00004-4-3 loss: 0.816121  [  128/  306]
train() client id: f_00004-4-4 loss: 0.795729  [  160/  306]
train() client id: f_00004-4-5 loss: 0.983367  [  192/  306]
train() client id: f_00004-4-6 loss: 0.772694  [  224/  306]
train() client id: f_00004-4-7 loss: 0.890041  [  256/  306]
train() client id: f_00004-4-8 loss: 0.723955  [  288/  306]
train() client id: f_00004-5-0 loss: 0.817907  [   32/  306]
train() client id: f_00004-5-1 loss: 0.772029  [   64/  306]
train() client id: f_00004-5-2 loss: 0.780254  [   96/  306]
train() client id: f_00004-5-3 loss: 0.898289  [  128/  306]
train() client id: f_00004-5-4 loss: 0.740248  [  160/  306]
train() client id: f_00004-5-5 loss: 0.881596  [  192/  306]
train() client id: f_00004-5-6 loss: 0.901300  [  224/  306]
train() client id: f_00004-5-7 loss: 0.811353  [  256/  306]
train() client id: f_00004-5-8 loss: 0.852612  [  288/  306]
train() client id: f_00004-6-0 loss: 0.742892  [   32/  306]
train() client id: f_00004-6-1 loss: 0.742458  [   64/  306]
train() client id: f_00004-6-2 loss: 0.785549  [   96/  306]
train() client id: f_00004-6-3 loss: 0.864767  [  128/  306]
train() client id: f_00004-6-4 loss: 0.696456  [  160/  306]
train() client id: f_00004-6-5 loss: 0.821689  [  192/  306]
train() client id: f_00004-6-6 loss: 0.921200  [  224/  306]
train() client id: f_00004-6-7 loss: 1.000793  [  256/  306]
train() client id: f_00004-6-8 loss: 0.848178  [  288/  306]
train() client id: f_00004-7-0 loss: 0.720317  [   32/  306]
train() client id: f_00004-7-1 loss: 0.731535  [   64/  306]
train() client id: f_00004-7-2 loss: 0.985727  [   96/  306]
train() client id: f_00004-7-3 loss: 0.811469  [  128/  306]
train() client id: f_00004-7-4 loss: 0.855046  [  160/  306]
train() client id: f_00004-7-5 loss: 0.781998  [  192/  306]
train() client id: f_00004-7-6 loss: 0.866017  [  224/  306]
train() client id: f_00004-7-7 loss: 0.936832  [  256/  306]
train() client id: f_00004-7-8 loss: 0.801663  [  288/  306]
train() client id: f_00004-8-0 loss: 0.808446  [   32/  306]
train() client id: f_00004-8-1 loss: 0.996811  [   64/  306]
train() client id: f_00004-8-2 loss: 0.827937  [   96/  306]
train() client id: f_00004-8-3 loss: 0.728994  [  128/  306]
train() client id: f_00004-8-4 loss: 0.891295  [  160/  306]
train() client id: f_00004-8-5 loss: 0.771869  [  192/  306]
train() client id: f_00004-8-6 loss: 0.783821  [  224/  306]
train() client id: f_00004-8-7 loss: 0.754506  [  256/  306]
train() client id: f_00004-8-8 loss: 0.818805  [  288/  306]
train() client id: f_00004-9-0 loss: 0.853278  [   32/  306]
train() client id: f_00004-9-1 loss: 0.789835  [   64/  306]
train() client id: f_00004-9-2 loss: 1.012403  [   96/  306]
train() client id: f_00004-9-3 loss: 0.828535  [  128/  306]
train() client id: f_00004-9-4 loss: 0.789935  [  160/  306]
train() client id: f_00004-9-5 loss: 0.792012  [  192/  306]
train() client id: f_00004-9-6 loss: 0.709974  [  224/  306]
train() client id: f_00004-9-7 loss: 0.868763  [  256/  306]
train() client id: f_00004-9-8 loss: 0.844613  [  288/  306]
train() client id: f_00004-10-0 loss: 0.820140  [   32/  306]
train() client id: f_00004-10-1 loss: 0.875703  [   64/  306]
train() client id: f_00004-10-2 loss: 0.795460  [   96/  306]
train() client id: f_00004-10-3 loss: 0.785059  [  128/  306]
train() client id: f_00004-10-4 loss: 0.792743  [  160/  306]
train() client id: f_00004-10-5 loss: 0.882885  [  192/  306]
train() client id: f_00004-10-6 loss: 0.969232  [  224/  306]
train() client id: f_00004-10-7 loss: 0.759522  [  256/  306]
train() client id: f_00004-10-8 loss: 0.689695  [  288/  306]
train() client id: f_00004-11-0 loss: 0.747802  [   32/  306]
train() client id: f_00004-11-1 loss: 0.913612  [   64/  306]
train() client id: f_00004-11-2 loss: 0.795765  [   96/  306]
train() client id: f_00004-11-3 loss: 0.731495  [  128/  306]
train() client id: f_00004-11-4 loss: 0.928372  [  160/  306]
train() client id: f_00004-11-5 loss: 0.774362  [  192/  306]
train() client id: f_00004-11-6 loss: 0.831383  [  224/  306]
train() client id: f_00004-11-7 loss: 0.765913  [  256/  306]
train() client id: f_00004-11-8 loss: 0.944073  [  288/  306]
train() client id: f_00004-12-0 loss: 0.829239  [   32/  306]
train() client id: f_00004-12-1 loss: 0.751803  [   64/  306]
train() client id: f_00004-12-2 loss: 0.693128  [   96/  306]
train() client id: f_00004-12-3 loss: 0.797362  [  128/  306]
train() client id: f_00004-12-4 loss: 0.899642  [  160/  306]
train() client id: f_00004-12-5 loss: 0.751479  [  192/  306]
train() client id: f_00004-12-6 loss: 0.880268  [  224/  306]
train() client id: f_00004-12-7 loss: 0.838914  [  256/  306]
train() client id: f_00004-12-8 loss: 0.880121  [  288/  306]
train() client id: f_00005-0-0 loss: 0.471381  [   32/  146]
train() client id: f_00005-0-1 loss: 0.371677  [   64/  146]
train() client id: f_00005-0-2 loss: 0.638908  [   96/  146]
train() client id: f_00005-0-3 loss: 0.527903  [  128/  146]
train() client id: f_00005-1-0 loss: 0.400753  [   32/  146]
train() client id: f_00005-1-1 loss: 0.390530  [   64/  146]
train() client id: f_00005-1-2 loss: 0.729357  [   96/  146]
train() client id: f_00005-1-3 loss: 0.439904  [  128/  146]
train() client id: f_00005-2-0 loss: 0.267168  [   32/  146]
train() client id: f_00005-2-1 loss: 0.728838  [   64/  146]
train() client id: f_00005-2-2 loss: 0.613862  [   96/  146]
train() client id: f_00005-2-3 loss: 0.306148  [  128/  146]
train() client id: f_00005-3-0 loss: 0.684717  [   32/  146]
train() client id: f_00005-3-1 loss: 0.637324  [   64/  146]
train() client id: f_00005-3-2 loss: 0.214915  [   96/  146]
train() client id: f_00005-3-3 loss: 0.476681  [  128/  146]
train() client id: f_00005-4-0 loss: 0.401481  [   32/  146]
train() client id: f_00005-4-1 loss: 0.280604  [   64/  146]
train() client id: f_00005-4-2 loss: 0.747247  [   96/  146]
train() client id: f_00005-4-3 loss: 0.548845  [  128/  146]
train() client id: f_00005-5-0 loss: 0.587389  [   32/  146]
train() client id: f_00005-5-1 loss: 0.298799  [   64/  146]
train() client id: f_00005-5-2 loss: 0.503495  [   96/  146]
train() client id: f_00005-5-3 loss: 0.488420  [  128/  146]
train() client id: f_00005-6-0 loss: 0.356410  [   32/  146]
train() client id: f_00005-6-1 loss: 0.338387  [   64/  146]
train() client id: f_00005-6-2 loss: 0.468501  [   96/  146]
train() client id: f_00005-6-3 loss: 0.674109  [  128/  146]
train() client id: f_00005-7-0 loss: 0.367930  [   32/  146]
train() client id: f_00005-7-1 loss: 0.555093  [   64/  146]
train() client id: f_00005-7-2 loss: 0.482140  [   96/  146]
train() client id: f_00005-7-3 loss: 0.639606  [  128/  146]
train() client id: f_00005-8-0 loss: 0.475609  [   32/  146]
train() client id: f_00005-8-1 loss: 0.479498  [   64/  146]
train() client id: f_00005-8-2 loss: 0.571518  [   96/  146]
train() client id: f_00005-8-3 loss: 0.373884  [  128/  146]
train() client id: f_00005-9-0 loss: 0.386372  [   32/  146]
train() client id: f_00005-9-1 loss: 0.411965  [   64/  146]
train() client id: f_00005-9-2 loss: 0.472173  [   96/  146]
train() client id: f_00005-9-3 loss: 0.510931  [  128/  146]
train() client id: f_00005-10-0 loss: 0.357628  [   32/  146]
train() client id: f_00005-10-1 loss: 0.374526  [   64/  146]
train() client id: f_00005-10-2 loss: 0.838134  [   96/  146]
train() client id: f_00005-10-3 loss: 0.399401  [  128/  146]
train() client id: f_00005-11-0 loss: 0.577499  [   32/  146]
train() client id: f_00005-11-1 loss: 0.494737  [   64/  146]
train() client id: f_00005-11-2 loss: 0.370114  [   96/  146]
train() client id: f_00005-11-3 loss: 0.557611  [  128/  146]
train() client id: f_00005-12-0 loss: 0.312174  [   32/  146]
train() client id: f_00005-12-1 loss: 0.523765  [   64/  146]
train() client id: f_00005-12-2 loss: 0.569543  [   96/  146]
train() client id: f_00005-12-3 loss: 0.552202  [  128/  146]
train() client id: f_00006-0-0 loss: 0.529338  [   32/   54]
train() client id: f_00006-1-0 loss: 0.523291  [   32/   54]
train() client id: f_00006-2-0 loss: 0.593922  [   32/   54]
train() client id: f_00006-3-0 loss: 0.580243  [   32/   54]
train() client id: f_00006-4-0 loss: 0.582792  [   32/   54]
train() client id: f_00006-5-0 loss: 0.579980  [   32/   54]
train() client id: f_00006-6-0 loss: 0.557083  [   32/   54]
train() client id: f_00006-7-0 loss: 0.495386  [   32/   54]
train() client id: f_00006-8-0 loss: 0.499160  [   32/   54]
train() client id: f_00006-9-0 loss: 0.555097  [   32/   54]
train() client id: f_00006-10-0 loss: 0.602433  [   32/   54]
train() client id: f_00006-11-0 loss: 0.531054  [   32/   54]
train() client id: f_00006-12-0 loss: 0.536617  [   32/   54]
train() client id: f_00007-0-0 loss: 0.654532  [   32/  179]
train() client id: f_00007-0-1 loss: 0.793132  [   64/  179]
train() client id: f_00007-0-2 loss: 0.757940  [   96/  179]
train() client id: f_00007-0-3 loss: 0.637367  [  128/  179]
train() client id: f_00007-0-4 loss: 0.556830  [  160/  179]
train() client id: f_00007-1-0 loss: 0.631828  [   32/  179]
train() client id: f_00007-1-1 loss: 0.746994  [   64/  179]
train() client id: f_00007-1-2 loss: 0.800299  [   96/  179]
train() client id: f_00007-1-3 loss: 0.761367  [  128/  179]
train() client id: f_00007-1-4 loss: 0.574939  [  160/  179]
train() client id: f_00007-2-0 loss: 0.576549  [   32/  179]
train() client id: f_00007-2-1 loss: 0.728086  [   64/  179]
train() client id: f_00007-2-2 loss: 0.707516  [   96/  179]
train() client id: f_00007-2-3 loss: 0.647216  [  128/  179]
train() client id: f_00007-2-4 loss: 0.811238  [  160/  179]
train() client id: f_00007-3-0 loss: 0.810547  [   32/  179]
train() client id: f_00007-3-1 loss: 0.587497  [   64/  179]
train() client id: f_00007-3-2 loss: 0.669027  [   96/  179]
train() client id: f_00007-3-3 loss: 0.633195  [  128/  179]
train() client id: f_00007-3-4 loss: 0.707321  [  160/  179]
train() client id: f_00007-4-0 loss: 0.766321  [   32/  179]
train() client id: f_00007-4-1 loss: 0.595936  [   64/  179]
train() client id: f_00007-4-2 loss: 0.731526  [   96/  179]
train() client id: f_00007-4-3 loss: 0.679746  [  128/  179]
train() client id: f_00007-4-4 loss: 0.598216  [  160/  179]
train() client id: f_00007-5-0 loss: 0.667039  [   32/  179]
train() client id: f_00007-5-1 loss: 0.645267  [   64/  179]
train() client id: f_00007-5-2 loss: 0.551679  [   96/  179]
train() client id: f_00007-5-3 loss: 0.736838  [  128/  179]
train() client id: f_00007-5-4 loss: 0.838499  [  160/  179]
train() client id: f_00007-6-0 loss: 0.588828  [   32/  179]
train() client id: f_00007-6-1 loss: 0.553226  [   64/  179]
train() client id: f_00007-6-2 loss: 0.638718  [   96/  179]
train() client id: f_00007-6-3 loss: 0.655995  [  128/  179]
train() client id: f_00007-6-4 loss: 0.798081  [  160/  179]
train() client id: f_00007-7-0 loss: 0.630427  [   32/  179]
train() client id: f_00007-7-1 loss: 0.642789  [   64/  179]
train() client id: f_00007-7-2 loss: 0.631531  [   96/  179]
train() client id: f_00007-7-3 loss: 0.566301  [  128/  179]
train() client id: f_00007-7-4 loss: 0.898737  [  160/  179]
train() client id: f_00007-8-0 loss: 0.536369  [   32/  179]
train() client id: f_00007-8-1 loss: 0.804093  [   64/  179]
train() client id: f_00007-8-2 loss: 0.540270  [   96/  179]
train() client id: f_00007-8-3 loss: 0.746479  [  128/  179]
train() client id: f_00007-8-4 loss: 0.796703  [  160/  179]
train() client id: f_00007-9-0 loss: 0.685348  [   32/  179]
train() client id: f_00007-9-1 loss: 0.716421  [   64/  179]
train() client id: f_00007-9-2 loss: 0.756052  [   96/  179]
train() client id: f_00007-9-3 loss: 0.611935  [  128/  179]
train() client id: f_00007-9-4 loss: 0.645106  [  160/  179]
train() client id: f_00007-10-0 loss: 0.816851  [   32/  179]
train() client id: f_00007-10-1 loss: 0.594652  [   64/  179]
train() client id: f_00007-10-2 loss: 0.821382  [   96/  179]
train() client id: f_00007-10-3 loss: 0.729066  [  128/  179]
train() client id: f_00007-10-4 loss: 0.545405  [  160/  179]
train() client id: f_00007-11-0 loss: 0.796502  [   32/  179]
train() client id: f_00007-11-1 loss: 0.651626  [   64/  179]
train() client id: f_00007-11-2 loss: 0.810426  [   96/  179]
train() client id: f_00007-11-3 loss: 0.716569  [  128/  179]
train() client id: f_00007-11-4 loss: 0.566491  [  160/  179]
train() client id: f_00007-12-0 loss: 0.721194  [   32/  179]
train() client id: f_00007-12-1 loss: 0.734736  [   64/  179]
train() client id: f_00007-12-2 loss: 0.512486  [   96/  179]
train() client id: f_00007-12-3 loss: 0.833917  [  128/  179]
train() client id: f_00007-12-4 loss: 0.556398  [  160/  179]
train() client id: f_00008-0-0 loss: 0.727594  [   32/  130]
train() client id: f_00008-0-1 loss: 0.797560  [   64/  130]
train() client id: f_00008-0-2 loss: 0.809568  [   96/  130]
train() client id: f_00008-0-3 loss: 0.650425  [  128/  130]
train() client id: f_00008-1-0 loss: 0.844386  [   32/  130]
train() client id: f_00008-1-1 loss: 0.746545  [   64/  130]
train() client id: f_00008-1-2 loss: 0.661877  [   96/  130]
train() client id: f_00008-1-3 loss: 0.732608  [  128/  130]
train() client id: f_00008-2-0 loss: 0.681948  [   32/  130]
train() client id: f_00008-2-1 loss: 0.835491  [   64/  130]
train() client id: f_00008-2-2 loss: 0.800010  [   96/  130]
train() client id: f_00008-2-3 loss: 0.642318  [  128/  130]
train() client id: f_00008-3-0 loss: 0.832152  [   32/  130]
train() client id: f_00008-3-1 loss: 0.634702  [   64/  130]
train() client id: f_00008-3-2 loss: 0.797292  [   96/  130]
train() client id: f_00008-3-3 loss: 0.678158  [  128/  130]
train() client id: f_00008-4-0 loss: 0.675477  [   32/  130]
train() client id: f_00008-4-1 loss: 0.777816  [   64/  130]
train() client id: f_00008-4-2 loss: 0.719591  [   96/  130]
train() client id: f_00008-4-3 loss: 0.764515  [  128/  130]
train() client id: f_00008-5-0 loss: 0.845115  [   32/  130]
train() client id: f_00008-5-1 loss: 0.774380  [   64/  130]
train() client id: f_00008-5-2 loss: 0.736978  [   96/  130]
train() client id: f_00008-5-3 loss: 0.625133  [  128/  130]
train() client id: f_00008-6-0 loss: 0.663763  [   32/  130]
train() client id: f_00008-6-1 loss: 0.637596  [   64/  130]
train() client id: f_00008-6-2 loss: 0.922143  [   96/  130]
train() client id: f_00008-6-3 loss: 0.721650  [  128/  130]
train() client id: f_00008-7-0 loss: 0.824698  [   32/  130]
train() client id: f_00008-7-1 loss: 0.727653  [   64/  130]
train() client id: f_00008-7-2 loss: 0.673921  [   96/  130]
train() client id: f_00008-7-3 loss: 0.752913  [  128/  130]
train() client id: f_00008-8-0 loss: 0.741861  [   32/  130]
train() client id: f_00008-8-1 loss: 0.777464  [   64/  130]
train() client id: f_00008-8-2 loss: 0.702902  [   96/  130]
train() client id: f_00008-8-3 loss: 0.754290  [  128/  130]
train() client id: f_00008-9-0 loss: 0.560792  [   32/  130]
train() client id: f_00008-9-1 loss: 0.739045  [   64/  130]
train() client id: f_00008-9-2 loss: 0.764706  [   96/  130]
train() client id: f_00008-9-3 loss: 0.848649  [  128/  130]
train() client id: f_00008-10-0 loss: 0.691868  [   32/  130]
train() client id: f_00008-10-1 loss: 0.727057  [   64/  130]
train() client id: f_00008-10-2 loss: 0.755467  [   96/  130]
train() client id: f_00008-10-3 loss: 0.808232  [  128/  130]
train() client id: f_00008-11-0 loss: 0.807961  [   32/  130]
train() client id: f_00008-11-1 loss: 0.719908  [   64/  130]
train() client id: f_00008-11-2 loss: 0.693692  [   96/  130]
train() client id: f_00008-11-3 loss: 0.725327  [  128/  130]
train() client id: f_00008-12-0 loss: 0.707282  [   32/  130]
train() client id: f_00008-12-1 loss: 0.693199  [   64/  130]
train() client id: f_00008-12-2 loss: 0.731187  [   96/  130]
train() client id: f_00008-12-3 loss: 0.842719  [  128/  130]
train() client id: f_00009-0-0 loss: 1.157439  [   32/  118]
train() client id: f_00009-0-1 loss: 1.085802  [   64/  118]
train() client id: f_00009-0-2 loss: 1.082524  [   96/  118]
train() client id: f_00009-1-0 loss: 0.978773  [   32/  118]
train() client id: f_00009-1-1 loss: 1.008540  [   64/  118]
train() client id: f_00009-1-2 loss: 0.991735  [   96/  118]
train() client id: f_00009-2-0 loss: 0.973643  [   32/  118]
train() client id: f_00009-2-1 loss: 1.006786  [   64/  118]
train() client id: f_00009-2-2 loss: 0.970190  [   96/  118]
train() client id: f_00009-3-0 loss: 1.027100  [   32/  118]
train() client id: f_00009-3-1 loss: 0.977736  [   64/  118]
train() client id: f_00009-3-2 loss: 0.893421  [   96/  118]
train() client id: f_00009-4-0 loss: 0.878146  [   32/  118]
train() client id: f_00009-4-1 loss: 0.912748  [   64/  118]
train() client id: f_00009-4-2 loss: 0.976186  [   96/  118]
train() client id: f_00009-5-0 loss: 0.915332  [   32/  118]
train() client id: f_00009-5-1 loss: 0.923093  [   64/  118]
train() client id: f_00009-5-2 loss: 0.946188  [   96/  118]
train() client id: f_00009-6-0 loss: 0.931648  [   32/  118]
train() client id: f_00009-6-1 loss: 0.864155  [   64/  118]
train() client id: f_00009-6-2 loss: 0.939274  [   96/  118]
train() client id: f_00009-7-0 loss: 0.743296  [   32/  118]
train() client id: f_00009-7-1 loss: 0.951331  [   64/  118]
train() client id: f_00009-7-2 loss: 0.830268  [   96/  118]
train() client id: f_00009-8-0 loss: 0.929446  [   32/  118]
train() client id: f_00009-8-1 loss: 0.802244  [   64/  118]
train() client id: f_00009-8-2 loss: 0.870359  [   96/  118]
train() client id: f_00009-9-0 loss: 0.812817  [   32/  118]
train() client id: f_00009-9-1 loss: 0.998268  [   64/  118]
train() client id: f_00009-9-2 loss: 0.690482  [   96/  118]
train() client id: f_00009-10-0 loss: 0.786914  [   32/  118]
train() client id: f_00009-10-1 loss: 0.878242  [   64/  118]
train() client id: f_00009-10-2 loss: 0.801567  [   96/  118]
train() client id: f_00009-11-0 loss: 0.784896  [   32/  118]
train() client id: f_00009-11-1 loss: 0.944567  [   64/  118]
train() client id: f_00009-11-2 loss: 0.775169  [   96/  118]
train() client id: f_00009-12-0 loss: 0.791487  [   32/  118]
train() client id: f_00009-12-1 loss: 0.883512  [   64/  118]
train() client id: f_00009-12-2 loss: 0.768807  [   96/  118]
At round 25 accuracy: 0.636604774535809
At round 25 training accuracy: 0.5808182427900738
At round 25 training loss: 0.8421898572486024
gradient difference: 0.5654993653297424
train() client id: f_00000-0-0 loss: 1.041279  [   32/  126]
train() client id: f_00000-0-1 loss: 1.152077  [   64/  126]
train() client id: f_00000-0-2 loss: 0.789616  [   96/  126]
train() client id: f_00000-1-0 loss: 1.188864  [   32/  126]
train() client id: f_00000-1-1 loss: 0.901958  [   64/  126]
train() client id: f_00000-1-2 loss: 0.743458  [   96/  126]
train() client id: f_00000-2-0 loss: 1.025179  [   32/  126]
train() client id: f_00000-2-1 loss: 0.903220  [   64/  126]
train() client id: f_00000-2-2 loss: 0.880058  [   96/  126]
train() client id: f_00000-3-0 loss: 0.964118  [   32/  126]
train() client id: f_00000-3-1 loss: 0.975451  [   64/  126]
train() client id: f_00000-3-2 loss: 0.878648  [   96/  126]
train() client id: f_00000-4-0 loss: 0.853674  [   32/  126]
train() client id: f_00000-4-1 loss: 0.898382  [   64/  126]
train() client id: f_00000-4-2 loss: 0.882399  [   96/  126]
train() client id: f_00000-5-0 loss: 0.951669  [   32/  126]
train() client id: f_00000-5-1 loss: 0.869275  [   64/  126]
train() client id: f_00000-5-2 loss: 0.897874  [   96/  126]
train() client id: f_00000-6-0 loss: 0.954638  [   32/  126]
train() client id: f_00000-6-1 loss: 0.773883  [   64/  126]
train() client id: f_00000-6-2 loss: 0.858335  [   96/  126]
train() client id: f_00000-7-0 loss: 0.915541  [   32/  126]
train() client id: f_00000-7-1 loss: 0.898522  [   64/  126]
train() client id: f_00000-7-2 loss: 0.816418  [   96/  126]
train() client id: f_00000-8-0 loss: 1.030272  [   32/  126]
train() client id: f_00000-8-1 loss: 0.793501  [   64/  126]
train() client id: f_00000-8-2 loss: 0.852804  [   96/  126]
train() client id: f_00000-9-0 loss: 0.970245  [   32/  126]
train() client id: f_00000-9-1 loss: 0.853952  [   64/  126]
train() client id: f_00000-9-2 loss: 0.852524  [   96/  126]
train() client id: f_00000-10-0 loss: 0.939753  [   32/  126]
train() client id: f_00000-10-1 loss: 0.779367  [   64/  126]
train() client id: f_00000-10-2 loss: 0.784452  [   96/  126]
train() client id: f_00000-11-0 loss: 0.965364  [   32/  126]
train() client id: f_00000-11-1 loss: 0.874250  [   64/  126]
train() client id: f_00000-11-2 loss: 0.978328  [   96/  126]
train() client id: f_00000-12-0 loss: 1.050473  [   32/  126]
train() client id: f_00000-12-1 loss: 0.857289  [   64/  126]
train() client id: f_00000-12-2 loss: 0.816886  [   96/  126]
train() client id: f_00001-0-0 loss: 0.522391  [   32/  265]
train() client id: f_00001-0-1 loss: 0.399640  [   64/  265]
train() client id: f_00001-0-2 loss: 0.523516  [   96/  265]
train() client id: f_00001-0-3 loss: 0.467772  [  128/  265]
train() client id: f_00001-0-4 loss: 0.463961  [  160/  265]
train() client id: f_00001-0-5 loss: 0.512872  [  192/  265]
train() client id: f_00001-0-6 loss: 0.444552  [  224/  265]
train() client id: f_00001-0-7 loss: 0.486553  [  256/  265]
train() client id: f_00001-1-0 loss: 0.505097  [   32/  265]
train() client id: f_00001-1-1 loss: 0.389914  [   64/  265]
train() client id: f_00001-1-2 loss: 0.506523  [   96/  265]
train() client id: f_00001-1-3 loss: 0.389142  [  128/  265]
train() client id: f_00001-1-4 loss: 0.450908  [  160/  265]
train() client id: f_00001-1-5 loss: 0.422785  [  192/  265]
train() client id: f_00001-1-6 loss: 0.525809  [  224/  265]
train() client id: f_00001-1-7 loss: 0.517891  [  256/  265]
train() client id: f_00001-2-0 loss: 0.445842  [   32/  265]
train() client id: f_00001-2-1 loss: 0.454301  [   64/  265]
train() client id: f_00001-2-2 loss: 0.478995  [   96/  265]
train() client id: f_00001-2-3 loss: 0.599418  [  128/  265]
train() client id: f_00001-2-4 loss: 0.406024  [  160/  265]
train() client id: f_00001-2-5 loss: 0.433191  [  192/  265]
train() client id: f_00001-2-6 loss: 0.528897  [  224/  265]
train() client id: f_00001-2-7 loss: 0.374637  [  256/  265]
train() client id: f_00001-3-0 loss: 0.431597  [   32/  265]
train() client id: f_00001-3-1 loss: 0.377253  [   64/  265]
train() client id: f_00001-3-2 loss: 0.402145  [   96/  265]
train() client id: f_00001-3-3 loss: 0.533142  [  128/  265]
train() client id: f_00001-3-4 loss: 0.478212  [  160/  265]
train() client id: f_00001-3-5 loss: 0.455299  [  192/  265]
train() client id: f_00001-3-6 loss: 0.557288  [  224/  265]
train() client id: f_00001-3-7 loss: 0.461132  [  256/  265]
train() client id: f_00001-4-0 loss: 0.492869  [   32/  265]
train() client id: f_00001-4-1 loss: 0.420876  [   64/  265]
train() client id: f_00001-4-2 loss: 0.421265  [   96/  265]
train() client id: f_00001-4-3 loss: 0.436149  [  128/  265]
train() client id: f_00001-4-4 loss: 0.419154  [  160/  265]
train() client id: f_00001-4-5 loss: 0.479634  [  192/  265]
train() client id: f_00001-4-6 loss: 0.433776  [  224/  265]
train() client id: f_00001-4-7 loss: 0.477581  [  256/  265]
train() client id: f_00001-5-0 loss: 0.534853  [   32/  265]
train() client id: f_00001-5-1 loss: 0.370428  [   64/  265]
train() client id: f_00001-5-2 loss: 0.436605  [   96/  265]
train() client id: f_00001-5-3 loss: 0.445174  [  128/  265]
train() client id: f_00001-5-4 loss: 0.414172  [  160/  265]
train() client id: f_00001-5-5 loss: 0.348503  [  192/  265]
train() client id: f_00001-5-6 loss: 0.583211  [  224/  265]
train() client id: f_00001-5-7 loss: 0.447951  [  256/  265]
train() client id: f_00001-6-0 loss: 0.459027  [   32/  265]
train() client id: f_00001-6-1 loss: 0.476510  [   64/  265]
train() client id: f_00001-6-2 loss: 0.468902  [   96/  265]
train() client id: f_00001-6-3 loss: 0.417327  [  128/  265]
train() client id: f_00001-6-4 loss: 0.469986  [  160/  265]
train() client id: f_00001-6-5 loss: 0.445496  [  192/  265]
train() client id: f_00001-6-6 loss: 0.522597  [  224/  265]
train() client id: f_00001-6-7 loss: 0.376652  [  256/  265]
train() client id: f_00001-7-0 loss: 0.538113  [   32/  265]
train() client id: f_00001-7-1 loss: 0.422045  [   64/  265]
train() client id: f_00001-7-2 loss: 0.356508  [   96/  265]
train() client id: f_00001-7-3 loss: 0.375770  [  128/  265]
train() client id: f_00001-7-4 loss: 0.413580  [  160/  265]
train() client id: f_00001-7-5 loss: 0.405092  [  192/  265]
train() client id: f_00001-7-6 loss: 0.667323  [  224/  265]
train() client id: f_00001-7-7 loss: 0.476748  [  256/  265]
train() client id: f_00001-8-0 loss: 0.641505  [   32/  265]
train() client id: f_00001-8-1 loss: 0.548309  [   64/  265]
train() client id: f_00001-8-2 loss: 0.387006  [   96/  265]
train() client id: f_00001-8-3 loss: 0.355311  [  128/  265]
train() client id: f_00001-8-4 loss: 0.347728  [  160/  265]
train() client id: f_00001-8-5 loss: 0.372274  [  192/  265]
train() client id: f_00001-8-6 loss: 0.534752  [  224/  265]
train() client id: f_00001-8-7 loss: 0.454205  [  256/  265]
train() client id: f_00001-9-0 loss: 0.472915  [   32/  265]
train() client id: f_00001-9-1 loss: 0.635097  [   64/  265]
train() client id: f_00001-9-2 loss: 0.435095  [   96/  265]
train() client id: f_00001-9-3 loss: 0.496117  [  128/  265]
train() client id: f_00001-9-4 loss: 0.405315  [  160/  265]
train() client id: f_00001-9-5 loss: 0.358542  [  192/  265]
train() client id: f_00001-9-6 loss: 0.372094  [  224/  265]
train() client id: f_00001-9-7 loss: 0.478656  [  256/  265]
train() client id: f_00001-10-0 loss: 0.421689  [   32/  265]
train() client id: f_00001-10-1 loss: 0.484118  [   64/  265]
train() client id: f_00001-10-2 loss: 0.498747  [   96/  265]
train() client id: f_00001-10-3 loss: 0.576481  [  128/  265]
train() client id: f_00001-10-4 loss: 0.359332  [  160/  265]
train() client id: f_00001-10-5 loss: 0.478587  [  192/  265]
train() client id: f_00001-10-6 loss: 0.365923  [  224/  265]
train() client id: f_00001-10-7 loss: 0.380612  [  256/  265]
train() client id: f_00001-11-0 loss: 0.601626  [   32/  265]
train() client id: f_00001-11-1 loss: 0.478256  [   64/  265]
train() client id: f_00001-11-2 loss: 0.445155  [   96/  265]
train() client id: f_00001-11-3 loss: 0.385646  [  128/  265]
train() client id: f_00001-11-4 loss: 0.350386  [  160/  265]
train() client id: f_00001-11-5 loss: 0.465046  [  192/  265]
train() client id: f_00001-11-6 loss: 0.450135  [  224/  265]
train() client id: f_00001-11-7 loss: 0.486383  [  256/  265]
train() client id: f_00001-12-0 loss: 0.437250  [   32/  265]
train() client id: f_00001-12-1 loss: 0.439920  [   64/  265]
train() client id: f_00001-12-2 loss: 0.596912  [   96/  265]
train() client id: f_00001-12-3 loss: 0.410235  [  128/  265]
train() client id: f_00001-12-4 loss: 0.447061  [  160/  265]
train() client id: f_00001-12-5 loss: 0.437532  [  192/  265]
train() client id: f_00001-12-6 loss: 0.364298  [  224/  265]
train() client id: f_00001-12-7 loss: 0.485753  [  256/  265]
train() client id: f_00002-0-0 loss: 1.195467  [   32/  124]
train() client id: f_00002-0-1 loss: 1.351896  [   64/  124]
train() client id: f_00002-0-2 loss: 1.393189  [   96/  124]
train() client id: f_00002-1-0 loss: 1.324076  [   32/  124]
train() client id: f_00002-1-1 loss: 1.293940  [   64/  124]
train() client id: f_00002-1-2 loss: 1.288422  [   96/  124]
train() client id: f_00002-2-0 loss: 1.203480  [   32/  124]
train() client id: f_00002-2-1 loss: 1.179091  [   64/  124]
train() client id: f_00002-2-2 loss: 1.364936  [   96/  124]
train() client id: f_00002-3-0 loss: 1.169722  [   32/  124]
train() client id: f_00002-3-1 loss: 1.201277  [   64/  124]
train() client id: f_00002-3-2 loss: 1.320067  [   96/  124]
train() client id: f_00002-4-0 loss: 1.290650  [   32/  124]
train() client id: f_00002-4-1 loss: 1.205043  [   64/  124]
train() client id: f_00002-4-2 loss: 1.112168  [   96/  124]
train() client id: f_00002-5-0 loss: 1.174190  [   32/  124]
train() client id: f_00002-5-1 loss: 1.172816  [   64/  124]
train() client id: f_00002-5-2 loss: 1.191252  [   96/  124]
train() client id: f_00002-6-0 loss: 1.247268  [   32/  124]
train() client id: f_00002-6-1 loss: 1.231594  [   64/  124]
train() client id: f_00002-6-2 loss: 1.196225  [   96/  124]
train() client id: f_00002-7-0 loss: 1.051682  [   32/  124]
train() client id: f_00002-7-1 loss: 1.103808  [   64/  124]
train() client id: f_00002-7-2 loss: 1.304104  [   96/  124]
train() client id: f_00002-8-0 loss: 1.115413  [   32/  124]
train() client id: f_00002-8-1 loss: 1.279028  [   64/  124]
train() client id: f_00002-8-2 loss: 1.268644  [   96/  124]
train() client id: f_00002-9-0 loss: 1.084027  [   32/  124]
train() client id: f_00002-9-1 loss: 1.338924  [   64/  124]
train() client id: f_00002-9-2 loss: 1.234766  [   96/  124]
train() client id: f_00002-10-0 loss: 1.049303  [   32/  124]
train() client id: f_00002-10-1 loss: 1.015751  [   64/  124]
train() client id: f_00002-10-2 loss: 1.352890  [   96/  124]
train() client id: f_00002-11-0 loss: 1.107630  [   32/  124]
train() client id: f_00002-11-1 loss: 1.152558  [   64/  124]
train() client id: f_00002-11-2 loss: 1.290788  [   96/  124]
train() client id: f_00002-12-0 loss: 1.321601  [   32/  124]
train() client id: f_00002-12-1 loss: 1.061014  [   64/  124]
train() client id: f_00002-12-2 loss: 1.199235  [   96/  124]
train() client id: f_00003-0-0 loss: 0.610157  [   32/   43]
train() client id: f_00003-1-0 loss: 0.497220  [   32/   43]
train() client id: f_00003-2-0 loss: 0.598055  [   32/   43]
train() client id: f_00003-3-0 loss: 0.564735  [   32/   43]
train() client id: f_00003-4-0 loss: 0.518155  [   32/   43]
train() client id: f_00003-5-0 loss: 0.673374  [   32/   43]
train() client id: f_00003-6-0 loss: 0.549229  [   32/   43]
train() client id: f_00003-7-0 loss: 0.742510  [   32/   43]
train() client id: f_00003-8-0 loss: 0.648151  [   32/   43]
train() client id: f_00003-9-0 loss: 0.622412  [   32/   43]
train() client id: f_00003-10-0 loss: 0.473245  [   32/   43]
train() client id: f_00003-11-0 loss: 0.732300  [   32/   43]
train() client id: f_00003-12-0 loss: 0.545152  [   32/   43]
train() client id: f_00004-0-0 loss: 0.694676  [   32/  306]
train() client id: f_00004-0-1 loss: 0.817978  [   64/  306]
train() client id: f_00004-0-2 loss: 0.920452  [   96/  306]
train() client id: f_00004-0-3 loss: 0.847862  [  128/  306]
train() client id: f_00004-0-4 loss: 0.643102  [  160/  306]
train() client id: f_00004-0-5 loss: 0.755260  [  192/  306]
train() client id: f_00004-0-6 loss: 0.738180  [  224/  306]
train() client id: f_00004-0-7 loss: 1.017598  [  256/  306]
train() client id: f_00004-0-8 loss: 0.552475  [  288/  306]
train() client id: f_00004-1-0 loss: 0.707052  [   32/  306]
train() client id: f_00004-1-1 loss: 0.808156  [   64/  306]
train() client id: f_00004-1-2 loss: 0.898040  [   96/  306]
train() client id: f_00004-1-3 loss: 0.764755  [  128/  306]
train() client id: f_00004-1-4 loss: 0.699581  [  160/  306]
train() client id: f_00004-1-5 loss: 0.760715  [  192/  306]
train() client id: f_00004-1-6 loss: 0.763496  [  224/  306]
train() client id: f_00004-1-7 loss: 0.911963  [  256/  306]
train() client id: f_00004-1-8 loss: 0.670691  [  288/  306]
train() client id: f_00004-2-0 loss: 0.795274  [   32/  306]
train() client id: f_00004-2-1 loss: 0.736647  [   64/  306]
train() client id: f_00004-2-2 loss: 0.735464  [   96/  306]
train() client id: f_00004-2-3 loss: 0.793272  [  128/  306]
train() client id: f_00004-2-4 loss: 0.792145  [  160/  306]
train() client id: f_00004-2-5 loss: 0.772404  [  192/  306]
train() client id: f_00004-2-6 loss: 0.786327  [  224/  306]
train() client id: f_00004-2-7 loss: 0.796208  [  256/  306]
train() client id: f_00004-2-8 loss: 0.704589  [  288/  306]
train() client id: f_00004-3-0 loss: 0.818924  [   32/  306]
train() client id: f_00004-3-1 loss: 0.708361  [   64/  306]
train() client id: f_00004-3-2 loss: 0.645777  [   96/  306]
train() client id: f_00004-3-3 loss: 0.750879  [  128/  306]
train() client id: f_00004-3-4 loss: 0.903684  [  160/  306]
train() client id: f_00004-3-5 loss: 0.786355  [  192/  306]
train() client id: f_00004-3-6 loss: 0.653001  [  224/  306]
train() client id: f_00004-3-7 loss: 0.719284  [  256/  306]
train() client id: f_00004-3-8 loss: 0.891310  [  288/  306]
train() client id: f_00004-4-0 loss: 0.782271  [   32/  306]
train() client id: f_00004-4-1 loss: 0.773835  [   64/  306]
train() client id: f_00004-4-2 loss: 0.747553  [   96/  306]
train() client id: f_00004-4-3 loss: 0.705695  [  128/  306]
train() client id: f_00004-4-4 loss: 0.689726  [  160/  306]
train() client id: f_00004-4-5 loss: 0.825218  [  192/  306]
train() client id: f_00004-4-6 loss: 0.744509  [  224/  306]
train() client id: f_00004-4-7 loss: 0.699923  [  256/  306]
train() client id: f_00004-4-8 loss: 0.797669  [  288/  306]
train() client id: f_00004-5-0 loss: 0.640243  [   32/  306]
train() client id: f_00004-5-1 loss: 0.820084  [   64/  306]
train() client id: f_00004-5-2 loss: 0.813375  [   96/  306]
train() client id: f_00004-5-3 loss: 0.786837  [  128/  306]
train() client id: f_00004-5-4 loss: 0.671873  [  160/  306]
train() client id: f_00004-5-5 loss: 0.690461  [  192/  306]
train() client id: f_00004-5-6 loss: 0.711704  [  224/  306]
train() client id: f_00004-5-7 loss: 0.896563  [  256/  306]
train() client id: f_00004-5-8 loss: 0.855670  [  288/  306]
train() client id: f_00004-6-0 loss: 0.694380  [   32/  306]
train() client id: f_00004-6-1 loss: 0.745370  [   64/  306]
train() client id: f_00004-6-2 loss: 0.861576  [   96/  306]
train() client id: f_00004-6-3 loss: 0.785568  [  128/  306]
train() client id: f_00004-6-4 loss: 0.729953  [  160/  306]
train() client id: f_00004-6-5 loss: 0.682006  [  192/  306]
train() client id: f_00004-6-6 loss: 0.860933  [  224/  306]
train() client id: f_00004-6-7 loss: 0.771982  [  256/  306]
train() client id: f_00004-6-8 loss: 0.695687  [  288/  306]
train() client id: f_00004-7-0 loss: 0.763938  [   32/  306]
train() client id: f_00004-7-1 loss: 0.825418  [   64/  306]
train() client id: f_00004-7-2 loss: 0.707346  [   96/  306]
train() client id: f_00004-7-3 loss: 0.771729  [  128/  306]
train() client id: f_00004-7-4 loss: 0.690480  [  160/  306]
train() client id: f_00004-7-5 loss: 0.809791  [  192/  306]
train() client id: f_00004-7-6 loss: 0.688484  [  224/  306]
train() client id: f_00004-7-7 loss: 0.792384  [  256/  306]
train() client id: f_00004-7-8 loss: 0.753196  [  288/  306]
train() client id: f_00004-8-0 loss: 0.794256  [   32/  306]
train() client id: f_00004-8-1 loss: 0.757763  [   64/  306]
train() client id: f_00004-8-2 loss: 0.719121  [   96/  306]
train() client id: f_00004-8-3 loss: 0.795016  [  128/  306]
train() client id: f_00004-8-4 loss: 0.707398  [  160/  306]
train() client id: f_00004-8-5 loss: 0.682790  [  192/  306]
train() client id: f_00004-8-6 loss: 0.802438  [  224/  306]
train() client id: f_00004-8-7 loss: 0.837918  [  256/  306]
train() client id: f_00004-8-8 loss: 0.771087  [  288/  306]
train() client id: f_00004-9-0 loss: 0.767110  [   32/  306]
train() client id: f_00004-9-1 loss: 0.771359  [   64/  306]
train() client id: f_00004-9-2 loss: 0.659504  [   96/  306]
train() client id: f_00004-9-3 loss: 0.790473  [  128/  306]
train() client id: f_00004-9-4 loss: 0.895704  [  160/  306]
train() client id: f_00004-9-5 loss: 0.829149  [  192/  306]
train() client id: f_00004-9-6 loss: 0.763688  [  224/  306]
train() client id: f_00004-9-7 loss: 0.597663  [  256/  306]
train() client id: f_00004-9-8 loss: 0.888655  [  288/  306]
train() client id: f_00004-10-0 loss: 0.799457  [   32/  306]
train() client id: f_00004-10-1 loss: 0.714472  [   64/  306]
train() client id: f_00004-10-2 loss: 0.787355  [   96/  306]
train() client id: f_00004-10-3 loss: 0.675420  [  128/  306]
train() client id: f_00004-10-4 loss: 0.776422  [  160/  306]
train() client id: f_00004-10-5 loss: 0.910084  [  192/  306]
train() client id: f_00004-10-6 loss: 0.826730  [  224/  306]
train() client id: f_00004-10-7 loss: 0.737511  [  256/  306]
train() client id: f_00004-10-8 loss: 0.697019  [  288/  306]
train() client id: f_00004-11-0 loss: 0.764873  [   32/  306]
train() client id: f_00004-11-1 loss: 0.871886  [   64/  306]
train() client id: f_00004-11-2 loss: 0.806544  [   96/  306]
train() client id: f_00004-11-3 loss: 0.722532  [  128/  306]
train() client id: f_00004-11-4 loss: 0.653224  [  160/  306]
train() client id: f_00004-11-5 loss: 0.645830  [  192/  306]
train() client id: f_00004-11-6 loss: 0.808395  [  224/  306]
train() client id: f_00004-11-7 loss: 0.742012  [  256/  306]
train() client id: f_00004-11-8 loss: 0.893414  [  288/  306]
train() client id: f_00004-12-0 loss: 0.671833  [   32/  306]
train() client id: f_00004-12-1 loss: 0.758459  [   64/  306]
train() client id: f_00004-12-2 loss: 0.905704  [   96/  306]
train() client id: f_00004-12-3 loss: 0.862226  [  128/  306]
train() client id: f_00004-12-4 loss: 0.647364  [  160/  306]
train() client id: f_00004-12-5 loss: 0.794268  [  192/  306]
train() client id: f_00004-12-6 loss: 0.803947  [  224/  306]
train() client id: f_00004-12-7 loss: 0.774191  [  256/  306]
train() client id: f_00004-12-8 loss: 0.695332  [  288/  306]
train() client id: f_00005-0-0 loss: 0.667234  [   32/  146]
train() client id: f_00005-0-1 loss: 0.631491  [   64/  146]
train() client id: f_00005-0-2 loss: 0.688174  [   96/  146]
train() client id: f_00005-0-3 loss: 0.412201  [  128/  146]
train() client id: f_00005-1-0 loss: 0.554885  [   32/  146]
train() client id: f_00005-1-1 loss: 0.890764  [   64/  146]
train() client id: f_00005-1-2 loss: 0.537339  [   96/  146]
train() client id: f_00005-1-3 loss: 0.549210  [  128/  146]
train() client id: f_00005-2-0 loss: 0.543819  [   32/  146]
train() client id: f_00005-2-1 loss: 0.647112  [   64/  146]
train() client id: f_00005-2-2 loss: 0.504565  [   96/  146]
train() client id: f_00005-2-3 loss: 0.641889  [  128/  146]
train() client id: f_00005-3-0 loss: 0.579636  [   32/  146]
train() client id: f_00005-3-1 loss: 0.686062  [   64/  146]
train() client id: f_00005-3-2 loss: 0.689700  [   96/  146]
train() client id: f_00005-3-3 loss: 0.438906  [  128/  146]
train() client id: f_00005-4-0 loss: 0.912646  [   32/  146]
train() client id: f_00005-4-1 loss: 0.429942  [   64/  146]
train() client id: f_00005-4-2 loss: 0.380507  [   96/  146]
train() client id: f_00005-4-3 loss: 0.647896  [  128/  146]
train() client id: f_00005-5-0 loss: 0.807374  [   32/  146]
train() client id: f_00005-5-1 loss: 0.594854  [   64/  146]
train() client id: f_00005-5-2 loss: 0.451552  [   96/  146]
train() client id: f_00005-5-3 loss: 0.512280  [  128/  146]
train() client id: f_00005-6-0 loss: 0.277314  [   32/  146]
train() client id: f_00005-6-1 loss: 0.599966  [   64/  146]
train() client id: f_00005-6-2 loss: 0.891960  [   96/  146]
train() client id: f_00005-6-3 loss: 0.611592  [  128/  146]
train() client id: f_00005-7-0 loss: 0.608958  [   32/  146]
train() client id: f_00005-7-1 loss: 0.868383  [   64/  146]
train() client id: f_00005-7-2 loss: 0.473397  [   96/  146]
train() client id: f_00005-7-3 loss: 0.511414  [  128/  146]
train() client id: f_00005-8-0 loss: 0.553347  [   32/  146]
train() client id: f_00005-8-1 loss: 0.589417  [   64/  146]
train() client id: f_00005-8-2 loss: 0.685127  [   96/  146]
train() client id: f_00005-8-3 loss: 0.515695  [  128/  146]
train() client id: f_00005-9-0 loss: 0.587595  [   32/  146]
train() client id: f_00005-9-1 loss: 0.582382  [   64/  146]
train() client id: f_00005-9-2 loss: 0.662821  [   96/  146]
train() client id: f_00005-9-3 loss: 0.498121  [  128/  146]
train() client id: f_00005-10-0 loss: 0.478208  [   32/  146]
train() client id: f_00005-10-1 loss: 0.539092  [   64/  146]
train() client id: f_00005-10-2 loss: 0.632140  [   96/  146]
train() client id: f_00005-10-3 loss: 0.463975  [  128/  146]
train() client id: f_00005-11-0 loss: 0.454279  [   32/  146]
train() client id: f_00005-11-1 loss: 0.628538  [   64/  146]
train() client id: f_00005-11-2 loss: 0.669729  [   96/  146]
train() client id: f_00005-11-3 loss: 0.387589  [  128/  146]
train() client id: f_00005-12-0 loss: 0.356445  [   32/  146]
train() client id: f_00005-12-1 loss: 0.295956  [   64/  146]
train() client id: f_00005-12-2 loss: 0.667704  [   96/  146]
train() client id: f_00005-12-3 loss: 0.821793  [  128/  146]
train() client id: f_00006-0-0 loss: 0.494153  [   32/   54]
train() client id: f_00006-1-0 loss: 0.547462  [   32/   54]
train() client id: f_00006-2-0 loss: 0.497979  [   32/   54]
train() client id: f_00006-3-0 loss: 0.497591  [   32/   54]
train() client id: f_00006-4-0 loss: 0.491605  [   32/   54]
train() client id: f_00006-5-0 loss: 0.583449  [   32/   54]
train() client id: f_00006-6-0 loss: 0.550002  [   32/   54]
train() client id: f_00006-7-0 loss: 0.535786  [   32/   54]
train() client id: f_00006-8-0 loss: 0.538817  [   32/   54]
train() client id: f_00006-9-0 loss: 0.579082  [   32/   54]
train() client id: f_00006-10-0 loss: 0.573709  [   32/   54]
train() client id: f_00006-11-0 loss: 0.556094  [   32/   54]
train() client id: f_00006-12-0 loss: 0.540253  [   32/   54]
train() client id: f_00007-0-0 loss: 0.695180  [   32/  179]
train() client id: f_00007-0-1 loss: 0.594685  [   64/  179]
train() client id: f_00007-0-2 loss: 0.799111  [   96/  179]
train() client id: f_00007-0-3 loss: 0.697156  [  128/  179]
train() client id: f_00007-0-4 loss: 0.942509  [  160/  179]
train() client id: f_00007-1-0 loss: 0.782256  [   32/  179]
train() client id: f_00007-1-1 loss: 0.672002  [   64/  179]
train() client id: f_00007-1-2 loss: 0.944480  [   96/  179]
train() client id: f_00007-1-3 loss: 0.602336  [  128/  179]
train() client id: f_00007-1-4 loss: 0.648549  [  160/  179]
train() client id: f_00007-2-0 loss: 0.552199  [   32/  179]
train() client id: f_00007-2-1 loss: 0.885283  [   64/  179]
train() client id: f_00007-2-2 loss: 0.711145  [   96/  179]
train() client id: f_00007-2-3 loss: 0.708707  [  128/  179]
train() client id: f_00007-2-4 loss: 0.759891  [  160/  179]
train() client id: f_00007-3-0 loss: 0.680858  [   32/  179]
train() client id: f_00007-3-1 loss: 0.990272  [   64/  179]
train() client id: f_00007-3-2 loss: 0.569532  [   96/  179]
train() client id: f_00007-3-3 loss: 0.580358  [  128/  179]
train() client id: f_00007-3-4 loss: 0.701367  [  160/  179]
train() client id: f_00007-4-0 loss: 0.936541  [   32/  179]
train() client id: f_00007-4-1 loss: 0.633370  [   64/  179]
train() client id: f_00007-4-2 loss: 0.649681  [   96/  179]
train() client id: f_00007-4-3 loss: 0.603309  [  128/  179]
train() client id: f_00007-4-4 loss: 0.619549  [  160/  179]
train() client id: f_00007-5-0 loss: 0.888884  [   32/  179]
train() client id: f_00007-5-1 loss: 0.516838  [   64/  179]
train() client id: f_00007-5-2 loss: 0.879086  [   96/  179]
train() client id: f_00007-5-3 loss: 0.584614  [  128/  179]
train() client id: f_00007-5-4 loss: 0.728297  [  160/  179]
train() client id: f_00007-6-0 loss: 0.734758  [   32/  179]
train() client id: f_00007-6-1 loss: 0.673268  [   64/  179]
train() client id: f_00007-6-2 loss: 0.559225  [   96/  179]
train() client id: f_00007-6-3 loss: 0.832931  [  128/  179]
train() client id: f_00007-6-4 loss: 0.632429  [  160/  179]
train() client id: f_00007-7-0 loss: 0.559354  [   32/  179]
train() client id: f_00007-7-1 loss: 0.769330  [   64/  179]
train() client id: f_00007-7-2 loss: 0.838192  [   96/  179]
train() client id: f_00007-7-3 loss: 0.710815  [  128/  179]
train() client id: f_00007-7-4 loss: 0.721439  [  160/  179]
train() client id: f_00007-8-0 loss: 0.975327  [   32/  179]
train() client id: f_00007-8-1 loss: 0.559110  [   64/  179]
train() client id: f_00007-8-2 loss: 0.743517  [   96/  179]
train() client id: f_00007-8-3 loss: 0.566964  [  128/  179]
train() client id: f_00007-8-4 loss: 0.702750  [  160/  179]
train() client id: f_00007-9-0 loss: 0.654832  [   32/  179]
train() client id: f_00007-9-1 loss: 0.740273  [   64/  179]
train() client id: f_00007-9-2 loss: 0.910851  [   96/  179]
train() client id: f_00007-9-3 loss: 0.553401  [  128/  179]
train() client id: f_00007-9-4 loss: 0.732776  [  160/  179]
train() client id: f_00007-10-0 loss: 0.627295  [   32/  179]
train() client id: f_00007-10-1 loss: 0.914530  [   64/  179]
train() client id: f_00007-10-2 loss: 0.577955  [   96/  179]
train() client id: f_00007-10-3 loss: 0.730642  [  128/  179]
train() client id: f_00007-10-4 loss: 0.647338  [  160/  179]
train() client id: f_00007-11-0 loss: 0.553865  [   32/  179]
train() client id: f_00007-11-1 loss: 0.619544  [   64/  179]
train() client id: f_00007-11-2 loss: 0.756212  [   96/  179]
train() client id: f_00007-11-3 loss: 0.785895  [  128/  179]
train() client id: f_00007-11-4 loss: 0.769453  [  160/  179]
train() client id: f_00007-12-0 loss: 0.732174  [   32/  179]
train() client id: f_00007-12-1 loss: 0.749116  [   64/  179]
train() client id: f_00007-12-2 loss: 0.523097  [   96/  179]
train() client id: f_00007-12-3 loss: 0.735699  [  128/  179]
train() client id: f_00007-12-4 loss: 0.676150  [  160/  179]
train() client id: f_00008-0-0 loss: 0.576606  [   32/  130]
train() client id: f_00008-0-1 loss: 0.677311  [   64/  130]
train() client id: f_00008-0-2 loss: 0.592627  [   96/  130]
train() client id: f_00008-0-3 loss: 0.704270  [  128/  130]
train() client id: f_00008-1-0 loss: 0.694279  [   32/  130]
train() client id: f_00008-1-1 loss: 0.547923  [   64/  130]
train() client id: f_00008-1-2 loss: 0.665229  [   96/  130]
train() client id: f_00008-1-3 loss: 0.633757  [  128/  130]
train() client id: f_00008-2-0 loss: 0.623122  [   32/  130]
train() client id: f_00008-2-1 loss: 0.644838  [   64/  130]
train() client id: f_00008-2-2 loss: 0.727795  [   96/  130]
train() client id: f_00008-2-3 loss: 0.564752  [  128/  130]
train() client id: f_00008-3-0 loss: 0.753894  [   32/  130]
train() client id: f_00008-3-1 loss: 0.638364  [   64/  130]
train() client id: f_00008-3-2 loss: 0.555077  [   96/  130]
train() client id: f_00008-3-3 loss: 0.608009  [  128/  130]
train() client id: f_00008-4-0 loss: 0.568970  [   32/  130]
train() client id: f_00008-4-1 loss: 0.710402  [   64/  130]
train() client id: f_00008-4-2 loss: 0.598914  [   96/  130]
train() client id: f_00008-4-3 loss: 0.678154  [  128/  130]
train() client id: f_00008-5-0 loss: 0.543137  [   32/  130]
train() client id: f_00008-5-1 loss: 0.593606  [   64/  130]
train() client id: f_00008-5-2 loss: 0.603251  [   96/  130]
train() client id: f_00008-5-3 loss: 0.810688  [  128/  130]
train() client id: f_00008-6-0 loss: 0.615381  [   32/  130]
train() client id: f_00008-6-1 loss: 0.616052  [   64/  130]
train() client id: f_00008-6-2 loss: 0.600909  [   96/  130]
train() client id: f_00008-6-3 loss: 0.640026  [  128/  130]
train() client id: f_00008-7-0 loss: 0.603620  [   32/  130]
train() client id: f_00008-7-1 loss: 0.511442  [   64/  130]
train() client id: f_00008-7-2 loss: 0.687400  [   96/  130]
train() client id: f_00008-7-3 loss: 0.704860  [  128/  130]
train() client id: f_00008-8-0 loss: 0.685422  [   32/  130]
train() client id: f_00008-8-1 loss: 0.638522  [   64/  130]
train() client id: f_00008-8-2 loss: 0.629213  [   96/  130]
train() client id: f_00008-8-3 loss: 0.589742  [  128/  130]
train() client id: f_00008-9-0 loss: 0.758685  [   32/  130]
train() client id: f_00008-9-1 loss: 0.546272  [   64/  130]
train() client id: f_00008-9-2 loss: 0.624544  [   96/  130]
train() client id: f_00008-9-3 loss: 0.585571  [  128/  130]
train() client id: f_00008-10-0 loss: 0.751853  [   32/  130]
train() client id: f_00008-10-1 loss: 0.612641  [   64/  130]
train() client id: f_00008-10-2 loss: 0.678454  [   96/  130]
train() client id: f_00008-10-3 loss: 0.494006  [  128/  130]
train() client id: f_00008-11-0 loss: 0.554811  [   32/  130]
train() client id: f_00008-11-1 loss: 0.758195  [   64/  130]
train() client id: f_00008-11-2 loss: 0.625810  [   96/  130]
train() client id: f_00008-11-3 loss: 0.580584  [  128/  130]
train() client id: f_00008-12-0 loss: 0.535077  [   32/  130]
train() client id: f_00008-12-1 loss: 0.673455  [   64/  130]
train() client id: f_00008-12-2 loss: 0.715578  [   96/  130]
train() client id: f_00008-12-3 loss: 0.593600  [  128/  130]
train() client id: f_00009-0-0 loss: 1.105946  [   32/  118]
train() client id: f_00009-0-1 loss: 1.116254  [   64/  118]
train() client id: f_00009-0-2 loss: 1.116336  [   96/  118]
train() client id: f_00009-1-0 loss: 1.104287  [   32/  118]
train() client id: f_00009-1-1 loss: 1.074790  [   64/  118]
train() client id: f_00009-1-2 loss: 1.056054  [   96/  118]
train() client id: f_00009-2-0 loss: 1.053751  [   32/  118]
train() client id: f_00009-2-1 loss: 1.013532  [   64/  118]
train() client id: f_00009-2-2 loss: 1.009045  [   96/  118]
train() client id: f_00009-3-0 loss: 1.017990  [   32/  118]
train() client id: f_00009-3-1 loss: 1.053072  [   64/  118]
train() client id: f_00009-3-2 loss: 0.829091  [   96/  118]
train() client id: f_00009-4-0 loss: 0.996341  [   32/  118]
train() client id: f_00009-4-1 loss: 1.111930  [   64/  118]
train() client id: f_00009-4-2 loss: 0.907369  [   96/  118]
train() client id: f_00009-5-0 loss: 1.094782  [   32/  118]
train() client id: f_00009-5-1 loss: 0.843029  [   64/  118]
train() client id: f_00009-5-2 loss: 0.890221  [   96/  118]
train() client id: f_00009-6-0 loss: 0.836034  [   32/  118]
train() client id: f_00009-6-1 loss: 0.938925  [   64/  118]
train() client id: f_00009-6-2 loss: 0.903233  [   96/  118]
train() client id: f_00009-7-0 loss: 0.878447  [   32/  118]
train() client id: f_00009-7-1 loss: 1.018980  [   64/  118]
train() client id: f_00009-7-2 loss: 0.839938  [   96/  118]
train() client id: f_00009-8-0 loss: 0.784650  [   32/  118]
train() client id: f_00009-8-1 loss: 1.071970  [   64/  118]
train() client id: f_00009-8-2 loss: 0.882792  [   96/  118]
train() client id: f_00009-9-0 loss: 0.933627  [   32/  118]
train() client id: f_00009-9-1 loss: 0.940443  [   64/  118]
train() client id: f_00009-9-2 loss: 0.828192  [   96/  118]
train() client id: f_00009-10-0 loss: 0.877189  [   32/  118]
train() client id: f_00009-10-1 loss: 0.817464  [   64/  118]
train() client id: f_00009-10-2 loss: 0.997621  [   96/  118]
train() client id: f_00009-11-0 loss: 0.853400  [   32/  118]
train() client id: f_00009-11-1 loss: 0.882873  [   64/  118]
train() client id: f_00009-11-2 loss: 0.869787  [   96/  118]
train() client id: f_00009-12-0 loss: 1.007153  [   32/  118]
train() client id: f_00009-12-1 loss: 0.838695  [   64/  118]
train() client id: f_00009-12-2 loss: 0.905085  [   96/  118]
At round 26 accuracy: 0.6392572944297082
At round 26 training accuracy: 0.5875251509054326
At round 26 training loss: 0.8274552921709794
gradient difference: 0.4022590219974518
train() client id: f_00000-0-0 loss: 1.224595  [   32/  126]
train() client id: f_00000-0-1 loss: 1.212322  [   64/  126]
train() client id: f_00000-0-2 loss: 1.083457  [   96/  126]
train() client id: f_00000-1-0 loss: 1.045378  [   32/  126]
train() client id: f_00000-1-1 loss: 1.206397  [   64/  126]
train() client id: f_00000-1-2 loss: 0.939214  [   96/  126]
train() client id: f_00000-2-0 loss: 1.108620  [   32/  126]
train() client id: f_00000-2-1 loss: 1.004971  [   64/  126]
train() client id: f_00000-2-2 loss: 1.012175  [   96/  126]
train() client id: f_00000-3-0 loss: 1.151748  [   32/  126]
train() client id: f_00000-3-1 loss: 0.882829  [   64/  126]
train() client id: f_00000-3-2 loss: 1.023670  [   96/  126]
train() client id: f_00000-4-0 loss: 0.931642  [   32/  126]
train() client id: f_00000-4-1 loss: 0.973647  [   64/  126]
train() client id: f_00000-4-2 loss: 1.058414  [   96/  126]
train() client id: f_00000-5-0 loss: 0.909937  [   32/  126]
train() client id: f_00000-5-1 loss: 0.903133  [   64/  126]
train() client id: f_00000-5-2 loss: 1.005632  [   96/  126]
train() client id: f_00000-6-0 loss: 0.932749  [   32/  126]
train() client id: f_00000-6-1 loss: 0.923616  [   64/  126]
train() client id: f_00000-6-2 loss: 0.994090  [   96/  126]
train() client id: f_00000-7-0 loss: 0.931947  [   32/  126]
train() client id: f_00000-7-1 loss: 0.864159  [   64/  126]
train() client id: f_00000-7-2 loss: 1.002039  [   96/  126]
train() client id: f_00000-8-0 loss: 0.876909  [   32/  126]
train() client id: f_00000-8-1 loss: 0.878255  [   64/  126]
train() client id: f_00000-8-2 loss: 0.968513  [   96/  126]
train() client id: f_00000-9-0 loss: 0.903638  [   32/  126]
train() client id: f_00000-9-1 loss: 0.959044  [   64/  126]
train() client id: f_00000-9-2 loss: 0.802914  [   96/  126]
train() client id: f_00000-10-0 loss: 0.972215  [   32/  126]
train() client id: f_00000-10-1 loss: 0.935070  [   64/  126]
train() client id: f_00000-10-2 loss: 0.836656  [   96/  126]
train() client id: f_00000-11-0 loss: 0.811970  [   32/  126]
train() client id: f_00000-11-1 loss: 0.824389  [   64/  126]
train() client id: f_00000-11-2 loss: 0.973708  [   96/  126]
train() client id: f_00000-12-0 loss: 1.018885  [   32/  126]
train() client id: f_00000-12-1 loss: 0.746450  [   64/  126]
train() client id: f_00000-12-2 loss: 1.050028  [   96/  126]
train() client id: f_00001-0-0 loss: 0.411210  [   32/  265]
train() client id: f_00001-0-1 loss: 0.492946  [   64/  265]
train() client id: f_00001-0-2 loss: 0.355362  [   96/  265]
train() client id: f_00001-0-3 loss: 0.430478  [  128/  265]
train() client id: f_00001-0-4 loss: 0.577582  [  160/  265]
train() client id: f_00001-0-5 loss: 0.426816  [  192/  265]
train() client id: f_00001-0-6 loss: 0.389647  [  224/  265]
train() client id: f_00001-0-7 loss: 0.403000  [  256/  265]
train() client id: f_00001-1-0 loss: 0.525821  [   32/  265]
train() client id: f_00001-1-1 loss: 0.387821  [   64/  265]
train() client id: f_00001-1-2 loss: 0.431838  [   96/  265]
train() client id: f_00001-1-3 loss: 0.377253  [  128/  265]
train() client id: f_00001-1-4 loss: 0.420444  [  160/  265]
train() client id: f_00001-1-5 loss: 0.336827  [  192/  265]
train() client id: f_00001-1-6 loss: 0.444903  [  224/  265]
train() client id: f_00001-1-7 loss: 0.481311  [  256/  265]
train() client id: f_00001-2-0 loss: 0.363440  [   32/  265]
train() client id: f_00001-2-1 loss: 0.382123  [   64/  265]
train() client id: f_00001-2-2 loss: 0.385719  [   96/  265]
train() client id: f_00001-2-3 loss: 0.333125  [  128/  265]
train() client id: f_00001-2-4 loss: 0.428455  [  160/  265]
train() client id: f_00001-2-5 loss: 0.474987  [  192/  265]
train() client id: f_00001-2-6 loss: 0.587034  [  224/  265]
train() client id: f_00001-2-7 loss: 0.390343  [  256/  265]
train() client id: f_00001-3-0 loss: 0.379892  [   32/  265]
train() client id: f_00001-3-1 loss: 0.483964  [   64/  265]
train() client id: f_00001-3-2 loss: 0.377588  [   96/  265]
train() client id: f_00001-3-3 loss: 0.314275  [  128/  265]
train() client id: f_00001-3-4 loss: 0.485499  [  160/  265]
train() client id: f_00001-3-5 loss: 0.411201  [  192/  265]
train() client id: f_00001-3-6 loss: 0.368263  [  224/  265]
train() client id: f_00001-3-7 loss: 0.453407  [  256/  265]
train() client id: f_00001-4-0 loss: 0.397076  [   32/  265]
train() client id: f_00001-4-1 loss: 0.433584  [   64/  265]
train() client id: f_00001-4-2 loss: 0.335582  [   96/  265]
train() client id: f_00001-4-3 loss: 0.449933  [  128/  265]
train() client id: f_00001-4-4 loss: 0.437442  [  160/  265]
train() client id: f_00001-4-5 loss: 0.484416  [  192/  265]
train() client id: f_00001-4-6 loss: 0.321976  [  224/  265]
train() client id: f_00001-4-7 loss: 0.411169  [  256/  265]
train() client id: f_00001-5-0 loss: 0.347815  [   32/  265]
train() client id: f_00001-5-1 loss: 0.402326  [   64/  265]
train() client id: f_00001-5-2 loss: 0.310520  [   96/  265]
train() client id: f_00001-5-3 loss: 0.517119  [  128/  265]
train() client id: f_00001-5-4 loss: 0.443425  [  160/  265]
train() client id: f_00001-5-5 loss: 0.443107  [  192/  265]
train() client id: f_00001-5-6 loss: 0.328807  [  224/  265]
train() client id: f_00001-5-7 loss: 0.382905  [  256/  265]
train() client id: f_00001-6-0 loss: 0.342486  [   32/  265]
train() client id: f_00001-6-1 loss: 0.366637  [   64/  265]
train() client id: f_00001-6-2 loss: 0.437684  [   96/  265]
train() client id: f_00001-6-3 loss: 0.335515  [  128/  265]
train() client id: f_00001-6-4 loss: 0.562496  [  160/  265]
train() client id: f_00001-6-5 loss: 0.369965  [  192/  265]
train() client id: f_00001-6-6 loss: 0.412446  [  224/  265]
train() client id: f_00001-6-7 loss: 0.353780  [  256/  265]
train() client id: f_00001-7-0 loss: 0.445576  [   32/  265]
train() client id: f_00001-7-1 loss: 0.296815  [   64/  265]
train() client id: f_00001-7-2 loss: 0.363755  [   96/  265]
train() client id: f_00001-7-3 loss: 0.487207  [  128/  265]
train() client id: f_00001-7-4 loss: 0.302069  [  160/  265]
train() client id: f_00001-7-5 loss: 0.438127  [  192/  265]
train() client id: f_00001-7-6 loss: 0.362667  [  224/  265]
train() client id: f_00001-7-7 loss: 0.527074  [  256/  265]
train() client id: f_00001-8-0 loss: 0.401701  [   32/  265]
train() client id: f_00001-8-1 loss: 0.419304  [   64/  265]
train() client id: f_00001-8-2 loss: 0.431327  [   96/  265]
train() client id: f_00001-8-3 loss: 0.309832  [  128/  265]
train() client id: f_00001-8-4 loss: 0.391878  [  160/  265]
train() client id: f_00001-8-5 loss: 0.369837  [  192/  265]
train() client id: f_00001-8-6 loss: 0.392334  [  224/  265]
train() client id: f_00001-8-7 loss: 0.503556  [  256/  265]
train() client id: f_00001-9-0 loss: 0.385045  [   32/  265]
train() client id: f_00001-9-1 loss: 0.447802  [   64/  265]
train() client id: f_00001-9-2 loss: 0.390186  [   96/  265]
train() client id: f_00001-9-3 loss: 0.300404  [  128/  265]
train() client id: f_00001-9-4 loss: 0.403625  [  160/  265]
train() client id: f_00001-9-5 loss: 0.423163  [  192/  265]
train() client id: f_00001-9-6 loss: 0.364175  [  224/  265]
train() client id: f_00001-9-7 loss: 0.502795  [  256/  265]
train() client id: f_00001-10-0 loss: 0.344557  [   32/  265]
train() client id: f_00001-10-1 loss: 0.339643  [   64/  265]
train() client id: f_00001-10-2 loss: 0.347777  [   96/  265]
train() client id: f_00001-10-3 loss: 0.476657  [  128/  265]
train() client id: f_00001-10-4 loss: 0.409135  [  160/  265]
train() client id: f_00001-10-5 loss: 0.373086  [  192/  265]
train() client id: f_00001-10-6 loss: 0.489961  [  224/  265]
train() client id: f_00001-10-7 loss: 0.422735  [  256/  265]
train() client id: f_00001-11-0 loss: 0.413791  [   32/  265]
train() client id: f_00001-11-1 loss: 0.303332  [   64/  265]
train() client id: f_00001-11-2 loss: 0.470394  [   96/  265]
train() client id: f_00001-11-3 loss: 0.435894  [  128/  265]
train() client id: f_00001-11-4 loss: 0.393040  [  160/  265]
train() client id: f_00001-11-5 loss: 0.377089  [  192/  265]
train() client id: f_00001-11-6 loss: 0.408793  [  224/  265]
train() client id: f_00001-11-7 loss: 0.403131  [  256/  265]
train() client id: f_00001-12-0 loss: 0.476309  [   32/  265]
train() client id: f_00001-12-1 loss: 0.483170  [   64/  265]
train() client id: f_00001-12-2 loss: 0.389856  [   96/  265]
train() client id: f_00001-12-3 loss: 0.385857  [  128/  265]
train() client id: f_00001-12-4 loss: 0.394662  [  160/  265]
train() client id: f_00001-12-5 loss: 0.311794  [  192/  265]
train() client id: f_00001-12-6 loss: 0.357192  [  224/  265]
train() client id: f_00001-12-7 loss: 0.358096  [  256/  265]
train() client id: f_00002-0-0 loss: 1.202874  [   32/  124]
train() client id: f_00002-0-1 loss: 1.123172  [   64/  124]
train() client id: f_00002-0-2 loss: 1.274756  [   96/  124]
train() client id: f_00002-1-0 loss: 1.261061  [   32/  124]
train() client id: f_00002-1-1 loss: 1.222382  [   64/  124]
train() client id: f_00002-1-2 loss: 1.078774  [   96/  124]
train() client id: f_00002-2-0 loss: 1.236097  [   32/  124]
train() client id: f_00002-2-1 loss: 1.124295  [   64/  124]
train() client id: f_00002-2-2 loss: 1.132339  [   96/  124]
train() client id: f_00002-3-0 loss: 1.076309  [   32/  124]
train() client id: f_00002-3-1 loss: 1.178889  [   64/  124]
train() client id: f_00002-3-2 loss: 1.044189  [   96/  124]
train() client id: f_00002-4-0 loss: 1.202609  [   32/  124]
train() client id: f_00002-4-1 loss: 0.981861  [   64/  124]
train() client id: f_00002-4-2 loss: 0.980895  [   96/  124]
train() client id: f_00002-5-0 loss: 1.183442  [   32/  124]
train() client id: f_00002-5-1 loss: 1.082531  [   64/  124]
train() client id: f_00002-5-2 loss: 0.957153  [   96/  124]
train() client id: f_00002-6-0 loss: 0.921086  [   32/  124]
train() client id: f_00002-6-1 loss: 0.948343  [   64/  124]
train() client id: f_00002-6-2 loss: 1.249710  [   96/  124]
train() client id: f_00002-7-0 loss: 1.041960  [   32/  124]
train() client id: f_00002-7-1 loss: 1.076769  [   64/  124]
train() client id: f_00002-7-2 loss: 0.956301  [   96/  124]
train() client id: f_00002-8-0 loss: 1.029738  [   32/  124]
train() client id: f_00002-8-1 loss: 1.033753  [   64/  124]
train() client id: f_00002-8-2 loss: 0.978742  [   96/  124]
train() client id: f_00002-9-0 loss: 1.003422  [   32/  124]
train() client id: f_00002-9-1 loss: 1.064608  [   64/  124]
train() client id: f_00002-9-2 loss: 0.940038  [   96/  124]
train() client id: f_00002-10-0 loss: 0.949410  [   32/  124]
train() client id: f_00002-10-1 loss: 0.910129  [   64/  124]
train() client id: f_00002-10-2 loss: 1.141289  [   96/  124]
train() client id: f_00002-11-0 loss: 0.931953  [   32/  124]
train() client id: f_00002-11-1 loss: 0.971709  [   64/  124]
train() client id: f_00002-11-2 loss: 0.919307  [   96/  124]
train() client id: f_00002-12-0 loss: 1.150869  [   32/  124]
train() client id: f_00002-12-1 loss: 0.830441  [   64/  124]
train() client id: f_00002-12-2 loss: 1.001896  [   96/  124]
train() client id: f_00003-0-0 loss: 0.873257  [   32/   43]
train() client id: f_00003-1-0 loss: 0.828937  [   32/   43]
train() client id: f_00003-2-0 loss: 0.705583  [   32/   43]
train() client id: f_00003-3-0 loss: 0.904786  [   32/   43]
train() client id: f_00003-4-0 loss: 0.787207  [   32/   43]
train() client id: f_00003-5-0 loss: 0.822285  [   32/   43]
train() client id: f_00003-6-0 loss: 0.877132  [   32/   43]
train() client id: f_00003-7-0 loss: 0.922058  [   32/   43]
train() client id: f_00003-8-0 loss: 0.833659  [   32/   43]
train() client id: f_00003-9-0 loss: 0.577830  [   32/   43]
train() client id: f_00003-10-0 loss: 0.721130  [   32/   43]
train() client id: f_00003-11-0 loss: 0.526700  [   32/   43]
train() client id: f_00003-12-0 loss: 0.867396  [   32/   43]
train() client id: f_00004-0-0 loss: 0.899844  [   32/  306]
train() client id: f_00004-0-1 loss: 0.906958  [   64/  306]
train() client id: f_00004-0-2 loss: 0.870583  [   96/  306]
train() client id: f_00004-0-3 loss: 0.948443  [  128/  306]
train() client id: f_00004-0-4 loss: 0.947897  [  160/  306]
train() client id: f_00004-0-5 loss: 0.924325  [  192/  306]
train() client id: f_00004-0-6 loss: 1.007246  [  224/  306]
train() client id: f_00004-0-7 loss: 0.949829  [  256/  306]
train() client id: f_00004-0-8 loss: 0.952922  [  288/  306]
train() client id: f_00004-1-0 loss: 0.908434  [   32/  306]
train() client id: f_00004-1-1 loss: 1.032289  [   64/  306]
train() client id: f_00004-1-2 loss: 0.826892  [   96/  306]
train() client id: f_00004-1-3 loss: 0.878268  [  128/  306]
train() client id: f_00004-1-4 loss: 0.936015  [  160/  306]
train() client id: f_00004-1-5 loss: 0.872861  [  192/  306]
train() client id: f_00004-1-6 loss: 1.016793  [  224/  306]
train() client id: f_00004-1-7 loss: 1.038290  [  256/  306]
train() client id: f_00004-1-8 loss: 0.817678  [  288/  306]
train() client id: f_00004-2-0 loss: 0.825622  [   32/  306]
train() client id: f_00004-2-1 loss: 0.996620  [   64/  306]
train() client id: f_00004-2-2 loss: 1.055886  [   96/  306]
train() client id: f_00004-2-3 loss: 0.944795  [  128/  306]
train() client id: f_00004-2-4 loss: 0.994888  [  160/  306]
train() client id: f_00004-2-5 loss: 0.905544  [  192/  306]
train() client id: f_00004-2-6 loss: 0.951687  [  224/  306]
train() client id: f_00004-2-7 loss: 0.697600  [  256/  306]
train() client id: f_00004-2-8 loss: 0.869795  [  288/  306]
train() client id: f_00004-3-0 loss: 0.844713  [   32/  306]
train() client id: f_00004-3-1 loss: 1.046313  [   64/  306]
train() client id: f_00004-3-2 loss: 0.858011  [   96/  306]
train() client id: f_00004-3-3 loss: 1.003308  [  128/  306]
train() client id: f_00004-3-4 loss: 0.913578  [  160/  306]
train() client id: f_00004-3-5 loss: 1.001813  [  192/  306]
train() client id: f_00004-3-6 loss: 0.967301  [  224/  306]
train() client id: f_00004-3-7 loss: 0.931644  [  256/  306]
train() client id: f_00004-3-8 loss: 0.750790  [  288/  306]
train() client id: f_00004-4-0 loss: 0.921226  [   32/  306]
train() client id: f_00004-4-1 loss: 0.843301  [   64/  306]
train() client id: f_00004-4-2 loss: 0.851442  [   96/  306]
train() client id: f_00004-4-3 loss: 0.940195  [  128/  306]
train() client id: f_00004-4-4 loss: 0.887387  [  160/  306]
train() client id: f_00004-4-5 loss: 0.948104  [  192/  306]
train() client id: f_00004-4-6 loss: 0.913278  [  224/  306]
train() client id: f_00004-4-7 loss: 0.832546  [  256/  306]
train() client id: f_00004-4-8 loss: 1.043607  [  288/  306]
train() client id: f_00004-5-0 loss: 0.871377  [   32/  306]
train() client id: f_00004-5-1 loss: 0.887622  [   64/  306]
train() client id: f_00004-5-2 loss: 1.019005  [   96/  306]
train() client id: f_00004-5-3 loss: 0.948902  [  128/  306]
train() client id: f_00004-5-4 loss: 0.895499  [  160/  306]
train() client id: f_00004-5-5 loss: 0.828553  [  192/  306]
train() client id: f_00004-5-6 loss: 0.910185  [  224/  306]
train() client id: f_00004-5-7 loss: 1.050351  [  256/  306]
train() client id: f_00004-5-8 loss: 0.888715  [  288/  306]
train() client id: f_00004-6-0 loss: 0.946736  [   32/  306]
train() client id: f_00004-6-1 loss: 0.924965  [   64/  306]
train() client id: f_00004-6-2 loss: 0.882408  [   96/  306]
train() client id: f_00004-6-3 loss: 0.835016  [  128/  306]
train() client id: f_00004-6-4 loss: 0.933838  [  160/  306]
train() client id: f_00004-6-5 loss: 1.039982  [  192/  306]
train() client id: f_00004-6-6 loss: 0.999270  [  224/  306]
train() client id: f_00004-6-7 loss: 0.801402  [  256/  306]
train() client id: f_00004-6-8 loss: 0.917377  [  288/  306]
train() client id: f_00004-7-0 loss: 0.903615  [   32/  306]
train() client id: f_00004-7-1 loss: 0.931887  [   64/  306]
train() client id: f_00004-7-2 loss: 0.956195  [   96/  306]
train() client id: f_00004-7-3 loss: 0.908505  [  128/  306]
train() client id: f_00004-7-4 loss: 0.842465  [  160/  306]
train() client id: f_00004-7-5 loss: 0.882210  [  192/  306]
train() client id: f_00004-7-6 loss: 0.859879  [  224/  306]
train() client id: f_00004-7-7 loss: 0.841431  [  256/  306]
train() client id: f_00004-7-8 loss: 1.030169  [  288/  306]
train() client id: f_00004-8-0 loss: 1.017768  [   32/  306]
train() client id: f_00004-8-1 loss: 0.812826  [   64/  306]
train() client id: f_00004-8-2 loss: 0.867977  [   96/  306]
train() client id: f_00004-8-3 loss: 0.842349  [  128/  306]
train() client id: f_00004-8-4 loss: 0.947522  [  160/  306]
train() client id: f_00004-8-5 loss: 0.812316  [  192/  306]
train() client id: f_00004-8-6 loss: 1.036696  [  224/  306]
train() client id: f_00004-8-7 loss: 0.942955  [  256/  306]
train() client id: f_00004-8-8 loss: 0.952653  [  288/  306]
train() client id: f_00004-9-0 loss: 0.944462  [   32/  306]
train() client id: f_00004-9-1 loss: 0.936340  [   64/  306]
train() client id: f_00004-9-2 loss: 0.833704  [   96/  306]
train() client id: f_00004-9-3 loss: 0.951705  [  128/  306]
train() client id: f_00004-9-4 loss: 0.951464  [  160/  306]
train() client id: f_00004-9-5 loss: 0.877845  [  192/  306]
train() client id: f_00004-9-6 loss: 0.965114  [  224/  306]
train() client id: f_00004-9-7 loss: 0.935743  [  256/  306]
train() client id: f_00004-9-8 loss: 0.828560  [  288/  306]
train() client id: f_00004-10-0 loss: 0.897862  [   32/  306]
train() client id: f_00004-10-1 loss: 0.919628  [   64/  306]
train() client id: f_00004-10-2 loss: 0.917329  [   96/  306]
train() client id: f_00004-10-3 loss: 0.965578  [  128/  306]
train() client id: f_00004-10-4 loss: 0.987027  [  160/  306]
train() client id: f_00004-10-5 loss: 0.825601  [  192/  306]
train() client id: f_00004-10-6 loss: 0.904338  [  224/  306]
train() client id: f_00004-10-7 loss: 0.850912  [  256/  306]
train() client id: f_00004-10-8 loss: 0.865180  [  288/  306]
train() client id: f_00004-11-0 loss: 1.129062  [   32/  306]
train() client id: f_00004-11-1 loss: 0.919648  [   64/  306]
train() client id: f_00004-11-2 loss: 0.837801  [   96/  306]
train() client id: f_00004-11-3 loss: 0.786982  [  128/  306]
train() client id: f_00004-11-4 loss: 0.799066  [  160/  306]
train() client id: f_00004-11-5 loss: 0.885637  [  192/  306]
train() client id: f_00004-11-6 loss: 0.954724  [  224/  306]
train() client id: f_00004-11-7 loss: 0.949651  [  256/  306]
train() client id: f_00004-11-8 loss: 0.935973  [  288/  306]
train() client id: f_00004-12-0 loss: 0.981698  [   32/  306]
train() client id: f_00004-12-1 loss: 0.868270  [   64/  306]
train() client id: f_00004-12-2 loss: 0.862581  [   96/  306]
train() client id: f_00004-12-3 loss: 0.899701  [  128/  306]
train() client id: f_00004-12-4 loss: 0.894541  [  160/  306]
train() client id: f_00004-12-5 loss: 0.900520  [  192/  306]
train() client id: f_00004-12-6 loss: 0.902880  [  224/  306]
train() client id: f_00004-12-7 loss: 1.011477  [  256/  306]
train() client id: f_00004-12-8 loss: 0.828754  [  288/  306]
train() client id: f_00005-0-0 loss: 0.305050  [   32/  146]
train() client id: f_00005-0-1 loss: 0.347120  [   64/  146]
train() client id: f_00005-0-2 loss: 0.506776  [   96/  146]
train() client id: f_00005-0-3 loss: 0.726055  [  128/  146]
train() client id: f_00005-1-0 loss: 0.608879  [   32/  146]
train() client id: f_00005-1-1 loss: 0.423827  [   64/  146]
train() client id: f_00005-1-2 loss: 0.282114  [   96/  146]
train() client id: f_00005-1-3 loss: 0.440040  [  128/  146]
train() client id: f_00005-2-0 loss: 0.466169  [   32/  146]
train() client id: f_00005-2-1 loss: 0.314861  [   64/  146]
train() client id: f_00005-2-2 loss: 0.485255  [   96/  146]
train() client id: f_00005-2-3 loss: 0.526122  [  128/  146]
train() client id: f_00005-3-0 loss: 0.384504  [   32/  146]
train() client id: f_00005-3-1 loss: 0.436128  [   64/  146]
train() client id: f_00005-3-2 loss: 0.332641  [   96/  146]
train() client id: f_00005-3-3 loss: 0.491561  [  128/  146]
train() client id: f_00005-4-0 loss: 0.308276  [   32/  146]
train() client id: f_00005-4-1 loss: 0.486011  [   64/  146]
train() client id: f_00005-4-2 loss: 0.491652  [   96/  146]
train() client id: f_00005-4-3 loss: 0.410943  [  128/  146]
train() client id: f_00005-5-0 loss: 0.355193  [   32/  146]
train() client id: f_00005-5-1 loss: 0.334633  [   64/  146]
train() client id: f_00005-5-2 loss: 0.464996  [   96/  146]
train() client id: f_00005-5-3 loss: 0.469499  [  128/  146]
train() client id: f_00005-6-0 loss: 0.083700  [   32/  146]
train() client id: f_00005-6-1 loss: 0.673110  [   64/  146]
train() client id: f_00005-6-2 loss: 0.495947  [   96/  146]
train() client id: f_00005-6-3 loss: 0.323649  [  128/  146]
train() client id: f_00005-7-0 loss: 0.268439  [   32/  146]
train() client id: f_00005-7-1 loss: 0.314901  [   64/  146]
train() client id: f_00005-7-2 loss: 0.467817  [   96/  146]
train() client id: f_00005-7-3 loss: 0.426974  [  128/  146]
train() client id: f_00005-8-0 loss: 0.592354  [   32/  146]
train() client id: f_00005-8-1 loss: 0.540179  [   64/  146]
train() client id: f_00005-8-2 loss: 0.117983  [   96/  146]
train() client id: f_00005-8-3 loss: 0.487283  [  128/  146]
train() client id: f_00005-9-0 loss: 0.545510  [   32/  146]
train() client id: f_00005-9-1 loss: 0.411985  [   64/  146]
train() client id: f_00005-9-2 loss: 0.420159  [   96/  146]
train() client id: f_00005-9-3 loss: 0.310048  [  128/  146]
train() client id: f_00005-10-0 loss: 0.428025  [   32/  146]
train() client id: f_00005-10-1 loss: 0.541444  [   64/  146]
train() client id: f_00005-10-2 loss: 0.543428  [   96/  146]
train() client id: f_00005-10-3 loss: 0.221910  [  128/  146]
train() client id: f_00005-11-0 loss: 0.283328  [   32/  146]
train() client id: f_00005-11-1 loss: 0.314183  [   64/  146]
train() client id: f_00005-11-2 loss: 0.594497  [   96/  146]
train() client id: f_00005-11-3 loss: 0.408742  [  128/  146]
train() client id: f_00005-12-0 loss: 0.468368  [   32/  146]
train() client id: f_00005-12-1 loss: 0.289842  [   64/  146]
train() client id: f_00005-12-2 loss: 0.435947  [   96/  146]
train() client id: f_00005-12-3 loss: 0.507891  [  128/  146]
train() client id: f_00006-0-0 loss: 0.528680  [   32/   54]
train() client id: f_00006-1-0 loss: 0.528582  [   32/   54]
train() client id: f_00006-2-0 loss: 0.542355  [   32/   54]
train() client id: f_00006-3-0 loss: 0.552433  [   32/   54]
train() client id: f_00006-4-0 loss: 0.497442  [   32/   54]
train() client id: f_00006-5-0 loss: 0.487554  [   32/   54]
train() client id: f_00006-6-0 loss: 0.529616  [   32/   54]
train() client id: f_00006-7-0 loss: 0.538185  [   32/   54]
train() client id: f_00006-8-0 loss: 0.580058  [   32/   54]
train() client id: f_00006-9-0 loss: 0.527500  [   32/   54]
train() client id: f_00006-10-0 loss: 0.560292  [   32/   54]
train() client id: f_00006-11-0 loss: 0.477912  [   32/   54]
train() client id: f_00006-12-0 loss: 0.587749  [   32/   54]
train() client id: f_00007-0-0 loss: 0.752843  [   32/  179]
train() client id: f_00007-0-1 loss: 0.499107  [   64/  179]
train() client id: f_00007-0-2 loss: 0.740854  [   96/  179]
train() client id: f_00007-0-3 loss: 0.531687  [  128/  179]
train() client id: f_00007-0-4 loss: 0.546592  [  160/  179]
train() client id: f_00007-1-0 loss: 0.683557  [   32/  179]
train() client id: f_00007-1-1 loss: 0.717208  [   64/  179]
train() client id: f_00007-1-2 loss: 0.536114  [   96/  179]
train() client id: f_00007-1-3 loss: 0.790890  [  128/  179]
train() client id: f_00007-1-4 loss: 0.468891  [  160/  179]
train() client id: f_00007-2-0 loss: 0.558715  [   32/  179]
train() client id: f_00007-2-1 loss: 0.513533  [   64/  179]
train() client id: f_00007-2-2 loss: 0.781196  [   96/  179]
train() client id: f_00007-2-3 loss: 0.695630  [  128/  179]
train() client id: f_00007-2-4 loss: 0.540025  [  160/  179]
train() client id: f_00007-3-0 loss: 0.564714  [   32/  179]
train() client id: f_00007-3-1 loss: 0.478738  [   64/  179]
train() client id: f_00007-3-2 loss: 0.618547  [   96/  179]
train() client id: f_00007-3-3 loss: 0.447612  [  128/  179]
train() client id: f_00007-3-4 loss: 0.818346  [  160/  179]
train() client id: f_00007-4-0 loss: 0.515582  [   32/  179]
train() client id: f_00007-4-1 loss: 0.664027  [   64/  179]
train() client id: f_00007-4-2 loss: 0.615813  [   96/  179]
train() client id: f_00007-4-3 loss: 0.548191  [  128/  179]
train() client id: f_00007-4-4 loss: 0.692121  [  160/  179]
train() client id: f_00007-5-0 loss: 0.431964  [   32/  179]
train() client id: f_00007-5-1 loss: 0.649322  [   64/  179]
train() client id: f_00007-5-2 loss: 0.569382  [   96/  179]
train() client id: f_00007-5-3 loss: 0.559740  [  128/  179]
train() client id: f_00007-5-4 loss: 0.757553  [  160/  179]
train() client id: f_00007-6-0 loss: 0.548317  [   32/  179]
train() client id: f_00007-6-1 loss: 0.724113  [   64/  179]
train() client id: f_00007-6-2 loss: 0.694641  [   96/  179]
train() client id: f_00007-6-3 loss: 0.440208  [  128/  179]
train() client id: f_00007-6-4 loss: 0.425967  [  160/  179]
train() client id: f_00007-7-0 loss: 0.556489  [   32/  179]
train() client id: f_00007-7-1 loss: 0.608305  [   64/  179]
train() client id: f_00007-7-2 loss: 0.502079  [   96/  179]
train() client id: f_00007-7-3 loss: 0.710001  [  128/  179]
train() client id: f_00007-7-4 loss: 0.656696  [  160/  179]
train() client id: f_00007-8-0 loss: 0.547693  [   32/  179]
train() client id: f_00007-8-1 loss: 0.789387  [   64/  179]
train() client id: f_00007-8-2 loss: 0.527765  [   96/  179]
train() client id: f_00007-8-3 loss: 0.522414  [  128/  179]
train() client id: f_00007-8-4 loss: 0.632912  [  160/  179]
train() client id: f_00007-9-0 loss: 0.623814  [   32/  179]
train() client id: f_00007-9-1 loss: 0.504463  [   64/  179]
train() client id: f_00007-9-2 loss: 0.533417  [   96/  179]
train() client id: f_00007-9-3 loss: 0.799142  [  128/  179]
train() client id: f_00007-9-4 loss: 0.531895  [  160/  179]
train() client id: f_00007-10-0 loss: 0.541371  [   32/  179]
train() client id: f_00007-10-1 loss: 0.441557  [   64/  179]
train() client id: f_00007-10-2 loss: 0.745646  [   96/  179]
train() client id: f_00007-10-3 loss: 0.581154  [  128/  179]
train() client id: f_00007-10-4 loss: 0.689425  [  160/  179]
train() client id: f_00007-11-0 loss: 0.469122  [   32/  179]
train() client id: f_00007-11-1 loss: 0.693145  [   64/  179]
train() client id: f_00007-11-2 loss: 0.601901  [   96/  179]
train() client id: f_00007-11-3 loss: 0.706727  [  128/  179]
train() client id: f_00007-11-4 loss: 0.538707  [  160/  179]
train() client id: f_00007-12-0 loss: 0.648342  [   32/  179]
train() client id: f_00007-12-1 loss: 0.423653  [   64/  179]
train() client id: f_00007-12-2 loss: 0.856430  [   96/  179]
train() client id: f_00007-12-3 loss: 0.424996  [  128/  179]
train() client id: f_00007-12-4 loss: 0.660777  [  160/  179]
train() client id: f_00008-0-0 loss: 0.780751  [   32/  130]
train() client id: f_00008-0-1 loss: 0.879507  [   64/  130]
train() client id: f_00008-0-2 loss: 0.802183  [   96/  130]
train() client id: f_00008-0-3 loss: 0.768938  [  128/  130]
train() client id: f_00008-1-0 loss: 0.894158  [   32/  130]
train() client id: f_00008-1-1 loss: 0.689197  [   64/  130]
train() client id: f_00008-1-2 loss: 0.811731  [   96/  130]
train() client id: f_00008-1-3 loss: 0.835481  [  128/  130]
train() client id: f_00008-2-0 loss: 0.804575  [   32/  130]
train() client id: f_00008-2-1 loss: 0.661552  [   64/  130]
train() client id: f_00008-2-2 loss: 0.966926  [   96/  130]
train() client id: f_00008-2-3 loss: 0.762782  [  128/  130]
train() client id: f_00008-3-0 loss: 0.874383  [   32/  130]
train() client id: f_00008-3-1 loss: 0.865508  [   64/  130]
train() client id: f_00008-3-2 loss: 0.694872  [   96/  130]
train() client id: f_00008-3-3 loss: 0.800017  [  128/  130]
train() client id: f_00008-4-0 loss: 0.879150  [   32/  130]
train() client id: f_00008-4-1 loss: 0.906480  [   64/  130]
train() client id: f_00008-4-2 loss: 0.737182  [   96/  130]
train() client id: f_00008-4-3 loss: 0.705885  [  128/  130]
train() client id: f_00008-5-0 loss: 0.699562  [   32/  130]
train() client id: f_00008-5-1 loss: 0.825926  [   64/  130]
train() client id: f_00008-5-2 loss: 0.842237  [   96/  130]
train() client id: f_00008-5-3 loss: 0.864192  [  128/  130]
train() client id: f_00008-6-0 loss: 0.727951  [   32/  130]
train() client id: f_00008-6-1 loss: 0.914733  [   64/  130]
train() client id: f_00008-6-2 loss: 0.768249  [   96/  130]
train() client id: f_00008-6-3 loss: 0.775558  [  128/  130]
train() client id: f_00008-7-0 loss: 0.813613  [   32/  130]
train() client id: f_00008-7-1 loss: 0.771066  [   64/  130]
train() client id: f_00008-7-2 loss: 0.796114  [   96/  130]
train() client id: f_00008-7-3 loss: 0.851204  [  128/  130]
train() client id: f_00008-8-0 loss: 0.839319  [   32/  130]
train() client id: f_00008-8-1 loss: 0.695567  [   64/  130]
train() client id: f_00008-8-2 loss: 0.861894  [   96/  130]
train() client id: f_00008-8-3 loss: 0.826736  [  128/  130]
train() client id: f_00008-9-0 loss: 0.773751  [   32/  130]
train() client id: f_00008-9-1 loss: 0.898658  [   64/  130]
train() client id: f_00008-9-2 loss: 0.849951  [   96/  130]
train() client id: f_00008-9-3 loss: 0.703464  [  128/  130]
train() client id: f_00008-10-0 loss: 0.782774  [   32/  130]
train() client id: f_00008-10-1 loss: 0.710975  [   64/  130]
train() client id: f_00008-10-2 loss: 0.970861  [   96/  130]
train() client id: f_00008-10-3 loss: 0.756400  [  128/  130]
train() client id: f_00008-11-0 loss: 0.819811  [   32/  130]
train() client id: f_00008-11-1 loss: 0.825803  [   64/  130]
train() client id: f_00008-11-2 loss: 0.746116  [   96/  130]
train() client id: f_00008-11-3 loss: 0.830987  [  128/  130]
train() client id: f_00008-12-0 loss: 0.892465  [   32/  130]
train() client id: f_00008-12-1 loss: 0.739989  [   64/  130]
train() client id: f_00008-12-2 loss: 0.744471  [   96/  130]
train() client id: f_00008-12-3 loss: 0.815788  [  128/  130]
train() client id: f_00009-0-0 loss: 1.137940  [   32/  118]
train() client id: f_00009-0-1 loss: 1.132285  [   64/  118]
train() client id: f_00009-0-2 loss: 1.155571  [   96/  118]
train() client id: f_00009-1-0 loss: 1.073641  [   32/  118]
train() client id: f_00009-1-1 loss: 1.098142  [   64/  118]
train() client id: f_00009-1-2 loss: 1.087928  [   96/  118]
train() client id: f_00009-2-0 loss: 1.092649  [   32/  118]
train() client id: f_00009-2-1 loss: 1.150364  [   64/  118]
train() client id: f_00009-2-2 loss: 0.993456  [   96/  118]
train() client id: f_00009-3-0 loss: 1.052291  [   32/  118]
train() client id: f_00009-3-1 loss: 1.044936  [   64/  118]
train() client id: f_00009-3-2 loss: 0.972144  [   96/  118]
train() client id: f_00009-4-0 loss: 0.882357  [   32/  118]
train() client id: f_00009-4-1 loss: 0.960312  [   64/  118]
train() client id: f_00009-4-2 loss: 1.107139  [   96/  118]
train() client id: f_00009-5-0 loss: 0.908671  [   32/  118]
train() client id: f_00009-5-1 loss: 0.997427  [   64/  118]
train() client id: f_00009-5-2 loss: 0.971074  [   96/  118]
train() client id: f_00009-6-0 loss: 0.801703  [   32/  118]
train() client id: f_00009-6-1 loss: 0.973154  [   64/  118]
train() client id: f_00009-6-2 loss: 1.029008  [   96/  118]
train() client id: f_00009-7-0 loss: 0.848741  [   32/  118]
train() client id: f_00009-7-1 loss: 0.964435  [   64/  118]
train() client id: f_00009-7-2 loss: 0.890792  [   96/  118]
train() client id: f_00009-8-0 loss: 0.905131  [   32/  118]
train() client id: f_00009-8-1 loss: 0.936455  [   64/  118]
train() client id: f_00009-8-2 loss: 0.763665  [   96/  118]
train() client id: f_00009-9-0 loss: 0.880839  [   32/  118]
train() client id: f_00009-9-1 loss: 0.886555  [   64/  118]
train() client id: f_00009-9-2 loss: 0.835248  [   96/  118]
train() client id: f_00009-10-0 loss: 0.987121  [   32/  118]
train() client id: f_00009-10-1 loss: 0.813647  [   64/  118]
train() client id: f_00009-10-2 loss: 0.847716  [   96/  118]
train() client id: f_00009-11-0 loss: 0.836135  [   32/  118]
train() client id: f_00009-11-1 loss: 0.899124  [   64/  118]
train() client id: f_00009-11-2 loss: 0.924071  [   96/  118]
train() client id: f_00009-12-0 loss: 0.869308  [   32/  118]
train() client id: f_00009-12-1 loss: 0.857529  [   64/  118]
train() client id: f_00009-12-2 loss: 0.851719  [   96/  118]
At round 27 accuracy: 0.6392572944297082
At round 27 training accuracy: 0.5814889336016097
At round 27 training loss: 0.8425139935062138
gradient difference: 0.39894264936447144
train() client id: f_00000-0-0 loss: 0.941098  [   32/  126]
train() client id: f_00000-0-1 loss: 1.283915  [   64/  126]
train() client id: f_00000-0-2 loss: 1.148024  [   96/  126]
train() client id: f_00000-1-0 loss: 1.021260  [   32/  126]
train() client id: f_00000-1-1 loss: 0.884342  [   64/  126]
train() client id: f_00000-1-2 loss: 1.107635  [   96/  126]
train() client id: f_00000-2-0 loss: 0.796479  [   32/  126]
train() client id: f_00000-2-1 loss: 0.937759  [   64/  126]
train() client id: f_00000-2-2 loss: 0.762258  [   96/  126]
train() client id: f_00000-3-0 loss: 0.849495  [   32/  126]
train() client id: f_00000-3-1 loss: 0.860586  [   64/  126]
train() client id: f_00000-3-2 loss: 0.896075  [   96/  126]
train() client id: f_00000-4-0 loss: 0.783156  [   32/  126]
train() client id: f_00000-4-1 loss: 0.794880  [   64/  126]
train() client id: f_00000-4-2 loss: 0.895670  [   96/  126]
train() client id: f_00000-5-0 loss: 0.835004  [   32/  126]
train() client id: f_00000-5-1 loss: 0.785905  [   64/  126]
train() client id: f_00000-5-2 loss: 0.775789  [   96/  126]
train() client id: f_00000-6-0 loss: 0.827364  [   32/  126]
train() client id: f_00000-6-1 loss: 0.630852  [   64/  126]
train() client id: f_00000-6-2 loss: 0.810347  [   96/  126]
train() client id: f_00000-7-0 loss: 0.747968  [   32/  126]
train() client id: f_00000-7-1 loss: 0.687487  [   64/  126]
train() client id: f_00000-7-2 loss: 0.695738  [   96/  126]
train() client id: f_00000-8-0 loss: 0.606003  [   32/  126]
train() client id: f_00000-8-1 loss: 0.797198  [   64/  126]
train() client id: f_00000-8-2 loss: 0.618071  [   96/  126]
train() client id: f_00000-9-0 loss: 0.574489  [   32/  126]
train() client id: f_00000-9-1 loss: 0.733800  [   64/  126]
train() client id: f_00000-9-2 loss: 0.750861  [   96/  126]
train() client id: f_00000-10-0 loss: 0.575826  [   32/  126]
train() client id: f_00000-10-1 loss: 0.721489  [   64/  126]
train() client id: f_00000-10-2 loss: 0.740774  [   96/  126]
train() client id: f_00000-11-0 loss: 0.611558  [   32/  126]
train() client id: f_00000-11-1 loss: 0.645208  [   64/  126]
train() client id: f_00000-11-2 loss: 0.668104  [   96/  126]
train() client id: f_00000-12-0 loss: 0.553575  [   32/  126]
train() client id: f_00000-12-1 loss: 0.539113  [   64/  126]
train() client id: f_00000-12-2 loss: 0.708929  [   96/  126]
train() client id: f_00001-0-0 loss: 0.458885  [   32/  265]
train() client id: f_00001-0-1 loss: 0.454794  [   64/  265]
train() client id: f_00001-0-2 loss: 0.387832  [   96/  265]
train() client id: f_00001-0-3 loss: 0.457898  [  128/  265]
train() client id: f_00001-0-4 loss: 0.524703  [  160/  265]
train() client id: f_00001-0-5 loss: 0.503345  [  192/  265]
train() client id: f_00001-0-6 loss: 0.534892  [  224/  265]
train() client id: f_00001-0-7 loss: 0.419739  [  256/  265]
train() client id: f_00001-1-0 loss: 0.501917  [   32/  265]
train() client id: f_00001-1-1 loss: 0.420122  [   64/  265]
train() client id: f_00001-1-2 loss: 0.526767  [   96/  265]
train() client id: f_00001-1-3 loss: 0.395552  [  128/  265]
train() client id: f_00001-1-4 loss: 0.367117  [  160/  265]
train() client id: f_00001-1-5 loss: 0.437909  [  192/  265]
train() client id: f_00001-1-6 loss: 0.526732  [  224/  265]
train() client id: f_00001-1-7 loss: 0.476022  [  256/  265]
train() client id: f_00001-2-0 loss: 0.529428  [   32/  265]
train() client id: f_00001-2-1 loss: 0.503493  [   64/  265]
train() client id: f_00001-2-2 loss: 0.503978  [   96/  265]
train() client id: f_00001-2-3 loss: 0.461568  [  128/  265]
train() client id: f_00001-2-4 loss: 0.412273  [  160/  265]
train() client id: f_00001-2-5 loss: 0.423752  [  192/  265]
train() client id: f_00001-2-6 loss: 0.418991  [  224/  265]
train() client id: f_00001-2-7 loss: 0.366477  [  256/  265]
train() client id: f_00001-3-0 loss: 0.552948  [   32/  265]
train() client id: f_00001-3-1 loss: 0.504312  [   64/  265]
train() client id: f_00001-3-2 loss: 0.393781  [   96/  265]
train() client id: f_00001-3-3 loss: 0.354153  [  128/  265]
train() client id: f_00001-3-4 loss: 0.482286  [  160/  265]
train() client id: f_00001-3-5 loss: 0.441881  [  192/  265]
train() client id: f_00001-3-6 loss: 0.369868  [  224/  265]
train() client id: f_00001-3-7 loss: 0.462153  [  256/  265]
train() client id: f_00001-4-0 loss: 0.372160  [   32/  265]
train() client id: f_00001-4-1 loss: 0.439096  [   64/  265]
train() client id: f_00001-4-2 loss: 0.412231  [   96/  265]
train() client id: f_00001-4-3 loss: 0.356018  [  128/  265]
train() client id: f_00001-4-4 loss: 0.460086  [  160/  265]
train() client id: f_00001-4-5 loss: 0.578641  [  192/  265]
train() client id: f_00001-4-6 loss: 0.456832  [  224/  265]
train() client id: f_00001-4-7 loss: 0.476184  [  256/  265]
train() client id: f_00001-5-0 loss: 0.359654  [   32/  265]
train() client id: f_00001-5-1 loss: 0.492761  [   64/  265]
train() client id: f_00001-5-2 loss: 0.413025  [   96/  265]
train() client id: f_00001-5-3 loss: 0.347664  [  128/  265]
train() client id: f_00001-5-4 loss: 0.413505  [  160/  265]
train() client id: f_00001-5-5 loss: 0.524616  [  192/  265]
train() client id: f_00001-5-6 loss: 0.480382  [  224/  265]
train() client id: f_00001-5-7 loss: 0.502112  [  256/  265]
train() client id: f_00001-6-0 loss: 0.419785  [   32/  265]
train() client id: f_00001-6-1 loss: 0.401612  [   64/  265]
train() client id: f_00001-6-2 loss: 0.438730  [   96/  265]
train() client id: f_00001-6-3 loss: 0.521662  [  128/  265]
train() client id: f_00001-6-4 loss: 0.353991  [  160/  265]
train() client id: f_00001-6-5 loss: 0.345393  [  192/  265]
train() client id: f_00001-6-6 loss: 0.486110  [  224/  265]
train() client id: f_00001-6-7 loss: 0.511759  [  256/  265]
train() client id: f_00001-7-0 loss: 0.532510  [   32/  265]
train() client id: f_00001-7-1 loss: 0.524690  [   64/  265]
train() client id: f_00001-7-2 loss: 0.430230  [   96/  265]
train() client id: f_00001-7-3 loss: 0.501766  [  128/  265]
train() client id: f_00001-7-4 loss: 0.341961  [  160/  265]
train() client id: f_00001-7-5 loss: 0.354296  [  192/  265]
train() client id: f_00001-7-6 loss: 0.349775  [  224/  265]
train() client id: f_00001-7-7 loss: 0.458139  [  256/  265]
train() client id: f_00001-8-0 loss: 0.427033  [   32/  265]
train() client id: f_00001-8-1 loss: 0.456746  [   64/  265]
train() client id: f_00001-8-2 loss: 0.672741  [   96/  265]
train() client id: f_00001-8-3 loss: 0.325845  [  128/  265]
train() client id: f_00001-8-4 loss: 0.384715  [  160/  265]
train() client id: f_00001-8-5 loss: 0.465076  [  192/  265]
train() client id: f_00001-8-6 loss: 0.408316  [  224/  265]
train() client id: f_00001-8-7 loss: 0.342306  [  256/  265]
train() client id: f_00001-9-0 loss: 0.489520  [   32/  265]
train() client id: f_00001-9-1 loss: 0.597753  [   64/  265]
train() client id: f_00001-9-2 loss: 0.401380  [   96/  265]
train() client id: f_00001-9-3 loss: 0.414518  [  128/  265]
train() client id: f_00001-9-4 loss: 0.353844  [  160/  265]
train() client id: f_00001-9-5 loss: 0.437134  [  192/  265]
train() client id: f_00001-9-6 loss: 0.363083  [  224/  265]
train() client id: f_00001-9-7 loss: 0.409505  [  256/  265]
train() client id: f_00001-10-0 loss: 0.391279  [   32/  265]
train() client id: f_00001-10-1 loss: 0.403092  [   64/  265]
train() client id: f_00001-10-2 loss: 0.462696  [   96/  265]
train() client id: f_00001-10-3 loss: 0.403448  [  128/  265]
train() client id: f_00001-10-4 loss: 0.407815  [  160/  265]
train() client id: f_00001-10-5 loss: 0.507824  [  192/  265]
train() client id: f_00001-10-6 loss: 0.489772  [  224/  265]
train() client id: f_00001-10-7 loss: 0.396474  [  256/  265]
train() client id: f_00001-11-0 loss: 0.347391  [   32/  265]
train() client id: f_00001-11-1 loss: 0.341827  [   64/  265]
train() client id: f_00001-11-2 loss: 0.394301  [   96/  265]
train() client id: f_00001-11-3 loss: 0.405963  [  128/  265]
train() client id: f_00001-11-4 loss: 0.420401  [  160/  265]
train() client id: f_00001-11-5 loss: 0.465163  [  192/  265]
train() client id: f_00001-11-6 loss: 0.419631  [  224/  265]
train() client id: f_00001-11-7 loss: 0.601804  [  256/  265]
train() client id: f_00001-12-0 loss: 0.364317  [   32/  265]
train() client id: f_00001-12-1 loss: 0.455023  [   64/  265]
train() client id: f_00001-12-2 loss: 0.498922  [   96/  265]
train() client id: f_00001-12-3 loss: 0.429904  [  128/  265]
train() client id: f_00001-12-4 loss: 0.353537  [  160/  265]
train() client id: f_00001-12-5 loss: 0.495038  [  192/  265]
train() client id: f_00001-12-6 loss: 0.386021  [  224/  265]
train() client id: f_00001-12-7 loss: 0.483198  [  256/  265]
train() client id: f_00002-0-0 loss: 1.136721  [   32/  124]
train() client id: f_00002-0-1 loss: 1.042547  [   64/  124]
train() client id: f_00002-0-2 loss: 1.224991  [   96/  124]
train() client id: f_00002-1-0 loss: 1.120142  [   32/  124]
train() client id: f_00002-1-1 loss: 1.136945  [   64/  124]
train() client id: f_00002-1-2 loss: 1.177181  [   96/  124]
train() client id: f_00002-2-0 loss: 1.086018  [   32/  124]
train() client id: f_00002-2-1 loss: 1.162799  [   64/  124]
train() client id: f_00002-2-2 loss: 1.132067  [   96/  124]
train() client id: f_00002-3-0 loss: 1.041412  [   32/  124]
train() client id: f_00002-3-1 loss: 1.072849  [   64/  124]
train() client id: f_00002-3-2 loss: 0.955073  [   96/  124]
train() client id: f_00002-4-0 loss: 1.127023  [   32/  124]
train() client id: f_00002-4-1 loss: 1.013793  [   64/  124]
train() client id: f_00002-4-2 loss: 1.036790  [   96/  124]
train() client id: f_00002-5-0 loss: 1.086071  [   32/  124]
train() client id: f_00002-5-1 loss: 1.115948  [   64/  124]
train() client id: f_00002-5-2 loss: 1.035655  [   96/  124]
train() client id: f_00002-6-0 loss: 0.947345  [   32/  124]
train() client id: f_00002-6-1 loss: 1.047076  [   64/  124]
train() client id: f_00002-6-2 loss: 0.924491  [   96/  124]
train() client id: f_00002-7-0 loss: 1.100792  [   32/  124]
train() client id: f_00002-7-1 loss: 0.961208  [   64/  124]
train() client id: f_00002-7-2 loss: 0.927570  [   96/  124]
train() client id: f_00002-8-0 loss: 1.038529  [   32/  124]
train() client id: f_00002-8-1 loss: 0.897128  [   64/  124]
train() client id: f_00002-8-2 loss: 0.959530  [   96/  124]
train() client id: f_00002-9-0 loss: 0.892559  [   32/  124]
train() client id: f_00002-9-1 loss: 0.902829  [   64/  124]
train() client id: f_00002-9-2 loss: 1.013448  [   96/  124]
train() client id: f_00002-10-0 loss: 0.956681  [   32/  124]
train() client id: f_00002-10-1 loss: 1.070228  [   64/  124]
train() client id: f_00002-10-2 loss: 0.866742  [   96/  124]
train() client id: f_00002-11-0 loss: 1.086192  [   32/  124]
train() client id: f_00002-11-1 loss: 0.872547  [   64/  124]
train() client id: f_00002-11-2 loss: 0.990379  [   96/  124]
train() client id: f_00002-12-0 loss: 0.981005  [   32/  124]
train() client id: f_00002-12-1 loss: 0.999703  [   64/  124]
train() client id: f_00002-12-2 loss: 0.966660  [   96/  124]
train() client id: f_00003-0-0 loss: 0.475154  [   32/   43]
train() client id: f_00003-1-0 loss: 0.669604  [   32/   43]
train() client id: f_00003-2-0 loss: 0.421924  [   32/   43]
train() client id: f_00003-3-0 loss: 0.644336  [   32/   43]
train() client id: f_00003-4-0 loss: 0.555523  [   32/   43]
train() client id: f_00003-5-0 loss: 0.619034  [   32/   43]
train() client id: f_00003-6-0 loss: 0.611232  [   32/   43]
train() client id: f_00003-7-0 loss: 0.771863  [   32/   43]
train() client id: f_00003-8-0 loss: 0.758913  [   32/   43]
train() client id: f_00003-9-0 loss: 0.689709  [   32/   43]
train() client id: f_00003-10-0 loss: 0.547431  [   32/   43]
train() client id: f_00003-11-0 loss: 0.727756  [   32/   43]
train() client id: f_00003-12-0 loss: 0.493725  [   32/   43]
train() client id: f_00004-0-0 loss: 0.958009  [   32/  306]
train() client id: f_00004-0-1 loss: 0.929476  [   64/  306]
train() client id: f_00004-0-2 loss: 0.954827  [   96/  306]
train() client id: f_00004-0-3 loss: 0.897661  [  128/  306]
train() client id: f_00004-0-4 loss: 0.881863  [  160/  306]
train() client id: f_00004-0-5 loss: 0.858918  [  192/  306]
train() client id: f_00004-0-6 loss: 1.045848  [  224/  306]
train() client id: f_00004-0-7 loss: 1.162632  [  256/  306]
train() client id: f_00004-0-8 loss: 0.834146  [  288/  306]
train() client id: f_00004-1-0 loss: 0.917407  [   32/  306]
train() client id: f_00004-1-1 loss: 0.968592  [   64/  306]
train() client id: f_00004-1-2 loss: 0.900238  [   96/  306]
train() client id: f_00004-1-3 loss: 0.965203  [  128/  306]
train() client id: f_00004-1-4 loss: 1.082422  [  160/  306]
train() client id: f_00004-1-5 loss: 0.958457  [  192/  306]
train() client id: f_00004-1-6 loss: 0.818030  [  224/  306]
train() client id: f_00004-1-7 loss: 0.917650  [  256/  306]
train() client id: f_00004-1-8 loss: 0.882941  [  288/  306]
train() client id: f_00004-2-0 loss: 0.825925  [   32/  306]
train() client id: f_00004-2-1 loss: 0.927207  [   64/  306]
train() client id: f_00004-2-2 loss: 1.061242  [   96/  306]
train() client id: f_00004-2-3 loss: 0.986855  [  128/  306]
train() client id: f_00004-2-4 loss: 0.918921  [  160/  306]
train() client id: f_00004-2-5 loss: 0.849065  [  192/  306]
train() client id: f_00004-2-6 loss: 0.970972  [  224/  306]
train() client id: f_00004-2-7 loss: 1.085755  [  256/  306]
train() client id: f_00004-2-8 loss: 0.802798  [  288/  306]
train() client id: f_00004-3-0 loss: 0.909601  [   32/  306]
train() client id: f_00004-3-1 loss: 0.919198  [   64/  306]
train() client id: f_00004-3-2 loss: 1.010212  [   96/  306]
train() client id: f_00004-3-3 loss: 0.947044  [  128/  306]
train() client id: f_00004-3-4 loss: 1.025558  [  160/  306]
train() client id: f_00004-3-5 loss: 0.993895  [  192/  306]
train() client id: f_00004-3-6 loss: 0.876822  [  224/  306]
train() client id: f_00004-3-7 loss: 0.800606  [  256/  306]
train() client id: f_00004-3-8 loss: 0.946361  [  288/  306]
train() client id: f_00004-4-0 loss: 0.921537  [   32/  306]
train() client id: f_00004-4-1 loss: 0.850758  [   64/  306]
train() client id: f_00004-4-2 loss: 1.044196  [   96/  306]
train() client id: f_00004-4-3 loss: 0.946247  [  128/  306]
train() client id: f_00004-4-4 loss: 0.902347  [  160/  306]
train() client id: f_00004-4-5 loss: 0.883413  [  192/  306]
train() client id: f_00004-4-6 loss: 1.021100  [  224/  306]
train() client id: f_00004-4-7 loss: 0.872265  [  256/  306]
train() client id: f_00004-4-8 loss: 0.832494  [  288/  306]
train() client id: f_00004-5-0 loss: 0.875599  [   32/  306]
train() client id: f_00004-5-1 loss: 0.971699  [   64/  306]
train() client id: f_00004-5-2 loss: 1.041050  [   96/  306]
train() client id: f_00004-5-3 loss: 0.874960  [  128/  306]
train() client id: f_00004-5-4 loss: 0.810621  [  160/  306]
train() client id: f_00004-5-5 loss: 0.881895  [  192/  306]
train() client id: f_00004-5-6 loss: 0.954252  [  224/  306]
train() client id: f_00004-5-7 loss: 0.865191  [  256/  306]
train() client id: f_00004-5-8 loss: 1.029094  [  288/  306]
train() client id: f_00004-6-0 loss: 0.869341  [   32/  306]
train() client id: f_00004-6-1 loss: 1.093876  [   64/  306]
train() client id: f_00004-6-2 loss: 0.934531  [   96/  306]
train() client id: f_00004-6-3 loss: 0.804640  [  128/  306]
train() client id: f_00004-6-4 loss: 0.912671  [  160/  306]
train() client id: f_00004-6-5 loss: 0.929111  [  192/  306]
train() client id: f_00004-6-6 loss: 0.894308  [  224/  306]
train() client id: f_00004-6-7 loss: 0.909524  [  256/  306]
train() client id: f_00004-6-8 loss: 0.904374  [  288/  306]
train() client id: f_00004-7-0 loss: 0.825560  [   32/  306]
train() client id: f_00004-7-1 loss: 0.860718  [   64/  306]
train() client id: f_00004-7-2 loss: 1.104231  [   96/  306]
train() client id: f_00004-7-3 loss: 0.854001  [  128/  306]
train() client id: f_00004-7-4 loss: 0.935679  [  160/  306]
train() client id: f_00004-7-5 loss: 0.991104  [  192/  306]
train() client id: f_00004-7-6 loss: 0.812957  [  224/  306]
train() client id: f_00004-7-7 loss: 1.020653  [  256/  306]
train() client id: f_00004-7-8 loss: 0.850380  [  288/  306]
train() client id: f_00004-8-0 loss: 0.916034  [   32/  306]
train() client id: f_00004-8-1 loss: 0.905692  [   64/  306]
train() client id: f_00004-8-2 loss: 1.017317  [   96/  306]
train() client id: f_00004-8-3 loss: 0.869548  [  128/  306]
train() client id: f_00004-8-4 loss: 0.837785  [  160/  306]
train() client id: f_00004-8-5 loss: 0.930183  [  192/  306]
train() client id: f_00004-8-6 loss: 0.948126  [  224/  306]
train() client id: f_00004-8-7 loss: 0.935612  [  256/  306]
train() client id: f_00004-8-8 loss: 0.904254  [  288/  306]
train() client id: f_00004-9-0 loss: 0.911407  [   32/  306]
train() client id: f_00004-9-1 loss: 1.000901  [   64/  306]
train() client id: f_00004-9-2 loss: 0.958699  [   96/  306]
train() client id: f_00004-9-3 loss: 0.831795  [  128/  306]
train() client id: f_00004-9-4 loss: 0.903456  [  160/  306]
train() client id: f_00004-9-5 loss: 0.851947  [  192/  306]
train() client id: f_00004-9-6 loss: 0.828993  [  224/  306]
train() client id: f_00004-9-7 loss: 0.963721  [  256/  306]
train() client id: f_00004-9-8 loss: 0.898313  [  288/  306]
train() client id: f_00004-10-0 loss: 0.922725  [   32/  306]
train() client id: f_00004-10-1 loss: 0.714343  [   64/  306]
train() client id: f_00004-10-2 loss: 0.849918  [   96/  306]
train() client id: f_00004-10-3 loss: 0.962331  [  128/  306]
train() client id: f_00004-10-4 loss: 0.929912  [  160/  306]
train() client id: f_00004-10-5 loss: 0.965512  [  192/  306]
train() client id: f_00004-10-6 loss: 0.841288  [  224/  306]
train() client id: f_00004-10-7 loss: 1.027790  [  256/  306]
train() client id: f_00004-10-8 loss: 0.891870  [  288/  306]
train() client id: f_00004-11-0 loss: 0.973032  [   32/  306]
train() client id: f_00004-11-1 loss: 0.865288  [   64/  306]
train() client id: f_00004-11-2 loss: 0.850216  [   96/  306]
train() client id: f_00004-11-3 loss: 0.876050  [  128/  306]
train() client id: f_00004-11-4 loss: 1.053258  [  160/  306]
train() client id: f_00004-11-5 loss: 0.804069  [  192/  306]
train() client id: f_00004-11-6 loss: 0.887072  [  224/  306]
train() client id: f_00004-11-7 loss: 0.905605  [  256/  306]
train() client id: f_00004-11-8 loss: 0.846206  [  288/  306]
train() client id: f_00004-12-0 loss: 0.895879  [   32/  306]
train() client id: f_00004-12-1 loss: 0.947953  [   64/  306]
train() client id: f_00004-12-2 loss: 0.952349  [   96/  306]
train() client id: f_00004-12-3 loss: 0.935079  [  128/  306]
train() client id: f_00004-12-4 loss: 0.872451  [  160/  306]
train() client id: f_00004-12-5 loss: 0.718041  [  192/  306]
train() client id: f_00004-12-6 loss: 0.856477  [  224/  306]
train() client id: f_00004-12-7 loss: 0.952913  [  256/  306]
train() client id: f_00004-12-8 loss: 0.969525  [  288/  306]
train() client id: f_00005-0-0 loss: 0.513630  [   32/  146]
train() client id: f_00005-0-1 loss: 0.356066  [   64/  146]
train() client id: f_00005-0-2 loss: 0.714882  [   96/  146]
train() client id: f_00005-0-3 loss: 0.636198  [  128/  146]
train() client id: f_00005-1-0 loss: 0.410687  [   32/  146]
train() client id: f_00005-1-1 loss: 0.616087  [   64/  146]
train() client id: f_00005-1-2 loss: 0.465636  [   96/  146]
train() client id: f_00005-1-3 loss: 0.459456  [  128/  146]
train() client id: f_00005-2-0 loss: 0.708731  [   32/  146]
train() client id: f_00005-2-1 loss: 0.686527  [   64/  146]
train() client id: f_00005-2-2 loss: 0.337129  [   96/  146]
train() client id: f_00005-2-3 loss: 0.534308  [  128/  146]
train() client id: f_00005-3-0 loss: 0.500090  [   32/  146]
train() client id: f_00005-3-1 loss: 0.735786  [   64/  146]
train() client id: f_00005-3-2 loss: 0.523534  [   96/  146]
train() client id: f_00005-3-3 loss: 0.525315  [  128/  146]
train() client id: f_00005-4-0 loss: 0.613261  [   32/  146]
train() client id: f_00005-4-1 loss: 0.512023  [   64/  146]
train() client id: f_00005-4-2 loss: 0.404547  [   96/  146]
train() client id: f_00005-4-3 loss: 0.452006  [  128/  146]
train() client id: f_00005-5-0 loss: 0.328479  [   32/  146]
train() client id: f_00005-5-1 loss: 0.846168  [   64/  146]
train() client id: f_00005-5-2 loss: 0.438976  [   96/  146]
train() client id: f_00005-5-3 loss: 0.532913  [  128/  146]
train() client id: f_00005-6-0 loss: 0.852873  [   32/  146]
train() client id: f_00005-6-1 loss: 0.733420  [   64/  146]
train() client id: f_00005-6-2 loss: 0.207677  [   96/  146]
train() client id: f_00005-6-3 loss: 0.277825  [  128/  146]
train() client id: f_00005-7-0 loss: 0.565295  [   32/  146]
train() client id: f_00005-7-1 loss: 0.647081  [   64/  146]
train() client id: f_00005-7-2 loss: 0.412375  [   96/  146]
train() client id: f_00005-7-3 loss: 0.518830  [  128/  146]
train() client id: f_00005-8-0 loss: 0.579838  [   32/  146]
train() client id: f_00005-8-1 loss: 0.353863  [   64/  146]
train() client id: f_00005-8-2 loss: 0.695273  [   96/  146]
train() client id: f_00005-8-3 loss: 0.429795  [  128/  146]
train() client id: f_00005-9-0 loss: 0.705673  [   32/  146]
train() client id: f_00005-9-1 loss: 0.459328  [   64/  146]
train() client id: f_00005-9-2 loss: 0.577385  [   96/  146]
train() client id: f_00005-9-3 loss: 0.334812  [  128/  146]
train() client id: f_00005-10-0 loss: 0.765375  [   32/  146]
train() client id: f_00005-10-1 loss: 0.372740  [   64/  146]
train() client id: f_00005-10-2 loss: 0.379987  [   96/  146]
train() client id: f_00005-10-3 loss: 0.451349  [  128/  146]
train() client id: f_00005-11-0 loss: 0.630736  [   32/  146]
train() client id: f_00005-11-1 loss: 0.722656  [   64/  146]
train() client id: f_00005-11-2 loss: 0.368786  [   96/  146]
train() client id: f_00005-11-3 loss: 0.529695  [  128/  146]
train() client id: f_00005-12-0 loss: 0.784152  [   32/  146]
train() client id: f_00005-12-1 loss: 0.476058  [   64/  146]
train() client id: f_00005-12-2 loss: 0.411217  [   96/  146]
train() client id: f_00005-12-3 loss: 0.365567  [  128/  146]
train() client id: f_00006-0-0 loss: 0.521533  [   32/   54]
train() client id: f_00006-1-0 loss: 0.491947  [   32/   54]
train() client id: f_00006-2-0 loss: 0.491484  [   32/   54]
train() client id: f_00006-3-0 loss: 0.538813  [   32/   54]
train() client id: f_00006-4-0 loss: 0.469207  [   32/   54]
train() client id: f_00006-5-0 loss: 0.479567  [   32/   54]
train() client id: f_00006-6-0 loss: 0.535730  [   32/   54]
train() client id: f_00006-7-0 loss: 0.438013  [   32/   54]
train() client id: f_00006-8-0 loss: 0.503771  [   32/   54]
train() client id: f_00006-9-0 loss: 0.481551  [   32/   54]
train() client id: f_00006-10-0 loss: 0.534343  [   32/   54]
train() client id: f_00006-11-0 loss: 0.441173  [   32/   54]
train() client id: f_00006-12-0 loss: 0.462834  [   32/   54]
train() client id: f_00007-0-0 loss: 0.518907  [   32/  179]
train() client id: f_00007-0-1 loss: 0.596639  [   64/  179]
train() client id: f_00007-0-2 loss: 0.446090  [   96/  179]
train() client id: f_00007-0-3 loss: 0.807317  [  128/  179]
train() client id: f_00007-0-4 loss: 0.461024  [  160/  179]
train() client id: f_00007-1-0 loss: 0.373239  [   32/  179]
train() client id: f_00007-1-1 loss: 0.615092  [   64/  179]
train() client id: f_00007-1-2 loss: 0.444417  [   96/  179]
train() client id: f_00007-1-3 loss: 0.724548  [  128/  179]
train() client id: f_00007-1-4 loss: 0.486410  [  160/  179]
train() client id: f_00007-2-0 loss: 0.397876  [   32/  179]
train() client id: f_00007-2-1 loss: 0.368564  [   64/  179]
train() client id: f_00007-2-2 loss: 0.615459  [   96/  179]
train() client id: f_00007-2-3 loss: 0.469144  [  128/  179]
train() client id: f_00007-2-4 loss: 0.646378  [  160/  179]
train() client id: f_00007-3-0 loss: 0.461938  [   32/  179]
train() client id: f_00007-3-1 loss: 0.497517  [   64/  179]
train() client id: f_00007-3-2 loss: 0.525590  [   96/  179]
train() client id: f_00007-3-3 loss: 0.489117  [  128/  179]
train() client id: f_00007-3-4 loss: 0.630858  [  160/  179]
train() client id: f_00007-4-0 loss: 0.542793  [   32/  179]
train() client id: f_00007-4-1 loss: 0.610559  [   64/  179]
train() client id: f_00007-4-2 loss: 0.483056  [   96/  179]
train() client id: f_00007-4-3 loss: 0.475514  [  128/  179]
train() client id: f_00007-4-4 loss: 0.470476  [  160/  179]
train() client id: f_00007-5-0 loss: 0.391347  [   32/  179]
train() client id: f_00007-5-1 loss: 0.570689  [   64/  179]
train() client id: f_00007-5-2 loss: 0.680482  [   96/  179]
train() client id: f_00007-5-3 loss: 0.472441  [  128/  179]
train() client id: f_00007-5-4 loss: 0.558721  [  160/  179]
train() client id: f_00007-6-0 loss: 0.689819  [   32/  179]
train() client id: f_00007-6-1 loss: 0.401082  [   64/  179]
train() client id: f_00007-6-2 loss: 0.442105  [   96/  179]
train() client id: f_00007-6-3 loss: 0.473016  [  128/  179]
train() client id: f_00007-6-4 loss: 0.610295  [  160/  179]
train() client id: f_00007-7-0 loss: 0.567049  [   32/  179]
train() client id: f_00007-7-1 loss: 0.445863  [   64/  179]
train() client id: f_00007-7-2 loss: 0.521596  [   96/  179]
train() client id: f_00007-7-3 loss: 0.436234  [  128/  179]
train() client id: f_00007-7-4 loss: 0.637762  [  160/  179]
train() client id: f_00007-8-0 loss: 0.436153  [   32/  179]
train() client id: f_00007-8-1 loss: 0.544044  [   64/  179]
train() client id: f_00007-8-2 loss: 0.526808  [   96/  179]
train() client id: f_00007-8-3 loss: 0.520660  [  128/  179]
train() client id: f_00007-8-4 loss: 0.557783  [  160/  179]
train() client id: f_00007-9-0 loss: 0.438536  [   32/  179]
train() client id: f_00007-9-1 loss: 0.632071  [   64/  179]
train() client id: f_00007-9-2 loss: 0.369928  [   96/  179]
train() client id: f_00007-9-3 loss: 0.434539  [  128/  179]
train() client id: f_00007-9-4 loss: 0.377358  [  160/  179]
train() client id: f_00007-10-0 loss: 0.654075  [   32/  179]
train() client id: f_00007-10-1 loss: 0.446048  [   64/  179]
train() client id: f_00007-10-2 loss: 0.353843  [   96/  179]
train() client id: f_00007-10-3 loss: 0.686118  [  128/  179]
train() client id: f_00007-10-4 loss: 0.435032  [  160/  179]
train() client id: f_00007-11-0 loss: 0.436159  [   32/  179]
train() client id: f_00007-11-1 loss: 0.641008  [   64/  179]
train() client id: f_00007-11-2 loss: 0.353327  [   96/  179]
train() client id: f_00007-11-3 loss: 0.532218  [  128/  179]
train() client id: f_00007-11-4 loss: 0.602002  [  160/  179]
train() client id: f_00007-12-0 loss: 0.608386  [   32/  179]
train() client id: f_00007-12-1 loss: 0.514643  [   64/  179]
train() client id: f_00007-12-2 loss: 0.554508  [   96/  179]
train() client id: f_00007-12-3 loss: 0.520818  [  128/  179]
train() client id: f_00007-12-4 loss: 0.353672  [  160/  179]
train() client id: f_00008-0-0 loss: 0.623412  [   32/  130]
train() client id: f_00008-0-1 loss: 0.758569  [   64/  130]
train() client id: f_00008-0-2 loss: 0.791044  [   96/  130]
train() client id: f_00008-0-3 loss: 0.718321  [  128/  130]
train() client id: f_00008-1-0 loss: 0.687955  [   32/  130]
train() client id: f_00008-1-1 loss: 0.728622  [   64/  130]
train() client id: f_00008-1-2 loss: 0.686111  [   96/  130]
train() client id: f_00008-1-3 loss: 0.776156  [  128/  130]
train() client id: f_00008-2-0 loss: 0.769983  [   32/  130]
train() client id: f_00008-2-1 loss: 0.784935  [   64/  130]
train() client id: f_00008-2-2 loss: 0.694373  [   96/  130]
train() client id: f_00008-2-3 loss: 0.678754  [  128/  130]
train() client id: f_00008-3-0 loss: 0.720782  [   32/  130]
train() client id: f_00008-3-1 loss: 0.740450  [   64/  130]
train() client id: f_00008-3-2 loss: 0.766639  [   96/  130]
train() client id: f_00008-3-3 loss: 0.695765  [  128/  130]
train() client id: f_00008-4-0 loss: 0.643723  [   32/  130]
train() client id: f_00008-4-1 loss: 0.718639  [   64/  130]
train() client id: f_00008-4-2 loss: 0.853866  [   96/  130]
train() client id: f_00008-4-3 loss: 0.680975  [  128/  130]
train() client id: f_00008-5-0 loss: 0.662948  [   32/  130]
train() client id: f_00008-5-1 loss: 0.764882  [   64/  130]
train() client id: f_00008-5-2 loss: 0.732015  [   96/  130]
train() client id: f_00008-5-3 loss: 0.764435  [  128/  130]
train() client id: f_00008-6-0 loss: 0.806657  [   32/  130]
train() client id: f_00008-6-1 loss: 0.674197  [   64/  130]
train() client id: f_00008-6-2 loss: 0.695458  [   96/  130]
train() client id: f_00008-6-3 loss: 0.736661  [  128/  130]
train() client id: f_00008-7-0 loss: 0.643418  [   32/  130]
train() client id: f_00008-7-1 loss: 0.741754  [   64/  130]
train() client id: f_00008-7-2 loss: 0.802437  [   96/  130]
train() client id: f_00008-7-3 loss: 0.692865  [  128/  130]
train() client id: f_00008-8-0 loss: 0.687091  [   32/  130]
train() client id: f_00008-8-1 loss: 0.714762  [   64/  130]
train() client id: f_00008-8-2 loss: 0.705586  [   96/  130]
train() client id: f_00008-8-3 loss: 0.800143  [  128/  130]
train() client id: f_00008-9-0 loss: 0.707868  [   32/  130]
train() client id: f_00008-9-1 loss: 0.636354  [   64/  130]
train() client id: f_00008-9-2 loss: 0.765429  [   96/  130]
train() client id: f_00008-9-3 loss: 0.813244  [  128/  130]
train() client id: f_00008-10-0 loss: 0.805536  [   32/  130]
train() client id: f_00008-10-1 loss: 0.666549  [   64/  130]
train() client id: f_00008-10-2 loss: 0.781245  [   96/  130]
train() client id: f_00008-10-3 loss: 0.679015  [  128/  130]
train() client id: f_00008-11-0 loss: 0.810064  [   32/  130]
train() client id: f_00008-11-1 loss: 0.657313  [   64/  130]
train() client id: f_00008-11-2 loss: 0.721241  [   96/  130]
train() client id: f_00008-11-3 loss: 0.706868  [  128/  130]
train() client id: f_00008-12-0 loss: 0.726350  [   32/  130]
train() client id: f_00008-12-1 loss: 0.800051  [   64/  130]
train() client id: f_00008-12-2 loss: 0.674213  [   96/  130]
train() client id: f_00008-12-3 loss: 0.732100  [  128/  130]
train() client id: f_00009-0-0 loss: 1.216646  [   32/  118]
train() client id: f_00009-0-1 loss: 1.080455  [   64/  118]
train() client id: f_00009-0-2 loss: 1.109855  [   96/  118]
train() client id: f_00009-1-0 loss: 1.115644  [   32/  118]
train() client id: f_00009-1-1 loss: 1.055903  [   64/  118]
train() client id: f_00009-1-2 loss: 1.095066  [   96/  118]
train() client id: f_00009-2-0 loss: 1.005012  [   32/  118]
train() client id: f_00009-2-1 loss: 1.101388  [   64/  118]
train() client id: f_00009-2-2 loss: 0.850937  [   96/  118]
train() client id: f_00009-3-0 loss: 1.133919  [   32/  118]
train() client id: f_00009-3-1 loss: 0.942473  [   64/  118]
train() client id: f_00009-3-2 loss: 1.042985  [   96/  118]
train() client id: f_00009-4-0 loss: 0.981379  [   32/  118]
train() client id: f_00009-4-1 loss: 1.027130  [   64/  118]
train() client id: f_00009-4-2 loss: 0.938279  [   96/  118]
train() client id: f_00009-5-0 loss: 0.890350  [   32/  118]
train() client id: f_00009-5-1 loss: 1.037979  [   64/  118]
train() client id: f_00009-5-2 loss: 0.810794  [   96/  118]
train() client id: f_00009-6-0 loss: 0.901182  [   32/  118]
train() client id: f_00009-6-1 loss: 0.994741  [   64/  118]
train() client id: f_00009-6-2 loss: 0.835558  [   96/  118]
train() client id: f_00009-7-0 loss: 1.022331  [   32/  118]
train() client id: f_00009-7-1 loss: 0.874697  [   64/  118]
train() client id: f_00009-7-2 loss: 0.813431  [   96/  118]
train() client id: f_00009-8-0 loss: 0.904814  [   32/  118]
train() client id: f_00009-8-1 loss: 0.861887  [   64/  118]
train() client id: f_00009-8-2 loss: 0.907931  [   96/  118]
train() client id: f_00009-9-0 loss: 0.805902  [   32/  118]
train() client id: f_00009-9-1 loss: 0.909295  [   64/  118]
train() client id: f_00009-9-2 loss: 0.925424  [   96/  118]
train() client id: f_00009-10-0 loss: 0.817202  [   32/  118]
train() client id: f_00009-10-1 loss: 0.860179  [   64/  118]
train() client id: f_00009-10-2 loss: 0.986248  [   96/  118]
train() client id: f_00009-11-0 loss: 0.885912  [   32/  118]
train() client id: f_00009-11-1 loss: 0.824837  [   64/  118]
train() client id: f_00009-11-2 loss: 0.851808  [   96/  118]
train() client id: f_00009-12-0 loss: 0.995134  [   32/  118]
train() client id: f_00009-12-1 loss: 0.872859  [   64/  118]
train() client id: f_00009-12-2 loss: 0.866292  [   96/  118]
At round 28 accuracy: 0.6392572944297082
At round 28 training accuracy: 0.5801475519785378
At round 28 training loss: 0.8394179669420158
gradient difference: 0.3806648850440979
train() client id: f_00000-0-0 loss: 1.225837  [   32/  126]
train() client id: f_00000-0-1 loss: 1.241538  [   64/  126]
train() client id: f_00000-0-2 loss: 1.097703  [   96/  126]
train() client id: f_00000-1-0 loss: 1.041693  [   32/  126]
train() client id: f_00000-1-1 loss: 0.995552  [   64/  126]
train() client id: f_00000-1-2 loss: 1.309965  [   96/  126]
train() client id: f_00000-2-0 loss: 1.070179  [   32/  126]
train() client id: f_00000-2-1 loss: 0.982449  [   64/  126]
train() client id: f_00000-2-2 loss: 0.933888  [   96/  126]
train() client id: f_00000-3-0 loss: 1.001418  [   32/  126]
train() client id: f_00000-3-1 loss: 0.967844  [   64/  126]
train() client id: f_00000-3-2 loss: 0.802255  [   96/  126]
train() client id: f_00000-4-0 loss: 0.785198  [   32/  126]
train() client id: f_00000-4-1 loss: 0.794604  [   64/  126]
train() client id: f_00000-4-2 loss: 0.808897  [   96/  126]
train() client id: f_00000-5-0 loss: 0.823187  [   32/  126]
train() client id: f_00000-5-1 loss: 0.875331  [   64/  126]
train() client id: f_00000-5-2 loss: 0.776219  [   96/  126]
train() client id: f_00000-6-0 loss: 0.780822  [   32/  126]
train() client id: f_00000-6-1 loss: 0.744312  [   64/  126]
train() client id: f_00000-6-2 loss: 0.846991  [   96/  126]
train() client id: f_00000-7-0 loss: 0.726064  [   32/  126]
train() client id: f_00000-7-1 loss: 0.767752  [   64/  126]
train() client id: f_00000-7-2 loss: 0.723845  [   96/  126]
train() client id: f_00000-8-0 loss: 0.884243  [   32/  126]
train() client id: f_00000-8-1 loss: 0.728966  [   64/  126]
train() client id: f_00000-8-2 loss: 0.746116  [   96/  126]
train() client id: f_00000-9-0 loss: 0.829255  [   32/  126]
train() client id: f_00000-9-1 loss: 0.627545  [   64/  126]
train() client id: f_00000-9-2 loss: 0.781422  [   96/  126]
train() client id: f_00000-10-0 loss: 0.687388  [   32/  126]
train() client id: f_00000-10-1 loss: 0.788647  [   64/  126]
train() client id: f_00000-10-2 loss: 0.771955  [   96/  126]
train() client id: f_00000-11-0 loss: 0.705843  [   32/  126]
train() client id: f_00000-11-1 loss: 0.672697  [   64/  126]
train() client id: f_00000-11-2 loss: 0.629665  [   96/  126]
train() client id: f_00000-12-0 loss: 0.670933  [   32/  126]
train() client id: f_00000-12-1 loss: 0.682059  [   64/  126]
train() client id: f_00000-12-2 loss: 0.715104  [   96/  126]
train() client id: f_00001-0-0 loss: 0.453696  [   32/  265]
train() client id: f_00001-0-1 loss: 0.306671  [   64/  265]
train() client id: f_00001-0-2 loss: 0.404680  [   96/  265]
train() client id: f_00001-0-3 loss: 0.344928  [  128/  265]
train() client id: f_00001-0-4 loss: 0.391512  [  160/  265]
train() client id: f_00001-0-5 loss: 0.327083  [  192/  265]
train() client id: f_00001-0-6 loss: 0.451663  [  224/  265]
train() client id: f_00001-0-7 loss: 0.414246  [  256/  265]
train() client id: f_00001-1-0 loss: 0.319705  [   32/  265]
train() client id: f_00001-1-1 loss: 0.573511  [   64/  265]
train() client id: f_00001-1-2 loss: 0.317393  [   96/  265]
train() client id: f_00001-1-3 loss: 0.381214  [  128/  265]
train() client id: f_00001-1-4 loss: 0.345703  [  160/  265]
train() client id: f_00001-1-5 loss: 0.403085  [  192/  265]
train() client id: f_00001-1-6 loss: 0.463105  [  224/  265]
train() client id: f_00001-1-7 loss: 0.311915  [  256/  265]
train() client id: f_00001-2-0 loss: 0.536786  [   32/  265]
train() client id: f_00001-2-1 loss: 0.340269  [   64/  265]
train() client id: f_00001-2-2 loss: 0.315623  [   96/  265]
train() client id: f_00001-2-3 loss: 0.290969  [  128/  265]
train() client id: f_00001-2-4 loss: 0.299874  [  160/  265]
train() client id: f_00001-2-5 loss: 0.446195  [  192/  265]
train() client id: f_00001-2-6 loss: 0.361366  [  224/  265]
train() client id: f_00001-2-7 loss: 0.467503  [  256/  265]
train() client id: f_00001-3-0 loss: 0.484511  [   32/  265]
train() client id: f_00001-3-1 loss: 0.384515  [   64/  265]
train() client id: f_00001-3-2 loss: 0.392763  [   96/  265]
train() client id: f_00001-3-3 loss: 0.378683  [  128/  265]
train() client id: f_00001-3-4 loss: 0.344105  [  160/  265]
train() client id: f_00001-3-5 loss: 0.336422  [  192/  265]
train() client id: f_00001-3-6 loss: 0.336484  [  224/  265]
train() client id: f_00001-3-7 loss: 0.373530  [  256/  265]
train() client id: f_00001-4-0 loss: 0.417557  [   32/  265]
train() client id: f_00001-4-1 loss: 0.409726  [   64/  265]
train() client id: f_00001-4-2 loss: 0.327905  [   96/  265]
train() client id: f_00001-4-3 loss: 0.287819  [  128/  265]
train() client id: f_00001-4-4 loss: 0.364463  [  160/  265]
train() client id: f_00001-4-5 loss: 0.469424  [  192/  265]
train() client id: f_00001-4-6 loss: 0.385865  [  224/  265]
train() client id: f_00001-4-7 loss: 0.322425  [  256/  265]
train() client id: f_00001-5-0 loss: 0.412576  [   32/  265]
train() client id: f_00001-5-1 loss: 0.294077  [   64/  265]
train() client id: f_00001-5-2 loss: 0.276638  [   96/  265]
train() client id: f_00001-5-3 loss: 0.331466  [  128/  265]
train() client id: f_00001-5-4 loss: 0.282376  [  160/  265]
train() client id: f_00001-5-5 loss: 0.533154  [  192/  265]
train() client id: f_00001-5-6 loss: 0.306446  [  224/  265]
train() client id: f_00001-5-7 loss: 0.433477  [  256/  265]
train() client id: f_00001-6-0 loss: 0.287864  [   32/  265]
train() client id: f_00001-6-1 loss: 0.275677  [   64/  265]
train() client id: f_00001-6-2 loss: 0.300020  [   96/  265]
train() client id: f_00001-6-3 loss: 0.423663  [  128/  265]
train() client id: f_00001-6-4 loss: 0.383060  [  160/  265]
train() client id: f_00001-6-5 loss: 0.487714  [  192/  265]
train() client id: f_00001-6-6 loss: 0.337017  [  224/  265]
train() client id: f_00001-6-7 loss: 0.446535  [  256/  265]
train() client id: f_00001-7-0 loss: 0.401791  [   32/  265]
train() client id: f_00001-7-1 loss: 0.332777  [   64/  265]
train() client id: f_00001-7-2 loss: 0.472018  [   96/  265]
train() client id: f_00001-7-3 loss: 0.372535  [  128/  265]
train() client id: f_00001-7-4 loss: 0.342140  [  160/  265]
train() client id: f_00001-7-5 loss: 0.269114  [  192/  265]
train() client id: f_00001-7-6 loss: 0.292873  [  224/  265]
train() client id: f_00001-7-7 loss: 0.408925  [  256/  265]
train() client id: f_00001-8-0 loss: 0.427609  [   32/  265]
train() client id: f_00001-8-1 loss: 0.512301  [   64/  265]
train() client id: f_00001-8-2 loss: 0.274426  [   96/  265]
train() client id: f_00001-8-3 loss: 0.323608  [  128/  265]
train() client id: f_00001-8-4 loss: 0.448483  [  160/  265]
train() client id: f_00001-8-5 loss: 0.308727  [  192/  265]
train() client id: f_00001-8-6 loss: 0.300461  [  224/  265]
train() client id: f_00001-8-7 loss: 0.322883  [  256/  265]
train() client id: f_00001-9-0 loss: 0.351896  [   32/  265]
train() client id: f_00001-9-1 loss: 0.323601  [   64/  265]
train() client id: f_00001-9-2 loss: 0.351443  [   96/  265]
train() client id: f_00001-9-3 loss: 0.366158  [  128/  265]
train() client id: f_00001-9-4 loss: 0.426212  [  160/  265]
train() client id: f_00001-9-5 loss: 0.326834  [  192/  265]
train() client id: f_00001-9-6 loss: 0.396205  [  224/  265]
train() client id: f_00001-9-7 loss: 0.285503  [  256/  265]
train() client id: f_00001-10-0 loss: 0.347721  [   32/  265]
train() client id: f_00001-10-1 loss: 0.330625  [   64/  265]
train() client id: f_00001-10-2 loss: 0.393481  [   96/  265]
train() client id: f_00001-10-3 loss: 0.388345  [  128/  265]
train() client id: f_00001-10-4 loss: 0.323809  [  160/  265]
train() client id: f_00001-10-5 loss: 0.337394  [  192/  265]
train() client id: f_00001-10-6 loss: 0.487205  [  224/  265]
train() client id: f_00001-10-7 loss: 0.302872  [  256/  265]
train() client id: f_00001-11-0 loss: 0.267092  [   32/  265]
train() client id: f_00001-11-1 loss: 0.457355  [   64/  265]
train() client id: f_00001-11-2 loss: 0.351982  [   96/  265]
train() client id: f_00001-11-3 loss: 0.355478  [  128/  265]
train() client id: f_00001-11-4 loss: 0.369897  [  160/  265]
train() client id: f_00001-11-5 loss: 0.385926  [  192/  265]
train() client id: f_00001-11-6 loss: 0.286272  [  224/  265]
train() client id: f_00001-11-7 loss: 0.356660  [  256/  265]
train() client id: f_00001-12-0 loss: 0.324413  [   32/  265]
train() client id: f_00001-12-1 loss: 0.444573  [   64/  265]
train() client id: f_00001-12-2 loss: 0.518372  [   96/  265]
train() client id: f_00001-12-3 loss: 0.322609  [  128/  265]
train() client id: f_00001-12-4 loss: 0.348002  [  160/  265]
train() client id: f_00001-12-5 loss: 0.285777  [  192/  265]
train() client id: f_00001-12-6 loss: 0.396142  [  224/  265]
train() client id: f_00001-12-7 loss: 0.262868  [  256/  265]
train() client id: f_00002-0-0 loss: 1.359902  [   32/  124]
train() client id: f_00002-0-1 loss: 1.287814  [   64/  124]
train() client id: f_00002-0-2 loss: 1.226081  [   96/  124]
train() client id: f_00002-1-0 loss: 1.339897  [   32/  124]
train() client id: f_00002-1-1 loss: 1.348285  [   64/  124]
train() client id: f_00002-1-2 loss: 1.133401  [   96/  124]
train() client id: f_00002-2-0 loss: 1.349251  [   32/  124]
train() client id: f_00002-2-1 loss: 1.226576  [   64/  124]
train() client id: f_00002-2-2 loss: 1.106514  [   96/  124]
train() client id: f_00002-3-0 loss: 1.047741  [   32/  124]
train() client id: f_00002-3-1 loss: 1.097759  [   64/  124]
train() client id: f_00002-3-2 loss: 1.194901  [   96/  124]
train() client id: f_00002-4-0 loss: 0.998323  [   32/  124]
train() client id: f_00002-4-1 loss: 1.307965  [   64/  124]
train() client id: f_00002-4-2 loss: 1.026003  [   96/  124]
train() client id: f_00002-5-0 loss: 1.231666  [   32/  124]
train() client id: f_00002-5-1 loss: 0.956642  [   64/  124]
train() client id: f_00002-5-2 loss: 1.151482  [   96/  124]
train() client id: f_00002-6-0 loss: 0.948772  [   32/  124]
train() client id: f_00002-6-1 loss: 1.027090  [   64/  124]
train() client id: f_00002-6-2 loss: 1.121599  [   96/  124]
train() client id: f_00002-7-0 loss: 1.051928  [   32/  124]
train() client id: f_00002-7-1 loss: 1.134194  [   64/  124]
train() client id: f_00002-7-2 loss: 1.002331  [   96/  124]
train() client id: f_00002-8-0 loss: 1.082967  [   32/  124]
train() client id: f_00002-8-1 loss: 1.093864  [   64/  124]
train() client id: f_00002-8-2 loss: 0.889296  [   96/  124]
train() client id: f_00002-9-0 loss: 1.007861  [   32/  124]
train() client id: f_00002-9-1 loss: 1.051647  [   64/  124]
train() client id: f_00002-9-2 loss: 0.916229  [   96/  124]
train() client id: f_00002-10-0 loss: 0.914989  [   32/  124]
train() client id: f_00002-10-1 loss: 0.888114  [   64/  124]
train() client id: f_00002-10-2 loss: 1.115857  [   96/  124]
train() client id: f_00002-11-0 loss: 0.845874  [   32/  124]
train() client id: f_00002-11-1 loss: 1.016181  [   64/  124]
train() client id: f_00002-11-2 loss: 1.062286  [   96/  124]
train() client id: f_00002-12-0 loss: 1.281013  [   32/  124]
train() client id: f_00002-12-1 loss: 0.753859  [   64/  124]
train() client id: f_00002-12-2 loss: 1.003326  [   96/  124]
train() client id: f_00003-0-0 loss: 0.888740  [   32/   43]
train() client id: f_00003-1-0 loss: 0.967943  [   32/   43]
train() client id: f_00003-2-0 loss: 0.731726  [   32/   43]
train() client id: f_00003-3-0 loss: 0.837415  [   32/   43]
train() client id: f_00003-4-0 loss: 0.869474  [   32/   43]
train() client id: f_00003-5-0 loss: 0.795194  [   32/   43]
train() client id: f_00003-6-0 loss: 0.932294  [   32/   43]
train() client id: f_00003-7-0 loss: 0.835913  [   32/   43]
train() client id: f_00003-8-0 loss: 0.858529  [   32/   43]
train() client id: f_00003-9-0 loss: 0.880395  [   32/   43]
train() client id: f_00003-10-0 loss: 0.926741  [   32/   43]
train() client id: f_00003-11-0 loss: 0.857827  [   32/   43]
train() client id: f_00003-12-0 loss: 0.678992  [   32/   43]
train() client id: f_00004-0-0 loss: 0.668801  [   32/  306]
train() client id: f_00004-0-1 loss: 0.827375  [   64/  306]
train() client id: f_00004-0-2 loss: 0.770650  [   96/  306]
train() client id: f_00004-0-3 loss: 0.807303  [  128/  306]
train() client id: f_00004-0-4 loss: 0.755270  [  160/  306]
train() client id: f_00004-0-5 loss: 0.788056  [  192/  306]
train() client id: f_00004-0-6 loss: 0.699154  [  224/  306]
train() client id: f_00004-0-7 loss: 0.746067  [  256/  306]
train() client id: f_00004-0-8 loss: 0.780113  [  288/  306]
train() client id: f_00004-1-0 loss: 0.837433  [   32/  306]
train() client id: f_00004-1-1 loss: 0.800693  [   64/  306]
train() client id: f_00004-1-2 loss: 0.727947  [   96/  306]
train() client id: f_00004-1-3 loss: 0.846862  [  128/  306]
train() client id: f_00004-1-4 loss: 0.757851  [  160/  306]
train() client id: f_00004-1-5 loss: 0.803655  [  192/  306]
train() client id: f_00004-1-6 loss: 0.731522  [  224/  306]
train() client id: f_00004-1-7 loss: 0.716492  [  256/  306]
train() client id: f_00004-1-8 loss: 0.716660  [  288/  306]
train() client id: f_00004-2-0 loss: 0.838590  [   32/  306]
train() client id: f_00004-2-1 loss: 0.791142  [   64/  306]
train() client id: f_00004-2-2 loss: 0.723741  [   96/  306]
train() client id: f_00004-2-3 loss: 0.649503  [  128/  306]
train() client id: f_00004-2-4 loss: 0.789889  [  160/  306]
train() client id: f_00004-2-5 loss: 0.680148  [  192/  306]
train() client id: f_00004-2-6 loss: 0.792936  [  224/  306]
train() client id: f_00004-2-7 loss: 0.834047  [  256/  306]
train() client id: f_00004-2-8 loss: 0.702904  [  288/  306]
train() client id: f_00004-3-0 loss: 0.874470  [   32/  306]
train() client id: f_00004-3-1 loss: 0.741317  [   64/  306]
train() client id: f_00004-3-2 loss: 0.568344  [   96/  306]
train() client id: f_00004-3-3 loss: 0.764614  [  128/  306]
train() client id: f_00004-3-4 loss: 0.812665  [  160/  306]
train() client id: f_00004-3-5 loss: 0.838652  [  192/  306]
train() client id: f_00004-3-6 loss: 0.847288  [  224/  306]
train() client id: f_00004-3-7 loss: 0.736613  [  256/  306]
train() client id: f_00004-3-8 loss: 0.754638  [  288/  306]
train() client id: f_00004-4-0 loss: 0.647355  [   32/  306]
train() client id: f_00004-4-1 loss: 0.704388  [   64/  306]
train() client id: f_00004-4-2 loss: 0.714692  [   96/  306]
train() client id: f_00004-4-3 loss: 0.752062  [  128/  306]
train() client id: f_00004-4-4 loss: 0.813781  [  160/  306]
train() client id: f_00004-4-5 loss: 0.743375  [  192/  306]
train() client id: f_00004-4-6 loss: 0.885049  [  224/  306]
train() client id: f_00004-4-7 loss: 0.767033  [  256/  306]
train() client id: f_00004-4-8 loss: 0.875469  [  288/  306]
train() client id: f_00004-5-0 loss: 0.764394  [   32/  306]
train() client id: f_00004-5-1 loss: 0.718900  [   64/  306]
train() client id: f_00004-5-2 loss: 0.802794  [   96/  306]
train() client id: f_00004-5-3 loss: 0.784087  [  128/  306]
train() client id: f_00004-5-4 loss: 0.772821  [  160/  306]
train() client id: f_00004-5-5 loss: 0.759568  [  192/  306]
train() client id: f_00004-5-6 loss: 0.825199  [  224/  306]
train() client id: f_00004-5-7 loss: 0.710939  [  256/  306]
train() client id: f_00004-5-8 loss: 0.829165  [  288/  306]
train() client id: f_00004-6-0 loss: 0.848922  [   32/  306]
train() client id: f_00004-6-1 loss: 0.900252  [   64/  306]
train() client id: f_00004-6-2 loss: 0.718069  [   96/  306]
train() client id: f_00004-6-3 loss: 0.662820  [  128/  306]
train() client id: f_00004-6-4 loss: 0.724123  [  160/  306]
train() client id: f_00004-6-5 loss: 0.765685  [  192/  306]
train() client id: f_00004-6-6 loss: 0.775776  [  224/  306]
train() client id: f_00004-6-7 loss: 0.686538  [  256/  306]
train() client id: f_00004-6-8 loss: 0.797136  [  288/  306]
train() client id: f_00004-7-0 loss: 0.801276  [   32/  306]
train() client id: f_00004-7-1 loss: 0.726409  [   64/  306]
train() client id: f_00004-7-2 loss: 0.778786  [   96/  306]
train() client id: f_00004-7-3 loss: 0.783193  [  128/  306]
train() client id: f_00004-7-4 loss: 0.728303  [  160/  306]
train() client id: f_00004-7-5 loss: 0.786159  [  192/  306]
train() client id: f_00004-7-6 loss: 0.841473  [  224/  306]
train() client id: f_00004-7-7 loss: 0.715261  [  256/  306]
train() client id: f_00004-7-8 loss: 0.623011  [  288/  306]
train() client id: f_00004-8-0 loss: 0.804028  [   32/  306]
train() client id: f_00004-8-1 loss: 0.813112  [   64/  306]
train() client id: f_00004-8-2 loss: 0.664536  [   96/  306]
train() client id: f_00004-8-3 loss: 0.868138  [  128/  306]
train() client id: f_00004-8-4 loss: 0.798166  [  160/  306]
train() client id: f_00004-8-5 loss: 0.799850  [  192/  306]
train() client id: f_00004-8-6 loss: 0.745070  [  224/  306]
train() client id: f_00004-8-7 loss: 0.732951  [  256/  306]
train() client id: f_00004-8-8 loss: 0.710825  [  288/  306]
train() client id: f_00004-9-0 loss: 0.839163  [   32/  306]
train() client id: f_00004-9-1 loss: 0.682809  [   64/  306]
train() client id: f_00004-9-2 loss: 0.768722  [   96/  306]
train() client id: f_00004-9-3 loss: 0.850299  [  128/  306]
train() client id: f_00004-9-4 loss: 0.814831  [  160/  306]
train() client id: f_00004-9-5 loss: 0.704942  [  192/  306]
train() client id: f_00004-9-6 loss: 0.847335  [  224/  306]
train() client id: f_00004-9-7 loss: 0.847007  [  256/  306]
train() client id: f_00004-9-8 loss: 0.730507  [  288/  306]
train() client id: f_00004-10-0 loss: 0.826801  [   32/  306]
train() client id: f_00004-10-1 loss: 0.821952  [   64/  306]
train() client id: f_00004-10-2 loss: 0.849668  [   96/  306]
train() client id: f_00004-10-3 loss: 0.894222  [  128/  306]
train() client id: f_00004-10-4 loss: 0.652543  [  160/  306]
train() client id: f_00004-10-5 loss: 0.743849  [  192/  306]
train() client id: f_00004-10-6 loss: 0.701819  [  224/  306]
train() client id: f_00004-10-7 loss: 0.781782  [  256/  306]
train() client id: f_00004-10-8 loss: 0.801711  [  288/  306]
train() client id: f_00004-11-0 loss: 0.829613  [   32/  306]
train() client id: f_00004-11-1 loss: 0.760761  [   64/  306]
train() client id: f_00004-11-2 loss: 0.763375  [   96/  306]
train() client id: f_00004-11-3 loss: 0.766180  [  128/  306]
train() client id: f_00004-11-4 loss: 0.679614  [  160/  306]
train() client id: f_00004-11-5 loss: 0.878958  [  192/  306]
train() client id: f_00004-11-6 loss: 0.796910  [  224/  306]
train() client id: f_00004-11-7 loss: 0.744797  [  256/  306]
train() client id: f_00004-11-8 loss: 0.823015  [  288/  306]
train() client id: f_00004-12-0 loss: 0.716145  [   32/  306]
train() client id: f_00004-12-1 loss: 0.707929  [   64/  306]
train() client id: f_00004-12-2 loss: 0.747448  [   96/  306]
train() client id: f_00004-12-3 loss: 0.719828  [  128/  306]
train() client id: f_00004-12-4 loss: 0.845140  [  160/  306]
train() client id: f_00004-12-5 loss: 0.790201  [  192/  306]
train() client id: f_00004-12-6 loss: 0.920197  [  224/  306]
train() client id: f_00004-12-7 loss: 0.809461  [  256/  306]
train() client id: f_00004-12-8 loss: 0.810877  [  288/  306]
train() client id: f_00005-0-0 loss: 0.955614  [   32/  146]
train() client id: f_00005-0-1 loss: 0.539657  [   64/  146]
train() client id: f_00005-0-2 loss: 0.945184  [   96/  146]
train() client id: f_00005-0-3 loss: 0.933506  [  128/  146]
train() client id: f_00005-1-0 loss: 0.627809  [   32/  146]
train() client id: f_00005-1-1 loss: 0.827031  [   64/  146]
train() client id: f_00005-1-2 loss: 0.677968  [   96/  146]
train() client id: f_00005-1-3 loss: 0.848260  [  128/  146]
train() client id: f_00005-2-0 loss: 0.907244  [   32/  146]
train() client id: f_00005-2-1 loss: 0.790650  [   64/  146]
train() client id: f_00005-2-2 loss: 0.637328  [   96/  146]
train() client id: f_00005-2-3 loss: 0.863425  [  128/  146]
train() client id: f_00005-3-0 loss: 0.731780  [   32/  146]
train() client id: f_00005-3-1 loss: 0.823231  [   64/  146]
train() client id: f_00005-3-2 loss: 0.916747  [   96/  146]
train() client id: f_00005-3-3 loss: 0.757825  [  128/  146]
train() client id: f_00005-4-0 loss: 0.856723  [   32/  146]
train() client id: f_00005-4-1 loss: 0.581431  [   64/  146]
train() client id: f_00005-4-2 loss: 0.878678  [   96/  146]
train() client id: f_00005-4-3 loss: 0.779563  [  128/  146]
train() client id: f_00005-5-0 loss: 0.652247  [   32/  146]
train() client id: f_00005-5-1 loss: 1.044298  [   64/  146]
train() client id: f_00005-5-2 loss: 0.736317  [   96/  146]
train() client id: f_00005-5-3 loss: 0.741304  [  128/  146]
train() client id: f_00005-6-0 loss: 0.710492  [   32/  146]
train() client id: f_00005-6-1 loss: 0.602956  [   64/  146]
train() client id: f_00005-6-2 loss: 1.133144  [   96/  146]
train() client id: f_00005-6-3 loss: 0.893161  [  128/  146]
train() client id: f_00005-7-0 loss: 0.770292  [   32/  146]
train() client id: f_00005-7-1 loss: 0.837508  [   64/  146]
train() client id: f_00005-7-2 loss: 1.079903  [   96/  146]
train() client id: f_00005-7-3 loss: 0.654998  [  128/  146]
train() client id: f_00005-8-0 loss: 0.693208  [   32/  146]
train() client id: f_00005-8-1 loss: 1.021457  [   64/  146]
train() client id: f_00005-8-2 loss: 0.821155  [   96/  146]
train() client id: f_00005-8-3 loss: 0.788213  [  128/  146]
train() client id: f_00005-9-0 loss: 0.920345  [   32/  146]
train() client id: f_00005-9-1 loss: 0.671941  [   64/  146]
train() client id: f_00005-9-2 loss: 1.000883  [   96/  146]
train() client id: f_00005-9-3 loss: 0.759676  [  128/  146]
train() client id: f_00005-10-0 loss: 0.870961  [   32/  146]
train() client id: f_00005-10-1 loss: 0.993622  [   64/  146]
train() client id: f_00005-10-2 loss: 0.692104  [   96/  146]
train() client id: f_00005-10-3 loss: 0.644845  [  128/  146]
train() client id: f_00005-11-0 loss: 0.874611  [   32/  146]
train() client id: f_00005-11-1 loss: 0.770333  [   64/  146]
train() client id: f_00005-11-2 loss: 0.583457  [   96/  146]
train() client id: f_00005-11-3 loss: 0.995101  [  128/  146]
train() client id: f_00005-12-0 loss: 0.990092  [   32/  146]
train() client id: f_00005-12-1 loss: 0.832986  [   64/  146]
train() client id: f_00005-12-2 loss: 0.754234  [   96/  146]
train() client id: f_00005-12-3 loss: 0.822685  [  128/  146]
train() client id: f_00006-0-0 loss: 0.524651  [   32/   54]
train() client id: f_00006-1-0 loss: 0.525604  [   32/   54]
train() client id: f_00006-2-0 loss: 0.591330  [   32/   54]
train() client id: f_00006-3-0 loss: 0.532220  [   32/   54]
train() client id: f_00006-4-0 loss: 0.531896  [   32/   54]
train() client id: f_00006-5-0 loss: 0.570623  [   32/   54]
train() client id: f_00006-6-0 loss: 0.527989  [   32/   54]
train() client id: f_00006-7-0 loss: 0.472186  [   32/   54]
train() client id: f_00006-8-0 loss: 0.584217  [   32/   54]
train() client id: f_00006-9-0 loss: 0.555815  [   32/   54]
train() client id: f_00006-10-0 loss: 0.590006  [   32/   54]
train() client id: f_00006-11-0 loss: 0.514852  [   32/   54]
train() client id: f_00006-12-0 loss: 0.586551  [   32/   54]
train() client id: f_00007-0-0 loss: 0.864649  [   32/  179]
train() client id: f_00007-0-1 loss: 0.714619  [   64/  179]
train() client id: f_00007-0-2 loss: 0.739946  [   96/  179]
train() client id: f_00007-0-3 loss: 0.824980  [  128/  179]
train() client id: f_00007-0-4 loss: 0.571241  [  160/  179]
train() client id: f_00007-1-0 loss: 0.742184  [   32/  179]
train() client id: f_00007-1-1 loss: 0.742569  [   64/  179]
train() client id: f_00007-1-2 loss: 0.631889  [   96/  179]
train() client id: f_00007-1-3 loss: 0.793150  [  128/  179]
train() client id: f_00007-1-4 loss: 0.671655  [  160/  179]
train() client id: f_00007-2-0 loss: 0.573126  [   32/  179]
train() client id: f_00007-2-1 loss: 0.848130  [   64/  179]
train() client id: f_00007-2-2 loss: 0.628506  [   96/  179]
train() client id: f_00007-2-3 loss: 0.542846  [  128/  179]
train() client id: f_00007-2-4 loss: 0.956368  [  160/  179]
train() client id: f_00007-3-0 loss: 0.663043  [   32/  179]
train() client id: f_00007-3-1 loss: 0.783055  [   64/  179]
train() client id: f_00007-3-2 loss: 0.787048  [   96/  179]
train() client id: f_00007-3-3 loss: 0.715442  [  128/  179]
train() client id: f_00007-3-4 loss: 0.604109  [  160/  179]
train() client id: f_00007-4-0 loss: 0.710930  [   32/  179]
train() client id: f_00007-4-1 loss: 0.710760  [   64/  179]
train() client id: f_00007-4-2 loss: 0.641087  [   96/  179]
train() client id: f_00007-4-3 loss: 0.701183  [  128/  179]
train() client id: f_00007-4-4 loss: 0.569124  [  160/  179]
train() client id: f_00007-5-0 loss: 0.592007  [   32/  179]
train() client id: f_00007-5-1 loss: 0.652355  [   64/  179]
train() client id: f_00007-5-2 loss: 0.778541  [   96/  179]
train() client id: f_00007-5-3 loss: 0.861763  [  128/  179]
train() client id: f_00007-5-4 loss: 0.673111  [  160/  179]
train() client id: f_00007-6-0 loss: 0.647853  [   32/  179]
train() client id: f_00007-6-1 loss: 0.710893  [   64/  179]
train() client id: f_00007-6-2 loss: 0.540802  [   96/  179]
train() client id: f_00007-6-3 loss: 0.796097  [  128/  179]
train() client id: f_00007-6-4 loss: 0.759280  [  160/  179]
train() client id: f_00007-7-0 loss: 0.621730  [   32/  179]
train() client id: f_00007-7-1 loss: 0.852044  [   64/  179]
train() client id: f_00007-7-2 loss: 0.588914  [   96/  179]
train() client id: f_00007-7-3 loss: 0.622033  [  128/  179]
train() client id: f_00007-7-4 loss: 0.828000  [  160/  179]
train() client id: f_00007-8-0 loss: 0.704703  [   32/  179]
train() client id: f_00007-8-1 loss: 0.729302  [   64/  179]
train() client id: f_00007-8-2 loss: 0.655881  [   96/  179]
train() client id: f_00007-8-3 loss: 0.762979  [  128/  179]
train() client id: f_00007-8-4 loss: 0.565944  [  160/  179]
train() client id: f_00007-9-0 loss: 0.876249  [   32/  179]
train() client id: f_00007-9-1 loss: 0.605663  [   64/  179]
train() client id: f_00007-9-2 loss: 0.849632  [   96/  179]
train() client id: f_00007-9-3 loss: 0.538043  [  128/  179]
train() client id: f_00007-9-4 loss: 0.663673  [  160/  179]
train() client id: f_00007-10-0 loss: 0.696060  [   32/  179]
train() client id: f_00007-10-1 loss: 0.742772  [   64/  179]
train() client id: f_00007-10-2 loss: 0.710948  [   96/  179]
train() client id: f_00007-10-3 loss: 0.726662  [  128/  179]
train() client id: f_00007-10-4 loss: 0.574081  [  160/  179]
train() client id: f_00007-11-0 loss: 0.624420  [   32/  179]
train() client id: f_00007-11-1 loss: 0.545918  [   64/  179]
train() client id: f_00007-11-2 loss: 0.633574  [   96/  179]
train() client id: f_00007-11-3 loss: 0.781458  [  128/  179]
train() client id: f_00007-11-4 loss: 0.893620  [  160/  179]
train() client id: f_00007-12-0 loss: 0.762199  [   32/  179]
train() client id: f_00007-12-1 loss: 0.545343  [   64/  179]
train() client id: f_00007-12-2 loss: 0.538268  [   96/  179]
train() client id: f_00007-12-3 loss: 0.957534  [  128/  179]
train() client id: f_00007-12-4 loss: 0.742124  [  160/  179]
train() client id: f_00008-0-0 loss: 0.763694  [   32/  130]
train() client id: f_00008-0-1 loss: 0.668234  [   64/  130]
train() client id: f_00008-0-2 loss: 0.778195  [   96/  130]
train() client id: f_00008-0-3 loss: 0.743418  [  128/  130]
train() client id: f_00008-1-0 loss: 0.682566  [   32/  130]
train() client id: f_00008-1-1 loss: 0.641592  [   64/  130]
train() client id: f_00008-1-2 loss: 0.891400  [   96/  130]
train() client id: f_00008-1-3 loss: 0.734183  [  128/  130]
train() client id: f_00008-2-0 loss: 0.772021  [   32/  130]
train() client id: f_00008-2-1 loss: 0.753611  [   64/  130]
train() client id: f_00008-2-2 loss: 0.692741  [   96/  130]
train() client id: f_00008-2-3 loss: 0.710622  [  128/  130]
train() client id: f_00008-3-0 loss: 0.718947  [   32/  130]
train() client id: f_00008-3-1 loss: 0.775042  [   64/  130]
train() client id: f_00008-3-2 loss: 0.716838  [   96/  130]
train() client id: f_00008-3-3 loss: 0.766989  [  128/  130]
train() client id: f_00008-4-0 loss: 0.754296  [   32/  130]
train() client id: f_00008-4-1 loss: 0.716592  [   64/  130]
train() client id: f_00008-4-2 loss: 0.705815  [   96/  130]
train() client id: f_00008-4-3 loss: 0.764541  [  128/  130]
train() client id: f_00008-5-0 loss: 0.766608  [   32/  130]
train() client id: f_00008-5-1 loss: 0.809728  [   64/  130]
train() client id: f_00008-5-2 loss: 0.694087  [   96/  130]
train() client id: f_00008-5-3 loss: 0.702372  [  128/  130]
train() client id: f_00008-6-0 loss: 0.674866  [   32/  130]
train() client id: f_00008-6-1 loss: 0.770784  [   64/  130]
train() client id: f_00008-6-2 loss: 0.752127  [   96/  130]
train() client id: f_00008-6-3 loss: 0.791985  [  128/  130]
train() client id: f_00008-7-0 loss: 0.703806  [   32/  130]
train() client id: f_00008-7-1 loss: 0.746163  [   64/  130]
train() client id: f_00008-7-2 loss: 0.776581  [   96/  130]
train() client id: f_00008-7-3 loss: 0.721612  [  128/  130]
train() client id: f_00008-8-0 loss: 0.787456  [   32/  130]
train() client id: f_00008-8-1 loss: 0.744077  [   64/  130]
train() client id: f_00008-8-2 loss: 0.742766  [   96/  130]
train() client id: f_00008-8-3 loss: 0.709984  [  128/  130]
train() client id: f_00008-9-0 loss: 0.755190  [   32/  130]
train() client id: f_00008-9-1 loss: 0.670525  [   64/  130]
train() client id: f_00008-9-2 loss: 0.920302  [   96/  130]
train() client id: f_00008-9-3 loss: 0.640902  [  128/  130]
train() client id: f_00008-10-0 loss: 0.759279  [   32/  130]
train() client id: f_00008-10-1 loss: 0.807744  [   64/  130]
train() client id: f_00008-10-2 loss: 0.735195  [   96/  130]
train() client id: f_00008-10-3 loss: 0.688025  [  128/  130]
train() client id: f_00008-11-0 loss: 0.684900  [   32/  130]
train() client id: f_00008-11-1 loss: 0.960769  [   64/  130]
train() client id: f_00008-11-2 loss: 0.659147  [   96/  130]
train() client id: f_00008-11-3 loss: 0.679069  [  128/  130]
train() client id: f_00008-12-0 loss: 0.703931  [   32/  130]
train() client id: f_00008-12-1 loss: 0.830681  [   64/  130]
train() client id: f_00008-12-2 loss: 0.714704  [   96/  130]
train() client id: f_00008-12-3 loss: 0.742891  [  128/  130]
train() client id: f_00009-0-0 loss: 1.194950  [   32/  118]
train() client id: f_00009-0-1 loss: 1.085586  [   64/  118]
train() client id: f_00009-0-2 loss: 1.026417  [   96/  118]
train() client id: f_00009-1-0 loss: 1.054682  [   32/  118]
train() client id: f_00009-1-1 loss: 1.110200  [   64/  118]
train() client id: f_00009-1-2 loss: 1.131982  [   96/  118]
train() client id: f_00009-2-0 loss: 1.096589  [   32/  118]
train() client id: f_00009-2-1 loss: 0.976829  [   64/  118]
train() client id: f_00009-2-2 loss: 0.954229  [   96/  118]
train() client id: f_00009-3-0 loss: 1.163614  [   32/  118]
train() client id: f_00009-3-1 loss: 0.906693  [   64/  118]
train() client id: f_00009-3-2 loss: 0.945130  [   96/  118]
train() client id: f_00009-4-0 loss: 0.991872  [   32/  118]
train() client id: f_00009-4-1 loss: 1.021451  [   64/  118]
train() client id: f_00009-4-2 loss: 0.945022  [   96/  118]
train() client id: f_00009-5-0 loss: 1.077845  [   32/  118]
train() client id: f_00009-5-1 loss: 0.970680  [   64/  118]
train() client id: f_00009-5-2 loss: 0.771835  [   96/  118]
train() client id: f_00009-6-0 loss: 0.984861  [   32/  118]
train() client id: f_00009-6-1 loss: 0.917606  [   64/  118]
train() client id: f_00009-6-2 loss: 0.867810  [   96/  118]
train() client id: f_00009-7-0 loss: 0.950305  [   32/  118]
train() client id: f_00009-7-1 loss: 1.001471  [   64/  118]
train() client id: f_00009-7-2 loss: 0.762982  [   96/  118]
train() client id: f_00009-8-0 loss: 0.905112  [   32/  118]
train() client id: f_00009-8-1 loss: 0.780281  [   64/  118]
train() client id: f_00009-8-2 loss: 0.837213  [   96/  118]
train() client id: f_00009-9-0 loss: 0.900986  [   32/  118]
train() client id: f_00009-9-1 loss: 0.817485  [   64/  118]
train() client id: f_00009-9-2 loss: 0.950715  [   96/  118]
train() client id: f_00009-10-0 loss: 0.873214  [   32/  118]
train() client id: f_00009-10-1 loss: 0.894299  [   64/  118]
train() client id: f_00009-10-2 loss: 0.866672  [   96/  118]
train() client id: f_00009-11-0 loss: 1.059547  [   32/  118]
train() client id: f_00009-11-1 loss: 0.847970  [   64/  118]
train() client id: f_00009-11-2 loss: 0.794595  [   96/  118]
train() client id: f_00009-12-0 loss: 0.879482  [   32/  118]
train() client id: f_00009-12-1 loss: 0.837511  [   64/  118]
train() client id: f_00009-12-2 loss: 0.905362  [   96/  118]
At round 29 accuracy: 0.6392572944297082
At round 29 training accuracy: 0.5848423876592891
At round 29 training loss: 0.8439166625162553
gradient difference: 0.4048001170158386
train() client id: f_00000-0-0 loss: 0.926806  [   32/  126]
train() client id: f_00000-0-1 loss: 1.026839  [   64/  126]
train() client id: f_00000-0-2 loss: 1.027435  [   96/  126]
train() client id: f_00000-1-0 loss: 1.128886  [   32/  126]
train() client id: f_00000-1-1 loss: 0.982890  [   64/  126]
train() client id: f_00000-1-2 loss: 0.847261  [   96/  126]
train() client id: f_00000-2-0 loss: 1.053230  [   32/  126]
train() client id: f_00000-2-1 loss: 0.778146  [   64/  126]
train() client id: f_00000-2-2 loss: 1.011972  [   96/  126]
train() client id: f_00000-3-0 loss: 0.871844  [   32/  126]
train() client id: f_00000-3-1 loss: 0.921103  [   64/  126]
train() client id: f_00000-3-2 loss: 0.812241  [   96/  126]
train() client id: f_00000-4-0 loss: 0.967902  [   32/  126]
train() client id: f_00000-4-1 loss: 0.744492  [   64/  126]
train() client id: f_00000-4-2 loss: 0.803769  [   96/  126]
train() client id: f_00000-5-0 loss: 0.840770  [   32/  126]
train() client id: f_00000-5-1 loss: 0.957238  [   64/  126]
train() client id: f_00000-5-2 loss: 0.657705  [   96/  126]
train() client id: f_00000-6-0 loss: 0.882653  [   32/  126]
train() client id: f_00000-6-1 loss: 0.839379  [   64/  126]
train() client id: f_00000-6-2 loss: 0.826204  [   96/  126]
train() client id: f_00000-7-0 loss: 0.726964  [   32/  126]
train() client id: f_00000-7-1 loss: 0.915598  [   64/  126]
train() client id: f_00000-7-2 loss: 0.844438  [   96/  126]
train() client id: f_00000-8-0 loss: 0.769022  [   32/  126]
train() client id: f_00000-8-1 loss: 0.954777  [   64/  126]
train() client id: f_00000-8-2 loss: 0.690666  [   96/  126]
train() client id: f_00000-9-0 loss: 0.771932  [   32/  126]
train() client id: f_00000-9-1 loss: 0.861478  [   64/  126]
train() client id: f_00000-9-2 loss: 0.773532  [   96/  126]
train() client id: f_00000-10-0 loss: 0.884128  [   32/  126]
train() client id: f_00000-10-1 loss: 0.846134  [   64/  126]
train() client id: f_00000-10-2 loss: 0.728041  [   96/  126]
train() client id: f_00000-11-0 loss: 0.865451  [   32/  126]
train() client id: f_00000-11-1 loss: 0.709744  [   64/  126]
train() client id: f_00000-11-2 loss: 0.887584  [   96/  126]
train() client id: f_00000-12-0 loss: 0.967540  [   32/  126]
train() client id: f_00000-12-1 loss: 0.756572  [   64/  126]
train() client id: f_00000-12-2 loss: 0.745840  [   96/  126]
train() client id: f_00001-0-0 loss: 0.511646  [   32/  265]
train() client id: f_00001-0-1 loss: 0.441480  [   64/  265]
train() client id: f_00001-0-2 loss: 0.476821  [   96/  265]
train() client id: f_00001-0-3 loss: 0.448076  [  128/  265]
train() client id: f_00001-0-4 loss: 0.530662  [  160/  265]
train() client id: f_00001-0-5 loss: 0.404465  [  192/  265]
train() client id: f_00001-0-6 loss: 0.602297  [  224/  265]
train() client id: f_00001-0-7 loss: 0.566601  [  256/  265]
train() client id: f_00001-1-0 loss: 0.439428  [   32/  265]
train() client id: f_00001-1-1 loss: 0.452423  [   64/  265]
train() client id: f_00001-1-2 loss: 0.492975  [   96/  265]
train() client id: f_00001-1-3 loss: 0.594509  [  128/  265]
train() client id: f_00001-1-4 loss: 0.429974  [  160/  265]
train() client id: f_00001-1-5 loss: 0.533091  [  192/  265]
train() client id: f_00001-1-6 loss: 0.449368  [  224/  265]
train() client id: f_00001-1-7 loss: 0.441868  [  256/  265]
train() client id: f_00001-2-0 loss: 0.501959  [   32/  265]
train() client id: f_00001-2-1 loss: 0.477348  [   64/  265]
train() client id: f_00001-2-2 loss: 0.495525  [   96/  265]
train() client id: f_00001-2-3 loss: 0.525791  [  128/  265]
train() client id: f_00001-2-4 loss: 0.537169  [  160/  265]
train() client id: f_00001-2-5 loss: 0.456259  [  192/  265]
train() client id: f_00001-2-6 loss: 0.417260  [  224/  265]
train() client id: f_00001-2-7 loss: 0.459573  [  256/  265]
train() client id: f_00001-3-0 loss: 0.511411  [   32/  265]
train() client id: f_00001-3-1 loss: 0.392035  [   64/  265]
train() client id: f_00001-3-2 loss: 0.527286  [   96/  265]
train() client id: f_00001-3-3 loss: 0.416645  [  128/  265]
train() client id: f_00001-3-4 loss: 0.520115  [  160/  265]
train() client id: f_00001-3-5 loss: 0.527765  [  192/  265]
train() client id: f_00001-3-6 loss: 0.449603  [  224/  265]
train() client id: f_00001-3-7 loss: 0.554044  [  256/  265]
train() client id: f_00001-4-0 loss: 0.576596  [   32/  265]
train() client id: f_00001-4-1 loss: 0.493841  [   64/  265]
train() client id: f_00001-4-2 loss: 0.513109  [   96/  265]
train() client id: f_00001-4-3 loss: 0.415929  [  128/  265]
train() client id: f_00001-4-4 loss: 0.431263  [  160/  265]
train() client id: f_00001-4-5 loss: 0.408659  [  192/  265]
train() client id: f_00001-4-6 loss: 0.526940  [  224/  265]
train() client id: f_00001-4-7 loss: 0.497559  [  256/  265]
train() client id: f_00001-5-0 loss: 0.384297  [   32/  265]
train() client id: f_00001-5-1 loss: 0.477894  [   64/  265]
train() client id: f_00001-5-2 loss: 0.620313  [   96/  265]
train() client id: f_00001-5-3 loss: 0.597699  [  128/  265]
train() client id: f_00001-5-4 loss: 0.396547  [  160/  265]
train() client id: f_00001-5-5 loss: 0.440338  [  192/  265]
train() client id: f_00001-5-6 loss: 0.500443  [  224/  265]
train() client id: f_00001-5-7 loss: 0.450732  [  256/  265]
train() client id: f_00001-6-0 loss: 0.531192  [   32/  265]
train() client id: f_00001-6-1 loss: 0.376099  [   64/  265]
train() client id: f_00001-6-2 loss: 0.514715  [   96/  265]
train() client id: f_00001-6-3 loss: 0.470065  [  128/  265]
train() client id: f_00001-6-4 loss: 0.420081  [  160/  265]
train() client id: f_00001-6-5 loss: 0.462401  [  192/  265]
train() client id: f_00001-6-6 loss: 0.531931  [  224/  265]
train() client id: f_00001-6-7 loss: 0.537681  [  256/  265]
train() client id: f_00001-7-0 loss: 0.463685  [   32/  265]
train() client id: f_00001-7-1 loss: 0.468201  [   64/  265]
train() client id: f_00001-7-2 loss: 0.505409  [   96/  265]
train() client id: f_00001-7-3 loss: 0.526894  [  128/  265]
train() client id: f_00001-7-4 loss: 0.464889  [  160/  265]
train() client id: f_00001-7-5 loss: 0.491001  [  192/  265]
train() client id: f_00001-7-6 loss: 0.569750  [  224/  265]
train() client id: f_00001-7-7 loss: 0.363332  [  256/  265]
train() client id: f_00001-8-0 loss: 0.445785  [   32/  265]
train() client id: f_00001-8-1 loss: 0.460857  [   64/  265]
train() client id: f_00001-8-2 loss: 0.494266  [   96/  265]
train() client id: f_00001-8-3 loss: 0.565941  [  128/  265]
train() client id: f_00001-8-4 loss: 0.479921  [  160/  265]
train() client id: f_00001-8-5 loss: 0.403139  [  192/  265]
train() client id: f_00001-8-6 loss: 0.486710  [  224/  265]
train() client id: f_00001-8-7 loss: 0.500951  [  256/  265]
train() client id: f_00001-9-0 loss: 0.469219  [   32/  265]
train() client id: f_00001-9-1 loss: 0.443281  [   64/  265]
train() client id: f_00001-9-2 loss: 0.469534  [   96/  265]
train() client id: f_00001-9-3 loss: 0.391146  [  128/  265]
train() client id: f_00001-9-4 loss: 0.509862  [  160/  265]
train() client id: f_00001-9-5 loss: 0.440705  [  192/  265]
train() client id: f_00001-9-6 loss: 0.544390  [  224/  265]
train() client id: f_00001-9-7 loss: 0.562743  [  256/  265]
train() client id: f_00001-10-0 loss: 0.389305  [   32/  265]
train() client id: f_00001-10-1 loss: 0.486279  [   64/  265]
train() client id: f_00001-10-2 loss: 0.375908  [   96/  265]
train() client id: f_00001-10-3 loss: 0.561361  [  128/  265]
train() client id: f_00001-10-4 loss: 0.608801  [  160/  265]
train() client id: f_00001-10-5 loss: 0.387240  [  192/  265]
train() client id: f_00001-10-6 loss: 0.506523  [  224/  265]
train() client id: f_00001-10-7 loss: 0.399894  [  256/  265]
train() client id: f_00001-11-0 loss: 0.393434  [   32/  265]
train() client id: f_00001-11-1 loss: 0.471440  [   64/  265]
train() client id: f_00001-11-2 loss: 0.420045  [   96/  265]
train() client id: f_00001-11-3 loss: 0.642269  [  128/  265]
train() client id: f_00001-11-4 loss: 0.491201  [  160/  265]
train() client id: f_00001-11-5 loss: 0.385392  [  192/  265]
train() client id: f_00001-11-6 loss: 0.529022  [  224/  265]
train() client id: f_00001-11-7 loss: 0.512204  [  256/  265]
train() client id: f_00001-12-0 loss: 0.677528  [   32/  265]
train() client id: f_00001-12-1 loss: 0.425273  [   64/  265]
train() client id: f_00001-12-2 loss: 0.483791  [   96/  265]
train() client id: f_00001-12-3 loss: 0.554676  [  128/  265]
train() client id: f_00001-12-4 loss: 0.386497  [  160/  265]
train() client id: f_00001-12-5 loss: 0.547163  [  192/  265]
train() client id: f_00001-12-6 loss: 0.383165  [  224/  265]
train() client id: f_00001-12-7 loss: 0.394090  [  256/  265]
train() client id: f_00002-0-0 loss: 1.019298  [   32/  124]
train() client id: f_00002-0-1 loss: 1.136472  [   64/  124]
train() client id: f_00002-0-2 loss: 1.329097  [   96/  124]
train() client id: f_00002-1-0 loss: 1.234387  [   32/  124]
train() client id: f_00002-1-1 loss: 1.111093  [   64/  124]
train() client id: f_00002-1-2 loss: 1.088709  [   96/  124]
train() client id: f_00002-2-0 loss: 1.250155  [   32/  124]
train() client id: f_00002-2-1 loss: 1.025805  [   64/  124]
train() client id: f_00002-2-2 loss: 1.200820  [   96/  124]
train() client id: f_00002-3-0 loss: 1.131305  [   32/  124]
train() client id: f_00002-3-1 loss: 1.012149  [   64/  124]
train() client id: f_00002-3-2 loss: 0.985603  [   96/  124]
train() client id: f_00002-4-0 loss: 1.108936  [   32/  124]
train() client id: f_00002-4-1 loss: 1.049362  [   64/  124]
train() client id: f_00002-4-2 loss: 0.977202  [   96/  124]
train() client id: f_00002-5-0 loss: 0.972914  [   32/  124]
train() client id: f_00002-5-1 loss: 1.041308  [   64/  124]
train() client id: f_00002-5-2 loss: 0.988854  [   96/  124]
train() client id: f_00002-6-0 loss: 0.934994  [   32/  124]
train() client id: f_00002-6-1 loss: 0.989319  [   64/  124]
train() client id: f_00002-6-2 loss: 0.886912  [   96/  124]
train() client id: f_00002-7-0 loss: 0.977901  [   32/  124]
train() client id: f_00002-7-1 loss: 1.032534  [   64/  124]
train() client id: f_00002-7-2 loss: 0.943551  [   96/  124]
train() client id: f_00002-8-0 loss: 0.836792  [   32/  124]
train() client id: f_00002-8-1 loss: 0.961188  [   64/  124]
train() client id: f_00002-8-2 loss: 1.000865  [   96/  124]
train() client id: f_00002-9-0 loss: 0.994559  [   32/  124]
train() client id: f_00002-9-1 loss: 0.726273  [   64/  124]
train() client id: f_00002-9-2 loss: 0.983527  [   96/  124]
train() client id: f_00002-10-0 loss: 1.046038  [   32/  124]
train() client id: f_00002-10-1 loss: 0.847621  [   64/  124]
train() client id: f_00002-10-2 loss: 0.925195  [   96/  124]
train() client id: f_00002-11-0 loss: 1.086890  [   32/  124]
train() client id: f_00002-11-1 loss: 0.721210  [   64/  124]
train() client id: f_00002-11-2 loss: 0.801746  [   96/  124]
train() client id: f_00002-12-0 loss: 0.756314  [   32/  124]
train() client id: f_00002-12-1 loss: 1.014259  [   64/  124]
train() client id: f_00002-12-2 loss: 0.952445  [   96/  124]
train() client id: f_00003-0-0 loss: 0.886230  [   32/   43]
train() client id: f_00003-1-0 loss: 0.803795  [   32/   43]
train() client id: f_00003-2-0 loss: 0.857299  [   32/   43]
train() client id: f_00003-3-0 loss: 0.854972  [   32/   43]
train() client id: f_00003-4-0 loss: 0.689507  [   32/   43]
train() client id: f_00003-5-0 loss: 0.973488  [   32/   43]
train() client id: f_00003-6-0 loss: 0.969784  [   32/   43]
train() client id: f_00003-7-0 loss: 0.778190  [   32/   43]
train() client id: f_00003-8-0 loss: 0.955280  [   32/   43]
train() client id: f_00003-9-0 loss: 1.004618  [   32/   43]
train() client id: f_00003-10-0 loss: 0.989174  [   32/   43]
train() client id: f_00003-11-0 loss: 0.813285  [   32/   43]
train() client id: f_00003-12-0 loss: 1.009301  [   32/   43]
train() client id: f_00004-0-0 loss: 0.968854  [   32/  306]
train() client id: f_00004-0-1 loss: 0.736821  [   64/  306]
train() client id: f_00004-0-2 loss: 0.811835  [   96/  306]
train() client id: f_00004-0-3 loss: 1.064703  [  128/  306]
train() client id: f_00004-0-4 loss: 0.677909  [  160/  306]
train() client id: f_00004-0-5 loss: 0.866881  [  192/  306]
train() client id: f_00004-0-6 loss: 0.910210  [  224/  306]
train() client id: f_00004-0-7 loss: 0.643962  [  256/  306]
train() client id: f_00004-0-8 loss: 0.911758  [  288/  306]
train() client id: f_00004-1-0 loss: 0.691816  [   32/  306]
train() client id: f_00004-1-1 loss: 0.864896  [   64/  306]
train() client id: f_00004-1-2 loss: 1.016370  [   96/  306]
train() client id: f_00004-1-3 loss: 0.912963  [  128/  306]
train() client id: f_00004-1-4 loss: 0.809289  [  160/  306]
train() client id: f_00004-1-5 loss: 0.755978  [  192/  306]
train() client id: f_00004-1-6 loss: 0.826730  [  224/  306]
train() client id: f_00004-1-7 loss: 0.814835  [  256/  306]
train() client id: f_00004-1-8 loss: 0.810548  [  288/  306]
train() client id: f_00004-2-0 loss: 0.765908  [   32/  306]
train() client id: f_00004-2-1 loss: 0.885996  [   64/  306]
train() client id: f_00004-2-2 loss: 0.821842  [   96/  306]
train() client id: f_00004-2-3 loss: 0.910002  [  128/  306]
train() client id: f_00004-2-4 loss: 0.737203  [  160/  306]
train() client id: f_00004-2-5 loss: 0.914492  [  192/  306]
train() client id: f_00004-2-6 loss: 0.933678  [  224/  306]
train() client id: f_00004-2-7 loss: 0.837011  [  256/  306]
train() client id: f_00004-2-8 loss: 0.809114  [  288/  306]
train() client id: f_00004-3-0 loss: 0.893622  [   32/  306]
train() client id: f_00004-3-1 loss: 0.742123  [   64/  306]
train() client id: f_00004-3-2 loss: 0.764537  [   96/  306]
train() client id: f_00004-3-3 loss: 0.791681  [  128/  306]
train() client id: f_00004-3-4 loss: 0.813937  [  160/  306]
train() client id: f_00004-3-5 loss: 0.874049  [  192/  306]
train() client id: f_00004-3-6 loss: 0.883892  [  224/  306]
train() client id: f_00004-3-7 loss: 0.967991  [  256/  306]
train() client id: f_00004-3-8 loss: 0.805281  [  288/  306]
train() client id: f_00004-4-0 loss: 0.810155  [   32/  306]
train() client id: f_00004-4-1 loss: 0.708844  [   64/  306]
train() client id: f_00004-4-2 loss: 0.843077  [   96/  306]
train() client id: f_00004-4-3 loss: 0.956796  [  128/  306]
train() client id: f_00004-4-4 loss: 0.885551  [  160/  306]
train() client id: f_00004-4-5 loss: 0.882157  [  192/  306]
train() client id: f_00004-4-6 loss: 0.779866  [  224/  306]
train() client id: f_00004-4-7 loss: 0.848842  [  256/  306]
train() client id: f_00004-4-8 loss: 0.900191  [  288/  306]
train() client id: f_00004-5-0 loss: 1.049462  [   32/  306]
train() client id: f_00004-5-1 loss: 0.988222  [   64/  306]
train() client id: f_00004-5-2 loss: 0.831715  [   96/  306]
train() client id: f_00004-5-3 loss: 0.838376  [  128/  306]
train() client id: f_00004-5-4 loss: 0.759314  [  160/  306]
train() client id: f_00004-5-5 loss: 0.732045  [  192/  306]
train() client id: f_00004-5-6 loss: 0.760884  [  224/  306]
train() client id: f_00004-5-7 loss: 0.883035  [  256/  306]
train() client id: f_00004-5-8 loss: 0.878360  [  288/  306]
train() client id: f_00004-6-0 loss: 0.908211  [   32/  306]
train() client id: f_00004-6-1 loss: 0.841080  [   64/  306]
train() client id: f_00004-6-2 loss: 0.818210  [   96/  306]
train() client id: f_00004-6-3 loss: 0.813205  [  128/  306]
train() client id: f_00004-6-4 loss: 0.830388  [  160/  306]
train() client id: f_00004-6-5 loss: 0.895424  [  192/  306]
train() client id: f_00004-6-6 loss: 0.874966  [  224/  306]
train() client id: f_00004-6-7 loss: 0.772885  [  256/  306]
train() client id: f_00004-6-8 loss: 0.848547  [  288/  306]
train() client id: f_00004-7-0 loss: 0.855704  [   32/  306]
train() client id: f_00004-7-1 loss: 0.769474  [   64/  306]
train() client id: f_00004-7-2 loss: 0.757647  [   96/  306]
train() client id: f_00004-7-3 loss: 0.899046  [  128/  306]
train() client id: f_00004-7-4 loss: 0.925526  [  160/  306]
train() client id: f_00004-7-5 loss: 0.876354  [  192/  306]
train() client id: f_00004-7-6 loss: 0.695817  [  224/  306]
train() client id: f_00004-7-7 loss: 0.917531  [  256/  306]
train() client id: f_00004-7-8 loss: 0.945617  [  288/  306]
train() client id: f_00004-8-0 loss: 0.775243  [   32/  306]
train() client id: f_00004-8-1 loss: 0.950384  [   64/  306]
train() client id: f_00004-8-2 loss: 0.972421  [   96/  306]
train() client id: f_00004-8-3 loss: 0.758201  [  128/  306]
train() client id: f_00004-8-4 loss: 0.917175  [  160/  306]
train() client id: f_00004-8-5 loss: 0.805440  [  192/  306]
train() client id: f_00004-8-6 loss: 0.794275  [  224/  306]
train() client id: f_00004-8-7 loss: 0.806039  [  256/  306]
train() client id: f_00004-8-8 loss: 0.770753  [  288/  306]
train() client id: f_00004-9-0 loss: 0.772171  [   32/  306]
train() client id: f_00004-9-1 loss: 0.759913  [   64/  306]
train() client id: f_00004-9-2 loss: 0.873514  [   96/  306]
train() client id: f_00004-9-3 loss: 0.927668  [  128/  306]
train() client id: f_00004-9-4 loss: 0.882871  [  160/  306]
train() client id: f_00004-9-5 loss: 0.903620  [  192/  306]
train() client id: f_00004-9-6 loss: 0.723941  [  224/  306]
train() client id: f_00004-9-7 loss: 0.827972  [  256/  306]
train() client id: f_00004-9-8 loss: 0.891562  [  288/  306]
train() client id: f_00004-10-0 loss: 0.745834  [   32/  306]
train() client id: f_00004-10-1 loss: 0.989011  [   64/  306]
train() client id: f_00004-10-2 loss: 0.780258  [   96/  306]
train() client id: f_00004-10-3 loss: 0.921304  [  128/  306]
train() client id: f_00004-10-4 loss: 0.840302  [  160/  306]
train() client id: f_00004-10-5 loss: 0.760849  [  192/  306]
train() client id: f_00004-10-6 loss: 0.786982  [  224/  306]
train() client id: f_00004-10-7 loss: 0.825037  [  256/  306]
train() client id: f_00004-10-8 loss: 0.920521  [  288/  306]
train() client id: f_00004-11-0 loss: 0.991255  [   32/  306]
train() client id: f_00004-11-1 loss: 0.802397  [   64/  306]
train() client id: f_00004-11-2 loss: 0.866801  [   96/  306]
train() client id: f_00004-11-3 loss: 0.983149  [  128/  306]
train() client id: f_00004-11-4 loss: 0.887743  [  160/  306]
train() client id: f_00004-11-5 loss: 0.709597  [  192/  306]
train() client id: f_00004-11-6 loss: 0.620789  [  224/  306]
train() client id: f_00004-11-7 loss: 0.821172  [  256/  306]
train() client id: f_00004-11-8 loss: 0.872076  [  288/  306]
train() client id: f_00004-12-0 loss: 0.875036  [   32/  306]
train() client id: f_00004-12-1 loss: 0.993091  [   64/  306]
train() client id: f_00004-12-2 loss: 0.888307  [   96/  306]
train() client id: f_00004-12-3 loss: 0.916397  [  128/  306]
train() client id: f_00004-12-4 loss: 0.811952  [  160/  306]
train() client id: f_00004-12-5 loss: 0.803190  [  192/  306]
train() client id: f_00004-12-6 loss: 0.793662  [  224/  306]
train() client id: f_00004-12-7 loss: 0.822832  [  256/  306]
train() client id: f_00004-12-8 loss: 0.762142  [  288/  306]
train() client id: f_00005-0-0 loss: 0.541285  [   32/  146]
train() client id: f_00005-0-1 loss: 0.734050  [   64/  146]
train() client id: f_00005-0-2 loss: 0.705130  [   96/  146]
train() client id: f_00005-0-3 loss: 0.666455  [  128/  146]
train() client id: f_00005-1-0 loss: 0.640921  [   32/  146]
train() client id: f_00005-1-1 loss: 0.581818  [   64/  146]
train() client id: f_00005-1-2 loss: 0.783209  [   96/  146]
train() client id: f_00005-1-3 loss: 0.706429  [  128/  146]
train() client id: f_00005-2-0 loss: 0.518021  [   32/  146]
train() client id: f_00005-2-1 loss: 0.656948  [   64/  146]
train() client id: f_00005-2-2 loss: 0.725925  [   96/  146]
train() client id: f_00005-2-3 loss: 0.660360  [  128/  146]
train() client id: f_00005-3-0 loss: 0.576301  [   32/  146]
train() client id: f_00005-3-1 loss: 0.621825  [   64/  146]
train() client id: f_00005-3-2 loss: 0.554740  [   96/  146]
train() client id: f_00005-3-3 loss: 0.796081  [  128/  146]
train() client id: f_00005-4-0 loss: 0.408536  [   32/  146]
train() client id: f_00005-4-1 loss: 0.647617  [   64/  146]
train() client id: f_00005-4-2 loss: 0.911236  [   96/  146]
train() client id: f_00005-4-3 loss: 0.613753  [  128/  146]
train() client id: f_00005-5-0 loss: 0.529411  [   32/  146]
train() client id: f_00005-5-1 loss: 0.691912  [   64/  146]
train() client id: f_00005-5-2 loss: 0.655934  [   96/  146]
train() client id: f_00005-5-3 loss: 0.453620  [  128/  146]
train() client id: f_00005-6-0 loss: 0.760771  [   32/  146]
train() client id: f_00005-6-1 loss: 0.509977  [   64/  146]
train() client id: f_00005-6-2 loss: 0.751990  [   96/  146]
train() client id: f_00005-6-3 loss: 0.695951  [  128/  146]
train() client id: f_00005-7-0 loss: 0.491170  [   32/  146]
train() client id: f_00005-7-1 loss: 0.705994  [   64/  146]
train() client id: f_00005-7-2 loss: 0.684071  [   96/  146]
train() client id: f_00005-7-3 loss: 0.674805  [  128/  146]
train() client id: f_00005-8-0 loss: 0.825722  [   32/  146]
train() client id: f_00005-8-1 loss: 0.680380  [   64/  146]
train() client id: f_00005-8-2 loss: 0.630606  [   96/  146]
train() client id: f_00005-8-3 loss: 0.620117  [  128/  146]
train() client id: f_00005-9-0 loss: 0.670316  [   32/  146]
train() client id: f_00005-9-1 loss: 0.679803  [   64/  146]
train() client id: f_00005-9-2 loss: 0.545718  [   96/  146]
train() client id: f_00005-9-3 loss: 0.836585  [  128/  146]
train() client id: f_00005-10-0 loss: 0.889686  [   32/  146]
train() client id: f_00005-10-1 loss: 0.620283  [   64/  146]
train() client id: f_00005-10-2 loss: 0.666699  [   96/  146]
train() client id: f_00005-10-3 loss: 0.545926  [  128/  146]
train() client id: f_00005-11-0 loss: 0.635986  [   32/  146]
train() client id: f_00005-11-1 loss: 0.546894  [   64/  146]
train() client id: f_00005-11-2 loss: 0.532171  [   96/  146]
train() client id: f_00005-11-3 loss: 0.664958  [  128/  146]
train() client id: f_00005-12-0 loss: 0.891632  [   32/  146]
train() client id: f_00005-12-1 loss: 0.588879  [   64/  146]
train() client id: f_00005-12-2 loss: 0.510188  [   96/  146]
train() client id: f_00005-12-3 loss: 0.320190  [  128/  146]
train() client id: f_00006-0-0 loss: 0.489275  [   32/   54]
train() client id: f_00006-1-0 loss: 0.489622  [   32/   54]
train() client id: f_00006-2-0 loss: 0.535959  [   32/   54]
train() client id: f_00006-3-0 loss: 0.465063  [   32/   54]
train() client id: f_00006-4-0 loss: 0.498290  [   32/   54]
train() client id: f_00006-5-0 loss: 0.485934  [   32/   54]
train() client id: f_00006-6-0 loss: 0.548162  [   32/   54]
train() client id: f_00006-7-0 loss: 0.438436  [   32/   54]
train() client id: f_00006-8-0 loss: 0.496861  [   32/   54]
train() client id: f_00006-9-0 loss: 0.529978  [   32/   54]
train() client id: f_00006-10-0 loss: 0.545432  [   32/   54]
train() client id: f_00006-11-0 loss: 0.466609  [   32/   54]
train() client id: f_00006-12-0 loss: 0.537880  [   32/   54]
train() client id: f_00007-0-0 loss: 0.441680  [   32/  179]
train() client id: f_00007-0-1 loss: 0.689519  [   64/  179]
train() client id: f_00007-0-2 loss: 0.482394  [   96/  179]
train() client id: f_00007-0-3 loss: 0.552683  [  128/  179]
train() client id: f_00007-0-4 loss: 0.373819  [  160/  179]
train() client id: f_00007-1-0 loss: 0.563752  [   32/  179]
train() client id: f_00007-1-1 loss: 0.712605  [   64/  179]
train() client id: f_00007-1-2 loss: 0.507761  [   96/  179]
train() client id: f_00007-1-3 loss: 0.363642  [  128/  179]
train() client id: f_00007-1-4 loss: 0.444361  [  160/  179]
train() client id: f_00007-2-0 loss: 0.323833  [   32/  179]
train() client id: f_00007-2-1 loss: 0.471681  [   64/  179]
train() client id: f_00007-2-2 loss: 0.767222  [   96/  179]
train() client id: f_00007-2-3 loss: 0.370397  [  128/  179]
train() client id: f_00007-2-4 loss: 0.546962  [  160/  179]
train() client id: f_00007-3-0 loss: 0.301747  [   32/  179]
train() client id: f_00007-3-1 loss: 0.467661  [   64/  179]
train() client id: f_00007-3-2 loss: 0.445315  [   96/  179]
train() client id: f_00007-3-3 loss: 0.435402  [  128/  179]
train() client id: f_00007-3-4 loss: 0.603179  [  160/  179]
train() client id: f_00007-4-0 loss: 0.361975  [   32/  179]
train() client id: f_00007-4-1 loss: 0.687916  [   64/  179]
train() client id: f_00007-4-2 loss: 0.397784  [   96/  179]
train() client id: f_00007-4-3 loss: 0.330787  [  128/  179]
train() client id: f_00007-4-4 loss: 0.565740  [  160/  179]
train() client id: f_00007-5-0 loss: 0.442163  [   32/  179]
train() client id: f_00007-5-1 loss: 0.576493  [   64/  179]
train() client id: f_00007-5-2 loss: 0.318842  [   96/  179]
train() client id: f_00007-5-3 loss: 0.304320  [  128/  179]
train() client id: f_00007-5-4 loss: 0.422512  [  160/  179]
train() client id: f_00007-6-0 loss: 0.508770  [   32/  179]
train() client id: f_00007-6-1 loss: 0.591423  [   64/  179]
train() client id: f_00007-6-2 loss: 0.406231  [   96/  179]
train() client id: f_00007-6-3 loss: 0.460124  [  128/  179]
train() client id: f_00007-6-4 loss: 0.391392  [  160/  179]
train() client id: f_00007-7-0 loss: 0.389365  [   32/  179]
train() client id: f_00007-7-1 loss: 0.397259  [   64/  179]
train() client id: f_00007-7-2 loss: 0.546936  [   96/  179]
train() client id: f_00007-7-3 loss: 0.410139  [  128/  179]
train() client id: f_00007-7-4 loss: 0.539055  [  160/  179]
train() client id: f_00007-8-0 loss: 0.428289  [   32/  179]
train() client id: f_00007-8-1 loss: 0.485478  [   64/  179]
train() client id: f_00007-8-2 loss: 0.365076  [   96/  179]
train() client id: f_00007-8-3 loss: 0.460799  [  128/  179]
train() client id: f_00007-8-4 loss: 0.455347  [  160/  179]
train() client id: f_00007-9-0 loss: 0.358981  [   32/  179]
train() client id: f_00007-9-1 loss: 0.533740  [   64/  179]
train() client id: f_00007-9-2 loss: 0.544397  [   96/  179]
train() client id: f_00007-9-3 loss: 0.391226  [  128/  179]
train() client id: f_00007-9-4 loss: 0.440454  [  160/  179]
train() client id: f_00007-10-0 loss: 0.298933  [   32/  179]
train() client id: f_00007-10-1 loss: 0.472253  [   64/  179]
train() client id: f_00007-10-2 loss: 0.272140  [   96/  179]
train() client id: f_00007-10-3 loss: 0.395139  [  128/  179]
train() client id: f_00007-10-4 loss: 0.701075  [  160/  179]
train() client id: f_00007-11-0 loss: 0.435749  [   32/  179]
train() client id: f_00007-11-1 loss: 0.511080  [   64/  179]
train() client id: f_00007-11-2 loss: 0.466660  [   96/  179]
train() client id: f_00007-11-3 loss: 0.357619  [  128/  179]
train() client id: f_00007-11-4 loss: 0.336874  [  160/  179]
train() client id: f_00007-12-0 loss: 0.360536  [   32/  179]
train() client id: f_00007-12-1 loss: 0.633887  [   64/  179]
train() client id: f_00007-12-2 loss: 0.467478  [   96/  179]
train() client id: f_00007-12-3 loss: 0.267388  [  128/  179]
train() client id: f_00007-12-4 loss: 0.481981  [  160/  179]
train() client id: f_00008-0-0 loss: 0.688482  [   32/  130]
train() client id: f_00008-0-1 loss: 0.845824  [   64/  130]
train() client id: f_00008-0-2 loss: 0.867678  [   96/  130]
train() client id: f_00008-0-3 loss: 0.738228  [  128/  130]
train() client id: f_00008-1-0 loss: 0.785427  [   32/  130]
train() client id: f_00008-1-1 loss: 0.773679  [   64/  130]
train() client id: f_00008-1-2 loss: 0.746839  [   96/  130]
train() client id: f_00008-1-3 loss: 0.834300  [  128/  130]
train() client id: f_00008-2-0 loss: 0.778415  [   32/  130]
train() client id: f_00008-2-1 loss: 0.751518  [   64/  130]
train() client id: f_00008-2-2 loss: 0.836340  [   96/  130]
train() client id: f_00008-2-3 loss: 0.764956  [  128/  130]
train() client id: f_00008-3-0 loss: 0.858844  [   32/  130]
train() client id: f_00008-3-1 loss: 0.743359  [   64/  130]
train() client id: f_00008-3-2 loss: 0.748022  [   96/  130]
train() client id: f_00008-3-3 loss: 0.792427  [  128/  130]
train() client id: f_00008-4-0 loss: 0.853563  [   32/  130]
train() client id: f_00008-4-1 loss: 0.762838  [   64/  130]
train() client id: f_00008-4-2 loss: 0.719330  [   96/  130]
train() client id: f_00008-4-3 loss: 0.768598  [  128/  130]
train() client id: f_00008-5-0 loss: 0.733815  [   32/  130]
train() client id: f_00008-5-1 loss: 0.839263  [   64/  130]
train() client id: f_00008-5-2 loss: 0.742856  [   96/  130]
train() client id: f_00008-5-3 loss: 0.817616  [  128/  130]
train() client id: f_00008-6-0 loss: 0.982877  [   32/  130]
train() client id: f_00008-6-1 loss: 0.665314  [   64/  130]
train() client id: f_00008-6-2 loss: 0.721742  [   96/  130]
train() client id: f_00008-6-3 loss: 0.752955  [  128/  130]
train() client id: f_00008-7-0 loss: 0.772223  [   32/  130]
train() client id: f_00008-7-1 loss: 0.798718  [   64/  130]
train() client id: f_00008-7-2 loss: 0.831358  [   96/  130]
train() client id: f_00008-7-3 loss: 0.728539  [  128/  130]
train() client id: f_00008-8-0 loss: 0.745950  [   32/  130]
train() client id: f_00008-8-1 loss: 0.639948  [   64/  130]
train() client id: f_00008-8-2 loss: 0.927917  [   96/  130]
train() client id: f_00008-8-3 loss: 0.832736  [  128/  130]
train() client id: f_00008-9-0 loss: 0.772515  [   32/  130]
train() client id: f_00008-9-1 loss: 0.714108  [   64/  130]
train() client id: f_00008-9-2 loss: 0.759832  [   96/  130]
train() client id: f_00008-9-3 loss: 0.880771  [  128/  130]
train() client id: f_00008-10-0 loss: 0.792233  [   32/  130]
train() client id: f_00008-10-1 loss: 0.693861  [   64/  130]
train() client id: f_00008-10-2 loss: 0.847106  [   96/  130]
train() client id: f_00008-10-3 loss: 0.791323  [  128/  130]
train() client id: f_00008-11-0 loss: 0.696335  [   32/  130]
train() client id: f_00008-11-1 loss: 0.796112  [   64/  130]
train() client id: f_00008-11-2 loss: 0.838974  [   96/  130]
train() client id: f_00008-11-3 loss: 0.816710  [  128/  130]
train() client id: f_00008-12-0 loss: 0.747459  [   32/  130]
train() client id: f_00008-12-1 loss: 0.789356  [   64/  130]
train() client id: f_00008-12-2 loss: 0.875740  [   96/  130]
train() client id: f_00008-12-3 loss: 0.735804  [  128/  130]
train() client id: f_00009-0-0 loss: 1.273399  [   32/  118]
train() client id: f_00009-0-1 loss: 1.158825  [   64/  118]
train() client id: f_00009-0-2 loss: 0.926139  [   96/  118]
train() client id: f_00009-1-0 loss: 1.110149  [   32/  118]
train() client id: f_00009-1-1 loss: 1.162986  [   64/  118]
train() client id: f_00009-1-2 loss: 0.957575  [   96/  118]
train() client id: f_00009-2-0 loss: 1.003746  [   32/  118]
train() client id: f_00009-2-1 loss: 1.125459  [   64/  118]
train() client id: f_00009-2-2 loss: 1.082798  [   96/  118]
train() client id: f_00009-3-0 loss: 0.960230  [   32/  118]
train() client id: f_00009-3-1 loss: 0.938799  [   64/  118]
train() client id: f_00009-3-2 loss: 1.053331  [   96/  118]
train() client id: f_00009-4-0 loss: 0.955725  [   32/  118]
train() client id: f_00009-4-1 loss: 0.967401  [   64/  118]
train() client id: f_00009-4-2 loss: 0.953562  [   96/  118]
train() client id: f_00009-5-0 loss: 1.010117  [   32/  118]
train() client id: f_00009-5-1 loss: 0.887722  [   64/  118]
train() client id: f_00009-5-2 loss: 0.913991  [   96/  118]
train() client id: f_00009-6-0 loss: 0.844135  [   32/  118]
train() client id: f_00009-6-1 loss: 0.940661  [   64/  118]
train() client id: f_00009-6-2 loss: 0.964284  [   96/  118]
train() client id: f_00009-7-0 loss: 0.928737  [   32/  118]
train() client id: f_00009-7-1 loss: 0.863233  [   64/  118]
train() client id: f_00009-7-2 loss: 0.912485  [   96/  118]
train() client id: f_00009-8-0 loss: 0.898435  [   32/  118]
train() client id: f_00009-8-1 loss: 0.993979  [   64/  118]
train() client id: f_00009-8-2 loss: 0.848592  [   96/  118]
train() client id: f_00009-9-0 loss: 0.951052  [   32/  118]
train() client id: f_00009-9-1 loss: 0.931861  [   64/  118]
train() client id: f_00009-9-2 loss: 0.810402  [   96/  118]
train() client id: f_00009-10-0 loss: 0.850586  [   32/  118]
train() client id: f_00009-10-1 loss: 0.874476  [   64/  118]
train() client id: f_00009-10-2 loss: 0.869723  [   96/  118]
train() client id: f_00009-11-0 loss: 0.833629  [   32/  118]
train() client id: f_00009-11-1 loss: 0.913857  [   64/  118]
train() client id: f_00009-11-2 loss: 0.834191  [   96/  118]
train() client id: f_00009-12-0 loss: 0.862210  [   32/  118]
train() client id: f_00009-12-1 loss: 0.819869  [   64/  118]
train() client id: f_00009-12-2 loss: 0.872947  [   96/  118]
At round 30 accuracy: 0.6419098143236074
At round 30 training accuracy: 0.5848423876592891
At round 30 training loss: 0.832648089883373
gradient difference: 0.48179522156715393
train() client id: f_00000-0-0 loss: 0.970562  [   32/  126]
train() client id: f_00000-0-1 loss: 0.950868  [   64/  126]
train() client id: f_00000-0-2 loss: 1.022388  [   96/  126]
train() client id: f_00000-1-0 loss: 1.159905  [   32/  126]
train() client id: f_00000-1-1 loss: 0.887849  [   64/  126]
train() client id: f_00000-1-2 loss: 0.873368  [   96/  126]
train() client id: f_00000-2-0 loss: 0.885020  [   32/  126]
train() client id: f_00000-2-1 loss: 0.846528  [   64/  126]
train() client id: f_00000-2-2 loss: 1.013892  [   96/  126]
train() client id: f_00000-3-0 loss: 1.032351  [   32/  126]
train() client id: f_00000-3-1 loss: 0.826579  [   64/  126]
train() client id: f_00000-3-2 loss: 0.782999  [   96/  126]
train() client id: f_00000-4-0 loss: 0.846892  [   32/  126]
train() client id: f_00000-4-1 loss: 0.926860  [   64/  126]
train() client id: f_00000-4-2 loss: 0.854756  [   96/  126]
train() client id: f_00000-5-0 loss: 1.031281  [   32/  126]
train() client id: f_00000-5-1 loss: 0.766554  [   64/  126]
train() client id: f_00000-5-2 loss: 0.850741  [   96/  126]
train() client id: f_00000-6-0 loss: 0.918132  [   32/  126]
train() client id: f_00000-6-1 loss: 0.886813  [   64/  126]
train() client id: f_00000-6-2 loss: 0.888025  [   96/  126]
train() client id: f_00000-7-0 loss: 0.915721  [   32/  126]
train() client id: f_00000-7-1 loss: 0.817670  [   64/  126]
train() client id: f_00000-7-2 loss: 0.847910  [   96/  126]
train() client id: f_00000-8-0 loss: 0.850522  [   32/  126]
train() client id: f_00000-8-1 loss: 0.965472  [   64/  126]
train() client id: f_00000-8-2 loss: 0.855771  [   96/  126]
train() client id: f_00000-9-0 loss: 0.786526  [   32/  126]
train() client id: f_00000-9-1 loss: 0.958511  [   64/  126]
train() client id: f_00000-9-2 loss: 0.958792  [   96/  126]
train() client id: f_00000-10-0 loss: 0.964367  [   32/  126]
train() client id: f_00000-10-1 loss: 1.009742  [   64/  126]
train() client id: f_00000-10-2 loss: 0.838653  [   96/  126]
train() client id: f_00000-11-0 loss: 0.970378  [   32/  126]
train() client id: f_00000-11-1 loss: 0.971854  [   64/  126]
train() client id: f_00000-11-2 loss: 0.748572  [   96/  126]
train() client id: f_00000-12-0 loss: 0.831925  [   32/  126]
train() client id: f_00000-12-1 loss: 0.929253  [   64/  126]
train() client id: f_00000-12-2 loss: 0.946626  [   96/  126]
train() client id: f_00001-0-0 loss: 0.464133  [   32/  265]
train() client id: f_00001-0-1 loss: 0.615083  [   64/  265]
train() client id: f_00001-0-2 loss: 0.506851  [   96/  265]
train() client id: f_00001-0-3 loss: 0.448247  [  128/  265]
train() client id: f_00001-0-4 loss: 0.572258  [  160/  265]
train() client id: f_00001-0-5 loss: 0.535439  [  192/  265]
train() client id: f_00001-0-6 loss: 0.423303  [  224/  265]
train() client id: f_00001-0-7 loss: 0.480008  [  256/  265]
train() client id: f_00001-1-0 loss: 0.599278  [   32/  265]
train() client id: f_00001-1-1 loss: 0.428544  [   64/  265]
train() client id: f_00001-1-2 loss: 0.429799  [   96/  265]
train() client id: f_00001-1-3 loss: 0.520185  [  128/  265]
train() client id: f_00001-1-4 loss: 0.483196  [  160/  265]
train() client id: f_00001-1-5 loss: 0.444687  [  192/  265]
train() client id: f_00001-1-6 loss: 0.422560  [  224/  265]
train() client id: f_00001-1-7 loss: 0.604396  [  256/  265]
train() client id: f_00001-2-0 loss: 0.439968  [   32/  265]
train() client id: f_00001-2-1 loss: 0.435222  [   64/  265]
train() client id: f_00001-2-2 loss: 0.582384  [   96/  265]
train() client id: f_00001-2-3 loss: 0.567276  [  128/  265]
train() client id: f_00001-2-4 loss: 0.493484  [  160/  265]
train() client id: f_00001-2-5 loss: 0.430582  [  192/  265]
train() client id: f_00001-2-6 loss: 0.441079  [  224/  265]
train() client id: f_00001-2-7 loss: 0.609815  [  256/  265]
train() client id: f_00001-3-0 loss: 0.428127  [   32/  265]
train() client id: f_00001-3-1 loss: 0.482679  [   64/  265]
train() client id: f_00001-3-2 loss: 0.371743  [   96/  265]
train() client id: f_00001-3-3 loss: 0.599991  [  128/  265]
train() client id: f_00001-3-4 loss: 0.648456  [  160/  265]
train() client id: f_00001-3-5 loss: 0.482938  [  192/  265]
train() client id: f_00001-3-6 loss: 0.491894  [  224/  265]
train() client id: f_00001-3-7 loss: 0.475326  [  256/  265]
train() client id: f_00001-4-0 loss: 0.520284  [   32/  265]
train() client id: f_00001-4-1 loss: 0.591327  [   64/  265]
train() client id: f_00001-4-2 loss: 0.380869  [   96/  265]
train() client id: f_00001-4-3 loss: 0.477784  [  128/  265]
train() client id: f_00001-4-4 loss: 0.529382  [  160/  265]
train() client id: f_00001-4-5 loss: 0.490046  [  192/  265]
train() client id: f_00001-4-6 loss: 0.557004  [  224/  265]
train() client id: f_00001-4-7 loss: 0.420841  [  256/  265]
train() client id: f_00001-5-0 loss: 0.394965  [   32/  265]
train() client id: f_00001-5-1 loss: 0.482968  [   64/  265]
train() client id: f_00001-5-2 loss: 0.520010  [   96/  265]
train() client id: f_00001-5-3 loss: 0.545983  [  128/  265]
train() client id: f_00001-5-4 loss: 0.463073  [  160/  265]
train() client id: f_00001-5-5 loss: 0.497241  [  192/  265]
train() client id: f_00001-5-6 loss: 0.539417  [  224/  265]
train() client id: f_00001-5-7 loss: 0.426155  [  256/  265]
train() client id: f_00001-6-0 loss: 0.533594  [   32/  265]
train() client id: f_00001-6-1 loss: 0.540526  [   64/  265]
train() client id: f_00001-6-2 loss: 0.593449  [   96/  265]
train() client id: f_00001-6-3 loss: 0.397766  [  128/  265]
train() client id: f_00001-6-4 loss: 0.413902  [  160/  265]
train() client id: f_00001-6-5 loss: 0.539283  [  192/  265]
train() client id: f_00001-6-6 loss: 0.437918  [  224/  265]
train() client id: f_00001-6-7 loss: 0.496931  [  256/  265]
train() client id: f_00001-7-0 loss: 0.535302  [   32/  265]
train() client id: f_00001-7-1 loss: 0.407018  [   64/  265]
train() client id: f_00001-7-2 loss: 0.572225  [   96/  265]
train() client id: f_00001-7-3 loss: 0.506080  [  128/  265]
train() client id: f_00001-7-4 loss: 0.540837  [  160/  265]
train() client id: f_00001-7-5 loss: 0.474380  [  192/  265]
train() client id: f_00001-7-6 loss: 0.484692  [  224/  265]
train() client id: f_00001-7-7 loss: 0.434090  [  256/  265]
train() client id: f_00001-8-0 loss: 0.549107  [   32/  265]
train() client id: f_00001-8-1 loss: 0.486251  [   64/  265]
train() client id: f_00001-8-2 loss: 0.406467  [   96/  265]
train() client id: f_00001-8-3 loss: 0.437130  [  128/  265]
train() client id: f_00001-8-4 loss: 0.535553  [  160/  265]
train() client id: f_00001-8-5 loss: 0.450361  [  192/  265]
train() client id: f_00001-8-6 loss: 0.536130  [  224/  265]
train() client id: f_00001-8-7 loss: 0.518345  [  256/  265]
train() client id: f_00001-9-0 loss: 0.494690  [   32/  265]
train() client id: f_00001-9-1 loss: 0.527991  [   64/  265]
train() client id: f_00001-9-2 loss: 0.522319  [   96/  265]
train() client id: f_00001-9-3 loss: 0.409215  [  128/  265]
train() client id: f_00001-9-4 loss: 0.541294  [  160/  265]
train() client id: f_00001-9-5 loss: 0.425677  [  192/  265]
train() client id: f_00001-9-6 loss: 0.564646  [  224/  265]
train() client id: f_00001-9-7 loss: 0.385706  [  256/  265]
train() client id: f_00001-10-0 loss: 0.554033  [   32/  265]
train() client id: f_00001-10-1 loss: 0.624021  [   64/  265]
train() client id: f_00001-10-2 loss: 0.399420  [   96/  265]
train() client id: f_00001-10-3 loss: 0.415257  [  128/  265]
train() client id: f_00001-10-4 loss: 0.386561  [  160/  265]
train() client id: f_00001-10-5 loss: 0.486576  [  192/  265]
train() client id: f_00001-10-6 loss: 0.579898  [  224/  265]
train() client id: f_00001-10-7 loss: 0.442329  [  256/  265]
train() client id: f_00001-11-0 loss: 0.615588  [   32/  265]
train() client id: f_00001-11-1 loss: 0.411300  [   64/  265]
train() client id: f_00001-11-2 loss: 0.420204  [   96/  265]
train() client id: f_00001-11-3 loss: 0.389311  [  128/  265]
train() client id: f_00001-11-4 loss: 0.680047  [  160/  265]
train() client id: f_00001-11-5 loss: 0.505222  [  192/  265]
train() client id: f_00001-11-6 loss: 0.477309  [  224/  265]
train() client id: f_00001-11-7 loss: 0.471418  [  256/  265]
train() client id: f_00001-12-0 loss: 0.399644  [   32/  265]
train() client id: f_00001-12-1 loss: 0.583034  [   64/  265]
train() client id: f_00001-12-2 loss: 0.468011  [   96/  265]
train() client id: f_00001-12-3 loss: 0.527911  [  128/  265]
train() client id: f_00001-12-4 loss: 0.442016  [  160/  265]
train() client id: f_00001-12-5 loss: 0.530138  [  192/  265]
train() client id: f_00001-12-6 loss: 0.498743  [  224/  265]
train() client id: f_00001-12-7 loss: 0.519560  [  256/  265]
train() client id: f_00002-0-0 loss: 1.240464  [   32/  124]
train() client id: f_00002-0-1 loss: 1.408715  [   64/  124]
train() client id: f_00002-0-2 loss: 1.235065  [   96/  124]
train() client id: f_00002-1-0 loss: 1.338048  [   32/  124]
train() client id: f_00002-1-1 loss: 1.165432  [   64/  124]
train() client id: f_00002-1-2 loss: 1.207984  [   96/  124]
train() client id: f_00002-2-0 loss: 1.236449  [   32/  124]
train() client id: f_00002-2-1 loss: 1.004214  [   64/  124]
train() client id: f_00002-2-2 loss: 1.174182  [   96/  124]
train() client id: f_00002-3-0 loss: 1.014626  [   32/  124]
train() client id: f_00002-3-1 loss: 1.153142  [   64/  124]
train() client id: f_00002-3-2 loss: 1.142803  [   96/  124]
train() client id: f_00002-4-0 loss: 1.142128  [   32/  124]
train() client id: f_00002-4-1 loss: 1.132214  [   64/  124]
train() client id: f_00002-4-2 loss: 1.020689  [   96/  124]
train() client id: f_00002-5-0 loss: 1.166185  [   32/  124]
train() client id: f_00002-5-1 loss: 1.017060  [   64/  124]
train() client id: f_00002-5-2 loss: 0.982086  [   96/  124]
train() client id: f_00002-6-0 loss: 0.904910  [   32/  124]
train() client id: f_00002-6-1 loss: 1.023563  [   64/  124]
train() client id: f_00002-6-2 loss: 1.018249  [   96/  124]
train() client id: f_00002-7-0 loss: 0.974884  [   32/  124]
train() client id: f_00002-7-1 loss: 1.080267  [   64/  124]
train() client id: f_00002-7-2 loss: 1.013043  [   96/  124]
train() client id: f_00002-8-0 loss: 0.886701  [   32/  124]
train() client id: f_00002-8-1 loss: 1.096936  [   64/  124]
train() client id: f_00002-8-2 loss: 0.890863  [   96/  124]
train() client id: f_00002-9-0 loss: 1.093226  [   32/  124]
train() client id: f_00002-9-1 loss: 0.932666  [   64/  124]
train() client id: f_00002-9-2 loss: 0.852220  [   96/  124]
train() client id: f_00002-10-0 loss: 0.807606  [   32/  124]
train() client id: f_00002-10-1 loss: 1.022440  [   64/  124]
train() client id: f_00002-10-2 loss: 0.925054  [   96/  124]
train() client id: f_00002-11-0 loss: 0.910512  [   32/  124]
train() client id: f_00002-11-1 loss: 0.973804  [   64/  124]
train() client id: f_00002-11-2 loss: 0.888132  [   96/  124]
train() client id: f_00002-12-0 loss: 0.861897  [   32/  124]
train() client id: f_00002-12-1 loss: 0.960184  [   64/  124]
train() client id: f_00002-12-2 loss: 0.801820  [   96/  124]
train() client id: f_00003-0-0 loss: 0.388027  [   32/   43]
train() client id: f_00003-1-0 loss: 0.464188  [   32/   43]
train() client id: f_00003-2-0 loss: 0.524255  [   32/   43]
train() client id: f_00003-3-0 loss: 0.396218  [   32/   43]
train() client id: f_00003-4-0 loss: 0.349334  [   32/   43]
train() client id: f_00003-5-0 loss: 0.467447  [   32/   43]
train() client id: f_00003-6-0 loss: 0.503418  [   32/   43]
train() client id: f_00003-7-0 loss: 0.524417  [   32/   43]
train() client id: f_00003-8-0 loss: 0.502276  [   32/   43]
train() client id: f_00003-9-0 loss: 0.525178  [   32/   43]
train() client id: f_00003-10-0 loss: 0.662744  [   32/   43]
train() client id: f_00003-11-0 loss: 0.604620  [   32/   43]
train() client id: f_00003-12-0 loss: 0.676870  [   32/   43]
train() client id: f_00004-0-0 loss: 0.883491  [   32/  306]
train() client id: f_00004-0-1 loss: 0.872719  [   64/  306]
train() client id: f_00004-0-2 loss: 1.109294  [   96/  306]
train() client id: f_00004-0-3 loss: 0.794434  [  128/  306]
train() client id: f_00004-0-4 loss: 0.923141  [  160/  306]
train() client id: f_00004-0-5 loss: 0.922126  [  192/  306]
train() client id: f_00004-0-6 loss: 0.897716  [  224/  306]
train() client id: f_00004-0-7 loss: 1.125402  [  256/  306]
train() client id: f_00004-0-8 loss: 0.860814  [  288/  306]
train() client id: f_00004-1-0 loss: 0.949327  [   32/  306]
train() client id: f_00004-1-1 loss: 0.957569  [   64/  306]
train() client id: f_00004-1-2 loss: 0.903520  [   96/  306]
train() client id: f_00004-1-3 loss: 0.939135  [  128/  306]
train() client id: f_00004-1-4 loss: 0.917948  [  160/  306]
train() client id: f_00004-1-5 loss: 0.861413  [  192/  306]
train() client id: f_00004-1-6 loss: 0.882955  [  224/  306]
train() client id: f_00004-1-7 loss: 0.819614  [  256/  306]
train() client id: f_00004-1-8 loss: 0.985049  [  288/  306]
train() client id: f_00004-2-0 loss: 0.801776  [   32/  306]
train() client id: f_00004-2-1 loss: 1.018658  [   64/  306]
train() client id: f_00004-2-2 loss: 0.929786  [   96/  306]
train() client id: f_00004-2-3 loss: 0.964141  [  128/  306]
train() client id: f_00004-2-4 loss: 0.958995  [  160/  306]
train() client id: f_00004-2-5 loss: 0.923663  [  192/  306]
train() client id: f_00004-2-6 loss: 0.874073  [  224/  306]
train() client id: f_00004-2-7 loss: 0.924248  [  256/  306]
train() client id: f_00004-2-8 loss: 0.917723  [  288/  306]
train() client id: f_00004-3-0 loss: 0.903200  [   32/  306]
train() client id: f_00004-3-1 loss: 0.871345  [   64/  306]
train() client id: f_00004-3-2 loss: 0.990351  [   96/  306]
train() client id: f_00004-3-3 loss: 0.913485  [  128/  306]
train() client id: f_00004-3-4 loss: 0.891163  [  160/  306]
train() client id: f_00004-3-5 loss: 0.846830  [  192/  306]
train() client id: f_00004-3-6 loss: 0.885799  [  224/  306]
train() client id: f_00004-3-7 loss: 0.929635  [  256/  306]
train() client id: f_00004-3-8 loss: 0.930801  [  288/  306]
train() client id: f_00004-4-0 loss: 0.860120  [   32/  306]
train() client id: f_00004-4-1 loss: 1.039509  [   64/  306]
train() client id: f_00004-4-2 loss: 0.838561  [   96/  306]
train() client id: f_00004-4-3 loss: 0.859582  [  128/  306]
train() client id: f_00004-4-4 loss: 0.929469  [  160/  306]
train() client id: f_00004-4-5 loss: 0.903177  [  192/  306]
train() client id: f_00004-4-6 loss: 0.843272  [  224/  306]
train() client id: f_00004-4-7 loss: 0.952823  [  256/  306]
train() client id: f_00004-4-8 loss: 0.859001  [  288/  306]
train() client id: f_00004-5-0 loss: 0.917576  [   32/  306]
train() client id: f_00004-5-1 loss: 0.844523  [   64/  306]
train() client id: f_00004-5-2 loss: 0.965623  [   96/  306]
train() client id: f_00004-5-3 loss: 0.898216  [  128/  306]
train() client id: f_00004-5-4 loss: 0.932429  [  160/  306]
train() client id: f_00004-5-5 loss: 0.857865  [  192/  306]
train() client id: f_00004-5-6 loss: 0.938928  [  224/  306]
train() client id: f_00004-5-7 loss: 0.761605  [  256/  306]
train() client id: f_00004-5-8 loss: 0.957337  [  288/  306]
train() client id: f_00004-6-0 loss: 0.904601  [   32/  306]
train() client id: f_00004-6-1 loss: 0.842818  [   64/  306]
train() client id: f_00004-6-2 loss: 0.933915  [   96/  306]
train() client id: f_00004-6-3 loss: 0.928426  [  128/  306]
train() client id: f_00004-6-4 loss: 0.848944  [  160/  306]
train() client id: f_00004-6-5 loss: 0.896861  [  192/  306]
train() client id: f_00004-6-6 loss: 0.866834  [  224/  306]
train() client id: f_00004-6-7 loss: 0.932010  [  256/  306]
train() client id: f_00004-6-8 loss: 0.959537  [  288/  306]
train() client id: f_00004-7-0 loss: 0.836243  [   32/  306]
train() client id: f_00004-7-1 loss: 1.072643  [   64/  306]
train() client id: f_00004-7-2 loss: 0.812584  [   96/  306]
train() client id: f_00004-7-3 loss: 1.054353  [  128/  306]
train() client id: f_00004-7-4 loss: 0.770687  [  160/  306]
train() client id: f_00004-7-5 loss: 0.817318  [  192/  306]
train() client id: f_00004-7-6 loss: 0.817117  [  224/  306]
train() client id: f_00004-7-7 loss: 0.881841  [  256/  306]
train() client id: f_00004-7-8 loss: 0.982573  [  288/  306]
train() client id: f_00004-8-0 loss: 0.893506  [   32/  306]
train() client id: f_00004-8-1 loss: 0.894967  [   64/  306]
train() client id: f_00004-8-2 loss: 0.930262  [   96/  306]
train() client id: f_00004-8-3 loss: 0.895780  [  128/  306]
train() client id: f_00004-8-4 loss: 0.942209  [  160/  306]
train() client id: f_00004-8-5 loss: 0.779049  [  192/  306]
train() client id: f_00004-8-6 loss: 0.783408  [  224/  306]
train() client id: f_00004-8-7 loss: 0.841526  [  256/  306]
train() client id: f_00004-8-8 loss: 1.015360  [  288/  306]
train() client id: f_00004-9-0 loss: 0.929404  [   32/  306]
train() client id: f_00004-9-1 loss: 0.745775  [   64/  306]
train() client id: f_00004-9-2 loss: 0.942313  [   96/  306]
train() client id: f_00004-9-3 loss: 0.798468  [  128/  306]
train() client id: f_00004-9-4 loss: 0.884096  [  160/  306]
train() client id: f_00004-9-5 loss: 1.014866  [  192/  306]
train() client id: f_00004-9-6 loss: 0.854171  [  224/  306]
train() client id: f_00004-9-7 loss: 1.019276  [  256/  306]
train() client id: f_00004-9-8 loss: 0.868394  [  288/  306]
train() client id: f_00004-10-0 loss: 0.980715  [   32/  306]
train() client id: f_00004-10-1 loss: 0.818280  [   64/  306]
train() client id: f_00004-10-2 loss: 0.927605  [   96/  306]
train() client id: f_00004-10-3 loss: 0.940710  [  128/  306]
train() client id: f_00004-10-4 loss: 0.874456  [  160/  306]
train() client id: f_00004-10-5 loss: 0.873769  [  192/  306]
train() client id: f_00004-10-6 loss: 0.833802  [  224/  306]
train() client id: f_00004-10-7 loss: 0.885332  [  256/  306]
train() client id: f_00004-10-8 loss: 0.769938  [  288/  306]
train() client id: f_00004-11-0 loss: 0.820843  [   32/  306]
train() client id: f_00004-11-1 loss: 0.902992  [   64/  306]
train() client id: f_00004-11-2 loss: 0.912521  [   96/  306]
train() client id: f_00004-11-3 loss: 0.858008  [  128/  306]
train() client id: f_00004-11-4 loss: 0.954633  [  160/  306]
train() client id: f_00004-11-5 loss: 0.936410  [  192/  306]
train() client id: f_00004-11-6 loss: 1.029479  [  224/  306]
train() client id: f_00004-11-7 loss: 0.747245  [  256/  306]
train() client id: f_00004-11-8 loss: 0.865690  [  288/  306]
train() client id: f_00004-12-0 loss: 0.889570  [   32/  306]
train() client id: f_00004-12-1 loss: 0.818052  [   64/  306]
train() client id: f_00004-12-2 loss: 0.960044  [   96/  306]
train() client id: f_00004-12-3 loss: 0.920456  [  128/  306]
train() client id: f_00004-12-4 loss: 0.757663  [  160/  306]
train() client id: f_00004-12-5 loss: 0.851881  [  192/  306]
train() client id: f_00004-12-6 loss: 0.793833  [  224/  306]
train() client id: f_00004-12-7 loss: 0.792581  [  256/  306]
train() client id: f_00004-12-8 loss: 1.227093  [  288/  306]
train() client id: f_00005-0-0 loss: 0.854109  [   32/  146]
train() client id: f_00005-0-1 loss: 0.857928  [   64/  146]
train() client id: f_00005-0-2 loss: 0.989751  [   96/  146]
train() client id: f_00005-0-3 loss: 0.924323  [  128/  146]
train() client id: f_00005-1-0 loss: 1.076612  [   32/  146]
train() client id: f_00005-1-1 loss: 0.818557  [   64/  146]
train() client id: f_00005-1-2 loss: 0.853944  [   96/  146]
train() client id: f_00005-1-3 loss: 0.945198  [  128/  146]
train() client id: f_00005-2-0 loss: 1.094880  [   32/  146]
train() client id: f_00005-2-1 loss: 0.922129  [   64/  146]
train() client id: f_00005-2-2 loss: 0.738707  [   96/  146]
train() client id: f_00005-2-3 loss: 0.888443  [  128/  146]
train() client id: f_00005-3-0 loss: 0.954459  [   32/  146]
train() client id: f_00005-3-1 loss: 1.260564  [   64/  146]
train() client id: f_00005-3-2 loss: 0.694034  [   96/  146]
train() client id: f_00005-3-3 loss: 0.882780  [  128/  146]
train() client id: f_00005-4-0 loss: 0.947122  [   32/  146]
train() client id: f_00005-4-1 loss: 0.957803  [   64/  146]
train() client id: f_00005-4-2 loss: 0.975281  [   96/  146]
train() client id: f_00005-4-3 loss: 0.817593  [  128/  146]
train() client id: f_00005-5-0 loss: 0.730657  [   32/  146]
train() client id: f_00005-5-1 loss: 0.823889  [   64/  146]
train() client id: f_00005-5-2 loss: 0.972522  [   96/  146]
train() client id: f_00005-5-3 loss: 1.077156  [  128/  146]
train() client id: f_00005-6-0 loss: 0.782620  [   32/  146]
train() client id: f_00005-6-1 loss: 1.217671  [   64/  146]
train() client id: f_00005-6-2 loss: 0.719965  [   96/  146]
train() client id: f_00005-6-3 loss: 1.178825  [  128/  146]
train() client id: f_00005-7-0 loss: 0.874307  [   32/  146]
train() client id: f_00005-7-1 loss: 0.752619  [   64/  146]
train() client id: f_00005-7-2 loss: 0.866992  [   96/  146]
train() client id: f_00005-7-3 loss: 1.094475  [  128/  146]
train() client id: f_00005-8-0 loss: 0.845224  [   32/  146]
train() client id: f_00005-8-1 loss: 1.060512  [   64/  146]
train() client id: f_00005-8-2 loss: 1.023926  [   96/  146]
train() client id: f_00005-8-3 loss: 0.873230  [  128/  146]
train() client id: f_00005-9-0 loss: 0.830364  [   32/  146]
train() client id: f_00005-9-1 loss: 1.079309  [   64/  146]
train() client id: f_00005-9-2 loss: 0.976305  [   96/  146]
train() client id: f_00005-9-3 loss: 0.809269  [  128/  146]
train() client id: f_00005-10-0 loss: 0.787511  [   32/  146]
train() client id: f_00005-10-1 loss: 1.147516  [   64/  146]
train() client id: f_00005-10-2 loss: 0.985679  [   96/  146]
train() client id: f_00005-10-3 loss: 0.946890  [  128/  146]
train() client id: f_00005-11-0 loss: 0.987103  [   32/  146]
train() client id: f_00005-11-1 loss: 0.727830  [   64/  146]
train() client id: f_00005-11-2 loss: 1.062971  [   96/  146]
train() client id: f_00005-11-3 loss: 0.834378  [  128/  146]
train() client id: f_00005-12-0 loss: 0.858851  [   32/  146]
train() client id: f_00005-12-1 loss: 0.844897  [   64/  146]
train() client id: f_00005-12-2 loss: 0.770833  [   96/  146]
train() client id: f_00005-12-3 loss: 1.200279  [  128/  146]
train() client id: f_00006-0-0 loss: 0.528368  [   32/   54]
train() client id: f_00006-1-0 loss: 0.424914  [   32/   54]
train() client id: f_00006-2-0 loss: 0.404841  [   32/   54]
train() client id: f_00006-3-0 loss: 0.434247  [   32/   54]
train() client id: f_00006-4-0 loss: 0.461215  [   32/   54]
train() client id: f_00006-5-0 loss: 0.514269  [   32/   54]
train() client id: f_00006-6-0 loss: 0.467812  [   32/   54]
train() client id: f_00006-7-0 loss: 0.440864  [   32/   54]
train() client id: f_00006-8-0 loss: 0.452285  [   32/   54]
train() client id: f_00006-9-0 loss: 0.476683  [   32/   54]
train() client id: f_00006-10-0 loss: 0.473406  [   32/   54]
train() client id: f_00006-11-0 loss: 0.513092  [   32/   54]
train() client id: f_00006-12-0 loss: 0.453028  [   32/   54]
train() client id: f_00007-0-0 loss: 0.667160  [   32/  179]
train() client id: f_00007-0-1 loss: 0.405594  [   64/  179]
train() client id: f_00007-0-2 loss: 0.489982  [   96/  179]
train() client id: f_00007-0-3 loss: 0.588670  [  128/  179]
train() client id: f_00007-0-4 loss: 0.494462  [  160/  179]
train() client id: f_00007-1-0 loss: 0.501257  [   32/  179]
train() client id: f_00007-1-1 loss: 0.343150  [   64/  179]
train() client id: f_00007-1-2 loss: 0.436262  [   96/  179]
train() client id: f_00007-1-3 loss: 0.526704  [  128/  179]
train() client id: f_00007-1-4 loss: 0.646045  [  160/  179]
train() client id: f_00007-2-0 loss: 0.419504  [   32/  179]
train() client id: f_00007-2-1 loss: 0.398606  [   64/  179]
train() client id: f_00007-2-2 loss: 0.675320  [   96/  179]
train() client id: f_00007-2-3 loss: 0.534489  [  128/  179]
train() client id: f_00007-2-4 loss: 0.460915  [  160/  179]
train() client id: f_00007-3-0 loss: 0.483628  [   32/  179]
train() client id: f_00007-3-1 loss: 0.387560  [   64/  179]
train() client id: f_00007-3-2 loss: 0.523926  [   96/  179]
train() client id: f_00007-3-3 loss: 0.475470  [  128/  179]
train() client id: f_00007-3-4 loss: 0.510909  [  160/  179]
train() client id: f_00007-4-0 loss: 0.419780  [   32/  179]
train() client id: f_00007-4-1 loss: 0.318685  [   64/  179]
train() client id: f_00007-4-2 loss: 0.533671  [   96/  179]
train() client id: f_00007-4-3 loss: 0.662089  [  128/  179]
train() client id: f_00007-4-4 loss: 0.477005  [  160/  179]
train() client id: f_00007-5-0 loss: 0.483792  [   32/  179]
train() client id: f_00007-5-1 loss: 0.722456  [   64/  179]
train() client id: f_00007-5-2 loss: 0.396754  [   96/  179]
train() client id: f_00007-5-3 loss: 0.431372  [  128/  179]
train() client id: f_00007-5-4 loss: 0.370719  [  160/  179]
train() client id: f_00007-6-0 loss: 0.436614  [   32/  179]
train() client id: f_00007-6-1 loss: 0.394912  [   64/  179]
train() client id: f_00007-6-2 loss: 0.549419  [   96/  179]
train() client id: f_00007-6-3 loss: 0.398686  [  128/  179]
train() client id: f_00007-6-4 loss: 0.579434  [  160/  179]
train() client id: f_00007-7-0 loss: 0.515090  [   32/  179]
train() client id: f_00007-7-1 loss: 0.512561  [   64/  179]
train() client id: f_00007-7-2 loss: 0.388829  [   96/  179]
train() client id: f_00007-7-3 loss: 0.515423  [  128/  179]
train() client id: f_00007-7-4 loss: 0.389492  [  160/  179]
train() client id: f_00007-8-0 loss: 0.364481  [   32/  179]
train() client id: f_00007-8-1 loss: 0.621670  [   64/  179]
train() client id: f_00007-8-2 loss: 0.402502  [   96/  179]
train() client id: f_00007-8-3 loss: 0.498990  [  128/  179]
train() client id: f_00007-8-4 loss: 0.445545  [  160/  179]
train() client id: f_00007-9-0 loss: 0.390444  [   32/  179]
train() client id: f_00007-9-1 loss: 0.417023  [   64/  179]
train() client id: f_00007-9-2 loss: 0.603188  [   96/  179]
train() client id: f_00007-9-3 loss: 0.425531  [  128/  179]
train() client id: f_00007-9-4 loss: 0.394889  [  160/  179]
train() client id: f_00007-10-0 loss: 0.289253  [   32/  179]
train() client id: f_00007-10-1 loss: 0.497133  [   64/  179]
train() client id: f_00007-10-2 loss: 0.448128  [   96/  179]
train() client id: f_00007-10-3 loss: 0.378960  [  128/  179]
train() client id: f_00007-10-4 loss: 0.531866  [  160/  179]
train() client id: f_00007-11-0 loss: 0.570903  [   32/  179]
train() client id: f_00007-11-1 loss: 0.306675  [   64/  179]
train() client id: f_00007-11-2 loss: 0.765552  [   96/  179]
train() client id: f_00007-11-3 loss: 0.286744  [  128/  179]
train() client id: f_00007-11-4 loss: 0.368099  [  160/  179]
train() client id: f_00007-12-0 loss: 0.486317  [   32/  179]
train() client id: f_00007-12-1 loss: 0.389035  [   64/  179]
train() client id: f_00007-12-2 loss: 0.290306  [   96/  179]
train() client id: f_00007-12-3 loss: 0.394769  [  128/  179]
train() client id: f_00007-12-4 loss: 0.443178  [  160/  179]
train() client id: f_00008-0-0 loss: 0.668804  [   32/  130]
train() client id: f_00008-0-1 loss: 0.798126  [   64/  130]
train() client id: f_00008-0-2 loss: 0.746880  [   96/  130]
train() client id: f_00008-0-3 loss: 0.769809  [  128/  130]
train() client id: f_00008-1-0 loss: 0.693789  [   32/  130]
train() client id: f_00008-1-1 loss: 0.737188  [   64/  130]
train() client id: f_00008-1-2 loss: 0.788131  [   96/  130]
train() client id: f_00008-1-3 loss: 0.802038  [  128/  130]
train() client id: f_00008-2-0 loss: 0.777967  [   32/  130]
train() client id: f_00008-2-1 loss: 0.812033  [   64/  130]
train() client id: f_00008-2-2 loss: 0.752142  [   96/  130]
train() client id: f_00008-2-3 loss: 0.686718  [  128/  130]
train() client id: f_00008-3-0 loss: 0.730998  [   32/  130]
train() client id: f_00008-3-1 loss: 0.861401  [   64/  130]
train() client id: f_00008-3-2 loss: 0.732042  [   96/  130]
train() client id: f_00008-3-3 loss: 0.689453  [  128/  130]
train() client id: f_00008-4-0 loss: 0.732087  [   32/  130]
train() client id: f_00008-4-1 loss: 0.909548  [   64/  130]
train() client id: f_00008-4-2 loss: 0.691012  [   96/  130]
train() client id: f_00008-4-3 loss: 0.663777  [  128/  130]
train() client id: f_00008-5-0 loss: 0.767153  [   32/  130]
train() client id: f_00008-5-1 loss: 0.638870  [   64/  130]
train() client id: f_00008-5-2 loss: 0.864353  [   96/  130]
train() client id: f_00008-5-3 loss: 0.736913  [  128/  130]
train() client id: f_00008-6-0 loss: 0.710029  [   32/  130]
train() client id: f_00008-6-1 loss: 0.847784  [   64/  130]
train() client id: f_00008-6-2 loss: 0.723922  [   96/  130]
train() client id: f_00008-6-3 loss: 0.726950  [  128/  130]
train() client id: f_00008-7-0 loss: 0.700460  [   32/  130]
train() client id: f_00008-7-1 loss: 0.751630  [   64/  130]
train() client id: f_00008-7-2 loss: 0.786728  [   96/  130]
train() client id: f_00008-7-3 loss: 0.768904  [  128/  130]
train() client id: f_00008-8-0 loss: 0.810405  [   32/  130]
train() client id: f_00008-8-1 loss: 0.699492  [   64/  130]
train() client id: f_00008-8-2 loss: 0.735926  [   96/  130]
train() client id: f_00008-8-3 loss: 0.758900  [  128/  130]
train() client id: f_00008-9-0 loss: 0.659358  [   32/  130]
train() client id: f_00008-9-1 loss: 0.717310  [   64/  130]
train() client id: f_00008-9-2 loss: 0.767344  [   96/  130]
train() client id: f_00008-9-3 loss: 0.837550  [  128/  130]
train() client id: f_00008-10-0 loss: 0.854136  [   32/  130]
train() client id: f_00008-10-1 loss: 0.731399  [   64/  130]
train() client id: f_00008-10-2 loss: 0.681311  [   96/  130]
train() client id: f_00008-10-3 loss: 0.695436  [  128/  130]
train() client id: f_00008-11-0 loss: 0.749236  [   32/  130]
train() client id: f_00008-11-1 loss: 0.817200  [   64/  130]
train() client id: f_00008-11-2 loss: 0.711878  [   96/  130]
train() client id: f_00008-11-3 loss: 0.688648  [  128/  130]
train() client id: f_00008-12-0 loss: 0.749156  [   32/  130]
train() client id: f_00008-12-1 loss: 0.759840  [   64/  130]
train() client id: f_00008-12-2 loss: 0.764532  [   96/  130]
train() client id: f_00008-12-3 loss: 0.671582  [  128/  130]
train() client id: f_00009-0-0 loss: 1.056576  [   32/  118]
train() client id: f_00009-0-1 loss: 1.153824  [   64/  118]
train() client id: f_00009-0-2 loss: 1.088766  [   96/  118]
train() client id: f_00009-1-0 loss: 1.164223  [   32/  118]
train() client id: f_00009-1-1 loss: 0.991228  [   64/  118]
train() client id: f_00009-1-2 loss: 1.084749  [   96/  118]
train() client id: f_00009-2-0 loss: 1.111684  [   32/  118]
train() client id: f_00009-2-1 loss: 1.001455  [   64/  118]
train() client id: f_00009-2-2 loss: 1.057661  [   96/  118]
train() client id: f_00009-3-0 loss: 0.964024  [   32/  118]
train() client id: f_00009-3-1 loss: 0.937854  [   64/  118]
train() client id: f_00009-3-2 loss: 1.083460  [   96/  118]
train() client id: f_00009-4-0 loss: 1.016823  [   32/  118]
train() client id: f_00009-4-1 loss: 0.892589  [   64/  118]
train() client id: f_00009-4-2 loss: 1.046583  [   96/  118]
train() client id: f_00009-5-0 loss: 1.014178  [   32/  118]
train() client id: f_00009-5-1 loss: 0.857155  [   64/  118]
train() client id: f_00009-5-2 loss: 0.981418  [   96/  118]
train() client id: f_00009-6-0 loss: 0.838658  [   32/  118]
train() client id: f_00009-6-1 loss: 1.041002  [   64/  118]
train() client id: f_00009-6-2 loss: 0.809831  [   96/  118]
train() client id: f_00009-7-0 loss: 0.825915  [   32/  118]
train() client id: f_00009-7-1 loss: 0.923254  [   64/  118]
train() client id: f_00009-7-2 loss: 0.903374  [   96/  118]
train() client id: f_00009-8-0 loss: 0.861511  [   32/  118]
train() client id: f_00009-8-1 loss: 0.738994  [   64/  118]
train() client id: f_00009-8-2 loss: 1.000575  [   96/  118]
train() client id: f_00009-9-0 loss: 0.875787  [   32/  118]
train() client id: f_00009-9-1 loss: 0.827516  [   64/  118]
train() client id: f_00009-9-2 loss: 0.896517  [   96/  118]
train() client id: f_00009-10-0 loss: 0.756098  [   32/  118]
train() client id: f_00009-10-1 loss: 0.850528  [   64/  118]
train() client id: f_00009-10-2 loss: 0.954978  [   96/  118]
train() client id: f_00009-11-0 loss: 0.725626  [   32/  118]
train() client id: f_00009-11-1 loss: 0.841834  [   64/  118]
train() client id: f_00009-11-2 loss: 0.960903  [   96/  118]
train() client id: f_00009-12-0 loss: 0.877171  [   32/  118]
train() client id: f_00009-12-1 loss: 0.880707  [   64/  118]
train() client id: f_00009-12-2 loss: 0.800137  [   96/  118]
At round 31 accuracy: 0.6419098143236074
At round 31 training accuracy: 0.5861837692823608
At round 31 training loss: 0.8392417098414889
gradient difference: 0.48505115509033203
train() client id: f_00000-0-0 loss: 1.108008  [   32/  126]
train() client id: f_00000-0-1 loss: 0.993608  [   64/  126]
train() client id: f_00000-0-2 loss: 1.077504  [   96/  126]
train() client id: f_00000-1-0 loss: 1.307825  [   32/  126]
train() client id: f_00000-1-1 loss: 1.083442  [   64/  126]
train() client id: f_00000-1-2 loss: 0.886379  [   96/  126]
train() client id: f_00000-2-0 loss: 0.942781  [   32/  126]
train() client id: f_00000-2-1 loss: 0.975690  [   64/  126]
train() client id: f_00000-2-2 loss: 0.986546  [   96/  126]
train() client id: f_00000-3-0 loss: 1.048169  [   32/  126]
train() client id: f_00000-3-1 loss: 0.931567  [   64/  126]
train() client id: f_00000-3-2 loss: 0.861820  [   96/  126]
train() client id: f_00000-4-0 loss: 0.751308  [   32/  126]
train() client id: f_00000-4-1 loss: 0.962191  [   64/  126]
train() client id: f_00000-4-2 loss: 0.917834  [   96/  126]
train() client id: f_00000-5-0 loss: 0.905845  [   32/  126]
train() client id: f_00000-5-1 loss: 0.829323  [   64/  126]
train() client id: f_00000-5-2 loss: 0.832457  [   96/  126]
train() client id: f_00000-6-0 loss: 0.870848  [   32/  126]
train() client id: f_00000-6-1 loss: 0.834128  [   64/  126]
train() client id: f_00000-6-2 loss: 0.907265  [   96/  126]
train() client id: f_00000-7-0 loss: 0.811192  [   32/  126]
train() client id: f_00000-7-1 loss: 0.769778  [   64/  126]
train() client id: f_00000-7-2 loss: 0.914056  [   96/  126]
train() client id: f_00000-8-0 loss: 0.869203  [   32/  126]
train() client id: f_00000-8-1 loss: 0.856159  [   64/  126]
train() client id: f_00000-8-2 loss: 0.879340  [   96/  126]
train() client id: f_00000-9-0 loss: 0.892339  [   32/  126]
train() client id: f_00000-9-1 loss: 0.818030  [   64/  126]
train() client id: f_00000-9-2 loss: 0.664625  [   96/  126]
train() client id: f_00000-10-0 loss: 0.790383  [   32/  126]
train() client id: f_00000-10-1 loss: 0.773411  [   64/  126]
train() client id: f_00000-10-2 loss: 0.828066  [   96/  126]
train() client id: f_00000-11-0 loss: 0.812859  [   32/  126]
train() client id: f_00000-11-1 loss: 0.802556  [   64/  126]
train() client id: f_00000-11-2 loss: 0.794270  [   96/  126]
train() client id: f_00000-12-0 loss: 0.839960  [   32/  126]
train() client id: f_00000-12-1 loss: 0.918687  [   64/  126]
train() client id: f_00000-12-2 loss: 0.735980  [   96/  126]
train() client id: f_00001-0-0 loss: 0.655005  [   32/  265]
train() client id: f_00001-0-1 loss: 0.457557  [   64/  265]
train() client id: f_00001-0-2 loss: 0.409277  [   96/  265]
train() client id: f_00001-0-3 loss: 0.449114  [  128/  265]
train() client id: f_00001-0-4 loss: 0.517356  [  160/  265]
train() client id: f_00001-0-5 loss: 0.509086  [  192/  265]
train() client id: f_00001-0-6 loss: 0.390953  [  224/  265]
train() client id: f_00001-0-7 loss: 0.422683  [  256/  265]
train() client id: f_00001-1-0 loss: 0.457468  [   32/  265]
train() client id: f_00001-1-1 loss: 0.542548  [   64/  265]
train() client id: f_00001-1-2 loss: 0.455469  [   96/  265]
train() client id: f_00001-1-3 loss: 0.399071  [  128/  265]
train() client id: f_00001-1-4 loss: 0.532622  [  160/  265]
train() client id: f_00001-1-5 loss: 0.429905  [  192/  265]
train() client id: f_00001-1-6 loss: 0.527584  [  224/  265]
train() client id: f_00001-1-7 loss: 0.461984  [  256/  265]
train() client id: f_00001-2-0 loss: 0.407376  [   32/  265]
train() client id: f_00001-2-1 loss: 0.500367  [   64/  265]
train() client id: f_00001-2-2 loss: 0.493551  [   96/  265]
train() client id: f_00001-2-3 loss: 0.456869  [  128/  265]
train() client id: f_00001-2-4 loss: 0.515815  [  160/  265]
train() client id: f_00001-2-5 loss: 0.422058  [  192/  265]
train() client id: f_00001-2-6 loss: 0.503563  [  224/  265]
train() client id: f_00001-2-7 loss: 0.444437  [  256/  265]
train() client id: f_00001-3-0 loss: 0.389433  [   32/  265]
train() client id: f_00001-3-1 loss: 0.473294  [   64/  265]
train() client id: f_00001-3-2 loss: 0.433237  [   96/  265]
train() client id: f_00001-3-3 loss: 0.383122  [  128/  265]
train() client id: f_00001-3-4 loss: 0.481824  [  160/  265]
train() client id: f_00001-3-5 loss: 0.354741  [  192/  265]
train() client id: f_00001-3-6 loss: 0.458008  [  224/  265]
train() client id: f_00001-3-7 loss: 0.658922  [  256/  265]
train() client id: f_00001-4-0 loss: 0.446599  [   32/  265]
train() client id: f_00001-4-1 loss: 0.476252  [   64/  265]
train() client id: f_00001-4-2 loss: 0.456896  [   96/  265]
train() client id: f_00001-4-3 loss: 0.434251  [  128/  265]
train() client id: f_00001-4-4 loss: 0.481151  [  160/  265]
train() client id: f_00001-4-5 loss: 0.396862  [  192/  265]
train() client id: f_00001-4-6 loss: 0.464445  [  224/  265]
train() client id: f_00001-4-7 loss: 0.494189  [  256/  265]
train() client id: f_00001-5-0 loss: 0.355291  [   32/  265]
train() client id: f_00001-5-1 loss: 0.469094  [   64/  265]
train() client id: f_00001-5-2 loss: 0.436495  [   96/  265]
train() client id: f_00001-5-3 loss: 0.411811  [  128/  265]
train() client id: f_00001-5-4 loss: 0.443324  [  160/  265]
train() client id: f_00001-5-5 loss: 0.523509  [  192/  265]
train() client id: f_00001-5-6 loss: 0.370569  [  224/  265]
train() client id: f_00001-5-7 loss: 0.532204  [  256/  265]
train() client id: f_00001-6-0 loss: 0.404798  [   32/  265]
train() client id: f_00001-6-1 loss: 0.472891  [   64/  265]
train() client id: f_00001-6-2 loss: 0.437825  [   96/  265]
train() client id: f_00001-6-3 loss: 0.475887  [  128/  265]
train() client id: f_00001-6-4 loss: 0.361797  [  160/  265]
train() client id: f_00001-6-5 loss: 0.443663  [  192/  265]
train() client id: f_00001-6-6 loss: 0.598625  [  224/  265]
train() client id: f_00001-6-7 loss: 0.406519  [  256/  265]
train() client id: f_00001-7-0 loss: 0.358803  [   32/  265]
train() client id: f_00001-7-1 loss: 0.344468  [   64/  265]
train() client id: f_00001-7-2 loss: 0.467363  [   96/  265]
train() client id: f_00001-7-3 loss: 0.575795  [  128/  265]
train() client id: f_00001-7-4 loss: 0.363949  [  160/  265]
train() client id: f_00001-7-5 loss: 0.360137  [  192/  265]
train() client id: f_00001-7-6 loss: 0.493129  [  224/  265]
train() client id: f_00001-7-7 loss: 0.627553  [  256/  265]
train() client id: f_00001-8-0 loss: 0.434001  [   32/  265]
train() client id: f_00001-8-1 loss: 0.352638  [   64/  265]
train() client id: f_00001-8-2 loss: 0.423812  [   96/  265]
train() client id: f_00001-8-3 loss: 0.428234  [  128/  265]
train() client id: f_00001-8-4 loss: 0.457741  [  160/  265]
train() client id: f_00001-8-5 loss: 0.492613  [  192/  265]
train() client id: f_00001-8-6 loss: 0.358877  [  224/  265]
train() client id: f_00001-8-7 loss: 0.489921  [  256/  265]
train() client id: f_00001-9-0 loss: 0.406332  [   32/  265]
train() client id: f_00001-9-1 loss: 0.338796  [   64/  265]
train() client id: f_00001-9-2 loss: 0.500927  [   96/  265]
train() client id: f_00001-9-3 loss: 0.546632  [  128/  265]
train() client id: f_00001-9-4 loss: 0.534846  [  160/  265]
train() client id: f_00001-9-5 loss: 0.353721  [  192/  265]
train() client id: f_00001-9-6 loss: 0.346405  [  224/  265]
train() client id: f_00001-9-7 loss: 0.451121  [  256/  265]
train() client id: f_00001-10-0 loss: 0.517859  [   32/  265]
train() client id: f_00001-10-1 loss: 0.339950  [   64/  265]
train() client id: f_00001-10-2 loss: 0.447216  [   96/  265]
train() client id: f_00001-10-3 loss: 0.479708  [  128/  265]
train() client id: f_00001-10-4 loss: 0.505837  [  160/  265]
train() client id: f_00001-10-5 loss: 0.422848  [  192/  265]
train() client id: f_00001-10-6 loss: 0.423938  [  224/  265]
train() client id: f_00001-10-7 loss: 0.377153  [  256/  265]
train() client id: f_00001-11-0 loss: 0.344089  [   32/  265]
train() client id: f_00001-11-1 loss: 0.468752  [   64/  265]
train() client id: f_00001-11-2 loss: 0.492798  [   96/  265]
train() client id: f_00001-11-3 loss: 0.383031  [  128/  265]
train() client id: f_00001-11-4 loss: 0.543874  [  160/  265]
train() client id: f_00001-11-5 loss: 0.480395  [  192/  265]
train() client id: f_00001-11-6 loss: 0.433885  [  224/  265]
train() client id: f_00001-11-7 loss: 0.406747  [  256/  265]
train() client id: f_00001-12-0 loss: 0.393036  [   32/  265]
train() client id: f_00001-12-1 loss: 0.565094  [   64/  265]
train() client id: f_00001-12-2 loss: 0.423805  [   96/  265]
train() client id: f_00001-12-3 loss: 0.348983  [  128/  265]
train() client id: f_00001-12-4 loss: 0.427095  [  160/  265]
train() client id: f_00001-12-5 loss: 0.502133  [  192/  265]
train() client id: f_00001-12-6 loss: 0.529792  [  224/  265]
train() client id: f_00001-12-7 loss: 0.348833  [  256/  265]
train() client id: f_00002-0-0 loss: 1.097989  [   32/  124]
train() client id: f_00002-0-1 loss: 1.293971  [   64/  124]
train() client id: f_00002-0-2 loss: 1.146219  [   96/  124]
train() client id: f_00002-1-0 loss: 1.407452  [   32/  124]
train() client id: f_00002-1-1 loss: 0.954987  [   64/  124]
train() client id: f_00002-1-2 loss: 1.105540  [   96/  124]
train() client id: f_00002-2-0 loss: 1.138180  [   32/  124]
train() client id: f_00002-2-1 loss: 1.020500  [   64/  124]
train() client id: f_00002-2-2 loss: 1.235095  [   96/  124]
train() client id: f_00002-3-0 loss: 1.130304  [   32/  124]
train() client id: f_00002-3-1 loss: 1.128060  [   64/  124]
train() client id: f_00002-3-2 loss: 1.145419  [   96/  124]
train() client id: f_00002-4-0 loss: 1.161688  [   32/  124]
train() client id: f_00002-4-1 loss: 0.991292  [   64/  124]
train() client id: f_00002-4-2 loss: 1.062705  [   96/  124]
train() client id: f_00002-5-0 loss: 1.073178  [   32/  124]
train() client id: f_00002-5-1 loss: 1.179930  [   64/  124]
train() client id: f_00002-5-2 loss: 1.068450  [   96/  124]
train() client id: f_00002-6-0 loss: 1.026352  [   32/  124]
train() client id: f_00002-6-1 loss: 1.073272  [   64/  124]
train() client id: f_00002-6-2 loss: 1.146921  [   96/  124]
train() client id: f_00002-7-0 loss: 1.123508  [   32/  124]
train() client id: f_00002-7-1 loss: 1.085542  [   64/  124]
train() client id: f_00002-7-2 loss: 1.090844  [   96/  124]
train() client id: f_00002-8-0 loss: 1.139905  [   32/  124]
train() client id: f_00002-8-1 loss: 1.119666  [   64/  124]
train() client id: f_00002-8-2 loss: 1.014062  [   96/  124]
train() client id: f_00002-9-0 loss: 1.072362  [   32/  124]
train() client id: f_00002-9-1 loss: 1.061323  [   64/  124]
train() client id: f_00002-9-2 loss: 1.206221  [   96/  124]
train() client id: f_00002-10-0 loss: 1.019937  [   32/  124]
train() client id: f_00002-10-1 loss: 1.065915  [   64/  124]
train() client id: f_00002-10-2 loss: 0.954162  [   96/  124]
train() client id: f_00002-11-0 loss: 0.991748  [   32/  124]
train() client id: f_00002-11-1 loss: 1.044702  [   64/  124]
train() client id: f_00002-11-2 loss: 1.182792  [   96/  124]
train() client id: f_00002-12-0 loss: 1.008009  [   32/  124]
train() client id: f_00002-12-1 loss: 0.906017  [   64/  124]
train() client id: f_00002-12-2 loss: 1.166594  [   96/  124]
train() client id: f_00003-0-0 loss: 0.609362  [   32/   43]
train() client id: f_00003-1-0 loss: 0.705224  [   32/   43]
train() client id: f_00003-2-0 loss: 0.815263  [   32/   43]
train() client id: f_00003-3-0 loss: 0.451852  [   32/   43]
train() client id: f_00003-4-0 loss: 0.575707  [   32/   43]
train() client id: f_00003-5-0 loss: 0.524522  [   32/   43]
train() client id: f_00003-6-0 loss: 0.556369  [   32/   43]
train() client id: f_00003-7-0 loss: 0.639180  [   32/   43]
train() client id: f_00003-8-0 loss: 0.565129  [   32/   43]
train() client id: f_00003-9-0 loss: 0.634239  [   32/   43]
train() client id: f_00003-10-0 loss: 0.525224  [   32/   43]
train() client id: f_00003-11-0 loss: 0.565277  [   32/   43]
train() client id: f_00003-12-0 loss: 0.508049  [   32/   43]
train() client id: f_00004-0-0 loss: 0.515621  [   32/  306]
train() client id: f_00004-0-1 loss: 0.555851  [   64/  306]
train() client id: f_00004-0-2 loss: 0.527412  [   96/  306]
train() client id: f_00004-0-3 loss: 0.547264  [  128/  306]
train() client id: f_00004-0-4 loss: 0.653249  [  160/  306]
train() client id: f_00004-0-5 loss: 0.373513  [  192/  306]
train() client id: f_00004-0-6 loss: 0.541289  [  224/  306]
train() client id: f_00004-0-7 loss: 0.468349  [  256/  306]
train() client id: f_00004-0-8 loss: 0.435233  [  288/  306]
train() client id: f_00004-1-0 loss: 0.499378  [   32/  306]
train() client id: f_00004-1-1 loss: 0.460497  [   64/  306]
train() client id: f_00004-1-2 loss: 0.468676  [   96/  306]
train() client id: f_00004-1-3 loss: 0.475636  [  128/  306]
train() client id: f_00004-1-4 loss: 0.504036  [  160/  306]
train() client id: f_00004-1-5 loss: 0.550467  [  192/  306]
train() client id: f_00004-1-6 loss: 0.434426  [  224/  306]
train() client id: f_00004-1-7 loss: 0.494208  [  256/  306]
train() client id: f_00004-1-8 loss: 0.749845  [  288/  306]
train() client id: f_00004-2-0 loss: 0.451386  [   32/  306]
train() client id: f_00004-2-1 loss: 0.647350  [   64/  306]
train() client id: f_00004-2-2 loss: 0.495338  [   96/  306]
train() client id: f_00004-2-3 loss: 0.440634  [  128/  306]
train() client id: f_00004-2-4 loss: 0.659442  [  160/  306]
train() client id: f_00004-2-5 loss: 0.430512  [  192/  306]
train() client id: f_00004-2-6 loss: 0.508829  [  224/  306]
train() client id: f_00004-2-7 loss: 0.430899  [  256/  306]
train() client id: f_00004-2-8 loss: 0.593116  [  288/  306]
train() client id: f_00004-3-0 loss: 0.537138  [   32/  306]
train() client id: f_00004-3-1 loss: 0.614212  [   64/  306]
train() client id: f_00004-3-2 loss: 0.478449  [   96/  306]
train() client id: f_00004-3-3 loss: 0.482032  [  128/  306]
train() client id: f_00004-3-4 loss: 0.565836  [  160/  306]
train() client id: f_00004-3-5 loss: 0.466614  [  192/  306]
train() client id: f_00004-3-6 loss: 0.506425  [  224/  306]
train() client id: f_00004-3-7 loss: 0.436438  [  256/  306]
train() client id: f_00004-3-8 loss: 0.386051  [  288/  306]
train() client id: f_00004-4-0 loss: 0.567416  [   32/  306]
train() client id: f_00004-4-1 loss: 0.435834  [   64/  306]
train() client id: f_00004-4-2 loss: 0.549105  [   96/  306]
train() client id: f_00004-4-3 loss: 0.645557  [  128/  306]
train() client id: f_00004-4-4 loss: 0.509689  [  160/  306]
train() client id: f_00004-4-5 loss: 0.561461  [  192/  306]
train() client id: f_00004-4-6 loss: 0.447606  [  224/  306]
train() client id: f_00004-4-7 loss: 0.427029  [  256/  306]
train() client id: f_00004-4-8 loss: 0.519704  [  288/  306]
train() client id: f_00004-5-0 loss: 0.484658  [   32/  306]
train() client id: f_00004-5-1 loss: 0.477189  [   64/  306]
train() client id: f_00004-5-2 loss: 0.490587  [   96/  306]
train() client id: f_00004-5-3 loss: 0.463609  [  128/  306]
train() client id: f_00004-5-4 loss: 0.485562  [  160/  306]
train() client id: f_00004-5-5 loss: 0.564411  [  192/  306]
train() client id: f_00004-5-6 loss: 0.563626  [  224/  306]
train() client id: f_00004-5-7 loss: 0.487970  [  256/  306]
train() client id: f_00004-5-8 loss: 0.690379  [  288/  306]
train() client id: f_00004-6-0 loss: 0.504613  [   32/  306]
train() client id: f_00004-6-1 loss: 0.573479  [   64/  306]
train() client id: f_00004-6-2 loss: 0.553944  [   96/  306]
train() client id: f_00004-6-3 loss: 0.488393  [  128/  306]
train() client id: f_00004-6-4 loss: 0.520933  [  160/  306]
train() client id: f_00004-6-5 loss: 0.477195  [  192/  306]
train() client id: f_00004-6-6 loss: 0.681959  [  224/  306]
train() client id: f_00004-6-7 loss: 0.513816  [  256/  306]
train() client id: f_00004-6-8 loss: 0.410398  [  288/  306]
train() client id: f_00004-7-0 loss: 0.485333  [   32/  306]
train() client id: f_00004-7-1 loss: 0.548038  [   64/  306]
train() client id: f_00004-7-2 loss: 0.448638  [   96/  306]
train() client id: f_00004-7-3 loss: 0.521569  [  128/  306]
train() client id: f_00004-7-4 loss: 0.543119  [  160/  306]
train() client id: f_00004-7-5 loss: 0.537761  [  192/  306]
train() client id: f_00004-7-6 loss: 0.557244  [  224/  306]
train() client id: f_00004-7-7 loss: 0.602068  [  256/  306]
train() client id: f_00004-7-8 loss: 0.413886  [  288/  306]
train() client id: f_00004-8-0 loss: 0.522324  [   32/  306]
train() client id: f_00004-8-1 loss: 0.594564  [   64/  306]
train() client id: f_00004-8-2 loss: 0.522670  [   96/  306]
train() client id: f_00004-8-3 loss: 0.451455  [  128/  306]
train() client id: f_00004-8-4 loss: 0.530076  [  160/  306]
train() client id: f_00004-8-5 loss: 0.570656  [  192/  306]
train() client id: f_00004-8-6 loss: 0.446392  [  224/  306]
train() client id: f_00004-8-7 loss: 0.468755  [  256/  306]
train() client id: f_00004-8-8 loss: 0.605131  [  288/  306]
train() client id: f_00004-9-0 loss: 0.460600  [   32/  306]
train() client id: f_00004-9-1 loss: 0.558221  [   64/  306]
train() client id: f_00004-9-2 loss: 0.432878  [   96/  306]
train() client id: f_00004-9-3 loss: 0.476125  [  128/  306]
train() client id: f_00004-9-4 loss: 0.539305  [  160/  306]
train() client id: f_00004-9-5 loss: 0.546963  [  192/  306]
train() client id: f_00004-9-6 loss: 0.609855  [  224/  306]
train() client id: f_00004-9-7 loss: 0.494725  [  256/  306]
train() client id: f_00004-9-8 loss: 0.592327  [  288/  306]
train() client id: f_00004-10-0 loss: 0.567962  [   32/  306]
train() client id: f_00004-10-1 loss: 0.498968  [   64/  306]
train() client id: f_00004-10-2 loss: 0.433307  [   96/  306]
train() client id: f_00004-10-3 loss: 0.537475  [  128/  306]
train() client id: f_00004-10-4 loss: 0.556665  [  160/  306]
train() client id: f_00004-10-5 loss: 0.607097  [  192/  306]
train() client id: f_00004-10-6 loss: 0.622234  [  224/  306]
train() client id: f_00004-10-7 loss: 0.564827  [  256/  306]
train() client id: f_00004-10-8 loss: 0.520039  [  288/  306]
train() client id: f_00004-11-0 loss: 0.598560  [   32/  306]
train() client id: f_00004-11-1 loss: 0.441373  [   64/  306]
train() client id: f_00004-11-2 loss: 0.441252  [   96/  306]
train() client id: f_00004-11-3 loss: 0.598015  [  128/  306]
train() client id: f_00004-11-4 loss: 0.640094  [  160/  306]
train() client id: f_00004-11-5 loss: 0.538915  [  192/  306]
train() client id: f_00004-11-6 loss: 0.436652  [  224/  306]
train() client id: f_00004-11-7 loss: 0.673885  [  256/  306]
train() client id: f_00004-11-8 loss: 0.478321  [  288/  306]
train() client id: f_00004-12-0 loss: 0.475155  [   32/  306]
train() client id: f_00004-12-1 loss: 0.537983  [   64/  306]
train() client id: f_00004-12-2 loss: 0.610313  [   96/  306]
train() client id: f_00004-12-3 loss: 0.560453  [  128/  306]
train() client id: f_00004-12-4 loss: 0.535236  [  160/  306]
train() client id: f_00004-12-5 loss: 0.570583  [  192/  306]
train() client id: f_00004-12-6 loss: 0.567292  [  224/  306]
train() client id: f_00004-12-7 loss: 0.513172  [  256/  306]
train() client id: f_00004-12-8 loss: 0.541087  [  288/  306]
train() client id: f_00005-0-0 loss: 0.528268  [   32/  146]
train() client id: f_00005-0-1 loss: 0.439578  [   64/  146]
train() client id: f_00005-0-2 loss: 0.395312  [   96/  146]
train() client id: f_00005-0-3 loss: 0.384056  [  128/  146]
train() client id: f_00005-1-0 loss: 0.548144  [   32/  146]
train() client id: f_00005-1-1 loss: 0.399210  [   64/  146]
train() client id: f_00005-1-2 loss: 0.366571  [   96/  146]
train() client id: f_00005-1-3 loss: 0.283140  [  128/  146]
train() client id: f_00005-2-0 loss: 0.184039  [   32/  146]
train() client id: f_00005-2-1 loss: 0.740824  [   64/  146]
train() client id: f_00005-2-2 loss: 0.391467  [   96/  146]
train() client id: f_00005-2-3 loss: 0.451492  [  128/  146]
train() client id: f_00005-3-0 loss: 0.526899  [   32/  146]
train() client id: f_00005-3-1 loss: 0.402116  [   64/  146]
train() client id: f_00005-3-2 loss: 0.462995  [   96/  146]
train() client id: f_00005-3-3 loss: 0.248969  [  128/  146]
train() client id: f_00005-4-0 loss: 0.358560  [   32/  146]
train() client id: f_00005-4-1 loss: 0.523308  [   64/  146]
train() client id: f_00005-4-2 loss: 0.274168  [   96/  146]
train() client id: f_00005-4-3 loss: 0.503749  [  128/  146]
train() client id: f_00005-5-0 loss: 0.295494  [   32/  146]
train() client id: f_00005-5-1 loss: 0.550152  [   64/  146]
train() client id: f_00005-5-2 loss: 0.550972  [   96/  146]
train() client id: f_00005-5-3 loss: 0.394166  [  128/  146]
train() client id: f_00005-6-0 loss: 0.339875  [   32/  146]
train() client id: f_00005-6-1 loss: 0.522446  [   64/  146]
train() client id: f_00005-6-2 loss: 0.647488  [   96/  146]
train() client id: f_00005-6-3 loss: 0.242328  [  128/  146]
train() client id: f_00005-7-0 loss: 0.625546  [   32/  146]
train() client id: f_00005-7-1 loss: 0.181671  [   64/  146]
train() client id: f_00005-7-2 loss: 0.229954  [   96/  146]
train() client id: f_00005-7-3 loss: 0.749973  [  128/  146]
train() client id: f_00005-8-0 loss: 0.481654  [   32/  146]
train() client id: f_00005-8-1 loss: 0.161268  [   64/  146]
train() client id: f_00005-8-2 loss: 0.470430  [   96/  146]
train() client id: f_00005-8-3 loss: 0.305087  [  128/  146]
train() client id: f_00005-9-0 loss: 0.846483  [   32/  146]
train() client id: f_00005-9-1 loss: 0.220957  [   64/  146]
train() client id: f_00005-9-2 loss: 0.503157  [   96/  146]
train() client id: f_00005-9-3 loss: 0.313645  [  128/  146]
train() client id: f_00005-10-0 loss: 0.456932  [   32/  146]
train() client id: f_00005-10-1 loss: 0.525970  [   64/  146]
train() client id: f_00005-10-2 loss: 0.582925  [   96/  146]
train() client id: f_00005-10-3 loss: 0.289830  [  128/  146]
train() client id: f_00005-11-0 loss: 0.522774  [   32/  146]
train() client id: f_00005-11-1 loss: 0.574318  [   64/  146]
train() client id: f_00005-11-2 loss: 0.353495  [   96/  146]
train() client id: f_00005-11-3 loss: 0.290297  [  128/  146]
train() client id: f_00005-12-0 loss: 0.292431  [   32/  146]
train() client id: f_00005-12-1 loss: 0.415814  [   64/  146]
train() client id: f_00005-12-2 loss: 0.454824  [   96/  146]
train() client id: f_00005-12-3 loss: 0.590376  [  128/  146]
train() client id: f_00006-0-0 loss: 0.561934  [   32/   54]
train() client id: f_00006-1-0 loss: 0.496340  [   32/   54]
train() client id: f_00006-2-0 loss: 0.539092  [   32/   54]
train() client id: f_00006-3-0 loss: 0.601731  [   32/   54]
train() client id: f_00006-4-0 loss: 0.539693  [   32/   54]
train() client id: f_00006-5-0 loss: 0.559569  [   32/   54]
train() client id: f_00006-6-0 loss: 0.598137  [   32/   54]
train() client id: f_00006-7-0 loss: 0.575696  [   32/   54]
train() client id: f_00006-8-0 loss: 0.581117  [   32/   54]
train() client id: f_00006-9-0 loss: 0.520448  [   32/   54]
train() client id: f_00006-10-0 loss: 0.590641  [   32/   54]
train() client id: f_00006-11-0 loss: 0.558092  [   32/   54]
train() client id: f_00006-12-0 loss: 0.579383  [   32/   54]
train() client id: f_00007-0-0 loss: 0.549674  [   32/  179]
train() client id: f_00007-0-1 loss: 0.663715  [   64/  179]
train() client id: f_00007-0-2 loss: 0.608139  [   96/  179]
train() client id: f_00007-0-3 loss: 0.727753  [  128/  179]
train() client id: f_00007-0-4 loss: 0.455733  [  160/  179]
train() client id: f_00007-1-0 loss: 0.599472  [   32/  179]
train() client id: f_00007-1-1 loss: 0.511854  [   64/  179]
train() client id: f_00007-1-2 loss: 0.519190  [   96/  179]
train() client id: f_00007-1-3 loss: 0.607521  [  128/  179]
train() client id: f_00007-1-4 loss: 0.656891  [  160/  179]
train() client id: f_00007-2-0 loss: 0.521723  [   32/  179]
train() client id: f_00007-2-1 loss: 0.574544  [   64/  179]
train() client id: f_00007-2-2 loss: 0.743848  [   96/  179]
train() client id: f_00007-2-3 loss: 0.525218  [  128/  179]
train() client id: f_00007-2-4 loss: 0.511402  [  160/  179]
train() client id: f_00007-3-0 loss: 0.560433  [   32/  179]
train() client id: f_00007-3-1 loss: 0.684236  [   64/  179]
train() client id: f_00007-3-2 loss: 0.394120  [   96/  179]
train() client id: f_00007-3-3 loss: 0.496100  [  128/  179]
train() client id: f_00007-3-4 loss: 0.471005  [  160/  179]
train() client id: f_00007-4-0 loss: 0.436843  [   32/  179]
train() client id: f_00007-4-1 loss: 0.474265  [   64/  179]
train() client id: f_00007-4-2 loss: 0.605389  [   96/  179]
train() client id: f_00007-4-3 loss: 0.469058  [  128/  179]
train() client id: f_00007-4-4 loss: 0.665372  [  160/  179]
train() client id: f_00007-5-0 loss: 0.406035  [   32/  179]
train() client id: f_00007-5-1 loss: 0.583465  [   64/  179]
train() client id: f_00007-5-2 loss: 0.485820  [   96/  179]
train() client id: f_00007-5-3 loss: 0.501127  [  128/  179]
train() client id: f_00007-5-4 loss: 0.658234  [  160/  179]
train() client id: f_00007-6-0 loss: 0.370077  [   32/  179]
train() client id: f_00007-6-1 loss: 0.563853  [   64/  179]
train() client id: f_00007-6-2 loss: 0.666777  [   96/  179]
train() client id: f_00007-6-3 loss: 0.375248  [  128/  179]
train() client id: f_00007-6-4 loss: 0.616694  [  160/  179]
train() client id: f_00007-7-0 loss: 0.471233  [   32/  179]
train() client id: f_00007-7-1 loss: 0.611266  [   64/  179]
train() client id: f_00007-7-2 loss: 0.488664  [   96/  179]
train() client id: f_00007-7-3 loss: 0.536832  [  128/  179]
train() client id: f_00007-7-4 loss: 0.544522  [  160/  179]
train() client id: f_00007-8-0 loss: 0.485043  [   32/  179]
train() client id: f_00007-8-1 loss: 0.364234  [   64/  179]
train() client id: f_00007-8-2 loss: 0.506497  [   96/  179]
train() client id: f_00007-8-3 loss: 0.453377  [  128/  179]
train() client id: f_00007-8-4 loss: 0.657533  [  160/  179]
train() client id: f_00007-9-0 loss: 0.592996  [   32/  179]
train() client id: f_00007-9-1 loss: 0.540152  [   64/  179]
train() client id: f_00007-9-2 loss: 0.476627  [   96/  179]
train() client id: f_00007-9-3 loss: 0.596545  [  128/  179]
train() client id: f_00007-9-4 loss: 0.416408  [  160/  179]
train() client id: f_00007-10-0 loss: 0.582481  [   32/  179]
train() client id: f_00007-10-1 loss: 0.532272  [   64/  179]
train() client id: f_00007-10-2 loss: 0.356727  [   96/  179]
train() client id: f_00007-10-3 loss: 0.461822  [  128/  179]
train() client id: f_00007-10-4 loss: 0.601395  [  160/  179]
train() client id: f_00007-11-0 loss: 0.435847  [   32/  179]
train() client id: f_00007-11-1 loss: 0.712407  [   64/  179]
train() client id: f_00007-11-2 loss: 0.432239  [   96/  179]
train() client id: f_00007-11-3 loss: 0.665921  [  128/  179]
train() client id: f_00007-11-4 loss: 0.350132  [  160/  179]
train() client id: f_00007-12-0 loss: 0.529964  [   32/  179]
train() client id: f_00007-12-1 loss: 0.460769  [   64/  179]
train() client id: f_00007-12-2 loss: 0.438608  [   96/  179]
train() client id: f_00007-12-3 loss: 0.551103  [  128/  179]
train() client id: f_00007-12-4 loss: 0.556258  [  160/  179]
train() client id: f_00008-0-0 loss: 0.709780  [   32/  130]
train() client id: f_00008-0-1 loss: 0.894571  [   64/  130]
train() client id: f_00008-0-2 loss: 0.854185  [   96/  130]
train() client id: f_00008-0-3 loss: 0.844627  [  128/  130]
train() client id: f_00008-1-0 loss: 0.850916  [   32/  130]
train() client id: f_00008-1-1 loss: 0.770456  [   64/  130]
train() client id: f_00008-1-2 loss: 0.791051  [   96/  130]
train() client id: f_00008-1-3 loss: 0.900711  [  128/  130]
train() client id: f_00008-2-0 loss: 0.812539  [   32/  130]
train() client id: f_00008-2-1 loss: 0.920157  [   64/  130]
train() client id: f_00008-2-2 loss: 0.902330  [   96/  130]
train() client id: f_00008-2-3 loss: 0.683052  [  128/  130]
train() client id: f_00008-3-0 loss: 0.871112  [   32/  130]
train() client id: f_00008-3-1 loss: 0.927836  [   64/  130]
train() client id: f_00008-3-2 loss: 0.716712  [   96/  130]
train() client id: f_00008-3-3 loss: 0.788275  [  128/  130]
train() client id: f_00008-4-0 loss: 0.959584  [   32/  130]
train() client id: f_00008-4-1 loss: 0.741613  [   64/  130]
train() client id: f_00008-4-2 loss: 0.788171  [   96/  130]
train() client id: f_00008-4-3 loss: 0.795869  [  128/  130]
train() client id: f_00008-5-0 loss: 0.828508  [   32/  130]
train() client id: f_00008-5-1 loss: 0.854715  [   64/  130]
train() client id: f_00008-5-2 loss: 0.802170  [   96/  130]
train() client id: f_00008-5-3 loss: 0.850280  [  128/  130]
train() client id: f_00008-6-0 loss: 0.791176  [   32/  130]
train() client id: f_00008-6-1 loss: 0.798148  [   64/  130]
train() client id: f_00008-6-2 loss: 0.778992  [   96/  130]
train() client id: f_00008-6-3 loss: 0.923702  [  128/  130]
train() client id: f_00008-7-0 loss: 0.811794  [   32/  130]
train() client id: f_00008-7-1 loss: 0.815655  [   64/  130]
train() client id: f_00008-7-2 loss: 0.867430  [   96/  130]
train() client id: f_00008-7-3 loss: 0.826039  [  128/  130]
train() client id: f_00008-8-0 loss: 0.833362  [   32/  130]
train() client id: f_00008-8-1 loss: 0.798419  [   64/  130]
train() client id: f_00008-8-2 loss: 0.839667  [   96/  130]
train() client id: f_00008-8-3 loss: 0.855454  [  128/  130]
train() client id: f_00008-9-0 loss: 0.758266  [   32/  130]
train() client id: f_00008-9-1 loss: 0.897067  [   64/  130]
train() client id: f_00008-9-2 loss: 0.845433  [   96/  130]
train() client id: f_00008-9-3 loss: 0.833196  [  128/  130]
train() client id: f_00008-10-0 loss: 0.800354  [   32/  130]
train() client id: f_00008-10-1 loss: 0.990046  [   64/  130]
train() client id: f_00008-10-2 loss: 0.697714  [   96/  130]
train() client id: f_00008-10-3 loss: 0.838342  [  128/  130]
train() client id: f_00008-11-0 loss: 0.828671  [   32/  130]
train() client id: f_00008-11-1 loss: 0.688120  [   64/  130]
train() client id: f_00008-11-2 loss: 0.821874  [   96/  130]
train() client id: f_00008-11-3 loss: 0.997348  [  128/  130]
train() client id: f_00008-12-0 loss: 0.814906  [   32/  130]
train() client id: f_00008-12-1 loss: 0.762259  [   64/  130]
train() client id: f_00008-12-2 loss: 0.930831  [   96/  130]
train() client id: f_00008-12-3 loss: 0.825727  [  128/  130]
train() client id: f_00009-0-0 loss: 1.094804  [   32/  118]
train() client id: f_00009-0-1 loss: 1.211290  [   64/  118]
train() client id: f_00009-0-2 loss: 1.214869  [   96/  118]
train() client id: f_00009-1-0 loss: 1.160562  [   32/  118]
train() client id: f_00009-1-1 loss: 1.127049  [   64/  118]
train() client id: f_00009-1-2 loss: 1.136041  [   96/  118]
train() client id: f_00009-2-0 loss: 1.064323  [   32/  118]
train() client id: f_00009-2-1 loss: 1.104756  [   64/  118]
train() client id: f_00009-2-2 loss: 1.141099  [   96/  118]
train() client id: f_00009-3-0 loss: 1.052129  [   32/  118]
train() client id: f_00009-3-1 loss: 0.900551  [   64/  118]
train() client id: f_00009-3-2 loss: 1.083803  [   96/  118]
train() client id: f_00009-4-0 loss: 1.035943  [   32/  118]
train() client id: f_00009-4-1 loss: 1.098127  [   64/  118]
train() client id: f_00009-4-2 loss: 0.953303  [   96/  118]
train() client id: f_00009-5-0 loss: 0.998899  [   32/  118]
train() client id: f_00009-5-1 loss: 0.910984  [   64/  118]
train() client id: f_00009-5-2 loss: 0.928638  [   96/  118]
train() client id: f_00009-6-0 loss: 0.976794  [   32/  118]
train() client id: f_00009-6-1 loss: 0.977429  [   64/  118]
train() client id: f_00009-6-2 loss: 0.963408  [   96/  118]
train() client id: f_00009-7-0 loss: 0.948739  [   32/  118]
train() client id: f_00009-7-1 loss: 0.937651  [   64/  118]
train() client id: f_00009-7-2 loss: 1.012902  [   96/  118]
train() client id: f_00009-8-0 loss: 0.938313  [   32/  118]
train() client id: f_00009-8-1 loss: 0.893179  [   64/  118]
train() client id: f_00009-8-2 loss: 0.809503  [   96/  118]
train() client id: f_00009-9-0 loss: 0.935157  [   32/  118]
train() client id: f_00009-9-1 loss: 0.909663  [   64/  118]
train() client id: f_00009-9-2 loss: 0.889192  [   96/  118]
train() client id: f_00009-10-0 loss: 0.994159  [   32/  118]
train() client id: f_00009-10-1 loss: 1.012509  [   64/  118]
train() client id: f_00009-10-2 loss: 0.768354  [   96/  118]
train() client id: f_00009-11-0 loss: 0.944353  [   32/  118]
train() client id: f_00009-11-1 loss: 0.894484  [   64/  118]
train() client id: f_00009-11-2 loss: 0.898849  [   96/  118]
train() client id: f_00009-12-0 loss: 0.983701  [   32/  118]
train() client id: f_00009-12-1 loss: 0.854990  [   64/  118]
train() client id: f_00009-12-2 loss: 0.798921  [   96/  118]
At round 32 accuracy: 0.6419098143236074
At round 32 training accuracy: 0.5801475519785378
At round 32 training loss: 0.8415551972424533
gradient difference: 0.44490885734558105
train() client id: f_00000-0-0 loss: 0.984054  [   32/  126]
train() client id: f_00000-0-1 loss: 1.438725  [   64/  126]
train() client id: f_00000-0-2 loss: 1.041391  [   96/  126]
train() client id: f_00000-1-0 loss: 1.187515  [   32/  126]
train() client id: f_00000-1-1 loss: 1.203533  [   64/  126]
train() client id: f_00000-1-2 loss: 1.135278  [   96/  126]
train() client id: f_00000-2-0 loss: 1.173687  [   32/  126]
train() client id: f_00000-2-1 loss: 1.013430  [   64/  126]
train() client id: f_00000-2-2 loss: 0.922091  [   96/  126]
train() client id: f_00000-3-0 loss: 1.120386  [   32/  126]
train() client id: f_00000-3-1 loss: 0.887112  [   64/  126]
train() client id: f_00000-3-2 loss: 1.051313  [   96/  126]
train() client id: f_00000-4-0 loss: 1.017569  [   32/  126]
train() client id: f_00000-4-1 loss: 0.999465  [   64/  126]
train() client id: f_00000-4-2 loss: 0.917113  [   96/  126]
train() client id: f_00000-5-0 loss: 0.814332  [   32/  126]
train() client id: f_00000-5-1 loss: 1.135405  [   64/  126]
train() client id: f_00000-5-2 loss: 0.868022  [   96/  126]
train() client id: f_00000-6-0 loss: 0.907593  [   32/  126]
train() client id: f_00000-6-1 loss: 1.044700  [   64/  126]
train() client id: f_00000-6-2 loss: 0.863023  [   96/  126]
train() client id: f_00000-7-0 loss: 0.880930  [   32/  126]
train() client id: f_00000-7-1 loss: 0.951221  [   64/  126]
train() client id: f_00000-7-2 loss: 0.840636  [   96/  126]
train() client id: f_00000-8-0 loss: 0.759127  [   32/  126]
train() client id: f_00000-8-1 loss: 0.926363  [   64/  126]
train() client id: f_00000-8-2 loss: 0.884001  [   96/  126]
train() client id: f_00000-9-0 loss: 0.920256  [   32/  126]
train() client id: f_00000-9-1 loss: 0.803359  [   64/  126]
train() client id: f_00000-9-2 loss: 0.810805  [   96/  126]
train() client id: f_00000-10-0 loss: 0.864765  [   32/  126]
train() client id: f_00000-10-1 loss: 0.923612  [   64/  126]
train() client id: f_00000-10-2 loss: 0.906206  [   96/  126]
train() client id: f_00000-11-0 loss: 0.925804  [   32/  126]
train() client id: f_00000-11-1 loss: 0.990069  [   64/  126]
train() client id: f_00000-11-2 loss: 0.825460  [   96/  126]
train() client id: f_00000-12-0 loss: 0.883228  [   32/  126]
train() client id: f_00000-12-1 loss: 0.940733  [   64/  126]
train() client id: f_00000-12-2 loss: 0.802228  [   96/  126]
train() client id: f_00001-0-0 loss: 0.575706  [   32/  265]
train() client id: f_00001-0-1 loss: 0.429573  [   64/  265]
train() client id: f_00001-0-2 loss: 0.510805  [   96/  265]
train() client id: f_00001-0-3 loss: 0.500459  [  128/  265]
train() client id: f_00001-0-4 loss: 0.622340  [  160/  265]
train() client id: f_00001-0-5 loss: 0.520019  [  192/  265]
train() client id: f_00001-0-6 loss: 0.447231  [  224/  265]
train() client id: f_00001-0-7 loss: 0.515923  [  256/  265]
train() client id: f_00001-1-0 loss: 0.455234  [   32/  265]
train() client id: f_00001-1-1 loss: 0.670975  [   64/  265]
train() client id: f_00001-1-2 loss: 0.424915  [   96/  265]
train() client id: f_00001-1-3 loss: 0.419676  [  128/  265]
train() client id: f_00001-1-4 loss: 0.569425  [  160/  265]
train() client id: f_00001-1-5 loss: 0.412748  [  192/  265]
train() client id: f_00001-1-6 loss: 0.523214  [  224/  265]
train() client id: f_00001-1-7 loss: 0.558707  [  256/  265]
train() client id: f_00001-2-0 loss: 0.437729  [   32/  265]
train() client id: f_00001-2-1 loss: 0.485278  [   64/  265]
train() client id: f_00001-2-2 loss: 0.495778  [   96/  265]
train() client id: f_00001-2-3 loss: 0.511730  [  128/  265]
train() client id: f_00001-2-4 loss: 0.528387  [  160/  265]
train() client id: f_00001-2-5 loss: 0.543127  [  192/  265]
train() client id: f_00001-2-6 loss: 0.492975  [  224/  265]
train() client id: f_00001-2-7 loss: 0.551982  [  256/  265]
train() client id: f_00001-3-0 loss: 0.497203  [   32/  265]
train() client id: f_00001-3-1 loss: 0.426270  [   64/  265]
train() client id: f_00001-3-2 loss: 0.529740  [   96/  265]
train() client id: f_00001-3-3 loss: 0.540385  [  128/  265]
train() client id: f_00001-3-4 loss: 0.527267  [  160/  265]
train() client id: f_00001-3-5 loss: 0.553065  [  192/  265]
train() client id: f_00001-3-6 loss: 0.450171  [  224/  265]
train() client id: f_00001-3-7 loss: 0.466347  [  256/  265]
train() client id: f_00001-4-0 loss: 0.626942  [   32/  265]
train() client id: f_00001-4-1 loss: 0.484094  [   64/  265]
train() client id: f_00001-4-2 loss: 0.435491  [   96/  265]
train() client id: f_00001-4-3 loss: 0.488890  [  128/  265]
train() client id: f_00001-4-4 loss: 0.543822  [  160/  265]
train() client id: f_00001-4-5 loss: 0.435294  [  192/  265]
train() client id: f_00001-4-6 loss: 0.497023  [  224/  265]
train() client id: f_00001-4-7 loss: 0.409989  [  256/  265]
train() client id: f_00001-5-0 loss: 0.429179  [   32/  265]
train() client id: f_00001-5-1 loss: 0.403917  [   64/  265]
train() client id: f_00001-5-2 loss: 0.403269  [   96/  265]
train() client id: f_00001-5-3 loss: 0.529537  [  128/  265]
train() client id: f_00001-5-4 loss: 0.440897  [  160/  265]
train() client id: f_00001-5-5 loss: 0.763023  [  192/  265]
train() client id: f_00001-5-6 loss: 0.517453  [  224/  265]
train() client id: f_00001-5-7 loss: 0.480577  [  256/  265]
train() client id: f_00001-6-0 loss: 0.404924  [   32/  265]
train() client id: f_00001-6-1 loss: 0.450667  [   64/  265]
train() client id: f_00001-6-2 loss: 0.464161  [   96/  265]
train() client id: f_00001-6-3 loss: 0.503999  [  128/  265]
train() client id: f_00001-6-4 loss: 0.613644  [  160/  265]
train() client id: f_00001-6-5 loss: 0.540829  [  192/  265]
train() client id: f_00001-6-6 loss: 0.404565  [  224/  265]
train() client id: f_00001-6-7 loss: 0.555886  [  256/  265]
train() client id: f_00001-7-0 loss: 0.572333  [   32/  265]
train() client id: f_00001-7-1 loss: 0.417278  [   64/  265]
train() client id: f_00001-7-2 loss: 0.479833  [   96/  265]
train() client id: f_00001-7-3 loss: 0.589869  [  128/  265]
train() client id: f_00001-7-4 loss: 0.562744  [  160/  265]
train() client id: f_00001-7-5 loss: 0.494981  [  192/  265]
train() client id: f_00001-7-6 loss: 0.389120  [  224/  265]
train() client id: f_00001-7-7 loss: 0.431976  [  256/  265]
train() client id: f_00001-8-0 loss: 0.610628  [   32/  265]
train() client id: f_00001-8-1 loss: 0.388449  [   64/  265]
train() client id: f_00001-8-2 loss: 0.436499  [   96/  265]
train() client id: f_00001-8-3 loss: 0.380190  [  128/  265]
train() client id: f_00001-8-4 loss: 0.518770  [  160/  265]
train() client id: f_00001-8-5 loss: 0.526488  [  192/  265]
train() client id: f_00001-8-6 loss: 0.572707  [  224/  265]
train() client id: f_00001-8-7 loss: 0.500840  [  256/  265]
train() client id: f_00001-9-0 loss: 0.570978  [   32/  265]
train() client id: f_00001-9-1 loss: 0.476019  [   64/  265]
train() client id: f_00001-9-2 loss: 0.492187  [   96/  265]
train() client id: f_00001-9-3 loss: 0.439505  [  128/  265]
train() client id: f_00001-9-4 loss: 0.477921  [  160/  265]
train() client id: f_00001-9-5 loss: 0.376541  [  192/  265]
train() client id: f_00001-9-6 loss: 0.547507  [  224/  265]
train() client id: f_00001-9-7 loss: 0.554624  [  256/  265]
train() client id: f_00001-10-0 loss: 0.518419  [   32/  265]
train() client id: f_00001-10-1 loss: 0.422958  [   64/  265]
train() client id: f_00001-10-2 loss: 0.423705  [   96/  265]
train() client id: f_00001-10-3 loss: 0.553547  [  128/  265]
train() client id: f_00001-10-4 loss: 0.427594  [  160/  265]
train() client id: f_00001-10-5 loss: 0.536725  [  192/  265]
train() client id: f_00001-10-6 loss: 0.536480  [  224/  265]
train() client id: f_00001-10-7 loss: 0.524838  [  256/  265]
train() client id: f_00001-11-0 loss: 0.442914  [   32/  265]
train() client id: f_00001-11-1 loss: 0.456497  [   64/  265]
train() client id: f_00001-11-2 loss: 0.473913  [   96/  265]
train() client id: f_00001-11-3 loss: 0.472012  [  128/  265]
train() client id: f_00001-11-4 loss: 0.462113  [  160/  265]
train() client id: f_00001-11-5 loss: 0.400966  [  192/  265]
train() client id: f_00001-11-6 loss: 0.408302  [  224/  265]
train() client id: f_00001-11-7 loss: 0.662250  [  256/  265]
train() client id: f_00001-12-0 loss: 0.647194  [   32/  265]
train() client id: f_00001-12-1 loss: 0.386087  [   64/  265]
train() client id: f_00001-12-2 loss: 0.551851  [   96/  265]
train() client id: f_00001-12-3 loss: 0.409415  [  128/  265]
train() client id: f_00001-12-4 loss: 0.496183  [  160/  265]
train() client id: f_00001-12-5 loss: 0.464752  [  192/  265]
train() client id: f_00001-12-6 loss: 0.564088  [  224/  265]
train() client id: f_00001-12-7 loss: 0.388559  [  256/  265]
train() client id: f_00002-0-0 loss: 1.128160  [   32/  124]
train() client id: f_00002-0-1 loss: 1.131708  [   64/  124]
train() client id: f_00002-0-2 loss: 0.951681  [   96/  124]
train() client id: f_00002-1-0 loss: 0.897568  [   32/  124]
train() client id: f_00002-1-1 loss: 0.930300  [   64/  124]
train() client id: f_00002-1-2 loss: 1.079656  [   96/  124]
train() client id: f_00002-2-0 loss: 1.095816  [   32/  124]
train() client id: f_00002-2-1 loss: 0.941570  [   64/  124]
train() client id: f_00002-2-2 loss: 0.852622  [   96/  124]
train() client id: f_00002-3-0 loss: 1.046860  [   32/  124]
train() client id: f_00002-3-1 loss: 0.859968  [   64/  124]
train() client id: f_00002-3-2 loss: 0.944463  [   96/  124]
train() client id: f_00002-4-0 loss: 0.952815  [   32/  124]
train() client id: f_00002-4-1 loss: 0.895743  [   64/  124]
train() client id: f_00002-4-2 loss: 1.004426  [   96/  124]
train() client id: f_00002-5-0 loss: 0.934430  [   32/  124]
train() client id: f_00002-5-1 loss: 0.964178  [   64/  124]
train() client id: f_00002-5-2 loss: 0.911885  [   96/  124]
train() client id: f_00002-6-0 loss: 0.831576  [   32/  124]
train() client id: f_00002-6-1 loss: 1.014981  [   64/  124]
train() client id: f_00002-6-2 loss: 0.837905  [   96/  124]
train() client id: f_00002-7-0 loss: 0.748114  [   32/  124]
train() client id: f_00002-7-1 loss: 0.778731  [   64/  124]
train() client id: f_00002-7-2 loss: 1.031116  [   96/  124]
train() client id: f_00002-8-0 loss: 0.833705  [   32/  124]
train() client id: f_00002-8-1 loss: 0.820295  [   64/  124]
train() client id: f_00002-8-2 loss: 0.961449  [   96/  124]
train() client id: f_00002-9-0 loss: 0.767918  [   32/  124]
train() client id: f_00002-9-1 loss: 0.839190  [   64/  124]
train() client id: f_00002-9-2 loss: 0.898973  [   96/  124]
train() client id: f_00002-10-0 loss: 0.996118  [   32/  124]
train() client id: f_00002-10-1 loss: 0.785697  [   64/  124]
train() client id: f_00002-10-2 loss: 0.846099  [   96/  124]
train() client id: f_00002-11-0 loss: 0.904194  [   32/  124]
train() client id: f_00002-11-1 loss: 0.856278  [   64/  124]
train() client id: f_00002-11-2 loss: 0.884198  [   96/  124]
train() client id: f_00002-12-0 loss: 0.918531  [   32/  124]
train() client id: f_00002-12-1 loss: 0.688421  [   64/  124]
train() client id: f_00002-12-2 loss: 0.860216  [   96/  124]
train() client id: f_00003-0-0 loss: 0.789530  [   32/   43]
train() client id: f_00003-1-0 loss: 0.852332  [   32/   43]
train() client id: f_00003-2-0 loss: 0.776183  [   32/   43]
train() client id: f_00003-3-0 loss: 0.794781  [   32/   43]
train() client id: f_00003-4-0 loss: 0.623470  [   32/   43]
train() client id: f_00003-5-0 loss: 0.867167  [   32/   43]
train() client id: f_00003-6-0 loss: 0.740435  [   32/   43]
train() client id: f_00003-7-0 loss: 0.597627  [   32/   43]
train() client id: f_00003-8-0 loss: 0.780656  [   32/   43]
train() client id: f_00003-9-0 loss: 0.725229  [   32/   43]
train() client id: f_00003-10-0 loss: 0.704898  [   32/   43]
train() client id: f_00003-11-0 loss: 0.776561  [   32/   43]
train() client id: f_00003-12-0 loss: 0.704695  [   32/   43]
train() client id: f_00004-0-0 loss: 0.778196  [   32/  306]
train() client id: f_00004-0-1 loss: 0.795976  [   64/  306]
train() client id: f_00004-0-2 loss: 0.828058  [   96/  306]
train() client id: f_00004-0-3 loss: 1.055469  [  128/  306]
train() client id: f_00004-0-4 loss: 0.842803  [  160/  306]
train() client id: f_00004-0-5 loss: 0.872025  [  192/  306]
train() client id: f_00004-0-6 loss: 0.974807  [  224/  306]
train() client id: f_00004-0-7 loss: 0.849396  [  256/  306]
train() client id: f_00004-0-8 loss: 0.988257  [  288/  306]
train() client id: f_00004-1-0 loss: 1.049809  [   32/  306]
train() client id: f_00004-1-1 loss: 0.841790  [   64/  306]
train() client id: f_00004-1-2 loss: 0.861376  [   96/  306]
train() client id: f_00004-1-3 loss: 0.887465  [  128/  306]
train() client id: f_00004-1-4 loss: 0.811155  [  160/  306]
train() client id: f_00004-1-5 loss: 0.772095  [  192/  306]
train() client id: f_00004-1-6 loss: 0.822538  [  224/  306]
train() client id: f_00004-1-7 loss: 0.910418  [  256/  306]
train() client id: f_00004-1-8 loss: 0.968990  [  288/  306]
train() client id: f_00004-2-0 loss: 0.809864  [   32/  306]
train() client id: f_00004-2-1 loss: 0.824151  [   64/  306]
train() client id: f_00004-2-2 loss: 1.039048  [   96/  306]
train() client id: f_00004-2-3 loss: 0.848748  [  128/  306]
train() client id: f_00004-2-4 loss: 0.850301  [  160/  306]
train() client id: f_00004-2-5 loss: 0.993742  [  192/  306]
train() client id: f_00004-2-6 loss: 0.764753  [  224/  306]
train() client id: f_00004-2-7 loss: 0.788305  [  256/  306]
train() client id: f_00004-2-8 loss: 0.931846  [  288/  306]
train() client id: f_00004-3-0 loss: 0.893497  [   32/  306]
train() client id: f_00004-3-1 loss: 0.984799  [   64/  306]
train() client id: f_00004-3-2 loss: 0.781968  [   96/  306]
train() client id: f_00004-3-3 loss: 0.848590  [  128/  306]
train() client id: f_00004-3-4 loss: 1.053058  [  160/  306]
train() client id: f_00004-3-5 loss: 0.886767  [  192/  306]
train() client id: f_00004-3-6 loss: 0.797436  [  224/  306]
train() client id: f_00004-3-7 loss: 0.902655  [  256/  306]
train() client id: f_00004-3-8 loss: 0.854035  [  288/  306]
train() client id: f_00004-4-0 loss: 0.893324  [   32/  306]
train() client id: f_00004-4-1 loss: 0.869722  [   64/  306]
train() client id: f_00004-4-2 loss: 0.831215  [   96/  306]
train() client id: f_00004-4-3 loss: 0.829445  [  128/  306]
train() client id: f_00004-4-4 loss: 0.936379  [  160/  306]
train() client id: f_00004-4-5 loss: 0.953649  [  192/  306]
train() client id: f_00004-4-6 loss: 0.896829  [  224/  306]
train() client id: f_00004-4-7 loss: 0.779194  [  256/  306]
train() client id: f_00004-4-8 loss: 0.885096  [  288/  306]
train() client id: f_00004-5-0 loss: 0.758454  [   32/  306]
train() client id: f_00004-5-1 loss: 0.868097  [   64/  306]
train() client id: f_00004-5-2 loss: 0.860143  [   96/  306]
train() client id: f_00004-5-3 loss: 1.034054  [  128/  306]
train() client id: f_00004-5-4 loss: 0.856451  [  160/  306]
train() client id: f_00004-5-5 loss: 0.894092  [  192/  306]
train() client id: f_00004-5-6 loss: 0.820180  [  224/  306]
train() client id: f_00004-5-7 loss: 0.967383  [  256/  306]
train() client id: f_00004-5-8 loss: 0.846387  [  288/  306]
train() client id: f_00004-6-0 loss: 0.879558  [   32/  306]
train() client id: f_00004-6-1 loss: 0.881527  [   64/  306]
train() client id: f_00004-6-2 loss: 0.871547  [   96/  306]
train() client id: f_00004-6-3 loss: 0.902265  [  128/  306]
train() client id: f_00004-6-4 loss: 0.782355  [  160/  306]
train() client id: f_00004-6-5 loss: 0.841517  [  192/  306]
train() client id: f_00004-6-6 loss: 0.851090  [  224/  306]
train() client id: f_00004-6-7 loss: 0.924600  [  256/  306]
train() client id: f_00004-6-8 loss: 0.986496  [  288/  306]
train() client id: f_00004-7-0 loss: 0.925373  [   32/  306]
train() client id: f_00004-7-1 loss: 0.870294  [   64/  306]
train() client id: f_00004-7-2 loss: 0.927160  [   96/  306]
train() client id: f_00004-7-3 loss: 0.893623  [  128/  306]
train() client id: f_00004-7-4 loss: 0.839083  [  160/  306]
train() client id: f_00004-7-5 loss: 0.896030  [  192/  306]
train() client id: f_00004-7-6 loss: 0.869924  [  224/  306]
train() client id: f_00004-7-7 loss: 0.928440  [  256/  306]
train() client id: f_00004-7-8 loss: 0.873157  [  288/  306]
train() client id: f_00004-8-0 loss: 0.916884  [   32/  306]
train() client id: f_00004-8-1 loss: 0.894615  [   64/  306]
train() client id: f_00004-8-2 loss: 0.865317  [   96/  306]
train() client id: f_00004-8-3 loss: 0.990654  [  128/  306]
train() client id: f_00004-8-4 loss: 0.899217  [  160/  306]
train() client id: f_00004-8-5 loss: 0.850898  [  192/  306]
train() client id: f_00004-8-6 loss: 0.877793  [  224/  306]
train() client id: f_00004-8-7 loss: 0.903518  [  256/  306]
train() client id: f_00004-8-8 loss: 0.748111  [  288/  306]
train() client id: f_00004-9-0 loss: 0.825542  [   32/  306]
train() client id: f_00004-9-1 loss: 0.849194  [   64/  306]
train() client id: f_00004-9-2 loss: 0.883843  [   96/  306]
train() client id: f_00004-9-3 loss: 0.990730  [  128/  306]
train() client id: f_00004-9-4 loss: 0.871915  [  160/  306]
train() client id: f_00004-9-5 loss: 0.917287  [  192/  306]
train() client id: f_00004-9-6 loss: 0.915311  [  224/  306]
train() client id: f_00004-9-7 loss: 0.744206  [  256/  306]
train() client id: f_00004-9-8 loss: 0.853678  [  288/  306]
train() client id: f_00004-10-0 loss: 0.926328  [   32/  306]
train() client id: f_00004-10-1 loss: 0.820634  [   64/  306]
train() client id: f_00004-10-2 loss: 1.027552  [   96/  306]
train() client id: f_00004-10-3 loss: 0.859785  [  128/  306]
train() client id: f_00004-10-4 loss: 0.875657  [  160/  306]
train() client id: f_00004-10-5 loss: 0.823129  [  192/  306]
train() client id: f_00004-10-6 loss: 0.992302  [  224/  306]
train() client id: f_00004-10-7 loss: 0.781614  [  256/  306]
train() client id: f_00004-10-8 loss: 0.828851  [  288/  306]
train() client id: f_00004-11-0 loss: 0.855454  [   32/  306]
train() client id: f_00004-11-1 loss: 0.914305  [   64/  306]
train() client id: f_00004-11-2 loss: 0.968642  [   96/  306]
train() client id: f_00004-11-3 loss: 0.859431  [  128/  306]
train() client id: f_00004-11-4 loss: 0.961342  [  160/  306]
train() client id: f_00004-11-5 loss: 0.843687  [  192/  306]
train() client id: f_00004-11-6 loss: 0.760548  [  224/  306]
train() client id: f_00004-11-7 loss: 0.821723  [  256/  306]
train() client id: f_00004-11-8 loss: 0.821991  [  288/  306]
train() client id: f_00004-12-0 loss: 0.852691  [   32/  306]
train() client id: f_00004-12-1 loss: 0.873866  [   64/  306]
train() client id: f_00004-12-2 loss: 0.919965  [   96/  306]
train() client id: f_00004-12-3 loss: 0.845780  [  128/  306]
train() client id: f_00004-12-4 loss: 0.863804  [  160/  306]
train() client id: f_00004-12-5 loss: 0.820186  [  192/  306]
train() client id: f_00004-12-6 loss: 0.846186  [  224/  306]
train() client id: f_00004-12-7 loss: 0.931763  [  256/  306]
train() client id: f_00004-12-8 loss: 0.910966  [  288/  306]
train() client id: f_00005-0-0 loss: 0.478278  [   32/  146]
train() client id: f_00005-0-1 loss: 0.573701  [   64/  146]
train() client id: f_00005-0-2 loss: 0.355980  [   96/  146]
train() client id: f_00005-0-3 loss: 0.562911  [  128/  146]
train() client id: f_00005-1-0 loss: 0.554198  [   32/  146]
train() client id: f_00005-1-1 loss: 0.544832  [   64/  146]
train() client id: f_00005-1-2 loss: 0.403449  [   96/  146]
train() client id: f_00005-1-3 loss: 0.544957  [  128/  146]
train() client id: f_00005-2-0 loss: 0.384578  [   32/  146]
train() client id: f_00005-2-1 loss: 0.415104  [   64/  146]
train() client id: f_00005-2-2 loss: 0.360207  [   96/  146]
train() client id: f_00005-2-3 loss: 0.687116  [  128/  146]
train() client id: f_00005-3-0 loss: 0.205288  [   32/  146]
train() client id: f_00005-3-1 loss: 0.399921  [   64/  146]
train() client id: f_00005-3-2 loss: 0.652448  [   96/  146]
train() client id: f_00005-3-3 loss: 0.445263  [  128/  146]
train() client id: f_00005-4-0 loss: 0.561201  [   32/  146]
train() client id: f_00005-4-1 loss: 0.403616  [   64/  146]
train() client id: f_00005-4-2 loss: 0.693558  [   96/  146]
train() client id: f_00005-4-3 loss: 0.275301  [  128/  146]
train() client id: f_00005-5-0 loss: 0.532387  [   32/  146]
train() client id: f_00005-5-1 loss: 0.568445  [   64/  146]
train() client id: f_00005-5-2 loss: 0.386648  [   96/  146]
train() client id: f_00005-5-3 loss: 0.409490  [  128/  146]
train() client id: f_00005-6-0 loss: 0.291479  [   32/  146]
train() client id: f_00005-6-1 loss: 0.562748  [   64/  146]
train() client id: f_00005-6-2 loss: 0.315682  [   96/  146]
train() client id: f_00005-6-3 loss: 0.366205  [  128/  146]
train() client id: f_00005-7-0 loss: 0.503202  [   32/  146]
train() client id: f_00005-7-1 loss: 0.783604  [   64/  146]
train() client id: f_00005-7-2 loss: 0.381854  [   96/  146]
train() client id: f_00005-7-3 loss: 0.173643  [  128/  146]
train() client id: f_00005-8-0 loss: 0.227810  [   32/  146]
train() client id: f_00005-8-1 loss: 0.548679  [   64/  146]
train() client id: f_00005-8-2 loss: 0.462767  [   96/  146]
train() client id: f_00005-8-3 loss: 0.682515  [  128/  146]
train() client id: f_00005-9-0 loss: 0.324522  [   32/  146]
train() client id: f_00005-9-1 loss: 0.723823  [   64/  146]
train() client id: f_00005-9-2 loss: 0.467227  [   96/  146]
train() client id: f_00005-9-3 loss: 0.399827  [  128/  146]
train() client id: f_00005-10-0 loss: 0.328834  [   32/  146]
train() client id: f_00005-10-1 loss: 0.561123  [   64/  146]
train() client id: f_00005-10-2 loss: 0.652908  [   96/  146]
train() client id: f_00005-10-3 loss: 0.331234  [  128/  146]
train() client id: f_00005-11-0 loss: 0.496951  [   32/  146]
train() client id: f_00005-11-1 loss: 0.435080  [   64/  146]
train() client id: f_00005-11-2 loss: 0.543708  [   96/  146]
train() client id: f_00005-11-3 loss: 0.245393  [  128/  146]
train() client id: f_00005-12-0 loss: 0.383202  [   32/  146]
train() client id: f_00005-12-1 loss: 0.474131  [   64/  146]
train() client id: f_00005-12-2 loss: 0.541624  [   96/  146]
train() client id: f_00005-12-3 loss: 0.495828  [  128/  146]
train() client id: f_00006-0-0 loss: 0.422403  [   32/   54]
train() client id: f_00006-1-0 loss: 0.517320  [   32/   54]
train() client id: f_00006-2-0 loss: 0.480982  [   32/   54]
train() client id: f_00006-3-0 loss: 0.530629  [   32/   54]
train() client id: f_00006-4-0 loss: 0.487433  [   32/   54]
train() client id: f_00006-5-0 loss: 0.519893  [   32/   54]
train() client id: f_00006-6-0 loss: 0.469219  [   32/   54]
train() client id: f_00006-7-0 loss: 0.515581  [   32/   54]
train() client id: f_00006-8-0 loss: 0.456507  [   32/   54]
train() client id: f_00006-9-0 loss: 0.533208  [   32/   54]
train() client id: f_00006-10-0 loss: 0.477461  [   32/   54]
train() client id: f_00006-11-0 loss: 0.513203  [   32/   54]
train() client id: f_00006-12-0 loss: 0.490544  [   32/   54]
train() client id: f_00007-0-0 loss: 0.552821  [   32/  179]
train() client id: f_00007-0-1 loss: 0.456348  [   64/  179]
train() client id: f_00007-0-2 loss: 0.501967  [   96/  179]
train() client id: f_00007-0-3 loss: 0.570013  [  128/  179]
train() client id: f_00007-0-4 loss: 0.525132  [  160/  179]
train() client id: f_00007-1-0 loss: 0.748675  [   32/  179]
train() client id: f_00007-1-1 loss: 0.583462  [   64/  179]
train() client id: f_00007-1-2 loss: 0.492687  [   96/  179]
train() client id: f_00007-1-3 loss: 0.505054  [  128/  179]
train() client id: f_00007-1-4 loss: 0.504948  [  160/  179]
train() client id: f_00007-2-0 loss: 0.464949  [   32/  179]
train() client id: f_00007-2-1 loss: 0.434180  [   64/  179]
train() client id: f_00007-2-2 loss: 0.528030  [   96/  179]
train() client id: f_00007-2-3 loss: 0.638072  [  128/  179]
train() client id: f_00007-2-4 loss: 0.605541  [  160/  179]
train() client id: f_00007-3-0 loss: 0.573233  [   32/  179]
train() client id: f_00007-3-1 loss: 0.748220  [   64/  179]
train() client id: f_00007-3-2 loss: 0.373744  [   96/  179]
train() client id: f_00007-3-3 loss: 0.436943  [  128/  179]
train() client id: f_00007-3-4 loss: 0.496862  [  160/  179]
train() client id: f_00007-4-0 loss: 0.392313  [   32/  179]
train() client id: f_00007-4-1 loss: 0.730178  [   64/  179]
train() client id: f_00007-4-2 loss: 0.624762  [   96/  179]
train() client id: f_00007-4-3 loss: 0.460398  [  128/  179]
train() client id: f_00007-4-4 loss: 0.528224  [  160/  179]
train() client id: f_00007-5-0 loss: 0.611523  [   32/  179]
train() client id: f_00007-5-1 loss: 0.395503  [   64/  179]
train() client id: f_00007-5-2 loss: 0.488416  [   96/  179]
train() client id: f_00007-5-3 loss: 0.624959  [  128/  179]
train() client id: f_00007-5-4 loss: 0.576912  [  160/  179]
train() client id: f_00007-6-0 loss: 0.562001  [   32/  179]
train() client id: f_00007-6-1 loss: 0.622803  [   64/  179]
train() client id: f_00007-6-2 loss: 0.382178  [   96/  179]
train() client id: f_00007-6-3 loss: 0.499330  [  128/  179]
train() client id: f_00007-6-4 loss: 0.617948  [  160/  179]
train() client id: f_00007-7-0 loss: 0.519677  [   32/  179]
train() client id: f_00007-7-1 loss: 0.393981  [   64/  179]
train() client id: f_00007-7-2 loss: 0.546880  [   96/  179]
train() client id: f_00007-7-3 loss: 0.466424  [  128/  179]
train() client id: f_00007-7-4 loss: 0.673763  [  160/  179]
train() client id: f_00007-8-0 loss: 0.440916  [   32/  179]
train() client id: f_00007-8-1 loss: 0.447902  [   64/  179]
train() client id: f_00007-8-2 loss: 0.853880  [   96/  179]
train() client id: f_00007-8-3 loss: 0.392362  [  128/  179]
train() client id: f_00007-8-4 loss: 0.582696  [  160/  179]
train() client id: f_00007-9-0 loss: 0.463307  [   32/  179]
train() client id: f_00007-9-1 loss: 0.560523  [   64/  179]
train() client id: f_00007-9-2 loss: 0.384672  [   96/  179]
train() client id: f_00007-9-3 loss: 0.473118  [  128/  179]
train() client id: f_00007-9-4 loss: 0.637561  [  160/  179]
train() client id: f_00007-10-0 loss: 0.450314  [   32/  179]
train() client id: f_00007-10-1 loss: 0.456210  [   64/  179]
train() client id: f_00007-10-2 loss: 0.458596  [   96/  179]
train() client id: f_00007-10-3 loss: 0.571055  [  128/  179]
train() client id: f_00007-10-4 loss: 0.562256  [  160/  179]
train() client id: f_00007-11-0 loss: 0.337819  [   32/  179]
train() client id: f_00007-11-1 loss: 0.680184  [   64/  179]
train() client id: f_00007-11-2 loss: 0.476377  [   96/  179]
train() client id: f_00007-11-3 loss: 0.491406  [  128/  179]
train() client id: f_00007-11-4 loss: 0.746681  [  160/  179]
train() client id: f_00007-12-0 loss: 0.480992  [   32/  179]
train() client id: f_00007-12-1 loss: 0.645390  [   64/  179]
train() client id: f_00007-12-2 loss: 0.594080  [   96/  179]
train() client id: f_00007-12-3 loss: 0.633332  [  128/  179]
train() client id: f_00007-12-4 loss: 0.342913  [  160/  179]
train() client id: f_00008-0-0 loss: 0.645080  [   32/  130]
train() client id: f_00008-0-1 loss: 0.853773  [   64/  130]
train() client id: f_00008-0-2 loss: 0.813353  [   96/  130]
train() client id: f_00008-0-3 loss: 0.653406  [  128/  130]
train() client id: f_00008-1-0 loss: 0.672761  [   32/  130]
train() client id: f_00008-1-1 loss: 0.820320  [   64/  130]
train() client id: f_00008-1-2 loss: 0.803410  [   96/  130]
train() client id: f_00008-1-3 loss: 0.677529  [  128/  130]
train() client id: f_00008-2-0 loss: 0.701941  [   32/  130]
train() client id: f_00008-2-1 loss: 0.737453  [   64/  130]
train() client id: f_00008-2-2 loss: 0.783009  [   96/  130]
train() client id: f_00008-2-3 loss: 0.780110  [  128/  130]
train() client id: f_00008-3-0 loss: 0.686854  [   32/  130]
train() client id: f_00008-3-1 loss: 0.749843  [   64/  130]
train() client id: f_00008-3-2 loss: 0.736918  [   96/  130]
train() client id: f_00008-3-3 loss: 0.813140  [  128/  130]
train() client id: f_00008-4-0 loss: 0.736999  [   32/  130]
train() client id: f_00008-4-1 loss: 0.795926  [   64/  130]
train() client id: f_00008-4-2 loss: 0.758136  [   96/  130]
train() client id: f_00008-4-3 loss: 0.705769  [  128/  130]
train() client id: f_00008-5-0 loss: 0.902869  [   32/  130]
train() client id: f_00008-5-1 loss: 0.712788  [   64/  130]
train() client id: f_00008-5-2 loss: 0.721934  [   96/  130]
train() client id: f_00008-5-3 loss: 0.666965  [  128/  130]
train() client id: f_00008-6-0 loss: 0.804127  [   32/  130]
train() client id: f_00008-6-1 loss: 0.715862  [   64/  130]
train() client id: f_00008-6-2 loss: 0.760595  [   96/  130]
train() client id: f_00008-6-3 loss: 0.713698  [  128/  130]
train() client id: f_00008-7-0 loss: 0.625192  [   32/  130]
train() client id: f_00008-7-1 loss: 0.824061  [   64/  130]
train() client id: f_00008-7-2 loss: 0.808727  [   96/  130]
train() client id: f_00008-7-3 loss: 0.710834  [  128/  130]
train() client id: f_00008-8-0 loss: 0.597367  [   32/  130]
train() client id: f_00008-8-1 loss: 0.801371  [   64/  130]
train() client id: f_00008-8-2 loss: 0.797806  [   96/  130]
train() client id: f_00008-8-3 loss: 0.783799  [  128/  130]
train() client id: f_00008-9-0 loss: 0.721208  [   32/  130]
train() client id: f_00008-9-1 loss: 0.790240  [   64/  130]
train() client id: f_00008-9-2 loss: 0.632574  [   96/  130]
train() client id: f_00008-9-3 loss: 0.836821  [  128/  130]
train() client id: f_00008-10-0 loss: 0.755354  [   32/  130]
train() client id: f_00008-10-1 loss: 0.764941  [   64/  130]
train() client id: f_00008-10-2 loss: 0.658790  [   96/  130]
train() client id: f_00008-10-3 loss: 0.772853  [  128/  130]
train() client id: f_00008-11-0 loss: 0.794791  [   32/  130]
train() client id: f_00008-11-1 loss: 0.702582  [   64/  130]
train() client id: f_00008-11-2 loss: 0.772035  [   96/  130]
train() client id: f_00008-11-3 loss: 0.702245  [  128/  130]
train() client id: f_00008-12-0 loss: 0.747974  [   32/  130]
train() client id: f_00008-12-1 loss: 0.740624  [   64/  130]
train() client id: f_00008-12-2 loss: 0.787514  [   96/  130]
train() client id: f_00008-12-3 loss: 0.698227  [  128/  130]
train() client id: f_00009-0-0 loss: 1.187357  [   32/  118]
train() client id: f_00009-0-1 loss: 0.959673  [   64/  118]
train() client id: f_00009-0-2 loss: 1.096148  [   96/  118]
train() client id: f_00009-1-0 loss: 1.119097  [   32/  118]
train() client id: f_00009-1-1 loss: 0.990918  [   64/  118]
train() client id: f_00009-1-2 loss: 1.013356  [   96/  118]
train() client id: f_00009-2-0 loss: 1.045999  [   32/  118]
train() client id: f_00009-2-1 loss: 0.972372  [   64/  118]
train() client id: f_00009-2-2 loss: 0.998586  [   96/  118]
train() client id: f_00009-3-0 loss: 1.032702  [   32/  118]
train() client id: f_00009-3-1 loss: 0.887390  [   64/  118]
train() client id: f_00009-3-2 loss: 0.946372  [   96/  118]
train() client id: f_00009-4-0 loss: 0.995302  [   32/  118]
train() client id: f_00009-4-1 loss: 0.886638  [   64/  118]
train() client id: f_00009-4-2 loss: 0.897050  [   96/  118]
train() client id: f_00009-5-0 loss: 0.990513  [   32/  118]
train() client id: f_00009-5-1 loss: 0.958052  [   64/  118]
train() client id: f_00009-5-2 loss: 0.944798  [   96/  118]
train() client id: f_00009-6-0 loss: 0.900145  [   32/  118]
train() client id: f_00009-6-1 loss: 0.847288  [   64/  118]
train() client id: f_00009-6-2 loss: 0.948219  [   96/  118]
train() client id: f_00009-7-0 loss: 0.935958  [   32/  118]
train() client id: f_00009-7-1 loss: 0.927055  [   64/  118]
train() client id: f_00009-7-2 loss: 0.931104  [   96/  118]
train() client id: f_00009-8-0 loss: 0.844202  [   32/  118]
train() client id: f_00009-8-1 loss: 0.950269  [   64/  118]
train() client id: f_00009-8-2 loss: 0.908297  [   96/  118]
train() client id: f_00009-9-0 loss: 0.937087  [   32/  118]
train() client id: f_00009-9-1 loss: 0.848283  [   64/  118]
train() client id: f_00009-9-2 loss: 0.956610  [   96/  118]
train() client id: f_00009-10-0 loss: 1.008457  [   32/  118]
train() client id: f_00009-10-1 loss: 0.974098  [   64/  118]
train() client id: f_00009-10-2 loss: 0.759519  [   96/  118]
train() client id: f_00009-11-0 loss: 0.863201  [   32/  118]
train() client id: f_00009-11-1 loss: 1.069053  [   64/  118]
train() client id: f_00009-11-2 loss: 0.781305  [   96/  118]
train() client id: f_00009-12-0 loss: 0.821599  [   32/  118]
train() client id: f_00009-12-1 loss: 0.893662  [   64/  118]
train() client id: f_00009-12-2 loss: 0.761821  [   96/  118]
At round 33 accuracy: 0.6445623342175066
At round 33 training accuracy: 0.5928906773977196
At round 33 training loss: 0.8156320909933074
gradient difference: 0.41151681542396545
train() client id: f_00000-0-0 loss: 1.129892  [   32/  126]
train() client id: f_00000-0-1 loss: 1.195492  [   64/  126]
train() client id: f_00000-0-2 loss: 1.287861  [   96/  126]
train() client id: f_00000-1-0 loss: 1.271532  [   32/  126]
train() client id: f_00000-1-1 loss: 1.260460  [   64/  126]
train() client id: f_00000-1-2 loss: 1.000361  [   96/  126]
train() client id: f_00000-2-0 loss: 1.064128  [   32/  126]
train() client id: f_00000-2-1 loss: 1.065134  [   64/  126]
train() client id: f_00000-2-2 loss: 1.047886  [   96/  126]
train() client id: f_00000-3-0 loss: 1.087857  [   32/  126]
train() client id: f_00000-3-1 loss: 1.005974  [   64/  126]
train() client id: f_00000-3-2 loss: 0.963864  [   96/  126]
train() client id: f_00000-4-0 loss: 0.852277  [   32/  126]
train() client id: f_00000-4-1 loss: 0.914502  [   64/  126]
train() client id: f_00000-4-2 loss: 0.884945  [   96/  126]
train() client id: f_00000-5-0 loss: 0.835892  [   32/  126]
train() client id: f_00000-5-1 loss: 0.896275  [   64/  126]
train() client id: f_00000-5-2 loss: 0.912253  [   96/  126]
train() client id: f_00000-6-0 loss: 0.810120  [   32/  126]
train() client id: f_00000-6-1 loss: 0.874451  [   64/  126]
train() client id: f_00000-6-2 loss: 1.014747  [   96/  126]
train() client id: f_00000-7-0 loss: 0.850422  [   32/  126]
train() client id: f_00000-7-1 loss: 0.976452  [   64/  126]
train() client id: f_00000-7-2 loss: 0.870910  [   96/  126]
train() client id: f_00000-8-0 loss: 0.897356  [   32/  126]
train() client id: f_00000-8-1 loss: 0.801767  [   64/  126]
train() client id: f_00000-8-2 loss: 0.914275  [   96/  126]
train() client id: f_00000-9-0 loss: 0.771057  [   32/  126]
train() client id: f_00000-9-1 loss: 0.849849  [   64/  126]
train() client id: f_00000-9-2 loss: 0.844921  [   96/  126]
train() client id: f_00000-10-0 loss: 0.801304  [   32/  126]
train() client id: f_00000-10-1 loss: 0.910884  [   64/  126]
train() client id: f_00000-10-2 loss: 0.794679  [   96/  126]
train() client id: f_00000-11-0 loss: 0.803371  [   32/  126]
train() client id: f_00000-11-1 loss: 1.026159  [   64/  126]
train() client id: f_00000-11-2 loss: 0.767427  [   96/  126]
train() client id: f_00000-12-0 loss: 0.945699  [   32/  126]
train() client id: f_00000-12-1 loss: 0.778472  [   64/  126]
train() client id: f_00000-12-2 loss: 0.867236  [   96/  126]
train() client id: f_00001-0-0 loss: 0.564097  [   32/  265]
train() client id: f_00001-0-1 loss: 0.475606  [   64/  265]
train() client id: f_00001-0-2 loss: 0.419139  [   96/  265]
train() client id: f_00001-0-3 loss: 0.458246  [  128/  265]
train() client id: f_00001-0-4 loss: 0.628697  [  160/  265]
train() client id: f_00001-0-5 loss: 0.553550  [  192/  265]
train() client id: f_00001-0-6 loss: 0.412288  [  224/  265]
train() client id: f_00001-0-7 loss: 0.517406  [  256/  265]
train() client id: f_00001-1-0 loss: 0.455994  [   32/  265]
train() client id: f_00001-1-1 loss: 0.532323  [   64/  265]
train() client id: f_00001-1-2 loss: 0.485497  [   96/  265]
train() client id: f_00001-1-3 loss: 0.419564  [  128/  265]
train() client id: f_00001-1-4 loss: 0.417329  [  160/  265]
train() client id: f_00001-1-5 loss: 0.631624  [  192/  265]
train() client id: f_00001-1-6 loss: 0.492927  [  224/  265]
train() client id: f_00001-1-7 loss: 0.475669  [  256/  265]
train() client id: f_00001-2-0 loss: 0.448405  [   32/  265]
train() client id: f_00001-2-1 loss: 0.434155  [   64/  265]
train() client id: f_00001-2-2 loss: 0.577598  [   96/  265]
train() client id: f_00001-2-3 loss: 0.579137  [  128/  265]
train() client id: f_00001-2-4 loss: 0.538603  [  160/  265]
train() client id: f_00001-2-5 loss: 0.487625  [  192/  265]
train() client id: f_00001-2-6 loss: 0.455682  [  224/  265]
train() client id: f_00001-2-7 loss: 0.394816  [  256/  265]
train() client id: f_00001-3-0 loss: 0.401677  [   32/  265]
train() client id: f_00001-3-1 loss: 0.395413  [   64/  265]
train() client id: f_00001-3-2 loss: 0.595247  [   96/  265]
train() client id: f_00001-3-3 loss: 0.493990  [  128/  265]
train() client id: f_00001-3-4 loss: 0.488046  [  160/  265]
train() client id: f_00001-3-5 loss: 0.536793  [  192/  265]
train() client id: f_00001-3-6 loss: 0.503752  [  224/  265]
train() client id: f_00001-3-7 loss: 0.432999  [  256/  265]
train() client id: f_00001-4-0 loss: 0.558072  [   32/  265]
train() client id: f_00001-4-1 loss: 0.469119  [   64/  265]
train() client id: f_00001-4-2 loss: 0.489610  [   96/  265]
train() client id: f_00001-4-3 loss: 0.459825  [  128/  265]
train() client id: f_00001-4-4 loss: 0.581661  [  160/  265]
train() client id: f_00001-4-5 loss: 0.383023  [  192/  265]
train() client id: f_00001-4-6 loss: 0.389376  [  224/  265]
train() client id: f_00001-4-7 loss: 0.523960  [  256/  265]
train() client id: f_00001-5-0 loss: 0.450228  [   32/  265]
train() client id: f_00001-5-1 loss: 0.473118  [   64/  265]
train() client id: f_00001-5-2 loss: 0.454540  [   96/  265]
train() client id: f_00001-5-3 loss: 0.422132  [  128/  265]
train() client id: f_00001-5-4 loss: 0.513396  [  160/  265]
train() client id: f_00001-5-5 loss: 0.388261  [  192/  265]
train() client id: f_00001-5-6 loss: 0.675125  [  224/  265]
train() client id: f_00001-5-7 loss: 0.454828  [  256/  265]
train() client id: f_00001-6-0 loss: 0.432824  [   32/  265]
train() client id: f_00001-6-1 loss: 0.382754  [   64/  265]
train() client id: f_00001-6-2 loss: 0.415515  [   96/  265]
train() client id: f_00001-6-3 loss: 0.674949  [  128/  265]
train() client id: f_00001-6-4 loss: 0.439313  [  160/  265]
train() client id: f_00001-6-5 loss: 0.498546  [  192/  265]
train() client id: f_00001-6-6 loss: 0.491713  [  224/  265]
train() client id: f_00001-6-7 loss: 0.482498  [  256/  265]
train() client id: f_00001-7-0 loss: 0.414591  [   32/  265]
train() client id: f_00001-7-1 loss: 0.392634  [   64/  265]
train() client id: f_00001-7-2 loss: 0.452613  [   96/  265]
train() client id: f_00001-7-3 loss: 0.498350  [  128/  265]
train() client id: f_00001-7-4 loss: 0.638578  [  160/  265]
train() client id: f_00001-7-5 loss: 0.477487  [  192/  265]
train() client id: f_00001-7-6 loss: 0.399104  [  224/  265]
train() client id: f_00001-7-7 loss: 0.398887  [  256/  265]
train() client id: f_00001-8-0 loss: 0.474285  [   32/  265]
train() client id: f_00001-8-1 loss: 0.488024  [   64/  265]
train() client id: f_00001-8-2 loss: 0.405732  [   96/  265]
train() client id: f_00001-8-3 loss: 0.458433  [  128/  265]
train() client id: f_00001-8-4 loss: 0.448593  [  160/  265]
train() client id: f_00001-8-5 loss: 0.549199  [  192/  265]
train() client id: f_00001-8-6 loss: 0.493822  [  224/  265]
train() client id: f_00001-8-7 loss: 0.414970  [  256/  265]
train() client id: f_00001-9-0 loss: 0.585989  [   32/  265]
train() client id: f_00001-9-1 loss: 0.511552  [   64/  265]
train() client id: f_00001-9-2 loss: 0.586818  [   96/  265]
train() client id: f_00001-9-3 loss: 0.386479  [  128/  265]
train() client id: f_00001-9-4 loss: 0.454915  [  160/  265]
train() client id: f_00001-9-5 loss: 0.382896  [  192/  265]
train() client id: f_00001-9-6 loss: 0.515626  [  224/  265]
train() client id: f_00001-9-7 loss: 0.378343  [  256/  265]
train() client id: f_00001-10-0 loss: 0.600033  [   32/  265]
train() client id: f_00001-10-1 loss: 0.402439  [   64/  265]
train() client id: f_00001-10-2 loss: 0.419264  [   96/  265]
train() client id: f_00001-10-3 loss: 0.451582  [  128/  265]
train() client id: f_00001-10-4 loss: 0.563773  [  160/  265]
train() client id: f_00001-10-5 loss: 0.463718  [  192/  265]
train() client id: f_00001-10-6 loss: 0.524808  [  224/  265]
train() client id: f_00001-10-7 loss: 0.385187  [  256/  265]
train() client id: f_00001-11-0 loss: 0.417798  [   32/  265]
train() client id: f_00001-11-1 loss: 0.454735  [   64/  265]
train() client id: f_00001-11-2 loss: 0.397528  [   96/  265]
train() client id: f_00001-11-3 loss: 0.615761  [  128/  265]
train() client id: f_00001-11-4 loss: 0.595124  [  160/  265]
train() client id: f_00001-11-5 loss: 0.436245  [  192/  265]
train() client id: f_00001-11-6 loss: 0.513322  [  224/  265]
train() client id: f_00001-11-7 loss: 0.365844  [  256/  265]
train() client id: f_00001-12-0 loss: 0.588571  [   32/  265]
train() client id: f_00001-12-1 loss: 0.513899  [   64/  265]
train() client id: f_00001-12-2 loss: 0.398084  [   96/  265]
train() client id: f_00001-12-3 loss: 0.381478  [  128/  265]
train() client id: f_00001-12-4 loss: 0.505527  [  160/  265]
train() client id: f_00001-12-5 loss: 0.414767  [  192/  265]
train() client id: f_00001-12-6 loss: 0.461471  [  224/  265]
train() client id: f_00001-12-7 loss: 0.509706  [  256/  265]
train() client id: f_00002-0-0 loss: 1.246969  [   32/  124]
train() client id: f_00002-0-1 loss: 1.268445  [   64/  124]
train() client id: f_00002-0-2 loss: 1.060834  [   96/  124]
train() client id: f_00002-1-0 loss: 1.193120  [   32/  124]
train() client id: f_00002-1-1 loss: 1.131500  [   64/  124]
train() client id: f_00002-1-2 loss: 1.146420  [   96/  124]
train() client id: f_00002-2-0 loss: 1.257170  [   32/  124]
train() client id: f_00002-2-1 loss: 1.148175  [   64/  124]
train() client id: f_00002-2-2 loss: 1.016056  [   96/  124]
train() client id: f_00002-3-0 loss: 1.157054  [   32/  124]
train() client id: f_00002-3-1 loss: 1.006672  [   64/  124]
train() client id: f_00002-3-2 loss: 1.097106  [   96/  124]
train() client id: f_00002-4-0 loss: 0.998549  [   32/  124]
train() client id: f_00002-4-1 loss: 1.016692  [   64/  124]
train() client id: f_00002-4-2 loss: 1.064465  [   96/  124]
train() client id: f_00002-5-0 loss: 0.980740  [   32/  124]
train() client id: f_00002-5-1 loss: 0.953568  [   64/  124]
train() client id: f_00002-5-2 loss: 1.116045  [   96/  124]
train() client id: f_00002-6-0 loss: 1.022345  [   32/  124]
train() client id: f_00002-6-1 loss: 1.027409  [   64/  124]
train() client id: f_00002-6-2 loss: 1.109171  [   96/  124]
train() client id: f_00002-7-0 loss: 1.181638  [   32/  124]
train() client id: f_00002-7-1 loss: 1.009348  [   64/  124]
train() client id: f_00002-7-2 loss: 0.868058  [   96/  124]
train() client id: f_00002-8-0 loss: 0.899053  [   32/  124]
train() client id: f_00002-8-1 loss: 1.020199  [   64/  124]
train() client id: f_00002-8-2 loss: 0.880592  [   96/  124]
train() client id: f_00002-9-0 loss: 0.871905  [   32/  124]
train() client id: f_00002-9-1 loss: 0.971435  [   64/  124]
train() client id: f_00002-9-2 loss: 1.103178  [   96/  124]
train() client id: f_00002-10-0 loss: 1.065684  [   32/  124]
train() client id: f_00002-10-1 loss: 0.940720  [   64/  124]
train() client id: f_00002-10-2 loss: 0.995684  [   96/  124]
train() client id: f_00002-11-0 loss: 0.812955  [   32/  124]
train() client id: f_00002-11-1 loss: 1.118718  [   64/  124]
train() client id: f_00002-11-2 loss: 0.842339  [   96/  124]
train() client id: f_00002-12-0 loss: 0.906299  [   32/  124]
train() client id: f_00002-12-1 loss: 1.043221  [   64/  124]
train() client id: f_00002-12-2 loss: 0.862875  [   96/  124]
train() client id: f_00003-0-0 loss: 0.633168  [   32/   43]
train() client id: f_00003-1-0 loss: 0.537915  [   32/   43]
train() client id: f_00003-2-0 loss: 0.731430  [   32/   43]
train() client id: f_00003-3-0 loss: 0.779308  [   32/   43]
train() client id: f_00003-4-0 loss: 0.647725  [   32/   43]
train() client id: f_00003-5-0 loss: 0.657730  [   32/   43]
train() client id: f_00003-6-0 loss: 0.732123  [   32/   43]
train() client id: f_00003-7-0 loss: 0.902254  [   32/   43]
train() client id: f_00003-8-0 loss: 0.654535  [   32/   43]
train() client id: f_00003-9-0 loss: 0.806308  [   32/   43]
train() client id: f_00003-10-0 loss: 0.773237  [   32/   43]
train() client id: f_00003-11-0 loss: 0.679127  [   32/   43]
train() client id: f_00003-12-0 loss: 0.859272  [   32/   43]
train() client id: f_00004-0-0 loss: 0.778131  [   32/  306]
train() client id: f_00004-0-1 loss: 0.685065  [   64/  306]
train() client id: f_00004-0-2 loss: 0.686829  [   96/  306]
train() client id: f_00004-0-3 loss: 0.977023  [  128/  306]
train() client id: f_00004-0-4 loss: 0.791216  [  160/  306]
train() client id: f_00004-0-5 loss: 0.886330  [  192/  306]
train() client id: f_00004-0-6 loss: 0.820595  [  224/  306]
train() client id: f_00004-0-7 loss: 0.800914  [  256/  306]
train() client id: f_00004-0-8 loss: 0.776622  [  288/  306]
train() client id: f_00004-1-0 loss: 0.712336  [   32/  306]
train() client id: f_00004-1-1 loss: 0.853092  [   64/  306]
train() client id: f_00004-1-2 loss: 0.946840  [   96/  306]
train() client id: f_00004-1-3 loss: 0.704389  [  128/  306]
train() client id: f_00004-1-4 loss: 0.665026  [  160/  306]
train() client id: f_00004-1-5 loss: 0.809985  [  192/  306]
train() client id: f_00004-1-6 loss: 0.812132  [  224/  306]
train() client id: f_00004-1-7 loss: 0.972320  [  256/  306]
train() client id: f_00004-1-8 loss: 0.865777  [  288/  306]
train() client id: f_00004-2-0 loss: 0.846093  [   32/  306]
train() client id: f_00004-2-1 loss: 0.770071  [   64/  306]
train() client id: f_00004-2-2 loss: 0.769331  [   96/  306]
train() client id: f_00004-2-3 loss: 0.791458  [  128/  306]
train() client id: f_00004-2-4 loss: 0.922304  [  160/  306]
train() client id: f_00004-2-5 loss: 0.925403  [  192/  306]
train() client id: f_00004-2-6 loss: 0.679936  [  224/  306]
train() client id: f_00004-2-7 loss: 0.694095  [  256/  306]
train() client id: f_00004-2-8 loss: 0.894501  [  288/  306]
train() client id: f_00004-3-0 loss: 0.958044  [   32/  306]
train() client id: f_00004-3-1 loss: 0.891324  [   64/  306]
train() client id: f_00004-3-2 loss: 0.826534  [   96/  306]
train() client id: f_00004-3-3 loss: 0.733629  [  128/  306]
train() client id: f_00004-3-4 loss: 0.762916  [  160/  306]
train() client id: f_00004-3-5 loss: 0.842480  [  192/  306]
train() client id: f_00004-3-6 loss: 0.780839  [  224/  306]
train() client id: f_00004-3-7 loss: 0.866708  [  256/  306]
train() client id: f_00004-3-8 loss: 0.694545  [  288/  306]
train() client id: f_00004-4-0 loss: 0.719967  [   32/  306]
train() client id: f_00004-4-1 loss: 0.890593  [   64/  306]
train() client id: f_00004-4-2 loss: 0.834933  [   96/  306]
train() client id: f_00004-4-3 loss: 0.847213  [  128/  306]
train() client id: f_00004-4-4 loss: 0.844704  [  160/  306]
train() client id: f_00004-4-5 loss: 0.948406  [  192/  306]
train() client id: f_00004-4-6 loss: 0.739544  [  224/  306]
train() client id: f_00004-4-7 loss: 0.703170  [  256/  306]
train() client id: f_00004-4-8 loss: 0.806181  [  288/  306]
train() client id: f_00004-5-0 loss: 0.871312  [   32/  306]
train() client id: f_00004-5-1 loss: 0.861298  [   64/  306]
train() client id: f_00004-5-2 loss: 0.871662  [   96/  306]
train() client id: f_00004-5-3 loss: 0.732859  [  128/  306]
train() client id: f_00004-5-4 loss: 0.740572  [  160/  306]
train() client id: f_00004-5-5 loss: 0.778605  [  192/  306]
train() client id: f_00004-5-6 loss: 0.735569  [  224/  306]
train() client id: f_00004-5-7 loss: 0.851005  [  256/  306]
train() client id: f_00004-5-8 loss: 0.860248  [  288/  306]
train() client id: f_00004-6-0 loss: 0.949745  [   32/  306]
train() client id: f_00004-6-1 loss: 0.891269  [   64/  306]
train() client id: f_00004-6-2 loss: 0.762481  [   96/  306]
train() client id: f_00004-6-3 loss: 0.734878  [  128/  306]
train() client id: f_00004-6-4 loss: 0.798094  [  160/  306]
train() client id: f_00004-6-5 loss: 0.798729  [  192/  306]
train() client id: f_00004-6-6 loss: 0.818776  [  224/  306]
train() client id: f_00004-6-7 loss: 0.897872  [  256/  306]
train() client id: f_00004-6-8 loss: 0.649516  [  288/  306]
train() client id: f_00004-7-0 loss: 0.687604  [   32/  306]
train() client id: f_00004-7-1 loss: 0.824739  [   64/  306]
train() client id: f_00004-7-2 loss: 0.821013  [   96/  306]
train() client id: f_00004-7-3 loss: 0.786249  [  128/  306]
train() client id: f_00004-7-4 loss: 0.841166  [  160/  306]
train() client id: f_00004-7-5 loss: 0.768096  [  192/  306]
train() client id: f_00004-7-6 loss: 0.792837  [  224/  306]
train() client id: f_00004-7-7 loss: 0.820697  [  256/  306]
train() client id: f_00004-7-8 loss: 0.939384  [  288/  306]
train() client id: f_00004-8-0 loss: 0.789833  [   32/  306]
train() client id: f_00004-8-1 loss: 0.878351  [   64/  306]
train() client id: f_00004-8-2 loss: 0.808372  [   96/  306]
train() client id: f_00004-8-3 loss: 0.801798  [  128/  306]
train() client id: f_00004-8-4 loss: 0.695396  [  160/  306]
train() client id: f_00004-8-5 loss: 0.779891  [  192/  306]
train() client id: f_00004-8-6 loss: 0.820338  [  224/  306]
train() client id: f_00004-8-7 loss: 0.811179  [  256/  306]
train() client id: f_00004-8-8 loss: 0.874121  [  288/  306]
train() client id: f_00004-9-0 loss: 1.009972  [   32/  306]
train() client id: f_00004-9-1 loss: 0.740102  [   64/  306]
train() client id: f_00004-9-2 loss: 0.744520  [   96/  306]
train() client id: f_00004-9-3 loss: 0.949147  [  128/  306]
train() client id: f_00004-9-4 loss: 0.783337  [  160/  306]
train() client id: f_00004-9-5 loss: 0.760943  [  192/  306]
train() client id: f_00004-9-6 loss: 0.782875  [  224/  306]
train() client id: f_00004-9-7 loss: 0.692825  [  256/  306]
train() client id: f_00004-9-8 loss: 0.832855  [  288/  306]
train() client id: f_00004-10-0 loss: 0.864238  [   32/  306]
train() client id: f_00004-10-1 loss: 0.800962  [   64/  306]
train() client id: f_00004-10-2 loss: 0.786756  [   96/  306]
train() client id: f_00004-10-3 loss: 0.851406  [  128/  306]
train() client id: f_00004-10-4 loss: 0.769030  [  160/  306]
train() client id: f_00004-10-5 loss: 0.891280  [  192/  306]
train() client id: f_00004-10-6 loss: 0.681234  [  224/  306]
train() client id: f_00004-10-7 loss: 0.819916  [  256/  306]
train() client id: f_00004-10-8 loss: 0.840883  [  288/  306]
train() client id: f_00004-11-0 loss: 0.798584  [   32/  306]
train() client id: f_00004-11-1 loss: 0.806529  [   64/  306]
train() client id: f_00004-11-2 loss: 0.812045  [   96/  306]
train() client id: f_00004-11-3 loss: 0.822588  [  128/  306]
train() client id: f_00004-11-4 loss: 0.923033  [  160/  306]
train() client id: f_00004-11-5 loss: 0.753123  [  192/  306]
train() client id: f_00004-11-6 loss: 0.722756  [  224/  306]
train() client id: f_00004-11-7 loss: 0.848844  [  256/  306]
train() client id: f_00004-11-8 loss: 0.772030  [  288/  306]
train() client id: f_00004-12-0 loss: 0.872812  [   32/  306]
train() client id: f_00004-12-1 loss: 0.785598  [   64/  306]
train() client id: f_00004-12-2 loss: 0.862405  [   96/  306]
train() client id: f_00004-12-3 loss: 0.696176  [  128/  306]
train() client id: f_00004-12-4 loss: 0.753719  [  160/  306]
train() client id: f_00004-12-5 loss: 0.869946  [  192/  306]
train() client id: f_00004-12-6 loss: 0.861378  [  224/  306]
train() client id: f_00004-12-7 loss: 0.734237  [  256/  306]
train() client id: f_00004-12-8 loss: 0.866431  [  288/  306]
train() client id: f_00005-0-0 loss: 0.355550  [   32/  146]
train() client id: f_00005-0-1 loss: 0.240915  [   64/  146]
train() client id: f_00005-0-2 loss: 0.667554  [   96/  146]
train() client id: f_00005-0-3 loss: 0.676444  [  128/  146]
train() client id: f_00005-1-0 loss: 0.476485  [   32/  146]
train() client id: f_00005-1-1 loss: 0.527313  [   64/  146]
train() client id: f_00005-1-2 loss: 0.273629  [   96/  146]
train() client id: f_00005-1-3 loss: 0.713545  [  128/  146]
train() client id: f_00005-2-0 loss: 0.296613  [   32/  146]
train() client id: f_00005-2-1 loss: 0.492119  [   64/  146]
train() client id: f_00005-2-2 loss: 0.653914  [   96/  146]
train() client id: f_00005-2-3 loss: 0.482112  [  128/  146]
train() client id: f_00005-3-0 loss: 0.568185  [   32/  146]
train() client id: f_00005-3-1 loss: 0.444078  [   64/  146]
train() client id: f_00005-3-2 loss: 0.660657  [   96/  146]
train() client id: f_00005-3-3 loss: 0.475273  [  128/  146]
train() client id: f_00005-4-0 loss: 0.538801  [   32/  146]
train() client id: f_00005-4-1 loss: 0.365352  [   64/  146]
train() client id: f_00005-4-2 loss: 0.603368  [   96/  146]
train() client id: f_00005-4-3 loss: 0.504834  [  128/  146]
train() client id: f_00005-5-0 loss: 0.598218  [   32/  146]
train() client id: f_00005-5-1 loss: 0.583772  [   64/  146]
train() client id: f_00005-5-2 loss: 0.380675  [   96/  146]
train() client id: f_00005-5-3 loss: 0.513646  [  128/  146]
train() client id: f_00005-6-0 loss: 0.523393  [   32/  146]
train() client id: f_00005-6-1 loss: 0.573653  [   64/  146]
train() client id: f_00005-6-2 loss: 0.343332  [   96/  146]
train() client id: f_00005-6-3 loss: 0.626513  [  128/  146]
train() client id: f_00005-7-0 loss: 0.731849  [   32/  146]
train() client id: f_00005-7-1 loss: 0.499111  [   64/  146]
train() client id: f_00005-7-2 loss: 0.424279  [   96/  146]
train() client id: f_00005-7-3 loss: 0.548792  [  128/  146]
train() client id: f_00005-8-0 loss: 0.541358  [   32/  146]
train() client id: f_00005-8-1 loss: 0.622840  [   64/  146]
train() client id: f_00005-8-2 loss: 0.454893  [   96/  146]
train() client id: f_00005-8-3 loss: 0.346666  [  128/  146]
train() client id: f_00005-9-0 loss: 0.375865  [   32/  146]
train() client id: f_00005-9-1 loss: 0.527589  [   64/  146]
train() client id: f_00005-9-2 loss: 0.513786  [   96/  146]
train() client id: f_00005-9-3 loss: 0.502830  [  128/  146]
train() client id: f_00005-10-0 loss: 0.665974  [   32/  146]
train() client id: f_00005-10-1 loss: 0.327716  [   64/  146]
train() client id: f_00005-10-2 loss: 0.715829  [   96/  146]
train() client id: f_00005-10-3 loss: 0.319920  [  128/  146]
train() client id: f_00005-11-0 loss: 0.408383  [   32/  146]
train() client id: f_00005-11-1 loss: 0.416233  [   64/  146]
train() client id: f_00005-11-2 loss: 0.798911  [   96/  146]
train() client id: f_00005-11-3 loss: 0.558190  [  128/  146]
train() client id: f_00005-12-0 loss: 0.413049  [   32/  146]
train() client id: f_00005-12-1 loss: 0.234285  [   64/  146]
train() client id: f_00005-12-2 loss: 0.717407  [   96/  146]
train() client id: f_00005-12-3 loss: 0.612870  [  128/  146]
train() client id: f_00006-0-0 loss: 0.471772  [   32/   54]
train() client id: f_00006-1-0 loss: 0.520075  [   32/   54]
train() client id: f_00006-2-0 loss: 0.514979  [   32/   54]
train() client id: f_00006-3-0 loss: 0.508653  [   32/   54]
train() client id: f_00006-4-0 loss: 0.488760  [   32/   54]
train() client id: f_00006-5-0 loss: 0.485969  [   32/   54]
train() client id: f_00006-6-0 loss: 0.410149  [   32/   54]
train() client id: f_00006-7-0 loss: 0.397987  [   32/   54]
train() client id: f_00006-8-0 loss: 0.497183  [   32/   54]
train() client id: f_00006-9-0 loss: 0.515069  [   32/   54]
train() client id: f_00006-10-0 loss: 0.405066  [   32/   54]
train() client id: f_00006-11-0 loss: 0.458185  [   32/   54]
train() client id: f_00006-12-0 loss: 0.462217  [   32/   54]
train() client id: f_00007-0-0 loss: 0.872724  [   32/  179]
train() client id: f_00007-0-1 loss: 0.721864  [   64/  179]
train() client id: f_00007-0-2 loss: 0.708160  [   96/  179]
train() client id: f_00007-0-3 loss: 0.715972  [  128/  179]
train() client id: f_00007-0-4 loss: 0.610267  [  160/  179]
train() client id: f_00007-1-0 loss: 0.574656  [   32/  179]
train() client id: f_00007-1-1 loss: 0.520600  [   64/  179]
train() client id: f_00007-1-2 loss: 0.805938  [   96/  179]
train() client id: f_00007-1-3 loss: 0.937674  [  128/  179]
train() client id: f_00007-1-4 loss: 0.558543  [  160/  179]
train() client id: f_00007-2-0 loss: 0.667760  [   32/  179]
train() client id: f_00007-2-1 loss: 0.602659  [   64/  179]
train() client id: f_00007-2-2 loss: 0.762403  [   96/  179]
train() client id: f_00007-2-3 loss: 0.845198  [  128/  179]
train() client id: f_00007-2-4 loss: 0.711666  [  160/  179]
train() client id: f_00007-3-0 loss: 0.598767  [   32/  179]
train() client id: f_00007-3-1 loss: 0.778769  [   64/  179]
train() client id: f_00007-3-2 loss: 0.714127  [   96/  179]
train() client id: f_00007-3-3 loss: 0.564611  [  128/  179]
train() client id: f_00007-3-4 loss: 0.738006  [  160/  179]
train() client id: f_00007-4-0 loss: 0.722293  [   32/  179]
train() client id: f_00007-4-1 loss: 0.597979  [   64/  179]
train() client id: f_00007-4-2 loss: 0.708758  [   96/  179]
train() client id: f_00007-4-3 loss: 0.710567  [  128/  179]
train() client id: f_00007-4-4 loss: 0.711548  [  160/  179]
train() client id: f_00007-5-0 loss: 0.660396  [   32/  179]
train() client id: f_00007-5-1 loss: 0.543441  [   64/  179]
train() client id: f_00007-5-2 loss: 0.667674  [   96/  179]
train() client id: f_00007-5-3 loss: 0.685570  [  128/  179]
train() client id: f_00007-5-4 loss: 0.946860  [  160/  179]
train() client id: f_00007-6-0 loss: 0.696647  [   32/  179]
train() client id: f_00007-6-1 loss: 0.700798  [   64/  179]
train() client id: f_00007-6-2 loss: 0.772635  [   96/  179]
train() client id: f_00007-6-3 loss: 0.780275  [  128/  179]
train() client id: f_00007-6-4 loss: 0.560963  [  160/  179]
train() client id: f_00007-7-0 loss: 0.703985  [   32/  179]
train() client id: f_00007-7-1 loss: 0.567917  [   64/  179]
train() client id: f_00007-7-2 loss: 0.637221  [   96/  179]
train() client id: f_00007-7-3 loss: 0.569700  [  128/  179]
train() client id: f_00007-7-4 loss: 0.789918  [  160/  179]
train() client id: f_00007-8-0 loss: 0.548128  [   32/  179]
train() client id: f_00007-8-1 loss: 0.722482  [   64/  179]
train() client id: f_00007-8-2 loss: 0.829578  [   96/  179]
train() client id: f_00007-8-3 loss: 0.640153  [  128/  179]
train() client id: f_00007-8-4 loss: 0.644680  [  160/  179]
train() client id: f_00007-9-0 loss: 0.912492  [   32/  179]
train() client id: f_00007-9-1 loss: 0.984994  [   64/  179]
train() client id: f_00007-9-2 loss: 0.534000  [   96/  179]
train() client id: f_00007-9-3 loss: 0.495229  [  128/  179]
train() client id: f_00007-9-4 loss: 0.552206  [  160/  179]
train() client id: f_00007-10-0 loss: 0.521637  [   32/  179]
train() client id: f_00007-10-1 loss: 1.003516  [   64/  179]
train() client id: f_00007-10-2 loss: 0.617538  [   96/  179]
train() client id: f_00007-10-3 loss: 0.684684  [  128/  179]
train() client id: f_00007-10-4 loss: 0.654329  [  160/  179]
train() client id: f_00007-11-0 loss: 0.651202  [   32/  179]
train() client id: f_00007-11-1 loss: 0.588722  [   64/  179]
train() client id: f_00007-11-2 loss: 0.562826  [   96/  179]
train() client id: f_00007-11-3 loss: 0.707105  [  128/  179]
train() client id: f_00007-11-4 loss: 0.864094  [  160/  179]
train() client id: f_00007-12-0 loss: 0.618796  [   32/  179]
train() client id: f_00007-12-1 loss: 0.704650  [   64/  179]
train() client id: f_00007-12-2 loss: 0.620286  [   96/  179]
train() client id: f_00007-12-3 loss: 0.616297  [  128/  179]
train() client id: f_00007-12-4 loss: 0.752978  [  160/  179]
train() client id: f_00008-0-0 loss: 0.709812  [   32/  130]
train() client id: f_00008-0-1 loss: 0.695675  [   64/  130]
train() client id: f_00008-0-2 loss: 0.828036  [   96/  130]
train() client id: f_00008-0-3 loss: 0.842117  [  128/  130]
train() client id: f_00008-1-0 loss: 0.782935  [   32/  130]
train() client id: f_00008-1-1 loss: 0.790973  [   64/  130]
train() client id: f_00008-1-2 loss: 0.767326  [   96/  130]
train() client id: f_00008-1-3 loss: 0.773090  [  128/  130]
train() client id: f_00008-2-0 loss: 0.644935  [   32/  130]
train() client id: f_00008-2-1 loss: 0.862140  [   64/  130]
train() client id: f_00008-2-2 loss: 0.814681  [   96/  130]
train() client id: f_00008-2-3 loss: 0.796024  [  128/  130]
train() client id: f_00008-3-0 loss: 0.795363  [   32/  130]
train() client id: f_00008-3-1 loss: 0.782647  [   64/  130]
train() client id: f_00008-3-2 loss: 0.762127  [   96/  130]
train() client id: f_00008-3-3 loss: 0.772678  [  128/  130]
train() client id: f_00008-4-0 loss: 0.862812  [   32/  130]
train() client id: f_00008-4-1 loss: 0.739536  [   64/  130]
train() client id: f_00008-4-2 loss: 0.762783  [   96/  130]
train() client id: f_00008-4-3 loss: 0.744273  [  128/  130]
train() client id: f_00008-5-0 loss: 0.788304  [   32/  130]
train() client id: f_00008-5-1 loss: 0.776445  [   64/  130]
train() client id: f_00008-5-2 loss: 0.659933  [   96/  130]
train() client id: f_00008-5-3 loss: 0.886823  [  128/  130]
train() client id: f_00008-6-0 loss: 0.845898  [   32/  130]
train() client id: f_00008-6-1 loss: 0.805995  [   64/  130]
train() client id: f_00008-6-2 loss: 0.727771  [   96/  130]
train() client id: f_00008-6-3 loss: 0.738951  [  128/  130]
train() client id: f_00008-7-0 loss: 0.776653  [   32/  130]
train() client id: f_00008-7-1 loss: 0.827808  [   64/  130]
train() client id: f_00008-7-2 loss: 0.720537  [   96/  130]
train() client id: f_00008-7-3 loss: 0.783262  [  128/  130]
train() client id: f_00008-8-0 loss: 0.726545  [   32/  130]
train() client id: f_00008-8-1 loss: 0.783516  [   64/  130]
train() client id: f_00008-8-2 loss: 0.735782  [   96/  130]
train() client id: f_00008-8-3 loss: 0.837094  [  128/  130]
train() client id: f_00008-9-0 loss: 0.810021  [   32/  130]
train() client id: f_00008-9-1 loss: 0.759478  [   64/  130]
train() client id: f_00008-9-2 loss: 0.732051  [   96/  130]
train() client id: f_00008-9-3 loss: 0.810450  [  128/  130]
train() client id: f_00008-10-0 loss: 0.811509  [   32/  130]
train() client id: f_00008-10-1 loss: 0.798768  [   64/  130]
train() client id: f_00008-10-2 loss: 0.745998  [   96/  130]
train() client id: f_00008-10-3 loss: 0.720375  [  128/  130]
train() client id: f_00008-11-0 loss: 0.815807  [   32/  130]
train() client id: f_00008-11-1 loss: 0.717066  [   64/  130]
train() client id: f_00008-11-2 loss: 0.674602  [   96/  130]
train() client id: f_00008-11-3 loss: 0.907363  [  128/  130]
train() client id: f_00008-12-0 loss: 0.713267  [   32/  130]
train() client id: f_00008-12-1 loss: 0.849330  [   64/  130]
train() client id: f_00008-12-2 loss: 0.759909  [   96/  130]
train() client id: f_00008-12-3 loss: 0.759103  [  128/  130]
train() client id: f_00009-0-0 loss: 1.185667  [   32/  118]
train() client id: f_00009-0-1 loss: 1.098927  [   64/  118]
train() client id: f_00009-0-2 loss: 1.171962  [   96/  118]
train() client id: f_00009-1-0 loss: 1.049611  [   32/  118]
train() client id: f_00009-1-1 loss: 1.032755  [   64/  118]
train() client id: f_00009-1-2 loss: 1.128264  [   96/  118]
train() client id: f_00009-2-0 loss: 1.156822  [   32/  118]
train() client id: f_00009-2-1 loss: 1.039306  [   64/  118]
train() client id: f_00009-2-2 loss: 0.995658  [   96/  118]
train() client id: f_00009-3-0 loss: 1.055656  [   32/  118]
train() client id: f_00009-3-1 loss: 1.004041  [   64/  118]
train() client id: f_00009-3-2 loss: 0.980953  [   96/  118]
train() client id: f_00009-4-0 loss: 0.990503  [   32/  118]
train() client id: f_00009-4-1 loss: 1.057705  [   64/  118]
train() client id: f_00009-4-2 loss: 0.947669  [   96/  118]
train() client id: f_00009-5-0 loss: 0.925221  [   32/  118]
train() client id: f_00009-5-1 loss: 0.935979  [   64/  118]
train() client id: f_00009-5-2 loss: 1.081879  [   96/  118]
train() client id: f_00009-6-0 loss: 1.060993  [   32/  118]
train() client id: f_00009-6-1 loss: 0.908724  [   64/  118]
train() client id: f_00009-6-2 loss: 0.897384  [   96/  118]
train() client id: f_00009-7-0 loss: 1.010446  [   32/  118]
train() client id: f_00009-7-1 loss: 0.937313  [   64/  118]
train() client id: f_00009-7-2 loss: 0.937842  [   96/  118]
train() client id: f_00009-8-0 loss: 1.066567  [   32/  118]
train() client id: f_00009-8-1 loss: 0.893998  [   64/  118]
train() client id: f_00009-8-2 loss: 0.834031  [   96/  118]
train() client id: f_00009-9-0 loss: 0.869979  [   32/  118]
train() client id: f_00009-9-1 loss: 0.963802  [   64/  118]
train() client id: f_00009-9-2 loss: 0.925790  [   96/  118]
train() client id: f_00009-10-0 loss: 0.996591  [   32/  118]
train() client id: f_00009-10-1 loss: 0.923863  [   64/  118]
train() client id: f_00009-10-2 loss: 0.821576  [   96/  118]
train() client id: f_00009-11-0 loss: 0.734794  [   32/  118]
train() client id: f_00009-11-1 loss: 0.921303  [   64/  118]
train() client id: f_00009-11-2 loss: 1.099316  [   96/  118]
train() client id: f_00009-12-0 loss: 0.841926  [   32/  118]
train() client id: f_00009-12-1 loss: 0.999863  [   64/  118]
train() client id: f_00009-12-2 loss: 0.963243  [   96/  118]
At round 34 accuracy: 0.6445623342175066
At round 34 training accuracy: 0.5868544600938967
At round 34 training loss: 0.8356718391578135
gradient difference: 0.4152091145515442
train() client id: f_00000-0-0 loss: 1.181146  [   32/  126]
train() client id: f_00000-0-1 loss: 1.164520  [   64/  126]
train() client id: f_00000-0-2 loss: 0.910717  [   96/  126]
train() client id: f_00000-1-0 loss: 1.125553  [   32/  126]
train() client id: f_00000-1-1 loss: 1.028751  [   64/  126]
train() client id: f_00000-1-2 loss: 0.857732  [   96/  126]
train() client id: f_00000-2-0 loss: 0.837939  [   32/  126]
train() client id: f_00000-2-1 loss: 0.990519  [   64/  126]
train() client id: f_00000-2-2 loss: 0.928217  [   96/  126]
train() client id: f_00000-3-0 loss: 0.990613  [   32/  126]
train() client id: f_00000-3-1 loss: 0.836988  [   64/  126]
train() client id: f_00000-3-2 loss: 0.915327  [   96/  126]
train() client id: f_00000-4-0 loss: 0.826659  [   32/  126]
train() client id: f_00000-4-1 loss: 0.827461  [   64/  126]
train() client id: f_00000-4-2 loss: 0.931319  [   96/  126]
train() client id: f_00000-5-0 loss: 0.944275  [   32/  126]
train() client id: f_00000-5-1 loss: 0.865711  [   64/  126]
train() client id: f_00000-5-2 loss: 0.852822  [   96/  126]
train() client id: f_00000-6-0 loss: 0.719894  [   32/  126]
train() client id: f_00000-6-1 loss: 0.932164  [   64/  126]
train() client id: f_00000-6-2 loss: 0.823437  [   96/  126]
train() client id: f_00000-7-0 loss: 0.846097  [   32/  126]
train() client id: f_00000-7-1 loss: 0.781315  [   64/  126]
train() client id: f_00000-7-2 loss: 0.702585  [   96/  126]
train() client id: f_00000-8-0 loss: 0.766173  [   32/  126]
train() client id: f_00000-8-1 loss: 0.875394  [   64/  126]
train() client id: f_00000-8-2 loss: 0.744489  [   96/  126]
train() client id: f_00000-9-0 loss: 0.759955  [   32/  126]
train() client id: f_00000-9-1 loss: 0.733896  [   64/  126]
train() client id: f_00000-9-2 loss: 0.784148  [   96/  126]
train() client id: f_00000-10-0 loss: 0.715430  [   32/  126]
train() client id: f_00000-10-1 loss: 0.848789  [   64/  126]
train() client id: f_00000-10-2 loss: 0.783685  [   96/  126]
train() client id: f_00000-11-0 loss: 0.746791  [   32/  126]
train() client id: f_00000-11-1 loss: 0.858647  [   64/  126]
train() client id: f_00000-11-2 loss: 0.798980  [   96/  126]
train() client id: f_00000-12-0 loss: 0.811144  [   32/  126]
train() client id: f_00000-12-1 loss: 0.808341  [   64/  126]
train() client id: f_00000-12-2 loss: 0.724755  [   96/  126]
train() client id: f_00001-0-0 loss: 0.339508  [   32/  265]
train() client id: f_00001-0-1 loss: 0.394806  [   64/  265]
train() client id: f_00001-0-2 loss: 0.435193  [   96/  265]
train() client id: f_00001-0-3 loss: 0.311012  [  128/  265]
train() client id: f_00001-0-4 loss: 0.454418  [  160/  265]
train() client id: f_00001-0-5 loss: 0.385366  [  192/  265]
train() client id: f_00001-0-6 loss: 0.354470  [  224/  265]
train() client id: f_00001-0-7 loss: 0.380949  [  256/  265]
train() client id: f_00001-1-0 loss: 0.328053  [   32/  265]
train() client id: f_00001-1-1 loss: 0.320520  [   64/  265]
train() client id: f_00001-1-2 loss: 0.581965  [   96/  265]
train() client id: f_00001-1-3 loss: 0.341973  [  128/  265]
train() client id: f_00001-1-4 loss: 0.338878  [  160/  265]
train() client id: f_00001-1-5 loss: 0.405187  [  192/  265]
train() client id: f_00001-1-6 loss: 0.426626  [  224/  265]
train() client id: f_00001-1-7 loss: 0.348450  [  256/  265]
train() client id: f_00001-2-0 loss: 0.504973  [   32/  265]
train() client id: f_00001-2-1 loss: 0.419654  [   64/  265]
train() client id: f_00001-2-2 loss: 0.339747  [   96/  265]
train() client id: f_00001-2-3 loss: 0.416510  [  128/  265]
train() client id: f_00001-2-4 loss: 0.301485  [  160/  265]
train() client id: f_00001-2-5 loss: 0.402660  [  192/  265]
train() client id: f_00001-2-6 loss: 0.290496  [  224/  265]
train() client id: f_00001-2-7 loss: 0.359287  [  256/  265]
train() client id: f_00001-3-0 loss: 0.362572  [   32/  265]
train() client id: f_00001-3-1 loss: 0.361418  [   64/  265]
train() client id: f_00001-3-2 loss: 0.323358  [   96/  265]
train() client id: f_00001-3-3 loss: 0.444219  [  128/  265]
train() client id: f_00001-3-4 loss: 0.310574  [  160/  265]
train() client id: f_00001-3-5 loss: 0.294587  [  192/  265]
train() client id: f_00001-3-6 loss: 0.537812  [  224/  265]
train() client id: f_00001-3-7 loss: 0.342745  [  256/  265]
train() client id: f_00001-4-0 loss: 0.389014  [   32/  265]
train() client id: f_00001-4-1 loss: 0.299666  [   64/  265]
train() client id: f_00001-4-2 loss: 0.359476  [   96/  265]
train() client id: f_00001-4-3 loss: 0.273676  [  128/  265]
train() client id: f_00001-4-4 loss: 0.444616  [  160/  265]
train() client id: f_00001-4-5 loss: 0.314517  [  192/  265]
train() client id: f_00001-4-6 loss: 0.343070  [  224/  265]
train() client id: f_00001-4-7 loss: 0.434807  [  256/  265]
train() client id: f_00001-5-0 loss: 0.280094  [   32/  265]
train() client id: f_00001-5-1 loss: 0.311570  [   64/  265]
train() client id: f_00001-5-2 loss: 0.359621  [   96/  265]
train() client id: f_00001-5-3 loss: 0.282765  [  128/  265]
train() client id: f_00001-5-4 loss: 0.555081  [  160/  265]
train() client id: f_00001-5-5 loss: 0.330961  [  192/  265]
train() client id: f_00001-5-6 loss: 0.423349  [  224/  265]
train() client id: f_00001-5-7 loss: 0.372371  [  256/  265]
train() client id: f_00001-6-0 loss: 0.356937  [   32/  265]
train() client id: f_00001-6-1 loss: 0.339952  [   64/  265]
train() client id: f_00001-6-2 loss: 0.327526  [   96/  265]
train() client id: f_00001-6-3 loss: 0.354730  [  128/  265]
train() client id: f_00001-6-4 loss: 0.372425  [  160/  265]
train() client id: f_00001-6-5 loss: 0.468874  [  192/  265]
train() client id: f_00001-6-6 loss: 0.367237  [  224/  265]
train() client id: f_00001-6-7 loss: 0.307975  [  256/  265]
train() client id: f_00001-7-0 loss: 0.392550  [   32/  265]
train() client id: f_00001-7-1 loss: 0.278074  [   64/  265]
train() client id: f_00001-7-2 loss: 0.250024  [   96/  265]
train() client id: f_00001-7-3 loss: 0.500246  [  128/  265]
train() client id: f_00001-7-4 loss: 0.280979  [  160/  265]
train() client id: f_00001-7-5 loss: 0.434557  [  192/  265]
train() client id: f_00001-7-6 loss: 0.296783  [  224/  265]
train() client id: f_00001-7-7 loss: 0.329107  [  256/  265]
train() client id: f_00001-8-0 loss: 0.312239  [   32/  265]
train() client id: f_00001-8-1 loss: 0.317921  [   64/  265]
train() client id: f_00001-8-2 loss: 0.358297  [   96/  265]
train() client id: f_00001-8-3 loss: 0.257028  [  128/  265]
train() client id: f_00001-8-4 loss: 0.357751  [  160/  265]
train() client id: f_00001-8-5 loss: 0.542994  [  192/  265]
train() client id: f_00001-8-6 loss: 0.395406  [  224/  265]
train() client id: f_00001-8-7 loss: 0.302366  [  256/  265]
train() client id: f_00001-9-0 loss: 0.374044  [   32/  265]
train() client id: f_00001-9-1 loss: 0.269545  [   64/  265]
train() client id: f_00001-9-2 loss: 0.317780  [   96/  265]
train() client id: f_00001-9-3 loss: 0.359482  [  128/  265]
train() client id: f_00001-9-4 loss: 0.409219  [  160/  265]
train() client id: f_00001-9-5 loss: 0.334139  [  192/  265]
train() client id: f_00001-9-6 loss: 0.432848  [  224/  265]
train() client id: f_00001-9-7 loss: 0.293838  [  256/  265]
train() client id: f_00001-10-0 loss: 0.243856  [   32/  265]
train() client id: f_00001-10-1 loss: 0.258007  [   64/  265]
train() client id: f_00001-10-2 loss: 0.275766  [   96/  265]
train() client id: f_00001-10-3 loss: 0.448842  [  128/  265]
train() client id: f_00001-10-4 loss: 0.414913  [  160/  265]
train() client id: f_00001-10-5 loss: 0.373895  [  192/  265]
train() client id: f_00001-10-6 loss: 0.399486  [  224/  265]
train() client id: f_00001-10-7 loss: 0.421828  [  256/  265]
train() client id: f_00001-11-0 loss: 0.240287  [   32/  265]
train() client id: f_00001-11-1 loss: 0.392565  [   64/  265]
train() client id: f_00001-11-2 loss: 0.341880  [   96/  265]
train() client id: f_00001-11-3 loss: 0.338408  [  128/  265]
train() client id: f_00001-11-4 loss: 0.315922  [  160/  265]
train() client id: f_00001-11-5 loss: 0.469879  [  192/  265]
train() client id: f_00001-11-6 loss: 0.269918  [  224/  265]
train() client id: f_00001-11-7 loss: 0.444589  [  256/  265]
train() client id: f_00001-12-0 loss: 0.368749  [   32/  265]
train() client id: f_00001-12-1 loss: 0.345433  [   64/  265]
train() client id: f_00001-12-2 loss: 0.329552  [   96/  265]
train() client id: f_00001-12-3 loss: 0.444337  [  128/  265]
train() client id: f_00001-12-4 loss: 0.295549  [  160/  265]
train() client id: f_00001-12-5 loss: 0.317147  [  192/  265]
train() client id: f_00001-12-6 loss: 0.440907  [  224/  265]
train() client id: f_00001-12-7 loss: 0.269236  [  256/  265]
train() client id: f_00002-0-0 loss: 1.531266  [   32/  124]
train() client id: f_00002-0-1 loss: 1.310141  [   64/  124]
train() client id: f_00002-0-2 loss: 1.428154  [   96/  124]
train() client id: f_00002-1-0 loss: 1.304774  [   32/  124]
train() client id: f_00002-1-1 loss: 1.449906  [   64/  124]
train() client id: f_00002-1-2 loss: 1.200169  [   96/  124]
train() client id: f_00002-2-0 loss: 1.187205  [   32/  124]
train() client id: f_00002-2-1 loss: 1.462551  [   64/  124]
train() client id: f_00002-2-2 loss: 1.137473  [   96/  124]
train() client id: f_00002-3-0 loss: 1.226210  [   32/  124]
train() client id: f_00002-3-1 loss: 1.124233  [   64/  124]
train() client id: f_00002-3-2 loss: 1.245994  [   96/  124]
train() client id: f_00002-4-0 loss: 1.299156  [   32/  124]
train() client id: f_00002-4-1 loss: 1.195006  [   64/  124]
train() client id: f_00002-4-2 loss: 1.105388  [   96/  124]
train() client id: f_00002-5-0 loss: 1.113741  [   32/  124]
train() client id: f_00002-5-1 loss: 1.195561  [   64/  124]
train() client id: f_00002-5-2 loss: 1.320314  [   96/  124]
train() client id: f_00002-6-0 loss: 1.331957  [   32/  124]
train() client id: f_00002-6-1 loss: 1.166747  [   64/  124]
train() client id: f_00002-6-2 loss: 0.911106  [   96/  124]
train() client id: f_00002-7-0 loss: 1.272388  [   32/  124]
train() client id: f_00002-7-1 loss: 1.124474  [   64/  124]
train() client id: f_00002-7-2 loss: 1.118236  [   96/  124]
train() client id: f_00002-8-0 loss: 1.170477  [   32/  124]
train() client id: f_00002-8-1 loss: 0.993045  [   64/  124]
train() client id: f_00002-8-2 loss: 1.064797  [   96/  124]
train() client id: f_00002-9-0 loss: 1.098330  [   32/  124]
train() client id: f_00002-9-1 loss: 1.066011  [   64/  124]
train() client id: f_00002-9-2 loss: 1.118075  [   96/  124]
train() client id: f_00002-10-0 loss: 1.182047  [   32/  124]
train() client id: f_00002-10-1 loss: 1.073248  [   64/  124]
train() client id: f_00002-10-2 loss: 0.962304  [   96/  124]
train() client id: f_00002-11-0 loss: 1.040138  [   32/  124]
train() client id: f_00002-11-1 loss: 1.051850  [   64/  124]
train() client id: f_00002-11-2 loss: 1.171105  [   96/  124]
train() client id: f_00002-12-0 loss: 1.018888  [   32/  124]
train() client id: f_00002-12-1 loss: 1.127880  [   64/  124]
train() client id: f_00002-12-2 loss: 0.888602  [   96/  124]
train() client id: f_00003-0-0 loss: 0.471611  [   32/   43]
train() client id: f_00003-1-0 loss: 0.518773  [   32/   43]
train() client id: f_00003-2-0 loss: 0.569359  [   32/   43]
train() client id: f_00003-3-0 loss: 0.431043  [   32/   43]
train() client id: f_00003-4-0 loss: 0.478030  [   32/   43]
train() client id: f_00003-5-0 loss: 0.559782  [   32/   43]
train() client id: f_00003-6-0 loss: 0.458962  [   32/   43]
train() client id: f_00003-7-0 loss: 0.522203  [   32/   43]
train() client id: f_00003-8-0 loss: 0.666648  [   32/   43]
train() client id: f_00003-9-0 loss: 0.509981  [   32/   43]
train() client id: f_00003-10-0 loss: 0.553447  [   32/   43]
train() client id: f_00003-11-0 loss: 0.642162  [   32/   43]
train() client id: f_00003-12-0 loss: 0.602604  [   32/   43]
train() client id: f_00004-0-0 loss: 0.701243  [   32/  306]
train() client id: f_00004-0-1 loss: 0.772793  [   64/  306]
train() client id: f_00004-0-2 loss: 0.910580  [   96/  306]
train() client id: f_00004-0-3 loss: 0.696030  [  128/  306]
train() client id: f_00004-0-4 loss: 0.786768  [  160/  306]
train() client id: f_00004-0-5 loss: 0.563944  [  192/  306]
train() client id: f_00004-0-6 loss: 0.696702  [  224/  306]
train() client id: f_00004-0-7 loss: 0.734502  [  256/  306]
train() client id: f_00004-0-8 loss: 0.753517  [  288/  306]
train() client id: f_00004-1-0 loss: 0.654530  [   32/  306]
train() client id: f_00004-1-1 loss: 0.685042  [   64/  306]
train() client id: f_00004-1-2 loss: 0.870299  [   96/  306]
train() client id: f_00004-1-3 loss: 0.732583  [  128/  306]
train() client id: f_00004-1-4 loss: 0.750556  [  160/  306]
train() client id: f_00004-1-5 loss: 0.801424  [  192/  306]
train() client id: f_00004-1-6 loss: 0.689971  [  224/  306]
train() client id: f_00004-1-7 loss: 0.676039  [  256/  306]
train() client id: f_00004-1-8 loss: 0.814340  [  288/  306]
train() client id: f_00004-2-0 loss: 0.588449  [   32/  306]
train() client id: f_00004-2-1 loss: 0.644826  [   64/  306]
train() client id: f_00004-2-2 loss: 0.791700  [   96/  306]
train() client id: f_00004-2-3 loss: 0.721559  [  128/  306]
train() client id: f_00004-2-4 loss: 0.777401  [  160/  306]
train() client id: f_00004-2-5 loss: 0.824674  [  192/  306]
train() client id: f_00004-2-6 loss: 0.751320  [  224/  306]
train() client id: f_00004-2-7 loss: 0.694771  [  256/  306]
train() client id: f_00004-2-8 loss: 0.846767  [  288/  306]
train() client id: f_00004-3-0 loss: 0.652662  [   32/  306]
train() client id: f_00004-3-1 loss: 0.782507  [   64/  306]
train() client id: f_00004-3-2 loss: 0.683036  [   96/  306]
train() client id: f_00004-3-3 loss: 0.727588  [  128/  306]
train() client id: f_00004-3-4 loss: 0.792670  [  160/  306]
train() client id: f_00004-3-5 loss: 0.775256  [  192/  306]
train() client id: f_00004-3-6 loss: 0.708182  [  224/  306]
train() client id: f_00004-3-7 loss: 0.771212  [  256/  306]
train() client id: f_00004-3-8 loss: 0.735044  [  288/  306]
train() client id: f_00004-4-0 loss: 0.743345  [   32/  306]
train() client id: f_00004-4-1 loss: 0.691417  [   64/  306]
train() client id: f_00004-4-2 loss: 0.715419  [   96/  306]
train() client id: f_00004-4-3 loss: 0.741215  [  128/  306]
train() client id: f_00004-4-4 loss: 0.730269  [  160/  306]
train() client id: f_00004-4-5 loss: 0.812943  [  192/  306]
train() client id: f_00004-4-6 loss: 0.743270  [  224/  306]
train() client id: f_00004-4-7 loss: 0.700320  [  256/  306]
train() client id: f_00004-4-8 loss: 0.751795  [  288/  306]
train() client id: f_00004-5-0 loss: 0.641329  [   32/  306]
train() client id: f_00004-5-1 loss: 0.702155  [   64/  306]
train() client id: f_00004-5-2 loss: 0.555760  [   96/  306]
train() client id: f_00004-5-3 loss: 0.814684  [  128/  306]
train() client id: f_00004-5-4 loss: 0.780900  [  160/  306]
train() client id: f_00004-5-5 loss: 0.658876  [  192/  306]
train() client id: f_00004-5-6 loss: 0.617897  [  224/  306]
train() client id: f_00004-5-7 loss: 0.878110  [  256/  306]
train() client id: f_00004-5-8 loss: 0.880854  [  288/  306]
train() client id: f_00004-6-0 loss: 0.693719  [   32/  306]
train() client id: f_00004-6-1 loss: 0.763359  [   64/  306]
train() client id: f_00004-6-2 loss: 0.702401  [   96/  306]
train() client id: f_00004-6-3 loss: 0.657203  [  128/  306]
train() client id: f_00004-6-4 loss: 0.770283  [  160/  306]
train() client id: f_00004-6-5 loss: 0.860062  [  192/  306]
train() client id: f_00004-6-6 loss: 0.740376  [  224/  306]
train() client id: f_00004-6-7 loss: 0.698048  [  256/  306]
train() client id: f_00004-6-8 loss: 0.692572  [  288/  306]
train() client id: f_00004-7-0 loss: 0.688607  [   32/  306]
train() client id: f_00004-7-1 loss: 0.659095  [   64/  306]
train() client id: f_00004-7-2 loss: 0.650155  [   96/  306]
train() client id: f_00004-7-3 loss: 0.810124  [  128/  306]
train() client id: f_00004-7-4 loss: 0.646871  [  160/  306]
train() client id: f_00004-7-5 loss: 0.849126  [  192/  306]
train() client id: f_00004-7-6 loss: 0.810680  [  224/  306]
train() client id: f_00004-7-7 loss: 0.782245  [  256/  306]
train() client id: f_00004-7-8 loss: 0.780115  [  288/  306]
train() client id: f_00004-8-0 loss: 0.815999  [   32/  306]
train() client id: f_00004-8-1 loss: 0.789296  [   64/  306]
train() client id: f_00004-8-2 loss: 0.792927  [   96/  306]
train() client id: f_00004-8-3 loss: 0.648500  [  128/  306]
train() client id: f_00004-8-4 loss: 0.732456  [  160/  306]
train() client id: f_00004-8-5 loss: 0.696059  [  192/  306]
train() client id: f_00004-8-6 loss: 0.813844  [  224/  306]
train() client id: f_00004-8-7 loss: 0.663928  [  256/  306]
train() client id: f_00004-8-8 loss: 0.675008  [  288/  306]
train() client id: f_00004-9-0 loss: 0.837056  [   32/  306]
train() client id: f_00004-9-1 loss: 0.752640  [   64/  306]
train() client id: f_00004-9-2 loss: 0.687737  [   96/  306]
train() client id: f_00004-9-3 loss: 0.760355  [  128/  306]
train() client id: f_00004-9-4 loss: 0.693178  [  160/  306]
train() client id: f_00004-9-5 loss: 0.804880  [  192/  306]
train() client id: f_00004-9-6 loss: 0.765011  [  224/  306]
train() client id: f_00004-9-7 loss: 0.843861  [  256/  306]
train() client id: f_00004-9-8 loss: 0.617666  [  288/  306]
train() client id: f_00004-10-0 loss: 0.613348  [   32/  306]
train() client id: f_00004-10-1 loss: 0.650346  [   64/  306]
train() client id: f_00004-10-2 loss: 0.811738  [   96/  306]
train() client id: f_00004-10-3 loss: 0.897661  [  128/  306]
train() client id: f_00004-10-4 loss: 0.727288  [  160/  306]
train() client id: f_00004-10-5 loss: 0.819415  [  192/  306]
train() client id: f_00004-10-6 loss: 0.753721  [  224/  306]
train() client id: f_00004-10-7 loss: 0.687739  [  256/  306]
train() client id: f_00004-10-8 loss: 0.723189  [  288/  306]
train() client id: f_00004-11-0 loss: 0.857638  [   32/  306]
train() client id: f_00004-11-1 loss: 0.770375  [   64/  306]
train() client id: f_00004-11-2 loss: 0.714969  [   96/  306]
train() client id: f_00004-11-3 loss: 0.679358  [  128/  306]
train() client id: f_00004-11-4 loss: 0.770703  [  160/  306]
train() client id: f_00004-11-5 loss: 0.678987  [  192/  306]
train() client id: f_00004-11-6 loss: 0.771323  [  224/  306]
train() client id: f_00004-11-7 loss: 0.736261  [  256/  306]
train() client id: f_00004-11-8 loss: 0.751458  [  288/  306]
train() client id: f_00004-12-0 loss: 0.759898  [   32/  306]
train() client id: f_00004-12-1 loss: 0.781799  [   64/  306]
train() client id: f_00004-12-2 loss: 0.643215  [   96/  306]
train() client id: f_00004-12-3 loss: 0.723631  [  128/  306]
train() client id: f_00004-12-4 loss: 0.846423  [  160/  306]
train() client id: f_00004-12-5 loss: 0.852156  [  192/  306]
train() client id: f_00004-12-6 loss: 0.755231  [  224/  306]
train() client id: f_00004-12-7 loss: 0.710769  [  256/  306]
train() client id: f_00004-12-8 loss: 0.612381  [  288/  306]
train() client id: f_00005-0-0 loss: 0.622788  [   32/  146]
train() client id: f_00005-0-1 loss: 0.402317  [   64/  146]
train() client id: f_00005-0-2 loss: 0.580063  [   96/  146]
train() client id: f_00005-0-3 loss: 0.578009  [  128/  146]
train() client id: f_00005-1-0 loss: 0.388080  [   32/  146]
train() client id: f_00005-1-1 loss: 0.774005  [   64/  146]
train() client id: f_00005-1-2 loss: 0.761593  [   96/  146]
train() client id: f_00005-1-3 loss: 0.474703  [  128/  146]
train() client id: f_00005-2-0 loss: 0.549552  [   32/  146]
train() client id: f_00005-2-1 loss: 0.658576  [   64/  146]
train() client id: f_00005-2-2 loss: 0.510101  [   96/  146]
train() client id: f_00005-2-3 loss: 0.623465  [  128/  146]
train() client id: f_00005-3-0 loss: 0.505635  [   32/  146]
train() client id: f_00005-3-1 loss: 0.364125  [   64/  146]
train() client id: f_00005-3-2 loss: 0.694163  [   96/  146]
train() client id: f_00005-3-3 loss: 0.628236  [  128/  146]
train() client id: f_00005-4-0 loss: 0.454851  [   32/  146]
train() client id: f_00005-4-1 loss: 0.754531  [   64/  146]
train() client id: f_00005-4-2 loss: 0.556608  [   96/  146]
train() client id: f_00005-4-3 loss: 0.474252  [  128/  146]
train() client id: f_00005-5-0 loss: 0.721118  [   32/  146]
train() client id: f_00005-5-1 loss: 0.468443  [   64/  146]
train() client id: f_00005-5-2 loss: 0.774305  [   96/  146]
train() client id: f_00005-5-3 loss: 0.379389  [  128/  146]
train() client id: f_00005-6-0 loss: 0.645751  [   32/  146]
train() client id: f_00005-6-1 loss: 0.852639  [   64/  146]
train() client id: f_00005-6-2 loss: 0.532244  [   96/  146]
train() client id: f_00005-6-3 loss: 0.346128  [  128/  146]
train() client id: f_00005-7-0 loss: 0.596772  [   32/  146]
train() client id: f_00005-7-1 loss: 0.637923  [   64/  146]
train() client id: f_00005-7-2 loss: 0.668736  [   96/  146]
train() client id: f_00005-7-3 loss: 0.522565  [  128/  146]
train() client id: f_00005-8-0 loss: 0.572518  [   32/  146]
train() client id: f_00005-8-1 loss: 0.451338  [   64/  146]
train() client id: f_00005-8-2 loss: 0.713958  [   96/  146]
train() client id: f_00005-8-3 loss: 0.680837  [  128/  146]
train() client id: f_00005-9-0 loss: 0.843793  [   32/  146]
train() client id: f_00005-9-1 loss: 0.456004  [   64/  146]
train() client id: f_00005-9-2 loss: 0.550706  [   96/  146]
train() client id: f_00005-9-3 loss: 0.475708  [  128/  146]
train() client id: f_00005-10-0 loss: 0.403776  [   32/  146]
train() client id: f_00005-10-1 loss: 0.699372  [   64/  146]
train() client id: f_00005-10-2 loss: 0.427343  [   96/  146]
train() client id: f_00005-10-3 loss: 0.666095  [  128/  146]
train() client id: f_00005-11-0 loss: 0.712927  [   32/  146]
train() client id: f_00005-11-1 loss: 0.637375  [   64/  146]
train() client id: f_00005-11-2 loss: 0.610577  [   96/  146]
train() client id: f_00005-11-3 loss: 0.436589  [  128/  146]
train() client id: f_00005-12-0 loss: 0.856073  [   32/  146]
train() client id: f_00005-12-1 loss: 0.443183  [   64/  146]
train() client id: f_00005-12-2 loss: 0.570529  [   96/  146]
train() client id: f_00005-12-3 loss: 0.581651  [  128/  146]
train() client id: f_00006-0-0 loss: 0.553376  [   32/   54]
train() client id: f_00006-1-0 loss: 0.505434  [   32/   54]
train() client id: f_00006-2-0 loss: 0.526692  [   32/   54]
train() client id: f_00006-3-0 loss: 0.567812  [   32/   54]
train() client id: f_00006-4-0 loss: 0.521275  [   32/   54]
train() client id: f_00006-5-0 loss: 0.561586  [   32/   54]
train() client id: f_00006-6-0 loss: 0.462032  [   32/   54]
train() client id: f_00006-7-0 loss: 0.562663  [   32/   54]
train() client id: f_00006-8-0 loss: 0.491949  [   32/   54]
train() client id: f_00006-9-0 loss: 0.547676  [   32/   54]
train() client id: f_00006-10-0 loss: 0.561740  [   32/   54]
train() client id: f_00006-11-0 loss: 0.499467  [   32/   54]
train() client id: f_00006-12-0 loss: 0.470472  [   32/   54]
train() client id: f_00007-0-0 loss: 0.511991  [   32/  179]
train() client id: f_00007-0-1 loss: 0.486350  [   64/  179]
train() client id: f_00007-0-2 loss: 0.743815  [   96/  179]
train() client id: f_00007-0-3 loss: 0.422057  [  128/  179]
train() client id: f_00007-0-4 loss: 0.526218  [  160/  179]
train() client id: f_00007-1-0 loss: 0.700370  [   32/  179]
train() client id: f_00007-1-1 loss: 0.586367  [   64/  179]
train() client id: f_00007-1-2 loss: 0.429420  [   96/  179]
train() client id: f_00007-1-3 loss: 0.374510  [  128/  179]
train() client id: f_00007-1-4 loss: 0.465013  [  160/  179]
train() client id: f_00007-2-0 loss: 0.327308  [   32/  179]
train() client id: f_00007-2-1 loss: 0.580696  [   64/  179]
train() client id: f_00007-2-2 loss: 0.398390  [   96/  179]
train() client id: f_00007-2-3 loss: 0.497374  [  128/  179]
train() client id: f_00007-2-4 loss: 0.683689  [  160/  179]
train() client id: f_00007-3-0 loss: 0.443369  [   32/  179]
train() client id: f_00007-3-1 loss: 0.695199  [   64/  179]
train() client id: f_00007-3-2 loss: 0.411056  [   96/  179]
train() client id: f_00007-3-3 loss: 0.586198  [  128/  179]
train() client id: f_00007-3-4 loss: 0.385288  [  160/  179]
train() client id: f_00007-4-0 loss: 0.544224  [   32/  179]
train() client id: f_00007-4-1 loss: 0.353852  [   64/  179]
train() client id: f_00007-4-2 loss: 0.555276  [   96/  179]
train() client id: f_00007-4-3 loss: 0.520753  [  128/  179]
train() client id: f_00007-4-4 loss: 0.340630  [  160/  179]
train() client id: f_00007-5-0 loss: 0.689928  [   32/  179]
train() client id: f_00007-5-1 loss: 0.452130  [   64/  179]
train() client id: f_00007-5-2 loss: 0.482960  [   96/  179]
train() client id: f_00007-5-3 loss: 0.449288  [  128/  179]
train() client id: f_00007-5-4 loss: 0.432441  [  160/  179]
train() client id: f_00007-6-0 loss: 0.437323  [   32/  179]
train() client id: f_00007-6-1 loss: 0.416744  [   64/  179]
train() client id: f_00007-6-2 loss: 0.435053  [   96/  179]
train() client id: f_00007-6-3 loss: 0.611407  [  128/  179]
train() client id: f_00007-6-4 loss: 0.497973  [  160/  179]
train() client id: f_00007-7-0 loss: 0.409401  [   32/  179]
train() client id: f_00007-7-1 loss: 0.437835  [   64/  179]
train() client id: f_00007-7-2 loss: 0.471673  [   96/  179]
train() client id: f_00007-7-3 loss: 0.394987  [  128/  179]
train() client id: f_00007-7-4 loss: 0.499663  [  160/  179]
train() client id: f_00007-8-0 loss: 0.606268  [   32/  179]
train() client id: f_00007-8-1 loss: 0.442928  [   64/  179]
train() client id: f_00007-8-2 loss: 0.506976  [   96/  179]
train() client id: f_00007-8-3 loss: 0.322788  [  128/  179]
train() client id: f_00007-8-4 loss: 0.502882  [  160/  179]
train() client id: f_00007-9-0 loss: 0.664487  [   32/  179]
train() client id: f_00007-9-1 loss: 0.405346  [   64/  179]
train() client id: f_00007-9-2 loss: 0.455723  [   96/  179]
train() client id: f_00007-9-3 loss: 0.319868  [  128/  179]
train() client id: f_00007-9-4 loss: 0.520447  [  160/  179]
train() client id: f_00007-10-0 loss: 0.416074  [   32/  179]
train() client id: f_00007-10-1 loss: 0.434350  [   64/  179]
train() client id: f_00007-10-2 loss: 0.416843  [   96/  179]
train() client id: f_00007-10-3 loss: 0.511931  [  128/  179]
train() client id: f_00007-10-4 loss: 0.658732  [  160/  179]
train() client id: f_00007-11-0 loss: 0.563613  [   32/  179]
train() client id: f_00007-11-1 loss: 0.306336  [   64/  179]
train() client id: f_00007-11-2 loss: 0.531263  [   96/  179]
train() client id: f_00007-11-3 loss: 0.531082  [  128/  179]
train() client id: f_00007-11-4 loss: 0.441001  [  160/  179]
train() client id: f_00007-12-0 loss: 0.349032  [   32/  179]
train() client id: f_00007-12-1 loss: 0.495020  [   64/  179]
train() client id: f_00007-12-2 loss: 0.607331  [   96/  179]
train() client id: f_00007-12-3 loss: 0.408655  [  128/  179]
train() client id: f_00007-12-4 loss: 0.308327  [  160/  179]
train() client id: f_00008-0-0 loss: 0.732389  [   32/  130]
train() client id: f_00008-0-1 loss: 0.817436  [   64/  130]
train() client id: f_00008-0-2 loss: 0.728741  [   96/  130]
train() client id: f_00008-0-3 loss: 0.784735  [  128/  130]
train() client id: f_00008-1-0 loss: 0.794930  [   32/  130]
train() client id: f_00008-1-1 loss: 0.780958  [   64/  130]
train() client id: f_00008-1-2 loss: 0.780092  [   96/  130]
train() client id: f_00008-1-3 loss: 0.711633  [  128/  130]
train() client id: f_00008-2-0 loss: 0.621312  [   32/  130]
train() client id: f_00008-2-1 loss: 0.711598  [   64/  130]
train() client id: f_00008-2-2 loss: 0.814242  [   96/  130]
train() client id: f_00008-2-3 loss: 0.886671  [  128/  130]
train() client id: f_00008-3-0 loss: 0.706968  [   32/  130]
train() client id: f_00008-3-1 loss: 0.867302  [   64/  130]
train() client id: f_00008-3-2 loss: 0.616742  [   96/  130]
train() client id: f_00008-3-3 loss: 0.881615  [  128/  130]
train() client id: f_00008-4-0 loss: 0.819751  [   32/  130]
train() client id: f_00008-4-1 loss: 0.747411  [   64/  130]
train() client id: f_00008-4-2 loss: 0.681393  [   96/  130]
train() client id: f_00008-4-3 loss: 0.824006  [  128/  130]
train() client id: f_00008-5-0 loss: 0.748992  [   32/  130]
train() client id: f_00008-5-1 loss: 0.833339  [   64/  130]
train() client id: f_00008-5-2 loss: 0.702279  [   96/  130]
train() client id: f_00008-5-3 loss: 0.729606  [  128/  130]
train() client id: f_00008-6-0 loss: 0.833673  [   32/  130]
train() client id: f_00008-6-1 loss: 0.777690  [   64/  130]
train() client id: f_00008-6-2 loss: 0.694361  [   96/  130]
train() client id: f_00008-6-3 loss: 0.758916  [  128/  130]
train() client id: f_00008-7-0 loss: 0.699649  [   32/  130]
train() client id: f_00008-7-1 loss: 0.732613  [   64/  130]
train() client id: f_00008-7-2 loss: 0.775928  [   96/  130]
train() client id: f_00008-7-3 loss: 0.868931  [  128/  130]
train() client id: f_00008-8-0 loss: 0.774915  [   32/  130]
train() client id: f_00008-8-1 loss: 0.680646  [   64/  130]
train() client id: f_00008-8-2 loss: 0.832080  [   96/  130]
train() client id: f_00008-8-3 loss: 0.795476  [  128/  130]
train() client id: f_00008-9-0 loss: 0.747610  [   32/  130]
train() client id: f_00008-9-1 loss: 0.781361  [   64/  130]
train() client id: f_00008-9-2 loss: 0.809863  [   96/  130]
train() client id: f_00008-9-3 loss: 0.710506  [  128/  130]
train() client id: f_00008-10-0 loss: 0.736278  [   32/  130]
train() client id: f_00008-10-1 loss: 0.704853  [   64/  130]
train() client id: f_00008-10-2 loss: 0.746388  [   96/  130]
train() client id: f_00008-10-3 loss: 0.890236  [  128/  130]
train() client id: f_00008-11-0 loss: 0.722761  [   32/  130]
train() client id: f_00008-11-1 loss: 0.743003  [   64/  130]
train() client id: f_00008-11-2 loss: 0.866628  [   96/  130]
train() client id: f_00008-11-3 loss: 0.741347  [  128/  130]
train() client id: f_00008-12-0 loss: 0.822656  [   32/  130]
train() client id: f_00008-12-1 loss: 0.817531  [   64/  130]
train() client id: f_00008-12-2 loss: 0.639986  [   96/  130]
train() client id: f_00008-12-3 loss: 0.766357  [  128/  130]
train() client id: f_00009-0-0 loss: 1.074013  [   32/  118]
train() client id: f_00009-0-1 loss: 1.045032  [   64/  118]
train() client id: f_00009-0-2 loss: 1.059234  [   96/  118]
train() client id: f_00009-1-0 loss: 1.045404  [   32/  118]
train() client id: f_00009-1-1 loss: 1.041036  [   64/  118]
train() client id: f_00009-1-2 loss: 0.949693  [   96/  118]
train() client id: f_00009-2-0 loss: 1.000455  [   32/  118]
train() client id: f_00009-2-1 loss: 1.028162  [   64/  118]
train() client id: f_00009-2-2 loss: 0.828572  [   96/  118]
train() client id: f_00009-3-0 loss: 0.915776  [   32/  118]
train() client id: f_00009-3-1 loss: 0.724804  [   64/  118]
train() client id: f_00009-3-2 loss: 1.036191  [   96/  118]
train() client id: f_00009-4-0 loss: 0.959170  [   32/  118]
train() client id: f_00009-4-1 loss: 0.840198  [   64/  118]
train() client id: f_00009-4-2 loss: 0.916998  [   96/  118]
train() client id: f_00009-5-0 loss: 0.764455  [   32/  118]
train() client id: f_00009-5-1 loss: 0.811909  [   64/  118]
train() client id: f_00009-5-2 loss: 1.031832  [   96/  118]
train() client id: f_00009-6-0 loss: 0.829314  [   32/  118]
train() client id: f_00009-6-1 loss: 0.774691  [   64/  118]
train() client id: f_00009-6-2 loss: 0.851040  [   96/  118]
train() client id: f_00009-7-0 loss: 0.862908  [   32/  118]
train() client id: f_00009-7-1 loss: 0.772220  [   64/  118]
train() client id: f_00009-7-2 loss: 0.889908  [   96/  118]
train() client id: f_00009-8-0 loss: 0.924928  [   32/  118]
train() client id: f_00009-8-1 loss: 0.821627  [   64/  118]
train() client id: f_00009-8-2 loss: 0.804886  [   96/  118]
train() client id: f_00009-9-0 loss: 0.813641  [   32/  118]
train() client id: f_00009-9-1 loss: 0.742874  [   64/  118]
train() client id: f_00009-9-2 loss: 0.897229  [   96/  118]
train() client id: f_00009-10-0 loss: 0.969934  [   32/  118]
train() client id: f_00009-10-1 loss: 0.794354  [   64/  118]
train() client id: f_00009-10-2 loss: 0.731814  [   96/  118]
train() client id: f_00009-11-0 loss: 0.700718  [   32/  118]
train() client id: f_00009-11-1 loss: 0.901632  [   64/  118]
train() client id: f_00009-11-2 loss: 0.844641  [   96/  118]
train() client id: f_00009-12-0 loss: 0.855139  [   32/  118]
train() client id: f_00009-12-1 loss: 0.835068  [   64/  118]
train() client id: f_00009-12-2 loss: 0.763703  [   96/  118]
At round 35 accuracy: 0.6472148541114059
At round 35 training accuracy: 0.5928906773977196
At round 35 training loss: 0.8230030892780369
gradient difference: 0.4805580973625183
train() client id: f_00000-0-0 loss: 1.192660  [   32/  126]
train() client id: f_00000-0-1 loss: 1.143577  [   64/  126]
train() client id: f_00000-0-2 loss: 1.075262  [   96/  126]
train() client id: f_00000-1-0 loss: 0.998253  [   32/  126]
train() client id: f_00000-1-1 loss: 1.193337  [   64/  126]
train() client id: f_00000-1-2 loss: 1.054726  [   96/  126]
train() client id: f_00000-2-0 loss: 0.925349  [   32/  126]
train() client id: f_00000-2-1 loss: 0.969157  [   64/  126]
train() client id: f_00000-2-2 loss: 0.889450  [   96/  126]
train() client id: f_00000-3-0 loss: 0.862392  [   32/  126]
train() client id: f_00000-3-1 loss: 1.106705  [   64/  126]
train() client id: f_00000-3-2 loss: 0.804522  [   96/  126]
train() client id: f_00000-4-0 loss: 0.925216  [   32/  126]
train() client id: f_00000-4-1 loss: 0.824268  [   64/  126]
train() client id: f_00000-4-2 loss: 0.935746  [   96/  126]
train() client id: f_00000-5-0 loss: 0.838477  [   32/  126]
train() client id: f_00000-5-1 loss: 0.805062  [   64/  126]
train() client id: f_00000-5-2 loss: 0.965876  [   96/  126]
train() client id: f_00000-6-0 loss: 0.779321  [   32/  126]
train() client id: f_00000-6-1 loss: 0.906598  [   64/  126]
train() client id: f_00000-6-2 loss: 0.884858  [   96/  126]
train() client id: f_00000-7-0 loss: 0.931929  [   32/  126]
train() client id: f_00000-7-1 loss: 0.726094  [   64/  126]
train() client id: f_00000-7-2 loss: 0.897270  [   96/  126]
train() client id: f_00000-8-0 loss: 0.652705  [   32/  126]
train() client id: f_00000-8-1 loss: 0.930702  [   64/  126]
train() client id: f_00000-8-2 loss: 0.946734  [   96/  126]
train() client id: f_00000-9-0 loss: 0.814569  [   32/  126]
train() client id: f_00000-9-1 loss: 0.799538  [   64/  126]
train() client id: f_00000-9-2 loss: 0.901264  [   96/  126]
train() client id: f_00000-10-0 loss: 0.934566  [   32/  126]
train() client id: f_00000-10-1 loss: 0.885997  [   64/  126]
train() client id: f_00000-10-2 loss: 0.787996  [   96/  126]
train() client id: f_00000-11-0 loss: 0.895183  [   32/  126]
train() client id: f_00000-11-1 loss: 0.923418  [   64/  126]
train() client id: f_00000-11-2 loss: 0.853952  [   96/  126]
train() client id: f_00000-12-0 loss: 0.835212  [   32/  126]
train() client id: f_00000-12-1 loss: 0.835643  [   64/  126]
train() client id: f_00000-12-2 loss: 0.923192  [   96/  126]
train() client id: f_00001-0-0 loss: 0.584026  [   32/  265]
train() client id: f_00001-0-1 loss: 0.426882  [   64/  265]
train() client id: f_00001-0-2 loss: 0.472157  [   96/  265]
train() client id: f_00001-0-3 loss: 0.547786  [  128/  265]
train() client id: f_00001-0-4 loss: 0.418528  [  160/  265]
train() client id: f_00001-0-5 loss: 0.513921  [  192/  265]
train() client id: f_00001-0-6 loss: 0.513235  [  224/  265]
train() client id: f_00001-0-7 loss: 0.575008  [  256/  265]
train() client id: f_00001-1-0 loss: 0.429635  [   32/  265]
train() client id: f_00001-1-1 loss: 0.473028  [   64/  265]
train() client id: f_00001-1-2 loss: 0.458852  [   96/  265]
train() client id: f_00001-1-3 loss: 0.542204  [  128/  265]
train() client id: f_00001-1-4 loss: 0.430283  [  160/  265]
train() client id: f_00001-1-5 loss: 0.603717  [  192/  265]
train() client id: f_00001-1-6 loss: 0.470393  [  224/  265]
train() client id: f_00001-1-7 loss: 0.593203  [  256/  265]
train() client id: f_00001-2-0 loss: 0.526725  [   32/  265]
train() client id: f_00001-2-1 loss: 0.437430  [   64/  265]
train() client id: f_00001-2-2 loss: 0.496332  [   96/  265]
train() client id: f_00001-2-3 loss: 0.393778  [  128/  265]
train() client id: f_00001-2-4 loss: 0.507923  [  160/  265]
train() client id: f_00001-2-5 loss: 0.392290  [  192/  265]
train() client id: f_00001-2-6 loss: 0.714513  [  224/  265]
train() client id: f_00001-2-7 loss: 0.411797  [  256/  265]
train() client id: f_00001-3-0 loss: 0.505854  [   32/  265]
train() client id: f_00001-3-1 loss: 0.656044  [   64/  265]
train() client id: f_00001-3-2 loss: 0.452321  [   96/  265]
train() client id: f_00001-3-3 loss: 0.482575  [  128/  265]
train() client id: f_00001-3-4 loss: 0.489695  [  160/  265]
train() client id: f_00001-3-5 loss: 0.491136  [  192/  265]
train() client id: f_00001-3-6 loss: 0.404793  [  224/  265]
train() client id: f_00001-3-7 loss: 0.448652  [  256/  265]
train() client id: f_00001-4-0 loss: 0.522437  [   32/  265]
train() client id: f_00001-4-1 loss: 0.522749  [   64/  265]
train() client id: f_00001-4-2 loss: 0.437344  [   96/  265]
train() client id: f_00001-4-3 loss: 0.447094  [  128/  265]
train() client id: f_00001-4-4 loss: 0.464683  [  160/  265]
train() client id: f_00001-4-5 loss: 0.447341  [  192/  265]
train() client id: f_00001-4-6 loss: 0.509935  [  224/  265]
train() client id: f_00001-4-7 loss: 0.512612  [  256/  265]
train() client id: f_00001-5-0 loss: 0.438435  [   32/  265]
train() client id: f_00001-5-1 loss: 0.409670  [   64/  265]
train() client id: f_00001-5-2 loss: 0.469591  [   96/  265]
train() client id: f_00001-5-3 loss: 0.648230  [  128/  265]
train() client id: f_00001-5-4 loss: 0.477867  [  160/  265]
train() client id: f_00001-5-5 loss: 0.476561  [  192/  265]
train() client id: f_00001-5-6 loss: 0.490309  [  224/  265]
train() client id: f_00001-5-7 loss: 0.478912  [  256/  265]
train() client id: f_00001-6-0 loss: 0.447573  [   32/  265]
train() client id: f_00001-6-1 loss: 0.472767  [   64/  265]
train() client id: f_00001-6-2 loss: 0.530105  [   96/  265]
train() client id: f_00001-6-3 loss: 0.618472  [  128/  265]
train() client id: f_00001-6-4 loss: 0.416252  [  160/  265]
train() client id: f_00001-6-5 loss: 0.477965  [  192/  265]
train() client id: f_00001-6-6 loss: 0.388218  [  224/  265]
train() client id: f_00001-6-7 loss: 0.472780  [  256/  265]
train() client id: f_00001-7-0 loss: 0.620419  [   32/  265]
train() client id: f_00001-7-1 loss: 0.368906  [   64/  265]
train() client id: f_00001-7-2 loss: 0.539810  [   96/  265]
train() client id: f_00001-7-3 loss: 0.527428  [  128/  265]
train() client id: f_00001-7-4 loss: 0.470893  [  160/  265]
train() client id: f_00001-7-5 loss: 0.487524  [  192/  265]
train() client id: f_00001-7-6 loss: 0.399920  [  224/  265]
train() client id: f_00001-7-7 loss: 0.452615  [  256/  265]
train() client id: f_00001-8-0 loss: 0.569466  [   32/  265]
train() client id: f_00001-8-1 loss: 0.532923  [   64/  265]
train() client id: f_00001-8-2 loss: 0.517746  [   96/  265]
train() client id: f_00001-8-3 loss: 0.372461  [  128/  265]
train() client id: f_00001-8-4 loss: 0.646613  [  160/  265]
train() client id: f_00001-8-5 loss: 0.377825  [  192/  265]
train() client id: f_00001-8-6 loss: 0.437203  [  224/  265]
train() client id: f_00001-8-7 loss: 0.412848  [  256/  265]
train() client id: f_00001-9-0 loss: 0.479688  [   32/  265]
train() client id: f_00001-9-1 loss: 0.474072  [   64/  265]
train() client id: f_00001-9-2 loss: 0.447641  [   96/  265]
train() client id: f_00001-9-3 loss: 0.527996  [  128/  265]
train() client id: f_00001-9-4 loss: 0.460291  [  160/  265]
train() client id: f_00001-9-5 loss: 0.370479  [  192/  265]
train() client id: f_00001-9-6 loss: 0.569938  [  224/  265]
train() client id: f_00001-9-7 loss: 0.443200  [  256/  265]
train() client id: f_00001-10-0 loss: 0.455013  [   32/  265]
train() client id: f_00001-10-1 loss: 0.419112  [   64/  265]
train() client id: f_00001-10-2 loss: 0.481909  [   96/  265]
train() client id: f_00001-10-3 loss: 0.517194  [  128/  265]
train() client id: f_00001-10-4 loss: 0.494904  [  160/  265]
train() client id: f_00001-10-5 loss: 0.382106  [  192/  265]
train() client id: f_00001-10-6 loss: 0.475629  [  224/  265]
train() client id: f_00001-10-7 loss: 0.617072  [  256/  265]
train() client id: f_00001-11-0 loss: 0.484659  [   32/  265]
train() client id: f_00001-11-1 loss: 0.477122  [   64/  265]
train() client id: f_00001-11-2 loss: 0.487135  [   96/  265]
train() client id: f_00001-11-3 loss: 0.561122  [  128/  265]
train() client id: f_00001-11-4 loss: 0.550281  [  160/  265]
train() client id: f_00001-11-5 loss: 0.395205  [  192/  265]
train() client id: f_00001-11-6 loss: 0.450369  [  224/  265]
train() client id: f_00001-11-7 loss: 0.459131  [  256/  265]
train() client id: f_00001-12-0 loss: 0.585229  [   32/  265]
train() client id: f_00001-12-1 loss: 0.452426  [   64/  265]
train() client id: f_00001-12-2 loss: 0.524622  [   96/  265]
train() client id: f_00001-12-3 loss: 0.418734  [  128/  265]
train() client id: f_00001-12-4 loss: 0.374197  [  160/  265]
train() client id: f_00001-12-5 loss: 0.387108  [  192/  265]
train() client id: f_00001-12-6 loss: 0.547321  [  224/  265]
train() client id: f_00001-12-7 loss: 0.483204  [  256/  265]
train() client id: f_00002-0-0 loss: 1.215030  [   32/  124]
train() client id: f_00002-0-1 loss: 1.352266  [   64/  124]
train() client id: f_00002-0-2 loss: 1.301850  [   96/  124]
train() client id: f_00002-1-0 loss: 1.313345  [   32/  124]
train() client id: f_00002-1-1 loss: 1.283611  [   64/  124]
train() client id: f_00002-1-2 loss: 1.290527  [   96/  124]
train() client id: f_00002-2-0 loss: 1.270465  [   32/  124]
train() client id: f_00002-2-1 loss: 1.123768  [   64/  124]
train() client id: f_00002-2-2 loss: 1.268296  [   96/  124]
train() client id: f_00002-3-0 loss: 1.323984  [   32/  124]
train() client id: f_00002-3-1 loss: 1.247442  [   64/  124]
train() client id: f_00002-3-2 loss: 1.097310  [   96/  124]
train() client id: f_00002-4-0 loss: 1.078409  [   32/  124]
train() client id: f_00002-4-1 loss: 1.329719  [   64/  124]
train() client id: f_00002-4-2 loss: 1.298927  [   96/  124]
train() client id: f_00002-5-0 loss: 1.262344  [   32/  124]
train() client id: f_00002-5-1 loss: 1.120397  [   64/  124]
train() client id: f_00002-5-2 loss: 1.227144  [   96/  124]
train() client id: f_00002-6-0 loss: 1.423018  [   32/  124]
train() client id: f_00002-6-1 loss: 1.063474  [   64/  124]
train() client id: f_00002-6-2 loss: 1.045845  [   96/  124]
train() client id: f_00002-7-0 loss: 1.133220  [   32/  124]
train() client id: f_00002-7-1 loss: 1.087077  [   64/  124]
train() client id: f_00002-7-2 loss: 1.176135  [   96/  124]
train() client id: f_00002-8-0 loss: 1.161648  [   32/  124]
train() client id: f_00002-8-1 loss: 1.291220  [   64/  124]
train() client id: f_00002-8-2 loss: 1.157761  [   96/  124]
train() client id: f_00002-9-0 loss: 1.048162  [   32/  124]
train() client id: f_00002-9-1 loss: 1.130998  [   64/  124]
train() client id: f_00002-9-2 loss: 1.277185  [   96/  124]
train() client id: f_00002-10-0 loss: 1.283024  [   32/  124]
train() client id: f_00002-10-1 loss: 1.098743  [   64/  124]
train() client id: f_00002-10-2 loss: 1.161006  [   96/  124]
train() client id: f_00002-11-0 loss: 1.127042  [   32/  124]
train() client id: f_00002-11-1 loss: 1.233672  [   64/  124]
train() client id: f_00002-11-2 loss: 1.062389  [   96/  124]
train() client id: f_00002-12-0 loss: 1.242270  [   32/  124]
train() client id: f_00002-12-1 loss: 1.215533  [   64/  124]
train() client id: f_00002-12-2 loss: 0.959903  [   96/  124]
train() client id: f_00003-0-0 loss: 0.661176  [   32/   43]
train() client id: f_00003-1-0 loss: 0.586419  [   32/   43]
train() client id: f_00003-2-0 loss: 0.564572  [   32/   43]
train() client id: f_00003-3-0 loss: 0.731443  [   32/   43]
train() client id: f_00003-4-0 loss: 0.561038  [   32/   43]
train() client id: f_00003-5-0 loss: 0.513329  [   32/   43]
train() client id: f_00003-6-0 loss: 0.603446  [   32/   43]
train() client id: f_00003-7-0 loss: 0.702988  [   32/   43]
train() client id: f_00003-8-0 loss: 0.657751  [   32/   43]
train() client id: f_00003-9-0 loss: 0.444988  [   32/   43]
train() client id: f_00003-10-0 loss: 0.803110  [   32/   43]
train() client id: f_00003-11-0 loss: 0.609062  [   32/   43]
train() client id: f_00003-12-0 loss: 0.816784  [   32/   43]
train() client id: f_00004-0-0 loss: 0.945955  [   32/  306]
train() client id: f_00004-0-1 loss: 0.944825  [   64/  306]
train() client id: f_00004-0-2 loss: 0.981789  [   96/  306]
train() client id: f_00004-0-3 loss: 0.981056  [  128/  306]
train() client id: f_00004-0-4 loss: 1.064183  [  160/  306]
train() client id: f_00004-0-5 loss: 0.893452  [  192/  306]
train() client id: f_00004-0-6 loss: 0.801020  [  224/  306]
train() client id: f_00004-0-7 loss: 1.063265  [  256/  306]
train() client id: f_00004-0-8 loss: 0.907457  [  288/  306]
train() client id: f_00004-1-0 loss: 0.916064  [   32/  306]
train() client id: f_00004-1-1 loss: 0.977064  [   64/  306]
train() client id: f_00004-1-2 loss: 0.980519  [   96/  306]
train() client id: f_00004-1-3 loss: 0.759132  [  128/  306]
train() client id: f_00004-1-4 loss: 1.030122  [  160/  306]
train() client id: f_00004-1-5 loss: 1.062115  [  192/  306]
train() client id: f_00004-1-6 loss: 1.033017  [  224/  306]
train() client id: f_00004-1-7 loss: 0.883955  [  256/  306]
train() client id: f_00004-1-8 loss: 0.922048  [  288/  306]
train() client id: f_00004-2-0 loss: 1.001105  [   32/  306]
train() client id: f_00004-2-1 loss: 0.973260  [   64/  306]
train() client id: f_00004-2-2 loss: 0.878827  [   96/  306]
train() client id: f_00004-2-3 loss: 1.004185  [  128/  306]
train() client id: f_00004-2-4 loss: 1.101562  [  160/  306]
train() client id: f_00004-2-5 loss: 1.037387  [  192/  306]
train() client id: f_00004-2-6 loss: 0.881814  [  224/  306]
train() client id: f_00004-2-7 loss: 0.818858  [  256/  306]
train() client id: f_00004-2-8 loss: 0.867525  [  288/  306]
train() client id: f_00004-3-0 loss: 0.864434  [   32/  306]
train() client id: f_00004-3-1 loss: 1.048198  [   64/  306]
train() client id: f_00004-3-2 loss: 1.112346  [   96/  306]
train() client id: f_00004-3-3 loss: 0.801038  [  128/  306]
train() client id: f_00004-3-4 loss: 1.023817  [  160/  306]
train() client id: f_00004-3-5 loss: 0.898859  [  192/  306]
train() client id: f_00004-3-6 loss: 0.947092  [  224/  306]
train() client id: f_00004-3-7 loss: 1.018547  [  256/  306]
train() client id: f_00004-3-8 loss: 0.918270  [  288/  306]
train() client id: f_00004-4-0 loss: 0.950657  [   32/  306]
train() client id: f_00004-4-1 loss: 0.833854  [   64/  306]
train() client id: f_00004-4-2 loss: 1.057161  [   96/  306]
train() client id: f_00004-4-3 loss: 0.929378  [  128/  306]
train() client id: f_00004-4-4 loss: 0.829709  [  160/  306]
train() client id: f_00004-4-5 loss: 0.997706  [  192/  306]
train() client id: f_00004-4-6 loss: 0.998975  [  224/  306]
train() client id: f_00004-4-7 loss: 0.836325  [  256/  306]
train() client id: f_00004-4-8 loss: 1.013813  [  288/  306]
train() client id: f_00004-5-0 loss: 0.909041  [   32/  306]
train() client id: f_00004-5-1 loss: 0.983262  [   64/  306]
train() client id: f_00004-5-2 loss: 1.024434  [   96/  306]
train() client id: f_00004-5-3 loss: 0.896253  [  128/  306]
train() client id: f_00004-5-4 loss: 0.877752  [  160/  306]
train() client id: f_00004-5-5 loss: 0.979035  [  192/  306]
train() client id: f_00004-5-6 loss: 0.877043  [  224/  306]
train() client id: f_00004-5-7 loss: 0.882156  [  256/  306]
train() client id: f_00004-5-8 loss: 1.050577  [  288/  306]
train() client id: f_00004-6-0 loss: 0.892552  [   32/  306]
train() client id: f_00004-6-1 loss: 1.034727  [   64/  306]
train() client id: f_00004-6-2 loss: 1.122812  [   96/  306]
train() client id: f_00004-6-3 loss: 0.942483  [  128/  306]
train() client id: f_00004-6-4 loss: 0.867442  [  160/  306]
train() client id: f_00004-6-5 loss: 0.963236  [  192/  306]
train() client id: f_00004-6-6 loss: 0.889163  [  224/  306]
train() client id: f_00004-6-7 loss: 0.888086  [  256/  306]
train() client id: f_00004-6-8 loss: 0.863128  [  288/  306]
train() client id: f_00004-7-0 loss: 0.939682  [   32/  306]
train() client id: f_00004-7-1 loss: 0.865150  [   64/  306]
train() client id: f_00004-7-2 loss: 0.957997  [   96/  306]
train() client id: f_00004-7-3 loss: 1.105380  [  128/  306]
train() client id: f_00004-7-4 loss: 0.942753  [  160/  306]
train() client id: f_00004-7-5 loss: 0.960554  [  192/  306]
train() client id: f_00004-7-6 loss: 0.858711  [  224/  306]
train() client id: f_00004-7-7 loss: 1.130103  [  256/  306]
train() client id: f_00004-7-8 loss: 0.781849  [  288/  306]
train() client id: f_00004-8-0 loss: 0.982126  [   32/  306]
train() client id: f_00004-8-1 loss: 0.873163  [   64/  306]
train() client id: f_00004-8-2 loss: 1.030303  [   96/  306]
train() client id: f_00004-8-3 loss: 0.899125  [  128/  306]
train() client id: f_00004-8-4 loss: 0.813866  [  160/  306]
train() client id: f_00004-8-5 loss: 0.968923  [  192/  306]
train() client id: f_00004-8-6 loss: 0.992887  [  224/  306]
train() client id: f_00004-8-7 loss: 0.844289  [  256/  306]
train() client id: f_00004-8-8 loss: 1.026391  [  288/  306]
train() client id: f_00004-9-0 loss: 0.947926  [   32/  306]
train() client id: f_00004-9-1 loss: 0.885399  [   64/  306]
train() client id: f_00004-9-2 loss: 0.856518  [   96/  306]
train() client id: f_00004-9-3 loss: 1.012987  [  128/  306]
train() client id: f_00004-9-4 loss: 0.850568  [  160/  306]
train() client id: f_00004-9-5 loss: 0.978580  [  192/  306]
train() client id: f_00004-9-6 loss: 1.070305  [  224/  306]
train() client id: f_00004-9-7 loss: 0.898610  [  256/  306]
train() client id: f_00004-9-8 loss: 0.907414  [  288/  306]
train() client id: f_00004-10-0 loss: 0.940595  [   32/  306]
train() client id: f_00004-10-1 loss: 0.978223  [   64/  306]
train() client id: f_00004-10-2 loss: 1.041729  [   96/  306]
train() client id: f_00004-10-3 loss: 0.921855  [  128/  306]
train() client id: f_00004-10-4 loss: 1.023571  [  160/  306]
train() client id: f_00004-10-5 loss: 0.915324  [  192/  306]
train() client id: f_00004-10-6 loss: 0.885079  [  224/  306]
train() client id: f_00004-10-7 loss: 0.886029  [  256/  306]
train() client id: f_00004-10-8 loss: 0.812120  [  288/  306]
train() client id: f_00004-11-0 loss: 0.808805  [   32/  306]
train() client id: f_00004-11-1 loss: 0.903649  [   64/  306]
train() client id: f_00004-11-2 loss: 0.919501  [   96/  306]
train() client id: f_00004-11-3 loss: 0.919378  [  128/  306]
train() client id: f_00004-11-4 loss: 0.912923  [  160/  306]
train() client id: f_00004-11-5 loss: 1.020533  [  192/  306]
train() client id: f_00004-11-6 loss: 0.951892  [  224/  306]
train() client id: f_00004-11-7 loss: 0.950664  [  256/  306]
train() client id: f_00004-11-8 loss: 1.042450  [  288/  306]
train() client id: f_00004-12-0 loss: 0.792902  [   32/  306]
train() client id: f_00004-12-1 loss: 0.891074  [   64/  306]
train() client id: f_00004-12-2 loss: 1.026294  [   96/  306]
train() client id: f_00004-12-3 loss: 0.854321  [  128/  306]
train() client id: f_00004-12-4 loss: 0.816740  [  160/  306]
train() client id: f_00004-12-5 loss: 0.906645  [  192/  306]
train() client id: f_00004-12-6 loss: 1.031676  [  224/  306]
train() client id: f_00004-12-7 loss: 0.998789  [  256/  306]
train() client id: f_00004-12-8 loss: 1.059636  [  288/  306]
train() client id: f_00005-0-0 loss: 0.355578  [   32/  146]
train() client id: f_00005-0-1 loss: 0.632424  [   64/  146]
train() client id: f_00005-0-2 loss: 0.597190  [   96/  146]
train() client id: f_00005-0-3 loss: 0.563906  [  128/  146]
train() client id: f_00005-1-0 loss: 0.517640  [   32/  146]
train() client id: f_00005-1-1 loss: 0.514370  [   64/  146]
train() client id: f_00005-1-2 loss: 0.695700  [   96/  146]
train() client id: f_00005-1-3 loss: 0.446012  [  128/  146]
train() client id: f_00005-2-0 loss: 0.501819  [   32/  146]
train() client id: f_00005-2-1 loss: 0.607157  [   64/  146]
train() client id: f_00005-2-2 loss: 0.549585  [   96/  146]
train() client id: f_00005-2-3 loss: 0.436075  [  128/  146]
train() client id: f_00005-3-0 loss: 0.680844  [   32/  146]
train() client id: f_00005-3-1 loss: 0.520074  [   64/  146]
train() client id: f_00005-3-2 loss: 0.552981  [   96/  146]
train() client id: f_00005-3-3 loss: 0.442011  [  128/  146]
train() client id: f_00005-4-0 loss: 0.558100  [   32/  146]
train() client id: f_00005-4-1 loss: 0.766553  [   64/  146]
train() client id: f_00005-4-2 loss: 0.277915  [   96/  146]
train() client id: f_00005-4-3 loss: 0.641639  [  128/  146]
train() client id: f_00005-5-0 loss: 0.718433  [   32/  146]
train() client id: f_00005-5-1 loss: 0.490337  [   64/  146]
train() client id: f_00005-5-2 loss: 0.516640  [   96/  146]
train() client id: f_00005-5-3 loss: 0.487614  [  128/  146]
train() client id: f_00005-6-0 loss: 0.674927  [   32/  146]
train() client id: f_00005-6-1 loss: 0.698085  [   64/  146]
train() client id: f_00005-6-2 loss: 0.293264  [   96/  146]
train() client id: f_00005-6-3 loss: 0.666696  [  128/  146]
train() client id: f_00005-7-0 loss: 0.463732  [   32/  146]
train() client id: f_00005-7-1 loss: 0.746534  [   64/  146]
train() client id: f_00005-7-2 loss: 0.506482  [   96/  146]
train() client id: f_00005-7-3 loss: 0.570120  [  128/  146]
train() client id: f_00005-8-0 loss: 0.546802  [   32/  146]
train() client id: f_00005-8-1 loss: 0.623306  [   64/  146]
train() client id: f_00005-8-2 loss: 0.565284  [   96/  146]
train() client id: f_00005-8-3 loss: 0.462486  [  128/  146]
train() client id: f_00005-9-0 loss: 0.332090  [   32/  146]
train() client id: f_00005-9-1 loss: 0.839154  [   64/  146]
train() client id: f_00005-9-2 loss: 0.400138  [   96/  146]
train() client id: f_00005-9-3 loss: 0.669714  [  128/  146]
train() client id: f_00005-10-0 loss: 0.744622  [   32/  146]
train() client id: f_00005-10-1 loss: 0.433614  [   64/  146]
train() client id: f_00005-10-2 loss: 0.513266  [   96/  146]
train() client id: f_00005-10-3 loss: 0.573829  [  128/  146]
train() client id: f_00005-11-0 loss: 0.423698  [   32/  146]
train() client id: f_00005-11-1 loss: 0.801472  [   64/  146]
train() client id: f_00005-11-2 loss: 0.527117  [   96/  146]
train() client id: f_00005-11-3 loss: 0.600046  [  128/  146]
train() client id: f_00005-12-0 loss: 0.585416  [   32/  146]
train() client id: f_00005-12-1 loss: 0.657227  [   64/  146]
train() client id: f_00005-12-2 loss: 0.317000  [   96/  146]
train() client id: f_00005-12-3 loss: 0.648058  [  128/  146]
train() client id: f_00006-0-0 loss: 0.597997  [   32/   54]
train() client id: f_00006-1-0 loss: 0.587844  [   32/   54]
train() client id: f_00006-2-0 loss: 0.596614  [   32/   54]
train() client id: f_00006-3-0 loss: 0.550833  [   32/   54]
train() client id: f_00006-4-0 loss: 0.551354  [   32/   54]
train() client id: f_00006-5-0 loss: 0.530612  [   32/   54]
train() client id: f_00006-6-0 loss: 0.492436  [   32/   54]
train() client id: f_00006-7-0 loss: 0.579063  [   32/   54]
train() client id: f_00006-8-0 loss: 0.554168  [   32/   54]
train() client id: f_00006-9-0 loss: 0.548189  [   32/   54]
train() client id: f_00006-10-0 loss: 0.584136  [   32/   54]
train() client id: f_00006-11-0 loss: 0.569489  [   32/   54]
train() client id: f_00006-12-0 loss: 0.617542  [   32/   54]
train() client id: f_00007-0-0 loss: 0.578214  [   32/  179]
train() client id: f_00007-0-1 loss: 0.693093  [   64/  179]
train() client id: f_00007-0-2 loss: 0.683902  [   96/  179]
train() client id: f_00007-0-3 loss: 0.696566  [  128/  179]
train() client id: f_00007-0-4 loss: 0.972355  [  160/  179]
train() client id: f_00007-1-0 loss: 0.764602  [   32/  179]
train() client id: f_00007-1-1 loss: 0.710709  [   64/  179]
train() client id: f_00007-1-2 loss: 0.659825  [   96/  179]
train() client id: f_00007-1-3 loss: 0.577181  [  128/  179]
train() client id: f_00007-1-4 loss: 0.908776  [  160/  179]
train() client id: f_00007-2-0 loss: 0.561428  [   32/  179]
train() client id: f_00007-2-1 loss: 0.646970  [   64/  179]
train() client id: f_00007-2-2 loss: 0.624294  [   96/  179]
train() client id: f_00007-2-3 loss: 0.760632  [  128/  179]
train() client id: f_00007-2-4 loss: 0.899419  [  160/  179]
train() client id: f_00007-3-0 loss: 0.705302  [   32/  179]
train() client id: f_00007-3-1 loss: 0.675775  [   64/  179]
train() client id: f_00007-3-2 loss: 0.804193  [   96/  179]
train() client id: f_00007-3-3 loss: 0.653584  [  128/  179]
train() client id: f_00007-3-4 loss: 0.737287  [  160/  179]
train() client id: f_00007-4-0 loss: 0.617137  [   32/  179]
train() client id: f_00007-4-1 loss: 0.577577  [   64/  179]
train() client id: f_00007-4-2 loss: 0.612174  [   96/  179]
train() client id: f_00007-4-3 loss: 0.830837  [  128/  179]
train() client id: f_00007-4-4 loss: 0.795308  [  160/  179]
train() client id: f_00007-5-0 loss: 0.770029  [   32/  179]
train() client id: f_00007-5-1 loss: 0.790582  [   64/  179]
train() client id: f_00007-5-2 loss: 0.562247  [   96/  179]
train() client id: f_00007-5-3 loss: 0.582423  [  128/  179]
train() client id: f_00007-5-4 loss: 0.705061  [  160/  179]
train() client id: f_00007-6-0 loss: 0.650649  [   32/  179]
train() client id: f_00007-6-1 loss: 0.618035  [   64/  179]
train() client id: f_00007-6-2 loss: 0.671175  [   96/  179]
train() client id: f_00007-6-3 loss: 0.740593  [  128/  179]
train() client id: f_00007-6-4 loss: 0.628832  [  160/  179]
train() client id: f_00007-7-0 loss: 0.627143  [   32/  179]
train() client id: f_00007-7-1 loss: 0.695145  [   64/  179]
train() client id: f_00007-7-2 loss: 0.733775  [   96/  179]
train() client id: f_00007-7-3 loss: 0.817974  [  128/  179]
train() client id: f_00007-7-4 loss: 0.618712  [  160/  179]
train() client id: f_00007-8-0 loss: 0.537159  [   32/  179]
train() client id: f_00007-8-1 loss: 0.692846  [   64/  179]
train() client id: f_00007-8-2 loss: 0.706984  [   96/  179]
train() client id: f_00007-8-3 loss: 0.695695  [  128/  179]
train() client id: f_00007-8-4 loss: 0.769577  [  160/  179]
train() client id: f_00007-9-0 loss: 0.587327  [   32/  179]
train() client id: f_00007-9-1 loss: 0.685792  [   64/  179]
train() client id: f_00007-9-2 loss: 0.525560  [   96/  179]
train() client id: f_00007-9-3 loss: 0.912067  [  128/  179]
train() client id: f_00007-9-4 loss: 0.772117  [  160/  179]
train() client id: f_00007-10-0 loss: 0.550379  [   32/  179]
train() client id: f_00007-10-1 loss: 0.515482  [   64/  179]
train() client id: f_00007-10-2 loss: 0.616717  [   96/  179]
train() client id: f_00007-10-3 loss: 0.949214  [  128/  179]
train() client id: f_00007-10-4 loss: 0.753867  [  160/  179]
train() client id: f_00007-11-0 loss: 0.825639  [   32/  179]
train() client id: f_00007-11-1 loss: 0.837801  [   64/  179]
train() client id: f_00007-11-2 loss: 0.519690  [   96/  179]
train() client id: f_00007-11-3 loss: 0.640882  [  128/  179]
train() client id: f_00007-11-4 loss: 0.540491  [  160/  179]
train() client id: f_00007-12-0 loss: 0.906818  [   32/  179]
train() client id: f_00007-12-1 loss: 0.550973  [   64/  179]
train() client id: f_00007-12-2 loss: 0.843596  [   96/  179]
train() client id: f_00007-12-3 loss: 0.503529  [  128/  179]
train() client id: f_00007-12-4 loss: 0.665037  [  160/  179]
train() client id: f_00008-0-0 loss: 0.749500  [   32/  130]
train() client id: f_00008-0-1 loss: 0.836853  [   64/  130]
train() client id: f_00008-0-2 loss: 0.645780  [   96/  130]
train() client id: f_00008-0-3 loss: 0.733923  [  128/  130]
train() client id: f_00008-1-0 loss: 0.676637  [   32/  130]
train() client id: f_00008-1-1 loss: 0.727260  [   64/  130]
train() client id: f_00008-1-2 loss: 0.868590  [   96/  130]
train() client id: f_00008-1-3 loss: 0.737472  [  128/  130]
train() client id: f_00008-2-0 loss: 0.725149  [   32/  130]
train() client id: f_00008-2-1 loss: 0.783391  [   64/  130]
train() client id: f_00008-2-2 loss: 0.764243  [   96/  130]
train() client id: f_00008-2-3 loss: 0.723677  [  128/  130]
train() client id: f_00008-3-0 loss: 0.790052  [   32/  130]
train() client id: f_00008-3-1 loss: 0.664731  [   64/  130]
train() client id: f_00008-3-2 loss: 0.642582  [   96/  130]
train() client id: f_00008-3-3 loss: 0.881694  [  128/  130]
train() client id: f_00008-4-0 loss: 0.738454  [   32/  130]
train() client id: f_00008-4-1 loss: 0.866295  [   64/  130]
train() client id: f_00008-4-2 loss: 0.732788  [   96/  130]
train() client id: f_00008-4-3 loss: 0.672785  [  128/  130]
train() client id: f_00008-5-0 loss: 0.719878  [   32/  130]
train() client id: f_00008-5-1 loss: 0.747792  [   64/  130]
train() client id: f_00008-5-2 loss: 0.800860  [   96/  130]
train() client id: f_00008-5-3 loss: 0.723855  [  128/  130]
train() client id: f_00008-6-0 loss: 0.769802  [   32/  130]
train() client id: f_00008-6-1 loss: 0.823073  [   64/  130]
train() client id: f_00008-6-2 loss: 0.725035  [   96/  130]
train() client id: f_00008-6-3 loss: 0.679212  [  128/  130]
train() client id: f_00008-7-0 loss: 0.714591  [   32/  130]
train() client id: f_00008-7-1 loss: 0.755327  [   64/  130]
train() client id: f_00008-7-2 loss: 0.803417  [   96/  130]
train() client id: f_00008-7-3 loss: 0.701801  [  128/  130]
train() client id: f_00008-8-0 loss: 0.704351  [   32/  130]
train() client id: f_00008-8-1 loss: 0.628665  [   64/  130]
train() client id: f_00008-8-2 loss: 0.770100  [   96/  130]
train() client id: f_00008-8-3 loss: 0.858250  [  128/  130]
train() client id: f_00008-9-0 loss: 0.641639  [   32/  130]
train() client id: f_00008-9-1 loss: 0.823304  [   64/  130]
train() client id: f_00008-9-2 loss: 0.790754  [   96/  130]
train() client id: f_00008-9-3 loss: 0.717919  [  128/  130]
train() client id: f_00008-10-0 loss: 0.801686  [   32/  130]
train() client id: f_00008-10-1 loss: 0.682027  [   64/  130]
train() client id: f_00008-10-2 loss: 0.746528  [   96/  130]
train() client id: f_00008-10-3 loss: 0.760914  [  128/  130]
train() client id: f_00008-11-0 loss: 0.654158  [   32/  130]
train() client id: f_00008-11-1 loss: 0.677495  [   64/  130]
train() client id: f_00008-11-2 loss: 0.830541  [   96/  130]
train() client id: f_00008-11-3 loss: 0.843512  [  128/  130]
train() client id: f_00008-12-0 loss: 0.714860  [   32/  130]
train() client id: f_00008-12-1 loss: 0.671819  [   64/  130]
train() client id: f_00008-12-2 loss: 0.813727  [   96/  130]
train() client id: f_00008-12-3 loss: 0.780276  [  128/  130]
train() client id: f_00009-0-0 loss: 1.174634  [   32/  118]
train() client id: f_00009-0-1 loss: 1.172559  [   64/  118]
train() client id: f_00009-0-2 loss: 1.176171  [   96/  118]
train() client id: f_00009-1-0 loss: 1.122927  [   32/  118]
train() client id: f_00009-1-1 loss: 1.184253  [   64/  118]
train() client id: f_00009-1-2 loss: 0.989619  [   96/  118]
train() client id: f_00009-2-0 loss: 1.096179  [   32/  118]
train() client id: f_00009-2-1 loss: 1.019614  [   64/  118]
train() client id: f_00009-2-2 loss: 1.056691  [   96/  118]
train() client id: f_00009-3-0 loss: 1.036698  [   32/  118]
train() client id: f_00009-3-1 loss: 0.930880  [   64/  118]
train() client id: f_00009-3-2 loss: 1.159768  [   96/  118]
train() client id: f_00009-4-0 loss: 0.982923  [   32/  118]
train() client id: f_00009-4-1 loss: 1.055790  [   64/  118]
train() client id: f_00009-4-2 loss: 0.876776  [   96/  118]
train() client id: f_00009-5-0 loss: 0.961045  [   32/  118]
train() client id: f_00009-5-1 loss: 0.936216  [   64/  118]
train() client id: f_00009-5-2 loss: 1.019111  [   96/  118]
train() client id: f_00009-6-0 loss: 0.935290  [   32/  118]
train() client id: f_00009-6-1 loss: 1.040223  [   64/  118]
train() client id: f_00009-6-2 loss: 0.837911  [   96/  118]
train() client id: f_00009-7-0 loss: 0.925874  [   32/  118]
train() client id: f_00009-7-1 loss: 0.946260  [   64/  118]
train() client id: f_00009-7-2 loss: 0.939348  [   96/  118]
train() client id: f_00009-8-0 loss: 0.856449  [   32/  118]
train() client id: f_00009-8-1 loss: 1.077894  [   64/  118]
train() client id: f_00009-8-2 loss: 0.751621  [   96/  118]
train() client id: f_00009-9-0 loss: 0.834515  [   32/  118]
train() client id: f_00009-9-1 loss: 0.941490  [   64/  118]
train() client id: f_00009-9-2 loss: 0.913964  [   96/  118]
train() client id: f_00009-10-0 loss: 1.033047  [   32/  118]
train() client id: f_00009-10-1 loss: 0.732010  [   64/  118]
train() client id: f_00009-10-2 loss: 0.924053  [   96/  118]
train() client id: f_00009-11-0 loss: 0.867635  [   32/  118]
train() client id: f_00009-11-1 loss: 0.873781  [   64/  118]
train() client id: f_00009-11-2 loss: 0.927060  [   96/  118]
train() client id: f_00009-12-0 loss: 1.037012  [   32/  118]
train() client id: f_00009-12-1 loss: 0.829617  [   64/  118]
train() client id: f_00009-12-2 loss: 0.889173  [   96/  118]
At round 36 accuracy: 0.6472148541114059
At round 36 training accuracy: 0.5895372233400402
At round 36 training loss: 0.8237061833733351
gradient difference: 0.4642011523246765
train() client id: f_00000-0-0 loss: 1.096161  [   32/  126]
train() client id: f_00000-0-1 loss: 1.280956  [   64/  126]
train() client id: f_00000-0-2 loss: 1.124240  [   96/  126]
train() client id: f_00000-1-0 loss: 1.063872  [   32/  126]
train() client id: f_00000-1-1 loss: 1.033961  [   64/  126]
train() client id: f_00000-1-2 loss: 0.938105  [   96/  126]
train() client id: f_00000-2-0 loss: 1.024813  [   32/  126]
train() client id: f_00000-2-1 loss: 1.056595  [   64/  126]
train() client id: f_00000-2-2 loss: 0.753835  [   96/  126]
train() client id: f_00000-3-0 loss: 0.910094  [   32/  126]
train() client id: f_00000-3-1 loss: 1.053398  [   64/  126]
train() client id: f_00000-3-2 loss: 0.758573  [   96/  126]
train() client id: f_00000-4-0 loss: 0.907149  [   32/  126]
train() client id: f_00000-4-1 loss: 0.760986  [   64/  126]
train() client id: f_00000-4-2 loss: 0.933190  [   96/  126]
train() client id: f_00000-5-0 loss: 0.850995  [   32/  126]
train() client id: f_00000-5-1 loss: 0.897457  [   64/  126]
train() client id: f_00000-5-2 loss: 0.848754  [   96/  126]
train() client id: f_00000-6-0 loss: 0.856608  [   32/  126]
train() client id: f_00000-6-1 loss: 0.865929  [   64/  126]
train() client id: f_00000-6-2 loss: 0.626947  [   96/  126]
train() client id: f_00000-7-0 loss: 0.836854  [   32/  126]
train() client id: f_00000-7-1 loss: 0.655916  [   64/  126]
train() client id: f_00000-7-2 loss: 0.792127  [   96/  126]
train() client id: f_00000-8-0 loss: 0.881176  [   32/  126]
train() client id: f_00000-8-1 loss: 0.682623  [   64/  126]
train() client id: f_00000-8-2 loss: 0.839941  [   96/  126]
train() client id: f_00000-9-0 loss: 0.834215  [   32/  126]
train() client id: f_00000-9-1 loss: 0.690153  [   64/  126]
train() client id: f_00000-9-2 loss: 0.686847  [   96/  126]
train() client id: f_00000-10-0 loss: 0.836435  [   32/  126]
train() client id: f_00000-10-1 loss: 0.726431  [   64/  126]
train() client id: f_00000-10-2 loss: 0.753812  [   96/  126]
train() client id: f_00000-11-0 loss: 0.699200  [   32/  126]
train() client id: f_00000-11-1 loss: 0.854627  [   64/  126]
train() client id: f_00000-11-2 loss: 0.758540  [   96/  126]
train() client id: f_00000-12-0 loss: 0.761203  [   32/  126]
train() client id: f_00000-12-1 loss: 0.657648  [   64/  126]
train() client id: f_00000-12-2 loss: 0.769767  [   96/  126]
train() client id: f_00001-0-0 loss: 0.580058  [   32/  265]
train() client id: f_00001-0-1 loss: 0.410743  [   64/  265]
train() client id: f_00001-0-2 loss: 0.360538  [   96/  265]
train() client id: f_00001-0-3 loss: 0.328725  [  128/  265]
train() client id: f_00001-0-4 loss: 0.423515  [  160/  265]
train() client id: f_00001-0-5 loss: 0.403180  [  192/  265]
train() client id: f_00001-0-6 loss: 0.458528  [  224/  265]
train() client id: f_00001-0-7 loss: 0.466408  [  256/  265]
train() client id: f_00001-1-0 loss: 0.369345  [   32/  265]
train() client id: f_00001-1-1 loss: 0.437494  [   64/  265]
train() client id: f_00001-1-2 loss: 0.399452  [   96/  265]
train() client id: f_00001-1-3 loss: 0.375363  [  128/  265]
train() client id: f_00001-1-4 loss: 0.419864  [  160/  265]
train() client id: f_00001-1-5 loss: 0.521143  [  192/  265]
train() client id: f_00001-1-6 loss: 0.425789  [  224/  265]
train() client id: f_00001-1-7 loss: 0.486369  [  256/  265]
train() client id: f_00001-2-0 loss: 0.540905  [   32/  265]
train() client id: f_00001-2-1 loss: 0.345512  [   64/  265]
train() client id: f_00001-2-2 loss: 0.374328  [   96/  265]
train() client id: f_00001-2-3 loss: 0.443924  [  128/  265]
train() client id: f_00001-2-4 loss: 0.360515  [  160/  265]
train() client id: f_00001-2-5 loss: 0.341294  [  192/  265]
train() client id: f_00001-2-6 loss: 0.499582  [  224/  265]
train() client id: f_00001-2-7 loss: 0.409794  [  256/  265]
train() client id: f_00001-3-0 loss: 0.371162  [   32/  265]
train() client id: f_00001-3-1 loss: 0.329567  [   64/  265]
train() client id: f_00001-3-2 loss: 0.333955  [   96/  265]
train() client id: f_00001-3-3 loss: 0.420939  [  128/  265]
train() client id: f_00001-3-4 loss: 0.351177  [  160/  265]
train() client id: f_00001-3-5 loss: 0.447260  [  192/  265]
train() client id: f_00001-3-6 loss: 0.367477  [  224/  265]
train() client id: f_00001-3-7 loss: 0.457286  [  256/  265]
train() client id: f_00001-4-0 loss: 0.602092  [   32/  265]
train() client id: f_00001-4-1 loss: 0.328283  [   64/  265]
train() client id: f_00001-4-2 loss: 0.311474  [   96/  265]
train() client id: f_00001-4-3 loss: 0.459887  [  128/  265]
train() client id: f_00001-4-4 loss: 0.425940  [  160/  265]
train() client id: f_00001-4-5 loss: 0.323692  [  192/  265]
train() client id: f_00001-4-6 loss: 0.340653  [  224/  265]
train() client id: f_00001-4-7 loss: 0.489666  [  256/  265]
train() client id: f_00001-5-0 loss: 0.329737  [   32/  265]
train() client id: f_00001-5-1 loss: 0.462924  [   64/  265]
train() client id: f_00001-5-2 loss: 0.356797  [   96/  265]
train() client id: f_00001-5-3 loss: 0.434396  [  128/  265]
train() client id: f_00001-5-4 loss: 0.391649  [  160/  265]
train() client id: f_00001-5-5 loss: 0.310521  [  192/  265]
train() client id: f_00001-5-6 loss: 0.325792  [  224/  265]
train() client id: f_00001-5-7 loss: 0.604760  [  256/  265]
train() client id: f_00001-6-0 loss: 0.313112  [   32/  265]
train() client id: f_00001-6-1 loss: 0.429527  [   64/  265]
train() client id: f_00001-6-2 loss: 0.340880  [   96/  265]
train() client id: f_00001-6-3 loss: 0.366686  [  128/  265]
train() client id: f_00001-6-4 loss: 0.560301  [  160/  265]
train() client id: f_00001-6-5 loss: 0.365225  [  192/  265]
train() client id: f_00001-6-6 loss: 0.554231  [  224/  265]
train() client id: f_00001-6-7 loss: 0.303004  [  256/  265]
train() client id: f_00001-7-0 loss: 0.434662  [   32/  265]
train() client id: f_00001-7-1 loss: 0.387285  [   64/  265]
train() client id: f_00001-7-2 loss: 0.417079  [   96/  265]
train() client id: f_00001-7-3 loss: 0.388018  [  128/  265]
train() client id: f_00001-7-4 loss: 0.315332  [  160/  265]
train() client id: f_00001-7-5 loss: 0.364794  [  192/  265]
train() client id: f_00001-7-6 loss: 0.515263  [  224/  265]
train() client id: f_00001-7-7 loss: 0.402086  [  256/  265]
train() client id: f_00001-8-0 loss: 0.350114  [   32/  265]
train() client id: f_00001-8-1 loss: 0.342526  [   64/  265]
train() client id: f_00001-8-2 loss: 0.323424  [   96/  265]
train() client id: f_00001-8-3 loss: 0.402358  [  128/  265]
train() client id: f_00001-8-4 loss: 0.532594  [  160/  265]
train() client id: f_00001-8-5 loss: 0.290914  [  192/  265]
train() client id: f_00001-8-6 loss: 0.602032  [  224/  265]
train() client id: f_00001-8-7 loss: 0.354928  [  256/  265]
train() client id: f_00001-9-0 loss: 0.479811  [   32/  265]
train() client id: f_00001-9-1 loss: 0.416941  [   64/  265]
train() client id: f_00001-9-2 loss: 0.410988  [   96/  265]
train() client id: f_00001-9-3 loss: 0.360285  [  128/  265]
train() client id: f_00001-9-4 loss: 0.302226  [  160/  265]
train() client id: f_00001-9-5 loss: 0.388750  [  192/  265]
train() client id: f_00001-9-6 loss: 0.539299  [  224/  265]
train() client id: f_00001-9-7 loss: 0.304154  [  256/  265]
train() client id: f_00001-10-0 loss: 0.532233  [   32/  265]
train() client id: f_00001-10-1 loss: 0.386472  [   64/  265]
train() client id: f_00001-10-2 loss: 0.444949  [   96/  265]
train() client id: f_00001-10-3 loss: 0.305549  [  128/  265]
train() client id: f_00001-10-4 loss: 0.362900  [  160/  265]
train() client id: f_00001-10-5 loss: 0.416933  [  192/  265]
train() client id: f_00001-10-6 loss: 0.296793  [  224/  265]
train() client id: f_00001-10-7 loss: 0.361466  [  256/  265]
train() client id: f_00001-11-0 loss: 0.360135  [   32/  265]
train() client id: f_00001-11-1 loss: 0.367878  [   64/  265]
train() client id: f_00001-11-2 loss: 0.480288  [   96/  265]
train() client id: f_00001-11-3 loss: 0.351955  [  128/  265]
train() client id: f_00001-11-4 loss: 0.349128  [  160/  265]
train() client id: f_00001-11-5 loss: 0.413390  [  192/  265]
train() client id: f_00001-11-6 loss: 0.432456  [  224/  265]
train() client id: f_00001-11-7 loss: 0.441796  [  256/  265]
train() client id: f_00001-12-0 loss: 0.368269  [   32/  265]
train() client id: f_00001-12-1 loss: 0.481510  [   64/  265]
train() client id: f_00001-12-2 loss: 0.434251  [   96/  265]
train() client id: f_00001-12-3 loss: 0.308390  [  128/  265]
train() client id: f_00001-12-4 loss: 0.381918  [  160/  265]
train() client id: f_00001-12-5 loss: 0.397213  [  192/  265]
train() client id: f_00001-12-6 loss: 0.316495  [  224/  265]
train() client id: f_00001-12-7 loss: 0.499513  [  256/  265]
train() client id: f_00002-0-0 loss: 1.457855  [   32/  124]
train() client id: f_00002-0-1 loss: 1.349375  [   64/  124]
train() client id: f_00002-0-2 loss: 1.412951  [   96/  124]
train() client id: f_00002-1-0 loss: 1.379218  [   32/  124]
train() client id: f_00002-1-1 loss: 1.398031  [   64/  124]
train() client id: f_00002-1-2 loss: 1.161002  [   96/  124]
train() client id: f_00002-2-0 loss: 1.302308  [   32/  124]
train() client id: f_00002-2-1 loss: 1.446126  [   64/  124]
train() client id: f_00002-2-2 loss: 1.165294  [   96/  124]
train() client id: f_00002-3-0 loss: 1.234464  [   32/  124]
train() client id: f_00002-3-1 loss: 1.220987  [   64/  124]
train() client id: f_00002-3-2 loss: 1.233966  [   96/  124]
train() client id: f_00002-4-0 loss: 1.273930  [   32/  124]
train() client id: f_00002-4-1 loss: 1.182949  [   64/  124]
train() client id: f_00002-4-2 loss: 1.394959  [   96/  124]
train() client id: f_00002-5-0 loss: 1.233427  [   32/  124]
train() client id: f_00002-5-1 loss: 1.428565  [   64/  124]
train() client id: f_00002-5-2 loss: 1.155449  [   96/  124]
train() client id: f_00002-6-0 loss: 1.246493  [   32/  124]
train() client id: f_00002-6-1 loss: 1.332464  [   64/  124]
train() client id: f_00002-6-2 loss: 1.170025  [   96/  124]
train() client id: f_00002-7-0 loss: 1.090062  [   32/  124]
train() client id: f_00002-7-1 loss: 1.252401  [   64/  124]
train() client id: f_00002-7-2 loss: 1.317307  [   96/  124]
train() client id: f_00002-8-0 loss: 1.218256  [   32/  124]
train() client id: f_00002-8-1 loss: 1.161835  [   64/  124]
train() client id: f_00002-8-2 loss: 1.361487  [   96/  124]
train() client id: f_00002-9-0 loss: 1.240451  [   32/  124]
train() client id: f_00002-9-1 loss: 1.274548  [   64/  124]
train() client id: f_00002-9-2 loss: 1.134187  [   96/  124]
train() client id: f_00002-10-0 loss: 1.362213  [   32/  124]
train() client id: f_00002-10-1 loss: 1.138662  [   64/  124]
train() client id: f_00002-10-2 loss: 1.107633  [   96/  124]
train() client id: f_00002-11-0 loss: 1.230249  [   32/  124]
train() client id: f_00002-11-1 loss: 1.156964  [   64/  124]
train() client id: f_00002-11-2 loss: 1.161481  [   96/  124]
train() client id: f_00002-12-0 loss: 1.127889  [   32/  124]
train() client id: f_00002-12-1 loss: 1.236879  [   64/  124]
train() client id: f_00002-12-2 loss: 1.281971  [   96/  124]
train() client id: f_00003-0-0 loss: 0.288275  [   32/   43]
train() client id: f_00003-1-0 loss: 0.490130  [   32/   43]
train() client id: f_00003-2-0 loss: 0.487206  [   32/   43]
train() client id: f_00003-3-0 loss: 0.512134  [   32/   43]
train() client id: f_00003-4-0 loss: 0.373063  [   32/   43]
train() client id: f_00003-5-0 loss: 0.644903  [   32/   43]
train() client id: f_00003-6-0 loss: 0.525674  [   32/   43]
train() client id: f_00003-7-0 loss: 0.535629  [   32/   43]
train() client id: f_00003-8-0 loss: 0.392620  [   32/   43]
train() client id: f_00003-9-0 loss: 0.594954  [   32/   43]
train() client id: f_00003-10-0 loss: 0.387132  [   32/   43]
train() client id: f_00003-11-0 loss: 0.511526  [   32/   43]
train() client id: f_00003-12-0 loss: 0.546242  [   32/   43]
train() client id: f_00004-0-0 loss: 0.694477  [   32/  306]
train() client id: f_00004-0-1 loss: 0.645043  [   64/  306]
train() client id: f_00004-0-2 loss: 0.683846  [   96/  306]
train() client id: f_00004-0-3 loss: 0.800741  [  128/  306]
train() client id: f_00004-0-4 loss: 0.654764  [  160/  306]
train() client id: f_00004-0-5 loss: 0.539151  [  192/  306]
train() client id: f_00004-0-6 loss: 0.736773  [  224/  306]
train() client id: f_00004-0-7 loss: 0.622305  [  256/  306]
train() client id: f_00004-0-8 loss: 0.693991  [  288/  306]
train() client id: f_00004-1-0 loss: 0.655541  [   32/  306]
train() client id: f_00004-1-1 loss: 0.616600  [   64/  306]
train() client id: f_00004-1-2 loss: 0.718456  [   96/  306]
train() client id: f_00004-1-3 loss: 0.726588  [  128/  306]
train() client id: f_00004-1-4 loss: 0.732833  [  160/  306]
train() client id: f_00004-1-5 loss: 0.749395  [  192/  306]
train() client id: f_00004-1-6 loss: 0.595020  [  224/  306]
train() client id: f_00004-1-7 loss: 0.617562  [  256/  306]
train() client id: f_00004-1-8 loss: 0.720501  [  288/  306]
train() client id: f_00004-2-0 loss: 0.646527  [   32/  306]
train() client id: f_00004-2-1 loss: 0.669877  [   64/  306]
train() client id: f_00004-2-2 loss: 0.742742  [   96/  306]
train() client id: f_00004-2-3 loss: 0.617049  [  128/  306]
train() client id: f_00004-2-4 loss: 0.790616  [  160/  306]
train() client id: f_00004-2-5 loss: 0.724340  [  192/  306]
train() client id: f_00004-2-6 loss: 0.592457  [  224/  306]
train() client id: f_00004-2-7 loss: 0.674545  [  256/  306]
train() client id: f_00004-2-8 loss: 0.577909  [  288/  306]
train() client id: f_00004-3-0 loss: 0.735784  [   32/  306]
train() client id: f_00004-3-1 loss: 0.570089  [   64/  306]
train() client id: f_00004-3-2 loss: 0.560773  [   96/  306]
train() client id: f_00004-3-3 loss: 0.626035  [  128/  306]
train() client id: f_00004-3-4 loss: 0.646668  [  160/  306]
train() client id: f_00004-3-5 loss: 0.763774  [  192/  306]
train() client id: f_00004-3-6 loss: 0.666586  [  224/  306]
train() client id: f_00004-3-7 loss: 0.654925  [  256/  306]
train() client id: f_00004-3-8 loss: 0.814710  [  288/  306]
train() client id: f_00004-4-0 loss: 0.612209  [   32/  306]
train() client id: f_00004-4-1 loss: 0.684688  [   64/  306]
train() client id: f_00004-4-2 loss: 0.639745  [   96/  306]
train() client id: f_00004-4-3 loss: 0.650213  [  128/  306]
train() client id: f_00004-4-4 loss: 0.740018  [  160/  306]
train() client id: f_00004-4-5 loss: 0.628088  [  192/  306]
train() client id: f_00004-4-6 loss: 0.759912  [  224/  306]
train() client id: f_00004-4-7 loss: 0.812441  [  256/  306]
train() client id: f_00004-4-8 loss: 0.551133  [  288/  306]
train() client id: f_00004-5-0 loss: 0.586242  [   32/  306]
train() client id: f_00004-5-1 loss: 0.667412  [   64/  306]
train() client id: f_00004-5-2 loss: 0.792013  [   96/  306]
train() client id: f_00004-5-3 loss: 0.622761  [  128/  306]
train() client id: f_00004-5-4 loss: 0.710343  [  160/  306]
train() client id: f_00004-5-5 loss: 0.590967  [  192/  306]
train() client id: f_00004-5-6 loss: 0.625000  [  224/  306]
train() client id: f_00004-5-7 loss: 0.636957  [  256/  306]
train() client id: f_00004-5-8 loss: 0.819391  [  288/  306]
train() client id: f_00004-6-0 loss: 0.579910  [   32/  306]
train() client id: f_00004-6-1 loss: 0.720093  [   64/  306]
train() client id: f_00004-6-2 loss: 0.646478  [   96/  306]
train() client id: f_00004-6-3 loss: 0.659539  [  128/  306]
train() client id: f_00004-6-4 loss: 0.667615  [  160/  306]
train() client id: f_00004-6-5 loss: 0.669905  [  192/  306]
train() client id: f_00004-6-6 loss: 0.719491  [  224/  306]
train() client id: f_00004-6-7 loss: 0.732435  [  256/  306]
train() client id: f_00004-6-8 loss: 0.642174  [  288/  306]
train() client id: f_00004-7-0 loss: 0.794691  [   32/  306]
train() client id: f_00004-7-1 loss: 0.637540  [   64/  306]
train() client id: f_00004-7-2 loss: 0.920409  [   96/  306]
train() client id: f_00004-7-3 loss: 0.607547  [  128/  306]
train() client id: f_00004-7-4 loss: 0.618726  [  160/  306]
train() client id: f_00004-7-5 loss: 0.695734  [  192/  306]
train() client id: f_00004-7-6 loss: 0.585044  [  224/  306]
train() client id: f_00004-7-7 loss: 0.558788  [  256/  306]
train() client id: f_00004-7-8 loss: 0.694538  [  288/  306]
train() client id: f_00004-8-0 loss: 0.669432  [   32/  306]
train() client id: f_00004-8-1 loss: 0.552141  [   64/  306]
train() client id: f_00004-8-2 loss: 0.733324  [   96/  306]
train() client id: f_00004-8-3 loss: 0.627029  [  128/  306]
train() client id: f_00004-8-4 loss: 0.795516  [  160/  306]
train() client id: f_00004-8-5 loss: 0.680279  [  192/  306]
train() client id: f_00004-8-6 loss: 0.635185  [  224/  306]
train() client id: f_00004-8-7 loss: 0.729224  [  256/  306]
train() client id: f_00004-8-8 loss: 0.656290  [  288/  306]
train() client id: f_00004-9-0 loss: 0.703506  [   32/  306]
train() client id: f_00004-9-1 loss: 0.616621  [   64/  306]
train() client id: f_00004-9-2 loss: 0.711710  [   96/  306]
train() client id: f_00004-9-3 loss: 0.665216  [  128/  306]
train() client id: f_00004-9-4 loss: 0.779671  [  160/  306]
train() client id: f_00004-9-5 loss: 0.638195  [  192/  306]
train() client id: f_00004-9-6 loss: 0.708828  [  224/  306]
train() client id: f_00004-9-7 loss: 0.697874  [  256/  306]
train() client id: f_00004-9-8 loss: 0.683444  [  288/  306]
train() client id: f_00004-10-0 loss: 0.687442  [   32/  306]
train() client id: f_00004-10-1 loss: 0.714122  [   64/  306]
train() client id: f_00004-10-2 loss: 0.799202  [   96/  306]
train() client id: f_00004-10-3 loss: 0.783747  [  128/  306]
train() client id: f_00004-10-4 loss: 0.638182  [  160/  306]
train() client id: f_00004-10-5 loss: 0.696506  [  192/  306]
train() client id: f_00004-10-6 loss: 0.663736  [  224/  306]
train() client id: f_00004-10-7 loss: 0.640862  [  256/  306]
train() client id: f_00004-10-8 loss: 0.668244  [  288/  306]
train() client id: f_00004-11-0 loss: 0.648665  [   32/  306]
train() client id: f_00004-11-1 loss: 0.641704  [   64/  306]
train() client id: f_00004-11-2 loss: 0.736133  [   96/  306]
train() client id: f_00004-11-3 loss: 0.658372  [  128/  306]
train() client id: f_00004-11-4 loss: 0.746417  [  160/  306]
train() client id: f_00004-11-5 loss: 0.719893  [  192/  306]
train() client id: f_00004-11-6 loss: 0.623019  [  224/  306]
train() client id: f_00004-11-7 loss: 0.647693  [  256/  306]
train() client id: f_00004-11-8 loss: 0.723894  [  288/  306]
train() client id: f_00004-12-0 loss: 0.739960  [   32/  306]
train() client id: f_00004-12-1 loss: 0.700309  [   64/  306]
train() client id: f_00004-12-2 loss: 0.582246  [   96/  306]
train() client id: f_00004-12-3 loss: 0.801391  [  128/  306]
train() client id: f_00004-12-4 loss: 0.697506  [  160/  306]
train() client id: f_00004-12-5 loss: 0.736622  [  192/  306]
train() client id: f_00004-12-6 loss: 0.673213  [  224/  306]
train() client id: f_00004-12-7 loss: 0.629519  [  256/  306]
train() client id: f_00004-12-8 loss: 0.638005  [  288/  306]
train() client id: f_00005-0-0 loss: 0.534126  [   32/  146]
train() client id: f_00005-0-1 loss: 0.708295  [   64/  146]
train() client id: f_00005-0-2 loss: 0.425616  [   96/  146]
train() client id: f_00005-0-3 loss: 0.646401  [  128/  146]
train() client id: f_00005-1-0 loss: 0.541425  [   32/  146]
train() client id: f_00005-1-1 loss: 0.488959  [   64/  146]
train() client id: f_00005-1-2 loss: 0.532776  [   96/  146]
train() client id: f_00005-1-3 loss: 0.460429  [  128/  146]
train() client id: f_00005-2-0 loss: 0.522941  [   32/  146]
train() client id: f_00005-2-1 loss: 0.527732  [   64/  146]
train() client id: f_00005-2-2 loss: 0.394138  [   96/  146]
train() client id: f_00005-2-3 loss: 0.915751  [  128/  146]
train() client id: f_00005-3-0 loss: 0.950785  [   32/  146]
train() client id: f_00005-3-1 loss: 0.364616  [   64/  146]
train() client id: f_00005-3-2 loss: 0.490668  [   96/  146]
train() client id: f_00005-3-3 loss: 0.330402  [  128/  146]
train() client id: f_00005-4-0 loss: 0.605703  [   32/  146]
train() client id: f_00005-4-1 loss: 0.481603  [   64/  146]
train() client id: f_00005-4-2 loss: 0.354387  [   96/  146]
train() client id: f_00005-4-3 loss: 0.829598  [  128/  146]
train() client id: f_00005-5-0 loss: 0.362823  [   32/  146]
train() client id: f_00005-5-1 loss: 0.519154  [   64/  146]
train() client id: f_00005-5-2 loss: 0.611239  [   96/  146]
train() client id: f_00005-5-3 loss: 0.783097  [  128/  146]
train() client id: f_00005-6-0 loss: 0.392255  [   32/  146]
train() client id: f_00005-6-1 loss: 0.568188  [   64/  146]
train() client id: f_00005-6-2 loss: 0.574922  [   96/  146]
train() client id: f_00005-6-3 loss: 0.753077  [  128/  146]
train() client id: f_00005-7-0 loss: 0.774594  [   32/  146]
train() client id: f_00005-7-1 loss: 0.570532  [   64/  146]
train() client id: f_00005-7-2 loss: 0.624905  [   96/  146]
train() client id: f_00005-7-3 loss: 0.284799  [  128/  146]
train() client id: f_00005-8-0 loss: 0.443058  [   32/  146]
train() client id: f_00005-8-1 loss: 0.633864  [   64/  146]
train() client id: f_00005-8-2 loss: 0.732854  [   96/  146]
train() client id: f_00005-8-3 loss: 0.464329  [  128/  146]
train() client id: f_00005-9-0 loss: 0.632533  [   32/  146]
train() client id: f_00005-9-1 loss: 0.384170  [   64/  146]
train() client id: f_00005-9-2 loss: 0.685013  [   96/  146]
train() client id: f_00005-9-3 loss: 0.666433  [  128/  146]
train() client id: f_00005-10-0 loss: 0.521364  [   32/  146]
train() client id: f_00005-10-1 loss: 0.549239  [   64/  146]
train() client id: f_00005-10-2 loss: 0.611627  [   96/  146]
train() client id: f_00005-10-3 loss: 0.506944  [  128/  146]
train() client id: f_00005-11-0 loss: 0.540283  [   32/  146]
train() client id: f_00005-11-1 loss: 0.576261  [   64/  146]
train() client id: f_00005-11-2 loss: 0.626930  [   96/  146]
train() client id: f_00005-11-3 loss: 0.430368  [  128/  146]
train() client id: f_00005-12-0 loss: 0.548765  [   32/  146]
train() client id: f_00005-12-1 loss: 0.413163  [   64/  146]
train() client id: f_00005-12-2 loss: 0.412104  [   96/  146]
train() client id: f_00005-12-3 loss: 0.855763  [  128/  146]
train() client id: f_00006-0-0 loss: 0.414369  [   32/   54]
train() client id: f_00006-1-0 loss: 0.507940  [   32/   54]
train() client id: f_00006-2-0 loss: 0.458412  [   32/   54]
train() client id: f_00006-3-0 loss: 0.526830  [   32/   54]
train() client id: f_00006-4-0 loss: 0.467309  [   32/   54]
train() client id: f_00006-5-0 loss: 0.531198  [   32/   54]
train() client id: f_00006-6-0 loss: 0.461327  [   32/   54]
train() client id: f_00006-7-0 loss: 0.462665  [   32/   54]
train() client id: f_00006-8-0 loss: 0.525894  [   32/   54]
train() client id: f_00006-9-0 loss: 0.526198  [   32/   54]
train() client id: f_00006-10-0 loss: 0.464618  [   32/   54]
train() client id: f_00006-11-0 loss: 0.539777  [   32/   54]
train() client id: f_00006-12-0 loss: 0.474329  [   32/   54]
train() client id: f_00007-0-0 loss: 0.615888  [   32/  179]
train() client id: f_00007-0-1 loss: 0.653858  [   64/  179]
train() client id: f_00007-0-2 loss: 0.597780  [   96/  179]
train() client id: f_00007-0-3 loss: 0.484328  [  128/  179]
train() client id: f_00007-0-4 loss: 0.573591  [  160/  179]
train() client id: f_00007-1-0 loss: 0.540228  [   32/  179]
train() client id: f_00007-1-1 loss: 0.433522  [   64/  179]
train() client id: f_00007-1-2 loss: 0.721408  [   96/  179]
train() client id: f_00007-1-3 loss: 0.602678  [  128/  179]
train() client id: f_00007-1-4 loss: 0.594991  [  160/  179]
train() client id: f_00007-2-0 loss: 0.539601  [   32/  179]
train() client id: f_00007-2-1 loss: 0.646079  [   64/  179]
train() client id: f_00007-2-2 loss: 0.489013  [   96/  179]
train() client id: f_00007-2-3 loss: 0.479166  [  128/  179]
train() client id: f_00007-2-4 loss: 0.437571  [  160/  179]
train() client id: f_00007-3-0 loss: 0.554223  [   32/  179]
train() client id: f_00007-3-1 loss: 0.431733  [   64/  179]
train() client id: f_00007-3-2 loss: 0.526449  [   96/  179]
train() client id: f_00007-3-3 loss: 0.492344  [  128/  179]
train() client id: f_00007-3-4 loss: 0.643020  [  160/  179]
train() client id: f_00007-4-0 loss: 0.592396  [   32/  179]
train() client id: f_00007-4-1 loss: 0.750233  [   64/  179]
train() client id: f_00007-4-2 loss: 0.512481  [   96/  179]
train() client id: f_00007-4-3 loss: 0.373901  [  128/  179]
train() client id: f_00007-4-4 loss: 0.383739  [  160/  179]
train() client id: f_00007-5-0 loss: 0.508889  [   32/  179]
train() client id: f_00007-5-1 loss: 0.407725  [   64/  179]
train() client id: f_00007-5-2 loss: 0.513335  [   96/  179]
train() client id: f_00007-5-3 loss: 0.655339  [  128/  179]
train() client id: f_00007-5-4 loss: 0.370130  [  160/  179]
train() client id: f_00007-6-0 loss: 0.408785  [   32/  179]
train() client id: f_00007-6-1 loss: 0.538051  [   64/  179]
train() client id: f_00007-6-2 loss: 0.362679  [   96/  179]
train() client id: f_00007-6-3 loss: 0.629380  [  128/  179]
train() client id: f_00007-6-4 loss: 0.616298  [  160/  179]
train() client id: f_00007-7-0 loss: 0.485626  [   32/  179]
train() client id: f_00007-7-1 loss: 0.420732  [   64/  179]
train() client id: f_00007-7-2 loss: 0.658042  [   96/  179]
train() client id: f_00007-7-3 loss: 0.576939  [  128/  179]
train() client id: f_00007-7-4 loss: 0.379427  [  160/  179]
train() client id: f_00007-8-0 loss: 0.396026  [   32/  179]
train() client id: f_00007-8-1 loss: 0.756647  [   64/  179]
train() client id: f_00007-8-2 loss: 0.416512  [   96/  179]
train() client id: f_00007-8-3 loss: 0.449122  [  128/  179]
train() client id: f_00007-8-4 loss: 0.573564  [  160/  179]
train() client id: f_00007-9-0 loss: 0.524289  [   32/  179]
train() client id: f_00007-9-1 loss: 0.766937  [   64/  179]
train() client id: f_00007-9-2 loss: 0.369541  [   96/  179]
train() client id: f_00007-9-3 loss: 0.512772  [  128/  179]
train() client id: f_00007-9-4 loss: 0.464917  [  160/  179]
train() client id: f_00007-10-0 loss: 0.628301  [   32/  179]
train() client id: f_00007-10-1 loss: 0.452364  [   64/  179]
train() client id: f_00007-10-2 loss: 0.443799  [   96/  179]
train() client id: f_00007-10-3 loss: 0.362669  [  128/  179]
train() client id: f_00007-10-4 loss: 0.647640  [  160/  179]
train() client id: f_00007-11-0 loss: 0.637220  [   32/  179]
train() client id: f_00007-11-1 loss: 0.662130  [   64/  179]
train() client id: f_00007-11-2 loss: 0.450981  [   96/  179]
train() client id: f_00007-11-3 loss: 0.476297  [  128/  179]
train() client id: f_00007-11-4 loss: 0.436010  [  160/  179]
train() client id: f_00007-12-0 loss: 0.433959  [   32/  179]
train() client id: f_00007-12-1 loss: 0.654750  [   64/  179]
train() client id: f_00007-12-2 loss: 0.362180  [   96/  179]
train() client id: f_00007-12-3 loss: 0.557052  [  128/  179]
train() client id: f_00007-12-4 loss: 0.496460  [  160/  179]
train() client id: f_00008-0-0 loss: 0.728797  [   32/  130]
train() client id: f_00008-0-1 loss: 0.752215  [   64/  130]
train() client id: f_00008-0-2 loss: 0.581429  [   96/  130]
train() client id: f_00008-0-3 loss: 0.643985  [  128/  130]
train() client id: f_00008-1-0 loss: 0.629342  [   32/  130]
train() client id: f_00008-1-1 loss: 0.585376  [   64/  130]
train() client id: f_00008-1-2 loss: 0.640435  [   96/  130]
train() client id: f_00008-1-3 loss: 0.815213  [  128/  130]
train() client id: f_00008-2-0 loss: 0.656081  [   32/  130]
train() client id: f_00008-2-1 loss: 0.631782  [   64/  130]
train() client id: f_00008-2-2 loss: 0.783294  [   96/  130]
train() client id: f_00008-2-3 loss: 0.609854  [  128/  130]
train() client id: f_00008-3-0 loss: 0.714171  [   32/  130]
train() client id: f_00008-3-1 loss: 0.670139  [   64/  130]
train() client id: f_00008-3-2 loss: 0.631911  [   96/  130]
train() client id: f_00008-3-3 loss: 0.646446  [  128/  130]
train() client id: f_00008-4-0 loss: 0.716198  [   32/  130]
train() client id: f_00008-4-1 loss: 0.622786  [   64/  130]
train() client id: f_00008-4-2 loss: 0.645661  [   96/  130]
train() client id: f_00008-4-3 loss: 0.715572  [  128/  130]
train() client id: f_00008-5-0 loss: 0.630530  [   32/  130]
train() client id: f_00008-5-1 loss: 0.653015  [   64/  130]
train() client id: f_00008-5-2 loss: 0.678722  [   96/  130]
train() client id: f_00008-5-3 loss: 0.735525  [  128/  130]
train() client id: f_00008-6-0 loss: 0.550274  [   32/  130]
train() client id: f_00008-6-1 loss: 0.556530  [   64/  130]
train() client id: f_00008-6-2 loss: 0.770968  [   96/  130]
train() client id: f_00008-6-3 loss: 0.817175  [  128/  130]
train() client id: f_00008-7-0 loss: 0.569104  [   32/  130]
train() client id: f_00008-7-1 loss: 0.612485  [   64/  130]
train() client id: f_00008-7-2 loss: 0.791565  [   96/  130]
train() client id: f_00008-7-3 loss: 0.727684  [  128/  130]
train() client id: f_00008-8-0 loss: 0.610467  [   32/  130]
train() client id: f_00008-8-1 loss: 0.668413  [   64/  130]
train() client id: f_00008-8-2 loss: 0.651006  [   96/  130]
train() client id: f_00008-8-3 loss: 0.736824  [  128/  130]
train() client id: f_00008-9-0 loss: 0.576781  [   32/  130]
train() client id: f_00008-9-1 loss: 0.654192  [   64/  130]
train() client id: f_00008-9-2 loss: 0.708299  [   96/  130]
train() client id: f_00008-9-3 loss: 0.731962  [  128/  130]
train() client id: f_00008-10-0 loss: 0.659109  [   32/  130]
train() client id: f_00008-10-1 loss: 0.699036  [   64/  130]
train() client id: f_00008-10-2 loss: 0.671775  [   96/  130]
train() client id: f_00008-10-3 loss: 0.668133  [  128/  130]
train() client id: f_00008-11-0 loss: 0.754236  [   32/  130]
train() client id: f_00008-11-1 loss: 0.548154  [   64/  130]
train() client id: f_00008-11-2 loss: 0.684488  [   96/  130]
train() client id: f_00008-11-3 loss: 0.711236  [  128/  130]
train() client id: f_00008-12-0 loss: 0.683298  [   32/  130]
train() client id: f_00008-12-1 loss: 0.709187  [   64/  130]
train() client id: f_00008-12-2 loss: 0.621868  [   96/  130]
train() client id: f_00008-12-3 loss: 0.659924  [  128/  130]
train() client id: f_00009-0-0 loss: 1.011507  [   32/  118]
train() client id: f_00009-0-1 loss: 1.213966  [   64/  118]
train() client id: f_00009-0-2 loss: 1.052449  [   96/  118]
train() client id: f_00009-1-0 loss: 0.994015  [   32/  118]
train() client id: f_00009-1-1 loss: 0.876350  [   64/  118]
train() client id: f_00009-1-2 loss: 1.120943  [   96/  118]
train() client id: f_00009-2-0 loss: 1.010071  [   32/  118]
train() client id: f_00009-2-1 loss: 1.153519  [   64/  118]
train() client id: f_00009-2-2 loss: 0.919874  [   96/  118]
train() client id: f_00009-3-0 loss: 0.980451  [   32/  118]
train() client id: f_00009-3-1 loss: 0.927226  [   64/  118]
train() client id: f_00009-3-2 loss: 0.887606  [   96/  118]
train() client id: f_00009-4-0 loss: 0.895437  [   32/  118]
train() client id: f_00009-4-1 loss: 0.962620  [   64/  118]
train() client id: f_00009-4-2 loss: 0.921823  [   96/  118]
train() client id: f_00009-5-0 loss: 0.960798  [   32/  118]
train() client id: f_00009-5-1 loss: 0.890978  [   64/  118]
train() client id: f_00009-5-2 loss: 0.849579  [   96/  118]
train() client id: f_00009-6-0 loss: 0.830178  [   32/  118]
train() client id: f_00009-6-1 loss: 0.884653  [   64/  118]
train() client id: f_00009-6-2 loss: 0.863906  [   96/  118]
train() client id: f_00009-7-0 loss: 0.741093  [   32/  118]
train() client id: f_00009-7-1 loss: 0.989680  [   64/  118]
train() client id: f_00009-7-2 loss: 0.704287  [   96/  118]
train() client id: f_00009-8-0 loss: 0.932427  [   32/  118]
train() client id: f_00009-8-1 loss: 0.767667  [   64/  118]
train() client id: f_00009-8-2 loss: 0.908079  [   96/  118]
train() client id: f_00009-9-0 loss: 0.924594  [   32/  118]
train() client id: f_00009-9-1 loss: 0.859576  [   64/  118]
train() client id: f_00009-9-2 loss: 0.826456  [   96/  118]
train() client id: f_00009-10-0 loss: 0.819782  [   32/  118]
train() client id: f_00009-10-1 loss: 0.785985  [   64/  118]
train() client id: f_00009-10-2 loss: 0.865651  [   96/  118]
train() client id: f_00009-11-0 loss: 0.976319  [   32/  118]
train() client id: f_00009-11-1 loss: 0.766194  [   64/  118]
train() client id: f_00009-11-2 loss: 0.797195  [   96/  118]
train() client id: f_00009-12-0 loss: 0.797162  [   32/  118]
train() client id: f_00009-12-1 loss: 0.860652  [   64/  118]
train() client id: f_00009-12-2 loss: 0.832239  [   96/  118]
At round 37 accuracy: 0.6472148541114059
At round 37 training accuracy: 0.5895372233400402
At round 37 training loss: 0.8216953918919977
gradient difference: 0.4356045722961426
train() client id: f_00000-0-0 loss: 1.139168  [   32/  126]
train() client id: f_00000-0-1 loss: 1.244235  [   64/  126]
train() client id: f_00000-0-2 loss: 1.095622  [   96/  126]
train() client id: f_00000-1-0 loss: 1.185157  [   32/  126]
train() client id: f_00000-1-1 loss: 1.144514  [   64/  126]
train() client id: f_00000-1-2 loss: 0.993358  [   96/  126]
train() client id: f_00000-2-0 loss: 0.881590  [   32/  126]
train() client id: f_00000-2-1 loss: 0.898956  [   64/  126]
train() client id: f_00000-2-2 loss: 1.198418  [   96/  126]
train() client id: f_00000-3-0 loss: 1.044513  [   32/  126]
train() client id: f_00000-3-1 loss: 1.097377  [   64/  126]
train() client id: f_00000-3-2 loss: 0.814054  [   96/  126]
train() client id: f_00000-4-0 loss: 0.842075  [   32/  126]
train() client id: f_00000-4-1 loss: 0.958230  [   64/  126]
train() client id: f_00000-4-2 loss: 1.047462  [   96/  126]
train() client id: f_00000-5-0 loss: 0.911880  [   32/  126]
train() client id: f_00000-5-1 loss: 0.992445  [   64/  126]
train() client id: f_00000-5-2 loss: 0.799733  [   96/  126]
train() client id: f_00000-6-0 loss: 0.765305  [   32/  126]
train() client id: f_00000-6-1 loss: 0.779708  [   64/  126]
train() client id: f_00000-6-2 loss: 0.952044  [   96/  126]
train() client id: f_00000-7-0 loss: 0.785088  [   32/  126]
train() client id: f_00000-7-1 loss: 0.798578  [   64/  126]
train() client id: f_00000-7-2 loss: 0.876658  [   96/  126]
train() client id: f_00000-8-0 loss: 0.973935  [   32/  126]
train() client id: f_00000-8-1 loss: 0.704234  [   64/  126]
train() client id: f_00000-8-2 loss: 0.772865  [   96/  126]
train() client id: f_00000-9-0 loss: 0.774973  [   32/  126]
train() client id: f_00000-9-1 loss: 0.855618  [   64/  126]
train() client id: f_00000-9-2 loss: 0.741718  [   96/  126]
train() client id: f_00000-10-0 loss: 0.867282  [   32/  126]
train() client id: f_00000-10-1 loss: 0.891414  [   64/  126]
train() client id: f_00000-10-2 loss: 0.655041  [   96/  126]
train() client id: f_00000-11-0 loss: 0.942726  [   32/  126]
train() client id: f_00000-11-1 loss: 0.726917  [   64/  126]
train() client id: f_00000-11-2 loss: 0.687815  [   96/  126]
train() client id: f_00000-12-0 loss: 0.744236  [   32/  126]
train() client id: f_00000-12-1 loss: 0.687621  [   64/  126]
train() client id: f_00000-12-2 loss: 0.739502  [   96/  126]
train() client id: f_00001-0-0 loss: 0.396008  [   32/  265]
train() client id: f_00001-0-1 loss: 0.307695  [   64/  265]
train() client id: f_00001-0-2 loss: 0.383681  [   96/  265]
train() client id: f_00001-0-3 loss: 0.369766  [  128/  265]
train() client id: f_00001-0-4 loss: 0.349899  [  160/  265]
train() client id: f_00001-0-5 loss: 0.360701  [  192/  265]
train() client id: f_00001-0-6 loss: 0.425433  [  224/  265]
train() client id: f_00001-0-7 loss: 0.433724  [  256/  265]
train() client id: f_00001-1-0 loss: 0.406232  [   32/  265]
train() client id: f_00001-1-1 loss: 0.350226  [   64/  265]
train() client id: f_00001-1-2 loss: 0.403538  [   96/  265]
train() client id: f_00001-1-3 loss: 0.358759  [  128/  265]
train() client id: f_00001-1-4 loss: 0.297432  [  160/  265]
train() client id: f_00001-1-5 loss: 0.277583  [  192/  265]
train() client id: f_00001-1-6 loss: 0.332004  [  224/  265]
train() client id: f_00001-1-7 loss: 0.520472  [  256/  265]
train() client id: f_00001-2-0 loss: 0.278429  [   32/  265]
train() client id: f_00001-2-1 loss: 0.511525  [   64/  265]
train() client id: f_00001-2-2 loss: 0.523194  [   96/  265]
train() client id: f_00001-2-3 loss: 0.296345  [  128/  265]
train() client id: f_00001-2-4 loss: 0.388480  [  160/  265]
train() client id: f_00001-2-5 loss: 0.290465  [  192/  265]
train() client id: f_00001-2-6 loss: 0.274140  [  224/  265]
train() client id: f_00001-2-7 loss: 0.394005  [  256/  265]
train() client id: f_00001-3-0 loss: 0.287573  [   32/  265]
train() client id: f_00001-3-1 loss: 0.399037  [   64/  265]
train() client id: f_00001-3-2 loss: 0.305187  [   96/  265]
train() client id: f_00001-3-3 loss: 0.561641  [  128/  265]
train() client id: f_00001-3-4 loss: 0.315409  [  160/  265]
train() client id: f_00001-3-5 loss: 0.374815  [  192/  265]
train() client id: f_00001-3-6 loss: 0.276408  [  224/  265]
train() client id: f_00001-3-7 loss: 0.344983  [  256/  265]
train() client id: f_00001-4-0 loss: 0.264929  [   32/  265]
train() client id: f_00001-4-1 loss: 0.317866  [   64/  265]
train() client id: f_00001-4-2 loss: 0.332133  [   96/  265]
train() client id: f_00001-4-3 loss: 0.416210  [  128/  265]
train() client id: f_00001-4-4 loss: 0.365610  [  160/  265]
train() client id: f_00001-4-5 loss: 0.311979  [  192/  265]
train() client id: f_00001-4-6 loss: 0.483699  [  224/  265]
train() client id: f_00001-4-7 loss: 0.407866  [  256/  265]
train() client id: f_00001-5-0 loss: 0.265432  [   32/  265]
train() client id: f_00001-5-1 loss: 0.413981  [   64/  265]
train() client id: f_00001-5-2 loss: 0.375198  [   96/  265]
train() client id: f_00001-5-3 loss: 0.440695  [  128/  265]
train() client id: f_00001-5-4 loss: 0.275494  [  160/  265]
train() client id: f_00001-5-5 loss: 0.325015  [  192/  265]
train() client id: f_00001-5-6 loss: 0.482674  [  224/  265]
train() client id: f_00001-5-7 loss: 0.296841  [  256/  265]
train() client id: f_00001-6-0 loss: 0.271057  [   32/  265]
train() client id: f_00001-6-1 loss: 0.325993  [   64/  265]
train() client id: f_00001-6-2 loss: 0.361320  [   96/  265]
train() client id: f_00001-6-3 loss: 0.343835  [  128/  265]
train() client id: f_00001-6-4 loss: 0.263842  [  160/  265]
train() client id: f_00001-6-5 loss: 0.456573  [  192/  265]
train() client id: f_00001-6-6 loss: 0.431617  [  224/  265]
train() client id: f_00001-6-7 loss: 0.381924  [  256/  265]
train() client id: f_00001-7-0 loss: 0.373388  [   32/  265]
train() client id: f_00001-7-1 loss: 0.411397  [   64/  265]
train() client id: f_00001-7-2 loss: 0.284902  [   96/  265]
train() client id: f_00001-7-3 loss: 0.247445  [  128/  265]
train() client id: f_00001-7-4 loss: 0.319845  [  160/  265]
train() client id: f_00001-7-5 loss: 0.487682  [  192/  265]
train() client id: f_00001-7-6 loss: 0.348938  [  224/  265]
train() client id: f_00001-7-7 loss: 0.398505  [  256/  265]
train() client id: f_00001-8-0 loss: 0.339202  [   32/  265]
train() client id: f_00001-8-1 loss: 0.277390  [   64/  265]
train() client id: f_00001-8-2 loss: 0.322382  [   96/  265]
train() client id: f_00001-8-3 loss: 0.269300  [  128/  265]
train() client id: f_00001-8-4 loss: 0.425850  [  160/  265]
train() client id: f_00001-8-5 loss: 0.282471  [  192/  265]
train() client id: f_00001-8-6 loss: 0.425330  [  224/  265]
train() client id: f_00001-8-7 loss: 0.514006  [  256/  265]
train() client id: f_00001-9-0 loss: 0.654757  [   32/  265]
train() client id: f_00001-9-1 loss: 0.258627  [   64/  265]
train() client id: f_00001-9-2 loss: 0.438322  [   96/  265]
train() client id: f_00001-9-3 loss: 0.298684  [  128/  265]
train() client id: f_00001-9-4 loss: 0.411039  [  160/  265]
train() client id: f_00001-9-5 loss: 0.287947  [  192/  265]
train() client id: f_00001-9-6 loss: 0.231245  [  224/  265]
train() client id: f_00001-9-7 loss: 0.271128  [  256/  265]
train() client id: f_00001-10-0 loss: 0.406295  [   32/  265]
train() client id: f_00001-10-1 loss: 0.260544  [   64/  265]
train() client id: f_00001-10-2 loss: 0.278786  [   96/  265]
train() client id: f_00001-10-3 loss: 0.425031  [  128/  265]
train() client id: f_00001-10-4 loss: 0.458361  [  160/  265]
train() client id: f_00001-10-5 loss: 0.366790  [  192/  265]
train() client id: f_00001-10-6 loss: 0.283104  [  224/  265]
train() client id: f_00001-10-7 loss: 0.294582  [  256/  265]
train() client id: f_00001-11-0 loss: 0.294205  [   32/  265]
train() client id: f_00001-11-1 loss: 0.382972  [   64/  265]
train() client id: f_00001-11-2 loss: 0.265139  [   96/  265]
train() client id: f_00001-11-3 loss: 0.460913  [  128/  265]
train() client id: f_00001-11-4 loss: 0.343566  [  160/  265]
train() client id: f_00001-11-5 loss: 0.399512  [  192/  265]
train() client id: f_00001-11-6 loss: 0.302631  [  224/  265]
train() client id: f_00001-11-7 loss: 0.402928  [  256/  265]
train() client id: f_00001-12-0 loss: 0.347339  [   32/  265]
train() client id: f_00001-12-1 loss: 0.280794  [   64/  265]
train() client id: f_00001-12-2 loss: 0.477679  [   96/  265]
train() client id: f_00001-12-3 loss: 0.332604  [  128/  265]
train() client id: f_00001-12-4 loss: 0.306216  [  160/  265]
train() client id: f_00001-12-5 loss: 0.341479  [  192/  265]
train() client id: f_00001-12-6 loss: 0.440222  [  224/  265]
train() client id: f_00001-12-7 loss: 0.334533  [  256/  265]
train() client id: f_00002-0-0 loss: 1.133826  [   32/  124]
train() client id: f_00002-0-1 loss: 1.063920  [   64/  124]
train() client id: f_00002-0-2 loss: 1.167099  [   96/  124]
train() client id: f_00002-1-0 loss: 1.092821  [   32/  124]
train() client id: f_00002-1-1 loss: 1.008674  [   64/  124]
train() client id: f_00002-1-2 loss: 1.010624  [   96/  124]
train() client id: f_00002-2-0 loss: 0.864757  [   32/  124]
train() client id: f_00002-2-1 loss: 1.254454  [   64/  124]
train() client id: f_00002-2-2 loss: 0.989519  [   96/  124]
train() client id: f_00002-3-0 loss: 0.796609  [   32/  124]
train() client id: f_00002-3-1 loss: 1.022194  [   64/  124]
train() client id: f_00002-3-2 loss: 1.110706  [   96/  124]
train() client id: f_00002-4-0 loss: 0.995884  [   32/  124]
train() client id: f_00002-4-1 loss: 1.024570  [   64/  124]
train() client id: f_00002-4-2 loss: 0.836003  [   96/  124]
train() client id: f_00002-5-0 loss: 0.905563  [   32/  124]
train() client id: f_00002-5-1 loss: 0.841885  [   64/  124]
train() client id: f_00002-5-2 loss: 0.917373  [   96/  124]
train() client id: f_00002-6-0 loss: 0.856801  [   32/  124]
train() client id: f_00002-6-1 loss: 0.893301  [   64/  124]
train() client id: f_00002-6-2 loss: 1.022880  [   96/  124]
train() client id: f_00002-7-0 loss: 0.759088  [   32/  124]
train() client id: f_00002-7-1 loss: 0.715741  [   64/  124]
train() client id: f_00002-7-2 loss: 0.949899  [   96/  124]
train() client id: f_00002-8-0 loss: 0.891235  [   32/  124]
train() client id: f_00002-8-1 loss: 0.885211  [   64/  124]
train() client id: f_00002-8-2 loss: 0.853063  [   96/  124]
train() client id: f_00002-9-0 loss: 0.773725  [   32/  124]
train() client id: f_00002-9-1 loss: 0.798672  [   64/  124]
train() client id: f_00002-9-2 loss: 0.834018  [   96/  124]
train() client id: f_00002-10-0 loss: 0.835776  [   32/  124]
train() client id: f_00002-10-1 loss: 0.853162  [   64/  124]
train() client id: f_00002-10-2 loss: 0.963951  [   96/  124]
train() client id: f_00002-11-0 loss: 0.804328  [   32/  124]
train() client id: f_00002-11-1 loss: 0.983654  [   64/  124]
train() client id: f_00002-11-2 loss: 0.779456  [   96/  124]
train() client id: f_00002-12-0 loss: 0.733804  [   32/  124]
train() client id: f_00002-12-1 loss: 0.999362  [   64/  124]
train() client id: f_00002-12-2 loss: 0.865030  [   96/  124]
train() client id: f_00003-0-0 loss: 0.525457  [   32/   43]
train() client id: f_00003-1-0 loss: 0.452752  [   32/   43]
train() client id: f_00003-2-0 loss: 0.588383  [   32/   43]
train() client id: f_00003-3-0 loss: 0.668238  [   32/   43]
train() client id: f_00003-4-0 loss: 0.593951  [   32/   43]
train() client id: f_00003-5-0 loss: 0.702904  [   32/   43]
train() client id: f_00003-6-0 loss: 0.557988  [   32/   43]
train() client id: f_00003-7-0 loss: 0.577428  [   32/   43]
train() client id: f_00003-8-0 loss: 0.625781  [   32/   43]
train() client id: f_00003-9-0 loss: 0.622942  [   32/   43]
train() client id: f_00003-10-0 loss: 0.439805  [   32/   43]
train() client id: f_00003-11-0 loss: 0.614153  [   32/   43]
train() client id: f_00003-12-0 loss: 0.592645  [   32/   43]
train() client id: f_00004-0-0 loss: 0.865756  [   32/  306]
train() client id: f_00004-0-1 loss: 0.733389  [   64/  306]
train() client id: f_00004-0-2 loss: 0.940287  [   96/  306]
train() client id: f_00004-0-3 loss: 0.853928  [  128/  306]
train() client id: f_00004-0-4 loss: 0.938500  [  160/  306]
train() client id: f_00004-0-5 loss: 0.875058  [  192/  306]
train() client id: f_00004-0-6 loss: 0.965795  [  224/  306]
train() client id: f_00004-0-7 loss: 0.968706  [  256/  306]
train() client id: f_00004-0-8 loss: 0.869850  [  288/  306]
train() client id: f_00004-1-0 loss: 0.986065  [   32/  306]
train() client id: f_00004-1-1 loss: 0.870492  [   64/  306]
train() client id: f_00004-1-2 loss: 0.769015  [   96/  306]
train() client id: f_00004-1-3 loss: 0.818982  [  128/  306]
train() client id: f_00004-1-4 loss: 0.815991  [  160/  306]
train() client id: f_00004-1-5 loss: 0.892779  [  192/  306]
train() client id: f_00004-1-6 loss: 1.011475  [  224/  306]
train() client id: f_00004-1-7 loss: 0.947416  [  256/  306]
train() client id: f_00004-1-8 loss: 0.852813  [  288/  306]
train() client id: f_00004-2-0 loss: 0.968878  [   32/  306]
train() client id: f_00004-2-1 loss: 0.843848  [   64/  306]
train() client id: f_00004-2-2 loss: 0.779619  [   96/  306]
train() client id: f_00004-2-3 loss: 0.912742  [  128/  306]
train() client id: f_00004-2-4 loss: 0.896557  [  160/  306]
train() client id: f_00004-2-5 loss: 0.798478  [  192/  306]
train() client id: f_00004-2-6 loss: 0.820172  [  224/  306]
train() client id: f_00004-2-7 loss: 1.025316  [  256/  306]
train() client id: f_00004-2-8 loss: 0.963340  [  288/  306]
train() client id: f_00004-3-0 loss: 0.866651  [   32/  306]
train() client id: f_00004-3-1 loss: 0.899329  [   64/  306]
train() client id: f_00004-3-2 loss: 1.049428  [   96/  306]
train() client id: f_00004-3-3 loss: 0.869310  [  128/  306]
train() client id: f_00004-3-4 loss: 0.877726  [  160/  306]
train() client id: f_00004-3-5 loss: 0.886726  [  192/  306]
train() client id: f_00004-3-6 loss: 0.884851  [  224/  306]
train() client id: f_00004-3-7 loss: 0.824007  [  256/  306]
train() client id: f_00004-3-8 loss: 0.815444  [  288/  306]
train() client id: f_00004-4-0 loss: 0.694307  [   32/  306]
train() client id: f_00004-4-1 loss: 0.885376  [   64/  306]
train() client id: f_00004-4-2 loss: 0.852658  [   96/  306]
train() client id: f_00004-4-3 loss: 0.944768  [  128/  306]
train() client id: f_00004-4-4 loss: 0.838984  [  160/  306]
train() client id: f_00004-4-5 loss: 1.037052  [  192/  306]
train() client id: f_00004-4-6 loss: 1.054566  [  224/  306]
train() client id: f_00004-4-7 loss: 0.858972  [  256/  306]
train() client id: f_00004-4-8 loss: 0.782278  [  288/  306]
train() client id: f_00004-5-0 loss: 0.918229  [   32/  306]
train() client id: f_00004-5-1 loss: 0.887598  [   64/  306]
train() client id: f_00004-5-2 loss: 0.907598  [   96/  306]
train() client id: f_00004-5-3 loss: 0.895040  [  128/  306]
train() client id: f_00004-5-4 loss: 0.910424  [  160/  306]
train() client id: f_00004-5-5 loss: 0.824595  [  192/  306]
train() client id: f_00004-5-6 loss: 0.917767  [  224/  306]
train() client id: f_00004-5-7 loss: 0.900161  [  256/  306]
train() client id: f_00004-5-8 loss: 0.853783  [  288/  306]
train() client id: f_00004-6-0 loss: 0.857328  [   32/  306]
train() client id: f_00004-6-1 loss: 0.904104  [   64/  306]
train() client id: f_00004-6-2 loss: 0.790762  [   96/  306]
train() client id: f_00004-6-3 loss: 0.939191  [  128/  306]
train() client id: f_00004-6-4 loss: 0.965879  [  160/  306]
train() client id: f_00004-6-5 loss: 0.931572  [  192/  306]
train() client id: f_00004-6-6 loss: 0.850289  [  224/  306]
train() client id: f_00004-6-7 loss: 0.994973  [  256/  306]
train() client id: f_00004-6-8 loss: 0.863092  [  288/  306]
train() client id: f_00004-7-0 loss: 0.969933  [   32/  306]
train() client id: f_00004-7-1 loss: 0.815542  [   64/  306]
train() client id: f_00004-7-2 loss: 0.950699  [   96/  306]
train() client id: f_00004-7-3 loss: 0.974937  [  128/  306]
train() client id: f_00004-7-4 loss: 0.883244  [  160/  306]
train() client id: f_00004-7-5 loss: 0.850044  [  192/  306]
train() client id: f_00004-7-6 loss: 0.716742  [  224/  306]
train() client id: f_00004-7-7 loss: 0.986879  [  256/  306]
train() client id: f_00004-7-8 loss: 0.839053  [  288/  306]
train() client id: f_00004-8-0 loss: 0.809672  [   32/  306]
train() client id: f_00004-8-1 loss: 0.973732  [   64/  306]
train() client id: f_00004-8-2 loss: 0.811528  [   96/  306]
train() client id: f_00004-8-3 loss: 0.884592  [  128/  306]
train() client id: f_00004-8-4 loss: 0.792520  [  160/  306]
train() client id: f_00004-8-5 loss: 0.838887  [  192/  306]
train() client id: f_00004-8-6 loss: 0.951211  [  224/  306]
train() client id: f_00004-8-7 loss: 1.009165  [  256/  306]
train() client id: f_00004-8-8 loss: 0.896558  [  288/  306]
train() client id: f_00004-9-0 loss: 0.944495  [   32/  306]
train() client id: f_00004-9-1 loss: 0.895210  [   64/  306]
train() client id: f_00004-9-2 loss: 0.884239  [   96/  306]
train() client id: f_00004-9-3 loss: 0.874844  [  128/  306]
train() client id: f_00004-9-4 loss: 0.905066  [  160/  306]
train() client id: f_00004-9-5 loss: 0.864068  [  192/  306]
train() client id: f_00004-9-6 loss: 0.843251  [  224/  306]
train() client id: f_00004-9-7 loss: 0.881017  [  256/  306]
train() client id: f_00004-9-8 loss: 0.885254  [  288/  306]
train() client id: f_00004-10-0 loss: 0.964979  [   32/  306]
train() client id: f_00004-10-1 loss: 0.885708  [   64/  306]
train() client id: f_00004-10-2 loss: 0.962395  [   96/  306]
train() client id: f_00004-10-3 loss: 0.827873  [  128/  306]
train() client id: f_00004-10-4 loss: 0.843364  [  160/  306]
train() client id: f_00004-10-5 loss: 0.894854  [  192/  306]
train() client id: f_00004-10-6 loss: 0.904252  [  224/  306]
train() client id: f_00004-10-7 loss: 0.902814  [  256/  306]
train() client id: f_00004-10-8 loss: 0.884992  [  288/  306]
train() client id: f_00004-11-0 loss: 0.881101  [   32/  306]
train() client id: f_00004-11-1 loss: 0.871059  [   64/  306]
train() client id: f_00004-11-2 loss: 0.884939  [   96/  306]
train() client id: f_00004-11-3 loss: 0.828898  [  128/  306]
train() client id: f_00004-11-4 loss: 0.950199  [  160/  306]
train() client id: f_00004-11-5 loss: 0.815821  [  192/  306]
train() client id: f_00004-11-6 loss: 0.904751  [  224/  306]
train() client id: f_00004-11-7 loss: 0.930399  [  256/  306]
train() client id: f_00004-11-8 loss: 0.935407  [  288/  306]
train() client id: f_00004-12-0 loss: 0.937233  [   32/  306]
train() client id: f_00004-12-1 loss: 0.817842  [   64/  306]
train() client id: f_00004-12-2 loss: 0.982551  [   96/  306]
train() client id: f_00004-12-3 loss: 0.872770  [  128/  306]
train() client id: f_00004-12-4 loss: 0.863611  [  160/  306]
train() client id: f_00004-12-5 loss: 0.855427  [  192/  306]
train() client id: f_00004-12-6 loss: 0.943838  [  224/  306]
train() client id: f_00004-12-7 loss: 0.912227  [  256/  306]
train() client id: f_00004-12-8 loss: 0.867895  [  288/  306]
train() client id: f_00005-0-0 loss: 0.474598  [   32/  146]
train() client id: f_00005-0-1 loss: 0.352266  [   64/  146]
train() client id: f_00005-0-2 loss: 0.329024  [   96/  146]
train() client id: f_00005-0-3 loss: 0.309218  [  128/  146]
train() client id: f_00005-1-0 loss: 0.307801  [   32/  146]
train() client id: f_00005-1-1 loss: 0.461787  [   64/  146]
train() client id: f_00005-1-2 loss: 0.328746  [   96/  146]
train() client id: f_00005-1-3 loss: 0.323950  [  128/  146]
train() client id: f_00005-2-0 loss: 0.196170  [   32/  146]
train() client id: f_00005-2-1 loss: 0.462042  [   64/  146]
train() client id: f_00005-2-2 loss: 0.468625  [   96/  146]
train() client id: f_00005-2-3 loss: 0.427405  [  128/  146]
train() client id: f_00005-3-0 loss: 0.341936  [   32/  146]
train() client id: f_00005-3-1 loss: 0.421986  [   64/  146]
train() client id: f_00005-3-2 loss: 0.564691  [   96/  146]
train() client id: f_00005-3-3 loss: 0.161829  [  128/  146]
train() client id: f_00005-4-0 loss: 0.456153  [   32/  146]
train() client id: f_00005-4-1 loss: 0.546774  [   64/  146]
train() client id: f_00005-4-2 loss: 0.362704  [   96/  146]
train() client id: f_00005-4-3 loss: 0.242376  [  128/  146]
train() client id: f_00005-5-0 loss: 0.256503  [   32/  146]
train() client id: f_00005-5-1 loss: 0.389476  [   64/  146]
train() client id: f_00005-5-2 loss: 0.322518  [   96/  146]
train() client id: f_00005-5-3 loss: 0.655447  [  128/  146]
train() client id: f_00005-6-0 loss: 0.537637  [   32/  146]
train() client id: f_00005-6-1 loss: 0.196224  [   64/  146]
train() client id: f_00005-6-2 loss: 0.397558  [   96/  146]
train() client id: f_00005-6-3 loss: 0.189894  [  128/  146]
train() client id: f_00005-7-0 loss: 0.248567  [   32/  146]
train() client id: f_00005-7-1 loss: 0.198020  [   64/  146]
train() client id: f_00005-7-2 loss: 0.172211  [   96/  146]
train() client id: f_00005-7-3 loss: 0.555476  [  128/  146]
train() client id: f_00005-8-0 loss: 0.405446  [   32/  146]
train() client id: f_00005-8-1 loss: 0.392447  [   64/  146]
train() client id: f_00005-8-2 loss: 0.346641  [   96/  146]
train() client id: f_00005-8-3 loss: 0.315249  [  128/  146]
train() client id: f_00005-9-0 loss: 0.514564  [   32/  146]
train() client id: f_00005-9-1 loss: 0.226466  [   64/  146]
train() client id: f_00005-9-2 loss: 0.253758  [   96/  146]
train() client id: f_00005-9-3 loss: 0.535886  [  128/  146]
train() client id: f_00005-10-0 loss: 0.222310  [   32/  146]
train() client id: f_00005-10-1 loss: 0.400111  [   64/  146]
train() client id: f_00005-10-2 loss: 0.537339  [   96/  146]
train() client id: f_00005-10-3 loss: 0.334908  [  128/  146]
train() client id: f_00005-11-0 loss: 0.343060  [   32/  146]
train() client id: f_00005-11-1 loss: 0.434387  [   64/  146]
train() client id: f_00005-11-2 loss: 0.550316  [   96/  146]
train() client id: f_00005-11-3 loss: 0.248074  [  128/  146]
train() client id: f_00005-12-0 loss: 0.417024  [   32/  146]
train() client id: f_00005-12-1 loss: 0.320837  [   64/  146]
train() client id: f_00005-12-2 loss: 0.267961  [   96/  146]
train() client id: f_00005-12-3 loss: 0.455450  [  128/  146]
train() client id: f_00006-0-0 loss: 0.513945  [   32/   54]
train() client id: f_00006-1-0 loss: 0.538412  [   32/   54]
train() client id: f_00006-2-0 loss: 0.562816  [   32/   54]
train() client id: f_00006-3-0 loss: 0.483897  [   32/   54]
train() client id: f_00006-4-0 loss: 0.538856  [   32/   54]
train() client id: f_00006-5-0 loss: 0.522330  [   32/   54]
train() client id: f_00006-6-0 loss: 0.571833  [   32/   54]
train() client id: f_00006-7-0 loss: 0.553218  [   32/   54]
train() client id: f_00006-8-0 loss: 0.580429  [   32/   54]
train() client id: f_00006-9-0 loss: 0.488337  [   32/   54]
train() client id: f_00006-10-0 loss: 0.515319  [   32/   54]
train() client id: f_00006-11-0 loss: 0.579434  [   32/   54]
train() client id: f_00006-12-0 loss: 0.539919  [   32/   54]
train() client id: f_00007-0-0 loss: 0.549525  [   32/  179]
train() client id: f_00007-0-1 loss: 0.574877  [   64/  179]
train() client id: f_00007-0-2 loss: 0.792490  [   96/  179]
train() client id: f_00007-0-3 loss: 0.576720  [  128/  179]
train() client id: f_00007-0-4 loss: 0.530848  [  160/  179]
train() client id: f_00007-1-0 loss: 0.760398  [   32/  179]
train() client id: f_00007-1-1 loss: 0.509659  [   64/  179]
train() client id: f_00007-1-2 loss: 0.607452  [   96/  179]
train() client id: f_00007-1-3 loss: 0.500127  [  128/  179]
train() client id: f_00007-1-4 loss: 0.406167  [  160/  179]
train() client id: f_00007-2-0 loss: 0.541764  [   32/  179]
train() client id: f_00007-2-1 loss: 0.498021  [   64/  179]
train() client id: f_00007-2-2 loss: 0.446477  [   96/  179]
train() client id: f_00007-2-3 loss: 0.667325  [  128/  179]
train() client id: f_00007-2-4 loss: 0.708755  [  160/  179]
train() client id: f_00007-3-0 loss: 0.683627  [   32/  179]
train() client id: f_00007-3-1 loss: 0.674545  [   64/  179]
train() client id: f_00007-3-2 loss: 0.590553  [   96/  179]
train() client id: f_00007-3-3 loss: 0.460834  [  128/  179]
train() client id: f_00007-3-4 loss: 0.501879  [  160/  179]
train() client id: f_00007-4-0 loss: 0.804196  [   32/  179]
train() client id: f_00007-4-1 loss: 0.540056  [   64/  179]
train() client id: f_00007-4-2 loss: 0.592101  [   96/  179]
train() client id: f_00007-4-3 loss: 0.535028  [  128/  179]
train() client id: f_00007-4-4 loss: 0.449566  [  160/  179]
train() client id: f_00007-5-0 loss: 0.619638  [   32/  179]
train() client id: f_00007-5-1 loss: 0.500313  [   64/  179]
train() client id: f_00007-5-2 loss: 0.547984  [   96/  179]
train() client id: f_00007-5-3 loss: 0.864530  [  128/  179]
train() client id: f_00007-5-4 loss: 0.417796  [  160/  179]
train() client id: f_00007-6-0 loss: 0.718046  [   32/  179]
train() client id: f_00007-6-1 loss: 0.414018  [   64/  179]
train() client id: f_00007-6-2 loss: 0.700540  [   96/  179]
train() client id: f_00007-6-3 loss: 0.694661  [  128/  179]
train() client id: f_00007-6-4 loss: 0.442625  [  160/  179]
train() client id: f_00007-7-0 loss: 0.485505  [   32/  179]
train() client id: f_00007-7-1 loss: 0.726129  [   64/  179]
train() client id: f_00007-7-2 loss: 0.590528  [   96/  179]
train() client id: f_00007-7-3 loss: 0.600351  [  128/  179]
train() client id: f_00007-7-4 loss: 0.456010  [  160/  179]
train() client id: f_00007-8-0 loss: 0.741721  [   32/  179]
train() client id: f_00007-8-1 loss: 0.521380  [   64/  179]
train() client id: f_00007-8-2 loss: 0.522644  [   96/  179]
train() client id: f_00007-8-3 loss: 0.600850  [  128/  179]
train() client id: f_00007-8-4 loss: 0.497279  [  160/  179]
train() client id: f_00007-9-0 loss: 0.534319  [   32/  179]
train() client id: f_00007-9-1 loss: 0.425010  [   64/  179]
train() client id: f_00007-9-2 loss: 0.668537  [   96/  179]
train() client id: f_00007-9-3 loss: 0.544097  [  128/  179]
train() client id: f_00007-9-4 loss: 0.497204  [  160/  179]
train() client id: f_00007-10-0 loss: 0.544156  [   32/  179]
train() client id: f_00007-10-1 loss: 0.505847  [   64/  179]
train() client id: f_00007-10-2 loss: 0.561195  [   96/  179]
train() client id: f_00007-10-3 loss: 0.522023  [  128/  179]
train() client id: f_00007-10-4 loss: 0.851337  [  160/  179]
train() client id: f_00007-11-0 loss: 0.852403  [   32/  179]
train() client id: f_00007-11-1 loss: 0.433357  [   64/  179]
train() client id: f_00007-11-2 loss: 0.489536  [   96/  179]
train() client id: f_00007-11-3 loss: 0.551359  [  128/  179]
train() client id: f_00007-11-4 loss: 0.521857  [  160/  179]
train() client id: f_00007-12-0 loss: 0.427761  [   32/  179]
train() client id: f_00007-12-1 loss: 0.571160  [   64/  179]
train() client id: f_00007-12-2 loss: 0.650185  [   96/  179]
train() client id: f_00007-12-3 loss: 0.649734  [  128/  179]
train() client id: f_00007-12-4 loss: 0.581122  [  160/  179]
train() client id: f_00008-0-0 loss: 0.710079  [   32/  130]
train() client id: f_00008-0-1 loss: 0.713610  [   64/  130]
train() client id: f_00008-0-2 loss: 0.726656  [   96/  130]
train() client id: f_00008-0-3 loss: 0.820546  [  128/  130]
train() client id: f_00008-1-0 loss: 0.693405  [   32/  130]
train() client id: f_00008-1-1 loss: 0.636327  [   64/  130]
train() client id: f_00008-1-2 loss: 0.831978  [   96/  130]
train() client id: f_00008-1-3 loss: 0.830457  [  128/  130]
train() client id: f_00008-2-0 loss: 0.811116  [   32/  130]
train() client id: f_00008-2-1 loss: 0.783527  [   64/  130]
train() client id: f_00008-2-2 loss: 0.696281  [   96/  130]
train() client id: f_00008-2-3 loss: 0.689997  [  128/  130]
train() client id: f_00008-3-0 loss: 0.777850  [   32/  130]
train() client id: f_00008-3-1 loss: 0.726531  [   64/  130]
train() client id: f_00008-3-2 loss: 0.729911  [   96/  130]
train() client id: f_00008-3-3 loss: 0.721694  [  128/  130]
train() client id: f_00008-4-0 loss: 0.723983  [   32/  130]
train() client id: f_00008-4-1 loss: 0.767615  [   64/  130]
train() client id: f_00008-4-2 loss: 0.675811  [   96/  130]
train() client id: f_00008-4-3 loss: 0.813776  [  128/  130]
train() client id: f_00008-5-0 loss: 0.815594  [   32/  130]
train() client id: f_00008-5-1 loss: 0.732224  [   64/  130]
train() client id: f_00008-5-2 loss: 0.713706  [   96/  130]
train() client id: f_00008-5-3 loss: 0.715647  [  128/  130]
train() client id: f_00008-6-0 loss: 0.835250  [   32/  130]
train() client id: f_00008-6-1 loss: 0.775312  [   64/  130]
train() client id: f_00008-6-2 loss: 0.748821  [   96/  130]
train() client id: f_00008-6-3 loss: 0.620155  [  128/  130]
train() client id: f_00008-7-0 loss: 0.727952  [   32/  130]
train() client id: f_00008-7-1 loss: 0.724260  [   64/  130]
train() client id: f_00008-7-2 loss: 0.771961  [   96/  130]
train() client id: f_00008-7-3 loss: 0.708862  [  128/  130]
train() client id: f_00008-8-0 loss: 0.733883  [   32/  130]
train() client id: f_00008-8-1 loss: 0.770534  [   64/  130]
train() client id: f_00008-8-2 loss: 0.813479  [   96/  130]
train() client id: f_00008-8-3 loss: 0.652850  [  128/  130]
train() client id: f_00008-9-0 loss: 0.851094  [   32/  130]
train() client id: f_00008-9-1 loss: 0.690210  [   64/  130]
train() client id: f_00008-9-2 loss: 0.722666  [   96/  130]
train() client id: f_00008-9-3 loss: 0.698796  [  128/  130]
train() client id: f_00008-10-0 loss: 0.735992  [   32/  130]
train() client id: f_00008-10-1 loss: 0.673222  [   64/  130]
train() client id: f_00008-10-2 loss: 0.732527  [   96/  130]
train() client id: f_00008-10-3 loss: 0.819778  [  128/  130]
train() client id: f_00008-11-0 loss: 0.717057  [   32/  130]
train() client id: f_00008-11-1 loss: 0.771313  [   64/  130]
train() client id: f_00008-11-2 loss: 0.704706  [   96/  130]
train() client id: f_00008-11-3 loss: 0.784304  [  128/  130]
train() client id: f_00008-12-0 loss: 0.758215  [   32/  130]
train() client id: f_00008-12-1 loss: 0.819549  [   64/  130]
train() client id: f_00008-12-2 loss: 0.724212  [   96/  130]
train() client id: f_00008-12-3 loss: 0.672327  [  128/  130]
train() client id: f_00009-0-0 loss: 1.193499  [   32/  118]
train() client id: f_00009-0-1 loss: 0.885495  [   64/  118]
train() client id: f_00009-0-2 loss: 1.021857  [   96/  118]
train() client id: f_00009-1-0 loss: 1.049383  [   32/  118]
train() client id: f_00009-1-1 loss: 0.962939  [   64/  118]
train() client id: f_00009-1-2 loss: 1.053264  [   96/  118]
train() client id: f_00009-2-0 loss: 0.996974  [   32/  118]
train() client id: f_00009-2-1 loss: 0.937435  [   64/  118]
train() client id: f_00009-2-2 loss: 0.987968  [   96/  118]
train() client id: f_00009-3-0 loss: 0.839554  [   32/  118]
train() client id: f_00009-3-1 loss: 1.039079  [   64/  118]
train() client id: f_00009-3-2 loss: 0.888405  [   96/  118]
train() client id: f_00009-4-0 loss: 1.022800  [   32/  118]
train() client id: f_00009-4-1 loss: 0.811590  [   64/  118]
train() client id: f_00009-4-2 loss: 0.892658  [   96/  118]
train() client id: f_00009-5-0 loss: 0.789045  [   32/  118]
train() client id: f_00009-5-1 loss: 0.968707  [   64/  118]
train() client id: f_00009-5-2 loss: 0.872220  [   96/  118]
train() client id: f_00009-6-0 loss: 0.825440  [   32/  118]
train() client id: f_00009-6-1 loss: 0.860504  [   64/  118]
train() client id: f_00009-6-2 loss: 0.843556  [   96/  118]
train() client id: f_00009-7-0 loss: 0.827630  [   32/  118]
train() client id: f_00009-7-1 loss: 0.906573  [   64/  118]
train() client id: f_00009-7-2 loss: 0.870304  [   96/  118]
train() client id: f_00009-8-0 loss: 0.969644  [   32/  118]
train() client id: f_00009-8-1 loss: 0.833580  [   64/  118]
train() client id: f_00009-8-2 loss: 0.628851  [   96/  118]
train() client id: f_00009-9-0 loss: 0.913590  [   32/  118]
train() client id: f_00009-9-1 loss: 0.798853  [   64/  118]
train() client id: f_00009-9-2 loss: 0.731241  [   96/  118]
train() client id: f_00009-10-0 loss: 0.948633  [   32/  118]
train() client id: f_00009-10-1 loss: 0.731378  [   64/  118]
train() client id: f_00009-10-2 loss: 0.739525  [   96/  118]
train() client id: f_00009-11-0 loss: 0.806226  [   32/  118]
train() client id: f_00009-11-1 loss: 0.707653  [   64/  118]
train() client id: f_00009-11-2 loss: 0.950107  [   96/  118]
train() client id: f_00009-12-0 loss: 0.775160  [   32/  118]
train() client id: f_00009-12-1 loss: 0.751819  [   64/  118]
train() client id: f_00009-12-2 loss: 0.929340  [   96/  118]
At round 38 accuracy: 0.6445623342175066
At round 38 training accuracy: 0.5875251509054326
At round 38 training loss: 0.8338925856123323
gradient difference: 0.43986600637435913
train() client id: f_00000-0-0 loss: 1.385325  [   32/  126]
train() client id: f_00000-0-1 loss: 1.187508  [   64/  126]
train() client id: f_00000-0-2 loss: 1.066548  [   96/  126]
train() client id: f_00000-1-0 loss: 1.199926  [   32/  126]
train() client id: f_00000-1-1 loss: 1.017755  [   64/  126]
train() client id: f_00000-1-2 loss: 1.091746  [   96/  126]
train() client id: f_00000-2-0 loss: 0.908837  [   32/  126]
train() client id: f_00000-2-1 loss: 0.996738  [   64/  126]
train() client id: f_00000-2-2 loss: 1.189907  [   96/  126]
train() client id: f_00000-3-0 loss: 1.017506  [   32/  126]
train() client id: f_00000-3-1 loss: 0.867453  [   64/  126]
train() client id: f_00000-3-2 loss: 1.020549  [   96/  126]
train() client id: f_00000-4-0 loss: 0.913539  [   32/  126]
train() client id: f_00000-4-1 loss: 1.039219  [   64/  126]
train() client id: f_00000-4-2 loss: 0.852746  [   96/  126]
train() client id: f_00000-5-0 loss: 1.027400  [   32/  126]
train() client id: f_00000-5-1 loss: 0.920658  [   64/  126]
train() client id: f_00000-5-2 loss: 0.834254  [   96/  126]
train() client id: f_00000-6-0 loss: 0.865068  [   32/  126]
train() client id: f_00000-6-1 loss: 1.004715  [   64/  126]
train() client id: f_00000-6-2 loss: 0.809485  [   96/  126]
train() client id: f_00000-7-0 loss: 0.840126  [   32/  126]
train() client id: f_00000-7-1 loss: 0.913071  [   64/  126]
train() client id: f_00000-7-2 loss: 0.932661  [   96/  126]
train() client id: f_00000-8-0 loss: 0.896537  [   32/  126]
train() client id: f_00000-8-1 loss: 0.743299  [   64/  126]
train() client id: f_00000-8-2 loss: 0.975599  [   96/  126]
train() client id: f_00000-9-0 loss: 0.902266  [   32/  126]
train() client id: f_00000-9-1 loss: 0.969479  [   64/  126]
train() client id: f_00000-9-2 loss: 0.801862  [   96/  126]
train() client id: f_00000-10-0 loss: 0.826285  [   32/  126]
train() client id: f_00000-10-1 loss: 0.819570  [   64/  126]
train() client id: f_00000-10-2 loss: 0.885028  [   96/  126]
train() client id: f_00000-11-0 loss: 0.925640  [   32/  126]
train() client id: f_00000-11-1 loss: 0.772630  [   64/  126]
train() client id: f_00000-11-2 loss: 0.786006  [   96/  126]
train() client id: f_00000-12-0 loss: 0.735398  [   32/  126]
train() client id: f_00000-12-1 loss: 0.897054  [   64/  126]
train() client id: f_00000-12-2 loss: 0.855173  [   96/  126]
train() client id: f_00001-0-0 loss: 0.535889  [   32/  265]
train() client id: f_00001-0-1 loss: 0.554389  [   64/  265]
train() client id: f_00001-0-2 loss: 0.507260  [   96/  265]
train() client id: f_00001-0-3 loss: 0.430322  [  128/  265]
train() client id: f_00001-0-4 loss: 0.576343  [  160/  265]
train() client id: f_00001-0-5 loss: 0.423331  [  192/  265]
train() client id: f_00001-0-6 loss: 0.492974  [  224/  265]
train() client id: f_00001-0-7 loss: 0.403481  [  256/  265]
train() client id: f_00001-1-0 loss: 0.400567  [   32/  265]
train() client id: f_00001-1-1 loss: 0.587575  [   64/  265]
train() client id: f_00001-1-2 loss: 0.521145  [   96/  265]
train() client id: f_00001-1-3 loss: 0.441900  [  128/  265]
train() client id: f_00001-1-4 loss: 0.445999  [  160/  265]
train() client id: f_00001-1-5 loss: 0.473454  [  192/  265]
train() client id: f_00001-1-6 loss: 0.596235  [  224/  265]
train() client id: f_00001-1-7 loss: 0.403305  [  256/  265]
train() client id: f_00001-2-0 loss: 0.495231  [   32/  265]
train() client id: f_00001-2-1 loss: 0.420676  [   64/  265]
train() client id: f_00001-2-2 loss: 0.461864  [   96/  265]
train() client id: f_00001-2-3 loss: 0.546276  [  128/  265]
train() client id: f_00001-2-4 loss: 0.478716  [  160/  265]
train() client id: f_00001-2-5 loss: 0.482580  [  192/  265]
train() client id: f_00001-2-6 loss: 0.444727  [  224/  265]
train() client id: f_00001-2-7 loss: 0.480167  [  256/  265]
train() client id: f_00001-3-0 loss: 0.402116  [   32/  265]
train() client id: f_00001-3-1 loss: 0.557660  [   64/  265]
train() client id: f_00001-3-2 loss: 0.586656  [   96/  265]
train() client id: f_00001-3-3 loss: 0.495423  [  128/  265]
train() client id: f_00001-3-4 loss: 0.415079  [  160/  265]
train() client id: f_00001-3-5 loss: 0.485701  [  192/  265]
train() client id: f_00001-3-6 loss: 0.452665  [  224/  265]
train() client id: f_00001-3-7 loss: 0.403201  [  256/  265]
train() client id: f_00001-4-0 loss: 0.571347  [   32/  265]
train() client id: f_00001-4-1 loss: 0.453232  [   64/  265]
train() client id: f_00001-4-2 loss: 0.421428  [   96/  265]
train() client id: f_00001-4-3 loss: 0.479792  [  128/  265]
train() client id: f_00001-4-4 loss: 0.443859  [  160/  265]
train() client id: f_00001-4-5 loss: 0.507334  [  192/  265]
train() client id: f_00001-4-6 loss: 0.489832  [  224/  265]
train() client id: f_00001-4-7 loss: 0.401016  [  256/  265]
train() client id: f_00001-5-0 loss: 0.439987  [   32/  265]
train() client id: f_00001-5-1 loss: 0.385267  [   64/  265]
train() client id: f_00001-5-2 loss: 0.458067  [   96/  265]
train() client id: f_00001-5-3 loss: 0.423162  [  128/  265]
train() client id: f_00001-5-4 loss: 0.476577  [  160/  265]
train() client id: f_00001-5-5 loss: 0.527927  [  192/  265]
train() client id: f_00001-5-6 loss: 0.452659  [  224/  265]
train() client id: f_00001-5-7 loss: 0.525533  [  256/  265]
train() client id: f_00001-6-0 loss: 0.452435  [   32/  265]
train() client id: f_00001-6-1 loss: 0.382780  [   64/  265]
train() client id: f_00001-6-2 loss: 0.397003  [   96/  265]
train() client id: f_00001-6-3 loss: 0.570604  [  128/  265]
train() client id: f_00001-6-4 loss: 0.477488  [  160/  265]
train() client id: f_00001-6-5 loss: 0.430301  [  192/  265]
train() client id: f_00001-6-6 loss: 0.477583  [  224/  265]
train() client id: f_00001-6-7 loss: 0.554832  [  256/  265]
train() client id: f_00001-7-0 loss: 0.437735  [   32/  265]
train() client id: f_00001-7-1 loss: 0.474352  [   64/  265]
train() client id: f_00001-7-2 loss: 0.466780  [   96/  265]
train() client id: f_00001-7-3 loss: 0.493670  [  128/  265]
train() client id: f_00001-7-4 loss: 0.445936  [  160/  265]
train() client id: f_00001-7-5 loss: 0.472741  [  192/  265]
train() client id: f_00001-7-6 loss: 0.469600  [  224/  265]
train() client id: f_00001-7-7 loss: 0.465909  [  256/  265]
train() client id: f_00001-8-0 loss: 0.422969  [   32/  265]
train() client id: f_00001-8-1 loss: 0.431121  [   64/  265]
train() client id: f_00001-8-2 loss: 0.659727  [   96/  265]
train() client id: f_00001-8-3 loss: 0.406690  [  128/  265]
train() client id: f_00001-8-4 loss: 0.465225  [  160/  265]
train() client id: f_00001-8-5 loss: 0.412324  [  192/  265]
train() client id: f_00001-8-6 loss: 0.400967  [  224/  265]
train() client id: f_00001-8-7 loss: 0.516139  [  256/  265]
train() client id: f_00001-9-0 loss: 0.652577  [   32/  265]
train() client id: f_00001-9-1 loss: 0.383272  [   64/  265]
train() client id: f_00001-9-2 loss: 0.435756  [   96/  265]
train() client id: f_00001-9-3 loss: 0.421679  [  128/  265]
train() client id: f_00001-9-4 loss: 0.496008  [  160/  265]
train() client id: f_00001-9-5 loss: 0.441299  [  192/  265]
train() client id: f_00001-9-6 loss: 0.506804  [  224/  265]
train() client id: f_00001-9-7 loss: 0.389842  [  256/  265]
train() client id: f_00001-10-0 loss: 0.396756  [   32/  265]
train() client id: f_00001-10-1 loss: 0.455173  [   64/  265]
train() client id: f_00001-10-2 loss: 0.476966  [   96/  265]
train() client id: f_00001-10-3 loss: 0.607068  [  128/  265]
train() client id: f_00001-10-4 loss: 0.411207  [  160/  265]
train() client id: f_00001-10-5 loss: 0.473468  [  192/  265]
train() client id: f_00001-10-6 loss: 0.495742  [  224/  265]
train() client id: f_00001-10-7 loss: 0.371652  [  256/  265]
train() client id: f_00001-11-0 loss: 0.360781  [   32/  265]
train() client id: f_00001-11-1 loss: 0.462413  [   64/  265]
train() client id: f_00001-11-2 loss: 0.493357  [   96/  265]
train() client id: f_00001-11-3 loss: 0.504404  [  128/  265]
train() client id: f_00001-11-4 loss: 0.518997  [  160/  265]
train() client id: f_00001-11-5 loss: 0.398047  [  192/  265]
train() client id: f_00001-11-6 loss: 0.361938  [  224/  265]
train() client id: f_00001-11-7 loss: 0.535980  [  256/  265]
train() client id: f_00001-12-0 loss: 0.482295  [   32/  265]
train() client id: f_00001-12-1 loss: 0.360520  [   64/  265]
train() client id: f_00001-12-2 loss: 0.441361  [   96/  265]
train() client id: f_00001-12-3 loss: 0.446251  [  128/  265]
train() client id: f_00001-12-4 loss: 0.452766  [  160/  265]
train() client id: f_00001-12-5 loss: 0.631720  [  192/  265]
train() client id: f_00001-12-6 loss: 0.451166  [  224/  265]
train() client id: f_00001-12-7 loss: 0.463198  [  256/  265]
train() client id: f_00002-0-0 loss: 1.105654  [   32/  124]
train() client id: f_00002-0-1 loss: 1.155974  [   64/  124]
train() client id: f_00002-0-2 loss: 1.006143  [   96/  124]
train() client id: f_00002-1-0 loss: 1.214055  [   32/  124]
train() client id: f_00002-1-1 loss: 0.936363  [   64/  124]
train() client id: f_00002-1-2 loss: 1.140841  [   96/  124]
train() client id: f_00002-2-0 loss: 1.047186  [   32/  124]
train() client id: f_00002-2-1 loss: 1.070465  [   64/  124]
train() client id: f_00002-2-2 loss: 1.033688  [   96/  124]
train() client id: f_00002-3-0 loss: 1.086558  [   32/  124]
train() client id: f_00002-3-1 loss: 0.852354  [   64/  124]
train() client id: f_00002-3-2 loss: 0.975507  [   96/  124]
train() client id: f_00002-4-0 loss: 0.951503  [   32/  124]
train() client id: f_00002-4-1 loss: 1.091828  [   64/  124]
train() client id: f_00002-4-2 loss: 0.995052  [   96/  124]
train() client id: f_00002-5-0 loss: 0.921952  [   32/  124]
train() client id: f_00002-5-1 loss: 1.096744  [   64/  124]
train() client id: f_00002-5-2 loss: 0.982162  [   96/  124]
train() client id: f_00002-6-0 loss: 1.079293  [   32/  124]
train() client id: f_00002-6-1 loss: 0.987718  [   64/  124]
train() client id: f_00002-6-2 loss: 0.873940  [   96/  124]
train() client id: f_00002-7-0 loss: 0.925187  [   32/  124]
train() client id: f_00002-7-1 loss: 1.043963  [   64/  124]
train() client id: f_00002-7-2 loss: 1.011193  [   96/  124]
train() client id: f_00002-8-0 loss: 0.825649  [   32/  124]
train() client id: f_00002-8-1 loss: 1.179441  [   64/  124]
train() client id: f_00002-8-2 loss: 0.887219  [   96/  124]
train() client id: f_00002-9-0 loss: 0.845512  [   32/  124]
train() client id: f_00002-9-1 loss: 1.190450  [   64/  124]
train() client id: f_00002-9-2 loss: 0.791659  [   96/  124]
train() client id: f_00002-10-0 loss: 1.064738  [   32/  124]
train() client id: f_00002-10-1 loss: 0.827199  [   64/  124]
train() client id: f_00002-10-2 loss: 1.020597  [   96/  124]
train() client id: f_00002-11-0 loss: 0.811441  [   32/  124]
train() client id: f_00002-11-1 loss: 0.964737  [   64/  124]
train() client id: f_00002-11-2 loss: 1.118924  [   96/  124]
train() client id: f_00002-12-0 loss: 0.874243  [   32/  124]
train() client id: f_00002-12-1 loss: 1.004921  [   64/  124]
train() client id: f_00002-12-2 loss: 1.014150  [   96/  124]
train() client id: f_00003-0-0 loss: 0.768793  [   32/   43]
train() client id: f_00003-1-0 loss: 0.716240  [   32/   43]
train() client id: f_00003-2-0 loss: 0.691099  [   32/   43]
train() client id: f_00003-3-0 loss: 0.679613  [   32/   43]
train() client id: f_00003-4-0 loss: 0.585126  [   32/   43]
train() client id: f_00003-5-0 loss: 0.710972  [   32/   43]
train() client id: f_00003-6-0 loss: 0.634217  [   32/   43]
train() client id: f_00003-7-0 loss: 0.640050  [   32/   43]
train() client id: f_00003-8-0 loss: 0.685689  [   32/   43]
train() client id: f_00003-9-0 loss: 0.667729  [   32/   43]
train() client id: f_00003-10-0 loss: 0.675056  [   32/   43]
train() client id: f_00003-11-0 loss: 0.658131  [   32/   43]
train() client id: f_00003-12-0 loss: 0.784704  [   32/   43]
train() client id: f_00004-0-0 loss: 0.984416  [   32/  306]
train() client id: f_00004-0-1 loss: 0.940024  [   64/  306]
train() client id: f_00004-0-2 loss: 0.881651  [   96/  306]
train() client id: f_00004-0-3 loss: 0.913294  [  128/  306]
train() client id: f_00004-0-4 loss: 0.849947  [  160/  306]
train() client id: f_00004-0-5 loss: 0.728338  [  192/  306]
train() client id: f_00004-0-6 loss: 0.874192  [  224/  306]
train() client id: f_00004-0-7 loss: 0.868847  [  256/  306]
train() client id: f_00004-0-8 loss: 0.829072  [  288/  306]
train() client id: f_00004-1-0 loss: 0.894072  [   32/  306]
train() client id: f_00004-1-1 loss: 0.989971  [   64/  306]
train() client id: f_00004-1-2 loss: 0.888787  [   96/  306]
train() client id: f_00004-1-3 loss: 0.837651  [  128/  306]
train() client id: f_00004-1-4 loss: 1.046052  [  160/  306]
train() client id: f_00004-1-5 loss: 0.847998  [  192/  306]
train() client id: f_00004-1-6 loss: 0.796745  [  224/  306]
train() client id: f_00004-1-7 loss: 0.896792  [  256/  306]
train() client id: f_00004-1-8 loss: 0.781794  [  288/  306]
train() client id: f_00004-2-0 loss: 0.887806  [   32/  306]
train() client id: f_00004-2-1 loss: 0.858894  [   64/  306]
train() client id: f_00004-2-2 loss: 0.841997  [   96/  306]
train() client id: f_00004-2-3 loss: 0.826557  [  128/  306]
train() client id: f_00004-2-4 loss: 0.826998  [  160/  306]
train() client id: f_00004-2-5 loss: 0.816101  [  192/  306]
train() client id: f_00004-2-6 loss: 0.916399  [  224/  306]
train() client id: f_00004-2-7 loss: 1.012695  [  256/  306]
train() client id: f_00004-2-8 loss: 0.925007  [  288/  306]
train() client id: f_00004-3-0 loss: 0.886706  [   32/  306]
train() client id: f_00004-3-1 loss: 1.015980  [   64/  306]
train() client id: f_00004-3-2 loss: 0.981381  [   96/  306]
train() client id: f_00004-3-3 loss: 0.927519  [  128/  306]
train() client id: f_00004-3-4 loss: 0.906308  [  160/  306]
train() client id: f_00004-3-5 loss: 0.802335  [  192/  306]
train() client id: f_00004-3-6 loss: 0.708059  [  224/  306]
train() client id: f_00004-3-7 loss: 0.818324  [  256/  306]
train() client id: f_00004-3-8 loss: 0.838507  [  288/  306]
train() client id: f_00004-4-0 loss: 0.962538  [   32/  306]
train() client id: f_00004-4-1 loss: 0.997002  [   64/  306]
train() client id: f_00004-4-2 loss: 0.792713  [   96/  306]
train() client id: f_00004-4-3 loss: 0.806037  [  128/  306]
train() client id: f_00004-4-4 loss: 0.909944  [  160/  306]
train() client id: f_00004-4-5 loss: 0.952823  [  192/  306]
train() client id: f_00004-4-6 loss: 0.779854  [  224/  306]
train() client id: f_00004-4-7 loss: 0.864228  [  256/  306]
train() client id: f_00004-4-8 loss: 0.904914  [  288/  306]
train() client id: f_00004-5-0 loss: 0.818434  [   32/  306]
train() client id: f_00004-5-1 loss: 0.793945  [   64/  306]
train() client id: f_00004-5-2 loss: 0.957313  [   96/  306]
train() client id: f_00004-5-3 loss: 0.898807  [  128/  306]
train() client id: f_00004-5-4 loss: 0.955867  [  160/  306]
train() client id: f_00004-5-5 loss: 0.905490  [  192/  306]
train() client id: f_00004-5-6 loss: 0.899841  [  224/  306]
train() client id: f_00004-5-7 loss: 0.774191  [  256/  306]
train() client id: f_00004-5-8 loss: 0.909534  [  288/  306]
train() client id: f_00004-6-0 loss: 0.863955  [   32/  306]
train() client id: f_00004-6-1 loss: 0.833627  [   64/  306]
train() client id: f_00004-6-2 loss: 0.921844  [   96/  306]
train() client id: f_00004-6-3 loss: 0.922274  [  128/  306]
train() client id: f_00004-6-4 loss: 0.899804  [  160/  306]
train() client id: f_00004-6-5 loss: 0.953104  [  192/  306]
train() client id: f_00004-6-6 loss: 0.873810  [  224/  306]
train() client id: f_00004-6-7 loss: 0.690936  [  256/  306]
train() client id: f_00004-6-8 loss: 0.910331  [  288/  306]
train() client id: f_00004-7-0 loss: 0.760001  [   32/  306]
train() client id: f_00004-7-1 loss: 0.880399  [   64/  306]
train() client id: f_00004-7-2 loss: 0.888226  [   96/  306]
train() client id: f_00004-7-3 loss: 0.928017  [  128/  306]
train() client id: f_00004-7-4 loss: 0.829648  [  160/  306]
train() client id: f_00004-7-5 loss: 0.848407  [  192/  306]
train() client id: f_00004-7-6 loss: 1.024151  [  224/  306]
train() client id: f_00004-7-7 loss: 0.886996  [  256/  306]
train() client id: f_00004-7-8 loss: 0.819497  [  288/  306]
train() client id: f_00004-8-0 loss: 0.908101  [   32/  306]
train() client id: f_00004-8-1 loss: 1.031698  [   64/  306]
train() client id: f_00004-8-2 loss: 0.937836  [   96/  306]
train() client id: f_00004-8-3 loss: 0.786254  [  128/  306]
train() client id: f_00004-8-4 loss: 0.839524  [  160/  306]
train() client id: f_00004-8-5 loss: 0.924227  [  192/  306]
train() client id: f_00004-8-6 loss: 0.867649  [  224/  306]
train() client id: f_00004-8-7 loss: 0.815111  [  256/  306]
train() client id: f_00004-8-8 loss: 0.877068  [  288/  306]
train() client id: f_00004-9-0 loss: 0.796889  [   32/  306]
train() client id: f_00004-9-1 loss: 0.825989  [   64/  306]
train() client id: f_00004-9-2 loss: 0.844887  [   96/  306]
train() client id: f_00004-9-3 loss: 0.809897  [  128/  306]
train() client id: f_00004-9-4 loss: 0.907297  [  160/  306]
train() client id: f_00004-9-5 loss: 0.947880  [  192/  306]
train() client id: f_00004-9-6 loss: 0.864411  [  224/  306]
train() client id: f_00004-9-7 loss: 0.896486  [  256/  306]
train() client id: f_00004-9-8 loss: 0.955797  [  288/  306]
train() client id: f_00004-10-0 loss: 0.921268  [   32/  306]
train() client id: f_00004-10-1 loss: 0.925694  [   64/  306]
train() client id: f_00004-10-2 loss: 0.902037  [   96/  306]
train() client id: f_00004-10-3 loss: 0.920197  [  128/  306]
train() client id: f_00004-10-4 loss: 0.813089  [  160/  306]
train() client id: f_00004-10-5 loss: 1.007301  [  192/  306]
train() client id: f_00004-10-6 loss: 0.882769  [  224/  306]
train() client id: f_00004-10-7 loss: 0.831452  [  256/  306]
train() client id: f_00004-10-8 loss: 0.815779  [  288/  306]
train() client id: f_00004-11-0 loss: 0.813241  [   32/  306]
train() client id: f_00004-11-1 loss: 0.919656  [   64/  306]
train() client id: f_00004-11-2 loss: 0.983097  [   96/  306]
train() client id: f_00004-11-3 loss: 0.986502  [  128/  306]
train() client id: f_00004-11-4 loss: 0.796205  [  160/  306]
train() client id: f_00004-11-5 loss: 0.906200  [  192/  306]
train() client id: f_00004-11-6 loss: 0.889017  [  224/  306]
train() client id: f_00004-11-7 loss: 0.782215  [  256/  306]
train() client id: f_00004-11-8 loss: 0.979218  [  288/  306]
train() client id: f_00004-12-0 loss: 0.910161  [   32/  306]
train() client id: f_00004-12-1 loss: 0.991025  [   64/  306]
train() client id: f_00004-12-2 loss: 0.890437  [   96/  306]
train() client id: f_00004-12-3 loss: 0.937411  [  128/  306]
train() client id: f_00004-12-4 loss: 0.911616  [  160/  306]
train() client id: f_00004-12-5 loss: 0.934125  [  192/  306]
train() client id: f_00004-12-6 loss: 0.772597  [  224/  306]
train() client id: f_00004-12-7 loss: 0.895535  [  256/  306]
train() client id: f_00004-12-8 loss: 0.857813  [  288/  306]
train() client id: f_00005-0-0 loss: 0.726235  [   32/  146]
train() client id: f_00005-0-1 loss: 0.455392  [   64/  146]
train() client id: f_00005-0-2 loss: 0.364029  [   96/  146]
train() client id: f_00005-0-3 loss: 0.700647  [  128/  146]
train() client id: f_00005-1-0 loss: 0.604954  [   32/  146]
train() client id: f_00005-1-1 loss: 0.560373  [   64/  146]
train() client id: f_00005-1-2 loss: 0.489318  [   96/  146]
train() client id: f_00005-1-3 loss: 0.493499  [  128/  146]
train() client id: f_00005-2-0 loss: 0.566908  [   32/  146]
train() client id: f_00005-2-1 loss: 0.781422  [   64/  146]
train() client id: f_00005-2-2 loss: 0.546353  [   96/  146]
train() client id: f_00005-2-3 loss: 0.248740  [  128/  146]
train() client id: f_00005-3-0 loss: 0.351062  [   32/  146]
train() client id: f_00005-3-1 loss: 0.444974  [   64/  146]
train() client id: f_00005-3-2 loss: 0.680299  [   96/  146]
train() client id: f_00005-3-3 loss: 0.745613  [  128/  146]
train() client id: f_00005-4-0 loss: 0.319657  [   32/  146]
train() client id: f_00005-4-1 loss: 0.462390  [   64/  146]
train() client id: f_00005-4-2 loss: 0.728228  [   96/  146]
train() client id: f_00005-4-3 loss: 0.638765  [  128/  146]
train() client id: f_00005-5-0 loss: 0.289228  [   32/  146]
train() client id: f_00005-5-1 loss: 0.504735  [   64/  146]
train() client id: f_00005-5-2 loss: 0.607498  [   96/  146]
train() client id: f_00005-5-3 loss: 0.702132  [  128/  146]
train() client id: f_00005-6-0 loss: 0.547286  [   32/  146]
train() client id: f_00005-6-1 loss: 0.346667  [   64/  146]
train() client id: f_00005-6-2 loss: 0.469039  [   96/  146]
train() client id: f_00005-6-3 loss: 0.655221  [  128/  146]
train() client id: f_00005-7-0 loss: 0.658247  [   32/  146]
train() client id: f_00005-7-1 loss: 0.413470  [   64/  146]
train() client id: f_00005-7-2 loss: 0.546140  [   96/  146]
train() client id: f_00005-7-3 loss: 0.449180  [  128/  146]
train() client id: f_00005-8-0 loss: 0.509268  [   32/  146]
train() client id: f_00005-8-1 loss: 0.398061  [   64/  146]
train() client id: f_00005-8-2 loss: 0.528827  [   96/  146]
train() client id: f_00005-8-3 loss: 0.438689  [  128/  146]
train() client id: f_00005-9-0 loss: 0.667267  [   32/  146]
train() client id: f_00005-9-1 loss: 0.423026  [   64/  146]
train() client id: f_00005-9-2 loss: 0.343512  [   96/  146]
train() client id: f_00005-9-3 loss: 0.552879  [  128/  146]
train() client id: f_00005-10-0 loss: 0.404827  [   32/  146]
train() client id: f_00005-10-1 loss: 0.508406  [   64/  146]
train() client id: f_00005-10-2 loss: 0.629648  [   96/  146]
train() client id: f_00005-10-3 loss: 0.535806  [  128/  146]
train() client id: f_00005-11-0 loss: 0.290480  [   32/  146]
train() client id: f_00005-11-1 loss: 0.508666  [   64/  146]
train() client id: f_00005-11-2 loss: 0.514269  [   96/  146]
train() client id: f_00005-11-3 loss: 0.474164  [  128/  146]
train() client id: f_00005-12-0 loss: 0.779454  [   32/  146]
train() client id: f_00005-12-1 loss: 0.603216  [   64/  146]
train() client id: f_00005-12-2 loss: 0.269741  [   96/  146]
train() client id: f_00005-12-3 loss: 0.514950  [  128/  146]
train() client id: f_00006-0-0 loss: 0.531668  [   32/   54]
train() client id: f_00006-1-0 loss: 0.485205  [   32/   54]
train() client id: f_00006-2-0 loss: 0.440349  [   32/   54]
train() client id: f_00006-3-0 loss: 0.539772  [   32/   54]
train() client id: f_00006-4-0 loss: 0.553738  [   32/   54]
train() client id: f_00006-5-0 loss: 0.463249  [   32/   54]
train() client id: f_00006-6-0 loss: 0.548009  [   32/   54]
train() client id: f_00006-7-0 loss: 0.423386  [   32/   54]
train() client id: f_00006-8-0 loss: 0.543658  [   32/   54]
train() client id: f_00006-9-0 loss: 0.517193  [   32/   54]
train() client id: f_00006-10-0 loss: 0.445967  [   32/   54]
train() client id: f_00006-11-0 loss: 0.494528  [   32/   54]
train() client id: f_00006-12-0 loss: 0.480010  [   32/   54]
train() client id: f_00007-0-0 loss: 0.465728  [   32/  179]
train() client id: f_00007-0-1 loss: 0.440263  [   64/  179]
train() client id: f_00007-0-2 loss: 0.670299  [   96/  179]
train() client id: f_00007-0-3 loss: 0.687489  [  128/  179]
train() client id: f_00007-0-4 loss: 0.614361  [  160/  179]
train() client id: f_00007-1-0 loss: 0.484483  [   32/  179]
train() client id: f_00007-1-1 loss: 0.592050  [   64/  179]
train() client id: f_00007-1-2 loss: 0.828540  [   96/  179]
train() client id: f_00007-1-3 loss: 0.495910  [  128/  179]
train() client id: f_00007-1-4 loss: 0.439617  [  160/  179]
train() client id: f_00007-2-0 loss: 0.482448  [   32/  179]
train() client id: f_00007-2-1 loss: 0.683606  [   64/  179]
train() client id: f_00007-2-2 loss: 0.556867  [   96/  179]
train() client id: f_00007-2-3 loss: 0.439636  [  128/  179]
train() client id: f_00007-2-4 loss: 0.515848  [  160/  179]
train() client id: f_00007-3-0 loss: 0.558145  [   32/  179]
train() client id: f_00007-3-1 loss: 0.415299  [   64/  179]
train() client id: f_00007-3-2 loss: 0.603304  [   96/  179]
train() client id: f_00007-3-3 loss: 0.479268  [  128/  179]
train() client id: f_00007-3-4 loss: 0.653654  [  160/  179]
train() client id: f_00007-4-0 loss: 0.474310  [   32/  179]
train() client id: f_00007-4-1 loss: 0.409009  [   64/  179]
train() client id: f_00007-4-2 loss: 0.537169  [   96/  179]
train() client id: f_00007-4-3 loss: 0.495025  [  128/  179]
train() client id: f_00007-4-4 loss: 0.636397  [  160/  179]
train() client id: f_00007-5-0 loss: 0.402268  [   32/  179]
train() client id: f_00007-5-1 loss: 0.503765  [   64/  179]
train() client id: f_00007-5-2 loss: 0.606269  [   96/  179]
train() client id: f_00007-5-3 loss: 0.439938  [  128/  179]
train() client id: f_00007-5-4 loss: 0.663551  [  160/  179]
train() client id: f_00007-6-0 loss: 0.483033  [   32/  179]
train() client id: f_00007-6-1 loss: 0.576985  [   64/  179]
train() client id: f_00007-6-2 loss: 0.368522  [   96/  179]
train() client id: f_00007-6-3 loss: 0.717005  [  128/  179]
train() client id: f_00007-6-4 loss: 0.552249  [  160/  179]
train() client id: f_00007-7-0 loss: 0.423552  [   32/  179]
train() client id: f_00007-7-1 loss: 0.425391  [   64/  179]
train() client id: f_00007-7-2 loss: 0.525616  [   96/  179]
train() client id: f_00007-7-3 loss: 0.607617  [  128/  179]
train() client id: f_00007-7-4 loss: 0.579085  [  160/  179]
train() client id: f_00007-8-0 loss: 0.441692  [   32/  179]
train() client id: f_00007-8-1 loss: 0.379480  [   64/  179]
train() client id: f_00007-8-2 loss: 0.568238  [   96/  179]
train() client id: f_00007-8-3 loss: 0.723394  [  128/  179]
train() client id: f_00007-8-4 loss: 0.430094  [  160/  179]
train() client id: f_00007-9-0 loss: 0.551491  [   32/  179]
train() client id: f_00007-9-1 loss: 0.665275  [   64/  179]
train() client id: f_00007-9-2 loss: 0.455083  [   96/  179]
train() client id: f_00007-9-3 loss: 0.476761  [  128/  179]
train() client id: f_00007-9-4 loss: 0.509651  [  160/  179]
train() client id: f_00007-10-0 loss: 0.546116  [   32/  179]
train() client id: f_00007-10-1 loss: 0.340538  [   64/  179]
train() client id: f_00007-10-2 loss: 0.622125  [   96/  179]
train() client id: f_00007-10-3 loss: 0.557018  [  128/  179]
train() client id: f_00007-10-4 loss: 0.418055  [  160/  179]
train() client id: f_00007-11-0 loss: 0.450947  [   32/  179]
train() client id: f_00007-11-1 loss: 0.482210  [   64/  179]
train() client id: f_00007-11-2 loss: 0.334323  [   96/  179]
train() client id: f_00007-11-3 loss: 0.491049  [  128/  179]
train() client id: f_00007-11-4 loss: 0.711048  [  160/  179]
train() client id: f_00007-12-0 loss: 0.350011  [   32/  179]
train() client id: f_00007-12-1 loss: 0.831980  [   64/  179]
train() client id: f_00007-12-2 loss: 0.441301  [   96/  179]
train() client id: f_00007-12-3 loss: 0.385926  [  128/  179]
train() client id: f_00007-12-4 loss: 0.591673  [  160/  179]
train() client id: f_00008-0-0 loss: 0.730069  [   32/  130]
train() client id: f_00008-0-1 loss: 0.785744  [   64/  130]
train() client id: f_00008-0-2 loss: 0.864448  [   96/  130]
train() client id: f_00008-0-3 loss: 0.777034  [  128/  130]
train() client id: f_00008-1-0 loss: 0.790508  [   32/  130]
train() client id: f_00008-1-1 loss: 0.848633  [   64/  130]
train() client id: f_00008-1-2 loss: 0.773847  [   96/  130]
train() client id: f_00008-1-3 loss: 0.746161  [  128/  130]
train() client id: f_00008-2-0 loss: 0.813076  [   32/  130]
train() client id: f_00008-2-1 loss: 0.867400  [   64/  130]
train() client id: f_00008-2-2 loss: 0.617464  [   96/  130]
train() client id: f_00008-2-3 loss: 0.846166  [  128/  130]
train() client id: f_00008-3-0 loss: 0.827579  [   32/  130]
train() client id: f_00008-3-1 loss: 0.813947  [   64/  130]
train() client id: f_00008-3-2 loss: 0.703699  [   96/  130]
train() client id: f_00008-3-3 loss: 0.770814  [  128/  130]
train() client id: f_00008-4-0 loss: 0.843086  [   32/  130]
train() client id: f_00008-4-1 loss: 0.780649  [   64/  130]
train() client id: f_00008-4-2 loss: 0.850320  [   96/  130]
train() client id: f_00008-4-3 loss: 0.674469  [  128/  130]
train() client id: f_00008-5-0 loss: 0.799315  [   32/  130]
train() client id: f_00008-5-1 loss: 0.738595  [   64/  130]
train() client id: f_00008-5-2 loss: 0.762833  [   96/  130]
train() client id: f_00008-5-3 loss: 0.848412  [  128/  130]
train() client id: f_00008-6-0 loss: 0.810553  [   32/  130]
train() client id: f_00008-6-1 loss: 0.757725  [   64/  130]
train() client id: f_00008-6-2 loss: 0.836610  [   96/  130]
train() client id: f_00008-6-3 loss: 0.747800  [  128/  130]
train() client id: f_00008-7-0 loss: 0.735586  [   32/  130]
train() client id: f_00008-7-1 loss: 0.761695  [   64/  130]
train() client id: f_00008-7-2 loss: 0.773289  [   96/  130]
train() client id: f_00008-7-3 loss: 0.840454  [  128/  130]
train() client id: f_00008-8-0 loss: 0.787593  [   32/  130]
train() client id: f_00008-8-1 loss: 0.683474  [   64/  130]
train() client id: f_00008-8-2 loss: 0.834014  [   96/  130]
train() client id: f_00008-8-3 loss: 0.811638  [  128/  130]
train() client id: f_00008-9-0 loss: 0.798208  [   32/  130]
train() client id: f_00008-9-1 loss: 0.799689  [   64/  130]
train() client id: f_00008-9-2 loss: 0.849001  [   96/  130]
train() client id: f_00008-9-3 loss: 0.706699  [  128/  130]
train() client id: f_00008-10-0 loss: 0.848855  [   32/  130]
train() client id: f_00008-10-1 loss: 0.841780  [   64/  130]
train() client id: f_00008-10-2 loss: 0.707010  [   96/  130]
train() client id: f_00008-10-3 loss: 0.751942  [  128/  130]
train() client id: f_00008-11-0 loss: 0.853330  [   32/  130]
train() client id: f_00008-11-1 loss: 0.776451  [   64/  130]
train() client id: f_00008-11-2 loss: 0.667845  [   96/  130]
train() client id: f_00008-11-3 loss: 0.851415  [  128/  130]
train() client id: f_00008-12-0 loss: 0.793881  [   32/  130]
train() client id: f_00008-12-1 loss: 0.850779  [   64/  130]
train() client id: f_00008-12-2 loss: 0.741686  [   96/  130]
train() client id: f_00008-12-3 loss: 0.764535  [  128/  130]
train() client id: f_00009-0-0 loss: 0.957958  [   32/  118]
train() client id: f_00009-0-1 loss: 1.050575  [   64/  118]
train() client id: f_00009-0-2 loss: 1.058279  [   96/  118]
train() client id: f_00009-1-0 loss: 1.122512  [   32/  118]
train() client id: f_00009-1-1 loss: 0.958065  [   64/  118]
train() client id: f_00009-1-2 loss: 0.860022  [   96/  118]
train() client id: f_00009-2-0 loss: 0.943488  [   32/  118]
train() client id: f_00009-2-1 loss: 0.931664  [   64/  118]
train() client id: f_00009-2-2 loss: 0.803269  [   96/  118]
train() client id: f_00009-3-0 loss: 0.864944  [   32/  118]
train() client id: f_00009-3-1 loss: 1.016173  [   64/  118]
train() client id: f_00009-3-2 loss: 0.813977  [   96/  118]
train() client id: f_00009-4-0 loss: 0.900244  [   32/  118]
train() client id: f_00009-4-1 loss: 0.935262  [   64/  118]
train() client id: f_00009-4-2 loss: 0.743273  [   96/  118]
train() client id: f_00009-5-0 loss: 0.786054  [   32/  118]
train() client id: f_00009-5-1 loss: 0.765297  [   64/  118]
train() client id: f_00009-5-2 loss: 0.799984  [   96/  118]
train() client id: f_00009-6-0 loss: 0.818293  [   32/  118]
train() client id: f_00009-6-1 loss: 0.811475  [   64/  118]
train() client id: f_00009-6-2 loss: 0.780648  [   96/  118]
train() client id: f_00009-7-0 loss: 0.732922  [   32/  118]
train() client id: f_00009-7-1 loss: 0.808263  [   64/  118]
train() client id: f_00009-7-2 loss: 0.752797  [   96/  118]
train() client id: f_00009-8-0 loss: 0.710133  [   32/  118]
train() client id: f_00009-8-1 loss: 0.788835  [   64/  118]
train() client id: f_00009-8-2 loss: 0.691593  [   96/  118]
train() client id: f_00009-9-0 loss: 0.921332  [   32/  118]
train() client id: f_00009-9-1 loss: 0.722383  [   64/  118]
train() client id: f_00009-9-2 loss: 0.676823  [   96/  118]
train() client id: f_00009-10-0 loss: 0.757842  [   32/  118]
train() client id: f_00009-10-1 loss: 0.692469  [   64/  118]
train() client id: f_00009-10-2 loss: 0.758954  [   96/  118]
train() client id: f_00009-11-0 loss: 0.712332  [   32/  118]
train() client id: f_00009-11-1 loss: 0.783500  [   64/  118]
train() client id: f_00009-11-2 loss: 0.585756  [   96/  118]
train() client id: f_00009-12-0 loss: 0.651032  [   32/  118]
train() client id: f_00009-12-1 loss: 0.661649  [   64/  118]
train() client id: f_00009-12-2 loss: 0.664730  [   96/  118]
At round 39 accuracy: 0.6445623342175066
At round 39 training accuracy: 0.5875251509054326
At round 39 training loss: 0.8367261232229825
gradient difference: 0.44294944405555725
train() client id: f_00000-0-0 loss: 1.363173  [   32/  126]
train() client id: f_00000-0-1 loss: 1.335077  [   64/  126]
train() client id: f_00000-0-2 loss: 1.189737  [   96/  126]
train() client id: f_00000-1-0 loss: 0.942470  [   32/  126]
train() client id: f_00000-1-1 loss: 1.017437  [   64/  126]
train() client id: f_00000-1-2 loss: 1.207619  [   96/  126]
train() client id: f_00000-2-0 loss: 0.943844  [   32/  126]
train() client id: f_00000-2-1 loss: 1.108860  [   64/  126]
train() client id: f_00000-2-2 loss: 0.888045  [   96/  126]
train() client id: f_00000-3-0 loss: 0.959099  [   32/  126]
train() client id: f_00000-3-1 loss: 0.935059  [   64/  126]
train() client id: f_00000-3-2 loss: 0.855812  [   96/  126]
train() client id: f_00000-4-0 loss: 1.076127  [   32/  126]
train() client id: f_00000-4-1 loss: 0.905841  [   64/  126]
train() client id: f_00000-4-2 loss: 0.862082  [   96/  126]
train() client id: f_00000-5-0 loss: 0.923543  [   32/  126]
train() client id: f_00000-5-1 loss: 0.813353  [   64/  126]
train() client id: f_00000-5-2 loss: 0.793823  [   96/  126]
train() client id: f_00000-6-0 loss: 0.817963  [   32/  126]
train() client id: f_00000-6-1 loss: 0.884935  [   64/  126]
train() client id: f_00000-6-2 loss: 0.786293  [   96/  126]
train() client id: f_00000-7-0 loss: 0.739271  [   32/  126]
train() client id: f_00000-7-1 loss: 0.810316  [   64/  126]
train() client id: f_00000-7-2 loss: 0.867914  [   96/  126]
train() client id: f_00000-8-0 loss: 0.826570  [   32/  126]
train() client id: f_00000-8-1 loss: 0.744397  [   64/  126]
train() client id: f_00000-8-2 loss: 0.751602  [   96/  126]
train() client id: f_00000-9-0 loss: 0.799202  [   32/  126]
train() client id: f_00000-9-1 loss: 0.859418  [   64/  126]
train() client id: f_00000-9-2 loss: 0.778507  [   96/  126]
train() client id: f_00000-10-0 loss: 0.934621  [   32/  126]
train() client id: f_00000-10-1 loss: 0.829851  [   64/  126]
train() client id: f_00000-10-2 loss: 0.736894  [   96/  126]
train() client id: f_00000-11-0 loss: 1.018222  [   32/  126]
train() client id: f_00000-11-1 loss: 0.796878  [   64/  126]
train() client id: f_00000-11-2 loss: 0.637354  [   96/  126]
train() client id: f_00000-12-0 loss: 0.712333  [   32/  126]
train() client id: f_00000-12-1 loss: 0.872335  [   64/  126]
train() client id: f_00000-12-2 loss: 0.854264  [   96/  126]
train() client id: f_00001-0-0 loss: 0.548252  [   32/  265]
train() client id: f_00001-0-1 loss: 0.512850  [   64/  265]
train() client id: f_00001-0-2 loss: 0.388038  [   96/  265]
train() client id: f_00001-0-3 loss: 0.529650  [  128/  265]
train() client id: f_00001-0-4 loss: 0.527716  [  160/  265]
train() client id: f_00001-0-5 loss: 0.408229  [  192/  265]
train() client id: f_00001-0-6 loss: 0.471197  [  224/  265]
train() client id: f_00001-0-7 loss: 0.517310  [  256/  265]
train() client id: f_00001-1-0 loss: 0.458299  [   32/  265]
train() client id: f_00001-1-1 loss: 0.465201  [   64/  265]
train() client id: f_00001-1-2 loss: 0.490975  [   96/  265]
train() client id: f_00001-1-3 loss: 0.446666  [  128/  265]
train() client id: f_00001-1-4 loss: 0.436419  [  160/  265]
train() client id: f_00001-1-5 loss: 0.613381  [  192/  265]
train() client id: f_00001-1-6 loss: 0.501593  [  224/  265]
train() client id: f_00001-1-7 loss: 0.441222  [  256/  265]
train() client id: f_00001-2-0 loss: 0.505167  [   32/  265]
train() client id: f_00001-2-1 loss: 0.443159  [   64/  265]
train() client id: f_00001-2-2 loss: 0.500200  [   96/  265]
train() client id: f_00001-2-3 loss: 0.444196  [  128/  265]
train() client id: f_00001-2-4 loss: 0.371704  [  160/  265]
train() client id: f_00001-2-5 loss: 0.515307  [  192/  265]
train() client id: f_00001-2-6 loss: 0.426126  [  224/  265]
train() client id: f_00001-2-7 loss: 0.526946  [  256/  265]
train() client id: f_00001-3-0 loss: 0.422588  [   32/  265]
train() client id: f_00001-3-1 loss: 0.444930  [   64/  265]
train() client id: f_00001-3-2 loss: 0.460750  [   96/  265]
train() client id: f_00001-3-3 loss: 0.657418  [  128/  265]
train() client id: f_00001-3-4 loss: 0.465509  [  160/  265]
train() client id: f_00001-3-5 loss: 0.422944  [  192/  265]
train() client id: f_00001-3-6 loss: 0.458680  [  224/  265]
train() client id: f_00001-3-7 loss: 0.425277  [  256/  265]
train() client id: f_00001-4-0 loss: 0.577802  [   32/  265]
train() client id: f_00001-4-1 loss: 0.452634  [   64/  265]
train() client id: f_00001-4-2 loss: 0.492412  [   96/  265]
train() client id: f_00001-4-3 loss: 0.451223  [  128/  265]
train() client id: f_00001-4-4 loss: 0.364844  [  160/  265]
train() client id: f_00001-4-5 loss: 0.427962  [  192/  265]
train() client id: f_00001-4-6 loss: 0.378948  [  224/  265]
train() client id: f_00001-4-7 loss: 0.586514  [  256/  265]
train() client id: f_00001-5-0 loss: 0.431527  [   32/  265]
train() client id: f_00001-5-1 loss: 0.469039  [   64/  265]
train() client id: f_00001-5-2 loss: 0.466334  [   96/  265]
train() client id: f_00001-5-3 loss: 0.545537  [  128/  265]
train() client id: f_00001-5-4 loss: 0.463720  [  160/  265]
train() client id: f_00001-5-5 loss: 0.418611  [  192/  265]
train() client id: f_00001-5-6 loss: 0.434207  [  224/  265]
train() client id: f_00001-5-7 loss: 0.485666  [  256/  265]
train() client id: f_00001-6-0 loss: 0.430315  [   32/  265]
train() client id: f_00001-6-1 loss: 0.358368  [   64/  265]
train() client id: f_00001-6-2 loss: 0.451928  [   96/  265]
train() client id: f_00001-6-3 loss: 0.611586  [  128/  265]
train() client id: f_00001-6-4 loss: 0.478763  [  160/  265]
train() client id: f_00001-6-5 loss: 0.450543  [  192/  265]
train() client id: f_00001-6-6 loss: 0.461333  [  224/  265]
train() client id: f_00001-6-7 loss: 0.456799  [  256/  265]
train() client id: f_00001-7-0 loss: 0.477538  [   32/  265]
train() client id: f_00001-7-1 loss: 0.463183  [   64/  265]
train() client id: f_00001-7-2 loss: 0.540559  [   96/  265]
train() client id: f_00001-7-3 loss: 0.401708  [  128/  265]
train() client id: f_00001-7-4 loss: 0.451655  [  160/  265]
train() client id: f_00001-7-5 loss: 0.545661  [  192/  265]
train() client id: f_00001-7-6 loss: 0.437863  [  224/  265]
train() client id: f_00001-7-7 loss: 0.378016  [  256/  265]
train() client id: f_00001-8-0 loss: 0.456726  [   32/  265]
train() client id: f_00001-8-1 loss: 0.405582  [   64/  265]
train() client id: f_00001-8-2 loss: 0.425500  [   96/  265]
train() client id: f_00001-8-3 loss: 0.485165  [  128/  265]
train() client id: f_00001-8-4 loss: 0.467565  [  160/  265]
train() client id: f_00001-8-5 loss: 0.434022  [  192/  265]
train() client id: f_00001-8-6 loss: 0.519749  [  224/  265]
train() client id: f_00001-8-7 loss: 0.485039  [  256/  265]
train() client id: f_00001-9-0 loss: 0.525595  [   32/  265]
train() client id: f_00001-9-1 loss: 0.425903  [   64/  265]
train() client id: f_00001-9-2 loss: 0.434514  [   96/  265]
train() client id: f_00001-9-3 loss: 0.436962  [  128/  265]
train() client id: f_00001-9-4 loss: 0.420671  [  160/  265]
train() client id: f_00001-9-5 loss: 0.379427  [  192/  265]
train() client id: f_00001-9-6 loss: 0.538893  [  224/  265]
train() client id: f_00001-9-7 loss: 0.511285  [  256/  265]
train() client id: f_00001-10-0 loss: 0.396611  [   32/  265]
train() client id: f_00001-10-1 loss: 0.451315  [   64/  265]
train() client id: f_00001-10-2 loss: 0.511209  [   96/  265]
train() client id: f_00001-10-3 loss: 0.589472  [  128/  265]
train() client id: f_00001-10-4 loss: 0.367773  [  160/  265]
train() client id: f_00001-10-5 loss: 0.485667  [  192/  265]
train() client id: f_00001-10-6 loss: 0.425918  [  224/  265]
train() client id: f_00001-10-7 loss: 0.442416  [  256/  265]
train() client id: f_00001-11-0 loss: 0.355540  [   32/  265]
train() client id: f_00001-11-1 loss: 0.431644  [   64/  265]
train() client id: f_00001-11-2 loss: 0.406435  [   96/  265]
train() client id: f_00001-11-3 loss: 0.531343  [  128/  265]
train() client id: f_00001-11-4 loss: 0.450802  [  160/  265]
train() client id: f_00001-11-5 loss: 0.471623  [  192/  265]
train() client id: f_00001-11-6 loss: 0.468710  [  224/  265]
train() client id: f_00001-11-7 loss: 0.482438  [  256/  265]
train() client id: f_00001-12-0 loss: 0.415079  [   32/  265]
train() client id: f_00001-12-1 loss: 0.442962  [   64/  265]
train() client id: f_00001-12-2 loss: 0.706914  [   96/  265]
train() client id: f_00001-12-3 loss: 0.370120  [  128/  265]
train() client id: f_00001-12-4 loss: 0.359205  [  160/  265]
train() client id: f_00001-12-5 loss: 0.432620  [  192/  265]
train() client id: f_00001-12-6 loss: 0.467449  [  224/  265]
train() client id: f_00001-12-7 loss: 0.487407  [  256/  265]
train() client id: f_00002-0-0 loss: 1.294151  [   32/  124]
train() client id: f_00002-0-1 loss: 1.122265  [   64/  124]
train() client id: f_00002-0-2 loss: 1.016941  [   96/  124]
train() client id: f_00002-1-0 loss: 1.033850  [   32/  124]
train() client id: f_00002-1-1 loss: 1.085288  [   64/  124]
train() client id: f_00002-1-2 loss: 1.061643  [   96/  124]
train() client id: f_00002-2-0 loss: 1.045981  [   32/  124]
train() client id: f_00002-2-1 loss: 1.144590  [   64/  124]
train() client id: f_00002-2-2 loss: 1.196503  [   96/  124]
train() client id: f_00002-3-0 loss: 1.054230  [   32/  124]
train() client id: f_00002-3-1 loss: 1.035715  [   64/  124]
train() client id: f_00002-3-2 loss: 1.135665  [   96/  124]
train() client id: f_00002-4-0 loss: 0.927138  [   32/  124]
train() client id: f_00002-4-1 loss: 1.085682  [   64/  124]
train() client id: f_00002-4-2 loss: 1.016186  [   96/  124]
train() client id: f_00002-5-0 loss: 0.952153  [   32/  124]
train() client id: f_00002-5-1 loss: 1.053428  [   64/  124]
train() client id: f_00002-5-2 loss: 0.970958  [   96/  124]
train() client id: f_00002-6-0 loss: 0.904057  [   32/  124]
train() client id: f_00002-6-1 loss: 1.041683  [   64/  124]
train() client id: f_00002-6-2 loss: 1.026078  [   96/  124]
train() client id: f_00002-7-0 loss: 0.878987  [   32/  124]
train() client id: f_00002-7-1 loss: 0.928150  [   64/  124]
train() client id: f_00002-7-2 loss: 0.925883  [   96/  124]
train() client id: f_00002-8-0 loss: 0.901565  [   32/  124]
train() client id: f_00002-8-1 loss: 0.886436  [   64/  124]
train() client id: f_00002-8-2 loss: 0.990350  [   96/  124]
train() client id: f_00002-9-0 loss: 0.844458  [   32/  124]
train() client id: f_00002-9-1 loss: 1.105431  [   64/  124]
train() client id: f_00002-9-2 loss: 0.953857  [   96/  124]
train() client id: f_00002-10-0 loss: 0.856587  [   32/  124]
train() client id: f_00002-10-1 loss: 0.960842  [   64/  124]
train() client id: f_00002-10-2 loss: 1.036668  [   96/  124]
train() client id: f_00002-11-0 loss: 0.910266  [   32/  124]
train() client id: f_00002-11-1 loss: 0.964877  [   64/  124]
train() client id: f_00002-11-2 loss: 0.910465  [   96/  124]
train() client id: f_00002-12-0 loss: 0.704528  [   32/  124]
train() client id: f_00002-12-1 loss: 0.935812  [   64/  124]
train() client id: f_00002-12-2 loss: 1.001433  [   96/  124]
train() client id: f_00003-0-0 loss: 0.606770  [   32/   43]
train() client id: f_00003-1-0 loss: 0.603752  [   32/   43]
train() client id: f_00003-2-0 loss: 0.713156  [   32/   43]
train() client id: f_00003-3-0 loss: 0.551095  [   32/   43]
train() client id: f_00003-4-0 loss: 0.525256  [   32/   43]
train() client id: f_00003-5-0 loss: 0.511750  [   32/   43]
train() client id: f_00003-6-0 loss: 0.533909  [   32/   43]
train() client id: f_00003-7-0 loss: 0.614618  [   32/   43]
train() client id: f_00003-8-0 loss: 0.624697  [   32/   43]
train() client id: f_00003-9-0 loss: 0.594905  [   32/   43]
train() client id: f_00003-10-0 loss: 0.575905  [   32/   43]
train() client id: f_00003-11-0 loss: 0.725917  [   32/   43]
train() client id: f_00003-12-0 loss: 0.706622  [   32/   43]
train() client id: f_00004-0-0 loss: 0.908803  [   32/  306]
train() client id: f_00004-0-1 loss: 0.837467  [   64/  306]
train() client id: f_00004-0-2 loss: 0.994745  [   96/  306]
train() client id: f_00004-0-3 loss: 0.859856  [  128/  306]
train() client id: f_00004-0-4 loss: 0.922719  [  160/  306]
train() client id: f_00004-0-5 loss: 0.772187  [  192/  306]
train() client id: f_00004-0-6 loss: 0.917983  [  224/  306]
train() client id: f_00004-0-7 loss: 1.030458  [  256/  306]
train() client id: f_00004-0-8 loss: 0.867353  [  288/  306]
train() client id: f_00004-1-0 loss: 0.795650  [   32/  306]
train() client id: f_00004-1-1 loss: 1.005903  [   64/  306]
train() client id: f_00004-1-2 loss: 0.978483  [   96/  306]
train() client id: f_00004-1-3 loss: 0.975833  [  128/  306]
train() client id: f_00004-1-4 loss: 1.018559  [  160/  306]
train() client id: f_00004-1-5 loss: 0.953456  [  192/  306]
train() client id: f_00004-1-6 loss: 0.830159  [  224/  306]
train() client id: f_00004-1-7 loss: 0.764642  [  256/  306]
train() client id: f_00004-1-8 loss: 0.817241  [  288/  306]
train() client id: f_00004-2-0 loss: 1.053891  [   32/  306]
train() client id: f_00004-2-1 loss: 0.697041  [   64/  306]
train() client id: f_00004-2-2 loss: 0.817183  [   96/  306]
train() client id: f_00004-2-3 loss: 0.839470  [  128/  306]
train() client id: f_00004-2-4 loss: 0.914617  [  160/  306]
train() client id: f_00004-2-5 loss: 1.000298  [  192/  306]
train() client id: f_00004-2-6 loss: 0.922794  [  224/  306]
train() client id: f_00004-2-7 loss: 0.924969  [  256/  306]
train() client id: f_00004-2-8 loss: 0.970196  [  288/  306]
train() client id: f_00004-3-0 loss: 0.768544  [   32/  306]
train() client id: f_00004-3-1 loss: 0.792239  [   64/  306]
train() client id: f_00004-3-2 loss: 0.813344  [   96/  306]
train() client id: f_00004-3-3 loss: 0.912903  [  128/  306]
train() client id: f_00004-3-4 loss: 0.900000  [  160/  306]
train() client id: f_00004-3-5 loss: 0.992714  [  192/  306]
train() client id: f_00004-3-6 loss: 0.973413  [  224/  306]
train() client id: f_00004-3-7 loss: 0.960061  [  256/  306]
train() client id: f_00004-3-8 loss: 0.899261  [  288/  306]
train() client id: f_00004-4-0 loss: 0.750816  [   32/  306]
train() client id: f_00004-4-1 loss: 0.895952  [   64/  306]
train() client id: f_00004-4-2 loss: 0.925639  [   96/  306]
train() client id: f_00004-4-3 loss: 0.829538  [  128/  306]
train() client id: f_00004-4-4 loss: 0.964562  [  160/  306]
train() client id: f_00004-4-5 loss: 1.018180  [  192/  306]
train() client id: f_00004-4-6 loss: 0.853443  [  224/  306]
train() client id: f_00004-4-7 loss: 0.954349  [  256/  306]
train() client id: f_00004-4-8 loss: 0.871624  [  288/  306]
train() client id: f_00004-5-0 loss: 0.822832  [   32/  306]
train() client id: f_00004-5-1 loss: 0.749630  [   64/  306]
train() client id: f_00004-5-2 loss: 1.026355  [   96/  306]
train() client id: f_00004-5-3 loss: 0.885908  [  128/  306]
train() client id: f_00004-5-4 loss: 0.867895  [  160/  306]
train() client id: f_00004-5-5 loss: 0.926905  [  192/  306]
train() client id: f_00004-5-6 loss: 1.006094  [  224/  306]
train() client id: f_00004-5-7 loss: 0.868732  [  256/  306]
train() client id: f_00004-5-8 loss: 0.811272  [  288/  306]
train() client id: f_00004-6-0 loss: 0.881065  [   32/  306]
train() client id: f_00004-6-1 loss: 0.872606  [   64/  306]
train() client id: f_00004-6-2 loss: 0.845660  [   96/  306]
train() client id: f_00004-6-3 loss: 1.016918  [  128/  306]
train() client id: f_00004-6-4 loss: 0.853010  [  160/  306]
train() client id: f_00004-6-5 loss: 0.928606  [  192/  306]
train() client id: f_00004-6-6 loss: 1.011298  [  224/  306]
train() client id: f_00004-6-7 loss: 0.901914  [  256/  306]
train() client id: f_00004-6-8 loss: 0.683361  [  288/  306]
train() client id: f_00004-7-0 loss: 0.973592  [   32/  306]
train() client id: f_00004-7-1 loss: 0.861796  [   64/  306]
train() client id: f_00004-7-2 loss: 0.864027  [   96/  306]
train() client id: f_00004-7-3 loss: 0.722965  [  128/  306]
train() client id: f_00004-7-4 loss: 0.849684  [  160/  306]
train() client id: f_00004-7-5 loss: 0.868927  [  192/  306]
train() client id: f_00004-7-6 loss: 0.837873  [  224/  306]
train() client id: f_00004-7-7 loss: 1.057353  [  256/  306]
train() client id: f_00004-7-8 loss: 0.982367  [  288/  306]
train() client id: f_00004-8-0 loss: 0.914492  [   32/  306]
train() client id: f_00004-8-1 loss: 0.860435  [   64/  306]
train() client id: f_00004-8-2 loss: 0.861113  [   96/  306]
train() client id: f_00004-8-3 loss: 0.925923  [  128/  306]
train() client id: f_00004-8-4 loss: 0.920899  [  160/  306]
train() client id: f_00004-8-5 loss: 0.930846  [  192/  306]
train() client id: f_00004-8-6 loss: 0.780561  [  224/  306]
train() client id: f_00004-8-7 loss: 0.786434  [  256/  306]
train() client id: f_00004-8-8 loss: 0.873751  [  288/  306]
train() client id: f_00004-9-0 loss: 0.868223  [   32/  306]
train() client id: f_00004-9-1 loss: 0.837728  [   64/  306]
train() client id: f_00004-9-2 loss: 0.800295  [   96/  306]
train() client id: f_00004-9-3 loss: 0.948485  [  128/  306]
train() client id: f_00004-9-4 loss: 0.840482  [  160/  306]
train() client id: f_00004-9-5 loss: 0.914351  [  192/  306]
train() client id: f_00004-9-6 loss: 0.852183  [  224/  306]
train() client id: f_00004-9-7 loss: 0.949257  [  256/  306]
train() client id: f_00004-9-8 loss: 0.893116  [  288/  306]
train() client id: f_00004-10-0 loss: 0.915506  [   32/  306]
train() client id: f_00004-10-1 loss: 0.778442  [   64/  306]
train() client id: f_00004-10-2 loss: 1.000779  [   96/  306]
train() client id: f_00004-10-3 loss: 0.827341  [  128/  306]
train() client id: f_00004-10-4 loss: 0.928861  [  160/  306]
train() client id: f_00004-10-5 loss: 0.868570  [  192/  306]
train() client id: f_00004-10-6 loss: 0.885159  [  224/  306]
train() client id: f_00004-10-7 loss: 0.850777  [  256/  306]
train() client id: f_00004-10-8 loss: 0.864650  [  288/  306]
train() client id: f_00004-11-0 loss: 0.851443  [   32/  306]
train() client id: f_00004-11-1 loss: 1.026351  [   64/  306]
train() client id: f_00004-11-2 loss: 0.834023  [   96/  306]
train() client id: f_00004-11-3 loss: 0.835435  [  128/  306]
train() client id: f_00004-11-4 loss: 0.850182  [  160/  306]
train() client id: f_00004-11-5 loss: 0.882612  [  192/  306]
train() client id: f_00004-11-6 loss: 0.747363  [  224/  306]
train() client id: f_00004-11-7 loss: 0.860832  [  256/  306]
train() client id: f_00004-11-8 loss: 1.065599  [  288/  306]
train() client id: f_00004-12-0 loss: 0.829643  [   32/  306]
train() client id: f_00004-12-1 loss: 0.874728  [   64/  306]
train() client id: f_00004-12-2 loss: 0.997657  [   96/  306]
train() client id: f_00004-12-3 loss: 0.821596  [  128/  306]
train() client id: f_00004-12-4 loss: 0.842337  [  160/  306]
train() client id: f_00004-12-5 loss: 0.800218  [  192/  306]
train() client id: f_00004-12-6 loss: 0.837361  [  224/  306]
train() client id: f_00004-12-7 loss: 0.851196  [  256/  306]
train() client id: f_00004-12-8 loss: 0.994414  [  288/  306]
train() client id: f_00005-0-0 loss: 0.533424  [   32/  146]
train() client id: f_00005-0-1 loss: 0.935163  [   64/  146]
train() client id: f_00005-0-2 loss: 0.317136  [   96/  146]
train() client id: f_00005-0-3 loss: 0.662689  [  128/  146]
train() client id: f_00005-1-0 loss: 0.531409  [   32/  146]
train() client id: f_00005-1-1 loss: 0.778158  [   64/  146]
train() client id: f_00005-1-2 loss: 0.447009  [   96/  146]
train() client id: f_00005-1-3 loss: 0.804406  [  128/  146]
train() client id: f_00005-2-0 loss: 0.703141  [   32/  146]
train() client id: f_00005-2-1 loss: 0.454903  [   64/  146]
train() client id: f_00005-2-2 loss: 0.615163  [   96/  146]
train() client id: f_00005-2-3 loss: 0.741195  [  128/  146]
train() client id: f_00005-3-0 loss: 0.515162  [   32/  146]
train() client id: f_00005-3-1 loss: 0.549298  [   64/  146]
train() client id: f_00005-3-2 loss: 0.651756  [   96/  146]
train() client id: f_00005-3-3 loss: 0.708758  [  128/  146]
train() client id: f_00005-4-0 loss: 0.650401  [   32/  146]
train() client id: f_00005-4-1 loss: 0.746152  [   64/  146]
train() client id: f_00005-4-2 loss: 0.782075  [   96/  146]
train() client id: f_00005-4-3 loss: 0.446511  [  128/  146]
train() client id: f_00005-5-0 loss: 0.625253  [   32/  146]
train() client id: f_00005-5-1 loss: 0.485923  [   64/  146]
train() client id: f_00005-5-2 loss: 0.574255  [   96/  146]
train() client id: f_00005-5-3 loss: 0.712669  [  128/  146]
train() client id: f_00005-6-0 loss: 0.657636  [   32/  146]
train() client id: f_00005-6-1 loss: 0.610002  [   64/  146]
train() client id: f_00005-6-2 loss: 0.516478  [   96/  146]
train() client id: f_00005-6-3 loss: 0.512699  [  128/  146]
train() client id: f_00005-7-0 loss: 0.567606  [   32/  146]
train() client id: f_00005-7-1 loss: 0.543308  [   64/  146]
train() client id: f_00005-7-2 loss: 0.753098  [   96/  146]
train() client id: f_00005-7-3 loss: 0.618663  [  128/  146]
train() client id: f_00005-8-0 loss: 0.460117  [   32/  146]
train() client id: f_00005-8-1 loss: 0.612377  [   64/  146]
train() client id: f_00005-8-2 loss: 0.625374  [   96/  146]
train() client id: f_00005-8-3 loss: 0.615960  [  128/  146]
train() client id: f_00005-9-0 loss: 0.726461  [   32/  146]
train() client id: f_00005-9-1 loss: 0.721011  [   64/  146]
train() client id: f_00005-9-2 loss: 0.641529  [   96/  146]
train() client id: f_00005-9-3 loss: 0.460172  [  128/  146]
train() client id: f_00005-10-0 loss: 0.521631  [   32/  146]
train() client id: f_00005-10-1 loss: 0.627509  [   64/  146]
train() client id: f_00005-10-2 loss: 0.803628  [   96/  146]
train() client id: f_00005-10-3 loss: 0.536604  [  128/  146]
train() client id: f_00005-11-0 loss: 0.527359  [   32/  146]
train() client id: f_00005-11-1 loss: 0.535990  [   64/  146]
train() client id: f_00005-11-2 loss: 0.717209  [   96/  146]
train() client id: f_00005-11-3 loss: 0.583606  [  128/  146]
train() client id: f_00005-12-0 loss: 0.279011  [   32/  146]
train() client id: f_00005-12-1 loss: 0.862507  [   64/  146]
train() client id: f_00005-12-2 loss: 0.851276  [   96/  146]
train() client id: f_00005-12-3 loss: 0.457180  [  128/  146]
train() client id: f_00006-0-0 loss: 0.509761  [   32/   54]
train() client id: f_00006-1-0 loss: 0.543790  [   32/   54]
train() client id: f_00006-2-0 loss: 0.555287  [   32/   54]
train() client id: f_00006-3-0 loss: 0.549306  [   32/   54]
train() client id: f_00006-4-0 loss: 0.504068  [   32/   54]
train() client id: f_00006-5-0 loss: 0.526336  [   32/   54]
train() client id: f_00006-6-0 loss: 0.566314  [   32/   54]
train() client id: f_00006-7-0 loss: 0.509151  [   32/   54]
train() client id: f_00006-8-0 loss: 0.563240  [   32/   54]
train() client id: f_00006-9-0 loss: 0.513707  [   32/   54]
train() client id: f_00006-10-0 loss: 0.503804  [   32/   54]
train() client id: f_00006-11-0 loss: 0.511582  [   32/   54]
train() client id: f_00006-12-0 loss: 0.571813  [   32/   54]
train() client id: f_00007-0-0 loss: 0.582570  [   32/  179]
train() client id: f_00007-0-1 loss: 0.383052  [   64/  179]
train() client id: f_00007-0-2 loss: 0.654501  [   96/  179]
train() client id: f_00007-0-3 loss: 0.527174  [  128/  179]
train() client id: f_00007-0-4 loss: 0.526317  [  160/  179]
train() client id: f_00007-1-0 loss: 0.472730  [   32/  179]
train() client id: f_00007-1-1 loss: 0.396094  [   64/  179]
train() client id: f_00007-1-2 loss: 0.604912  [   96/  179]
train() client id: f_00007-1-3 loss: 0.721189  [  128/  179]
train() client id: f_00007-1-4 loss: 0.504530  [  160/  179]
train() client id: f_00007-2-0 loss: 0.485331  [   32/  179]
train() client id: f_00007-2-1 loss: 0.525766  [   64/  179]
train() client id: f_00007-2-2 loss: 0.581562  [   96/  179]
train() client id: f_00007-2-3 loss: 0.528831  [  128/  179]
train() client id: f_00007-2-4 loss: 0.447058  [  160/  179]
train() client id: f_00007-3-0 loss: 0.570177  [   32/  179]
train() client id: f_00007-3-1 loss: 0.334116  [   64/  179]
train() client id: f_00007-3-2 loss: 0.554980  [   96/  179]
train() client id: f_00007-3-3 loss: 0.496148  [  128/  179]
train() client id: f_00007-3-4 loss: 0.648024  [  160/  179]
train() client id: f_00007-4-0 loss: 0.482836  [   32/  179]
train() client id: f_00007-4-1 loss: 0.522638  [   64/  179]
train() client id: f_00007-4-2 loss: 0.371425  [   96/  179]
train() client id: f_00007-4-3 loss: 0.585757  [  128/  179]
train() client id: f_00007-4-4 loss: 0.560364  [  160/  179]
train() client id: f_00007-5-0 loss: 0.417476  [   32/  179]
train() client id: f_00007-5-1 loss: 0.576423  [   64/  179]
train() client id: f_00007-5-2 loss: 0.370323  [   96/  179]
train() client id: f_00007-5-3 loss: 0.434676  [  128/  179]
train() client id: f_00007-5-4 loss: 0.632350  [  160/  179]
train() client id: f_00007-6-0 loss: 0.548655  [   32/  179]
train() client id: f_00007-6-1 loss: 0.570001  [   64/  179]
train() client id: f_00007-6-2 loss: 0.457647  [   96/  179]
train() client id: f_00007-6-3 loss: 0.480669  [  128/  179]
train() client id: f_00007-6-4 loss: 0.401775  [  160/  179]
train() client id: f_00007-7-0 loss: 0.635072  [   32/  179]
train() client id: f_00007-7-1 loss: 0.342412  [   64/  179]
train() client id: f_00007-7-2 loss: 0.504011  [   96/  179]
train() client id: f_00007-7-3 loss: 0.430056  [  128/  179]
train() client id: f_00007-7-4 loss: 0.488918  [  160/  179]
train() client id: f_00007-8-0 loss: 0.460182  [   32/  179]
train() client id: f_00007-8-1 loss: 0.535587  [   64/  179]
train() client id: f_00007-8-2 loss: 0.307457  [   96/  179]
train() client id: f_00007-8-3 loss: 0.433172  [  128/  179]
train() client id: f_00007-8-4 loss: 0.555108  [  160/  179]
train() client id: f_00007-9-0 loss: 0.448593  [   32/  179]
train() client id: f_00007-9-1 loss: 0.599383  [   64/  179]
train() client id: f_00007-9-2 loss: 0.506857  [   96/  179]
train() client id: f_00007-9-3 loss: 0.343150  [  128/  179]
train() client id: f_00007-9-4 loss: 0.614745  [  160/  179]
train() client id: f_00007-10-0 loss: 0.526028  [   32/  179]
train() client id: f_00007-10-1 loss: 0.499680  [   64/  179]
train() client id: f_00007-10-2 loss: 0.345388  [   96/  179]
train() client id: f_00007-10-3 loss: 0.317638  [  128/  179]
train() client id: f_00007-10-4 loss: 0.457550  [  160/  179]
train() client id: f_00007-11-0 loss: 0.359382  [   32/  179]
train() client id: f_00007-11-1 loss: 0.403575  [   64/  179]
train() client id: f_00007-11-2 loss: 0.669346  [   96/  179]
train() client id: f_00007-11-3 loss: 0.413140  [  128/  179]
train() client id: f_00007-11-4 loss: 0.489138  [  160/  179]
train() client id: f_00007-12-0 loss: 0.412472  [   32/  179]
train() client id: f_00007-12-1 loss: 0.516277  [   64/  179]
train() client id: f_00007-12-2 loss: 0.373928  [   96/  179]
train() client id: f_00007-12-3 loss: 0.627380  [  128/  179]
train() client id: f_00007-12-4 loss: 0.579839  [  160/  179]
train() client id: f_00008-0-0 loss: 0.682046  [   32/  130]
train() client id: f_00008-0-1 loss: 0.743607  [   64/  130]
train() client id: f_00008-0-2 loss: 0.798120  [   96/  130]
train() client id: f_00008-0-3 loss: 0.713679  [  128/  130]
train() client id: f_00008-1-0 loss: 0.772079  [   32/  130]
train() client id: f_00008-1-1 loss: 0.807090  [   64/  130]
train() client id: f_00008-1-2 loss: 0.669766  [   96/  130]
train() client id: f_00008-1-3 loss: 0.690310  [  128/  130]
train() client id: f_00008-2-0 loss: 0.725922  [   32/  130]
train() client id: f_00008-2-1 loss: 0.757451  [   64/  130]
train() client id: f_00008-2-2 loss: 0.794229  [   96/  130]
train() client id: f_00008-2-3 loss: 0.661375  [  128/  130]
train() client id: f_00008-3-0 loss: 0.707683  [   32/  130]
train() client id: f_00008-3-1 loss: 0.871840  [   64/  130]
train() client id: f_00008-3-2 loss: 0.663482  [   96/  130]
train() client id: f_00008-3-3 loss: 0.676755  [  128/  130]
train() client id: f_00008-4-0 loss: 0.817700  [   32/  130]
train() client id: f_00008-4-1 loss: 0.790359  [   64/  130]
train() client id: f_00008-4-2 loss: 0.648029  [   96/  130]
train() client id: f_00008-4-3 loss: 0.621966  [  128/  130]
train() client id: f_00008-5-0 loss: 0.784988  [   32/  130]
train() client id: f_00008-5-1 loss: 0.714734  [   64/  130]
train() client id: f_00008-5-2 loss: 0.718579  [   96/  130]
train() client id: f_00008-5-3 loss: 0.727006  [  128/  130]
train() client id: f_00008-6-0 loss: 0.794204  [   32/  130]
train() client id: f_00008-6-1 loss: 0.783821  [   64/  130]
train() client id: f_00008-6-2 loss: 0.633811  [   96/  130]
train() client id: f_00008-6-3 loss: 0.701526  [  128/  130]
train() client id: f_00008-7-0 loss: 0.700752  [   32/  130]
train() client id: f_00008-7-1 loss: 0.811594  [   64/  130]
train() client id: f_00008-7-2 loss: 0.558924  [   96/  130]
train() client id: f_00008-7-3 loss: 0.809594  [  128/  130]
train() client id: f_00008-8-0 loss: 0.751485  [   32/  130]
train() client id: f_00008-8-1 loss: 0.733690  [   64/  130]
train() client id: f_00008-8-2 loss: 0.722385  [   96/  130]
train() client id: f_00008-8-3 loss: 0.701600  [  128/  130]
train() client id: f_00008-9-0 loss: 0.841916  [   32/  130]
train() client id: f_00008-9-1 loss: 0.668480  [   64/  130]
train() client id: f_00008-9-2 loss: 0.773158  [   96/  130]
train() client id: f_00008-9-3 loss: 0.664114  [  128/  130]
train() client id: f_00008-10-0 loss: 0.670247  [   32/  130]
train() client id: f_00008-10-1 loss: 0.821523  [   64/  130]
train() client id: f_00008-10-2 loss: 0.630773  [   96/  130]
train() client id: f_00008-10-3 loss: 0.826035  [  128/  130]
train() client id: f_00008-11-0 loss: 0.795404  [   32/  130]
train() client id: f_00008-11-1 loss: 0.750992  [   64/  130]
train() client id: f_00008-11-2 loss: 0.765779  [   96/  130]
train() client id: f_00008-11-3 loss: 0.635589  [  128/  130]
train() client id: f_00008-12-0 loss: 0.765864  [   32/  130]
train() client id: f_00008-12-1 loss: 0.790174  [   64/  130]
train() client id: f_00008-12-2 loss: 0.562894  [   96/  130]
train() client id: f_00008-12-3 loss: 0.833924  [  128/  130]
train() client id: f_00009-0-0 loss: 1.159225  [   32/  118]
train() client id: f_00009-0-1 loss: 1.126094  [   64/  118]
train() client id: f_00009-0-2 loss: 1.013978  [   96/  118]
train() client id: f_00009-1-0 loss: 1.068290  [   32/  118]
train() client id: f_00009-1-1 loss: 1.002762  [   64/  118]
train() client id: f_00009-1-2 loss: 1.111678  [   96/  118]
train() client id: f_00009-2-0 loss: 0.955928  [   32/  118]
train() client id: f_00009-2-1 loss: 0.916485  [   64/  118]
train() client id: f_00009-2-2 loss: 1.070163  [   96/  118]
train() client id: f_00009-3-0 loss: 0.911881  [   32/  118]
train() client id: f_00009-3-1 loss: 1.016429  [   64/  118]
train() client id: f_00009-3-2 loss: 1.082123  [   96/  118]
train() client id: f_00009-4-0 loss: 1.092121  [   32/  118]
train() client id: f_00009-4-1 loss: 0.887688  [   64/  118]
train() client id: f_00009-4-2 loss: 0.998596  [   96/  118]
train() client id: f_00009-5-0 loss: 1.056851  [   32/  118]
train() client id: f_00009-5-1 loss: 0.919907  [   64/  118]
train() client id: f_00009-5-2 loss: 0.936086  [   96/  118]
train() client id: f_00009-6-0 loss: 1.012373  [   32/  118]
train() client id: f_00009-6-1 loss: 0.831470  [   64/  118]
train() client id: f_00009-6-2 loss: 0.950120  [   96/  118]
train() client id: f_00009-7-0 loss: 0.848238  [   32/  118]
train() client id: f_00009-7-1 loss: 0.947245  [   64/  118]
train() client id: f_00009-7-2 loss: 0.952064  [   96/  118]
train() client id: f_00009-8-0 loss: 0.985099  [   32/  118]
train() client id: f_00009-8-1 loss: 0.858806  [   64/  118]
train() client id: f_00009-8-2 loss: 0.917214  [   96/  118]
train() client id: f_00009-9-0 loss: 0.935955  [   32/  118]
train() client id: f_00009-9-1 loss: 0.759144  [   64/  118]
train() client id: f_00009-9-2 loss: 0.983869  [   96/  118]
train() client id: f_00009-10-0 loss: 0.832621  [   32/  118]
train() client id: f_00009-10-1 loss: 0.863260  [   64/  118]
train() client id: f_00009-10-2 loss: 0.978049  [   96/  118]
train() client id: f_00009-11-0 loss: 0.780293  [   32/  118]
train() client id: f_00009-11-1 loss: 0.936590  [   64/  118]
train() client id: f_00009-11-2 loss: 0.864495  [   96/  118]
train() client id: f_00009-12-0 loss: 0.722282  [   32/  118]
train() client id: f_00009-12-1 loss: 0.938409  [   64/  118]
train() client id: f_00009-12-2 loss: 1.019699  [   96/  118]
At round 40 accuracy: 0.6445623342175066
At round 40 training accuracy: 0.5881958417169685
At round 40 training loss: 0.836031612931596
gradient difference: 0.4153602123260498
train() client id: f_00000-0-0 loss: 0.965839  [   32/  126]
train() client id: f_00000-0-1 loss: 1.162636  [   64/  126]
train() client id: f_00000-0-2 loss: 1.190149  [   96/  126]
train() client id: f_00000-1-0 loss: 0.984343  [   32/  126]
train() client id: f_00000-1-1 loss: 0.873473  [   64/  126]
train() client id: f_00000-1-2 loss: 1.102217  [   96/  126]
train() client id: f_00000-2-0 loss: 0.922458  [   32/  126]
train() client id: f_00000-2-1 loss: 1.017220  [   64/  126]
train() client id: f_00000-2-2 loss: 0.940883  [   96/  126]
train() client id: f_00000-3-0 loss: 0.976541  [   32/  126]
train() client id: f_00000-3-1 loss: 0.924693  [   64/  126]
train() client id: f_00000-3-2 loss: 0.757639  [   96/  126]
train() client id: f_00000-4-0 loss: 0.914302  [   32/  126]
train() client id: f_00000-4-1 loss: 0.888100  [   64/  126]
train() client id: f_00000-4-2 loss: 0.699086  [   96/  126]
train() client id: f_00000-5-0 loss: 0.812255  [   32/  126]
train() client id: f_00000-5-1 loss: 0.898434  [   64/  126]
train() client id: f_00000-5-2 loss: 0.927125  [   96/  126]
train() client id: f_00000-6-0 loss: 0.816123  [   32/  126]
train() client id: f_00000-6-1 loss: 0.977221  [   64/  126]
train() client id: f_00000-6-2 loss: 0.750778  [   96/  126]
train() client id: f_00000-7-0 loss: 0.836730  [   32/  126]
train() client id: f_00000-7-1 loss: 0.877708  [   64/  126]
train() client id: f_00000-7-2 loss: 0.714648  [   96/  126]
train() client id: f_00000-8-0 loss: 0.841317  [   32/  126]
train() client id: f_00000-8-1 loss: 0.792872  [   64/  126]
train() client id: f_00000-8-2 loss: 0.807938  [   96/  126]
train() client id: f_00000-9-0 loss: 0.690262  [   32/  126]
train() client id: f_00000-9-1 loss: 0.686504  [   64/  126]
train() client id: f_00000-9-2 loss: 0.770705  [   96/  126]
train() client id: f_00000-10-0 loss: 0.659601  [   32/  126]
train() client id: f_00000-10-1 loss: 0.905711  [   64/  126]
train() client id: f_00000-10-2 loss: 0.748153  [   96/  126]
train() client id: f_00000-11-0 loss: 0.753480  [   32/  126]
train() client id: f_00000-11-1 loss: 0.704956  [   64/  126]
train() client id: f_00000-11-2 loss: 0.821141  [   96/  126]
train() client id: f_00000-12-0 loss: 0.746036  [   32/  126]
train() client id: f_00000-12-1 loss: 0.722120  [   64/  126]
train() client id: f_00000-12-2 loss: 0.736955  [   96/  126]
train() client id: f_00001-0-0 loss: 0.377708  [   32/  265]
train() client id: f_00001-0-1 loss: 0.552004  [   64/  265]
train() client id: f_00001-0-2 loss: 0.426959  [   96/  265]
train() client id: f_00001-0-3 loss: 0.334156  [  128/  265]
train() client id: f_00001-0-4 loss: 0.527965  [  160/  265]
train() client id: f_00001-0-5 loss: 0.387574  [  192/  265]
train() client id: f_00001-0-6 loss: 0.319188  [  224/  265]
train() client id: f_00001-0-7 loss: 0.341544  [  256/  265]
train() client id: f_00001-1-0 loss: 0.410940  [   32/  265]
train() client id: f_00001-1-1 loss: 0.503741  [   64/  265]
train() client id: f_00001-1-2 loss: 0.300734  [   96/  265]
train() client id: f_00001-1-3 loss: 0.409217  [  128/  265]
train() client id: f_00001-1-4 loss: 0.372277  [  160/  265]
train() client id: f_00001-1-5 loss: 0.414255  [  192/  265]
train() client id: f_00001-1-6 loss: 0.462975  [  224/  265]
train() client id: f_00001-1-7 loss: 0.306881  [  256/  265]
train() client id: f_00001-2-0 loss: 0.316566  [   32/  265]
train() client id: f_00001-2-1 loss: 0.318427  [   64/  265]
train() client id: f_00001-2-2 loss: 0.509061  [   96/  265]
train() client id: f_00001-2-3 loss: 0.385948  [  128/  265]
train() client id: f_00001-2-4 loss: 0.374604  [  160/  265]
train() client id: f_00001-2-5 loss: 0.384940  [  192/  265]
train() client id: f_00001-2-6 loss: 0.360621  [  224/  265]
train() client id: f_00001-2-7 loss: 0.492077  [  256/  265]
train() client id: f_00001-3-0 loss: 0.313141  [   32/  265]
train() client id: f_00001-3-1 loss: 0.411789  [   64/  265]
train() client id: f_00001-3-2 loss: 0.432962  [   96/  265]
train() client id: f_00001-3-3 loss: 0.429412  [  128/  265]
train() client id: f_00001-3-4 loss: 0.350968  [  160/  265]
train() client id: f_00001-3-5 loss: 0.423203  [  192/  265]
train() client id: f_00001-3-6 loss: 0.341509  [  224/  265]
train() client id: f_00001-3-7 loss: 0.384190  [  256/  265]
train() client id: f_00001-4-0 loss: 0.292969  [   32/  265]
train() client id: f_00001-4-1 loss: 0.320443  [   64/  265]
train() client id: f_00001-4-2 loss: 0.288736  [   96/  265]
train() client id: f_00001-4-3 loss: 0.347752  [  128/  265]
train() client id: f_00001-4-4 loss: 0.476536  [  160/  265]
train() client id: f_00001-4-5 loss: 0.392120  [  192/  265]
train() client id: f_00001-4-6 loss: 0.419457  [  224/  265]
train() client id: f_00001-4-7 loss: 0.540717  [  256/  265]
train() client id: f_00001-5-0 loss: 0.377257  [   32/  265]
train() client id: f_00001-5-1 loss: 0.384656  [   64/  265]
train() client id: f_00001-5-2 loss: 0.302610  [   96/  265]
train() client id: f_00001-5-3 loss: 0.408759  [  128/  265]
train() client id: f_00001-5-4 loss: 0.278891  [  160/  265]
train() client id: f_00001-5-5 loss: 0.378237  [  192/  265]
train() client id: f_00001-5-6 loss: 0.473768  [  224/  265]
train() client id: f_00001-5-7 loss: 0.462650  [  256/  265]
train() client id: f_00001-6-0 loss: 0.369709  [   32/  265]
train() client id: f_00001-6-1 loss: 0.309251  [   64/  265]
train() client id: f_00001-6-2 loss: 0.589751  [   96/  265]
train() client id: f_00001-6-3 loss: 0.336690  [  128/  265]
train() client id: f_00001-6-4 loss: 0.363287  [  160/  265]
train() client id: f_00001-6-5 loss: 0.364609  [  192/  265]
train() client id: f_00001-6-6 loss: 0.365994  [  224/  265]
train() client id: f_00001-6-7 loss: 0.338151  [  256/  265]
train() client id: f_00001-7-0 loss: 0.330948  [   32/  265]
train() client id: f_00001-7-1 loss: 0.426615  [   64/  265]
train() client id: f_00001-7-2 loss: 0.439579  [   96/  265]
train() client id: f_00001-7-3 loss: 0.472215  [  128/  265]
train() client id: f_00001-7-4 loss: 0.301169  [  160/  265]
train() client id: f_00001-7-5 loss: 0.365062  [  192/  265]
train() client id: f_00001-7-6 loss: 0.415985  [  224/  265]
train() client id: f_00001-7-7 loss: 0.276807  [  256/  265]
train() client id: f_00001-8-0 loss: 0.288526  [   32/  265]
train() client id: f_00001-8-1 loss: 0.483569  [   64/  265]
train() client id: f_00001-8-2 loss: 0.424024  [   96/  265]
train() client id: f_00001-8-3 loss: 0.328256  [  128/  265]
train() client id: f_00001-8-4 loss: 0.497560  [  160/  265]
train() client id: f_00001-8-5 loss: 0.335162  [  192/  265]
train() client id: f_00001-8-6 loss: 0.368143  [  224/  265]
train() client id: f_00001-8-7 loss: 0.294417  [  256/  265]
train() client id: f_00001-9-0 loss: 0.280452  [   32/  265]
train() client id: f_00001-9-1 loss: 0.443147  [   64/  265]
train() client id: f_00001-9-2 loss: 0.317472  [   96/  265]
train() client id: f_00001-9-3 loss: 0.394978  [  128/  265]
train() client id: f_00001-9-4 loss: 0.280339  [  160/  265]
train() client id: f_00001-9-5 loss: 0.600757  [  192/  265]
train() client id: f_00001-9-6 loss: 0.401808  [  224/  265]
train() client id: f_00001-9-7 loss: 0.290511  [  256/  265]
train() client id: f_00001-10-0 loss: 0.330036  [   32/  265]
train() client id: f_00001-10-1 loss: 0.347580  [   64/  265]
train() client id: f_00001-10-2 loss: 0.369951  [   96/  265]
train() client id: f_00001-10-3 loss: 0.360959  [  128/  265]
train() client id: f_00001-10-4 loss: 0.408098  [  160/  265]
train() client id: f_00001-10-5 loss: 0.366004  [  192/  265]
train() client id: f_00001-10-6 loss: 0.396961  [  224/  265]
train() client id: f_00001-10-7 loss: 0.435249  [  256/  265]
train() client id: f_00001-11-0 loss: 0.409649  [   32/  265]
train() client id: f_00001-11-1 loss: 0.431840  [   64/  265]
train() client id: f_00001-11-2 loss: 0.422015  [   96/  265]
train() client id: f_00001-11-3 loss: 0.271524  [  128/  265]
train() client id: f_00001-11-4 loss: 0.271152  [  160/  265]
train() client id: f_00001-11-5 loss: 0.529491  [  192/  265]
train() client id: f_00001-11-6 loss: 0.398193  [  224/  265]
train() client id: f_00001-11-7 loss: 0.277034  [  256/  265]
train() client id: f_00001-12-0 loss: 0.452375  [   32/  265]
train() client id: f_00001-12-1 loss: 0.423193  [   64/  265]
train() client id: f_00001-12-2 loss: 0.362013  [   96/  265]
train() client id: f_00001-12-3 loss: 0.345416  [  128/  265]
train() client id: f_00001-12-4 loss: 0.389525  [  160/  265]
train() client id: f_00001-12-5 loss: 0.274967  [  192/  265]
train() client id: f_00001-12-6 loss: 0.337676  [  224/  265]
train() client id: f_00001-12-7 loss: 0.429434  [  256/  265]
train() client id: f_00002-0-0 loss: 1.182080  [   32/  124]
train() client id: f_00002-0-1 loss: 1.244240  [   64/  124]
train() client id: f_00002-0-2 loss: 1.057719  [   96/  124]
train() client id: f_00002-1-0 loss: 1.188550  [   32/  124]
train() client id: f_00002-1-1 loss: 0.818379  [   64/  124]
train() client id: f_00002-1-2 loss: 1.231611  [   96/  124]
train() client id: f_00002-2-0 loss: 1.207187  [   32/  124]
train() client id: f_00002-2-1 loss: 0.941453  [   64/  124]
train() client id: f_00002-2-2 loss: 1.076245  [   96/  124]
train() client id: f_00002-3-0 loss: 1.029691  [   32/  124]
train() client id: f_00002-3-1 loss: 0.889846  [   64/  124]
train() client id: f_00002-3-2 loss: 1.099420  [   96/  124]
train() client id: f_00002-4-0 loss: 0.935369  [   32/  124]
train() client id: f_00002-4-1 loss: 0.877360  [   64/  124]
train() client id: f_00002-4-2 loss: 1.133199  [   96/  124]
train() client id: f_00002-5-0 loss: 0.967282  [   32/  124]
train() client id: f_00002-5-1 loss: 0.843656  [   64/  124]
train() client id: f_00002-5-2 loss: 1.076216  [   96/  124]
train() client id: f_00002-6-0 loss: 1.075267  [   32/  124]
train() client id: f_00002-6-1 loss: 0.940754  [   64/  124]
train() client id: f_00002-6-2 loss: 0.807232  [   96/  124]
train() client id: f_00002-7-0 loss: 0.811182  [   32/  124]
train() client id: f_00002-7-1 loss: 0.827271  [   64/  124]
train() client id: f_00002-7-2 loss: 0.893120  [   96/  124]
train() client id: f_00002-8-0 loss: 0.902110  [   32/  124]
train() client id: f_00002-8-1 loss: 1.060078  [   64/  124]
train() client id: f_00002-8-2 loss: 0.868833  [   96/  124]
train() client id: f_00002-9-0 loss: 0.902104  [   32/  124]
train() client id: f_00002-9-1 loss: 0.883493  [   64/  124]
train() client id: f_00002-9-2 loss: 0.891462  [   96/  124]
train() client id: f_00002-10-0 loss: 0.841495  [   32/  124]
train() client id: f_00002-10-1 loss: 0.820569  [   64/  124]
train() client id: f_00002-10-2 loss: 0.997268  [   96/  124]
train() client id: f_00002-11-0 loss: 0.915607  [   32/  124]
train() client id: f_00002-11-1 loss: 0.873439  [   64/  124]
train() client id: f_00002-11-2 loss: 0.938148  [   96/  124]
train() client id: f_00002-12-0 loss: 0.985452  [   32/  124]
train() client id: f_00002-12-1 loss: 0.754701  [   64/  124]
train() client id: f_00002-12-2 loss: 0.886899  [   96/  124]
train() client id: f_00003-0-0 loss: 0.596129  [   32/   43]
train() client id: f_00003-1-0 loss: 0.417493  [   32/   43]
train() client id: f_00003-2-0 loss: 0.344195  [   32/   43]
train() client id: f_00003-3-0 loss: 0.755983  [   32/   43]
train() client id: f_00003-4-0 loss: 0.363998  [   32/   43]
train() client id: f_00003-5-0 loss: 0.478586  [   32/   43]
train() client id: f_00003-6-0 loss: 0.451807  [   32/   43]
train() client id: f_00003-7-0 loss: 0.571066  [   32/   43]
train() client id: f_00003-8-0 loss: 0.488179  [   32/   43]
train() client id: f_00003-9-0 loss: 0.562088  [   32/   43]
train() client id: f_00003-10-0 loss: 0.635586  [   32/   43]
train() client id: f_00003-11-0 loss: 0.524483  [   32/   43]
train() client id: f_00003-12-0 loss: 0.512511  [   32/   43]
train() client id: f_00004-0-0 loss: 0.776878  [   32/  306]
train() client id: f_00004-0-1 loss: 0.845239  [   64/  306]
train() client id: f_00004-0-2 loss: 0.664637  [   96/  306]
train() client id: f_00004-0-3 loss: 0.796134  [  128/  306]
train() client id: f_00004-0-4 loss: 0.754888  [  160/  306]
train() client id: f_00004-0-5 loss: 0.833801  [  192/  306]
train() client id: f_00004-0-6 loss: 0.725451  [  224/  306]
train() client id: f_00004-0-7 loss: 0.802416  [  256/  306]
train() client id: f_00004-0-8 loss: 0.632116  [  288/  306]
train() client id: f_00004-1-0 loss: 0.776165  [   32/  306]
train() client id: f_00004-1-1 loss: 0.844577  [   64/  306]
train() client id: f_00004-1-2 loss: 0.661189  [   96/  306]
train() client id: f_00004-1-3 loss: 0.803743  [  128/  306]
train() client id: f_00004-1-4 loss: 0.841770  [  160/  306]
train() client id: f_00004-1-5 loss: 0.807640  [  192/  306]
train() client id: f_00004-1-6 loss: 0.765298  [  224/  306]
train() client id: f_00004-1-7 loss: 0.622448  [  256/  306]
train() client id: f_00004-1-8 loss: 0.576270  [  288/  306]
train() client id: f_00004-2-0 loss: 0.723328  [   32/  306]
train() client id: f_00004-2-1 loss: 0.737043  [   64/  306]
train() client id: f_00004-2-2 loss: 0.794435  [   96/  306]
train() client id: f_00004-2-3 loss: 0.585752  [  128/  306]
train() client id: f_00004-2-4 loss: 0.765219  [  160/  306]
train() client id: f_00004-2-5 loss: 0.836602  [  192/  306]
train() client id: f_00004-2-6 loss: 0.741069  [  224/  306]
train() client id: f_00004-2-7 loss: 0.822060  [  256/  306]
train() client id: f_00004-2-8 loss: 0.714135  [  288/  306]
train() client id: f_00004-3-0 loss: 0.699595  [   32/  306]
train() client id: f_00004-3-1 loss: 0.731332  [   64/  306]
train() client id: f_00004-3-2 loss: 0.879090  [   96/  306]
train() client id: f_00004-3-3 loss: 0.703543  [  128/  306]
train() client id: f_00004-3-4 loss: 0.652272  [  160/  306]
train() client id: f_00004-3-5 loss: 0.800030  [  192/  306]
train() client id: f_00004-3-6 loss: 0.677086  [  224/  306]
train() client id: f_00004-3-7 loss: 0.755555  [  256/  306]
train() client id: f_00004-3-8 loss: 0.787527  [  288/  306]
train() client id: f_00004-4-0 loss: 0.651633  [   32/  306]
train() client id: f_00004-4-1 loss: 0.773328  [   64/  306]
train() client id: f_00004-4-2 loss: 0.794972  [   96/  306]
train() client id: f_00004-4-3 loss: 0.708672  [  128/  306]
train() client id: f_00004-4-4 loss: 0.861684  [  160/  306]
train() client id: f_00004-4-5 loss: 0.645998  [  192/  306]
train() client id: f_00004-4-6 loss: 0.687157  [  224/  306]
train() client id: f_00004-4-7 loss: 0.842480  [  256/  306]
train() client id: f_00004-4-8 loss: 0.782541  [  288/  306]
train() client id: f_00004-5-0 loss: 0.813984  [   32/  306]
train() client id: f_00004-5-1 loss: 0.759299  [   64/  306]
train() client id: f_00004-5-2 loss: 0.735330  [   96/  306]
train() client id: f_00004-5-3 loss: 0.656615  [  128/  306]
train() client id: f_00004-5-4 loss: 0.682626  [  160/  306]
train() client id: f_00004-5-5 loss: 0.768993  [  192/  306]
train() client id: f_00004-5-6 loss: 0.637311  [  224/  306]
train() client id: f_00004-5-7 loss: 0.730891  [  256/  306]
train() client id: f_00004-5-8 loss: 0.842829  [  288/  306]
train() client id: f_00004-6-0 loss: 0.830493  [   32/  306]
train() client id: f_00004-6-1 loss: 0.788031  [   64/  306]
train() client id: f_00004-6-2 loss: 0.680083  [   96/  306]
train() client id: f_00004-6-3 loss: 0.807142  [  128/  306]
train() client id: f_00004-6-4 loss: 0.702247  [  160/  306]
train() client id: f_00004-6-5 loss: 0.671216  [  192/  306]
train() client id: f_00004-6-6 loss: 0.642881  [  224/  306]
train() client id: f_00004-6-7 loss: 0.676631  [  256/  306]
train() client id: f_00004-6-8 loss: 0.941942  [  288/  306]
train() client id: f_00004-7-0 loss: 0.655991  [   32/  306]
train() client id: f_00004-7-1 loss: 0.773495  [   64/  306]
train() client id: f_00004-7-2 loss: 0.748614  [   96/  306]
train() client id: f_00004-7-3 loss: 0.914485  [  128/  306]
train() client id: f_00004-7-4 loss: 0.744797  [  160/  306]
train() client id: f_00004-7-5 loss: 0.941317  [  192/  306]
train() client id: f_00004-7-6 loss: 0.728859  [  224/  306]
train() client id: f_00004-7-7 loss: 0.716754  [  256/  306]
train() client id: f_00004-7-8 loss: 0.616053  [  288/  306]
train() client id: f_00004-8-0 loss: 0.700529  [   32/  306]
train() client id: f_00004-8-1 loss: 0.717091  [   64/  306]
train() client id: f_00004-8-2 loss: 0.808788  [   96/  306]
train() client id: f_00004-8-3 loss: 0.702325  [  128/  306]
train() client id: f_00004-8-4 loss: 0.667888  [  160/  306]
train() client id: f_00004-8-5 loss: 0.863526  [  192/  306]
train() client id: f_00004-8-6 loss: 0.776668  [  224/  306]
train() client id: f_00004-8-7 loss: 0.834379  [  256/  306]
train() client id: f_00004-8-8 loss: 0.716505  [  288/  306]
train() client id: f_00004-9-0 loss: 0.833585  [   32/  306]
train() client id: f_00004-9-1 loss: 0.706418  [   64/  306]
train() client id: f_00004-9-2 loss: 0.689328  [   96/  306]
train() client id: f_00004-9-3 loss: 0.758091  [  128/  306]
train() client id: f_00004-9-4 loss: 0.765820  [  160/  306]
train() client id: f_00004-9-5 loss: 0.802354  [  192/  306]
train() client id: f_00004-9-6 loss: 0.817681  [  224/  306]
train() client id: f_00004-9-7 loss: 0.677486  [  256/  306]
train() client id: f_00004-9-8 loss: 0.730997  [  288/  306]
train() client id: f_00004-10-0 loss: 0.737835  [   32/  306]
train() client id: f_00004-10-1 loss: 0.781528  [   64/  306]
train() client id: f_00004-10-2 loss: 0.669463  [   96/  306]
train() client id: f_00004-10-3 loss: 0.733957  [  128/  306]
train() client id: f_00004-10-4 loss: 0.731103  [  160/  306]
train() client id: f_00004-10-5 loss: 0.689931  [  192/  306]
train() client id: f_00004-10-6 loss: 0.955391  [  224/  306]
train() client id: f_00004-10-7 loss: 0.846944  [  256/  306]
train() client id: f_00004-10-8 loss: 0.655723  [  288/  306]
train() client id: f_00004-11-0 loss: 0.748493  [   32/  306]
train() client id: f_00004-11-1 loss: 0.713901  [   64/  306]
train() client id: f_00004-11-2 loss: 0.807302  [   96/  306]
train() client id: f_00004-11-3 loss: 0.655960  [  128/  306]
train() client id: f_00004-11-4 loss: 0.688027  [  160/  306]
train() client id: f_00004-11-5 loss: 0.749442  [  192/  306]
train() client id: f_00004-11-6 loss: 0.791103  [  224/  306]
train() client id: f_00004-11-7 loss: 0.698050  [  256/  306]
train() client id: f_00004-11-8 loss: 0.897577  [  288/  306]
train() client id: f_00004-12-0 loss: 0.788903  [   32/  306]
train() client id: f_00004-12-1 loss: 0.758051  [   64/  306]
train() client id: f_00004-12-2 loss: 0.735576  [   96/  306]
train() client id: f_00004-12-3 loss: 0.647237  [  128/  306]
train() client id: f_00004-12-4 loss: 0.661102  [  160/  306]
train() client id: f_00004-12-5 loss: 0.732874  [  192/  306]
train() client id: f_00004-12-6 loss: 0.708053  [  224/  306]
train() client id: f_00004-12-7 loss: 0.797666  [  256/  306]
train() client id: f_00004-12-8 loss: 0.806413  [  288/  306]
train() client id: f_00005-0-0 loss: 0.703686  [   32/  146]
train() client id: f_00005-0-1 loss: 0.649785  [   64/  146]
train() client id: f_00005-0-2 loss: 1.055965  [   96/  146]
train() client id: f_00005-0-3 loss: 0.772678  [  128/  146]
train() client id: f_00005-1-0 loss: 0.994251  [   32/  146]
train() client id: f_00005-1-1 loss: 0.811341  [   64/  146]
train() client id: f_00005-1-2 loss: 0.721117  [   96/  146]
train() client id: f_00005-1-3 loss: 0.642536  [  128/  146]
train() client id: f_00005-2-0 loss: 0.963302  [   32/  146]
train() client id: f_00005-2-1 loss: 0.723520  [   64/  146]
train() client id: f_00005-2-2 loss: 0.934495  [   96/  146]
train() client id: f_00005-2-3 loss: 0.775802  [  128/  146]
train() client id: f_00005-3-0 loss: 0.616272  [   32/  146]
train() client id: f_00005-3-1 loss: 0.746887  [   64/  146]
train() client id: f_00005-3-2 loss: 0.625354  [   96/  146]
train() client id: f_00005-3-3 loss: 1.211923  [  128/  146]
train() client id: f_00005-4-0 loss: 0.833692  [   32/  146]
train() client id: f_00005-4-1 loss: 0.661979  [   64/  146]
train() client id: f_00005-4-2 loss: 0.879980  [   96/  146]
train() client id: f_00005-4-3 loss: 0.727612  [  128/  146]
train() client id: f_00005-5-0 loss: 0.787565  [   32/  146]
train() client id: f_00005-5-1 loss: 0.699549  [   64/  146]
train() client id: f_00005-5-2 loss: 0.794907  [   96/  146]
train() client id: f_00005-5-3 loss: 0.898112  [  128/  146]
train() client id: f_00005-6-0 loss: 0.777002  [   32/  146]
train() client id: f_00005-6-1 loss: 0.914955  [   64/  146]
train() client id: f_00005-6-2 loss: 0.713341  [   96/  146]
train() client id: f_00005-6-3 loss: 0.984848  [  128/  146]
train() client id: f_00005-7-0 loss: 0.813151  [   32/  146]
train() client id: f_00005-7-1 loss: 0.717628  [   64/  146]
train() client id: f_00005-7-2 loss: 0.843709  [   96/  146]
train() client id: f_00005-7-3 loss: 0.827689  [  128/  146]
train() client id: f_00005-8-0 loss: 0.776684  [   32/  146]
train() client id: f_00005-8-1 loss: 0.960381  [   64/  146]
train() client id: f_00005-8-2 loss: 0.711731  [   96/  146]
train() client id: f_00005-8-3 loss: 0.718497  [  128/  146]
train() client id: f_00005-9-0 loss: 0.837874  [   32/  146]
train() client id: f_00005-9-1 loss: 0.841019  [   64/  146]
train() client id: f_00005-9-2 loss: 0.797486  [   96/  146]
train() client id: f_00005-9-3 loss: 0.684161  [  128/  146]
train() client id: f_00005-10-0 loss: 0.776450  [   32/  146]
train() client id: f_00005-10-1 loss: 0.880376  [   64/  146]
train() client id: f_00005-10-2 loss: 0.921363  [   96/  146]
train() client id: f_00005-10-3 loss: 0.602068  [  128/  146]
train() client id: f_00005-11-0 loss: 0.777397  [   32/  146]
train() client id: f_00005-11-1 loss: 0.682726  [   64/  146]
train() client id: f_00005-11-2 loss: 0.801072  [   96/  146]
train() client id: f_00005-11-3 loss: 0.781989  [  128/  146]
train() client id: f_00005-12-0 loss: 0.856588  [   32/  146]
train() client id: f_00005-12-1 loss: 1.062619  [   64/  146]
train() client id: f_00005-12-2 loss: 0.723692  [   96/  146]
train() client id: f_00005-12-3 loss: 0.682426  [  128/  146]
train() client id: f_00006-0-0 loss: 0.464829  [   32/   54]
train() client id: f_00006-1-0 loss: 0.417533  [   32/   54]
train() client id: f_00006-2-0 loss: 0.467793  [   32/   54]
train() client id: f_00006-3-0 loss: 0.468764  [   32/   54]
train() client id: f_00006-4-0 loss: 0.518947  [   32/   54]
train() client id: f_00006-5-0 loss: 0.448147  [   32/   54]
train() client id: f_00006-6-0 loss: 0.411639  [   32/   54]
train() client id: f_00006-7-0 loss: 0.519216  [   32/   54]
train() client id: f_00006-8-0 loss: 0.444415  [   32/   54]
train() client id: f_00006-9-0 loss: 0.418441  [   32/   54]
train() client id: f_00006-10-0 loss: 0.396980  [   32/   54]
train() client id: f_00006-11-0 loss: 0.511152  [   32/   54]
train() client id: f_00006-12-0 loss: 0.510480  [   32/   54]
train() client id: f_00007-0-0 loss: 0.451510  [   32/  179]
train() client id: f_00007-0-1 loss: 0.529187  [   64/  179]
train() client id: f_00007-0-2 loss: 0.481278  [   96/  179]
train() client id: f_00007-0-3 loss: 0.398127  [  128/  179]
train() client id: f_00007-0-4 loss: 0.726680  [  160/  179]
train() client id: f_00007-1-0 loss: 0.344802  [   32/  179]
train() client id: f_00007-1-1 loss: 0.636585  [   64/  179]
train() client id: f_00007-1-2 loss: 0.430909  [   96/  179]
train() client id: f_00007-1-3 loss: 0.501737  [  128/  179]
train() client id: f_00007-1-4 loss: 0.651307  [  160/  179]
train() client id: f_00007-2-0 loss: 0.525023  [   32/  179]
train() client id: f_00007-2-1 loss: 0.301830  [   64/  179]
train() client id: f_00007-2-2 loss: 0.352902  [   96/  179]
train() client id: f_00007-2-3 loss: 0.438344  [  128/  179]
train() client id: f_00007-2-4 loss: 0.754112  [  160/  179]
train() client id: f_00007-3-0 loss: 0.502961  [   32/  179]
train() client id: f_00007-3-1 loss: 0.513693  [   64/  179]
train() client id: f_00007-3-2 loss: 0.330997  [   96/  179]
train() client id: f_00007-3-3 loss: 0.547843  [  128/  179]
train() client id: f_00007-3-4 loss: 0.450412  [  160/  179]
train() client id: f_00007-4-0 loss: 0.722036  [   32/  179]
train() client id: f_00007-4-1 loss: 0.402499  [   64/  179]
train() client id: f_00007-4-2 loss: 0.348443  [   96/  179]
train() client id: f_00007-4-3 loss: 0.505078  [  128/  179]
train() client id: f_00007-4-4 loss: 0.358268  [  160/  179]
train() client id: f_00007-5-0 loss: 0.480630  [   32/  179]
train() client id: f_00007-5-1 loss: 0.535584  [   64/  179]
train() client id: f_00007-5-2 loss: 0.457540  [   96/  179]
train() client id: f_00007-5-3 loss: 0.431986  [  128/  179]
train() client id: f_00007-5-4 loss: 0.495867  [  160/  179]
train() client id: f_00007-6-0 loss: 0.588553  [   32/  179]
train() client id: f_00007-6-1 loss: 0.405900  [   64/  179]
train() client id: f_00007-6-2 loss: 0.768505  [   96/  179]
train() client id: f_00007-6-3 loss: 0.293895  [  128/  179]
train() client id: f_00007-6-4 loss: 0.322129  [  160/  179]
train() client id: f_00007-7-0 loss: 0.627418  [   32/  179]
train() client id: f_00007-7-1 loss: 0.449764  [   64/  179]
train() client id: f_00007-7-2 loss: 0.299341  [   96/  179]
train() client id: f_00007-7-3 loss: 0.650272  [  128/  179]
train() client id: f_00007-7-4 loss: 0.329679  [  160/  179]
train() client id: f_00007-8-0 loss: 0.293019  [   32/  179]
train() client id: f_00007-8-1 loss: 0.573218  [   64/  179]
train() client id: f_00007-8-2 loss: 0.391336  [   96/  179]
train() client id: f_00007-8-3 loss: 0.407865  [  128/  179]
train() client id: f_00007-8-4 loss: 0.695922  [  160/  179]
train() client id: f_00007-9-0 loss: 0.425311  [   32/  179]
train() client id: f_00007-9-1 loss: 0.324023  [   64/  179]
train() client id: f_00007-9-2 loss: 0.620265  [   96/  179]
train() client id: f_00007-9-3 loss: 0.560993  [  128/  179]
train() client id: f_00007-9-4 loss: 0.418240  [  160/  179]
train() client id: f_00007-10-0 loss: 0.372314  [   32/  179]
train() client id: f_00007-10-1 loss: 0.506140  [   64/  179]
train() client id: f_00007-10-2 loss: 0.405218  [   96/  179]
train() client id: f_00007-10-3 loss: 0.545867  [  128/  179]
train() client id: f_00007-10-4 loss: 0.411606  [  160/  179]
train() client id: f_00007-11-0 loss: 0.471191  [   32/  179]
train() client id: f_00007-11-1 loss: 0.401129  [   64/  179]
train() client id: f_00007-11-2 loss: 0.385178  [   96/  179]
train() client id: f_00007-11-3 loss: 0.497034  [  128/  179]
train() client id: f_00007-11-4 loss: 0.493124  [  160/  179]
train() client id: f_00007-12-0 loss: 0.332202  [   32/  179]
train() client id: f_00007-12-1 loss: 0.608600  [   64/  179]
train() client id: f_00007-12-2 loss: 0.267900  [   96/  179]
train() client id: f_00007-12-3 loss: 0.502462  [  128/  179]
train() client id: f_00007-12-4 loss: 0.555157  [  160/  179]
train() client id: f_00008-0-0 loss: 0.620525  [   32/  130]
train() client id: f_00008-0-1 loss: 0.684711  [   64/  130]
train() client id: f_00008-0-2 loss: 0.607160  [   96/  130]
train() client id: f_00008-0-3 loss: 0.727154  [  128/  130]
train() client id: f_00008-1-0 loss: 0.765837  [   32/  130]
train() client id: f_00008-1-1 loss: 0.613125  [   64/  130]
train() client id: f_00008-1-2 loss: 0.562120  [   96/  130]
train() client id: f_00008-1-3 loss: 0.661146  [  128/  130]
train() client id: f_00008-2-0 loss: 0.645033  [   32/  130]
train() client id: f_00008-2-1 loss: 0.638584  [   64/  130]
train() client id: f_00008-2-2 loss: 0.708514  [   96/  130]
train() client id: f_00008-2-3 loss: 0.643429  [  128/  130]
train() client id: f_00008-3-0 loss: 0.749280  [   32/  130]
train() client id: f_00008-3-1 loss: 0.705652  [   64/  130]
train() client id: f_00008-3-2 loss: 0.646688  [   96/  130]
train() client id: f_00008-3-3 loss: 0.540696  [  128/  130]
train() client id: f_00008-4-0 loss: 0.597269  [   32/  130]
train() client id: f_00008-4-1 loss: 0.667514  [   64/  130]
train() client id: f_00008-4-2 loss: 0.622492  [   96/  130]
train() client id: f_00008-4-3 loss: 0.729246  [  128/  130]
train() client id: f_00008-5-0 loss: 0.776906  [   32/  130]
train() client id: f_00008-5-1 loss: 0.538022  [   64/  130]
train() client id: f_00008-5-2 loss: 0.683873  [   96/  130]
train() client id: f_00008-5-3 loss: 0.624443  [  128/  130]
train() client id: f_00008-6-0 loss: 0.597981  [   32/  130]
train() client id: f_00008-6-1 loss: 0.588950  [   64/  130]
train() client id: f_00008-6-2 loss: 0.619308  [   96/  130]
train() client id: f_00008-6-3 loss: 0.830554  [  128/  130]
train() client id: f_00008-7-0 loss: 0.818686  [   32/  130]
train() client id: f_00008-7-1 loss: 0.630459  [   64/  130]
train() client id: f_00008-7-2 loss: 0.578957  [   96/  130]
train() client id: f_00008-7-3 loss: 0.566049  [  128/  130]
train() client id: f_00008-8-0 loss: 0.751389  [   32/  130]
train() client id: f_00008-8-1 loss: 0.560449  [   64/  130]
train() client id: f_00008-8-2 loss: 0.608122  [   96/  130]
train() client id: f_00008-8-3 loss: 0.702361  [  128/  130]
train() client id: f_00008-9-0 loss: 0.595597  [   32/  130]
train() client id: f_00008-9-1 loss: 0.713736  [   64/  130]
train() client id: f_00008-9-2 loss: 0.604124  [   96/  130]
train() client id: f_00008-9-3 loss: 0.735961  [  128/  130]
train() client id: f_00008-10-0 loss: 0.497373  [   32/  130]
train() client id: f_00008-10-1 loss: 0.781774  [   64/  130]
train() client id: f_00008-10-2 loss: 0.737044  [   96/  130]
train() client id: f_00008-10-3 loss: 0.632235  [  128/  130]
train() client id: f_00008-11-0 loss: 0.670564  [   32/  130]
train() client id: f_00008-11-1 loss: 0.566570  [   64/  130]
train() client id: f_00008-11-2 loss: 0.731294  [   96/  130]
train() client id: f_00008-11-3 loss: 0.682109  [  128/  130]
train() client id: f_00008-12-0 loss: 0.724762  [   32/  130]
train() client id: f_00008-12-1 loss: 0.613947  [   64/  130]
train() client id: f_00008-12-2 loss: 0.732412  [   96/  130]
train() client id: f_00008-12-3 loss: 0.580963  [  128/  130]
train() client id: f_00009-0-0 loss: 1.160120  [   32/  118]
train() client id: f_00009-0-1 loss: 1.057610  [   64/  118]
train() client id: f_00009-0-2 loss: 0.980093  [   96/  118]
train() client id: f_00009-1-0 loss: 1.130771  [   32/  118]
train() client id: f_00009-1-1 loss: 0.897453  [   64/  118]
train() client id: f_00009-1-2 loss: 0.975068  [   96/  118]
train() client id: f_00009-2-0 loss: 0.966791  [   32/  118]
train() client id: f_00009-2-1 loss: 0.963402  [   64/  118]
train() client id: f_00009-2-2 loss: 0.778320  [   96/  118]
train() client id: f_00009-3-0 loss: 0.976799  [   32/  118]
train() client id: f_00009-3-1 loss: 0.954476  [   64/  118]
train() client id: f_00009-3-2 loss: 0.854618  [   96/  118]
train() client id: f_00009-4-0 loss: 0.931434  [   32/  118]
train() client id: f_00009-4-1 loss: 0.821024  [   64/  118]
train() client id: f_00009-4-2 loss: 0.806628  [   96/  118]
train() client id: f_00009-5-0 loss: 0.692192  [   32/  118]
train() client id: f_00009-5-1 loss: 0.845949  [   64/  118]
train() client id: f_00009-5-2 loss: 0.823740  [   96/  118]
train() client id: f_00009-6-0 loss: 0.745645  [   32/  118]
train() client id: f_00009-6-1 loss: 0.795021  [   64/  118]
train() client id: f_00009-6-2 loss: 0.776424  [   96/  118]
train() client id: f_00009-7-0 loss: 0.945735  [   32/  118]
train() client id: f_00009-7-1 loss: 0.764263  [   64/  118]
train() client id: f_00009-7-2 loss: 0.647509  [   96/  118]
train() client id: f_00009-8-0 loss: 0.726209  [   32/  118]
train() client id: f_00009-8-1 loss: 0.721570  [   64/  118]
train() client id: f_00009-8-2 loss: 0.738073  [   96/  118]
train() client id: f_00009-9-0 loss: 0.721778  [   32/  118]
train() client id: f_00009-9-1 loss: 0.779598  [   64/  118]
train() client id: f_00009-9-2 loss: 0.754043  [   96/  118]
train() client id: f_00009-10-0 loss: 0.606610  [   32/  118]
train() client id: f_00009-10-1 loss: 0.861324  [   64/  118]
train() client id: f_00009-10-2 loss: 0.676626  [   96/  118]
train() client id: f_00009-11-0 loss: 0.672351  [   32/  118]
train() client id: f_00009-11-1 loss: 0.627594  [   64/  118]
train() client id: f_00009-11-2 loss: 0.695148  [   96/  118]
train() client id: f_00009-12-0 loss: 0.804300  [   32/  118]
train() client id: f_00009-12-1 loss: 0.673364  [   64/  118]
train() client id: f_00009-12-2 loss: 0.629637  [   96/  118]
At round 41 accuracy: 0.6445623342175066
At round 41 training accuracy: 0.5922199865861838
At round 41 training loss: 0.8212314056205504
gradient difference: 0.3923566937446594
train() client id: f_00000-0-0 loss: 1.172646  [   32/  126]
train() client id: f_00000-0-1 loss: 1.050315  [   64/  126]
train() client id: f_00000-0-2 loss: 1.133355  [   96/  126]
train() client id: f_00000-1-0 loss: 0.973422  [   32/  126]
train() client id: f_00000-1-1 loss: 0.867724  [   64/  126]
train() client id: f_00000-1-2 loss: 1.114608  [   96/  126]
train() client id: f_00000-2-0 loss: 0.926415  [   32/  126]
train() client id: f_00000-2-1 loss: 0.909080  [   64/  126]
train() client id: f_00000-2-2 loss: 1.208971  [   96/  126]
train() client id: f_00000-3-0 loss: 0.955215  [   32/  126]
train() client id: f_00000-3-1 loss: 1.023639  [   64/  126]
train() client id: f_00000-3-2 loss: 0.851754  [   96/  126]
train() client id: f_00000-4-0 loss: 0.837293  [   32/  126]
train() client id: f_00000-4-1 loss: 0.940431  [   64/  126]
train() client id: f_00000-4-2 loss: 0.837903  [   96/  126]
train() client id: f_00000-5-0 loss: 0.941241  [   32/  126]
train() client id: f_00000-5-1 loss: 1.003082  [   64/  126]
train() client id: f_00000-5-2 loss: 0.706466  [   96/  126]
train() client id: f_00000-6-0 loss: 0.845459  [   32/  126]
train() client id: f_00000-6-1 loss: 0.845752  [   64/  126]
train() client id: f_00000-6-2 loss: 0.778365  [   96/  126]
train() client id: f_00000-7-0 loss: 0.844778  [   32/  126]
train() client id: f_00000-7-1 loss: 0.890038  [   64/  126]
train() client id: f_00000-7-2 loss: 0.801672  [   96/  126]
train() client id: f_00000-8-0 loss: 0.711764  [   32/  126]
train() client id: f_00000-8-1 loss: 0.772214  [   64/  126]
train() client id: f_00000-8-2 loss: 0.835079  [   96/  126]
train() client id: f_00000-9-0 loss: 0.693615  [   32/  126]
train() client id: f_00000-9-1 loss: 0.823222  [   64/  126]
train() client id: f_00000-9-2 loss: 0.863109  [   96/  126]
train() client id: f_00000-10-0 loss: 0.739783  [   32/  126]
train() client id: f_00000-10-1 loss: 0.743944  [   64/  126]
train() client id: f_00000-10-2 loss: 0.858798  [   96/  126]
train() client id: f_00000-11-0 loss: 0.790177  [   32/  126]
train() client id: f_00000-11-1 loss: 0.679500  [   64/  126]
train() client id: f_00000-11-2 loss: 0.817828  [   96/  126]
train() client id: f_00000-12-0 loss: 0.854416  [   32/  126]
train() client id: f_00000-12-1 loss: 0.794470  [   64/  126]
train() client id: f_00000-12-2 loss: 0.823503  [   96/  126]
train() client id: f_00001-0-0 loss: 0.393449  [   32/  265]
train() client id: f_00001-0-1 loss: 0.504867  [   64/  265]
train() client id: f_00001-0-2 loss: 0.390867  [   96/  265]
train() client id: f_00001-0-3 loss: 0.479584  [  128/  265]
train() client id: f_00001-0-4 loss: 0.383742  [  160/  265]
train() client id: f_00001-0-5 loss: 0.344023  [  192/  265]
train() client id: f_00001-0-6 loss: 0.367100  [  224/  265]
train() client id: f_00001-0-7 loss: 0.521931  [  256/  265]
train() client id: f_00001-1-0 loss: 0.415415  [   32/  265]
train() client id: f_00001-1-1 loss: 0.351519  [   64/  265]
train() client id: f_00001-1-2 loss: 0.490376  [   96/  265]
train() client id: f_00001-1-3 loss: 0.394741  [  128/  265]
train() client id: f_00001-1-4 loss: 0.561930  [  160/  265]
train() client id: f_00001-1-5 loss: 0.352752  [  192/  265]
train() client id: f_00001-1-6 loss: 0.399920  [  224/  265]
train() client id: f_00001-1-7 loss: 0.324612  [  256/  265]
train() client id: f_00001-2-0 loss: 0.370217  [   32/  265]
train() client id: f_00001-2-1 loss: 0.515374  [   64/  265]
train() client id: f_00001-2-2 loss: 0.312432  [   96/  265]
train() client id: f_00001-2-3 loss: 0.403824  [  128/  265]
train() client id: f_00001-2-4 loss: 0.482127  [  160/  265]
train() client id: f_00001-2-5 loss: 0.432696  [  192/  265]
train() client id: f_00001-2-6 loss: 0.449908  [  224/  265]
train() client id: f_00001-2-7 loss: 0.312107  [  256/  265]
train() client id: f_00001-3-0 loss: 0.472256  [   32/  265]
train() client id: f_00001-3-1 loss: 0.320573  [   64/  265]
train() client id: f_00001-3-2 loss: 0.367772  [   96/  265]
train() client id: f_00001-3-3 loss: 0.342740  [  128/  265]
train() client id: f_00001-3-4 loss: 0.556007  [  160/  265]
train() client id: f_00001-3-5 loss: 0.367331  [  192/  265]
train() client id: f_00001-3-6 loss: 0.443704  [  224/  265]
train() client id: f_00001-3-7 loss: 0.358588  [  256/  265]
train() client id: f_00001-4-0 loss: 0.408562  [   32/  265]
train() client id: f_00001-4-1 loss: 0.524265  [   64/  265]
train() client id: f_00001-4-2 loss: 0.358554  [   96/  265]
train() client id: f_00001-4-3 loss: 0.390637  [  128/  265]
train() client id: f_00001-4-4 loss: 0.383897  [  160/  265]
train() client id: f_00001-4-5 loss: 0.393030  [  192/  265]
train() client id: f_00001-4-6 loss: 0.397342  [  224/  265]
train() client id: f_00001-4-7 loss: 0.330955  [  256/  265]
train() client id: f_00001-5-0 loss: 0.380961  [   32/  265]
train() client id: f_00001-5-1 loss: 0.650556  [   64/  265]
train() client id: f_00001-5-2 loss: 0.364237  [   96/  265]
train() client id: f_00001-5-3 loss: 0.353064  [  128/  265]
train() client id: f_00001-5-4 loss: 0.355306  [  160/  265]
train() client id: f_00001-5-5 loss: 0.348884  [  192/  265]
train() client id: f_00001-5-6 loss: 0.305236  [  224/  265]
train() client id: f_00001-5-7 loss: 0.357625  [  256/  265]
train() client id: f_00001-6-0 loss: 0.294561  [   32/  265]
train() client id: f_00001-6-1 loss: 0.407206  [   64/  265]
train() client id: f_00001-6-2 loss: 0.322729  [   96/  265]
train() client id: f_00001-6-3 loss: 0.469169  [  128/  265]
train() client id: f_00001-6-4 loss: 0.446356  [  160/  265]
train() client id: f_00001-6-5 loss: 0.366956  [  192/  265]
train() client id: f_00001-6-6 loss: 0.422651  [  224/  265]
train() client id: f_00001-6-7 loss: 0.347983  [  256/  265]
train() client id: f_00001-7-0 loss: 0.547604  [   32/  265]
train() client id: f_00001-7-1 loss: 0.437037  [   64/  265]
train() client id: f_00001-7-2 loss: 0.325114  [   96/  265]
train() client id: f_00001-7-3 loss: 0.294276  [  128/  265]
train() client id: f_00001-7-4 loss: 0.453921  [  160/  265]
train() client id: f_00001-7-5 loss: 0.304075  [  192/  265]
train() client id: f_00001-7-6 loss: 0.443644  [  224/  265]
train() client id: f_00001-7-7 loss: 0.293278  [  256/  265]
train() client id: f_00001-8-0 loss: 0.397601  [   32/  265]
train() client id: f_00001-8-1 loss: 0.409483  [   64/  265]
train() client id: f_00001-8-2 loss: 0.397209  [   96/  265]
train() client id: f_00001-8-3 loss: 0.508501  [  128/  265]
train() client id: f_00001-8-4 loss: 0.404815  [  160/  265]
train() client id: f_00001-8-5 loss: 0.373351  [  192/  265]
train() client id: f_00001-8-6 loss: 0.315360  [  224/  265]
train() client id: f_00001-8-7 loss: 0.275341  [  256/  265]
train() client id: f_00001-9-0 loss: 0.354284  [   32/  265]
train() client id: f_00001-9-1 loss: 0.434586  [   64/  265]
train() client id: f_00001-9-2 loss: 0.522486  [   96/  265]
train() client id: f_00001-9-3 loss: 0.384351  [  128/  265]
train() client id: f_00001-9-4 loss: 0.368218  [  160/  265]
train() client id: f_00001-9-5 loss: 0.278154  [  192/  265]
train() client id: f_00001-9-6 loss: 0.376451  [  224/  265]
train() client id: f_00001-9-7 loss: 0.347604  [  256/  265]
train() client id: f_00001-10-0 loss: 0.282023  [   32/  265]
train() client id: f_00001-10-1 loss: 0.326641  [   64/  265]
train() client id: f_00001-10-2 loss: 0.378712  [   96/  265]
train() client id: f_00001-10-3 loss: 0.484143  [  128/  265]
train() client id: f_00001-10-4 loss: 0.615930  [  160/  265]
train() client id: f_00001-10-5 loss: 0.350812  [  192/  265]
train() client id: f_00001-10-6 loss: 0.298241  [  224/  265]
train() client id: f_00001-10-7 loss: 0.294163  [  256/  265]
train() client id: f_00001-11-0 loss: 0.377541  [   32/  265]
train() client id: f_00001-11-1 loss: 0.353410  [   64/  265]
train() client id: f_00001-11-2 loss: 0.352715  [   96/  265]
train() client id: f_00001-11-3 loss: 0.375206  [  128/  265]
train() client id: f_00001-11-4 loss: 0.367913  [  160/  265]
train() client id: f_00001-11-5 loss: 0.363039  [  192/  265]
train() client id: f_00001-11-6 loss: 0.367756  [  224/  265]
train() client id: f_00001-11-7 loss: 0.461134  [  256/  265]
train() client id: f_00001-12-0 loss: 0.379075  [   32/  265]
train() client id: f_00001-12-1 loss: 0.319155  [   64/  265]
train() client id: f_00001-12-2 loss: 0.285511  [   96/  265]
train() client id: f_00001-12-3 loss: 0.495319  [  128/  265]
train() client id: f_00001-12-4 loss: 0.363112  [  160/  265]
train() client id: f_00001-12-5 loss: 0.496025  [  192/  265]
train() client id: f_00001-12-6 loss: 0.282006  [  224/  265]
train() client id: f_00001-12-7 loss: 0.390864  [  256/  265]
train() client id: f_00002-0-0 loss: 1.108727  [   32/  124]
train() client id: f_00002-0-1 loss: 1.083336  [   64/  124]
train() client id: f_00002-0-2 loss: 1.248904  [   96/  124]
train() client id: f_00002-1-0 loss: 1.126639  [   32/  124]
train() client id: f_00002-1-1 loss: 1.238299  [   64/  124]
train() client id: f_00002-1-2 loss: 1.165012  [   96/  124]
train() client id: f_00002-2-0 loss: 0.904459  [   32/  124]
train() client id: f_00002-2-1 loss: 1.183432  [   64/  124]
train() client id: f_00002-2-2 loss: 1.151989  [   96/  124]
train() client id: f_00002-3-0 loss: 1.168135  [   32/  124]
train() client id: f_00002-3-1 loss: 1.266738  [   64/  124]
train() client id: f_00002-3-2 loss: 0.845238  [   96/  124]
train() client id: f_00002-4-0 loss: 1.052183  [   32/  124]
train() client id: f_00002-4-1 loss: 1.166465  [   64/  124]
train() client id: f_00002-4-2 loss: 1.077397  [   96/  124]
train() client id: f_00002-5-0 loss: 1.104309  [   32/  124]
train() client id: f_00002-5-1 loss: 1.139571  [   64/  124]
train() client id: f_00002-5-2 loss: 1.003325  [   96/  124]
train() client id: f_00002-6-0 loss: 0.907682  [   32/  124]
train() client id: f_00002-6-1 loss: 1.172685  [   64/  124]
train() client id: f_00002-6-2 loss: 0.952217  [   96/  124]
train() client id: f_00002-7-0 loss: 0.976275  [   32/  124]
train() client id: f_00002-7-1 loss: 1.036935  [   64/  124]
train() client id: f_00002-7-2 loss: 1.032515  [   96/  124]
train() client id: f_00002-8-0 loss: 1.055801  [   32/  124]
train() client id: f_00002-8-1 loss: 1.111062  [   64/  124]
train() client id: f_00002-8-2 loss: 0.865384  [   96/  124]
train() client id: f_00002-9-0 loss: 1.062014  [   32/  124]
train() client id: f_00002-9-1 loss: 0.894491  [   64/  124]
train() client id: f_00002-9-2 loss: 0.955927  [   96/  124]
train() client id: f_00002-10-0 loss: 0.913521  [   32/  124]
train() client id: f_00002-10-1 loss: 1.035532  [   64/  124]
train() client id: f_00002-10-2 loss: 1.115057  [   96/  124]
train() client id: f_00002-11-0 loss: 1.014962  [   32/  124]
train() client id: f_00002-11-1 loss: 0.994132  [   64/  124]
train() client id: f_00002-11-2 loss: 0.940813  [   96/  124]
train() client id: f_00002-12-0 loss: 0.995452  [   32/  124]
train() client id: f_00002-12-1 loss: 1.081804  [   64/  124]
train() client id: f_00002-12-2 loss: 1.053042  [   96/  124]
train() client id: f_00003-0-0 loss: 0.754055  [   32/   43]
train() client id: f_00003-1-0 loss: 0.829942  [   32/   43]
train() client id: f_00003-2-0 loss: 0.735741  [   32/   43]
train() client id: f_00003-3-0 loss: 0.735385  [   32/   43]
train() client id: f_00003-4-0 loss: 0.528837  [   32/   43]
train() client id: f_00003-5-0 loss: 0.839155  [   32/   43]
train() client id: f_00003-6-0 loss: 0.750618  [   32/   43]
train() client id: f_00003-7-0 loss: 0.758528  [   32/   43]
train() client id: f_00003-8-0 loss: 0.743968  [   32/   43]
train() client id: f_00003-9-0 loss: 0.625050  [   32/   43]
train() client id: f_00003-10-0 loss: 0.752689  [   32/   43]
train() client id: f_00003-11-0 loss: 0.861126  [   32/   43]
train() client id: f_00003-12-0 loss: 0.697842  [   32/   43]
train() client id: f_00004-0-0 loss: 0.864972  [   32/  306]
train() client id: f_00004-0-1 loss: 0.687325  [   64/  306]
train() client id: f_00004-0-2 loss: 0.842442  [   96/  306]
train() client id: f_00004-0-3 loss: 0.661316  [  128/  306]
train() client id: f_00004-0-4 loss: 0.825342  [  160/  306]
train() client id: f_00004-0-5 loss: 0.851017  [  192/  306]
train() client id: f_00004-0-6 loss: 0.784612  [  224/  306]
train() client id: f_00004-0-7 loss: 0.985200  [  256/  306]
train() client id: f_00004-0-8 loss: 0.747392  [  288/  306]
train() client id: f_00004-1-0 loss: 0.885544  [   32/  306]
train() client id: f_00004-1-1 loss: 0.824357  [   64/  306]
train() client id: f_00004-1-2 loss: 0.900865  [   96/  306]
train() client id: f_00004-1-3 loss: 0.792866  [  128/  306]
train() client id: f_00004-1-4 loss: 0.785188  [  160/  306]
train() client id: f_00004-1-5 loss: 0.783827  [  192/  306]
train() client id: f_00004-1-6 loss: 0.873189  [  224/  306]
train() client id: f_00004-1-7 loss: 0.703674  [  256/  306]
train() client id: f_00004-1-8 loss: 0.776183  [  288/  306]
train() client id: f_00004-2-0 loss: 0.707671  [   32/  306]
train() client id: f_00004-2-1 loss: 0.774803  [   64/  306]
train() client id: f_00004-2-2 loss: 0.797144  [   96/  306]
train() client id: f_00004-2-3 loss: 0.812749  [  128/  306]
train() client id: f_00004-2-4 loss: 0.808746  [  160/  306]
train() client id: f_00004-2-5 loss: 0.936661  [  192/  306]
train() client id: f_00004-2-6 loss: 0.726982  [  224/  306]
train() client id: f_00004-2-7 loss: 0.836543  [  256/  306]
train() client id: f_00004-2-8 loss: 0.816017  [  288/  306]
train() client id: f_00004-3-0 loss: 0.837966  [   32/  306]
train() client id: f_00004-3-1 loss: 0.908485  [   64/  306]
train() client id: f_00004-3-2 loss: 0.822312  [   96/  306]
train() client id: f_00004-3-3 loss: 0.763375  [  128/  306]
train() client id: f_00004-3-4 loss: 0.766368  [  160/  306]
train() client id: f_00004-3-5 loss: 0.775443  [  192/  306]
train() client id: f_00004-3-6 loss: 0.742569  [  224/  306]
train() client id: f_00004-3-7 loss: 0.711690  [  256/  306]
train() client id: f_00004-3-8 loss: 0.880481  [  288/  306]
train() client id: f_00004-4-0 loss: 0.811304  [   32/  306]
train() client id: f_00004-4-1 loss: 0.800334  [   64/  306]
train() client id: f_00004-4-2 loss: 0.778218  [   96/  306]
train() client id: f_00004-4-3 loss: 0.728914  [  128/  306]
train() client id: f_00004-4-4 loss: 0.761283  [  160/  306]
train() client id: f_00004-4-5 loss: 0.802444  [  192/  306]
train() client id: f_00004-4-6 loss: 0.927207  [  224/  306]
train() client id: f_00004-4-7 loss: 0.799094  [  256/  306]
train() client id: f_00004-4-8 loss: 0.774710  [  288/  306]
train() client id: f_00004-5-0 loss: 0.762253  [   32/  306]
train() client id: f_00004-5-1 loss: 0.762308  [   64/  306]
train() client id: f_00004-5-2 loss: 0.832156  [   96/  306]
train() client id: f_00004-5-3 loss: 0.946314  [  128/  306]
train() client id: f_00004-5-4 loss: 0.630267  [  160/  306]
train() client id: f_00004-5-5 loss: 0.823058  [  192/  306]
train() client id: f_00004-5-6 loss: 0.809790  [  224/  306]
train() client id: f_00004-5-7 loss: 0.747712  [  256/  306]
train() client id: f_00004-5-8 loss: 0.794343  [  288/  306]
train() client id: f_00004-6-0 loss: 0.887685  [   32/  306]
train() client id: f_00004-6-1 loss: 0.840256  [   64/  306]
train() client id: f_00004-6-2 loss: 0.738439  [   96/  306]
train() client id: f_00004-6-3 loss: 0.698153  [  128/  306]
train() client id: f_00004-6-4 loss: 0.775789  [  160/  306]
train() client id: f_00004-6-5 loss: 0.704267  [  192/  306]
train() client id: f_00004-6-6 loss: 0.812407  [  224/  306]
train() client id: f_00004-6-7 loss: 0.822068  [  256/  306]
train() client id: f_00004-6-8 loss: 0.820388  [  288/  306]
train() client id: f_00004-7-0 loss: 0.707436  [   32/  306]
train() client id: f_00004-7-1 loss: 0.802988  [   64/  306]
train() client id: f_00004-7-2 loss: 0.760527  [   96/  306]
train() client id: f_00004-7-3 loss: 0.756701  [  128/  306]
train() client id: f_00004-7-4 loss: 0.908245  [  160/  306]
train() client id: f_00004-7-5 loss: 0.684038  [  192/  306]
train() client id: f_00004-7-6 loss: 0.914967  [  224/  306]
train() client id: f_00004-7-7 loss: 0.884236  [  256/  306]
train() client id: f_00004-7-8 loss: 0.810232  [  288/  306]
train() client id: f_00004-8-0 loss: 0.730796  [   32/  306]
train() client id: f_00004-8-1 loss: 0.744561  [   64/  306]
train() client id: f_00004-8-2 loss: 0.786407  [   96/  306]
train() client id: f_00004-8-3 loss: 0.841480  [  128/  306]
train() client id: f_00004-8-4 loss: 0.796568  [  160/  306]
train() client id: f_00004-8-5 loss: 0.842468  [  192/  306]
train() client id: f_00004-8-6 loss: 0.855845  [  224/  306]
train() client id: f_00004-8-7 loss: 0.750867  [  256/  306]
train() client id: f_00004-8-8 loss: 0.748657  [  288/  306]
train() client id: f_00004-9-0 loss: 0.636691  [   32/  306]
train() client id: f_00004-9-1 loss: 0.691003  [   64/  306]
train() client id: f_00004-9-2 loss: 0.885031  [   96/  306]
train() client id: f_00004-9-3 loss: 0.742959  [  128/  306]
train() client id: f_00004-9-4 loss: 0.855268  [  160/  306]
train() client id: f_00004-9-5 loss: 0.932634  [  192/  306]
train() client id: f_00004-9-6 loss: 0.853009  [  224/  306]
train() client id: f_00004-9-7 loss: 0.826524  [  256/  306]
train() client id: f_00004-9-8 loss: 0.754246  [  288/  306]
train() client id: f_00004-10-0 loss: 0.808279  [   32/  306]
train() client id: f_00004-10-1 loss: 0.766693  [   64/  306]
train() client id: f_00004-10-2 loss: 0.819787  [   96/  306]
train() client id: f_00004-10-3 loss: 0.849062  [  128/  306]
train() client id: f_00004-10-4 loss: 0.761011  [  160/  306]
train() client id: f_00004-10-5 loss: 0.988440  [  192/  306]
train() client id: f_00004-10-6 loss: 0.662347  [  224/  306]
train() client id: f_00004-10-7 loss: 0.756094  [  256/  306]
train() client id: f_00004-10-8 loss: 0.795683  [  288/  306]
train() client id: f_00004-11-0 loss: 0.823351  [   32/  306]
train() client id: f_00004-11-1 loss: 0.804907  [   64/  306]
train() client id: f_00004-11-2 loss: 0.904784  [   96/  306]
train() client id: f_00004-11-3 loss: 0.807398  [  128/  306]
train() client id: f_00004-11-4 loss: 0.810896  [  160/  306]
train() client id: f_00004-11-5 loss: 0.820314  [  192/  306]
train() client id: f_00004-11-6 loss: 0.660694  [  224/  306]
train() client id: f_00004-11-7 loss: 0.697181  [  256/  306]
train() client id: f_00004-11-8 loss: 0.880033  [  288/  306]
train() client id: f_00004-12-0 loss: 0.900659  [   32/  306]
train() client id: f_00004-12-1 loss: 0.868169  [   64/  306]
train() client id: f_00004-12-2 loss: 0.659084  [   96/  306]
train() client id: f_00004-12-3 loss: 0.710751  [  128/  306]
train() client id: f_00004-12-4 loss: 0.744079  [  160/  306]
train() client id: f_00004-12-5 loss: 0.778889  [  192/  306]
train() client id: f_00004-12-6 loss: 0.774984  [  224/  306]
train() client id: f_00004-12-7 loss: 0.906748  [  256/  306]
train() client id: f_00004-12-8 loss: 0.817584  [  288/  306]
train() client id: f_00005-0-0 loss: 0.833108  [   32/  146]
train() client id: f_00005-0-1 loss: 0.726614  [   64/  146]
train() client id: f_00005-0-2 loss: 0.731578  [   96/  146]
train() client id: f_00005-0-3 loss: 0.715061  [  128/  146]
train() client id: f_00005-1-0 loss: 0.766885  [   32/  146]
train() client id: f_00005-1-1 loss: 0.722489  [   64/  146]
train() client id: f_00005-1-2 loss: 0.732642  [   96/  146]
train() client id: f_00005-1-3 loss: 0.835723  [  128/  146]
train() client id: f_00005-2-0 loss: 0.592502  [   32/  146]
train() client id: f_00005-2-1 loss: 0.703883  [   64/  146]
train() client id: f_00005-2-2 loss: 0.924152  [   96/  146]
train() client id: f_00005-2-3 loss: 0.596802  [  128/  146]
train() client id: f_00005-3-0 loss: 0.742378  [   32/  146]
train() client id: f_00005-3-1 loss: 0.698030  [   64/  146]
train() client id: f_00005-3-2 loss: 0.755874  [   96/  146]
train() client id: f_00005-3-3 loss: 0.745058  [  128/  146]
train() client id: f_00005-4-0 loss: 0.734718  [   32/  146]
train() client id: f_00005-4-1 loss: 0.751066  [   64/  146]
train() client id: f_00005-4-2 loss: 0.926669  [   96/  146]
train() client id: f_00005-4-3 loss: 0.797651  [  128/  146]
train() client id: f_00005-5-0 loss: 0.504885  [   32/  146]
train() client id: f_00005-5-1 loss: 0.713163  [   64/  146]
train() client id: f_00005-5-2 loss: 0.828797  [   96/  146]
train() client id: f_00005-5-3 loss: 0.911023  [  128/  146]
train() client id: f_00005-6-0 loss: 0.625836  [   32/  146]
train() client id: f_00005-6-1 loss: 0.693619  [   64/  146]
train() client id: f_00005-6-2 loss: 0.922819  [   96/  146]
train() client id: f_00005-6-3 loss: 0.790187  [  128/  146]
train() client id: f_00005-7-0 loss: 0.672716  [   32/  146]
train() client id: f_00005-7-1 loss: 0.693780  [   64/  146]
train() client id: f_00005-7-2 loss: 0.906187  [   96/  146]
train() client id: f_00005-7-3 loss: 0.578940  [  128/  146]
train() client id: f_00005-8-0 loss: 0.687710  [   32/  146]
train() client id: f_00005-8-1 loss: 0.821512  [   64/  146]
train() client id: f_00005-8-2 loss: 0.680197  [   96/  146]
train() client id: f_00005-8-3 loss: 0.800906  [  128/  146]
train() client id: f_00005-9-0 loss: 1.040593  [   32/  146]
train() client id: f_00005-9-1 loss: 0.849914  [   64/  146]
train() client id: f_00005-9-2 loss: 0.488524  [   96/  146]
train() client id: f_00005-9-3 loss: 0.731259  [  128/  146]
train() client id: f_00005-10-0 loss: 0.891112  [   32/  146]
train() client id: f_00005-10-1 loss: 0.740253  [   64/  146]
train() client id: f_00005-10-2 loss: 0.702804  [   96/  146]
train() client id: f_00005-10-3 loss: 0.770269  [  128/  146]
train() client id: f_00005-11-0 loss: 0.758504  [   32/  146]
train() client id: f_00005-11-1 loss: 0.446780  [   64/  146]
train() client id: f_00005-11-2 loss: 0.940253  [   96/  146]
train() client id: f_00005-11-3 loss: 0.900309  [  128/  146]
train() client id: f_00005-12-0 loss: 0.891049  [   32/  146]
train() client id: f_00005-12-1 loss: 0.601349  [   64/  146]
train() client id: f_00005-12-2 loss: 0.775741  [   96/  146]
train() client id: f_00005-12-3 loss: 0.676050  [  128/  146]
train() client id: f_00006-0-0 loss: 0.444569  [   32/   54]
train() client id: f_00006-1-0 loss: 0.430324  [   32/   54]
train() client id: f_00006-2-0 loss: 0.389361  [   32/   54]
train() client id: f_00006-3-0 loss: 0.495180  [   32/   54]
train() client id: f_00006-4-0 loss: 0.430727  [   32/   54]
train() client id: f_00006-5-0 loss: 0.497405  [   32/   54]
train() client id: f_00006-6-0 loss: 0.485431  [   32/   54]
train() client id: f_00006-7-0 loss: 0.449894  [   32/   54]
train() client id: f_00006-8-0 loss: 0.436271  [   32/   54]
train() client id: f_00006-9-0 loss: 0.470126  [   32/   54]
train() client id: f_00006-10-0 loss: 0.436695  [   32/   54]
train() client id: f_00006-11-0 loss: 0.386565  [   32/   54]
train() client id: f_00006-12-0 loss: 0.436950  [   32/   54]
train() client id: f_00007-0-0 loss: 0.460407  [   32/  179]
train() client id: f_00007-0-1 loss: 0.802644  [   64/  179]
train() client id: f_00007-0-2 loss: 0.357377  [   96/  179]
train() client id: f_00007-0-3 loss: 0.412821  [  128/  179]
train() client id: f_00007-0-4 loss: 0.414836  [  160/  179]
train() client id: f_00007-1-0 loss: 0.459922  [   32/  179]
train() client id: f_00007-1-1 loss: 0.473688  [   64/  179]
train() client id: f_00007-1-2 loss: 0.584884  [   96/  179]
train() client id: f_00007-1-3 loss: 0.304161  [  128/  179]
train() client id: f_00007-1-4 loss: 0.566971  [  160/  179]
train() client id: f_00007-2-0 loss: 0.741445  [   32/  179]
train() client id: f_00007-2-1 loss: 0.442661  [   64/  179]
train() client id: f_00007-2-2 loss: 0.353576  [   96/  179]
train() client id: f_00007-2-3 loss: 0.391583  [  128/  179]
train() client id: f_00007-2-4 loss: 0.378532  [  160/  179]
train() client id: f_00007-3-0 loss: 0.291957  [   32/  179]
train() client id: f_00007-3-1 loss: 0.319758  [   64/  179]
train() client id: f_00007-3-2 loss: 0.506813  [   96/  179]
train() client id: f_00007-3-3 loss: 0.445367  [  128/  179]
train() client id: f_00007-3-4 loss: 0.622395  [  160/  179]
train() client id: f_00007-4-0 loss: 0.528075  [   32/  179]
train() client id: f_00007-4-1 loss: 0.384361  [   64/  179]
train() client id: f_00007-4-2 loss: 0.446596  [   96/  179]
train() client id: f_00007-4-3 loss: 0.366796  [  128/  179]
train() client id: f_00007-4-4 loss: 0.510692  [  160/  179]
train() client id: f_00007-5-0 loss: 0.261851  [   32/  179]
train() client id: f_00007-5-1 loss: 0.479747  [   64/  179]
train() client id: f_00007-5-2 loss: 0.403740  [   96/  179]
train() client id: f_00007-5-3 loss: 0.582576  [  128/  179]
train() client id: f_00007-5-4 loss: 0.384801  [  160/  179]
train() client id: f_00007-6-0 loss: 0.313640  [   32/  179]
train() client id: f_00007-6-1 loss: 0.269920  [   64/  179]
train() client id: f_00007-6-2 loss: 0.395007  [   96/  179]
train() client id: f_00007-6-3 loss: 0.744351  [  128/  179]
train() client id: f_00007-6-4 loss: 0.546629  [  160/  179]
train() client id: f_00007-7-0 loss: 0.492553  [   32/  179]
train() client id: f_00007-7-1 loss: 0.576462  [   64/  179]
train() client id: f_00007-7-2 loss: 0.358985  [   96/  179]
train() client id: f_00007-7-3 loss: 0.364353  [  128/  179]
train() client id: f_00007-7-4 loss: 0.349966  [  160/  179]
train() client id: f_00007-8-0 loss: 0.372127  [   32/  179]
train() client id: f_00007-8-1 loss: 0.424290  [   64/  179]
train() client id: f_00007-8-2 loss: 0.504538  [   96/  179]
train() client id: f_00007-8-3 loss: 0.508594  [  128/  179]
train() client id: f_00007-8-4 loss: 0.439381  [  160/  179]
train() client id: f_00007-9-0 loss: 0.616554  [   32/  179]
train() client id: f_00007-9-1 loss: 0.412994  [   64/  179]
train() client id: f_00007-9-2 loss: 0.288662  [   96/  179]
train() client id: f_00007-9-3 loss: 0.552728  [  128/  179]
train() client id: f_00007-9-4 loss: 0.264456  [  160/  179]
train() client id: f_00007-10-0 loss: 0.375859  [   32/  179]
train() client id: f_00007-10-1 loss: 0.356168  [   64/  179]
train() client id: f_00007-10-2 loss: 0.456809  [   96/  179]
train() client id: f_00007-10-3 loss: 0.497244  [  128/  179]
train() client id: f_00007-10-4 loss: 0.334486  [  160/  179]
train() client id: f_00007-11-0 loss: 0.370904  [   32/  179]
train() client id: f_00007-11-1 loss: 0.417097  [   64/  179]
train() client id: f_00007-11-2 loss: 0.637879  [   96/  179]
train() client id: f_00007-11-3 loss: 0.343290  [  128/  179]
train() client id: f_00007-11-4 loss: 0.308639  [  160/  179]
train() client id: f_00007-12-0 loss: 0.380823  [   32/  179]
train() client id: f_00007-12-1 loss: 0.446355  [   64/  179]
train() client id: f_00007-12-2 loss: 0.445292  [   96/  179]
train() client id: f_00007-12-3 loss: 0.384619  [  128/  179]
train() client id: f_00007-12-4 loss: 0.537879  [  160/  179]
train() client id: f_00008-0-0 loss: 0.745932  [   32/  130]
train() client id: f_00008-0-1 loss: 0.787830  [   64/  130]
train() client id: f_00008-0-2 loss: 0.751827  [   96/  130]
train() client id: f_00008-0-3 loss: 0.800466  [  128/  130]
train() client id: f_00008-1-0 loss: 0.903658  [   32/  130]
train() client id: f_00008-1-1 loss: 0.737353  [   64/  130]
train() client id: f_00008-1-2 loss: 0.753400  [   96/  130]
train() client id: f_00008-1-3 loss: 0.702810  [  128/  130]
train() client id: f_00008-2-0 loss: 0.857316  [   32/  130]
train() client id: f_00008-2-1 loss: 0.907780  [   64/  130]
train() client id: f_00008-2-2 loss: 0.632105  [   96/  130]
train() client id: f_00008-2-3 loss: 0.705930  [  128/  130]
train() client id: f_00008-3-0 loss: 0.768607  [   32/  130]
train() client id: f_00008-3-1 loss: 0.761279  [   64/  130]
train() client id: f_00008-3-2 loss: 0.762012  [   96/  130]
train() client id: f_00008-3-3 loss: 0.813814  [  128/  130]
train() client id: f_00008-4-0 loss: 0.670446  [   32/  130]
train() client id: f_00008-4-1 loss: 0.845411  [   64/  130]
train() client id: f_00008-4-2 loss: 0.797963  [   96/  130]
train() client id: f_00008-4-3 loss: 0.780214  [  128/  130]
train() client id: f_00008-5-0 loss: 0.809539  [   32/  130]
train() client id: f_00008-5-1 loss: 0.785497  [   64/  130]
train() client id: f_00008-5-2 loss: 0.731451  [   96/  130]
train() client id: f_00008-5-3 loss: 0.770042  [  128/  130]
train() client id: f_00008-6-0 loss: 0.789165  [   32/  130]
train() client id: f_00008-6-1 loss: 0.722534  [   64/  130]
train() client id: f_00008-6-2 loss: 0.778478  [   96/  130]
train() client id: f_00008-6-3 loss: 0.803669  [  128/  130]
train() client id: f_00008-7-0 loss: 0.819082  [   32/  130]
train() client id: f_00008-7-1 loss: 0.704649  [   64/  130]
train() client id: f_00008-7-2 loss: 0.665145  [   96/  130]
train() client id: f_00008-7-3 loss: 0.878628  [  128/  130]
train() client id: f_00008-8-0 loss: 0.751482  [   32/  130]
train() client id: f_00008-8-1 loss: 0.897559  [   64/  130]
train() client id: f_00008-8-2 loss: 0.799450  [   96/  130]
train() client id: f_00008-8-3 loss: 0.648324  [  128/  130]
train() client id: f_00008-9-0 loss: 0.743640  [   32/  130]
train() client id: f_00008-9-1 loss: 0.782432  [   64/  130]
train() client id: f_00008-9-2 loss: 0.767245  [   96/  130]
train() client id: f_00008-9-3 loss: 0.756337  [  128/  130]
train() client id: f_00008-10-0 loss: 0.943218  [   32/  130]
train() client id: f_00008-10-1 loss: 0.661570  [   64/  130]
train() client id: f_00008-10-2 loss: 0.791678  [   96/  130]
train() client id: f_00008-10-3 loss: 0.669670  [  128/  130]
train() client id: f_00008-11-0 loss: 0.785012  [   32/  130]
train() client id: f_00008-11-1 loss: 0.755299  [   64/  130]
train() client id: f_00008-11-2 loss: 0.802029  [   96/  130]
train() client id: f_00008-11-3 loss: 0.744028  [  128/  130]
train() client id: f_00008-12-0 loss: 0.764301  [   32/  130]
train() client id: f_00008-12-1 loss: 0.654150  [   64/  130]
train() client id: f_00008-12-2 loss: 0.857472  [   96/  130]
train() client id: f_00008-12-3 loss: 0.817064  [  128/  130]
train() client id: f_00009-0-0 loss: 1.210398  [   32/  118]
train() client id: f_00009-0-1 loss: 1.094988  [   64/  118]
train() client id: f_00009-0-2 loss: 1.313664  [   96/  118]
train() client id: f_00009-1-0 loss: 1.099067  [   32/  118]
train() client id: f_00009-1-1 loss: 1.049691  [   64/  118]
train() client id: f_00009-1-2 loss: 1.239016  [   96/  118]
train() client id: f_00009-2-0 loss: 1.044331  [   32/  118]
train() client id: f_00009-2-1 loss: 1.245486  [   64/  118]
train() client id: f_00009-2-2 loss: 1.065809  [   96/  118]
train() client id: f_00009-3-0 loss: 1.058693  [   32/  118]
train() client id: f_00009-3-1 loss: 1.048182  [   64/  118]
train() client id: f_00009-3-2 loss: 0.891976  [   96/  118]
train() client id: f_00009-4-0 loss: 0.950591  [   32/  118]
train() client id: f_00009-4-1 loss: 1.033119  [   64/  118]
train() client id: f_00009-4-2 loss: 0.910592  [   96/  118]
train() client id: f_00009-5-0 loss: 1.114430  [   32/  118]
train() client id: f_00009-5-1 loss: 0.843255  [   64/  118]
train() client id: f_00009-5-2 loss: 0.954942  [   96/  118]
train() client id: f_00009-6-0 loss: 0.956472  [   32/  118]
train() client id: f_00009-6-1 loss: 1.113008  [   64/  118]
train() client id: f_00009-6-2 loss: 0.830190  [   96/  118]
train() client id: f_00009-7-0 loss: 0.865318  [   32/  118]
train() client id: f_00009-7-1 loss: 0.962848  [   64/  118]
train() client id: f_00009-7-2 loss: 0.849801  [   96/  118]
train() client id: f_00009-8-0 loss: 0.962391  [   32/  118]
train() client id: f_00009-8-1 loss: 0.902255  [   64/  118]
train() client id: f_00009-8-2 loss: 0.985104  [   96/  118]
train() client id: f_00009-9-0 loss: 0.859243  [   32/  118]
train() client id: f_00009-9-1 loss: 0.838216  [   64/  118]
train() client id: f_00009-9-2 loss: 0.938026  [   96/  118]
train() client id: f_00009-10-0 loss: 0.819756  [   32/  118]
train() client id: f_00009-10-1 loss: 0.959938  [   64/  118]
train() client id: f_00009-10-2 loss: 1.008703  [   96/  118]
train() client id: f_00009-11-0 loss: 0.782043  [   32/  118]
train() client id: f_00009-11-1 loss: 1.022568  [   64/  118]
train() client id: f_00009-11-2 loss: 0.839072  [   96/  118]
train() client id: f_00009-12-0 loss: 0.967234  [   32/  118]
train() client id: f_00009-12-1 loss: 0.768164  [   64/  118]
train() client id: f_00009-12-2 loss: 0.932869  [   96/  118]
At round 42 accuracy: 0.6445623342175066
At round 42 training accuracy: 0.5902079141515761
At round 42 training loss: 0.8313722041735987
gradient difference: 0.3924322724342346
train() client id: f_00000-0-0 loss: 1.316433  [   32/  126]
train() client id: f_00000-0-1 loss: 1.037432  [   64/  126]
train() client id: f_00000-0-2 loss: 1.086805  [   96/  126]
train() client id: f_00000-1-0 loss: 1.181697  [   32/  126]
train() client id: f_00000-1-1 loss: 1.155039  [   64/  126]
train() client id: f_00000-1-2 loss: 1.088091  [   96/  126]
train() client id: f_00000-2-0 loss: 0.955797  [   32/  126]
train() client id: f_00000-2-1 loss: 0.941273  [   64/  126]
train() client id: f_00000-2-2 loss: 1.099251  [   96/  126]
train() client id: f_00000-3-0 loss: 0.824396  [   32/  126]
train() client id: f_00000-3-1 loss: 0.905965  [   64/  126]
train() client id: f_00000-3-2 loss: 1.041197  [   96/  126]
train() client id: f_00000-4-0 loss: 0.931994  [   32/  126]
train() client id: f_00000-4-1 loss: 0.891519  [   64/  126]
train() client id: f_00000-4-2 loss: 0.824126  [   96/  126]
train() client id: f_00000-5-0 loss: 0.712019  [   32/  126]
train() client id: f_00000-5-1 loss: 0.955165  [   64/  126]
train() client id: f_00000-5-2 loss: 0.782242  [   96/  126]
train() client id: f_00000-6-0 loss: 0.904361  [   32/  126]
train() client id: f_00000-6-1 loss: 0.685336  [   64/  126]
train() client id: f_00000-6-2 loss: 0.780468  [   96/  126]
train() client id: f_00000-7-0 loss: 0.740707  [   32/  126]
train() client id: f_00000-7-1 loss: 0.736558  [   64/  126]
train() client id: f_00000-7-2 loss: 0.877756  [   96/  126]
train() client id: f_00000-8-0 loss: 0.760261  [   32/  126]
train() client id: f_00000-8-1 loss: 0.723809  [   64/  126]
train() client id: f_00000-8-2 loss: 0.792412  [   96/  126]
train() client id: f_00000-9-0 loss: 0.762337  [   32/  126]
train() client id: f_00000-9-1 loss: 0.809555  [   64/  126]
train() client id: f_00000-9-2 loss: 0.763261  [   96/  126]
train() client id: f_00000-10-0 loss: 0.587906  [   32/  126]
train() client id: f_00000-10-1 loss: 0.763351  [   64/  126]
train() client id: f_00000-10-2 loss: 0.784953  [   96/  126]
train() client id: f_00000-11-0 loss: 0.663244  [   32/  126]
train() client id: f_00000-11-1 loss: 0.801445  [   64/  126]
train() client id: f_00000-11-2 loss: 0.694900  [   96/  126]
train() client id: f_00000-12-0 loss: 0.730280  [   32/  126]
train() client id: f_00000-12-1 loss: 0.778783  [   64/  126]
train() client id: f_00000-12-2 loss: 0.765457  [   96/  126]
train() client id: f_00001-0-0 loss: 0.518578  [   32/  265]
train() client id: f_00001-0-1 loss: 0.386771  [   64/  265]
train() client id: f_00001-0-2 loss: 0.449524  [   96/  265]
train() client id: f_00001-0-3 loss: 0.582302  [  128/  265]
train() client id: f_00001-0-4 loss: 0.433337  [  160/  265]
train() client id: f_00001-0-5 loss: 0.489673  [  192/  265]
train() client id: f_00001-0-6 loss: 0.376570  [  224/  265]
train() client id: f_00001-0-7 loss: 0.433060  [  256/  265]
train() client id: f_00001-1-0 loss: 0.460321  [   32/  265]
train() client id: f_00001-1-1 loss: 0.357065  [   64/  265]
train() client id: f_00001-1-2 loss: 0.359352  [   96/  265]
train() client id: f_00001-1-3 loss: 0.403904  [  128/  265]
train() client id: f_00001-1-4 loss: 0.529825  [  160/  265]
train() client id: f_00001-1-5 loss: 0.649851  [  192/  265]
train() client id: f_00001-1-6 loss: 0.444826  [  224/  265]
train() client id: f_00001-1-7 loss: 0.395553  [  256/  265]
train() client id: f_00001-2-0 loss: 0.518722  [   32/  265]
train() client id: f_00001-2-1 loss: 0.356517  [   64/  265]
train() client id: f_00001-2-2 loss: 0.518261  [   96/  265]
train() client id: f_00001-2-3 loss: 0.497320  [  128/  265]
train() client id: f_00001-2-4 loss: 0.348065  [  160/  265]
train() client id: f_00001-2-5 loss: 0.425847  [  192/  265]
train() client id: f_00001-2-6 loss: 0.455914  [  224/  265]
train() client id: f_00001-2-7 loss: 0.358545  [  256/  265]
train() client id: f_00001-3-0 loss: 0.509118  [   32/  265]
train() client id: f_00001-3-1 loss: 0.431927  [   64/  265]
train() client id: f_00001-3-2 loss: 0.372098  [   96/  265]
train() client id: f_00001-3-3 loss: 0.436982  [  128/  265]
train() client id: f_00001-3-4 loss: 0.351379  [  160/  265]
train() client id: f_00001-3-5 loss: 0.434386  [  192/  265]
train() client id: f_00001-3-6 loss: 0.510663  [  224/  265]
train() client id: f_00001-3-7 loss: 0.494490  [  256/  265]
train() client id: f_00001-4-0 loss: 0.478018  [   32/  265]
train() client id: f_00001-4-1 loss: 0.424373  [   64/  265]
train() client id: f_00001-4-2 loss: 0.555264  [   96/  265]
train() client id: f_00001-4-3 loss: 0.340090  [  128/  265]
train() client id: f_00001-4-4 loss: 0.481163  [  160/  265]
train() client id: f_00001-4-5 loss: 0.434389  [  192/  265]
train() client id: f_00001-4-6 loss: 0.408018  [  224/  265]
train() client id: f_00001-4-7 loss: 0.345762  [  256/  265]
train() client id: f_00001-5-0 loss: 0.359443  [   32/  265]
train() client id: f_00001-5-1 loss: 0.470750  [   64/  265]
train() client id: f_00001-5-2 loss: 0.387431  [   96/  265]
train() client id: f_00001-5-3 loss: 0.520113  [  128/  265]
train() client id: f_00001-5-4 loss: 0.480142  [  160/  265]
train() client id: f_00001-5-5 loss: 0.343210  [  192/  265]
train() client id: f_00001-5-6 loss: 0.368763  [  224/  265]
train() client id: f_00001-5-7 loss: 0.508623  [  256/  265]
train() client id: f_00001-6-0 loss: 0.350834  [   32/  265]
train() client id: f_00001-6-1 loss: 0.396593  [   64/  265]
train() client id: f_00001-6-2 loss: 0.412230  [   96/  265]
train() client id: f_00001-6-3 loss: 0.487286  [  128/  265]
train() client id: f_00001-6-4 loss: 0.479230  [  160/  265]
train() client id: f_00001-6-5 loss: 0.456469  [  192/  265]
train() client id: f_00001-6-6 loss: 0.448605  [  224/  265]
train() client id: f_00001-6-7 loss: 0.443558  [  256/  265]
train() client id: f_00001-7-0 loss: 0.475831  [   32/  265]
train() client id: f_00001-7-1 loss: 0.481002  [   64/  265]
train() client id: f_00001-7-2 loss: 0.418677  [   96/  265]
train() client id: f_00001-7-3 loss: 0.397426  [  128/  265]
train() client id: f_00001-7-4 loss: 0.508722  [  160/  265]
train() client id: f_00001-7-5 loss: 0.415856  [  192/  265]
train() client id: f_00001-7-6 loss: 0.359383  [  224/  265]
train() client id: f_00001-7-7 loss: 0.419202  [  256/  265]
train() client id: f_00001-8-0 loss: 0.426502  [   32/  265]
train() client id: f_00001-8-1 loss: 0.393164  [   64/  265]
train() client id: f_00001-8-2 loss: 0.553325  [   96/  265]
train() client id: f_00001-8-3 loss: 0.432446  [  128/  265]
train() client id: f_00001-8-4 loss: 0.501135  [  160/  265]
train() client id: f_00001-8-5 loss: 0.450011  [  192/  265]
train() client id: f_00001-8-6 loss: 0.394563  [  224/  265]
train() client id: f_00001-8-7 loss: 0.320622  [  256/  265]
train() client id: f_00001-9-0 loss: 0.347672  [   32/  265]
train() client id: f_00001-9-1 loss: 0.451382  [   64/  265]
train() client id: f_00001-9-2 loss: 0.351394  [   96/  265]
train() client id: f_00001-9-3 loss: 0.488499  [  128/  265]
train() client id: f_00001-9-4 loss: 0.493760  [  160/  265]
train() client id: f_00001-9-5 loss: 0.434394  [  192/  265]
train() client id: f_00001-9-6 loss: 0.435050  [  224/  265]
train() client id: f_00001-9-7 loss: 0.484441  [  256/  265]
train() client id: f_00001-10-0 loss: 0.409842  [   32/  265]
train() client id: f_00001-10-1 loss: 0.455274  [   64/  265]
train() client id: f_00001-10-2 loss: 0.395810  [   96/  265]
train() client id: f_00001-10-3 loss: 0.430121  [  128/  265]
train() client id: f_00001-10-4 loss: 0.460279  [  160/  265]
train() client id: f_00001-10-5 loss: 0.541045  [  192/  265]
train() client id: f_00001-10-6 loss: 0.350432  [  224/  265]
train() client id: f_00001-10-7 loss: 0.425660  [  256/  265]
train() client id: f_00001-11-0 loss: 0.363786  [   32/  265]
train() client id: f_00001-11-1 loss: 0.429566  [   64/  265]
train() client id: f_00001-11-2 loss: 0.378328  [   96/  265]
train() client id: f_00001-11-3 loss: 0.499232  [  128/  265]
train() client id: f_00001-11-4 loss: 0.408671  [  160/  265]
train() client id: f_00001-11-5 loss: 0.525589  [  192/  265]
train() client id: f_00001-11-6 loss: 0.358119  [  224/  265]
train() client id: f_00001-11-7 loss: 0.510125  [  256/  265]
train() client id: f_00001-12-0 loss: 0.340258  [   32/  265]
train() client id: f_00001-12-1 loss: 0.388142  [   64/  265]
train() client id: f_00001-12-2 loss: 0.388015  [   96/  265]
train() client id: f_00001-12-3 loss: 0.407398  [  128/  265]
train() client id: f_00001-12-4 loss: 0.363065  [  160/  265]
train() client id: f_00001-12-5 loss: 0.645263  [  192/  265]
train() client id: f_00001-12-6 loss: 0.479987  [  224/  265]
train() client id: f_00001-12-7 loss: 0.472131  [  256/  265]
train() client id: f_00002-0-0 loss: 1.245360  [   32/  124]
train() client id: f_00002-0-1 loss: 1.201911  [   64/  124]
train() client id: f_00002-0-2 loss: 1.132761  [   96/  124]
train() client id: f_00002-1-0 loss: 1.096368  [   32/  124]
train() client id: f_00002-1-1 loss: 0.957777  [   64/  124]
train() client id: f_00002-1-2 loss: 1.078347  [   96/  124]
train() client id: f_00002-2-0 loss: 1.177294  [   32/  124]
train() client id: f_00002-2-1 loss: 1.074557  [   64/  124]
train() client id: f_00002-2-2 loss: 0.899379  [   96/  124]
train() client id: f_00002-3-0 loss: 0.997610  [   32/  124]
train() client id: f_00002-3-1 loss: 0.941125  [   64/  124]
train() client id: f_00002-3-2 loss: 1.003020  [   96/  124]
train() client id: f_00002-4-0 loss: 1.032688  [   32/  124]
train() client id: f_00002-4-1 loss: 1.010624  [   64/  124]
train() client id: f_00002-4-2 loss: 0.915897  [   96/  124]
train() client id: f_00002-5-0 loss: 0.801992  [   32/  124]
train() client id: f_00002-5-1 loss: 0.879613  [   64/  124]
train() client id: f_00002-5-2 loss: 1.132879  [   96/  124]
train() client id: f_00002-6-0 loss: 0.967006  [   32/  124]
train() client id: f_00002-6-1 loss: 1.010970  [   64/  124]
train() client id: f_00002-6-2 loss: 0.900171  [   96/  124]
train() client id: f_00002-7-0 loss: 1.103600  [   32/  124]
train() client id: f_00002-7-1 loss: 0.791448  [   64/  124]
train() client id: f_00002-7-2 loss: 0.933167  [   96/  124]
train() client id: f_00002-8-0 loss: 0.910857  [   32/  124]
train() client id: f_00002-8-1 loss: 0.674606  [   64/  124]
train() client id: f_00002-8-2 loss: 1.024663  [   96/  124]
train() client id: f_00002-9-0 loss: 0.874554  [   32/  124]
train() client id: f_00002-9-1 loss: 0.850834  [   64/  124]
train() client id: f_00002-9-2 loss: 0.947223  [   96/  124]
train() client id: f_00002-10-0 loss: 0.925713  [   32/  124]
train() client id: f_00002-10-1 loss: 0.900939  [   64/  124]
train() client id: f_00002-10-2 loss: 0.807383  [   96/  124]
train() client id: f_00002-11-0 loss: 0.791432  [   32/  124]
train() client id: f_00002-11-1 loss: 0.955162  [   64/  124]
train() client id: f_00002-11-2 loss: 0.886624  [   96/  124]
train() client id: f_00002-12-0 loss: 0.839724  [   32/  124]
train() client id: f_00002-12-1 loss: 0.833740  [   64/  124]
train() client id: f_00002-12-2 loss: 0.853446  [   96/  124]
train() client id: f_00003-0-0 loss: 0.767840  [   32/   43]
train() client id: f_00003-1-0 loss: 0.629032  [   32/   43]
train() client id: f_00003-2-0 loss: 0.534931  [   32/   43]
train() client id: f_00003-3-0 loss: 0.618097  [   32/   43]
train() client id: f_00003-4-0 loss: 0.406076  [   32/   43]
train() client id: f_00003-5-0 loss: 0.682132  [   32/   43]
train() client id: f_00003-6-0 loss: 0.659939  [   32/   43]
train() client id: f_00003-7-0 loss: 0.441844  [   32/   43]
train() client id: f_00003-8-0 loss: 0.528671  [   32/   43]
train() client id: f_00003-9-0 loss: 0.522373  [   32/   43]
train() client id: f_00003-10-0 loss: 0.601471  [   32/   43]
train() client id: f_00003-11-0 loss: 0.452546  [   32/   43]
train() client id: f_00003-12-0 loss: 0.503495  [   32/   43]
train() client id: f_00004-0-0 loss: 0.926635  [   32/  306]
train() client id: f_00004-0-1 loss: 0.801152  [   64/  306]
train() client id: f_00004-0-2 loss: 0.723494  [   96/  306]
train() client id: f_00004-0-3 loss: 0.884218  [  128/  306]
train() client id: f_00004-0-4 loss: 0.860555  [  160/  306]
train() client id: f_00004-0-5 loss: 0.839385  [  192/  306]
train() client id: f_00004-0-6 loss: 0.756665  [  224/  306]
train() client id: f_00004-0-7 loss: 0.756988  [  256/  306]
train() client id: f_00004-0-8 loss: 0.908378  [  288/  306]
train() client id: f_00004-1-0 loss: 0.708218  [   32/  306]
train() client id: f_00004-1-1 loss: 0.789066  [   64/  306]
train() client id: f_00004-1-2 loss: 0.832808  [   96/  306]
train() client id: f_00004-1-3 loss: 0.755038  [  128/  306]
train() client id: f_00004-1-4 loss: 0.838464  [  160/  306]
train() client id: f_00004-1-5 loss: 0.972744  [  192/  306]
train() client id: f_00004-1-6 loss: 0.765079  [  224/  306]
train() client id: f_00004-1-7 loss: 0.959794  [  256/  306]
train() client id: f_00004-1-8 loss: 0.847074  [  288/  306]
train() client id: f_00004-2-0 loss: 0.868635  [   32/  306]
train() client id: f_00004-2-1 loss: 0.734273  [   64/  306]
train() client id: f_00004-2-2 loss: 0.813044  [   96/  306]
train() client id: f_00004-2-3 loss: 0.943839  [  128/  306]
train() client id: f_00004-2-4 loss: 0.810287  [  160/  306]
train() client id: f_00004-2-5 loss: 0.909292  [  192/  306]
train() client id: f_00004-2-6 loss: 0.798567  [  224/  306]
train() client id: f_00004-2-7 loss: 0.743973  [  256/  306]
train() client id: f_00004-2-8 loss: 0.816165  [  288/  306]
train() client id: f_00004-3-0 loss: 0.847247  [   32/  306]
train() client id: f_00004-3-1 loss: 0.779848  [   64/  306]
train() client id: f_00004-3-2 loss: 0.868508  [   96/  306]
train() client id: f_00004-3-3 loss: 0.923667  [  128/  306]
train() client id: f_00004-3-4 loss: 0.832010  [  160/  306]
train() client id: f_00004-3-5 loss: 0.879346  [  192/  306]
train() client id: f_00004-3-6 loss: 0.863646  [  224/  306]
train() client id: f_00004-3-7 loss: 0.750309  [  256/  306]
train() client id: f_00004-3-8 loss: 0.802628  [  288/  306]
train() client id: f_00004-4-0 loss: 0.824399  [   32/  306]
train() client id: f_00004-4-1 loss: 0.830519  [   64/  306]
train() client id: f_00004-4-2 loss: 0.817484  [   96/  306]
train() client id: f_00004-4-3 loss: 0.915961  [  128/  306]
train() client id: f_00004-4-4 loss: 0.756266  [  160/  306]
train() client id: f_00004-4-5 loss: 0.853150  [  192/  306]
train() client id: f_00004-4-6 loss: 0.943664  [  224/  306]
train() client id: f_00004-4-7 loss: 0.704839  [  256/  306]
train() client id: f_00004-4-8 loss: 0.937914  [  288/  306]
train() client id: f_00004-5-0 loss: 0.852543  [   32/  306]
train() client id: f_00004-5-1 loss: 0.888931  [   64/  306]
train() client id: f_00004-5-2 loss: 0.943160  [   96/  306]
train() client id: f_00004-5-3 loss: 0.788069  [  128/  306]
train() client id: f_00004-5-4 loss: 0.776271  [  160/  306]
train() client id: f_00004-5-5 loss: 0.823840  [  192/  306]
train() client id: f_00004-5-6 loss: 0.858730  [  224/  306]
train() client id: f_00004-5-7 loss: 0.851031  [  256/  306]
train() client id: f_00004-5-8 loss: 0.823704  [  288/  306]
train() client id: f_00004-6-0 loss: 0.815732  [   32/  306]
train() client id: f_00004-6-1 loss: 0.824626  [   64/  306]
train() client id: f_00004-6-2 loss: 0.851835  [   96/  306]
train() client id: f_00004-6-3 loss: 0.900157  [  128/  306]
train() client id: f_00004-6-4 loss: 0.792910  [  160/  306]
train() client id: f_00004-6-5 loss: 0.931068  [  192/  306]
train() client id: f_00004-6-6 loss: 0.876744  [  224/  306]
train() client id: f_00004-6-7 loss: 0.721944  [  256/  306]
train() client id: f_00004-6-8 loss: 0.803978  [  288/  306]
train() client id: f_00004-7-0 loss: 0.866310  [   32/  306]
train() client id: f_00004-7-1 loss: 0.830215  [   64/  306]
train() client id: f_00004-7-2 loss: 0.987019  [   96/  306]
train() client id: f_00004-7-3 loss: 0.735484  [  128/  306]
train() client id: f_00004-7-4 loss: 0.752519  [  160/  306]
train() client id: f_00004-7-5 loss: 0.882263  [  192/  306]
train() client id: f_00004-7-6 loss: 0.756260  [  224/  306]
train() client id: f_00004-7-7 loss: 0.899445  [  256/  306]
train() client id: f_00004-7-8 loss: 0.895759  [  288/  306]
train() client id: f_00004-8-0 loss: 1.006444  [   32/  306]
train() client id: f_00004-8-1 loss: 0.864456  [   64/  306]
train() client id: f_00004-8-2 loss: 0.803688  [   96/  306]
train() client id: f_00004-8-3 loss: 0.745977  [  128/  306]
train() client id: f_00004-8-4 loss: 0.774328  [  160/  306]
train() client id: f_00004-8-5 loss: 0.816895  [  192/  306]
train() client id: f_00004-8-6 loss: 0.800098  [  224/  306]
train() client id: f_00004-8-7 loss: 0.851253  [  256/  306]
train() client id: f_00004-8-8 loss: 0.827966  [  288/  306]
train() client id: f_00004-9-0 loss: 0.922778  [   32/  306]
train() client id: f_00004-9-1 loss: 0.762364  [   64/  306]
train() client id: f_00004-9-2 loss: 0.719809  [   96/  306]
train() client id: f_00004-9-3 loss: 0.822650  [  128/  306]
train() client id: f_00004-9-4 loss: 0.842967  [  160/  306]
train() client id: f_00004-9-5 loss: 0.785968  [  192/  306]
train() client id: f_00004-9-6 loss: 0.889492  [  224/  306]
train() client id: f_00004-9-7 loss: 0.805371  [  256/  306]
train() client id: f_00004-9-8 loss: 0.903166  [  288/  306]
train() client id: f_00004-10-0 loss: 0.908594  [   32/  306]
train() client id: f_00004-10-1 loss: 0.838729  [   64/  306]
train() client id: f_00004-10-2 loss: 0.902232  [   96/  306]
train() client id: f_00004-10-3 loss: 0.762531  [  128/  306]
train() client id: f_00004-10-4 loss: 0.827451  [  160/  306]
train() client id: f_00004-10-5 loss: 0.740860  [  192/  306]
train() client id: f_00004-10-6 loss: 0.831778  [  224/  306]
train() client id: f_00004-10-7 loss: 0.886966  [  256/  306]
train() client id: f_00004-10-8 loss: 0.808077  [  288/  306]
train() client id: f_00004-11-0 loss: 0.778734  [   32/  306]
train() client id: f_00004-11-1 loss: 0.929547  [   64/  306]
train() client id: f_00004-11-2 loss: 0.949962  [   96/  306]
train() client id: f_00004-11-3 loss: 0.721669  [  128/  306]
train() client id: f_00004-11-4 loss: 0.903326  [  160/  306]
train() client id: f_00004-11-5 loss: 0.794383  [  192/  306]
train() client id: f_00004-11-6 loss: 0.871462  [  224/  306]
train() client id: f_00004-11-7 loss: 0.865673  [  256/  306]
train() client id: f_00004-11-8 loss: 0.729630  [  288/  306]
train() client id: f_00004-12-0 loss: 0.834218  [   32/  306]
train() client id: f_00004-12-1 loss: 0.845833  [   64/  306]
train() client id: f_00004-12-2 loss: 0.809129  [   96/  306]
train() client id: f_00004-12-3 loss: 0.936893  [  128/  306]
train() client id: f_00004-12-4 loss: 0.797659  [  160/  306]
train() client id: f_00004-12-5 loss: 0.812878  [  192/  306]
train() client id: f_00004-12-6 loss: 0.919755  [  224/  306]
train() client id: f_00004-12-7 loss: 0.794643  [  256/  306]
train() client id: f_00004-12-8 loss: 0.851480  [  288/  306]
train() client id: f_00005-0-0 loss: 0.976528  [   32/  146]
train() client id: f_00005-0-1 loss: 0.479681  [   64/  146]
train() client id: f_00005-0-2 loss: 0.758865  [   96/  146]
train() client id: f_00005-0-3 loss: 0.820193  [  128/  146]
train() client id: f_00005-1-0 loss: 0.904027  [   32/  146]
train() client id: f_00005-1-1 loss: 0.818725  [   64/  146]
train() client id: f_00005-1-2 loss: 0.538481  [   96/  146]
train() client id: f_00005-1-3 loss: 0.784460  [  128/  146]
train() client id: f_00005-2-0 loss: 0.548797  [   32/  146]
train() client id: f_00005-2-1 loss: 0.771588  [   64/  146]
train() client id: f_00005-2-2 loss: 0.756324  [   96/  146]
train() client id: f_00005-2-3 loss: 0.751140  [  128/  146]
train() client id: f_00005-3-0 loss: 0.932690  [   32/  146]
train() client id: f_00005-3-1 loss: 0.760182  [   64/  146]
train() client id: f_00005-3-2 loss: 0.749777  [   96/  146]
train() client id: f_00005-3-3 loss: 0.572698  [  128/  146]
train() client id: f_00005-4-0 loss: 0.550394  [   32/  146]
train() client id: f_00005-4-1 loss: 0.744691  [   64/  146]
train() client id: f_00005-4-2 loss: 0.708369  [   96/  146]
train() client id: f_00005-4-3 loss: 0.688731  [  128/  146]
train() client id: f_00005-5-0 loss: 0.938379  [   32/  146]
train() client id: f_00005-5-1 loss: 0.791391  [   64/  146]
train() client id: f_00005-5-2 loss: 0.509557  [   96/  146]
train() client id: f_00005-5-3 loss: 0.839587  [  128/  146]
train() client id: f_00005-6-0 loss: 0.659423  [   32/  146]
train() client id: f_00005-6-1 loss: 0.648634  [   64/  146]
train() client id: f_00005-6-2 loss: 0.928029  [   96/  146]
train() client id: f_00005-6-3 loss: 0.817679  [  128/  146]
train() client id: f_00005-7-0 loss: 0.764523  [   32/  146]
train() client id: f_00005-7-1 loss: 0.794921  [   64/  146]
train() client id: f_00005-7-2 loss: 0.647785  [   96/  146]
train() client id: f_00005-7-3 loss: 0.613662  [  128/  146]
train() client id: f_00005-8-0 loss: 0.902802  [   32/  146]
train() client id: f_00005-8-1 loss: 0.779886  [   64/  146]
train() client id: f_00005-8-2 loss: 0.424411  [   96/  146]
train() client id: f_00005-8-3 loss: 0.715744  [  128/  146]
train() client id: f_00005-9-0 loss: 0.705651  [   32/  146]
train() client id: f_00005-9-1 loss: 0.374660  [   64/  146]
train() client id: f_00005-9-2 loss: 0.830018  [   96/  146]
train() client id: f_00005-9-3 loss: 0.796764  [  128/  146]
train() client id: f_00005-10-0 loss: 0.764141  [   32/  146]
train() client id: f_00005-10-1 loss: 0.611111  [   64/  146]
train() client id: f_00005-10-2 loss: 0.666256  [   96/  146]
train() client id: f_00005-10-3 loss: 0.808765  [  128/  146]
train() client id: f_00005-11-0 loss: 0.799209  [   32/  146]
train() client id: f_00005-11-1 loss: 0.720419  [   64/  146]
train() client id: f_00005-11-2 loss: 0.561308  [   96/  146]
train() client id: f_00005-11-3 loss: 0.770180  [  128/  146]
train() client id: f_00005-12-0 loss: 0.700145  [   32/  146]
train() client id: f_00005-12-1 loss: 1.174407  [   64/  146]
train() client id: f_00005-12-2 loss: 0.505969  [   96/  146]
train() client id: f_00005-12-3 loss: 0.603465  [  128/  146]
train() client id: f_00006-0-0 loss: 0.514652  [   32/   54]
train() client id: f_00006-1-0 loss: 0.561583  [   32/   54]
train() client id: f_00006-2-0 loss: 0.477894  [   32/   54]
train() client id: f_00006-3-0 loss: 0.527494  [   32/   54]
train() client id: f_00006-4-0 loss: 0.511526  [   32/   54]
train() client id: f_00006-5-0 loss: 0.507703  [   32/   54]
train() client id: f_00006-6-0 loss: 0.545997  [   32/   54]
train() client id: f_00006-7-0 loss: 0.509419  [   32/   54]
train() client id: f_00006-8-0 loss: 0.467583  [   32/   54]
train() client id: f_00006-9-0 loss: 0.561238  [   32/   54]
train() client id: f_00006-10-0 loss: 0.464841  [   32/   54]
train() client id: f_00006-11-0 loss: 0.582647  [   32/   54]
train() client id: f_00006-12-0 loss: 0.514829  [   32/   54]
train() client id: f_00007-0-0 loss: 0.489237  [   32/  179]
train() client id: f_00007-0-1 loss: 0.527779  [   64/  179]
train() client id: f_00007-0-2 loss: 0.556808  [   96/  179]
train() client id: f_00007-0-3 loss: 0.350166  [  128/  179]
train() client id: f_00007-0-4 loss: 0.331831  [  160/  179]
train() client id: f_00007-1-0 loss: 0.401880  [   32/  179]
train() client id: f_00007-1-1 loss: 0.426500  [   64/  179]
train() client id: f_00007-1-2 loss: 0.483301  [   96/  179]
train() client id: f_00007-1-3 loss: 0.497439  [  128/  179]
train() client id: f_00007-1-4 loss: 0.437642  [  160/  179]
train() client id: f_00007-2-0 loss: 0.460558  [   32/  179]
train() client id: f_00007-2-1 loss: 0.504753  [   64/  179]
train() client id: f_00007-2-2 loss: 0.333384  [   96/  179]
train() client id: f_00007-2-3 loss: 0.478776  [  128/  179]
train() client id: f_00007-2-4 loss: 0.316053  [  160/  179]
train() client id: f_00007-3-0 loss: 0.434070  [   32/  179]
train() client id: f_00007-3-1 loss: 0.382949  [   64/  179]
train() client id: f_00007-3-2 loss: 0.429955  [   96/  179]
train() client id: f_00007-3-3 loss: 0.412474  [  128/  179]
train() client id: f_00007-3-4 loss: 0.441302  [  160/  179]
train() client id: f_00007-4-0 loss: 0.222725  [   32/  179]
train() client id: f_00007-4-1 loss: 0.449185  [   64/  179]
train() client id: f_00007-4-2 loss: 0.624694  [   96/  179]
train() client id: f_00007-4-3 loss: 0.279719  [  128/  179]
train() client id: f_00007-4-4 loss: 0.348054  [  160/  179]
train() client id: f_00007-5-0 loss: 0.388832  [   32/  179]
train() client id: f_00007-5-1 loss: 0.322309  [   64/  179]
train() client id: f_00007-5-2 loss: 0.251756  [   96/  179]
train() client id: f_00007-5-3 loss: 0.312349  [  128/  179]
train() client id: f_00007-5-4 loss: 0.444067  [  160/  179]
train() client id: f_00007-6-0 loss: 0.259513  [   32/  179]
train() client id: f_00007-6-1 loss: 0.472781  [   64/  179]
train() client id: f_00007-6-2 loss: 0.427570  [   96/  179]
train() client id: f_00007-6-3 loss: 0.445277  [  128/  179]
train() client id: f_00007-6-4 loss: 0.224318  [  160/  179]
train() client id: f_00007-7-0 loss: 0.335536  [   32/  179]
train() client id: f_00007-7-1 loss: 0.343260  [   64/  179]
train() client id: f_00007-7-2 loss: 0.457256  [   96/  179]
train() client id: f_00007-7-3 loss: 0.223404  [  128/  179]
train() client id: f_00007-7-4 loss: 0.578675  [  160/  179]
train() client id: f_00007-8-0 loss: 0.441197  [   32/  179]
train() client id: f_00007-8-1 loss: 0.314979  [   64/  179]
train() client id: f_00007-8-2 loss: 0.329061  [   96/  179]
train() client id: f_00007-8-3 loss: 0.236441  [  128/  179]
train() client id: f_00007-8-4 loss: 0.470698  [  160/  179]
train() client id: f_00007-9-0 loss: 0.571627  [   32/  179]
train() client id: f_00007-9-1 loss: 0.241816  [   64/  179]
train() client id: f_00007-9-2 loss: 0.209514  [   96/  179]
train() client id: f_00007-9-3 loss: 0.293163  [  128/  179]
train() client id: f_00007-9-4 loss: 0.498945  [  160/  179]
train() client id: f_00007-10-0 loss: 0.308145  [   32/  179]
train() client id: f_00007-10-1 loss: 0.509790  [   64/  179]
train() client id: f_00007-10-2 loss: 0.340848  [   96/  179]
train() client id: f_00007-10-3 loss: 0.395938  [  128/  179]
train() client id: f_00007-10-4 loss: 0.325922  [  160/  179]
train() client id: f_00007-11-0 loss: 0.389997  [   32/  179]
train() client id: f_00007-11-1 loss: 0.320893  [   64/  179]
train() client id: f_00007-11-2 loss: 0.417184  [   96/  179]
train() client id: f_00007-11-3 loss: 0.401898  [  128/  179]
train() client id: f_00007-11-4 loss: 0.274469  [  160/  179]
train() client id: f_00007-12-0 loss: 0.384999  [   32/  179]
train() client id: f_00007-12-1 loss: 0.323814  [   64/  179]
train() client id: f_00007-12-2 loss: 0.203618  [   96/  179]
train() client id: f_00007-12-3 loss: 0.494208  [  128/  179]
train() client id: f_00007-12-4 loss: 0.324340  [  160/  179]
train() client id: f_00008-0-0 loss: 0.738714  [   32/  130]
train() client id: f_00008-0-1 loss: 0.715727  [   64/  130]
train() client id: f_00008-0-2 loss: 0.621710  [   96/  130]
train() client id: f_00008-0-3 loss: 0.633847  [  128/  130]
train() client id: f_00008-1-0 loss: 0.718467  [   32/  130]
train() client id: f_00008-1-1 loss: 0.583352  [   64/  130]
train() client id: f_00008-1-2 loss: 0.737683  [   96/  130]
train() client id: f_00008-1-3 loss: 0.671072  [  128/  130]
train() client id: f_00008-2-0 loss: 0.670881  [   32/  130]
train() client id: f_00008-2-1 loss: 0.673508  [   64/  130]
train() client id: f_00008-2-2 loss: 0.761158  [   96/  130]
train() client id: f_00008-2-3 loss: 0.645003  [  128/  130]
train() client id: f_00008-3-0 loss: 0.689623  [   32/  130]
train() client id: f_00008-3-1 loss: 0.635779  [   64/  130]
train() client id: f_00008-3-2 loss: 0.574036  [   96/  130]
train() client id: f_00008-3-3 loss: 0.815175  [  128/  130]
train() client id: f_00008-4-0 loss: 0.729909  [   32/  130]
train() client id: f_00008-4-1 loss: 0.625374  [   64/  130]
train() client id: f_00008-4-2 loss: 0.602025  [   96/  130]
train() client id: f_00008-4-3 loss: 0.796555  [  128/  130]
train() client id: f_00008-5-0 loss: 0.710359  [   32/  130]
train() client id: f_00008-5-1 loss: 0.627226  [   64/  130]
train() client id: f_00008-5-2 loss: 0.681035  [   96/  130]
train() client id: f_00008-5-3 loss: 0.683096  [  128/  130]
train() client id: f_00008-6-0 loss: 0.570066  [   32/  130]
train() client id: f_00008-6-1 loss: 0.774990  [   64/  130]
train() client id: f_00008-6-2 loss: 0.738321  [   96/  130]
train() client id: f_00008-6-3 loss: 0.674497  [  128/  130]
train() client id: f_00008-7-0 loss: 0.768184  [   32/  130]
train() client id: f_00008-7-1 loss: 0.733349  [   64/  130]
train() client id: f_00008-7-2 loss: 0.559824  [   96/  130]
train() client id: f_00008-7-3 loss: 0.693624  [  128/  130]
train() client id: f_00008-8-0 loss: 0.620781  [   32/  130]
train() client id: f_00008-8-1 loss: 0.614230  [   64/  130]
train() client id: f_00008-8-2 loss: 0.738217  [   96/  130]
train() client id: f_00008-8-3 loss: 0.745123  [  128/  130]
train() client id: f_00008-9-0 loss: 0.645747  [   32/  130]
train() client id: f_00008-9-1 loss: 0.733653  [   64/  130]
train() client id: f_00008-9-2 loss: 0.665597  [   96/  130]
train() client id: f_00008-9-3 loss: 0.708800  [  128/  130]
train() client id: f_00008-10-0 loss: 0.640073  [   32/  130]
train() client id: f_00008-10-1 loss: 0.741956  [   64/  130]
train() client id: f_00008-10-2 loss: 0.689039  [   96/  130]
train() client id: f_00008-10-3 loss: 0.687655  [  128/  130]
train() client id: f_00008-11-0 loss: 0.683481  [   32/  130]
train() client id: f_00008-11-1 loss: 0.796835  [   64/  130]
train() client id: f_00008-11-2 loss: 0.593295  [   96/  130]
train() client id: f_00008-11-3 loss: 0.683145  [  128/  130]
train() client id: f_00008-12-0 loss: 0.698234  [   32/  130]
train() client id: f_00008-12-1 loss: 0.592199  [   64/  130]
train() client id: f_00008-12-2 loss: 0.771151  [   96/  130]
train() client id: f_00008-12-3 loss: 0.701504  [  128/  130]
train() client id: f_00009-0-0 loss: 1.091892  [   32/  118]
train() client id: f_00009-0-1 loss: 1.080757  [   64/  118]
train() client id: f_00009-0-2 loss: 1.003903  [   96/  118]
train() client id: f_00009-1-0 loss: 1.074214  [   32/  118]
train() client id: f_00009-1-1 loss: 0.979480  [   64/  118]
train() client id: f_00009-1-2 loss: 0.944717  [   96/  118]
train() client id: f_00009-2-0 loss: 1.076844  [   32/  118]
train() client id: f_00009-2-1 loss: 0.839739  [   64/  118]
train() client id: f_00009-2-2 loss: 0.928987  [   96/  118]
train() client id: f_00009-3-0 loss: 0.835170  [   32/  118]
train() client id: f_00009-3-1 loss: 0.919776  [   64/  118]
train() client id: f_00009-3-2 loss: 1.008656  [   96/  118]
train() client id: f_00009-4-0 loss: 1.037947  [   32/  118]
train() client id: f_00009-4-1 loss: 0.840444  [   64/  118]
train() client id: f_00009-4-2 loss: 0.810872  [   96/  118]
train() client id: f_00009-5-0 loss: 0.765550  [   32/  118]
train() client id: f_00009-5-1 loss: 0.927008  [   64/  118]
train() client id: f_00009-5-2 loss: 0.790034  [   96/  118]
train() client id: f_00009-6-0 loss: 0.825749  [   32/  118]
train() client id: f_00009-6-1 loss: 0.766598  [   64/  118]
train() client id: f_00009-6-2 loss: 0.864208  [   96/  118]
train() client id: f_00009-7-0 loss: 0.973627  [   32/  118]
train() client id: f_00009-7-1 loss: 0.673314  [   64/  118]
train() client id: f_00009-7-2 loss: 0.819819  [   96/  118]
train() client id: f_00009-8-0 loss: 0.795375  [   32/  118]
train() client id: f_00009-8-1 loss: 0.801373  [   64/  118]
train() client id: f_00009-8-2 loss: 0.740978  [   96/  118]
train() client id: f_00009-9-0 loss: 0.745219  [   32/  118]
train() client id: f_00009-9-1 loss: 0.750521  [   64/  118]
train() client id: f_00009-9-2 loss: 0.781785  [   96/  118]
train() client id: f_00009-10-0 loss: 0.691926  [   32/  118]
train() client id: f_00009-10-1 loss: 0.700163  [   64/  118]
train() client id: f_00009-10-2 loss: 0.942212  [   96/  118]
train() client id: f_00009-11-0 loss: 0.854022  [   32/  118]
train() client id: f_00009-11-1 loss: 0.745056  [   64/  118]
train() client id: f_00009-11-2 loss: 0.758833  [   96/  118]
train() client id: f_00009-12-0 loss: 0.650625  [   32/  118]
train() client id: f_00009-12-1 loss: 0.741032  [   64/  118]
train() client id: f_00009-12-2 loss: 0.866426  [   96/  118]
At round 43 accuracy: 0.6445623342175066
At round 43 training accuracy: 0.5848423876592891
At round 43 training loss: 0.8442767110697152
gradient difference: 0.39521268010139465
train() client id: f_00000-0-0 loss: 1.032647  [   32/  126]
train() client id: f_00000-0-1 loss: 1.044315  [   64/  126]
train() client id: f_00000-0-2 loss: 1.072512  [   96/  126]
train() client id: f_00000-1-0 loss: 0.968421  [   32/  126]
train() client id: f_00000-1-1 loss: 1.156983  [   64/  126]
train() client id: f_00000-1-2 loss: 0.837825  [   96/  126]
train() client id: f_00000-2-0 loss: 0.876558  [   32/  126]
train() client id: f_00000-2-1 loss: 0.759239  [   64/  126]
train() client id: f_00000-2-2 loss: 0.908021  [   96/  126]
train() client id: f_00000-3-0 loss: 0.747289  [   32/  126]
train() client id: f_00000-3-1 loss: 0.860492  [   64/  126]
train() client id: f_00000-3-2 loss: 0.912785  [   96/  126]
train() client id: f_00000-4-0 loss: 0.764399  [   32/  126]
train() client id: f_00000-4-1 loss: 0.859116  [   64/  126]
train() client id: f_00000-4-2 loss: 0.971664  [   96/  126]
train() client id: f_00000-5-0 loss: 0.893618  [   32/  126]
train() client id: f_00000-5-1 loss: 0.710122  [   64/  126]
train() client id: f_00000-5-2 loss: 0.854654  [   96/  126]
train() client id: f_00000-6-0 loss: 0.835506  [   32/  126]
train() client id: f_00000-6-1 loss: 0.742779  [   64/  126]
train() client id: f_00000-6-2 loss: 0.780235  [   96/  126]
train() client id: f_00000-7-0 loss: 0.793740  [   32/  126]
train() client id: f_00000-7-1 loss: 0.775189  [   64/  126]
train() client id: f_00000-7-2 loss: 0.931065  [   96/  126]
train() client id: f_00000-8-0 loss: 0.761098  [   32/  126]
train() client id: f_00000-8-1 loss: 0.857763  [   64/  126]
train() client id: f_00000-8-2 loss: 0.711332  [   96/  126]
train() client id: f_00000-9-0 loss: 0.745180  [   32/  126]
train() client id: f_00000-9-1 loss: 0.721624  [   64/  126]
train() client id: f_00000-9-2 loss: 0.777633  [   96/  126]
train() client id: f_00000-10-0 loss: 0.797183  [   32/  126]
train() client id: f_00000-10-1 loss: 0.794301  [   64/  126]
train() client id: f_00000-10-2 loss: 0.786492  [   96/  126]
train() client id: f_00000-11-0 loss: 0.827781  [   32/  126]
train() client id: f_00000-11-1 loss: 0.737226  [   64/  126]
train() client id: f_00000-11-2 loss: 0.861353  [   96/  126]
train() client id: f_00000-12-0 loss: 0.760253  [   32/  126]
train() client id: f_00000-12-1 loss: 0.909527  [   64/  126]
train() client id: f_00000-12-2 loss: 0.812531  [   96/  126]
train() client id: f_00001-0-0 loss: 0.408566  [   32/  265]
train() client id: f_00001-0-1 loss: 0.567965  [   64/  265]
train() client id: f_00001-0-2 loss: 0.346284  [   96/  265]
train() client id: f_00001-0-3 loss: 0.365461  [  128/  265]
train() client id: f_00001-0-4 loss: 0.424896  [  160/  265]
train() client id: f_00001-0-5 loss: 0.432755  [  192/  265]
train() client id: f_00001-0-6 loss: 0.409775  [  224/  265]
train() client id: f_00001-0-7 loss: 0.466036  [  256/  265]
train() client id: f_00001-1-0 loss: 0.532631  [   32/  265]
train() client id: f_00001-1-1 loss: 0.339924  [   64/  265]
train() client id: f_00001-1-2 loss: 0.379047  [   96/  265]
train() client id: f_00001-1-3 loss: 0.417456  [  128/  265]
train() client id: f_00001-1-4 loss: 0.355227  [  160/  265]
train() client id: f_00001-1-5 loss: 0.425845  [  192/  265]
train() client id: f_00001-1-6 loss: 0.371986  [  224/  265]
train() client id: f_00001-1-7 loss: 0.504845  [  256/  265]
train() client id: f_00001-2-0 loss: 0.403997  [   32/  265]
train() client id: f_00001-2-1 loss: 0.451580  [   64/  265]
train() client id: f_00001-2-2 loss: 0.475268  [   96/  265]
train() client id: f_00001-2-3 loss: 0.301212  [  128/  265]
train() client id: f_00001-2-4 loss: 0.456788  [  160/  265]
train() client id: f_00001-2-5 loss: 0.339025  [  192/  265]
train() client id: f_00001-2-6 loss: 0.352544  [  224/  265]
train() client id: f_00001-2-7 loss: 0.526421  [  256/  265]
train() client id: f_00001-3-0 loss: 0.561344  [   32/  265]
train() client id: f_00001-3-1 loss: 0.336843  [   64/  265]
train() client id: f_00001-3-2 loss: 0.377597  [   96/  265]
train() client id: f_00001-3-3 loss: 0.407549  [  128/  265]
train() client id: f_00001-3-4 loss: 0.432874  [  160/  265]
train() client id: f_00001-3-5 loss: 0.360514  [  192/  265]
train() client id: f_00001-3-6 loss: 0.390897  [  224/  265]
train() client id: f_00001-3-7 loss: 0.396662  [  256/  265]
train() client id: f_00001-4-0 loss: 0.292842  [   32/  265]
train() client id: f_00001-4-1 loss: 0.444044  [   64/  265]
train() client id: f_00001-4-2 loss: 0.349706  [   96/  265]
train() client id: f_00001-4-3 loss: 0.363991  [  128/  265]
train() client id: f_00001-4-4 loss: 0.429278  [  160/  265]
train() client id: f_00001-4-5 loss: 0.458660  [  192/  265]
train() client id: f_00001-4-6 loss: 0.368151  [  224/  265]
train() client id: f_00001-4-7 loss: 0.481347  [  256/  265]
train() client id: f_00001-5-0 loss: 0.369043  [   32/  265]
train() client id: f_00001-5-1 loss: 0.369990  [   64/  265]
train() client id: f_00001-5-2 loss: 0.371277  [   96/  265]
train() client id: f_00001-5-3 loss: 0.479865  [  128/  265]
train() client id: f_00001-5-4 loss: 0.385784  [  160/  265]
train() client id: f_00001-5-5 loss: 0.421623  [  192/  265]
train() client id: f_00001-5-6 loss: 0.441110  [  224/  265]
train() client id: f_00001-5-7 loss: 0.372405  [  256/  265]
train() client id: f_00001-6-0 loss: 0.417889  [   32/  265]
train() client id: f_00001-6-1 loss: 0.392136  [   64/  265]
train() client id: f_00001-6-2 loss: 0.476949  [   96/  265]
train() client id: f_00001-6-3 loss: 0.341598  [  128/  265]
train() client id: f_00001-6-4 loss: 0.443755  [  160/  265]
train() client id: f_00001-6-5 loss: 0.412233  [  192/  265]
train() client id: f_00001-6-6 loss: 0.311804  [  224/  265]
train() client id: f_00001-6-7 loss: 0.398447  [  256/  265]
train() client id: f_00001-7-0 loss: 0.398820  [   32/  265]
train() client id: f_00001-7-1 loss: 0.450039  [   64/  265]
train() client id: f_00001-7-2 loss: 0.499507  [   96/  265]
train() client id: f_00001-7-3 loss: 0.397968  [  128/  265]
train() client id: f_00001-7-4 loss: 0.400025  [  160/  265]
train() client id: f_00001-7-5 loss: 0.301928  [  192/  265]
train() client id: f_00001-7-6 loss: 0.421380  [  224/  265]
train() client id: f_00001-7-7 loss: 0.313782  [  256/  265]
train() client id: f_00001-8-0 loss: 0.412516  [   32/  265]
train() client id: f_00001-8-1 loss: 0.353846  [   64/  265]
train() client id: f_00001-8-2 loss: 0.340827  [   96/  265]
train() client id: f_00001-8-3 loss: 0.396723  [  128/  265]
train() client id: f_00001-8-4 loss: 0.520484  [  160/  265]
train() client id: f_00001-8-5 loss: 0.396412  [  192/  265]
train() client id: f_00001-8-6 loss: 0.362400  [  224/  265]
train() client id: f_00001-8-7 loss: 0.396146  [  256/  265]
train() client id: f_00001-9-0 loss: 0.463384  [   32/  265]
train() client id: f_00001-9-1 loss: 0.425811  [   64/  265]
train() client id: f_00001-9-2 loss: 0.313160  [   96/  265]
train() client id: f_00001-9-3 loss: 0.328053  [  128/  265]
train() client id: f_00001-9-4 loss: 0.360906  [  160/  265]
train() client id: f_00001-9-5 loss: 0.495659  [  192/  265]
train() client id: f_00001-9-6 loss: 0.293452  [  224/  265]
train() client id: f_00001-9-7 loss: 0.489156  [  256/  265]
train() client id: f_00001-10-0 loss: 0.363197  [   32/  265]
train() client id: f_00001-10-1 loss: 0.401217  [   64/  265]
train() client id: f_00001-10-2 loss: 0.443779  [   96/  265]
train() client id: f_00001-10-3 loss: 0.296452  [  128/  265]
train() client id: f_00001-10-4 loss: 0.373873  [  160/  265]
train() client id: f_00001-10-5 loss: 0.319530  [  192/  265]
train() client id: f_00001-10-6 loss: 0.470757  [  224/  265]
train() client id: f_00001-10-7 loss: 0.507494  [  256/  265]
train() client id: f_00001-11-0 loss: 0.291771  [   32/  265]
train() client id: f_00001-11-1 loss: 0.421210  [   64/  265]
train() client id: f_00001-11-2 loss: 0.383304  [   96/  265]
train() client id: f_00001-11-3 loss: 0.305826  [  128/  265]
train() client id: f_00001-11-4 loss: 0.418830  [  160/  265]
train() client id: f_00001-11-5 loss: 0.327030  [  192/  265]
train() client id: f_00001-11-6 loss: 0.432167  [  224/  265]
train() client id: f_00001-11-7 loss: 0.583195  [  256/  265]
train() client id: f_00001-12-0 loss: 0.496656  [   32/  265]
train() client id: f_00001-12-1 loss: 0.402940  [   64/  265]
train() client id: f_00001-12-2 loss: 0.287247  [   96/  265]
train() client id: f_00001-12-3 loss: 0.430131  [  128/  265]
train() client id: f_00001-12-4 loss: 0.312416  [  160/  265]
train() client id: f_00001-12-5 loss: 0.296602  [  192/  265]
train() client id: f_00001-12-6 loss: 0.516924  [  224/  265]
train() client id: f_00001-12-7 loss: 0.313911  [  256/  265]
train() client id: f_00002-0-0 loss: 1.300741  [   32/  124]
train() client id: f_00002-0-1 loss: 1.155024  [   64/  124]
train() client id: f_00002-0-2 loss: 1.218223  [   96/  124]
train() client id: f_00002-1-0 loss: 1.271134  [   32/  124]
train() client id: f_00002-1-1 loss: 1.194278  [   64/  124]
train() client id: f_00002-1-2 loss: 1.205009  [   96/  124]
train() client id: f_00002-2-0 loss: 1.173537  [   32/  124]
train() client id: f_00002-2-1 loss: 1.180423  [   64/  124]
train() client id: f_00002-2-2 loss: 1.107113  [   96/  124]
train() client id: f_00002-3-0 loss: 1.128956  [   32/  124]
train() client id: f_00002-3-1 loss: 1.091461  [   64/  124]
train() client id: f_00002-3-2 loss: 1.121921  [   96/  124]
train() client id: f_00002-4-0 loss: 0.903016  [   32/  124]
train() client id: f_00002-4-1 loss: 1.043445  [   64/  124]
train() client id: f_00002-4-2 loss: 1.210440  [   96/  124]
train() client id: f_00002-5-0 loss: 1.087048  [   32/  124]
train() client id: f_00002-5-1 loss: 0.891022  [   64/  124]
train() client id: f_00002-5-2 loss: 1.043044  [   96/  124]
train() client id: f_00002-6-0 loss: 1.033750  [   32/  124]
train() client id: f_00002-6-1 loss: 1.164551  [   64/  124]
train() client id: f_00002-6-2 loss: 1.043116  [   96/  124]
train() client id: f_00002-7-0 loss: 0.918317  [   32/  124]
train() client id: f_00002-7-1 loss: 0.911151  [   64/  124]
train() client id: f_00002-7-2 loss: 1.171647  [   96/  124]
train() client id: f_00002-8-0 loss: 0.913651  [   32/  124]
train() client id: f_00002-8-1 loss: 0.899266  [   64/  124]
train() client id: f_00002-8-2 loss: 1.102226  [   96/  124]
train() client id: f_00002-9-0 loss: 0.990924  [   32/  124]
train() client id: f_00002-9-1 loss: 0.879426  [   64/  124]
train() client id: f_00002-9-2 loss: 0.880237  [   96/  124]
train() client id: f_00002-10-0 loss: 0.985285  [   32/  124]
train() client id: f_00002-10-1 loss: 0.983511  [   64/  124]
train() client id: f_00002-10-2 loss: 0.952378  [   96/  124]
train() client id: f_00002-11-0 loss: 1.078170  [   32/  124]
train() client id: f_00002-11-1 loss: 0.826019  [   64/  124]
train() client id: f_00002-11-2 loss: 1.028994  [   96/  124]
train() client id: f_00002-12-0 loss: 1.019647  [   32/  124]
train() client id: f_00002-12-1 loss: 0.936728  [   64/  124]
train() client id: f_00002-12-2 loss: 0.920716  [   96/  124]
train() client id: f_00003-0-0 loss: 0.681478  [   32/   43]
train() client id: f_00003-1-0 loss: 0.741456  [   32/   43]
train() client id: f_00003-2-0 loss: 0.921089  [   32/   43]
train() client id: f_00003-3-0 loss: 0.929440  [   32/   43]
train() client id: f_00003-4-0 loss: 0.707187  [   32/   43]
train() client id: f_00003-5-0 loss: 0.690438  [   32/   43]
train() client id: f_00003-6-0 loss: 0.831405  [   32/   43]
train() client id: f_00003-7-0 loss: 0.662384  [   32/   43]
train() client id: f_00003-8-0 loss: 0.570413  [   32/   43]
train() client id: f_00003-9-0 loss: 0.733352  [   32/   43]
train() client id: f_00003-10-0 loss: 0.890769  [   32/   43]
train() client id: f_00003-11-0 loss: 0.644041  [   32/   43]
train() client id: f_00003-12-0 loss: 0.803591  [   32/   43]
train() client id: f_00004-0-0 loss: 0.952652  [   32/  306]
train() client id: f_00004-0-1 loss: 0.806304  [   64/  306]
train() client id: f_00004-0-2 loss: 0.941092  [   96/  306]
train() client id: f_00004-0-3 loss: 0.900032  [  128/  306]
train() client id: f_00004-0-4 loss: 0.864362  [  160/  306]
train() client id: f_00004-0-5 loss: 0.857342  [  192/  306]
train() client id: f_00004-0-6 loss: 0.808249  [  224/  306]
train() client id: f_00004-0-7 loss: 0.975165  [  256/  306]
train() client id: f_00004-0-8 loss: 0.992498  [  288/  306]
train() client id: f_00004-1-0 loss: 0.774763  [   32/  306]
train() client id: f_00004-1-1 loss: 0.821778  [   64/  306]
train() client id: f_00004-1-2 loss: 0.906249  [   96/  306]
train() client id: f_00004-1-3 loss: 0.970853  [  128/  306]
train() client id: f_00004-1-4 loss: 0.874485  [  160/  306]
train() client id: f_00004-1-5 loss: 0.925661  [  192/  306]
train() client id: f_00004-1-6 loss: 0.895092  [  224/  306]
train() client id: f_00004-1-7 loss: 0.899808  [  256/  306]
train() client id: f_00004-1-8 loss: 0.859426  [  288/  306]
train() client id: f_00004-2-0 loss: 0.975063  [   32/  306]
train() client id: f_00004-2-1 loss: 0.827751  [   64/  306]
train() client id: f_00004-2-2 loss: 0.926661  [   96/  306]
train() client id: f_00004-2-3 loss: 0.833332  [  128/  306]
train() client id: f_00004-2-4 loss: 0.963798  [  160/  306]
train() client id: f_00004-2-5 loss: 0.812846  [  192/  306]
train() client id: f_00004-2-6 loss: 0.873939  [  224/  306]
train() client id: f_00004-2-7 loss: 0.948050  [  256/  306]
train() client id: f_00004-2-8 loss: 0.891653  [  288/  306]
train() client id: f_00004-3-0 loss: 0.852497  [   32/  306]
train() client id: f_00004-3-1 loss: 0.839973  [   64/  306]
train() client id: f_00004-3-2 loss: 0.804787  [   96/  306]
train() client id: f_00004-3-3 loss: 0.809918  [  128/  306]
train() client id: f_00004-3-4 loss: 0.950923  [  160/  306]
train() client id: f_00004-3-5 loss: 1.022905  [  192/  306]
train() client id: f_00004-3-6 loss: 1.010930  [  224/  306]
train() client id: f_00004-3-7 loss: 0.927198  [  256/  306]
train() client id: f_00004-3-8 loss: 0.813273  [  288/  306]
train() client id: f_00004-4-0 loss: 0.908105  [   32/  306]
train() client id: f_00004-4-1 loss: 0.862308  [   64/  306]
train() client id: f_00004-4-2 loss: 0.865063  [   96/  306]
train() client id: f_00004-4-3 loss: 0.878053  [  128/  306]
train() client id: f_00004-4-4 loss: 0.773349  [  160/  306]
train() client id: f_00004-4-5 loss: 0.961250  [  192/  306]
train() client id: f_00004-4-6 loss: 0.985289  [  224/  306]
train() client id: f_00004-4-7 loss: 0.912095  [  256/  306]
train() client id: f_00004-4-8 loss: 0.826600  [  288/  306]
train() client id: f_00004-5-0 loss: 0.855349  [   32/  306]
train() client id: f_00004-5-1 loss: 0.817341  [   64/  306]
train() client id: f_00004-5-2 loss: 0.745668  [   96/  306]
train() client id: f_00004-5-3 loss: 0.904162  [  128/  306]
train() client id: f_00004-5-4 loss: 0.923293  [  160/  306]
train() client id: f_00004-5-5 loss: 0.862710  [  192/  306]
train() client id: f_00004-5-6 loss: 1.010765  [  224/  306]
train() client id: f_00004-5-7 loss: 0.846695  [  256/  306]
train() client id: f_00004-5-8 loss: 0.909160  [  288/  306]
train() client id: f_00004-6-0 loss: 0.954080  [   32/  306]
train() client id: f_00004-6-1 loss: 1.001028  [   64/  306]
train() client id: f_00004-6-2 loss: 0.862914  [   96/  306]
train() client id: f_00004-6-3 loss: 0.881238  [  128/  306]
train() client id: f_00004-6-4 loss: 0.817525  [  160/  306]
train() client id: f_00004-6-5 loss: 0.987383  [  192/  306]
train() client id: f_00004-6-6 loss: 0.852345  [  224/  306]
train() client id: f_00004-6-7 loss: 0.715115  [  256/  306]
train() client id: f_00004-6-8 loss: 0.849171  [  288/  306]
train() client id: f_00004-7-0 loss: 0.805734  [   32/  306]
train() client id: f_00004-7-1 loss: 0.896024  [   64/  306]
train() client id: f_00004-7-2 loss: 0.922555  [   96/  306]
train() client id: f_00004-7-3 loss: 0.790986  [  128/  306]
train() client id: f_00004-7-4 loss: 0.943874  [  160/  306]
train() client id: f_00004-7-5 loss: 0.847469  [  192/  306]
train() client id: f_00004-7-6 loss: 0.821452  [  224/  306]
train() client id: f_00004-7-7 loss: 0.773474  [  256/  306]
train() client id: f_00004-7-8 loss: 1.047859  [  288/  306]
train() client id: f_00004-8-0 loss: 0.832664  [   32/  306]
train() client id: f_00004-8-1 loss: 0.781017  [   64/  306]
train() client id: f_00004-8-2 loss: 0.927096  [   96/  306]
train() client id: f_00004-8-3 loss: 1.139572  [  128/  306]
train() client id: f_00004-8-4 loss: 0.847999  [  160/  306]
train() client id: f_00004-8-5 loss: 0.754553  [  192/  306]
train() client id: f_00004-8-6 loss: 0.778450  [  224/  306]
train() client id: f_00004-8-7 loss: 0.853301  [  256/  306]
train() client id: f_00004-8-8 loss: 0.953229  [  288/  306]
train() client id: f_00004-9-0 loss: 0.845149  [   32/  306]
train() client id: f_00004-9-1 loss: 0.805216  [   64/  306]
train() client id: f_00004-9-2 loss: 0.902115  [   96/  306]
train() client id: f_00004-9-3 loss: 0.831975  [  128/  306]
train() client id: f_00004-9-4 loss: 0.830278  [  160/  306]
train() client id: f_00004-9-5 loss: 0.837509  [  192/  306]
train() client id: f_00004-9-6 loss: 1.016177  [  224/  306]
train() client id: f_00004-9-7 loss: 0.860742  [  256/  306]
train() client id: f_00004-9-8 loss: 0.869645  [  288/  306]
train() client id: f_00004-10-0 loss: 0.800850  [   32/  306]
train() client id: f_00004-10-1 loss: 0.844405  [   64/  306]
train() client id: f_00004-10-2 loss: 0.754099  [   96/  306]
train() client id: f_00004-10-3 loss: 0.860235  [  128/  306]
train() client id: f_00004-10-4 loss: 0.812825  [  160/  306]
train() client id: f_00004-10-5 loss: 0.916991  [  192/  306]
train() client id: f_00004-10-6 loss: 0.901759  [  224/  306]
train() client id: f_00004-10-7 loss: 0.975640  [  256/  306]
train() client id: f_00004-10-8 loss: 0.942352  [  288/  306]
train() client id: f_00004-11-0 loss: 0.751605  [   32/  306]
train() client id: f_00004-11-1 loss: 1.033729  [   64/  306]
train() client id: f_00004-11-2 loss: 0.806040  [   96/  306]
train() client id: f_00004-11-3 loss: 0.833097  [  128/  306]
train() client id: f_00004-11-4 loss: 0.988848  [  160/  306]
train() client id: f_00004-11-5 loss: 0.897606  [  192/  306]
train() client id: f_00004-11-6 loss: 0.745895  [  224/  306]
train() client id: f_00004-11-7 loss: 0.923211  [  256/  306]
train() client id: f_00004-11-8 loss: 0.841950  [  288/  306]
train() client id: f_00004-12-0 loss: 0.757177  [   32/  306]
train() client id: f_00004-12-1 loss: 0.841030  [   64/  306]
train() client id: f_00004-12-2 loss: 0.912193  [   96/  306]
train() client id: f_00004-12-3 loss: 0.740815  [  128/  306]
train() client id: f_00004-12-4 loss: 0.774920  [  160/  306]
train() client id: f_00004-12-5 loss: 0.958824  [  192/  306]
train() client id: f_00004-12-6 loss: 0.847717  [  224/  306]
train() client id: f_00004-12-7 loss: 0.986463  [  256/  306]
train() client id: f_00004-12-8 loss: 0.959411  [  288/  306]
train() client id: f_00005-0-0 loss: 0.528603  [   32/  146]
train() client id: f_00005-0-1 loss: 0.714358  [   64/  146]
train() client id: f_00005-0-2 loss: 0.924867  [   96/  146]
train() client id: f_00005-0-3 loss: 0.671494  [  128/  146]
train() client id: f_00005-1-0 loss: 0.676438  [   32/  146]
train() client id: f_00005-1-1 loss: 0.659953  [   64/  146]
train() client id: f_00005-1-2 loss: 0.869059  [   96/  146]
train() client id: f_00005-1-3 loss: 0.702888  [  128/  146]
train() client id: f_00005-2-0 loss: 0.610775  [   32/  146]
train() client id: f_00005-2-1 loss: 0.598720  [   64/  146]
train() client id: f_00005-2-2 loss: 0.741973  [   96/  146]
train() client id: f_00005-2-3 loss: 0.684521  [  128/  146]
train() client id: f_00005-3-0 loss: 0.813196  [   32/  146]
train() client id: f_00005-3-1 loss: 0.682662  [   64/  146]
train() client id: f_00005-3-2 loss: 0.722292  [   96/  146]
train() client id: f_00005-3-3 loss: 0.480575  [  128/  146]
train() client id: f_00005-4-0 loss: 0.815621  [   32/  146]
train() client id: f_00005-4-1 loss: 0.833152  [   64/  146]
train() client id: f_00005-4-2 loss: 0.715014  [   96/  146]
train() client id: f_00005-4-3 loss: 0.545779  [  128/  146]
train() client id: f_00005-5-0 loss: 0.815163  [   32/  146]
train() client id: f_00005-5-1 loss: 0.462070  [   64/  146]
train() client id: f_00005-5-2 loss: 0.623251  [   96/  146]
train() client id: f_00005-5-3 loss: 0.925460  [  128/  146]
train() client id: f_00005-6-0 loss: 0.811671  [   32/  146]
train() client id: f_00005-6-1 loss: 0.743570  [   64/  146]
train() client id: f_00005-6-2 loss: 0.456996  [   96/  146]
train() client id: f_00005-6-3 loss: 0.666443  [  128/  146]
train() client id: f_00005-7-0 loss: 0.637995  [   32/  146]
train() client id: f_00005-7-1 loss: 0.330904  [   64/  146]
train() client id: f_00005-7-2 loss: 0.733860  [   96/  146]
train() client id: f_00005-7-3 loss: 0.840590  [  128/  146]
train() client id: f_00005-8-0 loss: 0.747943  [   32/  146]
train() client id: f_00005-8-1 loss: 0.760617  [   64/  146]
train() client id: f_00005-8-2 loss: 0.534653  [   96/  146]
train() client id: f_00005-8-3 loss: 0.633819  [  128/  146]
train() client id: f_00005-9-0 loss: 0.623421  [   32/  146]
train() client id: f_00005-9-1 loss: 0.963612  [   64/  146]
train() client id: f_00005-9-2 loss: 0.651012  [   96/  146]
train() client id: f_00005-9-3 loss: 0.515758  [  128/  146]
train() client id: f_00005-10-0 loss: 0.620847  [   32/  146]
train() client id: f_00005-10-1 loss: 0.769176  [   64/  146]
train() client id: f_00005-10-2 loss: 0.561203  [   96/  146]
train() client id: f_00005-10-3 loss: 0.799997  [  128/  146]
train() client id: f_00005-11-0 loss: 0.657433  [   32/  146]
train() client id: f_00005-11-1 loss: 0.677101  [   64/  146]
train() client id: f_00005-11-2 loss: 0.835580  [   96/  146]
train() client id: f_00005-11-3 loss: 0.489257  [  128/  146]
train() client id: f_00005-12-0 loss: 0.648564  [   32/  146]
train() client id: f_00005-12-1 loss: 0.533314  [   64/  146]
train() client id: f_00005-12-2 loss: 0.711313  [   96/  146]
train() client id: f_00005-12-3 loss: 0.852170  [  128/  146]
train() client id: f_00006-0-0 loss: 0.504466  [   32/   54]
train() client id: f_00006-1-0 loss: 0.527689  [   32/   54]
train() client id: f_00006-2-0 loss: 0.581737  [   32/   54]
train() client id: f_00006-3-0 loss: 0.525854  [   32/   54]
train() client id: f_00006-4-0 loss: 0.572248  [   32/   54]
train() client id: f_00006-5-0 loss: 0.566092  [   32/   54]
train() client id: f_00006-6-0 loss: 0.571263  [   32/   54]
train() client id: f_00006-7-0 loss: 0.451063  [   32/   54]
train() client id: f_00006-8-0 loss: 0.486125  [   32/   54]
train() client id: f_00006-9-0 loss: 0.558403  [   32/   54]
train() client id: f_00006-10-0 loss: 0.519246  [   32/   54]
train() client id: f_00006-11-0 loss: 0.566175  [   32/   54]
train() client id: f_00006-12-0 loss: 0.551828  [   32/   54]
train() client id: f_00007-0-0 loss: 0.787690  [   32/  179]
train() client id: f_00007-0-1 loss: 0.594980  [   64/  179]
train() client id: f_00007-0-2 loss: 0.674798  [   96/  179]
train() client id: f_00007-0-3 loss: 0.517078  [  128/  179]
train() client id: f_00007-0-4 loss: 0.643872  [  160/  179]
train() client id: f_00007-1-0 loss: 0.583134  [   32/  179]
train() client id: f_00007-1-1 loss: 0.488156  [   64/  179]
train() client id: f_00007-1-2 loss: 0.727774  [   96/  179]
train() client id: f_00007-1-3 loss: 0.733352  [  128/  179]
train() client id: f_00007-1-4 loss: 0.685524  [  160/  179]
train() client id: f_00007-2-0 loss: 0.767189  [   32/  179]
train() client id: f_00007-2-1 loss: 0.531130  [   64/  179]
train() client id: f_00007-2-2 loss: 0.546856  [   96/  179]
train() client id: f_00007-2-3 loss: 0.605164  [  128/  179]
train() client id: f_00007-2-4 loss: 0.698497  [  160/  179]
train() client id: f_00007-3-0 loss: 0.918813  [   32/  179]
train() client id: f_00007-3-1 loss: 0.562121  [   64/  179]
train() client id: f_00007-3-2 loss: 0.700657  [   96/  179]
train() client id: f_00007-3-3 loss: 0.492472  [  128/  179]
train() client id: f_00007-3-4 loss: 0.442431  [  160/  179]
train() client id: f_00007-4-0 loss: 0.626061  [   32/  179]
train() client id: f_00007-4-1 loss: 0.609060  [   64/  179]
train() client id: f_00007-4-2 loss: 0.684801  [   96/  179]
train() client id: f_00007-4-3 loss: 0.523174  [  128/  179]
train() client id: f_00007-4-4 loss: 0.518956  [  160/  179]
train() client id: f_00007-5-0 loss: 0.604615  [   32/  179]
train() client id: f_00007-5-1 loss: 0.629454  [   64/  179]
train() client id: f_00007-5-2 loss: 0.550619  [   96/  179]
train() client id: f_00007-5-3 loss: 0.531379  [  128/  179]
train() client id: f_00007-5-4 loss: 0.771350  [  160/  179]
train() client id: f_00007-6-0 loss: 0.528841  [   32/  179]
train() client id: f_00007-6-1 loss: 0.479597  [   64/  179]
train() client id: f_00007-6-2 loss: 0.472683  [   96/  179]
train() client id: f_00007-6-3 loss: 0.877786  [  128/  179]
train() client id: f_00007-6-4 loss: 0.619749  [  160/  179]
train() client id: f_00007-7-0 loss: 0.561274  [   32/  179]
train() client id: f_00007-7-1 loss: 0.771043  [   64/  179]
train() client id: f_00007-7-2 loss: 0.512854  [   96/  179]
train() client id: f_00007-7-3 loss: 0.557808  [  128/  179]
train() client id: f_00007-7-4 loss: 0.483847  [  160/  179]
train() client id: f_00007-8-0 loss: 0.522359  [   32/  179]
train() client id: f_00007-8-1 loss: 0.679423  [   64/  179]
train() client id: f_00007-8-2 loss: 0.514541  [   96/  179]
train() client id: f_00007-8-3 loss: 0.454329  [  128/  179]
train() client id: f_00007-8-4 loss: 0.819421  [  160/  179]
train() client id: f_00007-9-0 loss: 0.576675  [   32/  179]
train() client id: f_00007-9-1 loss: 0.514831  [   64/  179]
train() client id: f_00007-9-2 loss: 0.440740  [   96/  179]
train() client id: f_00007-9-3 loss: 0.544994  [  128/  179]
train() client id: f_00007-9-4 loss: 0.613446  [  160/  179]
train() client id: f_00007-10-0 loss: 0.572410  [   32/  179]
train() client id: f_00007-10-1 loss: 0.407750  [   64/  179]
train() client id: f_00007-10-2 loss: 0.777680  [   96/  179]
train() client id: f_00007-10-3 loss: 0.413470  [  128/  179]
train() client id: f_00007-10-4 loss: 0.638777  [  160/  179]
train() client id: f_00007-11-0 loss: 0.632006  [   32/  179]
train() client id: f_00007-11-1 loss: 0.586120  [   64/  179]
train() client id: f_00007-11-2 loss: 0.522625  [   96/  179]
train() client id: f_00007-11-3 loss: 0.589669  [  128/  179]
train() client id: f_00007-11-4 loss: 0.541594  [  160/  179]
train() client id: f_00007-12-0 loss: 0.585595  [   32/  179]
train() client id: f_00007-12-1 loss: 0.620772  [   64/  179]
train() client id: f_00007-12-2 loss: 0.544024  [   96/  179]
train() client id: f_00007-12-3 loss: 0.438165  [  128/  179]
train() client id: f_00007-12-4 loss: 0.670531  [  160/  179]
train() client id: f_00008-0-0 loss: 0.816688  [   32/  130]
train() client id: f_00008-0-1 loss: 0.829220  [   64/  130]
train() client id: f_00008-0-2 loss: 0.727106  [   96/  130]
train() client id: f_00008-0-3 loss: 0.557335  [  128/  130]
train() client id: f_00008-1-0 loss: 0.661651  [   32/  130]
train() client id: f_00008-1-1 loss: 0.728453  [   64/  130]
train() client id: f_00008-1-2 loss: 0.839226  [   96/  130]
train() client id: f_00008-1-3 loss: 0.687315  [  128/  130]
train() client id: f_00008-2-0 loss: 0.741138  [   32/  130]
train() client id: f_00008-2-1 loss: 0.591087  [   64/  130]
train() client id: f_00008-2-2 loss: 0.869203  [   96/  130]
train() client id: f_00008-2-3 loss: 0.721494  [  128/  130]
train() client id: f_00008-3-0 loss: 0.709618  [   32/  130]
train() client id: f_00008-3-1 loss: 0.803262  [   64/  130]
train() client id: f_00008-3-2 loss: 0.752944  [   96/  130]
train() client id: f_00008-3-3 loss: 0.654554  [  128/  130]
train() client id: f_00008-4-0 loss: 0.709069  [   32/  130]
train() client id: f_00008-4-1 loss: 0.721441  [   64/  130]
train() client id: f_00008-4-2 loss: 0.710984  [   96/  130]
train() client id: f_00008-4-3 loss: 0.792770  [  128/  130]
train() client id: f_00008-5-0 loss: 0.827619  [   32/  130]
train() client id: f_00008-5-1 loss: 0.811661  [   64/  130]
train() client id: f_00008-5-2 loss: 0.591367  [   96/  130]
train() client id: f_00008-5-3 loss: 0.672967  [  128/  130]
train() client id: f_00008-6-0 loss: 0.764027  [   32/  130]
train() client id: f_00008-6-1 loss: 0.668456  [   64/  130]
train() client id: f_00008-6-2 loss: 0.761527  [   96/  130]
train() client id: f_00008-6-3 loss: 0.732386  [  128/  130]
train() client id: f_00008-7-0 loss: 0.724708  [   32/  130]
train() client id: f_00008-7-1 loss: 0.784700  [   64/  130]
train() client id: f_00008-7-2 loss: 0.702569  [   96/  130]
train() client id: f_00008-7-3 loss: 0.682928  [  128/  130]
train() client id: f_00008-8-0 loss: 0.781477  [   32/  130]
train() client id: f_00008-8-1 loss: 0.651041  [   64/  130]
train() client id: f_00008-8-2 loss: 0.746414  [   96/  130]
train() client id: f_00008-8-3 loss: 0.733611  [  128/  130]
train() client id: f_00008-9-0 loss: 0.740106  [   32/  130]
train() client id: f_00008-9-1 loss: 0.698434  [   64/  130]
train() client id: f_00008-9-2 loss: 0.817045  [   96/  130]
train() client id: f_00008-9-3 loss: 0.662854  [  128/  130]
train() client id: f_00008-10-0 loss: 0.756329  [   32/  130]
train() client id: f_00008-10-1 loss: 0.680844  [   64/  130]
train() client id: f_00008-10-2 loss: 0.776137  [   96/  130]
train() client id: f_00008-10-3 loss: 0.702737  [  128/  130]
train() client id: f_00008-11-0 loss: 0.737923  [   32/  130]
train() client id: f_00008-11-1 loss: 0.776522  [   64/  130]
train() client id: f_00008-11-2 loss: 0.690045  [   96/  130]
train() client id: f_00008-11-3 loss: 0.727930  [  128/  130]
train() client id: f_00008-12-0 loss: 0.664697  [   32/  130]
train() client id: f_00008-12-1 loss: 0.858446  [   64/  130]
train() client id: f_00008-12-2 loss: 0.631786  [   96/  130]
train() client id: f_00008-12-3 loss: 0.779131  [  128/  130]
train() client id: f_00009-0-0 loss: 0.975510  [   32/  118]
train() client id: f_00009-0-1 loss: 1.034899  [   64/  118]
train() client id: f_00009-0-2 loss: 0.947228  [   96/  118]
train() client id: f_00009-1-0 loss: 0.954573  [   32/  118]
train() client id: f_00009-1-1 loss: 1.077345  [   64/  118]
train() client id: f_00009-1-2 loss: 0.964902  [   96/  118]
train() client id: f_00009-2-0 loss: 0.985244  [   32/  118]
train() client id: f_00009-2-1 loss: 0.779799  [   64/  118]
train() client id: f_00009-2-2 loss: 0.828437  [   96/  118]
train() client id: f_00009-3-0 loss: 0.895501  [   32/  118]
train() client id: f_00009-3-1 loss: 0.854092  [   64/  118]
train() client id: f_00009-3-2 loss: 0.919998  [   96/  118]
train() client id: f_00009-4-0 loss: 0.812957  [   32/  118]
train() client id: f_00009-4-1 loss: 0.805162  [   64/  118]
train() client id: f_00009-4-2 loss: 0.899529  [   96/  118]
train() client id: f_00009-5-0 loss: 0.918877  [   32/  118]
train() client id: f_00009-5-1 loss: 0.764728  [   64/  118]
train() client id: f_00009-5-2 loss: 0.632258  [   96/  118]
train() client id: f_00009-6-0 loss: 0.704487  [   32/  118]
train() client id: f_00009-6-1 loss: 0.751365  [   64/  118]
train() client id: f_00009-6-2 loss: 0.835313  [   96/  118]
train() client id: f_00009-7-0 loss: 0.680126  [   32/  118]
train() client id: f_00009-7-1 loss: 0.676062  [   64/  118]
train() client id: f_00009-7-2 loss: 0.844132  [   96/  118]
train() client id: f_00009-8-0 loss: 0.758087  [   32/  118]
train() client id: f_00009-8-1 loss: 0.721543  [   64/  118]
train() client id: f_00009-8-2 loss: 0.693463  [   96/  118]
train() client id: f_00009-9-0 loss: 0.663358  [   32/  118]
train() client id: f_00009-9-1 loss: 0.815533  [   64/  118]
train() client id: f_00009-9-2 loss: 0.564230  [   96/  118]
train() client id: f_00009-10-0 loss: 0.704597  [   32/  118]
train() client id: f_00009-10-1 loss: 0.764273  [   64/  118]
train() client id: f_00009-10-2 loss: 0.593155  [   96/  118]
train() client id: f_00009-11-0 loss: 0.834091  [   32/  118]
train() client id: f_00009-11-1 loss: 0.627351  [   64/  118]
train() client id: f_00009-11-2 loss: 0.671393  [   96/  118]
train() client id: f_00009-12-0 loss: 0.791964  [   32/  118]
train() client id: f_00009-12-1 loss: 0.624085  [   64/  118]
train() client id: f_00009-12-2 loss: 0.708728  [   96/  118]
At round 44 accuracy: 0.6445623342175066
At round 44 training accuracy: 0.5855130784708249
At round 44 training loss: 0.8434885455190921
gradient difference: 0.4285246729850769
train() client id: f_00000-0-0 loss: 0.893859  [   32/  126]
train() client id: f_00000-0-1 loss: 1.206105  [   64/  126]
train() client id: f_00000-0-2 loss: 0.800185  [   96/  126]
train() client id: f_00000-1-0 loss: 0.897337  [   32/  126]
train() client id: f_00000-1-1 loss: 0.899338  [   64/  126]
train() client id: f_00000-1-2 loss: 1.058042  [   96/  126]
train() client id: f_00000-2-0 loss: 0.835990  [   32/  126]
train() client id: f_00000-2-1 loss: 0.972033  [   64/  126]
train() client id: f_00000-2-2 loss: 0.866700  [   96/  126]
train() client id: f_00000-3-0 loss: 1.004425  [   32/  126]
train() client id: f_00000-3-1 loss: 0.744002  [   64/  126]
train() client id: f_00000-3-2 loss: 0.886516  [   96/  126]
train() client id: f_00000-4-0 loss: 0.836305  [   32/  126]
train() client id: f_00000-4-1 loss: 0.842769  [   64/  126]
train() client id: f_00000-4-2 loss: 0.819047  [   96/  126]
train() client id: f_00000-5-0 loss: 0.842841  [   32/  126]
train() client id: f_00000-5-1 loss: 0.830735  [   64/  126]
train() client id: f_00000-5-2 loss: 0.757008  [   96/  126]
train() client id: f_00000-6-0 loss: 0.801392  [   32/  126]
train() client id: f_00000-6-1 loss: 0.908903  [   64/  126]
train() client id: f_00000-6-2 loss: 0.759112  [   96/  126]
train() client id: f_00000-7-0 loss: 0.902665  [   32/  126]
train() client id: f_00000-7-1 loss: 0.757893  [   64/  126]
train() client id: f_00000-7-2 loss: 0.745089  [   96/  126]
train() client id: f_00000-8-0 loss: 0.747187  [   32/  126]
train() client id: f_00000-8-1 loss: 0.717634  [   64/  126]
train() client id: f_00000-8-2 loss: 0.813037  [   96/  126]
train() client id: f_00000-9-0 loss: 0.791895  [   32/  126]
train() client id: f_00000-9-1 loss: 0.798888  [   64/  126]
train() client id: f_00000-9-2 loss: 0.812164  [   96/  126]
train() client id: f_00000-10-0 loss: 0.891150  [   32/  126]
train() client id: f_00000-10-1 loss: 0.891239  [   64/  126]
train() client id: f_00000-10-2 loss: 0.643111  [   96/  126]
train() client id: f_00000-11-0 loss: 0.757449  [   32/  126]
train() client id: f_00000-11-1 loss: 0.824553  [   64/  126]
train() client id: f_00000-11-2 loss: 0.724693  [   96/  126]
train() client id: f_00000-12-0 loss: 0.724933  [   32/  126]
train() client id: f_00000-12-1 loss: 0.804712  [   64/  126]
train() client id: f_00000-12-2 loss: 0.863303  [   96/  126]
train() client id: f_00001-0-0 loss: 0.572288  [   32/  265]
train() client id: f_00001-0-1 loss: 0.425177  [   64/  265]
train() client id: f_00001-0-2 loss: 0.596730  [   96/  265]
train() client id: f_00001-0-3 loss: 0.444408  [  128/  265]
train() client id: f_00001-0-4 loss: 0.521818  [  160/  265]
train() client id: f_00001-0-5 loss: 0.518399  [  192/  265]
train() client id: f_00001-0-6 loss: 0.517439  [  224/  265]
train() client id: f_00001-0-7 loss: 0.485173  [  256/  265]
train() client id: f_00001-1-0 loss: 0.436635  [   32/  265]
train() client id: f_00001-1-1 loss: 0.459890  [   64/  265]
train() client id: f_00001-1-2 loss: 0.521772  [   96/  265]
train() client id: f_00001-1-3 loss: 0.485111  [  128/  265]
train() client id: f_00001-1-4 loss: 0.621436  [  160/  265]
train() client id: f_00001-1-5 loss: 0.490663  [  192/  265]
train() client id: f_00001-1-6 loss: 0.526012  [  224/  265]
train() client id: f_00001-1-7 loss: 0.516447  [  256/  265]
train() client id: f_00001-2-0 loss: 0.536201  [   32/  265]
train() client id: f_00001-2-1 loss: 0.507610  [   64/  265]
train() client id: f_00001-2-2 loss: 0.489550  [   96/  265]
train() client id: f_00001-2-3 loss: 0.515516  [  128/  265]
train() client id: f_00001-2-4 loss: 0.512533  [  160/  265]
train() client id: f_00001-2-5 loss: 0.571554  [  192/  265]
train() client id: f_00001-2-6 loss: 0.455846  [  224/  265]
train() client id: f_00001-2-7 loss: 0.396693  [  256/  265]
train() client id: f_00001-3-0 loss: 0.398381  [   32/  265]
train() client id: f_00001-3-1 loss: 0.485960  [   64/  265]
train() client id: f_00001-3-2 loss: 0.405075  [   96/  265]
train() client id: f_00001-3-3 loss: 0.470115  [  128/  265]
train() client id: f_00001-3-4 loss: 0.482491  [  160/  265]
train() client id: f_00001-3-5 loss: 0.507345  [  192/  265]
train() client id: f_00001-3-6 loss: 0.702210  [  224/  265]
train() client id: f_00001-3-7 loss: 0.547942  [  256/  265]
train() client id: f_00001-4-0 loss: 0.570011  [   32/  265]
train() client id: f_00001-4-1 loss: 0.407166  [   64/  265]
train() client id: f_00001-4-2 loss: 0.444211  [   96/  265]
train() client id: f_00001-4-3 loss: 0.458251  [  128/  265]
train() client id: f_00001-4-4 loss: 0.416344  [  160/  265]
train() client id: f_00001-4-5 loss: 0.456694  [  192/  265]
train() client id: f_00001-4-6 loss: 0.409026  [  224/  265]
train() client id: f_00001-4-7 loss: 0.598399  [  256/  265]
train() client id: f_00001-5-0 loss: 0.599244  [   32/  265]
train() client id: f_00001-5-1 loss: 0.415829  [   64/  265]
train() client id: f_00001-5-2 loss: 0.434242  [   96/  265]
train() client id: f_00001-5-3 loss: 0.594688  [  128/  265]
train() client id: f_00001-5-4 loss: 0.410207  [  160/  265]
train() client id: f_00001-5-5 loss: 0.491086  [  192/  265]
train() client id: f_00001-5-6 loss: 0.540959  [  224/  265]
train() client id: f_00001-5-7 loss: 0.481879  [  256/  265]
train() client id: f_00001-6-0 loss: 0.481271  [   32/  265]
train() client id: f_00001-6-1 loss: 0.451609  [   64/  265]
train() client id: f_00001-6-2 loss: 0.465150  [   96/  265]
train() client id: f_00001-6-3 loss: 0.470606  [  128/  265]
train() client id: f_00001-6-4 loss: 0.454612  [  160/  265]
train() client id: f_00001-6-5 loss: 0.496049  [  192/  265]
train() client id: f_00001-6-6 loss: 0.486718  [  224/  265]
train() client id: f_00001-6-7 loss: 0.485605  [  256/  265]
train() client id: f_00001-7-0 loss: 0.507977  [   32/  265]
train() client id: f_00001-7-1 loss: 0.457237  [   64/  265]
train() client id: f_00001-7-2 loss: 0.402995  [   96/  265]
train() client id: f_00001-7-3 loss: 0.437970  [  128/  265]
train() client id: f_00001-7-4 loss: 0.711294  [  160/  265]
train() client id: f_00001-7-5 loss: 0.455921  [  192/  265]
train() client id: f_00001-7-6 loss: 0.408769  [  224/  265]
train() client id: f_00001-7-7 loss: 0.480939  [  256/  265]
train() client id: f_00001-8-0 loss: 0.389548  [   32/  265]
train() client id: f_00001-8-1 loss: 0.624942  [   64/  265]
train() client id: f_00001-8-2 loss: 0.474356  [   96/  265]
train() client id: f_00001-8-3 loss: 0.466053  [  128/  265]
train() client id: f_00001-8-4 loss: 0.475348  [  160/  265]
train() client id: f_00001-8-5 loss: 0.474764  [  192/  265]
train() client id: f_00001-8-6 loss: 0.506755  [  224/  265]
train() client id: f_00001-8-7 loss: 0.550416  [  256/  265]
train() client id: f_00001-9-0 loss: 0.567129  [   32/  265]
train() client id: f_00001-9-1 loss: 0.532131  [   64/  265]
train() client id: f_00001-9-2 loss: 0.397258  [   96/  265]
train() client id: f_00001-9-3 loss: 0.461377  [  128/  265]
train() client id: f_00001-9-4 loss: 0.572955  [  160/  265]
train() client id: f_00001-9-5 loss: 0.416830  [  192/  265]
train() client id: f_00001-9-6 loss: 0.510571  [  224/  265]
train() client id: f_00001-9-7 loss: 0.504655  [  256/  265]
train() client id: f_00001-10-0 loss: 0.407596  [   32/  265]
train() client id: f_00001-10-1 loss: 0.649397  [   64/  265]
train() client id: f_00001-10-2 loss: 0.567510  [   96/  265]
train() client id: f_00001-10-3 loss: 0.385826  [  128/  265]
train() client id: f_00001-10-4 loss: 0.408403  [  160/  265]
train() client id: f_00001-10-5 loss: 0.557020  [  192/  265]
train() client id: f_00001-10-6 loss: 0.402871  [  224/  265]
train() client id: f_00001-10-7 loss: 0.592262  [  256/  265]
train() client id: f_00001-11-0 loss: 0.450911  [   32/  265]
train() client id: f_00001-11-1 loss: 0.483495  [   64/  265]
train() client id: f_00001-11-2 loss: 0.544086  [   96/  265]
train() client id: f_00001-11-3 loss: 0.505533  [  128/  265]
train() client id: f_00001-11-4 loss: 0.552319  [  160/  265]
train() client id: f_00001-11-5 loss: 0.557319  [  192/  265]
train() client id: f_00001-11-6 loss: 0.409321  [  224/  265]
train() client id: f_00001-11-7 loss: 0.408719  [  256/  265]
train() client id: f_00001-12-0 loss: 0.425700  [   32/  265]
train() client id: f_00001-12-1 loss: 0.503975  [   64/  265]
train() client id: f_00001-12-2 loss: 0.484773  [   96/  265]
train() client id: f_00001-12-3 loss: 0.457611  [  128/  265]
train() client id: f_00001-12-4 loss: 0.502673  [  160/  265]
train() client id: f_00001-12-5 loss: 0.580543  [  192/  265]
train() client id: f_00001-12-6 loss: 0.609740  [  224/  265]
train() client id: f_00001-12-7 loss: 0.404581  [  256/  265]
train() client id: f_00002-0-0 loss: 1.117420  [   32/  124]
train() client id: f_00002-0-1 loss: 1.386828  [   64/  124]
train() client id: f_00002-0-2 loss: 1.353611  [   96/  124]
train() client id: f_00002-1-0 loss: 1.433495  [   32/  124]
train() client id: f_00002-1-1 loss: 1.199256  [   64/  124]
train() client id: f_00002-1-2 loss: 1.147009  [   96/  124]
train() client id: f_00002-2-0 loss: 1.235018  [   32/  124]
train() client id: f_00002-2-1 loss: 0.975756  [   64/  124]
train() client id: f_00002-2-2 loss: 1.217491  [   96/  124]
train() client id: f_00002-3-0 loss: 1.112887  [   32/  124]
train() client id: f_00002-3-1 loss: 1.141126  [   64/  124]
train() client id: f_00002-3-2 loss: 1.202118  [   96/  124]
train() client id: f_00002-4-0 loss: 1.379352  [   32/  124]
train() client id: f_00002-4-1 loss: 1.059490  [   64/  124]
train() client id: f_00002-4-2 loss: 1.025220  [   96/  124]
train() client id: f_00002-5-0 loss: 1.013430  [   32/  124]
train() client id: f_00002-5-1 loss: 1.260490  [   64/  124]
train() client id: f_00002-5-2 loss: 1.000362  [   96/  124]
train() client id: f_00002-6-0 loss: 1.130272  [   32/  124]
train() client id: f_00002-6-1 loss: 0.998198  [   64/  124]
train() client id: f_00002-6-2 loss: 1.167995  [   96/  124]
train() client id: f_00002-7-0 loss: 1.116423  [   32/  124]
train() client id: f_00002-7-1 loss: 1.010393  [   64/  124]
train() client id: f_00002-7-2 loss: 0.974059  [   96/  124]
train() client id: f_00002-8-0 loss: 1.007826  [   32/  124]
train() client id: f_00002-8-1 loss: 1.138835  [   64/  124]
train() client id: f_00002-8-2 loss: 0.893872  [   96/  124]
train() client id: f_00002-9-0 loss: 1.154318  [   32/  124]
train() client id: f_00002-9-1 loss: 1.009086  [   64/  124]
train() client id: f_00002-9-2 loss: 0.938148  [   96/  124]
train() client id: f_00002-10-0 loss: 0.989307  [   32/  124]
train() client id: f_00002-10-1 loss: 0.901670  [   64/  124]
train() client id: f_00002-10-2 loss: 1.205519  [   96/  124]
train() client id: f_00002-11-0 loss: 0.996176  [   32/  124]
train() client id: f_00002-11-1 loss: 1.078223  [   64/  124]
train() client id: f_00002-11-2 loss: 1.053411  [   96/  124]
train() client id: f_00002-12-0 loss: 0.938835  [   32/  124]
train() client id: f_00002-12-1 loss: 1.024120  [   64/  124]
train() client id: f_00002-12-2 loss: 0.990371  [   96/  124]
train() client id: f_00003-0-0 loss: 0.676244  [   32/   43]
train() client id: f_00003-1-0 loss: 0.597409  [   32/   43]
train() client id: f_00003-2-0 loss: 0.504213  [   32/   43]
train() client id: f_00003-3-0 loss: 0.580372  [   32/   43]
train() client id: f_00003-4-0 loss: 0.571761  [   32/   43]
train() client id: f_00003-5-0 loss: 0.500033  [   32/   43]
train() client id: f_00003-6-0 loss: 0.479687  [   32/   43]
train() client id: f_00003-7-0 loss: 0.616506  [   32/   43]
train() client id: f_00003-8-0 loss: 0.479790  [   32/   43]
train() client id: f_00003-9-0 loss: 0.455150  [   32/   43]
train() client id: f_00003-10-0 loss: 0.448341  [   32/   43]
train() client id: f_00003-11-0 loss: 0.507406  [   32/   43]
train() client id: f_00003-12-0 loss: 0.571660  [   32/   43]
train() client id: f_00004-0-0 loss: 0.607272  [   32/  306]
train() client id: f_00004-0-1 loss: 0.728717  [   64/  306]
train() client id: f_00004-0-2 loss: 0.768834  [   96/  306]
train() client id: f_00004-0-3 loss: 0.794250  [  128/  306]
train() client id: f_00004-0-4 loss: 0.749437  [  160/  306]
train() client id: f_00004-0-5 loss: 0.803903  [  192/  306]
train() client id: f_00004-0-6 loss: 0.748025  [  224/  306]
train() client id: f_00004-0-7 loss: 0.795720  [  256/  306]
train() client id: f_00004-0-8 loss: 0.738061  [  288/  306]
train() client id: f_00004-1-0 loss: 0.689623  [   32/  306]
train() client id: f_00004-1-1 loss: 0.719308  [   64/  306]
train() client id: f_00004-1-2 loss: 0.709050  [   96/  306]
train() client id: f_00004-1-3 loss: 0.791832  [  128/  306]
train() client id: f_00004-1-4 loss: 0.832605  [  160/  306]
train() client id: f_00004-1-5 loss: 0.773383  [  192/  306]
train() client id: f_00004-1-6 loss: 0.687442  [  224/  306]
train() client id: f_00004-1-7 loss: 0.662442  [  256/  306]
train() client id: f_00004-1-8 loss: 0.863917  [  288/  306]
train() client id: f_00004-2-0 loss: 0.745898  [   32/  306]
train() client id: f_00004-2-1 loss: 0.751799  [   64/  306]
train() client id: f_00004-2-2 loss: 0.777071  [   96/  306]
train() client id: f_00004-2-3 loss: 0.739889  [  128/  306]
train() client id: f_00004-2-4 loss: 0.752306  [  160/  306]
train() client id: f_00004-2-5 loss: 0.730443  [  192/  306]
train() client id: f_00004-2-6 loss: 0.658554  [  224/  306]
train() client id: f_00004-2-7 loss: 0.745328  [  256/  306]
train() client id: f_00004-2-8 loss: 0.761797  [  288/  306]
train() client id: f_00004-3-0 loss: 0.724768  [   32/  306]
train() client id: f_00004-3-1 loss: 0.599886  [   64/  306]
train() client id: f_00004-3-2 loss: 0.840030  [   96/  306]
train() client id: f_00004-3-3 loss: 0.701771  [  128/  306]
train() client id: f_00004-3-4 loss: 0.770633  [  160/  306]
train() client id: f_00004-3-5 loss: 0.705400  [  192/  306]
train() client id: f_00004-3-6 loss: 0.818595  [  224/  306]
train() client id: f_00004-3-7 loss: 0.816080  [  256/  306]
train() client id: f_00004-3-8 loss: 0.721104  [  288/  306]
train() client id: f_00004-4-0 loss: 0.765124  [   32/  306]
train() client id: f_00004-4-1 loss: 0.774067  [   64/  306]
train() client id: f_00004-4-2 loss: 0.991504  [   96/  306]
train() client id: f_00004-4-3 loss: 0.712111  [  128/  306]
train() client id: f_00004-4-4 loss: 0.665694  [  160/  306]
train() client id: f_00004-4-5 loss: 0.662914  [  192/  306]
train() client id: f_00004-4-6 loss: 0.639331  [  224/  306]
train() client id: f_00004-4-7 loss: 0.806314  [  256/  306]
train() client id: f_00004-4-8 loss: 0.744060  [  288/  306]
train() client id: f_00004-5-0 loss: 0.734676  [   32/  306]
train() client id: f_00004-5-1 loss: 0.711270  [   64/  306]
train() client id: f_00004-5-2 loss: 0.843943  [   96/  306]
train() client id: f_00004-5-3 loss: 0.688771  [  128/  306]
train() client id: f_00004-5-4 loss: 0.666002  [  160/  306]
train() client id: f_00004-5-5 loss: 0.760039  [  192/  306]
train() client id: f_00004-5-6 loss: 0.780395  [  224/  306]
train() client id: f_00004-5-7 loss: 0.741524  [  256/  306]
train() client id: f_00004-5-8 loss: 0.757305  [  288/  306]
train() client id: f_00004-6-0 loss: 0.809354  [   32/  306]
train() client id: f_00004-6-1 loss: 0.738928  [   64/  306]
train() client id: f_00004-6-2 loss: 0.820026  [   96/  306]
train() client id: f_00004-6-3 loss: 0.748776  [  128/  306]
train() client id: f_00004-6-4 loss: 0.680512  [  160/  306]
train() client id: f_00004-6-5 loss: 0.677232  [  192/  306]
train() client id: f_00004-6-6 loss: 0.759313  [  224/  306]
train() client id: f_00004-6-7 loss: 0.859009  [  256/  306]
train() client id: f_00004-6-8 loss: 0.591600  [  288/  306]
train() client id: f_00004-7-0 loss: 0.785609  [   32/  306]
train() client id: f_00004-7-1 loss: 0.685206  [   64/  306]
train() client id: f_00004-7-2 loss: 0.727263  [   96/  306]
train() client id: f_00004-7-3 loss: 0.800766  [  128/  306]
train() client id: f_00004-7-4 loss: 0.719132  [  160/  306]
train() client id: f_00004-7-5 loss: 0.763043  [  192/  306]
train() client id: f_00004-7-6 loss: 0.625437  [  224/  306]
train() client id: f_00004-7-7 loss: 0.684099  [  256/  306]
train() client id: f_00004-7-8 loss: 0.740573  [  288/  306]
train() client id: f_00004-8-0 loss: 0.788522  [   32/  306]
train() client id: f_00004-8-1 loss: 0.715915  [   64/  306]
train() client id: f_00004-8-2 loss: 0.761847  [   96/  306]
train() client id: f_00004-8-3 loss: 0.680565  [  128/  306]
train() client id: f_00004-8-4 loss: 0.736839  [  160/  306]
train() client id: f_00004-8-5 loss: 0.690669  [  192/  306]
train() client id: f_00004-8-6 loss: 0.836580  [  224/  306]
train() client id: f_00004-8-7 loss: 0.587664  [  256/  306]
train() client id: f_00004-8-8 loss: 0.888757  [  288/  306]
train() client id: f_00004-9-0 loss: 0.603687  [   32/  306]
train() client id: f_00004-9-1 loss: 0.814874  [   64/  306]
train() client id: f_00004-9-2 loss: 0.689241  [   96/  306]
train() client id: f_00004-9-3 loss: 0.744709  [  128/  306]
train() client id: f_00004-9-4 loss: 0.742478  [  160/  306]
train() client id: f_00004-9-5 loss: 0.840171  [  192/  306]
train() client id: f_00004-9-6 loss: 0.690731  [  224/  306]
train() client id: f_00004-9-7 loss: 0.777488  [  256/  306]
train() client id: f_00004-9-8 loss: 0.809633  [  288/  306]
train() client id: f_00004-10-0 loss: 0.789287  [   32/  306]
train() client id: f_00004-10-1 loss: 0.691041  [   64/  306]
train() client id: f_00004-10-2 loss: 0.798256  [   96/  306]
train() client id: f_00004-10-3 loss: 0.584790  [  128/  306]
train() client id: f_00004-10-4 loss: 0.954482  [  160/  306]
train() client id: f_00004-10-5 loss: 0.848750  [  192/  306]
train() client id: f_00004-10-6 loss: 0.733378  [  224/  306]
train() client id: f_00004-10-7 loss: 0.577862  [  256/  306]
train() client id: f_00004-10-8 loss: 0.765285  [  288/  306]
train() client id: f_00004-11-0 loss: 0.806598  [   32/  306]
train() client id: f_00004-11-1 loss: 0.701798  [   64/  306]
train() client id: f_00004-11-2 loss: 0.616957  [   96/  306]
train() client id: f_00004-11-3 loss: 0.760836  [  128/  306]
train() client id: f_00004-11-4 loss: 0.609255  [  160/  306]
train() client id: f_00004-11-5 loss: 0.730759  [  192/  306]
train() client id: f_00004-11-6 loss: 0.834209  [  224/  306]
train() client id: f_00004-11-7 loss: 0.786379  [  256/  306]
train() client id: f_00004-11-8 loss: 0.751093  [  288/  306]
train() client id: f_00004-12-0 loss: 0.820873  [   32/  306]
train() client id: f_00004-12-1 loss: 0.680778  [   64/  306]
train() client id: f_00004-12-2 loss: 0.754415  [   96/  306]
train() client id: f_00004-12-3 loss: 0.708842  [  128/  306]
train() client id: f_00004-12-4 loss: 0.764449  [  160/  306]
train() client id: f_00004-12-5 loss: 0.645457  [  192/  306]
train() client id: f_00004-12-6 loss: 0.817419  [  224/  306]
train() client id: f_00004-12-7 loss: 0.672850  [  256/  306]
train() client id: f_00004-12-8 loss: 0.809727  [  288/  306]
train() client id: f_00005-0-0 loss: 0.178195  [   32/  146]
train() client id: f_00005-0-1 loss: 0.664789  [   64/  146]
train() client id: f_00005-0-2 loss: 0.566221  [   96/  146]
train() client id: f_00005-0-3 loss: 0.353375  [  128/  146]
train() client id: f_00005-1-0 loss: 0.669428  [   32/  146]
train() client id: f_00005-1-1 loss: 0.454991  [   64/  146]
train() client id: f_00005-1-2 loss: 0.337783  [   96/  146]
train() client id: f_00005-1-3 loss: 0.357122  [  128/  146]
train() client id: f_00005-2-0 loss: 0.453402  [   32/  146]
train() client id: f_00005-2-1 loss: 0.387334  [   64/  146]
train() client id: f_00005-2-2 loss: 0.249075  [   96/  146]
train() client id: f_00005-2-3 loss: 0.658861  [  128/  146]
train() client id: f_00005-3-0 loss: 0.384566  [   32/  146]
train() client id: f_00005-3-1 loss: 0.210134  [   64/  146]
train() client id: f_00005-3-2 loss: 0.683671  [   96/  146]
train() client id: f_00005-3-3 loss: 0.467897  [  128/  146]
train() client id: f_00005-4-0 loss: 0.426422  [   32/  146]
train() client id: f_00005-4-1 loss: 0.698927  [   64/  146]
train() client id: f_00005-4-2 loss: 0.404335  [   96/  146]
train() client id: f_00005-4-3 loss: 0.198237  [  128/  146]
train() client id: f_00005-5-0 loss: 0.581062  [   32/  146]
train() client id: f_00005-5-1 loss: 0.385040  [   64/  146]
train() client id: f_00005-5-2 loss: 0.155719  [   96/  146]
train() client id: f_00005-5-3 loss: 0.395100  [  128/  146]
train() client id: f_00005-6-0 loss: 0.381854  [   32/  146]
train() client id: f_00005-6-1 loss: 0.364970  [   64/  146]
train() client id: f_00005-6-2 loss: 0.425908  [   96/  146]
train() client id: f_00005-6-3 loss: 0.555028  [  128/  146]
train() client id: f_00005-7-0 loss: 0.637454  [   32/  146]
train() client id: f_00005-7-1 loss: 0.283151  [   64/  146]
train() client id: f_00005-7-2 loss: 0.437475  [   96/  146]
train() client id: f_00005-7-3 loss: 0.186318  [  128/  146]
train() client id: f_00005-8-0 loss: 0.336402  [   32/  146]
train() client id: f_00005-8-1 loss: 0.357692  [   64/  146]
train() client id: f_00005-8-2 loss: 0.509468  [   96/  146]
train() client id: f_00005-8-3 loss: 0.337437  [  128/  146]
train() client id: f_00005-9-0 loss: 0.461031  [   32/  146]
train() client id: f_00005-9-1 loss: 0.470767  [   64/  146]
train() client id: f_00005-9-2 loss: 0.234919  [   96/  146]
train() client id: f_00005-9-3 loss: 0.464676  [  128/  146]
train() client id: f_00005-10-0 loss: 0.200385  [   32/  146]
train() client id: f_00005-10-1 loss: 0.362194  [   64/  146]
train() client id: f_00005-10-2 loss: 0.651123  [   96/  146]
train() client id: f_00005-10-3 loss: 0.522465  [  128/  146]
train() client id: f_00005-11-0 loss: 0.161848  [   32/  146]
train() client id: f_00005-11-1 loss: 0.364167  [   64/  146]
train() client id: f_00005-11-2 loss: 0.497419  [   96/  146]
train() client id: f_00005-11-3 loss: 0.579875  [  128/  146]
train() client id: f_00005-12-0 loss: 0.328824  [   32/  146]
train() client id: f_00005-12-1 loss: 0.281515  [   64/  146]
train() client id: f_00005-12-2 loss: 0.433400  [   96/  146]
train() client id: f_00005-12-3 loss: 0.402922  [  128/  146]
train() client id: f_00006-0-0 loss: 0.455501  [   32/   54]
train() client id: f_00006-1-0 loss: 0.447838  [   32/   54]
train() client id: f_00006-2-0 loss: 0.477662  [   32/   54]
train() client id: f_00006-3-0 loss: 0.507161  [   32/   54]
train() client id: f_00006-4-0 loss: 0.425052  [   32/   54]
train() client id: f_00006-5-0 loss: 0.465537  [   32/   54]
train() client id: f_00006-6-0 loss: 0.423430  [   32/   54]
train() client id: f_00006-7-0 loss: 0.520070  [   32/   54]
train() client id: f_00006-8-0 loss: 0.485238  [   32/   54]
train() client id: f_00006-9-0 loss: 0.459379  [   32/   54]
train() client id: f_00006-10-0 loss: 0.519265  [   32/   54]
train() client id: f_00006-11-0 loss: 0.504802  [   32/   54]
train() client id: f_00006-12-0 loss: 0.472781  [   32/   54]
train() client id: f_00007-0-0 loss: 0.479464  [   32/  179]
train() client id: f_00007-0-1 loss: 0.527037  [   64/  179]
train() client id: f_00007-0-2 loss: 0.493416  [   96/  179]
train() client id: f_00007-0-3 loss: 0.285356  [  128/  179]
train() client id: f_00007-0-4 loss: 0.483576  [  160/  179]
train() client id: f_00007-1-0 loss: 0.451078  [   32/  179]
train() client id: f_00007-1-1 loss: 0.399956  [   64/  179]
train() client id: f_00007-1-2 loss: 0.438509  [   96/  179]
train() client id: f_00007-1-3 loss: 0.559445  [  128/  179]
train() client id: f_00007-1-4 loss: 0.513949  [  160/  179]
train() client id: f_00007-2-0 loss: 0.471268  [   32/  179]
train() client id: f_00007-2-1 loss: 0.404572  [   64/  179]
train() client id: f_00007-2-2 loss: 0.252324  [   96/  179]
train() client id: f_00007-2-3 loss: 0.646903  [  128/  179]
train() client id: f_00007-2-4 loss: 0.361832  [  160/  179]
train() client id: f_00007-3-0 loss: 0.476872  [   32/  179]
train() client id: f_00007-3-1 loss: 0.460730  [   64/  179]
train() client id: f_00007-3-2 loss: 0.641973  [   96/  179]
train() client id: f_00007-3-3 loss: 0.286061  [  128/  179]
train() client id: f_00007-3-4 loss: 0.248979  [  160/  179]
train() client id: f_00007-4-0 loss: 0.472765  [   32/  179]
train() client id: f_00007-4-1 loss: 0.278307  [   64/  179]
train() client id: f_00007-4-2 loss: 0.528247  [   96/  179]
train() client id: f_00007-4-3 loss: 0.555318  [  128/  179]
train() client id: f_00007-4-4 loss: 0.261152  [  160/  179]
train() client id: f_00007-5-0 loss: 0.393965  [   32/  179]
train() client id: f_00007-5-1 loss: 0.485657  [   64/  179]
train() client id: f_00007-5-2 loss: 0.408011  [   96/  179]
train() client id: f_00007-5-3 loss: 0.525206  [  128/  179]
train() client id: f_00007-5-4 loss: 0.326081  [  160/  179]
train() client id: f_00007-6-0 loss: 0.359732  [   32/  179]
train() client id: f_00007-6-1 loss: 0.556363  [   64/  179]
train() client id: f_00007-6-2 loss: 0.501222  [   96/  179]
train() client id: f_00007-6-3 loss: 0.249005  [  128/  179]
train() client id: f_00007-6-4 loss: 0.441402  [  160/  179]
train() client id: f_00007-7-0 loss: 0.485398  [   32/  179]
train() client id: f_00007-7-1 loss: 0.626131  [   64/  179]
train() client id: f_00007-7-2 loss: 0.297104  [   96/  179]
train() client id: f_00007-7-3 loss: 0.311199  [  128/  179]
train() client id: f_00007-7-4 loss: 0.238484  [  160/  179]
train() client id: f_00007-8-0 loss: 0.343594  [   32/  179]
train() client id: f_00007-8-1 loss: 0.345441  [   64/  179]
train() client id: f_00007-8-2 loss: 0.520089  [   96/  179]
train() client id: f_00007-8-3 loss: 0.354676  [  128/  179]
train() client id: f_00007-8-4 loss: 0.511414  [  160/  179]
train() client id: f_00007-9-0 loss: 0.414913  [   32/  179]
train() client id: f_00007-9-1 loss: 0.523983  [   64/  179]
train() client id: f_00007-9-2 loss: 0.218809  [   96/  179]
train() client id: f_00007-9-3 loss: 0.356944  [  128/  179]
train() client id: f_00007-9-4 loss: 0.336363  [  160/  179]
train() client id: f_00007-10-0 loss: 0.465977  [   32/  179]
train() client id: f_00007-10-1 loss: 0.492422  [   64/  179]
train() client id: f_00007-10-2 loss: 0.344245  [   96/  179]
train() client id: f_00007-10-3 loss: 0.431679  [  128/  179]
train() client id: f_00007-10-4 loss: 0.324747  [  160/  179]
train() client id: f_00007-11-0 loss: 0.403577  [   32/  179]
train() client id: f_00007-11-1 loss: 0.460586  [   64/  179]
train() client id: f_00007-11-2 loss: 0.501486  [   96/  179]
train() client id: f_00007-11-3 loss: 0.257834  [  128/  179]
train() client id: f_00007-11-4 loss: 0.346835  [  160/  179]
train() client id: f_00007-12-0 loss: 0.534333  [   32/  179]
train() client id: f_00007-12-1 loss: 0.357512  [   64/  179]
train() client id: f_00007-12-2 loss: 0.241983  [   96/  179]
train() client id: f_00007-12-3 loss: 0.500484  [  128/  179]
train() client id: f_00007-12-4 loss: 0.324657  [  160/  179]
train() client id: f_00008-0-0 loss: 0.687155  [   32/  130]
train() client id: f_00008-0-1 loss: 0.739103  [   64/  130]
train() client id: f_00008-0-2 loss: 0.534197  [   96/  130]
train() client id: f_00008-0-3 loss: 0.571503  [  128/  130]
train() client id: f_00008-1-0 loss: 0.566429  [   32/  130]
train() client id: f_00008-1-1 loss: 0.655836  [   64/  130]
train() client id: f_00008-1-2 loss: 0.712655  [   96/  130]
train() client id: f_00008-1-3 loss: 0.666568  [  128/  130]
train() client id: f_00008-2-0 loss: 0.645556  [   32/  130]
train() client id: f_00008-2-1 loss: 0.638704  [   64/  130]
train() client id: f_00008-2-2 loss: 0.619116  [   96/  130]
train() client id: f_00008-2-3 loss: 0.698024  [  128/  130]
train() client id: f_00008-3-0 loss: 0.693860  [   32/  130]
train() client id: f_00008-3-1 loss: 0.711372  [   64/  130]
train() client id: f_00008-3-2 loss: 0.557168  [   96/  130]
train() client id: f_00008-3-3 loss: 0.643204  [  128/  130]
train() client id: f_00008-4-0 loss: 0.582548  [   32/  130]
train() client id: f_00008-4-1 loss: 0.733567  [   64/  130]
train() client id: f_00008-4-2 loss: 0.622696  [   96/  130]
train() client id: f_00008-4-3 loss: 0.624042  [  128/  130]
train() client id: f_00008-5-0 loss: 0.654591  [   32/  130]
train() client id: f_00008-5-1 loss: 0.598443  [   64/  130]
train() client id: f_00008-5-2 loss: 0.676766  [   96/  130]
train() client id: f_00008-5-3 loss: 0.640213  [  128/  130]
train() client id: f_00008-6-0 loss: 0.668945  [   32/  130]
train() client id: f_00008-6-1 loss: 0.611493  [   64/  130]
train() client id: f_00008-6-2 loss: 0.672775  [   96/  130]
train() client id: f_00008-6-3 loss: 0.641249  [  128/  130]
train() client id: f_00008-7-0 loss: 0.608597  [   32/  130]
train() client id: f_00008-7-1 loss: 0.644246  [   64/  130]
train() client id: f_00008-7-2 loss: 0.639094  [   96/  130]
train() client id: f_00008-7-3 loss: 0.635652  [  128/  130]
train() client id: f_00008-8-0 loss: 0.707486  [   32/  130]
train() client id: f_00008-8-1 loss: 0.608260  [   64/  130]
train() client id: f_00008-8-2 loss: 0.611234  [   96/  130]
train() client id: f_00008-8-3 loss: 0.647626  [  128/  130]
train() client id: f_00008-9-0 loss: 0.776770  [   32/  130]
train() client id: f_00008-9-1 loss: 0.573809  [   64/  130]
train() client id: f_00008-9-2 loss: 0.634822  [   96/  130]
train() client id: f_00008-9-3 loss: 0.620493  [  128/  130]
train() client id: f_00008-10-0 loss: 0.596015  [   32/  130]
train() client id: f_00008-10-1 loss: 0.680723  [   64/  130]
train() client id: f_00008-10-2 loss: 0.626771  [   96/  130]
train() client id: f_00008-10-3 loss: 0.684806  [  128/  130]
train() client id: f_00008-11-0 loss: 0.717820  [   32/  130]
train() client id: f_00008-11-1 loss: 0.562311  [   64/  130]
train() client id: f_00008-11-2 loss: 0.679758  [   96/  130]
train() client id: f_00008-11-3 loss: 0.631480  [  128/  130]
train() client id: f_00008-12-0 loss: 0.671262  [   32/  130]
train() client id: f_00008-12-1 loss: 0.588487  [   64/  130]
train() client id: f_00008-12-2 loss: 0.666714  [   96/  130]
train() client id: f_00008-12-3 loss: 0.651474  [  128/  130]
train() client id: f_00009-0-0 loss: 1.024196  [   32/  118]
train() client id: f_00009-0-1 loss: 1.059221  [   64/  118]
train() client id: f_00009-0-2 loss: 1.036775  [   96/  118]
train() client id: f_00009-1-0 loss: 1.003608  [   32/  118]
train() client id: f_00009-1-1 loss: 0.902042  [   64/  118]
train() client id: f_00009-1-2 loss: 0.961810  [   96/  118]
train() client id: f_00009-2-0 loss: 1.046358  [   32/  118]
train() client id: f_00009-2-1 loss: 0.938940  [   64/  118]
train() client id: f_00009-2-2 loss: 0.885520  [   96/  118]
train() client id: f_00009-3-0 loss: 0.851698  [   32/  118]
train() client id: f_00009-3-1 loss: 0.946782  [   64/  118]
train() client id: f_00009-3-2 loss: 0.958618  [   96/  118]
train() client id: f_00009-4-0 loss: 0.935252  [   32/  118]
train() client id: f_00009-4-1 loss: 0.883068  [   64/  118]
train() client id: f_00009-4-2 loss: 0.987328  [   96/  118]
train() client id: f_00009-5-0 loss: 0.829173  [   32/  118]
train() client id: f_00009-5-1 loss: 0.886572  [   64/  118]
train() client id: f_00009-5-2 loss: 0.896908  [   96/  118]
train() client id: f_00009-6-0 loss: 0.917245  [   32/  118]
train() client id: f_00009-6-1 loss: 0.844138  [   64/  118]
train() client id: f_00009-6-2 loss: 0.799859  [   96/  118]
train() client id: f_00009-7-0 loss: 0.828762  [   32/  118]
train() client id: f_00009-7-1 loss: 0.797860  [   64/  118]
train() client id: f_00009-7-2 loss: 0.827244  [   96/  118]
train() client id: f_00009-8-0 loss: 0.742065  [   32/  118]
train() client id: f_00009-8-1 loss: 1.058297  [   64/  118]
train() client id: f_00009-8-2 loss: 0.648639  [   96/  118]
train() client id: f_00009-9-0 loss: 0.813413  [   32/  118]
train() client id: f_00009-9-1 loss: 0.736191  [   64/  118]
train() client id: f_00009-9-2 loss: 0.797053  [   96/  118]
train() client id: f_00009-10-0 loss: 1.004288  [   32/  118]
train() client id: f_00009-10-1 loss: 0.719211  [   64/  118]
train() client id: f_00009-10-2 loss: 0.662865  [   96/  118]
train() client id: f_00009-11-0 loss: 0.730190  [   32/  118]
train() client id: f_00009-11-1 loss: 0.757127  [   64/  118]
train() client id: f_00009-11-2 loss: 0.904668  [   96/  118]
train() client id: f_00009-12-0 loss: 0.639122  [   32/  118]
train() client id: f_00009-12-1 loss: 0.874318  [   64/  118]
train() client id: f_00009-12-2 loss: 0.851877  [   96/  118]
At round 45 accuracy: 0.6445623342175066
At round 45 training accuracy: 0.5868544600938967
At round 45 training loss: 0.8341159030582723
gradient difference: 0.38348454236984253
train() client id: f_00000-0-0 loss: 0.923340  [   32/  126]
train() client id: f_00000-0-1 loss: 0.963294  [   64/  126]
train() client id: f_00000-0-2 loss: 1.250011  [   96/  126]
train() client id: f_00000-1-0 loss: 1.121230  [   32/  126]
train() client id: f_00000-1-1 loss: 0.954538  [   64/  126]
train() client id: f_00000-1-2 loss: 1.036020  [   96/  126]
train() client id: f_00000-2-0 loss: 0.856110  [   32/  126]
train() client id: f_00000-2-1 loss: 0.961034  [   64/  126]
train() client id: f_00000-2-2 loss: 0.978030  [   96/  126]
train() client id: f_00000-3-0 loss: 1.042292  [   32/  126]
train() client id: f_00000-3-1 loss: 0.860293  [   64/  126]
train() client id: f_00000-3-2 loss: 0.855273  [   96/  126]
train() client id: f_00000-4-0 loss: 0.836365  [   32/  126]
train() client id: f_00000-4-1 loss: 0.915543  [   64/  126]
train() client id: f_00000-4-2 loss: 0.767524  [   96/  126]
train() client id: f_00000-5-0 loss: 0.828777  [   32/  126]
train() client id: f_00000-5-1 loss: 0.699007  [   64/  126]
train() client id: f_00000-5-2 loss: 0.917179  [   96/  126]
train() client id: f_00000-6-0 loss: 0.675861  [   32/  126]
train() client id: f_00000-6-1 loss: 0.829902  [   64/  126]
train() client id: f_00000-6-2 loss: 0.715702  [   96/  126]
train() client id: f_00000-7-0 loss: 0.776520  [   32/  126]
train() client id: f_00000-7-1 loss: 0.853005  [   64/  126]
train() client id: f_00000-7-2 loss: 0.721544  [   96/  126]
train() client id: f_00000-8-0 loss: 0.701669  [   32/  126]
train() client id: f_00000-8-1 loss: 0.842992  [   64/  126]
train() client id: f_00000-8-2 loss: 0.748631  [   96/  126]
train() client id: f_00000-9-0 loss: 0.616264  [   32/  126]
train() client id: f_00000-9-1 loss: 0.827964  [   64/  126]
train() client id: f_00000-9-2 loss: 0.702393  [   96/  126]
train() client id: f_00000-10-0 loss: 0.661463  [   32/  126]
train() client id: f_00000-10-1 loss: 0.808906  [   64/  126]
train() client id: f_00000-10-2 loss: 0.697453  [   96/  126]
train() client id: f_00000-11-0 loss: 0.686465  [   32/  126]
train() client id: f_00000-11-1 loss: 0.751786  [   64/  126]
train() client id: f_00000-11-2 loss: 0.668398  [   96/  126]
train() client id: f_00000-12-0 loss: 0.695535  [   32/  126]
train() client id: f_00000-12-1 loss: 0.659235  [   64/  126]
train() client id: f_00000-12-2 loss: 0.893835  [   96/  126]
train() client id: f_00001-0-0 loss: 0.538045  [   32/  265]
train() client id: f_00001-0-1 loss: 0.518689  [   64/  265]
train() client id: f_00001-0-2 loss: 0.433307  [   96/  265]
train() client id: f_00001-0-3 loss: 0.515061  [  128/  265]
train() client id: f_00001-0-4 loss: 0.655656  [  160/  265]
train() client id: f_00001-0-5 loss: 0.544593  [  192/  265]
train() client id: f_00001-0-6 loss: 0.423713  [  224/  265]
train() client id: f_00001-0-7 loss: 0.415521  [  256/  265]
train() client id: f_00001-1-0 loss: 0.409298  [   32/  265]
train() client id: f_00001-1-1 loss: 0.526557  [   64/  265]
train() client id: f_00001-1-2 loss: 0.518447  [   96/  265]
train() client id: f_00001-1-3 loss: 0.569765  [  128/  265]
train() client id: f_00001-1-4 loss: 0.580216  [  160/  265]
train() client id: f_00001-1-5 loss: 0.500515  [  192/  265]
train() client id: f_00001-1-6 loss: 0.478776  [  224/  265]
train() client id: f_00001-1-7 loss: 0.412383  [  256/  265]
train() client id: f_00001-2-0 loss: 0.483985  [   32/  265]
train() client id: f_00001-2-1 loss: 0.462668  [   64/  265]
train() client id: f_00001-2-2 loss: 0.551818  [   96/  265]
train() client id: f_00001-2-3 loss: 0.500662  [  128/  265]
train() client id: f_00001-2-4 loss: 0.418957  [  160/  265]
train() client id: f_00001-2-5 loss: 0.483804  [  192/  265]
train() client id: f_00001-2-6 loss: 0.516007  [  224/  265]
train() client id: f_00001-2-7 loss: 0.549740  [  256/  265]
train() client id: f_00001-3-0 loss: 0.485875  [   32/  265]
train() client id: f_00001-3-1 loss: 0.372745  [   64/  265]
train() client id: f_00001-3-2 loss: 0.543963  [   96/  265]
train() client id: f_00001-3-3 loss: 0.533927  [  128/  265]
train() client id: f_00001-3-4 loss: 0.435583  [  160/  265]
train() client id: f_00001-3-5 loss: 0.494427  [  192/  265]
train() client id: f_00001-3-6 loss: 0.512957  [  224/  265]
train() client id: f_00001-3-7 loss: 0.554808  [  256/  265]
train() client id: f_00001-4-0 loss: 0.541125  [   32/  265]
train() client id: f_00001-4-1 loss: 0.561716  [   64/  265]
train() client id: f_00001-4-2 loss: 0.558685  [   96/  265]
train() client id: f_00001-4-3 loss: 0.438483  [  128/  265]
train() client id: f_00001-4-4 loss: 0.451498  [  160/  265]
train() client id: f_00001-4-5 loss: 0.411623  [  192/  265]
train() client id: f_00001-4-6 loss: 0.426189  [  224/  265]
train() client id: f_00001-4-7 loss: 0.506634  [  256/  265]
train() client id: f_00001-5-0 loss: 0.404514  [   32/  265]
train() client id: f_00001-5-1 loss: 0.446330  [   64/  265]
train() client id: f_00001-5-2 loss: 0.659295  [   96/  265]
train() client id: f_00001-5-3 loss: 0.474431  [  128/  265]
train() client id: f_00001-5-4 loss: 0.526254  [  160/  265]
train() client id: f_00001-5-5 loss: 0.475814  [  192/  265]
train() client id: f_00001-5-6 loss: 0.419393  [  224/  265]
train() client id: f_00001-5-7 loss: 0.443991  [  256/  265]
train() client id: f_00001-6-0 loss: 0.397611  [   32/  265]
train() client id: f_00001-6-1 loss: 0.437484  [   64/  265]
train() client id: f_00001-6-2 loss: 0.581409  [   96/  265]
train() client id: f_00001-6-3 loss: 0.379739  [  128/  265]
train() client id: f_00001-6-4 loss: 0.493045  [  160/  265]
train() client id: f_00001-6-5 loss: 0.536619  [  192/  265]
train() client id: f_00001-6-6 loss: 0.455356  [  224/  265]
train() client id: f_00001-6-7 loss: 0.591278  [  256/  265]
train() client id: f_00001-7-0 loss: 0.542943  [   32/  265]
train() client id: f_00001-7-1 loss: 0.448528  [   64/  265]
train() client id: f_00001-7-2 loss: 0.734222  [   96/  265]
train() client id: f_00001-7-3 loss: 0.462985  [  128/  265]
train() client id: f_00001-7-4 loss: 0.386822  [  160/  265]
train() client id: f_00001-7-5 loss: 0.417010  [  192/  265]
train() client id: f_00001-7-6 loss: 0.382506  [  224/  265]
train() client id: f_00001-7-7 loss: 0.487666  [  256/  265]
train() client id: f_00001-8-0 loss: 0.394549  [   32/  265]
train() client id: f_00001-8-1 loss: 0.586812  [   64/  265]
train() client id: f_00001-8-2 loss: 0.443475  [   96/  265]
train() client id: f_00001-8-3 loss: 0.385636  [  128/  265]
train() client id: f_00001-8-4 loss: 0.584506  [  160/  265]
train() client id: f_00001-8-5 loss: 0.465984  [  192/  265]
train() client id: f_00001-8-6 loss: 0.558655  [  224/  265]
train() client id: f_00001-8-7 loss: 0.386380  [  256/  265]
train() client id: f_00001-9-0 loss: 0.474376  [   32/  265]
train() client id: f_00001-9-1 loss: 0.461070  [   64/  265]
train() client id: f_00001-9-2 loss: 0.427986  [   96/  265]
train() client id: f_00001-9-3 loss: 0.481419  [  128/  265]
train() client id: f_00001-9-4 loss: 0.540071  [  160/  265]
train() client id: f_00001-9-5 loss: 0.414638  [  192/  265]
train() client id: f_00001-9-6 loss: 0.413287  [  224/  265]
train() client id: f_00001-9-7 loss: 0.574041  [  256/  265]
train() client id: f_00001-10-0 loss: 0.390384  [   32/  265]
train() client id: f_00001-10-1 loss: 0.455225  [   64/  265]
train() client id: f_00001-10-2 loss: 0.662858  [   96/  265]
train() client id: f_00001-10-3 loss: 0.536447  [  128/  265]
train() client id: f_00001-10-4 loss: 0.441042  [  160/  265]
train() client id: f_00001-10-5 loss: 0.529401  [  192/  265]
train() client id: f_00001-10-6 loss: 0.453016  [  224/  265]
train() client id: f_00001-10-7 loss: 0.386000  [  256/  265]
train() client id: f_00001-11-0 loss: 0.533555  [   32/  265]
train() client id: f_00001-11-1 loss: 0.472526  [   64/  265]
train() client id: f_00001-11-2 loss: 0.481747  [   96/  265]
train() client id: f_00001-11-3 loss: 0.423849  [  128/  265]
train() client id: f_00001-11-4 loss: 0.427896  [  160/  265]
train() client id: f_00001-11-5 loss: 0.571233  [  192/  265]
train() client id: f_00001-11-6 loss: 0.448310  [  224/  265]
train() client id: f_00001-11-7 loss: 0.436004  [  256/  265]
train() client id: f_00001-12-0 loss: 0.459990  [   32/  265]
train() client id: f_00001-12-1 loss: 0.440376  [   64/  265]
train() client id: f_00001-12-2 loss: 0.469195  [   96/  265]
train() client id: f_00001-12-3 loss: 0.710680  [  128/  265]
train() client id: f_00001-12-4 loss: 0.366355  [  160/  265]
train() client id: f_00001-12-5 loss: 0.399300  [  192/  265]
train() client id: f_00001-12-6 loss: 0.527416  [  224/  265]
train() client id: f_00001-12-7 loss: 0.478936  [  256/  265]
train() client id: f_00002-0-0 loss: 1.408903  [   32/  124]
train() client id: f_00002-0-1 loss: 1.015811  [   64/  124]
train() client id: f_00002-0-2 loss: 1.192023  [   96/  124]
train() client id: f_00002-1-0 loss: 1.381449  [   32/  124]
train() client id: f_00002-1-1 loss: 1.091702  [   64/  124]
train() client id: f_00002-1-2 loss: 1.178235  [   96/  124]
train() client id: f_00002-2-0 loss: 1.095336  [   32/  124]
train() client id: f_00002-2-1 loss: 1.221731  [   64/  124]
train() client id: f_00002-2-2 loss: 1.047961  [   96/  124]
train() client id: f_00002-3-0 loss: 1.300732  [   32/  124]
train() client id: f_00002-3-1 loss: 1.078301  [   64/  124]
train() client id: f_00002-3-2 loss: 1.183321  [   96/  124]
train() client id: f_00002-4-0 loss: 1.118657  [   32/  124]
train() client id: f_00002-4-1 loss: 0.967464  [   64/  124]
train() client id: f_00002-4-2 loss: 0.994507  [   96/  124]
train() client id: f_00002-5-0 loss: 1.283097  [   32/  124]
train() client id: f_00002-5-1 loss: 0.930264  [   64/  124]
train() client id: f_00002-5-2 loss: 0.999411  [   96/  124]
train() client id: f_00002-6-0 loss: 0.907809  [   32/  124]
train() client id: f_00002-6-1 loss: 0.981206  [   64/  124]
train() client id: f_00002-6-2 loss: 1.167324  [   96/  124]
train() client id: f_00002-7-0 loss: 0.945184  [   32/  124]
train() client id: f_00002-7-1 loss: 1.071390  [   64/  124]
train() client id: f_00002-7-2 loss: 0.968013  [   96/  124]
train() client id: f_00002-8-0 loss: 0.969617  [   32/  124]
train() client id: f_00002-8-1 loss: 0.958084  [   64/  124]
train() client id: f_00002-8-2 loss: 0.944836  [   96/  124]
train() client id: f_00002-9-0 loss: 0.971721  [   32/  124]
train() client id: f_00002-9-1 loss: 0.880943  [   64/  124]
train() client id: f_00002-9-2 loss: 1.162750  [   96/  124]
train() client id: f_00002-10-0 loss: 1.126269  [   32/  124]
train() client id: f_00002-10-1 loss: 0.873936  [   64/  124]
train() client id: f_00002-10-2 loss: 0.972533  [   96/  124]
train() client id: f_00002-11-0 loss: 1.158521  [   32/  124]
train() client id: f_00002-11-1 loss: 0.790962  [   64/  124]
train() client id: f_00002-11-2 loss: 0.926494  [   96/  124]
train() client id: f_00002-12-0 loss: 0.907089  [   32/  124]
train() client id: f_00002-12-1 loss: 0.929667  [   64/  124]
train() client id: f_00002-12-2 loss: 1.127801  [   96/  124]
train() client id: f_00003-0-0 loss: 0.583305  [   32/   43]
train() client id: f_00003-1-0 loss: 0.622890  [   32/   43]
train() client id: f_00003-2-0 loss: 0.551523  [   32/   43]
train() client id: f_00003-3-0 loss: 0.861099  [   32/   43]
train() client id: f_00003-4-0 loss: 0.409094  [   32/   43]
train() client id: f_00003-5-0 loss: 0.631674  [   32/   43]
train() client id: f_00003-6-0 loss: 0.641982  [   32/   43]
train() client id: f_00003-7-0 loss: 0.576148  [   32/   43]
train() client id: f_00003-8-0 loss: 0.503585  [   32/   43]
train() client id: f_00003-9-0 loss: 0.738326  [   32/   43]
train() client id: f_00003-10-0 loss: 0.574218  [   32/   43]
train() client id: f_00003-11-0 loss: 0.389700  [   32/   43]
train() client id: f_00003-12-0 loss: 0.638950  [   32/   43]
train() client id: f_00004-0-0 loss: 0.742501  [   32/  306]
train() client id: f_00004-0-1 loss: 0.799573  [   64/  306]
train() client id: f_00004-0-2 loss: 0.738634  [   96/  306]
train() client id: f_00004-0-3 loss: 0.532871  [  128/  306]
train() client id: f_00004-0-4 loss: 0.803061  [  160/  306]
train() client id: f_00004-0-5 loss: 0.614504  [  192/  306]
train() client id: f_00004-0-6 loss: 0.791615  [  224/  306]
train() client id: f_00004-0-7 loss: 0.821453  [  256/  306]
train() client id: f_00004-0-8 loss: 0.639377  [  288/  306]
train() client id: f_00004-1-0 loss: 0.742580  [   32/  306]
train() client id: f_00004-1-1 loss: 0.710843  [   64/  306]
train() client id: f_00004-1-2 loss: 0.759806  [   96/  306]
train() client id: f_00004-1-3 loss: 0.640546  [  128/  306]
train() client id: f_00004-1-4 loss: 0.749501  [  160/  306]
train() client id: f_00004-1-5 loss: 0.694655  [  192/  306]
train() client id: f_00004-1-6 loss: 0.698241  [  224/  306]
train() client id: f_00004-1-7 loss: 0.696061  [  256/  306]
train() client id: f_00004-1-8 loss: 0.714097  [  288/  306]
train() client id: f_00004-2-0 loss: 0.784975  [   32/  306]
train() client id: f_00004-2-1 loss: 0.736494  [   64/  306]
train() client id: f_00004-2-2 loss: 0.758653  [   96/  306]
train() client id: f_00004-2-3 loss: 0.762561  [  128/  306]
train() client id: f_00004-2-4 loss: 0.849259  [  160/  306]
train() client id: f_00004-2-5 loss: 0.681027  [  192/  306]
train() client id: f_00004-2-6 loss: 0.670883  [  224/  306]
train() client id: f_00004-2-7 loss: 0.685127  [  256/  306]
train() client id: f_00004-2-8 loss: 0.606133  [  288/  306]
train() client id: f_00004-3-0 loss: 0.738258  [   32/  306]
train() client id: f_00004-3-1 loss: 0.767311  [   64/  306]
train() client id: f_00004-3-2 loss: 0.593854  [   96/  306]
train() client id: f_00004-3-3 loss: 0.659800  [  128/  306]
train() client id: f_00004-3-4 loss: 0.711195  [  160/  306]
train() client id: f_00004-3-5 loss: 0.841431  [  192/  306]
train() client id: f_00004-3-6 loss: 0.750927  [  224/  306]
train() client id: f_00004-3-7 loss: 0.723938  [  256/  306]
train() client id: f_00004-3-8 loss: 0.748055  [  288/  306]
train() client id: f_00004-4-0 loss: 0.701022  [   32/  306]
train() client id: f_00004-4-1 loss: 0.732126  [   64/  306]
train() client id: f_00004-4-2 loss: 0.724695  [   96/  306]
train() client id: f_00004-4-3 loss: 0.665751  [  128/  306]
train() client id: f_00004-4-4 loss: 0.623205  [  160/  306]
train() client id: f_00004-4-5 loss: 0.703100  [  192/  306]
train() client id: f_00004-4-6 loss: 0.761900  [  224/  306]
train() client id: f_00004-4-7 loss: 0.726827  [  256/  306]
train() client id: f_00004-4-8 loss: 0.788210  [  288/  306]
train() client id: f_00004-5-0 loss: 0.621849  [   32/  306]
train() client id: f_00004-5-1 loss: 0.718632  [   64/  306]
train() client id: f_00004-5-2 loss: 0.620861  [   96/  306]
train() client id: f_00004-5-3 loss: 0.763580  [  128/  306]
train() client id: f_00004-5-4 loss: 0.802524  [  160/  306]
train() client id: f_00004-5-5 loss: 0.613402  [  192/  306]
train() client id: f_00004-5-6 loss: 0.716471  [  224/  306]
train() client id: f_00004-5-7 loss: 0.813754  [  256/  306]
train() client id: f_00004-5-8 loss: 0.815638  [  288/  306]
train() client id: f_00004-6-0 loss: 0.738605  [   32/  306]
train() client id: f_00004-6-1 loss: 0.814705  [   64/  306]
train() client id: f_00004-6-2 loss: 0.652208  [   96/  306]
train() client id: f_00004-6-3 loss: 0.750847  [  128/  306]
train() client id: f_00004-6-4 loss: 0.684505  [  160/  306]
train() client id: f_00004-6-5 loss: 0.746596  [  192/  306]
train() client id: f_00004-6-6 loss: 0.637668  [  224/  306]
train() client id: f_00004-6-7 loss: 0.833665  [  256/  306]
train() client id: f_00004-6-8 loss: 0.706545  [  288/  306]
train() client id: f_00004-7-0 loss: 0.655417  [   32/  306]
train() client id: f_00004-7-1 loss: 0.706010  [   64/  306]
train() client id: f_00004-7-2 loss: 0.643246  [   96/  306]
train() client id: f_00004-7-3 loss: 0.804503  [  128/  306]
train() client id: f_00004-7-4 loss: 0.742690  [  160/  306]
train() client id: f_00004-7-5 loss: 0.671779  [  192/  306]
train() client id: f_00004-7-6 loss: 0.811203  [  224/  306]
train() client id: f_00004-7-7 loss: 0.580847  [  256/  306]
train() client id: f_00004-7-8 loss: 0.811972  [  288/  306]
train() client id: f_00004-8-0 loss: 0.854702  [   32/  306]
train() client id: f_00004-8-1 loss: 0.694120  [   64/  306]
train() client id: f_00004-8-2 loss: 0.795186  [   96/  306]
train() client id: f_00004-8-3 loss: 0.699551  [  128/  306]
train() client id: f_00004-8-4 loss: 0.667042  [  160/  306]
train() client id: f_00004-8-5 loss: 0.647668  [  192/  306]
train() client id: f_00004-8-6 loss: 0.587294  [  224/  306]
train() client id: f_00004-8-7 loss: 0.811543  [  256/  306]
train() client id: f_00004-8-8 loss: 0.741570  [  288/  306]
train() client id: f_00004-9-0 loss: 0.759779  [   32/  306]
train() client id: f_00004-9-1 loss: 0.776376  [   64/  306]
train() client id: f_00004-9-2 loss: 0.655634  [   96/  306]
train() client id: f_00004-9-3 loss: 0.585815  [  128/  306]
train() client id: f_00004-9-4 loss: 0.777502  [  160/  306]
train() client id: f_00004-9-5 loss: 0.599303  [  192/  306]
train() client id: f_00004-9-6 loss: 0.793716  [  224/  306]
train() client id: f_00004-9-7 loss: 0.673254  [  256/  306]
train() client id: f_00004-9-8 loss: 0.843774  [  288/  306]
train() client id: f_00004-10-0 loss: 0.819141  [   32/  306]
train() client id: f_00004-10-1 loss: 0.538651  [   64/  306]
train() client id: f_00004-10-2 loss: 0.849750  [   96/  306]
train() client id: f_00004-10-3 loss: 0.597239  [  128/  306]
train() client id: f_00004-10-4 loss: 0.710467  [  160/  306]
train() client id: f_00004-10-5 loss: 0.747178  [  192/  306]
train() client id: f_00004-10-6 loss: 0.741595  [  224/  306]
train() client id: f_00004-10-7 loss: 0.679345  [  256/  306]
train() client id: f_00004-10-8 loss: 0.809595  [  288/  306]
train() client id: f_00004-11-0 loss: 0.775860  [   32/  306]
train() client id: f_00004-11-1 loss: 0.729522  [   64/  306]
train() client id: f_00004-11-2 loss: 0.707875  [   96/  306]
train() client id: f_00004-11-3 loss: 0.774308  [  128/  306]
train() client id: f_00004-11-4 loss: 0.716067  [  160/  306]
train() client id: f_00004-11-5 loss: 0.618476  [  192/  306]
train() client id: f_00004-11-6 loss: 0.695442  [  224/  306]
train() client id: f_00004-11-7 loss: 0.760191  [  256/  306]
train() client id: f_00004-11-8 loss: 0.773406  [  288/  306]
train() client id: f_00004-12-0 loss: 0.790844  [   32/  306]
train() client id: f_00004-12-1 loss: 0.664961  [   64/  306]
train() client id: f_00004-12-2 loss: 0.787430  [   96/  306]
train() client id: f_00004-12-3 loss: 0.730434  [  128/  306]
train() client id: f_00004-12-4 loss: 0.756149  [  160/  306]
train() client id: f_00004-12-5 loss: 0.709363  [  192/  306]
train() client id: f_00004-12-6 loss: 0.618470  [  224/  306]
train() client id: f_00004-12-7 loss: 0.742183  [  256/  306]
train() client id: f_00004-12-8 loss: 0.710419  [  288/  306]
train() client id: f_00005-0-0 loss: 0.911487  [   32/  146]
train() client id: f_00005-0-1 loss: 0.533316  [   64/  146]
train() client id: f_00005-0-2 loss: 0.589851  [   96/  146]
train() client id: f_00005-0-3 loss: 0.558979  [  128/  146]
train() client id: f_00005-1-0 loss: 0.299100  [   32/  146]
train() client id: f_00005-1-1 loss: 0.591151  [   64/  146]
train() client id: f_00005-1-2 loss: 0.797218  [   96/  146]
train() client id: f_00005-1-3 loss: 0.712260  [  128/  146]
train() client id: f_00005-2-0 loss: 0.592551  [   32/  146]
train() client id: f_00005-2-1 loss: 0.866665  [   64/  146]
train() client id: f_00005-2-2 loss: 0.654692  [   96/  146]
train() client id: f_00005-2-3 loss: 0.320280  [  128/  146]
train() client id: f_00005-3-0 loss: 0.857286  [   32/  146]
train() client id: f_00005-3-1 loss: 0.589026  [   64/  146]
train() client id: f_00005-3-2 loss: 0.369156  [   96/  146]
train() client id: f_00005-3-3 loss: 0.560853  [  128/  146]
train() client id: f_00005-4-0 loss: 0.701827  [   32/  146]
train() client id: f_00005-4-1 loss: 0.642042  [   64/  146]
train() client id: f_00005-4-2 loss: 0.820645  [   96/  146]
train() client id: f_00005-4-3 loss: 0.381509  [  128/  146]
train() client id: f_00005-5-0 loss: 0.802738  [   32/  146]
train() client id: f_00005-5-1 loss: 0.465041  [   64/  146]
train() client id: f_00005-5-2 loss: 0.613178  [   96/  146]
train() client id: f_00005-5-3 loss: 0.743469  [  128/  146]
train() client id: f_00005-6-0 loss: 0.564819  [   32/  146]
train() client id: f_00005-6-1 loss: 0.432202  [   64/  146]
train() client id: f_00005-6-2 loss: 0.793007  [   96/  146]
train() client id: f_00005-6-3 loss: 0.529937  [  128/  146]
train() client id: f_00005-7-0 loss: 0.692806  [   32/  146]
train() client id: f_00005-7-1 loss: 0.385398  [   64/  146]
train() client id: f_00005-7-2 loss: 0.840317  [   96/  146]
train() client id: f_00005-7-3 loss: 0.530417  [  128/  146]
train() client id: f_00005-8-0 loss: 0.738094  [   32/  146]
train() client id: f_00005-8-1 loss: 0.579172  [   64/  146]
train() client id: f_00005-8-2 loss: 0.468725  [   96/  146]
train() client id: f_00005-8-3 loss: 0.581136  [  128/  146]
train() client id: f_00005-9-0 loss: 0.620001  [   32/  146]
train() client id: f_00005-9-1 loss: 0.735442  [   64/  146]
train() client id: f_00005-9-2 loss: 0.423443  [   96/  146]
train() client id: f_00005-9-3 loss: 0.598687  [  128/  146]
train() client id: f_00005-10-0 loss: 0.450988  [   32/  146]
train() client id: f_00005-10-1 loss: 0.826419  [   64/  146]
train() client id: f_00005-10-2 loss: 0.607072  [   96/  146]
train() client id: f_00005-10-3 loss: 0.606693  [  128/  146]
train() client id: f_00005-11-0 loss: 0.541718  [   32/  146]
train() client id: f_00005-11-1 loss: 0.875969  [   64/  146]
train() client id: f_00005-11-2 loss: 0.742846  [   96/  146]
train() client id: f_00005-11-3 loss: 0.445117  [  128/  146]
train() client id: f_00005-12-0 loss: 0.745205  [   32/  146]
train() client id: f_00005-12-1 loss: 0.643713  [   64/  146]
train() client id: f_00005-12-2 loss: 0.511477  [   96/  146]
train() client id: f_00005-12-3 loss: 0.451711  [  128/  146]
train() client id: f_00006-0-0 loss: 0.559715  [   32/   54]
train() client id: f_00006-1-0 loss: 0.430061  [   32/   54]
train() client id: f_00006-2-0 loss: 0.514942  [   32/   54]
train() client id: f_00006-3-0 loss: 0.553332  [   32/   54]
train() client id: f_00006-4-0 loss: 0.503821  [   32/   54]
train() client id: f_00006-5-0 loss: 0.485087  [   32/   54]
train() client id: f_00006-6-0 loss: 0.455601  [   32/   54]
train() client id: f_00006-7-0 loss: 0.538861  [   32/   54]
train() client id: f_00006-8-0 loss: 0.494845  [   32/   54]
train() client id: f_00006-9-0 loss: 0.425676  [   32/   54]
train() client id: f_00006-10-0 loss: 0.540684  [   32/   54]
train() client id: f_00006-11-0 loss: 0.544778  [   32/   54]
train() client id: f_00006-12-0 loss: 0.507925  [   32/   54]
train() client id: f_00007-0-0 loss: 0.735333  [   32/  179]
train() client id: f_00007-0-1 loss: 0.607517  [   64/  179]
train() client id: f_00007-0-2 loss: 0.686770  [   96/  179]
train() client id: f_00007-0-3 loss: 0.642815  [  128/  179]
train() client id: f_00007-0-4 loss: 0.509245  [  160/  179]
train() client id: f_00007-1-0 loss: 0.498556  [   32/  179]
train() client id: f_00007-1-1 loss: 0.762650  [   64/  179]
train() client id: f_00007-1-2 loss: 0.508035  [   96/  179]
train() client id: f_00007-1-3 loss: 0.620532  [  128/  179]
train() client id: f_00007-1-4 loss: 0.673761  [  160/  179]
train() client id: f_00007-2-0 loss: 0.671065  [   32/  179]
train() client id: f_00007-2-1 loss: 0.556201  [   64/  179]
train() client id: f_00007-2-2 loss: 0.659677  [   96/  179]
train() client id: f_00007-2-3 loss: 0.598853  [  128/  179]
train() client id: f_00007-2-4 loss: 0.490867  [  160/  179]
train() client id: f_00007-3-0 loss: 0.505929  [   32/  179]
train() client id: f_00007-3-1 loss: 0.789336  [   64/  179]
train() client id: f_00007-3-2 loss: 0.750468  [   96/  179]
train() client id: f_00007-3-3 loss: 0.508898  [  128/  179]
train() client id: f_00007-3-4 loss: 0.488113  [  160/  179]
train() client id: f_00007-4-0 loss: 0.501727  [   32/  179]
train() client id: f_00007-4-1 loss: 0.440195  [   64/  179]
train() client id: f_00007-4-2 loss: 0.674795  [   96/  179]
train() client id: f_00007-4-3 loss: 0.564707  [  128/  179]
train() client id: f_00007-4-4 loss: 0.805400  [  160/  179]
train() client id: f_00007-5-0 loss: 0.439933  [   32/  179]
train() client id: f_00007-5-1 loss: 0.882089  [   64/  179]
train() client id: f_00007-5-2 loss: 0.528214  [   96/  179]
train() client id: f_00007-5-3 loss: 0.464773  [  128/  179]
train() client id: f_00007-5-4 loss: 0.591266  [  160/  179]
train() client id: f_00007-6-0 loss: 0.663725  [   32/  179]
train() client id: f_00007-6-1 loss: 0.452509  [   64/  179]
train() client id: f_00007-6-2 loss: 0.483342  [   96/  179]
train() client id: f_00007-6-3 loss: 0.548429  [  128/  179]
train() client id: f_00007-6-4 loss: 0.619471  [  160/  179]
train() client id: f_00007-7-0 loss: 0.547844  [   32/  179]
train() client id: f_00007-7-1 loss: 0.544209  [   64/  179]
train() client id: f_00007-7-2 loss: 0.536524  [   96/  179]
train() client id: f_00007-7-3 loss: 0.613006  [  128/  179]
train() client id: f_00007-7-4 loss: 0.623497  [  160/  179]
train() client id: f_00007-8-0 loss: 0.711374  [   32/  179]
train() client id: f_00007-8-1 loss: 0.665384  [   64/  179]
train() client id: f_00007-8-2 loss: 0.515040  [   96/  179]
train() client id: f_00007-8-3 loss: 0.530258  [  128/  179]
train() client id: f_00007-8-4 loss: 0.477482  [  160/  179]
train() client id: f_00007-9-0 loss: 0.619149  [   32/  179]
train() client id: f_00007-9-1 loss: 0.676676  [   64/  179]
train() client id: f_00007-9-2 loss: 0.473431  [   96/  179]
train() client id: f_00007-9-3 loss: 0.583627  [  128/  179]
train() client id: f_00007-9-4 loss: 0.631655  [  160/  179]
train() client id: f_00007-10-0 loss: 0.510302  [   32/  179]
train() client id: f_00007-10-1 loss: 0.448082  [   64/  179]
train() client id: f_00007-10-2 loss: 0.685954  [   96/  179]
train() client id: f_00007-10-3 loss: 0.702921  [  128/  179]
train() client id: f_00007-10-4 loss: 0.675606  [  160/  179]
train() client id: f_00007-11-0 loss: 0.682451  [   32/  179]
train() client id: f_00007-11-1 loss: 0.514427  [   64/  179]
train() client id: f_00007-11-2 loss: 0.628086  [   96/  179]
train() client id: f_00007-11-3 loss: 0.556454  [  128/  179]
train() client id: f_00007-11-4 loss: 0.545223  [  160/  179]
train() client id: f_00007-12-0 loss: 0.821134  [   32/  179]
train() client id: f_00007-12-1 loss: 0.461745  [   64/  179]
train() client id: f_00007-12-2 loss: 0.432361  [   96/  179]
train() client id: f_00007-12-3 loss: 0.396351  [  128/  179]
train() client id: f_00007-12-4 loss: 0.722039  [  160/  179]
train() client id: f_00008-0-0 loss: 0.704241  [   32/  130]
train() client id: f_00008-0-1 loss: 0.748562  [   64/  130]
train() client id: f_00008-0-2 loss: 0.707929  [   96/  130]
train() client id: f_00008-0-3 loss: 0.690992  [  128/  130]
train() client id: f_00008-1-0 loss: 0.653955  [   32/  130]
train() client id: f_00008-1-1 loss: 0.789278  [   64/  130]
train() client id: f_00008-1-2 loss: 0.627465  [   96/  130]
train() client id: f_00008-1-3 loss: 0.805817  [  128/  130]
train() client id: f_00008-2-0 loss: 0.767128  [   32/  130]
train() client id: f_00008-2-1 loss: 0.753734  [   64/  130]
train() client id: f_00008-2-2 loss: 0.729331  [   96/  130]
train() client id: f_00008-2-3 loss: 0.630485  [  128/  130]
train() client id: f_00008-3-0 loss: 0.696703  [   32/  130]
train() client id: f_00008-3-1 loss: 0.710420  [   64/  130]
train() client id: f_00008-3-2 loss: 0.662030  [   96/  130]
train() client id: f_00008-3-3 loss: 0.772597  [  128/  130]
train() client id: f_00008-4-0 loss: 0.662392  [   32/  130]
train() client id: f_00008-4-1 loss: 0.778362  [   64/  130]
train() client id: f_00008-4-2 loss: 0.701556  [   96/  130]
train() client id: f_00008-4-3 loss: 0.722224  [  128/  130]
train() client id: f_00008-5-0 loss: 0.871129  [   32/  130]
train() client id: f_00008-5-1 loss: 0.673893  [   64/  130]
train() client id: f_00008-5-2 loss: 0.656116  [   96/  130]
train() client id: f_00008-5-3 loss: 0.654988  [  128/  130]
train() client id: f_00008-6-0 loss: 0.660068  [   32/  130]
train() client id: f_00008-6-1 loss: 0.753617  [   64/  130]
train() client id: f_00008-6-2 loss: 0.668309  [   96/  130]
train() client id: f_00008-6-3 loss: 0.778277  [  128/  130]
train() client id: f_00008-7-0 loss: 0.559960  [   32/  130]
train() client id: f_00008-7-1 loss: 0.721452  [   64/  130]
train() client id: f_00008-7-2 loss: 0.607460  [   96/  130]
train() client id: f_00008-7-3 loss: 0.910515  [  128/  130]
train() client id: f_00008-8-0 loss: 0.655010  [   32/  130]
train() client id: f_00008-8-1 loss: 0.698038  [   64/  130]
train() client id: f_00008-8-2 loss: 0.727267  [   96/  130]
train() client id: f_00008-8-3 loss: 0.716518  [  128/  130]
train() client id: f_00008-9-0 loss: 0.767623  [   32/  130]
train() client id: f_00008-9-1 loss: 0.592604  [   64/  130]
train() client id: f_00008-9-2 loss: 0.658005  [   96/  130]
train() client id: f_00008-9-3 loss: 0.831168  [  128/  130]
train() client id: f_00008-10-0 loss: 0.769909  [   32/  130]
train() client id: f_00008-10-1 loss: 0.627823  [   64/  130]
train() client id: f_00008-10-2 loss: 0.652682  [   96/  130]
train() client id: f_00008-10-3 loss: 0.733816  [  128/  130]
train() client id: f_00008-11-0 loss: 0.757851  [   32/  130]
train() client id: f_00008-11-1 loss: 0.620716  [   64/  130]
train() client id: f_00008-11-2 loss: 0.725759  [   96/  130]
train() client id: f_00008-11-3 loss: 0.701919  [  128/  130]
train() client id: f_00008-12-0 loss: 0.709265  [   32/  130]
train() client id: f_00008-12-1 loss: 0.775448  [   64/  130]
train() client id: f_00008-12-2 loss: 0.732710  [   96/  130]
train() client id: f_00008-12-3 loss: 0.608176  [  128/  130]
train() client id: f_00009-0-0 loss: 1.201219  [   32/  118]
train() client id: f_00009-0-1 loss: 1.036856  [   64/  118]
train() client id: f_00009-0-2 loss: 1.163680  [   96/  118]
train() client id: f_00009-1-0 loss: 0.887046  [   32/  118]
train() client id: f_00009-1-1 loss: 0.971217  [   64/  118]
train() client id: f_00009-1-2 loss: 1.195104  [   96/  118]
train() client id: f_00009-2-0 loss: 0.957898  [   32/  118]
train() client id: f_00009-2-1 loss: 0.956531  [   64/  118]
train() client id: f_00009-2-2 loss: 0.923370  [   96/  118]
train() client id: f_00009-3-0 loss: 0.808048  [   32/  118]
train() client id: f_00009-3-1 loss: 0.792847  [   64/  118]
train() client id: f_00009-3-2 loss: 1.036956  [   96/  118]
train() client id: f_00009-4-0 loss: 0.965703  [   32/  118]
train() client id: f_00009-4-1 loss: 0.881427  [   64/  118]
train() client id: f_00009-4-2 loss: 0.824320  [   96/  118]
train() client id: f_00009-5-0 loss: 0.801800  [   32/  118]
train() client id: f_00009-5-1 loss: 0.828648  [   64/  118]
train() client id: f_00009-5-2 loss: 0.877232  [   96/  118]
train() client id: f_00009-6-0 loss: 0.804878  [   32/  118]
train() client id: f_00009-6-1 loss: 0.791648  [   64/  118]
train() client id: f_00009-6-2 loss: 0.905357  [   96/  118]
train() client id: f_00009-7-0 loss: 0.730675  [   32/  118]
train() client id: f_00009-7-1 loss: 0.716160  [   64/  118]
train() client id: f_00009-7-2 loss: 0.919395  [   96/  118]
train() client id: f_00009-8-0 loss: 0.747266  [   32/  118]
train() client id: f_00009-8-1 loss: 0.977372  [   64/  118]
train() client id: f_00009-8-2 loss: 0.678836  [   96/  118]
train() client id: f_00009-9-0 loss: 0.753773  [   32/  118]
train() client id: f_00009-9-1 loss: 0.803354  [   64/  118]
train() client id: f_00009-9-2 loss: 0.723118  [   96/  118]
train() client id: f_00009-10-0 loss: 0.780606  [   32/  118]
train() client id: f_00009-10-1 loss: 0.813920  [   64/  118]
train() client id: f_00009-10-2 loss: 0.733880  [   96/  118]
train() client id: f_00009-11-0 loss: 0.942771  [   32/  118]
train() client id: f_00009-11-1 loss: 0.713697  [   64/  118]
train() client id: f_00009-11-2 loss: 0.692284  [   96/  118]
train() client id: f_00009-12-0 loss: 0.684210  [   32/  118]
train() client id: f_00009-12-1 loss: 0.745668  [   64/  118]
train() client id: f_00009-12-2 loss: 0.800046  [   96/  118]
At round 46 accuracy: 0.6445623342175066
At round 46 training accuracy: 0.5922199865861838
At round 46 training loss: 0.8264657360388113
gradient difference: 0.43766194581985474
train() client id: f_00000-0-0 loss: 1.020461  [   32/  126]
train() client id: f_00000-0-1 loss: 1.281025  [   64/  126]
train() client id: f_00000-0-2 loss: 1.201374  [   96/  126]
train() client id: f_00000-1-0 loss: 1.011928  [   32/  126]
train() client id: f_00000-1-1 loss: 0.921439  [   64/  126]
train() client id: f_00000-1-2 loss: 1.011590  [   96/  126]
train() client id: f_00000-2-0 loss: 0.814322  [   32/  126]
train() client id: f_00000-2-1 loss: 1.212070  [   64/  126]
train() client id: f_00000-2-2 loss: 0.851046  [   96/  126]
train() client id: f_00000-3-0 loss: 1.033265  [   32/  126]
train() client id: f_00000-3-1 loss: 0.799598  [   64/  126]
train() client id: f_00000-3-2 loss: 0.855528  [   96/  126]
train() client id: f_00000-4-0 loss: 0.841664  [   32/  126]
train() client id: f_00000-4-1 loss: 0.966873  [   64/  126]
train() client id: f_00000-4-2 loss: 0.729197  [   96/  126]
train() client id: f_00000-5-0 loss: 0.819317  [   32/  126]
train() client id: f_00000-5-1 loss: 0.800019  [   64/  126]
train() client id: f_00000-5-2 loss: 0.858277  [   96/  126]
train() client id: f_00000-6-0 loss: 0.643450  [   32/  126]
train() client id: f_00000-6-1 loss: 0.745314  [   64/  126]
train() client id: f_00000-6-2 loss: 0.822794  [   96/  126]
train() client id: f_00000-7-0 loss: 0.775070  [   32/  126]
train() client id: f_00000-7-1 loss: 0.680124  [   64/  126]
train() client id: f_00000-7-2 loss: 0.632073  [   96/  126]
train() client id: f_00000-8-0 loss: 0.668125  [   32/  126]
train() client id: f_00000-8-1 loss: 0.770005  [   64/  126]
train() client id: f_00000-8-2 loss: 0.698257  [   96/  126]
train() client id: f_00000-9-0 loss: 0.630065  [   32/  126]
train() client id: f_00000-9-1 loss: 0.697783  [   64/  126]
train() client id: f_00000-9-2 loss: 0.783771  [   96/  126]
train() client id: f_00000-10-0 loss: 0.556984  [   32/  126]
train() client id: f_00000-10-1 loss: 0.829952  [   64/  126]
train() client id: f_00000-10-2 loss: 0.646134  [   96/  126]
train() client id: f_00000-11-0 loss: 0.555306  [   32/  126]
train() client id: f_00000-11-1 loss: 0.731616  [   64/  126]
train() client id: f_00000-11-2 loss: 0.658403  [   96/  126]
train() client id: f_00000-12-0 loss: 0.722841  [   32/  126]
train() client id: f_00000-12-1 loss: 0.616997  [   64/  126]
train() client id: f_00000-12-2 loss: 0.765220  [   96/  126]
train() client id: f_00001-0-0 loss: 0.428097  [   32/  265]
train() client id: f_00001-0-1 loss: 0.361089  [   64/  265]
train() client id: f_00001-0-2 loss: 0.511361  [   96/  265]
train() client id: f_00001-0-3 loss: 0.316614  [  128/  265]
train() client id: f_00001-0-4 loss: 0.358914  [  160/  265]
train() client id: f_00001-0-5 loss: 0.489180  [  192/  265]
train() client id: f_00001-0-6 loss: 0.526465  [  224/  265]
train() client id: f_00001-0-7 loss: 0.579616  [  256/  265]
train() client id: f_00001-1-0 loss: 0.348553  [   32/  265]
train() client id: f_00001-1-1 loss: 0.374487  [   64/  265]
train() client id: f_00001-1-2 loss: 0.553600  [   96/  265]
train() client id: f_00001-1-3 loss: 0.561644  [  128/  265]
train() client id: f_00001-1-4 loss: 0.352816  [  160/  265]
train() client id: f_00001-1-5 loss: 0.428639  [  192/  265]
train() client id: f_00001-1-6 loss: 0.462961  [  224/  265]
train() client id: f_00001-1-7 loss: 0.334362  [  256/  265]
train() client id: f_00001-2-0 loss: 0.364073  [   32/  265]
train() client id: f_00001-2-1 loss: 0.418189  [   64/  265]
train() client id: f_00001-2-2 loss: 0.514061  [   96/  265]
train() client id: f_00001-2-3 loss: 0.428457  [  128/  265]
train() client id: f_00001-2-4 loss: 0.437268  [  160/  265]
train() client id: f_00001-2-5 loss: 0.428913  [  192/  265]
train() client id: f_00001-2-6 loss: 0.427582  [  224/  265]
train() client id: f_00001-2-7 loss: 0.429416  [  256/  265]
train() client id: f_00001-3-0 loss: 0.427162  [   32/  265]
train() client id: f_00001-3-1 loss: 0.375022  [   64/  265]
train() client id: f_00001-3-2 loss: 0.370879  [   96/  265]
train() client id: f_00001-3-3 loss: 0.574575  [  128/  265]
train() client id: f_00001-3-4 loss: 0.359925  [  160/  265]
train() client id: f_00001-3-5 loss: 0.387638  [  192/  265]
train() client id: f_00001-3-6 loss: 0.458728  [  224/  265]
train() client id: f_00001-3-7 loss: 0.442116  [  256/  265]
train() client id: f_00001-4-0 loss: 0.510914  [   32/  265]
train() client id: f_00001-4-1 loss: 0.516697  [   64/  265]
train() client id: f_00001-4-2 loss: 0.342387  [   96/  265]
train() client id: f_00001-4-3 loss: 0.570196  [  128/  265]
train() client id: f_00001-4-4 loss: 0.339285  [  160/  265]
train() client id: f_00001-4-5 loss: 0.406024  [  192/  265]
train() client id: f_00001-4-6 loss: 0.352574  [  224/  265]
train() client id: f_00001-4-7 loss: 0.301286  [  256/  265]
train() client id: f_00001-5-0 loss: 0.370941  [   32/  265]
train() client id: f_00001-5-1 loss: 0.328599  [   64/  265]
train() client id: f_00001-5-2 loss: 0.320189  [   96/  265]
train() client id: f_00001-5-3 loss: 0.344828  [  128/  265]
train() client id: f_00001-5-4 loss: 0.325822  [  160/  265]
train() client id: f_00001-5-5 loss: 0.612652  [  192/  265]
train() client id: f_00001-5-6 loss: 0.519861  [  224/  265]
train() client id: f_00001-5-7 loss: 0.530319  [  256/  265]
train() client id: f_00001-6-0 loss: 0.437815  [   32/  265]
train() client id: f_00001-6-1 loss: 0.410472  [   64/  265]
train() client id: f_00001-6-2 loss: 0.479439  [   96/  265]
train() client id: f_00001-6-3 loss: 0.385182  [  128/  265]
train() client id: f_00001-6-4 loss: 0.415939  [  160/  265]
train() client id: f_00001-6-5 loss: 0.381493  [  192/  265]
train() client id: f_00001-6-6 loss: 0.415129  [  224/  265]
train() client id: f_00001-6-7 loss: 0.401142  [  256/  265]
train() client id: f_00001-7-0 loss: 0.377050  [   32/  265]
train() client id: f_00001-7-1 loss: 0.426314  [   64/  265]
train() client id: f_00001-7-2 loss: 0.459983  [   96/  265]
train() client id: f_00001-7-3 loss: 0.397350  [  128/  265]
train() client id: f_00001-7-4 loss: 0.365208  [  160/  265]
train() client id: f_00001-7-5 loss: 0.510282  [  192/  265]
train() client id: f_00001-7-6 loss: 0.359056  [  224/  265]
train() client id: f_00001-7-7 loss: 0.340149  [  256/  265]
train() client id: f_00001-8-0 loss: 0.409044  [   32/  265]
train() client id: f_00001-8-1 loss: 0.315866  [   64/  265]
train() client id: f_00001-8-2 loss: 0.322238  [   96/  265]
train() client id: f_00001-8-3 loss: 0.322310  [  128/  265]
train() client id: f_00001-8-4 loss: 0.481020  [  160/  265]
train() client id: f_00001-8-5 loss: 0.474898  [  192/  265]
train() client id: f_00001-8-6 loss: 0.394566  [  224/  265]
train() client id: f_00001-8-7 loss: 0.528989  [  256/  265]
train() client id: f_00001-9-0 loss: 0.532589  [   32/  265]
train() client id: f_00001-9-1 loss: 0.434143  [   64/  265]
train() client id: f_00001-9-2 loss: 0.339456  [   96/  265]
train() client id: f_00001-9-3 loss: 0.433075  [  128/  265]
train() client id: f_00001-9-4 loss: 0.424632  [  160/  265]
train() client id: f_00001-9-5 loss: 0.403810  [  192/  265]
train() client id: f_00001-9-6 loss: 0.362130  [  224/  265]
train() client id: f_00001-9-7 loss: 0.365898  [  256/  265]
train() client id: f_00001-10-0 loss: 0.432909  [   32/  265]
train() client id: f_00001-10-1 loss: 0.315416  [   64/  265]
train() client id: f_00001-10-2 loss: 0.406852  [   96/  265]
train() client id: f_00001-10-3 loss: 0.438795  [  128/  265]
train() client id: f_00001-10-4 loss: 0.445071  [  160/  265]
train() client id: f_00001-10-5 loss: 0.455602  [  192/  265]
train() client id: f_00001-10-6 loss: 0.401469  [  224/  265]
train() client id: f_00001-10-7 loss: 0.322045  [  256/  265]
train() client id: f_00001-11-0 loss: 0.354748  [   32/  265]
train() client id: f_00001-11-1 loss: 0.492571  [   64/  265]
train() client id: f_00001-11-2 loss: 0.392473  [   96/  265]
train() client id: f_00001-11-3 loss: 0.446553  [  128/  265]
train() client id: f_00001-11-4 loss: 0.323770  [  160/  265]
train() client id: f_00001-11-5 loss: 0.401352  [  192/  265]
train() client id: f_00001-11-6 loss: 0.568946  [  224/  265]
train() client id: f_00001-11-7 loss: 0.325509  [  256/  265]
train() client id: f_00001-12-0 loss: 0.414028  [   32/  265]
train() client id: f_00001-12-1 loss: 0.379965  [   64/  265]
train() client id: f_00001-12-2 loss: 0.444153  [   96/  265]
train() client id: f_00001-12-3 loss: 0.375235  [  128/  265]
train() client id: f_00001-12-4 loss: 0.392467  [  160/  265]
train() client id: f_00001-12-5 loss: 0.298720  [  192/  265]
train() client id: f_00001-12-6 loss: 0.373666  [  224/  265]
train() client id: f_00001-12-7 loss: 0.617050  [  256/  265]
train() client id: f_00002-0-0 loss: 1.004468  [   32/  124]
train() client id: f_00002-0-1 loss: 0.833444  [   64/  124]
train() client id: f_00002-0-2 loss: 0.967990  [   96/  124]
train() client id: f_00002-1-0 loss: 0.943018  [   32/  124]
train() client id: f_00002-1-1 loss: 1.165362  [   64/  124]
train() client id: f_00002-1-2 loss: 0.891504  [   96/  124]
train() client id: f_00002-2-0 loss: 0.947265  [   32/  124]
train() client id: f_00002-2-1 loss: 0.962634  [   64/  124]
train() client id: f_00002-2-2 loss: 1.000414  [   96/  124]
train() client id: f_00002-3-0 loss: 0.835412  [   32/  124]
train() client id: f_00002-3-1 loss: 0.875021  [   64/  124]
train() client id: f_00002-3-2 loss: 0.821263  [   96/  124]
train() client id: f_00002-4-0 loss: 0.987361  [   32/  124]
train() client id: f_00002-4-1 loss: 0.864807  [   64/  124]
train() client id: f_00002-4-2 loss: 0.890970  [   96/  124]
train() client id: f_00002-5-0 loss: 0.783181  [   32/  124]
train() client id: f_00002-5-1 loss: 0.812179  [   64/  124]
train() client id: f_00002-5-2 loss: 0.910518  [   96/  124]
train() client id: f_00002-6-0 loss: 0.902703  [   32/  124]
train() client id: f_00002-6-1 loss: 0.756696  [   64/  124]
train() client id: f_00002-6-2 loss: 0.729536  [   96/  124]
train() client id: f_00002-7-0 loss: 1.021916  [   32/  124]
train() client id: f_00002-7-1 loss: 0.853706  [   64/  124]
train() client id: f_00002-7-2 loss: 0.720257  [   96/  124]
train() client id: f_00002-8-0 loss: 0.830852  [   32/  124]
train() client id: f_00002-8-1 loss: 0.703965  [   64/  124]
train() client id: f_00002-8-2 loss: 0.846371  [   96/  124]
train() client id: f_00002-9-0 loss: 0.854332  [   32/  124]
train() client id: f_00002-9-1 loss: 0.902118  [   64/  124]
train() client id: f_00002-9-2 loss: 0.748204  [   96/  124]
train() client id: f_00002-10-0 loss: 0.867562  [   32/  124]
train() client id: f_00002-10-1 loss: 0.682166  [   64/  124]
train() client id: f_00002-10-2 loss: 0.686410  [   96/  124]
train() client id: f_00002-11-0 loss: 1.026428  [   32/  124]
train() client id: f_00002-11-1 loss: 0.721424  [   64/  124]
train() client id: f_00002-11-2 loss: 0.793869  [   96/  124]
train() client id: f_00002-12-0 loss: 0.659227  [   32/  124]
train() client id: f_00002-12-1 loss: 0.900109  [   64/  124]
train() client id: f_00002-12-2 loss: 0.832800  [   96/  124]
train() client id: f_00003-0-0 loss: 0.721969  [   32/   43]
train() client id: f_00003-1-0 loss: 0.632023  [   32/   43]
train() client id: f_00003-2-0 loss: 0.457945  [   32/   43]
train() client id: f_00003-3-0 loss: 0.688780  [   32/   43]
train() client id: f_00003-4-0 loss: 0.691604  [   32/   43]
train() client id: f_00003-5-0 loss: 0.719421  [   32/   43]
train() client id: f_00003-6-0 loss: 0.612635  [   32/   43]
train() client id: f_00003-7-0 loss: 0.573999  [   32/   43]
train() client id: f_00003-8-0 loss: 0.687937  [   32/   43]
train() client id: f_00003-9-0 loss: 0.672686  [   32/   43]
train() client id: f_00003-10-0 loss: 0.893011  [   32/   43]
train() client id: f_00003-11-0 loss: 0.573681  [   32/   43]
train() client id: f_00003-12-0 loss: 0.709054  [   32/   43]
train() client id: f_00004-0-0 loss: 0.862193  [   32/  306]
train() client id: f_00004-0-1 loss: 0.956690  [   64/  306]
train() client id: f_00004-0-2 loss: 0.979426  [   96/  306]
train() client id: f_00004-0-3 loss: 0.776157  [  128/  306]
train() client id: f_00004-0-4 loss: 0.963614  [  160/  306]
train() client id: f_00004-0-5 loss: 0.739406  [  192/  306]
train() client id: f_00004-0-6 loss: 0.824262  [  224/  306]
train() client id: f_00004-0-7 loss: 0.911371  [  256/  306]
train() client id: f_00004-0-8 loss: 0.801778  [  288/  306]
train() client id: f_00004-1-0 loss: 0.685909  [   32/  306]
train() client id: f_00004-1-1 loss: 0.832395  [   64/  306]
train() client id: f_00004-1-2 loss: 0.909912  [   96/  306]
train() client id: f_00004-1-3 loss: 0.847694  [  128/  306]
train() client id: f_00004-1-4 loss: 1.039405  [  160/  306]
train() client id: f_00004-1-5 loss: 0.892280  [  192/  306]
train() client id: f_00004-1-6 loss: 0.888377  [  224/  306]
train() client id: f_00004-1-7 loss: 0.902020  [  256/  306]
train() client id: f_00004-1-8 loss: 0.813446  [  288/  306]
train() client id: f_00004-2-0 loss: 0.908873  [   32/  306]
train() client id: f_00004-2-1 loss: 0.916223  [   64/  306]
train() client id: f_00004-2-2 loss: 0.837143  [   96/  306]
train() client id: f_00004-2-3 loss: 0.897904  [  128/  306]
train() client id: f_00004-2-4 loss: 0.875264  [  160/  306]
train() client id: f_00004-2-5 loss: 0.897155  [  192/  306]
train() client id: f_00004-2-6 loss: 0.821203  [  224/  306]
train() client id: f_00004-2-7 loss: 0.628846  [  256/  306]
train() client id: f_00004-2-8 loss: 0.943428  [  288/  306]
train() client id: f_00004-3-0 loss: 0.806508  [   32/  306]
train() client id: f_00004-3-1 loss: 0.846146  [   64/  306]
train() client id: f_00004-3-2 loss: 0.903601  [   96/  306]
train() client id: f_00004-3-3 loss: 0.746119  [  128/  306]
train() client id: f_00004-3-4 loss: 0.860215  [  160/  306]
train() client id: f_00004-3-5 loss: 0.804212  [  192/  306]
train() client id: f_00004-3-6 loss: 0.992665  [  224/  306]
train() client id: f_00004-3-7 loss: 0.854134  [  256/  306]
train() client id: f_00004-3-8 loss: 0.883377  [  288/  306]
train() client id: f_00004-4-0 loss: 0.935419  [   32/  306]
train() client id: f_00004-4-1 loss: 0.762881  [   64/  306]
train() client id: f_00004-4-2 loss: 0.857357  [   96/  306]
train() client id: f_00004-4-3 loss: 0.783858  [  128/  306]
train() client id: f_00004-4-4 loss: 0.947813  [  160/  306]
train() client id: f_00004-4-5 loss: 0.909676  [  192/  306]
train() client id: f_00004-4-6 loss: 0.865984  [  224/  306]
train() client id: f_00004-4-7 loss: 0.783744  [  256/  306]
train() client id: f_00004-4-8 loss: 0.870378  [  288/  306]
train() client id: f_00004-5-0 loss: 0.681560  [   32/  306]
train() client id: f_00004-5-1 loss: 1.034853  [   64/  306]
train() client id: f_00004-5-2 loss: 0.930988  [   96/  306]
train() client id: f_00004-5-3 loss: 0.821948  [  128/  306]
train() client id: f_00004-5-4 loss: 0.861816  [  160/  306]
train() client id: f_00004-5-5 loss: 0.935433  [  192/  306]
train() client id: f_00004-5-6 loss: 0.863853  [  224/  306]
train() client id: f_00004-5-7 loss: 0.892879  [  256/  306]
train() client id: f_00004-5-8 loss: 0.724123  [  288/  306]
train() client id: f_00004-6-0 loss: 0.819552  [   32/  306]
train() client id: f_00004-6-1 loss: 0.959695  [   64/  306]
train() client id: f_00004-6-2 loss: 0.754739  [   96/  306]
train() client id: f_00004-6-3 loss: 0.834557  [  128/  306]
train() client id: f_00004-6-4 loss: 0.893707  [  160/  306]
train() client id: f_00004-6-5 loss: 0.845739  [  192/  306]
train() client id: f_00004-6-6 loss: 1.009064  [  224/  306]
train() client id: f_00004-6-7 loss: 0.832935  [  256/  306]
train() client id: f_00004-6-8 loss: 0.767939  [  288/  306]
train() client id: f_00004-7-0 loss: 0.858068  [   32/  306]
train() client id: f_00004-7-1 loss: 0.785743  [   64/  306]
train() client id: f_00004-7-2 loss: 0.889534  [   96/  306]
train() client id: f_00004-7-3 loss: 0.806273  [  128/  306]
train() client id: f_00004-7-4 loss: 0.768860  [  160/  306]
train() client id: f_00004-7-5 loss: 1.063264  [  192/  306]
train() client id: f_00004-7-6 loss: 0.885035  [  224/  306]
train() client id: f_00004-7-7 loss: 0.775921  [  256/  306]
train() client id: f_00004-7-8 loss: 0.826445  [  288/  306]
train() client id: f_00004-8-0 loss: 0.865795  [   32/  306]
train() client id: f_00004-8-1 loss: 0.845099  [   64/  306]
train() client id: f_00004-8-2 loss: 0.819832  [   96/  306]
train() client id: f_00004-8-3 loss: 0.859788  [  128/  306]
train() client id: f_00004-8-4 loss: 0.807435  [  160/  306]
train() client id: f_00004-8-5 loss: 0.798985  [  192/  306]
train() client id: f_00004-8-6 loss: 0.797931  [  224/  306]
train() client id: f_00004-8-7 loss: 0.916789  [  256/  306]
train() client id: f_00004-8-8 loss: 0.926053  [  288/  306]
train() client id: f_00004-9-0 loss: 0.820080  [   32/  306]
train() client id: f_00004-9-1 loss: 0.698220  [   64/  306]
train() client id: f_00004-9-2 loss: 0.953252  [   96/  306]
train() client id: f_00004-9-3 loss: 0.716890  [  128/  306]
train() client id: f_00004-9-4 loss: 0.980478  [  160/  306]
train() client id: f_00004-9-5 loss: 0.806473  [  192/  306]
train() client id: f_00004-9-6 loss: 0.867542  [  224/  306]
train() client id: f_00004-9-7 loss: 0.912184  [  256/  306]
train() client id: f_00004-9-8 loss: 0.897985  [  288/  306]
train() client id: f_00004-10-0 loss: 0.785120  [   32/  306]
train() client id: f_00004-10-1 loss: 0.790299  [   64/  306]
train() client id: f_00004-10-2 loss: 0.864078  [   96/  306]
train() client id: f_00004-10-3 loss: 1.014168  [  128/  306]
train() client id: f_00004-10-4 loss: 0.800853  [  160/  306]
train() client id: f_00004-10-5 loss: 0.766594  [  192/  306]
train() client id: f_00004-10-6 loss: 0.927991  [  224/  306]
train() client id: f_00004-10-7 loss: 0.846486  [  256/  306]
train() client id: f_00004-10-8 loss: 0.877668  [  288/  306]
train() client id: f_00004-11-0 loss: 0.677714  [   32/  306]
train() client id: f_00004-11-1 loss: 0.851381  [   64/  306]
train() client id: f_00004-11-2 loss: 0.891300  [   96/  306]
train() client id: f_00004-11-3 loss: 0.899743  [  128/  306]
train() client id: f_00004-11-4 loss: 0.853407  [  160/  306]
train() client id: f_00004-11-5 loss: 0.778426  [  192/  306]
train() client id: f_00004-11-6 loss: 0.848071  [  224/  306]
train() client id: f_00004-11-7 loss: 0.974086  [  256/  306]
train() client id: f_00004-11-8 loss: 0.879993  [  288/  306]
train() client id: f_00004-12-0 loss: 0.927104  [   32/  306]
train() client id: f_00004-12-1 loss: 0.809312  [   64/  306]
train() client id: f_00004-12-2 loss: 0.810229  [   96/  306]
train() client id: f_00004-12-3 loss: 0.970797  [  128/  306]
train() client id: f_00004-12-4 loss: 0.719984  [  160/  306]
train() client id: f_00004-12-5 loss: 0.668106  [  192/  306]
train() client id: f_00004-12-6 loss: 0.881448  [  224/  306]
train() client id: f_00004-12-7 loss: 0.853624  [  256/  306]
train() client id: f_00004-12-8 loss: 0.963321  [  288/  306]
train() client id: f_00005-0-0 loss: 0.608054  [   32/  146]
train() client id: f_00005-0-1 loss: 0.928956  [   64/  146]
train() client id: f_00005-0-2 loss: 0.825721  [   96/  146]
train() client id: f_00005-0-3 loss: 0.675987  [  128/  146]
train() client id: f_00005-1-0 loss: 0.583795  [   32/  146]
train() client id: f_00005-1-1 loss: 0.760930  [   64/  146]
train() client id: f_00005-1-2 loss: 0.927103  [   96/  146]
train() client id: f_00005-1-3 loss: 0.592504  [  128/  146]
train() client id: f_00005-2-0 loss: 0.734169  [   32/  146]
train() client id: f_00005-2-1 loss: 0.646458  [   64/  146]
train() client id: f_00005-2-2 loss: 0.802796  [   96/  146]
train() client id: f_00005-2-3 loss: 0.677201  [  128/  146]
train() client id: f_00005-3-0 loss: 1.003236  [   32/  146]
train() client id: f_00005-3-1 loss: 0.585432  [   64/  146]
train() client id: f_00005-3-2 loss: 0.885484  [   96/  146]
train() client id: f_00005-3-3 loss: 0.567682  [  128/  146]
train() client id: f_00005-4-0 loss: 0.584302  [   32/  146]
train() client id: f_00005-4-1 loss: 0.911169  [   64/  146]
train() client id: f_00005-4-2 loss: 0.940362  [   96/  146]
train() client id: f_00005-4-3 loss: 0.648327  [  128/  146]
train() client id: f_00005-5-0 loss: 0.741487  [   32/  146]
train() client id: f_00005-5-1 loss: 0.998612  [   64/  146]
train() client id: f_00005-5-2 loss: 0.674005  [   96/  146]
train() client id: f_00005-5-3 loss: 0.635463  [  128/  146]
train() client id: f_00005-6-0 loss: 0.730288  [   32/  146]
train() client id: f_00005-6-1 loss: 0.666095  [   64/  146]
train() client id: f_00005-6-2 loss: 0.769542  [   96/  146]
train() client id: f_00005-6-3 loss: 0.703946  [  128/  146]
train() client id: f_00005-7-0 loss: 0.853688  [   32/  146]
train() client id: f_00005-7-1 loss: 0.876204  [   64/  146]
train() client id: f_00005-7-2 loss: 0.707958  [   96/  146]
train() client id: f_00005-7-3 loss: 0.615237  [  128/  146]
train() client id: f_00005-8-0 loss: 0.598237  [   32/  146]
train() client id: f_00005-8-1 loss: 0.656246  [   64/  146]
train() client id: f_00005-8-2 loss: 0.708272  [   96/  146]
train() client id: f_00005-8-3 loss: 0.881853  [  128/  146]
train() client id: f_00005-9-0 loss: 0.733042  [   32/  146]
train() client id: f_00005-9-1 loss: 0.669225  [   64/  146]
train() client id: f_00005-9-2 loss: 0.630281  [   96/  146]
train() client id: f_00005-9-3 loss: 0.683769  [  128/  146]
train() client id: f_00005-10-0 loss: 0.759887  [   32/  146]
train() client id: f_00005-10-1 loss: 0.884654  [   64/  146]
train() client id: f_00005-10-2 loss: 0.598649  [   96/  146]
train() client id: f_00005-10-3 loss: 0.669019  [  128/  146]
train() client id: f_00005-11-0 loss: 0.771636  [   32/  146]
train() client id: f_00005-11-1 loss: 0.880829  [   64/  146]
train() client id: f_00005-11-2 loss: 0.630889  [   96/  146]
train() client id: f_00005-11-3 loss: 0.577472  [  128/  146]
train() client id: f_00005-12-0 loss: 0.605671  [   32/  146]
train() client id: f_00005-12-1 loss: 0.737491  [   64/  146]
train() client id: f_00005-12-2 loss: 0.691464  [   96/  146]
train() client id: f_00005-12-3 loss: 0.787875  [  128/  146]
train() client id: f_00006-0-0 loss: 0.490863  [   32/   54]
train() client id: f_00006-1-0 loss: 0.517112  [   32/   54]
train() client id: f_00006-2-0 loss: 0.468800  [   32/   54]
train() client id: f_00006-3-0 loss: 0.489788  [   32/   54]
train() client id: f_00006-4-0 loss: 0.495743  [   32/   54]
train() client id: f_00006-5-0 loss: 0.531901  [   32/   54]
train() client id: f_00006-6-0 loss: 0.540501  [   32/   54]
train() client id: f_00006-7-0 loss: 0.489950  [   32/   54]
train() client id: f_00006-8-0 loss: 0.471237  [   32/   54]
train() client id: f_00006-9-0 loss: 0.507197  [   32/   54]
train() client id: f_00006-10-0 loss: 0.543363  [   32/   54]
train() client id: f_00006-11-0 loss: 0.541623  [   32/   54]
train() client id: f_00006-12-0 loss: 0.549374  [   32/   54]
train() client id: f_00007-0-0 loss: 0.566634  [   32/  179]
train() client id: f_00007-0-1 loss: 0.533024  [   64/  179]
train() client id: f_00007-0-2 loss: 0.437995  [   96/  179]
train() client id: f_00007-0-3 loss: 0.398841  [  128/  179]
train() client id: f_00007-0-4 loss: 0.424180  [  160/  179]
train() client id: f_00007-1-0 loss: 0.244894  [   32/  179]
train() client id: f_00007-1-1 loss: 0.402564  [   64/  179]
train() client id: f_00007-1-2 loss: 0.472010  [   96/  179]
train() client id: f_00007-1-3 loss: 0.686025  [  128/  179]
train() client id: f_00007-1-4 loss: 0.450494  [  160/  179]
train() client id: f_00007-2-0 loss: 0.375887  [   32/  179]
train() client id: f_00007-2-1 loss: 0.390355  [   64/  179]
train() client id: f_00007-2-2 loss: 0.358849  [   96/  179]
train() client id: f_00007-2-3 loss: 0.596168  [  128/  179]
train() client id: f_00007-2-4 loss: 0.457148  [  160/  179]
train() client id: f_00007-3-0 loss: 0.446166  [   32/  179]
train() client id: f_00007-3-1 loss: 0.372282  [   64/  179]
train() client id: f_00007-3-2 loss: 0.489819  [   96/  179]
train() client id: f_00007-3-3 loss: 0.409470  [  128/  179]
train() client id: f_00007-3-4 loss: 0.405026  [  160/  179]
train() client id: f_00007-4-0 loss: 0.479002  [   32/  179]
train() client id: f_00007-4-1 loss: 0.317136  [   64/  179]
train() client id: f_00007-4-2 loss: 0.541795  [   96/  179]
train() client id: f_00007-4-3 loss: 0.265439  [  128/  179]
train() client id: f_00007-4-4 loss: 0.609125  [  160/  179]
train() client id: f_00007-5-0 loss: 0.278856  [   32/  179]
train() client id: f_00007-5-1 loss: 0.485330  [   64/  179]
train() client id: f_00007-5-2 loss: 0.287209  [   96/  179]
train() client id: f_00007-5-3 loss: 0.614900  [  128/  179]
train() client id: f_00007-5-4 loss: 0.401620  [  160/  179]
train() client id: f_00007-6-0 loss: 0.356688  [   32/  179]
train() client id: f_00007-6-1 loss: 0.610041  [   64/  179]
train() client id: f_00007-6-2 loss: 0.422701  [   96/  179]
train() client id: f_00007-6-3 loss: 0.449652  [  128/  179]
train() client id: f_00007-6-4 loss: 0.318149  [  160/  179]
train() client id: f_00007-7-0 loss: 0.243661  [   32/  179]
train() client id: f_00007-7-1 loss: 0.508779  [   64/  179]
train() client id: f_00007-7-2 loss: 0.395599  [   96/  179]
train() client id: f_00007-7-3 loss: 0.355062  [  128/  179]
train() client id: f_00007-7-4 loss: 0.317622  [  160/  179]
train() client id: f_00007-8-0 loss: 0.357493  [   32/  179]
train() client id: f_00007-8-1 loss: 0.241742  [   64/  179]
train() client id: f_00007-8-2 loss: 0.342311  [   96/  179]
train() client id: f_00007-8-3 loss: 0.569165  [  128/  179]
train() client id: f_00007-8-4 loss: 0.481347  [  160/  179]
train() client id: f_00007-9-0 loss: 0.244556  [   32/  179]
train() client id: f_00007-9-1 loss: 0.571629  [   64/  179]
train() client id: f_00007-9-2 loss: 0.412331  [   96/  179]
train() client id: f_00007-9-3 loss: 0.319615  [  128/  179]
train() client id: f_00007-9-4 loss: 0.530781  [  160/  179]
train() client id: f_00007-10-0 loss: 0.305583  [   32/  179]
train() client id: f_00007-10-1 loss: 0.269702  [   64/  179]
train() client id: f_00007-10-2 loss: 0.392330  [   96/  179]
train() client id: f_00007-10-3 loss: 0.513344  [  128/  179]
train() client id: f_00007-10-4 loss: 0.480518  [  160/  179]
train() client id: f_00007-11-0 loss: 0.554499  [   32/  179]
train() client id: f_00007-11-1 loss: 0.350756  [   64/  179]
train() client id: f_00007-11-2 loss: 0.324964  [   96/  179]
train() client id: f_00007-11-3 loss: 0.402521  [  128/  179]
train() client id: f_00007-11-4 loss: 0.424270  [  160/  179]
train() client id: f_00007-12-0 loss: 0.663049  [   32/  179]
train() client id: f_00007-12-1 loss: 0.200619  [   64/  179]
train() client id: f_00007-12-2 loss: 0.455240  [   96/  179]
train() client id: f_00007-12-3 loss: 0.326997  [  128/  179]
train() client id: f_00007-12-4 loss: 0.238337  [  160/  179]
train() client id: f_00008-0-0 loss: 0.788012  [   32/  130]
train() client id: f_00008-0-1 loss: 0.712585  [   64/  130]
train() client id: f_00008-0-2 loss: 0.816818  [   96/  130]
train() client id: f_00008-0-3 loss: 0.788665  [  128/  130]
train() client id: f_00008-1-0 loss: 0.820233  [   32/  130]
train() client id: f_00008-1-1 loss: 0.708845  [   64/  130]
train() client id: f_00008-1-2 loss: 0.801290  [   96/  130]
train() client id: f_00008-1-3 loss: 0.787337  [  128/  130]
train() client id: f_00008-2-0 loss: 0.829213  [   32/  130]
train() client id: f_00008-2-1 loss: 0.842925  [   64/  130]
train() client id: f_00008-2-2 loss: 0.689310  [   96/  130]
train() client id: f_00008-2-3 loss: 0.714851  [  128/  130]
train() client id: f_00008-3-0 loss: 0.756142  [   32/  130]
train() client id: f_00008-3-1 loss: 0.835041  [   64/  130]
train() client id: f_00008-3-2 loss: 0.838272  [   96/  130]
train() client id: f_00008-3-3 loss: 0.674159  [  128/  130]
train() client id: f_00008-4-0 loss: 0.751544  [   32/  130]
train() client id: f_00008-4-1 loss: 0.793396  [   64/  130]
train() client id: f_00008-4-2 loss: 0.752330  [   96/  130]
train() client id: f_00008-4-3 loss: 0.775898  [  128/  130]
train() client id: f_00008-5-0 loss: 0.742424  [   32/  130]
train() client id: f_00008-5-1 loss: 0.811763  [   64/  130]
train() client id: f_00008-5-2 loss: 0.770669  [   96/  130]
train() client id: f_00008-5-3 loss: 0.782950  [  128/  130]
train() client id: f_00008-6-0 loss: 0.793274  [   32/  130]
train() client id: f_00008-6-1 loss: 0.809476  [   64/  130]
train() client id: f_00008-6-2 loss: 0.685450  [   96/  130]
train() client id: f_00008-6-3 loss: 0.814441  [  128/  130]
train() client id: f_00008-7-0 loss: 0.785698  [   32/  130]
train() client id: f_00008-7-1 loss: 0.841948  [   64/  130]
train() client id: f_00008-7-2 loss: 0.652093  [   96/  130]
train() client id: f_00008-7-3 loss: 0.793145  [  128/  130]
train() client id: f_00008-8-0 loss: 0.666634  [   32/  130]
train() client id: f_00008-8-1 loss: 0.822151  [   64/  130]
train() client id: f_00008-8-2 loss: 0.886198  [   96/  130]
train() client id: f_00008-8-3 loss: 0.721126  [  128/  130]
train() client id: f_00008-9-0 loss: 0.724925  [   32/  130]
train() client id: f_00008-9-1 loss: 0.762376  [   64/  130]
train() client id: f_00008-9-2 loss: 0.726365  [   96/  130]
train() client id: f_00008-9-3 loss: 0.882268  [  128/  130]
train() client id: f_00008-10-0 loss: 0.828856  [   32/  130]
train() client id: f_00008-10-1 loss: 0.858650  [   64/  130]
train() client id: f_00008-10-2 loss: 0.686979  [   96/  130]
train() client id: f_00008-10-3 loss: 0.704647  [  128/  130]
train() client id: f_00008-11-0 loss: 0.700024  [   32/  130]
train() client id: f_00008-11-1 loss: 0.903347  [   64/  130]
train() client id: f_00008-11-2 loss: 0.712141  [   96/  130]
train() client id: f_00008-11-3 loss: 0.740901  [  128/  130]
train() client id: f_00008-12-0 loss: 0.722467  [   32/  130]
train() client id: f_00008-12-1 loss: 0.794155  [   64/  130]
train() client id: f_00008-12-2 loss: 0.798097  [   96/  130]
train() client id: f_00008-12-3 loss: 0.773379  [  128/  130]
train() client id: f_00009-0-0 loss: 1.023702  [   32/  118]
train() client id: f_00009-0-1 loss: 0.916947  [   64/  118]
train() client id: f_00009-0-2 loss: 0.909911  [   96/  118]
train() client id: f_00009-1-0 loss: 0.945632  [   32/  118]
train() client id: f_00009-1-1 loss: 0.993381  [   64/  118]
train() client id: f_00009-1-2 loss: 0.904893  [   96/  118]
train() client id: f_00009-2-0 loss: 0.868459  [   32/  118]
train() client id: f_00009-2-1 loss: 0.890380  [   64/  118]
train() client id: f_00009-2-2 loss: 0.958341  [   96/  118]
train() client id: f_00009-3-0 loss: 0.862977  [   32/  118]
train() client id: f_00009-3-1 loss: 0.928506  [   64/  118]
train() client id: f_00009-3-2 loss: 0.749190  [   96/  118]
train() client id: f_00009-4-0 loss: 0.813048  [   32/  118]
train() client id: f_00009-4-1 loss: 0.841404  [   64/  118]
train() client id: f_00009-4-2 loss: 0.874511  [   96/  118]
train() client id: f_00009-5-0 loss: 0.773945  [   32/  118]
train() client id: f_00009-5-1 loss: 0.751272  [   64/  118]
train() client id: f_00009-5-2 loss: 0.813533  [   96/  118]
train() client id: f_00009-6-0 loss: 0.792586  [   32/  118]
train() client id: f_00009-6-1 loss: 0.945256  [   64/  118]
train() client id: f_00009-6-2 loss: 0.656085  [   96/  118]
train() client id: f_00009-7-0 loss: 0.796107  [   32/  118]
train() client id: f_00009-7-1 loss: 0.636549  [   64/  118]
train() client id: f_00009-7-2 loss: 0.825250  [   96/  118]
train() client id: f_00009-8-0 loss: 0.703831  [   32/  118]
train() client id: f_00009-8-1 loss: 0.990590  [   64/  118]
train() client id: f_00009-8-2 loss: 0.763935  [   96/  118]
train() client id: f_00009-9-0 loss: 0.898622  [   32/  118]
train() client id: f_00009-9-1 loss: 0.770041  [   64/  118]
train() client id: f_00009-9-2 loss: 0.645091  [   96/  118]
train() client id: f_00009-10-0 loss: 0.695256  [   32/  118]
train() client id: f_00009-10-1 loss: 0.821627  [   64/  118]
train() client id: f_00009-10-2 loss: 0.715626  [   96/  118]
train() client id: f_00009-11-0 loss: 0.819607  [   32/  118]
train() client id: f_00009-11-1 loss: 0.865382  [   64/  118]
train() client id: f_00009-11-2 loss: 0.705561  [   96/  118]
train() client id: f_00009-12-0 loss: 0.732974  [   32/  118]
train() client id: f_00009-12-1 loss: 0.611781  [   64/  118]
train() client id: f_00009-12-2 loss: 0.752000  [   96/  118]
At round 47 accuracy: 0.6445623342175066
At round 47 training accuracy: 0.5915492957746479
At round 47 training loss: 0.8252481106124034
gradient difference: 0.3978869616985321
train() client id: f_00000-0-0 loss: 1.165171  [   32/  126]
train() client id: f_00000-0-1 loss: 1.040516  [   64/  126]
train() client id: f_00000-0-2 loss: 1.134031  [   96/  126]
train() client id: f_00000-1-0 loss: 0.902750  [   32/  126]
train() client id: f_00000-1-1 loss: 1.220395  [   64/  126]
train() client id: f_00000-1-2 loss: 1.057186  [   96/  126]
train() client id: f_00000-2-0 loss: 0.909069  [   32/  126]
train() client id: f_00000-2-1 loss: 0.927435  [   64/  126]
train() client id: f_00000-2-2 loss: 0.925094  [   96/  126]
train() client id: f_00000-3-0 loss: 0.949092  [   32/  126]
train() client id: f_00000-3-1 loss: 0.844868  [   64/  126]
train() client id: f_00000-3-2 loss: 0.964534  [   96/  126]
train() client id: f_00000-4-0 loss: 0.863826  [   32/  126]
train() client id: f_00000-4-1 loss: 0.743252  [   64/  126]
train() client id: f_00000-4-2 loss: 0.883191  [   96/  126]
train() client id: f_00000-5-0 loss: 0.767018  [   32/  126]
train() client id: f_00000-5-1 loss: 0.837002  [   64/  126]
train() client id: f_00000-5-2 loss: 0.899498  [   96/  126]
train() client id: f_00000-6-0 loss: 0.936004  [   32/  126]
train() client id: f_00000-6-1 loss: 0.735033  [   64/  126]
train() client id: f_00000-6-2 loss: 0.702323  [   96/  126]
train() client id: f_00000-7-0 loss: 0.765549  [   32/  126]
train() client id: f_00000-7-1 loss: 0.691555  [   64/  126]
train() client id: f_00000-7-2 loss: 0.691035  [   96/  126]
train() client id: f_00000-8-0 loss: 0.636328  [   32/  126]
train() client id: f_00000-8-1 loss: 0.793310  [   64/  126]
train() client id: f_00000-8-2 loss: 0.699680  [   96/  126]
train() client id: f_00000-9-0 loss: 0.845332  [   32/  126]
train() client id: f_00000-9-1 loss: 0.557594  [   64/  126]
train() client id: f_00000-9-2 loss: 0.739520  [   96/  126]
train() client id: f_00000-10-0 loss: 0.645569  [   32/  126]
train() client id: f_00000-10-1 loss: 0.805669  [   64/  126]
train() client id: f_00000-10-2 loss: 0.665243  [   96/  126]
train() client id: f_00000-11-0 loss: 0.702824  [   32/  126]
train() client id: f_00000-11-1 loss: 0.626015  [   64/  126]
train() client id: f_00000-11-2 loss: 0.786679  [   96/  126]
train() client id: f_00000-12-0 loss: 0.620462  [   32/  126]
train() client id: f_00000-12-1 loss: 0.789597  [   64/  126]
train() client id: f_00000-12-2 loss: 0.666760  [   96/  126]
train() client id: f_00001-0-0 loss: 0.259729  [   32/  265]
train() client id: f_00001-0-1 loss: 0.185535  [   64/  265]
train() client id: f_00001-0-2 loss: 0.378135  [   96/  265]
train() client id: f_00001-0-3 loss: 0.219213  [  128/  265]
train() client id: f_00001-0-4 loss: 0.178228  [  160/  265]
train() client id: f_00001-0-5 loss: 0.237001  [  192/  265]
train() client id: f_00001-0-6 loss: 0.211332  [  224/  265]
train() client id: f_00001-0-7 loss: 0.240483  [  256/  265]
train() client id: f_00001-1-0 loss: 0.262585  [   32/  265]
train() client id: f_00001-1-1 loss: 0.217214  [   64/  265]
train() client id: f_00001-1-2 loss: 0.210869  [   96/  265]
train() client id: f_00001-1-3 loss: 0.197689  [  128/  265]
train() client id: f_00001-1-4 loss: 0.301574  [  160/  265]
train() client id: f_00001-1-5 loss: 0.156207  [  192/  265]
train() client id: f_00001-1-6 loss: 0.340993  [  224/  265]
train() client id: f_00001-1-7 loss: 0.227604  [  256/  265]
train() client id: f_00001-2-0 loss: 0.229904  [   32/  265]
train() client id: f_00001-2-1 loss: 0.203444  [   64/  265]
train() client id: f_00001-2-2 loss: 0.203254  [   96/  265]
train() client id: f_00001-2-3 loss: 0.173943  [  128/  265]
train() client id: f_00001-2-4 loss: 0.218065  [  160/  265]
train() client id: f_00001-2-5 loss: 0.229955  [  192/  265]
train() client id: f_00001-2-6 loss: 0.275034  [  224/  265]
train() client id: f_00001-2-7 loss: 0.245749  [  256/  265]
train() client id: f_00001-3-0 loss: 0.207172  [   32/  265]
train() client id: f_00001-3-1 loss: 0.294994  [   64/  265]
train() client id: f_00001-3-2 loss: 0.255179  [   96/  265]
train() client id: f_00001-3-3 loss: 0.250766  [  128/  265]
train() client id: f_00001-3-4 loss: 0.133440  [  160/  265]
train() client id: f_00001-3-5 loss: 0.144628  [  192/  265]
train() client id: f_00001-3-6 loss: 0.202650  [  224/  265]
train() client id: f_00001-3-7 loss: 0.293147  [  256/  265]
train() client id: f_00001-4-0 loss: 0.190323  [   32/  265]
train() client id: f_00001-4-1 loss: 0.270814  [   64/  265]
train() client id: f_00001-4-2 loss: 0.245093  [   96/  265]
train() client id: f_00001-4-3 loss: 0.297870  [  128/  265]
train() client id: f_00001-4-4 loss: 0.137877  [  160/  265]
train() client id: f_00001-4-5 loss: 0.215419  [  192/  265]
train() client id: f_00001-4-6 loss: 0.210895  [  224/  265]
train() client id: f_00001-4-7 loss: 0.176025  [  256/  265]
train() client id: f_00001-5-0 loss: 0.184783  [   32/  265]
train() client id: f_00001-5-1 loss: 0.132804  [   64/  265]
train() client id: f_00001-5-2 loss: 0.180401  [   96/  265]
train() client id: f_00001-5-3 loss: 0.378186  [  128/  265]
train() client id: f_00001-5-4 loss: 0.223263  [  160/  265]
train() client id: f_00001-5-5 loss: 0.219831  [  192/  265]
train() client id: f_00001-5-6 loss: 0.128406  [  224/  265]
train() client id: f_00001-5-7 loss: 0.164429  [  256/  265]
train() client id: f_00001-6-0 loss: 0.231547  [   32/  265]
train() client id: f_00001-6-1 loss: 0.324272  [   64/  265]
train() client id: f_00001-6-2 loss: 0.250815  [   96/  265]
train() client id: f_00001-6-3 loss: 0.176148  [  128/  265]
train() client id: f_00001-6-4 loss: 0.144108  [  160/  265]
train() client id: f_00001-6-5 loss: 0.157465  [  192/  265]
train() client id: f_00001-6-6 loss: 0.219183  [  224/  265]
train() client id: f_00001-6-7 loss: 0.159517  [  256/  265]
train() client id: f_00001-7-0 loss: 0.152154  [   32/  265]
train() client id: f_00001-7-1 loss: 0.264279  [   64/  265]
train() client id: f_00001-7-2 loss: 0.127325  [   96/  265]
train() client id: f_00001-7-3 loss: 0.260056  [  128/  265]
train() client id: f_00001-7-4 loss: 0.256987  [  160/  265]
train() client id: f_00001-7-5 loss: 0.145482  [  192/  265]
train() client id: f_00001-7-6 loss: 0.184030  [  224/  265]
train() client id: f_00001-7-7 loss: 0.244961  [  256/  265]
train() client id: f_00001-8-0 loss: 0.195980  [   32/  265]
train() client id: f_00001-8-1 loss: 0.180966  [   64/  265]
train() client id: f_00001-8-2 loss: 0.152117  [   96/  265]
train() client id: f_00001-8-3 loss: 0.229553  [  128/  265]
train() client id: f_00001-8-4 loss: 0.207699  [  160/  265]
train() client id: f_00001-8-5 loss: 0.156558  [  192/  265]
train() client id: f_00001-8-6 loss: 0.195319  [  224/  265]
train() client id: f_00001-8-7 loss: 0.290661  [  256/  265]
train() client id: f_00001-9-0 loss: 0.248537  [   32/  265]
train() client id: f_00001-9-1 loss: 0.277326  [   64/  265]
train() client id: f_00001-9-2 loss: 0.108629  [   96/  265]
train() client id: f_00001-9-3 loss: 0.244294  [  128/  265]
train() client id: f_00001-9-4 loss: 0.214777  [  160/  265]
train() client id: f_00001-9-5 loss: 0.162428  [  192/  265]
train() client id: f_00001-9-6 loss: 0.101662  [  224/  265]
train() client id: f_00001-9-7 loss: 0.203524  [  256/  265]
train() client id: f_00001-10-0 loss: 0.192623  [   32/  265]
train() client id: f_00001-10-1 loss: 0.198119  [   64/  265]
train() client id: f_00001-10-2 loss: 0.104620  [   96/  265]
train() client id: f_00001-10-3 loss: 0.155129  [  128/  265]
train() client id: f_00001-10-4 loss: 0.323283  [  160/  265]
train() client id: f_00001-10-5 loss: 0.161658  [  192/  265]
train() client id: f_00001-10-6 loss: 0.229234  [  224/  265]
train() client id: f_00001-10-7 loss: 0.217072  [  256/  265]
train() client id: f_00001-11-0 loss: 0.323355  [   32/  265]
train() client id: f_00001-11-1 loss: 0.111252  [   64/  265]
train() client id: f_00001-11-2 loss: 0.105811  [   96/  265]
train() client id: f_00001-11-3 loss: 0.172344  [  128/  265]
train() client id: f_00001-11-4 loss: 0.161372  [  160/  265]
train() client id: f_00001-11-5 loss: 0.350890  [  192/  265]
train() client id: f_00001-11-6 loss: 0.208184  [  224/  265]
train() client id: f_00001-11-7 loss: 0.098520  [  256/  265]
train() client id: f_00001-12-0 loss: 0.252167  [   32/  265]
train() client id: f_00001-12-1 loss: 0.159729  [   64/  265]
train() client id: f_00001-12-2 loss: 0.101796  [   96/  265]
train() client id: f_00001-12-3 loss: 0.161062  [  128/  265]
train() client id: f_00001-12-4 loss: 0.285254  [  160/  265]
train() client id: f_00001-12-5 loss: 0.283326  [  192/  265]
train() client id: f_00001-12-6 loss: 0.134052  [  224/  265]
train() client id: f_00001-12-7 loss: 0.122222  [  256/  265]
train() client id: f_00002-0-0 loss: 1.285063  [   32/  124]
train() client id: f_00002-0-1 loss: 1.094988  [   64/  124]
train() client id: f_00002-0-2 loss: 1.160974  [   96/  124]
train() client id: f_00002-1-0 loss: 1.024725  [   32/  124]
train() client id: f_00002-1-1 loss: 1.268362  [   64/  124]
train() client id: f_00002-1-2 loss: 1.247087  [   96/  124]
train() client id: f_00002-2-0 loss: 1.248061  [   32/  124]
train() client id: f_00002-2-1 loss: 1.102519  [   64/  124]
train() client id: f_00002-2-2 loss: 1.176771  [   96/  124]
train() client id: f_00002-3-0 loss: 1.153268  [   32/  124]
train() client id: f_00002-3-1 loss: 0.957860  [   64/  124]
train() client id: f_00002-3-2 loss: 1.138003  [   96/  124]
train() client id: f_00002-4-0 loss: 1.086080  [   32/  124]
train() client id: f_00002-4-1 loss: 0.845551  [   64/  124]
train() client id: f_00002-4-2 loss: 1.054641  [   96/  124]
train() client id: f_00002-5-0 loss: 1.113850  [   32/  124]
train() client id: f_00002-5-1 loss: 0.944647  [   64/  124]
train() client id: f_00002-5-2 loss: 1.010623  [   96/  124]
train() client id: f_00002-6-0 loss: 1.081679  [   32/  124]
train() client id: f_00002-6-1 loss: 0.947134  [   64/  124]
train() client id: f_00002-6-2 loss: 0.896605  [   96/  124]
train() client id: f_00002-7-0 loss: 1.027415  [   32/  124]
train() client id: f_00002-7-1 loss: 0.984509  [   64/  124]
train() client id: f_00002-7-2 loss: 0.988901  [   96/  124]
train() client id: f_00002-8-0 loss: 0.886989  [   32/  124]
train() client id: f_00002-8-1 loss: 0.863067  [   64/  124]
train() client id: f_00002-8-2 loss: 1.098642  [   96/  124]
train() client id: f_00002-9-0 loss: 1.030595  [   32/  124]
train() client id: f_00002-9-1 loss: 0.986108  [   64/  124]
train() client id: f_00002-9-2 loss: 0.786910  [   96/  124]
train() client id: f_00002-10-0 loss: 0.910550  [   32/  124]
train() client id: f_00002-10-1 loss: 1.074089  [   64/  124]
train() client id: f_00002-10-2 loss: 0.875237  [   96/  124]
train() client id: f_00002-11-0 loss: 0.721649  [   32/  124]
train() client id: f_00002-11-1 loss: 0.964845  [   64/  124]
train() client id: f_00002-11-2 loss: 1.047063  [   96/  124]
train() client id: f_00002-12-0 loss: 0.907129  [   32/  124]
train() client id: f_00002-12-1 loss: 0.755762  [   64/  124]
train() client id: f_00002-12-2 loss: 1.103866  [   96/  124]
train() client id: f_00003-0-0 loss: 0.517033  [   32/   43]
train() client id: f_00003-1-0 loss: 0.515288  [   32/   43]
train() client id: f_00003-2-0 loss: 0.594380  [   32/   43]
train() client id: f_00003-3-0 loss: 0.376279  [   32/   43]
train() client id: f_00003-4-0 loss: 0.510251  [   32/   43]
train() client id: f_00003-5-0 loss: 0.683036  [   32/   43]
train() client id: f_00003-6-0 loss: 0.683712  [   32/   43]
train() client id: f_00003-7-0 loss: 0.574543  [   32/   43]
train() client id: f_00003-8-0 loss: 0.696171  [   32/   43]
train() client id: f_00003-9-0 loss: 0.473870  [   32/   43]
train() client id: f_00003-10-0 loss: 0.693157  [   32/   43]
train() client id: f_00003-11-0 loss: 0.698698  [   32/   43]
train() client id: f_00003-12-0 loss: 0.584659  [   32/   43]
train() client id: f_00004-0-0 loss: 0.809024  [   32/  306]
train() client id: f_00004-0-1 loss: 0.748935  [   64/  306]
train() client id: f_00004-0-2 loss: 0.728349  [   96/  306]
train() client id: f_00004-0-3 loss: 0.918106  [  128/  306]
train() client id: f_00004-0-4 loss: 0.796356  [  160/  306]
train() client id: f_00004-0-5 loss: 0.862367  [  192/  306]
train() client id: f_00004-0-6 loss: 0.802002  [  224/  306]
train() client id: f_00004-0-7 loss: 0.696658  [  256/  306]
train() client id: f_00004-0-8 loss: 0.719714  [  288/  306]
train() client id: f_00004-1-0 loss: 0.739529  [   32/  306]
train() client id: f_00004-1-1 loss: 0.829637  [   64/  306]
train() client id: f_00004-1-2 loss: 0.681264  [   96/  306]
train() client id: f_00004-1-3 loss: 0.894257  [  128/  306]
train() client id: f_00004-1-4 loss: 0.698611  [  160/  306]
train() client id: f_00004-1-5 loss: 0.863352  [  192/  306]
train() client id: f_00004-1-6 loss: 0.756095  [  224/  306]
train() client id: f_00004-1-7 loss: 0.633970  [  256/  306]
train() client id: f_00004-1-8 loss: 0.906493  [  288/  306]
train() client id: f_00004-2-0 loss: 0.741781  [   32/  306]
train() client id: f_00004-2-1 loss: 0.781120  [   64/  306]
train() client id: f_00004-2-2 loss: 0.749074  [   96/  306]
train() client id: f_00004-2-3 loss: 0.775698  [  128/  306]
train() client id: f_00004-2-4 loss: 0.747637  [  160/  306]
train() client id: f_00004-2-5 loss: 0.723270  [  192/  306]
train() client id: f_00004-2-6 loss: 0.749811  [  224/  306]
train() client id: f_00004-2-7 loss: 0.750084  [  256/  306]
train() client id: f_00004-2-8 loss: 0.821263  [  288/  306]
train() client id: f_00004-3-0 loss: 0.735617  [   32/  306]
train() client id: f_00004-3-1 loss: 0.729704  [   64/  306]
train() client id: f_00004-3-2 loss: 0.877446  [   96/  306]
train() client id: f_00004-3-3 loss: 0.738075  [  128/  306]
train() client id: f_00004-3-4 loss: 0.760238  [  160/  306]
train() client id: f_00004-3-5 loss: 0.827131  [  192/  306]
train() client id: f_00004-3-6 loss: 0.695358  [  224/  306]
train() client id: f_00004-3-7 loss: 0.871703  [  256/  306]
train() client id: f_00004-3-8 loss: 0.747702  [  288/  306]
train() client id: f_00004-4-0 loss: 0.718309  [   32/  306]
train() client id: f_00004-4-1 loss: 0.822571  [   64/  306]
train() client id: f_00004-4-2 loss: 0.746697  [   96/  306]
train() client id: f_00004-4-3 loss: 0.750810  [  128/  306]
train() client id: f_00004-4-4 loss: 0.731664  [  160/  306]
train() client id: f_00004-4-5 loss: 0.725892  [  192/  306]
train() client id: f_00004-4-6 loss: 0.781140  [  224/  306]
train() client id: f_00004-4-7 loss: 0.913667  [  256/  306]
train() client id: f_00004-4-8 loss: 0.863215  [  288/  306]
train() client id: f_00004-5-0 loss: 0.687650  [   32/  306]
train() client id: f_00004-5-1 loss: 0.796290  [   64/  306]
train() client id: f_00004-5-2 loss: 0.712258  [   96/  306]
train() client id: f_00004-5-3 loss: 0.843326  [  128/  306]
train() client id: f_00004-5-4 loss: 0.786540  [  160/  306]
train() client id: f_00004-5-5 loss: 0.823860  [  192/  306]
train() client id: f_00004-5-6 loss: 0.862610  [  224/  306]
train() client id: f_00004-5-7 loss: 0.777930  [  256/  306]
train() client id: f_00004-5-8 loss: 0.751873  [  288/  306]
train() client id: f_00004-6-0 loss: 0.660083  [   32/  306]
train() client id: f_00004-6-1 loss: 0.810393  [   64/  306]
train() client id: f_00004-6-2 loss: 0.748671  [   96/  306]
train() client id: f_00004-6-3 loss: 0.758688  [  128/  306]
train() client id: f_00004-6-4 loss: 0.800549  [  160/  306]
train() client id: f_00004-6-5 loss: 0.659402  [  192/  306]
train() client id: f_00004-6-6 loss: 0.762290  [  224/  306]
train() client id: f_00004-6-7 loss: 0.885057  [  256/  306]
train() client id: f_00004-6-8 loss: 0.835207  [  288/  306]
train() client id: f_00004-7-0 loss: 0.664988  [   32/  306]
train() client id: f_00004-7-1 loss: 0.717730  [   64/  306]
train() client id: f_00004-7-2 loss: 0.726113  [   96/  306]
train() client id: f_00004-7-3 loss: 0.766545  [  128/  306]
train() client id: f_00004-7-4 loss: 0.970083  [  160/  306]
train() client id: f_00004-7-5 loss: 0.687862  [  192/  306]
train() client id: f_00004-7-6 loss: 0.842793  [  224/  306]
train() client id: f_00004-7-7 loss: 0.707799  [  256/  306]
train() client id: f_00004-7-8 loss: 0.929678  [  288/  306]
train() client id: f_00004-8-0 loss: 0.862425  [   32/  306]
train() client id: f_00004-8-1 loss: 0.726363  [   64/  306]
train() client id: f_00004-8-2 loss: 0.784768  [   96/  306]
train() client id: f_00004-8-3 loss: 0.735820  [  128/  306]
train() client id: f_00004-8-4 loss: 0.796134  [  160/  306]
train() client id: f_00004-8-5 loss: 0.806639  [  192/  306]
train() client id: f_00004-8-6 loss: 0.748847  [  224/  306]
train() client id: f_00004-8-7 loss: 0.855687  [  256/  306]
train() client id: f_00004-8-8 loss: 0.721705  [  288/  306]
train() client id: f_00004-9-0 loss: 0.786476  [   32/  306]
train() client id: f_00004-9-1 loss: 0.724122  [   64/  306]
train() client id: f_00004-9-2 loss: 0.819899  [   96/  306]
train() client id: f_00004-9-3 loss: 0.756187  [  128/  306]
train() client id: f_00004-9-4 loss: 0.893509  [  160/  306]
train() client id: f_00004-9-5 loss: 0.743706  [  192/  306]
train() client id: f_00004-9-6 loss: 0.764752  [  224/  306]
train() client id: f_00004-9-7 loss: 0.690513  [  256/  306]
train() client id: f_00004-9-8 loss: 0.757858  [  288/  306]
train() client id: f_00004-10-0 loss: 0.742136  [   32/  306]
train() client id: f_00004-10-1 loss: 0.792747  [   64/  306]
train() client id: f_00004-10-2 loss: 0.644126  [   96/  306]
train() client id: f_00004-10-3 loss: 0.816383  [  128/  306]
train() client id: f_00004-10-4 loss: 0.726701  [  160/  306]
train() client id: f_00004-10-5 loss: 0.791225  [  192/  306]
train() client id: f_00004-10-6 loss: 0.919508  [  224/  306]
train() client id: f_00004-10-7 loss: 0.747299  [  256/  306]
train() client id: f_00004-10-8 loss: 0.785333  [  288/  306]
train() client id: f_00004-11-0 loss: 0.707109  [   32/  306]
train() client id: f_00004-11-1 loss: 0.701456  [   64/  306]
train() client id: f_00004-11-2 loss: 0.771435  [   96/  306]
train() client id: f_00004-11-3 loss: 0.761901  [  128/  306]
train() client id: f_00004-11-4 loss: 0.938667  [  160/  306]
train() client id: f_00004-11-5 loss: 0.749408  [  192/  306]
train() client id: f_00004-11-6 loss: 0.835750  [  224/  306]
train() client id: f_00004-11-7 loss: 0.776752  [  256/  306]
train() client id: f_00004-11-8 loss: 0.756700  [  288/  306]
train() client id: f_00004-12-0 loss: 0.803466  [   32/  306]
train() client id: f_00004-12-1 loss: 0.766211  [   64/  306]
train() client id: f_00004-12-2 loss: 0.731668  [   96/  306]
train() client id: f_00004-12-3 loss: 0.774606  [  128/  306]
train() client id: f_00004-12-4 loss: 0.862463  [  160/  306]
train() client id: f_00004-12-5 loss: 0.836913  [  192/  306]
train() client id: f_00004-12-6 loss: 0.630682  [  224/  306]
train() client id: f_00004-12-7 loss: 0.761603  [  256/  306]
train() client id: f_00004-12-8 loss: 0.847783  [  288/  306]
train() client id: f_00005-0-0 loss: 0.753710  [   32/  146]
train() client id: f_00005-0-1 loss: 0.578488  [   64/  146]
train() client id: f_00005-0-2 loss: 0.546272  [   96/  146]
train() client id: f_00005-0-3 loss: 0.530942  [  128/  146]
train() client id: f_00005-1-0 loss: 0.450326  [   32/  146]
train() client id: f_00005-1-1 loss: 0.680241  [   64/  146]
train() client id: f_00005-1-2 loss: 0.486113  [   96/  146]
train() client id: f_00005-1-3 loss: 0.645839  [  128/  146]
train() client id: f_00005-2-0 loss: 0.408205  [   32/  146]
train() client id: f_00005-2-1 loss: 0.632512  [   64/  146]
train() client id: f_00005-2-2 loss: 0.862149  [   96/  146]
train() client id: f_00005-2-3 loss: 0.435756  [  128/  146]
train() client id: f_00005-3-0 loss: 0.542271  [   32/  146]
train() client id: f_00005-3-1 loss: 0.761197  [   64/  146]
train() client id: f_00005-3-2 loss: 0.464518  [   96/  146]
train() client id: f_00005-3-3 loss: 0.598833  [  128/  146]
train() client id: f_00005-4-0 loss: 0.389058  [   32/  146]
train() client id: f_00005-4-1 loss: 0.483390  [   64/  146]
train() client id: f_00005-4-2 loss: 0.697728  [   96/  146]
train() client id: f_00005-4-3 loss: 0.660977  [  128/  146]
train() client id: f_00005-5-0 loss: 0.887636  [   32/  146]
train() client id: f_00005-5-1 loss: 0.456787  [   64/  146]
train() client id: f_00005-5-2 loss: 0.360056  [   96/  146]
train() client id: f_00005-5-3 loss: 0.639263  [  128/  146]
train() client id: f_00005-6-0 loss: 0.561981  [   32/  146]
train() client id: f_00005-6-1 loss: 0.686935  [   64/  146]
train() client id: f_00005-6-2 loss: 0.557449  [   96/  146]
train() client id: f_00005-6-3 loss: 0.584704  [  128/  146]
train() client id: f_00005-7-0 loss: 0.700870  [   32/  146]
train() client id: f_00005-7-1 loss: 0.429859  [   64/  146]
train() client id: f_00005-7-2 loss: 0.500573  [   96/  146]
train() client id: f_00005-7-3 loss: 0.614739  [  128/  146]
train() client id: f_00005-8-0 loss: 0.488966  [   32/  146]
train() client id: f_00005-8-1 loss: 0.419418  [   64/  146]
train() client id: f_00005-8-2 loss: 0.653321  [   96/  146]
train() client id: f_00005-8-3 loss: 0.582336  [  128/  146]
train() client id: f_00005-9-0 loss: 0.562008  [   32/  146]
train() client id: f_00005-9-1 loss: 0.783795  [   64/  146]
train() client id: f_00005-9-2 loss: 0.431754  [   96/  146]
train() client id: f_00005-9-3 loss: 0.676068  [  128/  146]
train() client id: f_00005-10-0 loss: 0.524898  [   32/  146]
train() client id: f_00005-10-1 loss: 0.892707  [   64/  146]
train() client id: f_00005-10-2 loss: 0.710141  [   96/  146]
train() client id: f_00005-10-3 loss: 0.284746  [  128/  146]
train() client id: f_00005-11-0 loss: 0.597579  [   32/  146]
train() client id: f_00005-11-1 loss: 0.491186  [   64/  146]
train() client id: f_00005-11-2 loss: 0.588778  [   96/  146]
train() client id: f_00005-11-3 loss: 0.402998  [  128/  146]
train() client id: f_00005-12-0 loss: 0.611360  [   32/  146]
train() client id: f_00005-12-1 loss: 0.454089  [   64/  146]
train() client id: f_00005-12-2 loss: 0.748467  [   96/  146]
train() client id: f_00005-12-3 loss: 0.533964  [  128/  146]
train() client id: f_00006-0-0 loss: 0.429221  [   32/   54]
train() client id: f_00006-1-0 loss: 0.448339  [   32/   54]
train() client id: f_00006-2-0 loss: 0.527160  [   32/   54]
train() client id: f_00006-3-0 loss: 0.407616  [   32/   54]
train() client id: f_00006-4-0 loss: 0.516521  [   32/   54]
train() client id: f_00006-5-0 loss: 0.448768  [   32/   54]
train() client id: f_00006-6-0 loss: 0.440934  [   32/   54]
train() client id: f_00006-7-0 loss: 0.454758  [   32/   54]
train() client id: f_00006-8-0 loss: 0.464309  [   32/   54]
train() client id: f_00006-9-0 loss: 0.471789  [   32/   54]
train() client id: f_00006-10-0 loss: 0.461127  [   32/   54]
train() client id: f_00006-11-0 loss: 0.407688  [   32/   54]
train() client id: f_00006-12-0 loss: 0.463351  [   32/   54]
train() client id: f_00007-0-0 loss: 0.571340  [   32/  179]
train() client id: f_00007-0-1 loss: 0.679552  [   64/  179]
train() client id: f_00007-0-2 loss: 0.773187  [   96/  179]
train() client id: f_00007-0-3 loss: 0.742475  [  128/  179]
train() client id: f_00007-0-4 loss: 0.800660  [  160/  179]
train() client id: f_00007-1-0 loss: 0.808115  [   32/  179]
train() client id: f_00007-1-1 loss: 0.733419  [   64/  179]
train() client id: f_00007-1-2 loss: 0.559942  [   96/  179]
train() client id: f_00007-1-3 loss: 0.712825  [  128/  179]
train() client id: f_00007-1-4 loss: 0.595489  [  160/  179]
train() client id: f_00007-2-0 loss: 0.768787  [   32/  179]
train() client id: f_00007-2-1 loss: 0.800861  [   64/  179]
train() client id: f_00007-2-2 loss: 0.638121  [   96/  179]
train() client id: f_00007-2-3 loss: 0.655039  [  128/  179]
train() client id: f_00007-2-4 loss: 0.624815  [  160/  179]
train() client id: f_00007-3-0 loss: 0.692715  [   32/  179]
train() client id: f_00007-3-1 loss: 0.680658  [   64/  179]
train() client id: f_00007-3-2 loss: 0.550072  [   96/  179]
train() client id: f_00007-3-3 loss: 0.763358  [  128/  179]
train() client id: f_00007-3-4 loss: 0.780411  [  160/  179]
train() client id: f_00007-4-0 loss: 0.726632  [   32/  179]
train() client id: f_00007-4-1 loss: 0.540075  [   64/  179]
train() client id: f_00007-4-2 loss: 0.564576  [   96/  179]
train() client id: f_00007-4-3 loss: 0.598913  [  128/  179]
train() client id: f_00007-4-4 loss: 0.741536  [  160/  179]
train() client id: f_00007-5-0 loss: 0.790580  [   32/  179]
train() client id: f_00007-5-1 loss: 0.545846  [   64/  179]
train() client id: f_00007-5-2 loss: 0.973187  [   96/  179]
train() client id: f_00007-5-3 loss: 0.562578  [  128/  179]
train() client id: f_00007-5-4 loss: 0.582956  [  160/  179]
train() client id: f_00007-6-0 loss: 0.807482  [   32/  179]
train() client id: f_00007-6-1 loss: 0.638595  [   64/  179]
train() client id: f_00007-6-2 loss: 0.710634  [   96/  179]
train() client id: f_00007-6-3 loss: 0.532479  [  128/  179]
train() client id: f_00007-6-4 loss: 0.725528  [  160/  179]
train() client id: f_00007-7-0 loss: 0.631927  [   32/  179]
train() client id: f_00007-7-1 loss: 0.772115  [   64/  179]
train() client id: f_00007-7-2 loss: 0.617899  [   96/  179]
train() client id: f_00007-7-3 loss: 0.612156  [  128/  179]
train() client id: f_00007-7-4 loss: 0.810898  [  160/  179]
train() client id: f_00007-8-0 loss: 0.801051  [   32/  179]
train() client id: f_00007-8-1 loss: 0.598282  [   64/  179]
train() client id: f_00007-8-2 loss: 0.676069  [   96/  179]
train() client id: f_00007-8-3 loss: 0.506332  [  128/  179]
train() client id: f_00007-8-4 loss: 0.815253  [  160/  179]
train() client id: f_00007-9-0 loss: 0.822770  [   32/  179]
train() client id: f_00007-9-1 loss: 0.643046  [   64/  179]
train() client id: f_00007-9-2 loss: 0.606828  [   96/  179]
train() client id: f_00007-9-3 loss: 0.502765  [  128/  179]
train() client id: f_00007-9-4 loss: 0.806290  [  160/  179]
train() client id: f_00007-10-0 loss: 0.528244  [   32/  179]
train() client id: f_00007-10-1 loss: 0.534954  [   64/  179]
train() client id: f_00007-10-2 loss: 0.718621  [   96/  179]
train() client id: f_00007-10-3 loss: 0.538698  [  128/  179]
train() client id: f_00007-10-4 loss: 0.973999  [  160/  179]
train() client id: f_00007-11-0 loss: 0.698224  [   32/  179]
train() client id: f_00007-11-1 loss: 0.511757  [   64/  179]
train() client id: f_00007-11-2 loss: 0.728432  [   96/  179]
train() client id: f_00007-11-3 loss: 0.594368  [  128/  179]
train() client id: f_00007-11-4 loss: 0.656163  [  160/  179]
train() client id: f_00007-12-0 loss: 0.548580  [   32/  179]
train() client id: f_00007-12-1 loss: 0.643991  [   64/  179]
train() client id: f_00007-12-2 loss: 0.886042  [   96/  179]
train() client id: f_00007-12-3 loss: 0.621163  [  128/  179]
train() client id: f_00007-12-4 loss: 0.699098  [  160/  179]
train() client id: f_00008-0-0 loss: 0.681327  [   32/  130]
train() client id: f_00008-0-1 loss: 0.780353  [   64/  130]
train() client id: f_00008-0-2 loss: 0.846770  [   96/  130]
train() client id: f_00008-0-3 loss: 0.710320  [  128/  130]
train() client id: f_00008-1-0 loss: 0.711492  [   32/  130]
train() client id: f_00008-1-1 loss: 0.811949  [   64/  130]
train() client id: f_00008-1-2 loss: 0.645582  [   96/  130]
train() client id: f_00008-1-3 loss: 0.837173  [  128/  130]
train() client id: f_00008-2-0 loss: 0.832161  [   32/  130]
train() client id: f_00008-2-1 loss: 0.779983  [   64/  130]
train() client id: f_00008-2-2 loss: 0.702000  [   96/  130]
train() client id: f_00008-2-3 loss: 0.709717  [  128/  130]
train() client id: f_00008-3-0 loss: 0.873557  [   32/  130]
train() client id: f_00008-3-1 loss: 0.823006  [   64/  130]
train() client id: f_00008-3-2 loss: 0.611069  [   96/  130]
train() client id: f_00008-3-3 loss: 0.732055  [  128/  130]
train() client id: f_00008-4-0 loss: 0.769724  [   32/  130]
train() client id: f_00008-4-1 loss: 0.810521  [   64/  130]
train() client id: f_00008-4-2 loss: 0.702863  [   96/  130]
train() client id: f_00008-4-3 loss: 0.752034  [  128/  130]
train() client id: f_00008-5-0 loss: 0.748358  [   32/  130]
train() client id: f_00008-5-1 loss: 0.809926  [   64/  130]
train() client id: f_00008-5-2 loss: 0.707757  [   96/  130]
train() client id: f_00008-5-3 loss: 0.753819  [  128/  130]
train() client id: f_00008-6-0 loss: 0.632669  [   32/  130]
train() client id: f_00008-6-1 loss: 0.850835  [   64/  130]
train() client id: f_00008-6-2 loss: 0.849416  [   96/  130]
train() client id: f_00008-6-3 loss: 0.684891  [  128/  130]
train() client id: f_00008-7-0 loss: 0.772281  [   32/  130]
train() client id: f_00008-7-1 loss: 0.756391  [   64/  130]
train() client id: f_00008-7-2 loss: 0.785878  [   96/  130]
train() client id: f_00008-7-3 loss: 0.710635  [  128/  130]
train() client id: f_00008-8-0 loss: 0.882248  [   32/  130]
train() client id: f_00008-8-1 loss: 0.671390  [   64/  130]
train() client id: f_00008-8-2 loss: 0.689622  [   96/  130]
train() client id: f_00008-8-3 loss: 0.760443  [  128/  130]
train() client id: f_00008-9-0 loss: 0.714582  [   32/  130]
train() client id: f_00008-9-1 loss: 0.637456  [   64/  130]
train() client id: f_00008-9-2 loss: 0.874102  [   96/  130]
train() client id: f_00008-9-3 loss: 0.785153  [  128/  130]
train() client id: f_00008-10-0 loss: 0.802070  [   32/  130]
train() client id: f_00008-10-1 loss: 0.698471  [   64/  130]
train() client id: f_00008-10-2 loss: 0.847216  [   96/  130]
train() client id: f_00008-10-3 loss: 0.674997  [  128/  130]
train() client id: f_00008-11-0 loss: 0.809826  [   32/  130]
train() client id: f_00008-11-1 loss: 0.746597  [   64/  130]
train() client id: f_00008-11-2 loss: 0.705175  [   96/  130]
train() client id: f_00008-11-3 loss: 0.777558  [  128/  130]
train() client id: f_00008-12-0 loss: 0.638218  [   32/  130]
train() client id: f_00008-12-1 loss: 0.847640  [   64/  130]
train() client id: f_00008-12-2 loss: 0.773167  [   96/  130]
train() client id: f_00008-12-3 loss: 0.785670  [  128/  130]
train() client id: f_00009-0-0 loss: 1.119833  [   32/  118]
train() client id: f_00009-0-1 loss: 1.104247  [   64/  118]
train() client id: f_00009-0-2 loss: 1.100111  [   96/  118]
train() client id: f_00009-1-0 loss: 1.039885  [   32/  118]
train() client id: f_00009-1-1 loss: 1.152707  [   64/  118]
train() client id: f_00009-1-2 loss: 1.056560  [   96/  118]
train() client id: f_00009-2-0 loss: 0.964066  [   32/  118]
train() client id: f_00009-2-1 loss: 1.020712  [   64/  118]
train() client id: f_00009-2-2 loss: 1.091215  [   96/  118]
train() client id: f_00009-3-0 loss: 0.858932  [   32/  118]
train() client id: f_00009-3-1 loss: 1.103574  [   64/  118]
train() client id: f_00009-3-2 loss: 1.006023  [   96/  118]
train() client id: f_00009-4-0 loss: 1.094629  [   32/  118]
train() client id: f_00009-4-1 loss: 0.895912  [   64/  118]
train() client id: f_00009-4-2 loss: 0.939121  [   96/  118]
train() client id: f_00009-5-0 loss: 0.947688  [   32/  118]
train() client id: f_00009-5-1 loss: 0.799959  [   64/  118]
train() client id: f_00009-5-2 loss: 0.814987  [   96/  118]
train() client id: f_00009-6-0 loss: 0.968716  [   32/  118]
train() client id: f_00009-6-1 loss: 0.943578  [   64/  118]
train() client id: f_00009-6-2 loss: 0.848951  [   96/  118]
train() client id: f_00009-7-0 loss: 0.964900  [   32/  118]
train() client id: f_00009-7-1 loss: 0.847555  [   64/  118]
train() client id: f_00009-7-2 loss: 0.889343  [   96/  118]
train() client id: f_00009-8-0 loss: 0.846296  [   32/  118]
train() client id: f_00009-8-1 loss: 0.903595  [   64/  118]
train() client id: f_00009-8-2 loss: 0.887078  [   96/  118]
train() client id: f_00009-9-0 loss: 0.779768  [   32/  118]
train() client id: f_00009-9-1 loss: 0.880891  [   64/  118]
train() client id: f_00009-9-2 loss: 0.874912  [   96/  118]
train() client id: f_00009-10-0 loss: 0.864506  [   32/  118]
train() client id: f_00009-10-1 loss: 0.755153  [   64/  118]
train() client id: f_00009-10-2 loss: 0.998860  [   96/  118]
train() client id: f_00009-11-0 loss: 0.781129  [   32/  118]
train() client id: f_00009-11-1 loss: 0.759008  [   64/  118]
train() client id: f_00009-11-2 loss: 0.830497  [   96/  118]
train() client id: f_00009-12-0 loss: 0.860498  [   32/  118]
train() client id: f_00009-12-1 loss: 0.982469  [   64/  118]
train() client id: f_00009-12-2 loss: 0.790064  [   96/  118]
At round 48 accuracy: 0.6419098143236074
At round 48 training accuracy: 0.5881958417169685
At round 48 training loss: 0.837002376122194
gradient difference: 0.4551474452018738
train() client id: f_00000-0-0 loss: 1.335514  [   32/  126]
train() client id: f_00000-0-1 loss: 1.346989  [   64/  126]
train() client id: f_00000-0-2 loss: 1.134024  [   96/  126]
train() client id: f_00000-1-0 loss: 1.258359  [   32/  126]
train() client id: f_00000-1-1 loss: 1.104187  [   64/  126]
train() client id: f_00000-1-2 loss: 1.044910  [   96/  126]
train() client id: f_00000-2-0 loss: 1.133954  [   32/  126]
train() client id: f_00000-2-1 loss: 0.969123  [   64/  126]
train() client id: f_00000-2-2 loss: 1.157801  [   96/  126]
train() client id: f_00000-3-0 loss: 0.967857  [   32/  126]
train() client id: f_00000-3-1 loss: 1.099558  [   64/  126]
train() client id: f_00000-3-2 loss: 0.905735  [   96/  126]
train() client id: f_00000-4-0 loss: 0.943678  [   32/  126]
train() client id: f_00000-4-1 loss: 0.948896  [   64/  126]
train() client id: f_00000-4-2 loss: 0.979956  [   96/  126]
train() client id: f_00000-5-0 loss: 0.960651  [   32/  126]
train() client id: f_00000-5-1 loss: 0.880386  [   64/  126]
train() client id: f_00000-5-2 loss: 0.737426  [   96/  126]
train() client id: f_00000-6-0 loss: 0.776348  [   32/  126]
train() client id: f_00000-6-1 loss: 0.838739  [   64/  126]
train() client id: f_00000-6-2 loss: 0.802960  [   96/  126]
train() client id: f_00000-7-0 loss: 0.811251  [   32/  126]
train() client id: f_00000-7-1 loss: 0.792323  [   64/  126]
train() client id: f_00000-7-2 loss: 0.836357  [   96/  126]
train() client id: f_00000-8-0 loss: 0.761229  [   32/  126]
train() client id: f_00000-8-1 loss: 0.755560  [   64/  126]
train() client id: f_00000-8-2 loss: 0.831678  [   96/  126]
train() client id: f_00000-9-0 loss: 0.685566  [   32/  126]
train() client id: f_00000-9-1 loss: 0.881525  [   64/  126]
train() client id: f_00000-9-2 loss: 0.843062  [   96/  126]
train() client id: f_00000-10-0 loss: 0.776572  [   32/  126]
train() client id: f_00000-10-1 loss: 0.821059  [   64/  126]
train() client id: f_00000-10-2 loss: 0.777171  [   96/  126]
train() client id: f_00000-11-0 loss: 0.776127  [   32/  126]
train() client id: f_00000-11-1 loss: 0.806314  [   64/  126]
train() client id: f_00000-11-2 loss: 0.723785  [   96/  126]
train() client id: f_00000-12-0 loss: 0.807383  [   32/  126]
train() client id: f_00000-12-1 loss: 0.776127  [   64/  126]
train() client id: f_00000-12-2 loss: 0.821830  [   96/  126]
train() client id: f_00001-0-0 loss: 0.428035  [   32/  265]
train() client id: f_00001-0-1 loss: 0.569953  [   64/  265]
train() client id: f_00001-0-2 loss: 0.471638  [   96/  265]
train() client id: f_00001-0-3 loss: 0.478925  [  128/  265]
train() client id: f_00001-0-4 loss: 0.366357  [  160/  265]
train() client id: f_00001-0-5 loss: 0.505392  [  192/  265]
train() client id: f_00001-0-6 loss: 0.517604  [  224/  265]
train() client id: f_00001-0-7 loss: 0.503234  [  256/  265]
train() client id: f_00001-1-0 loss: 0.446385  [   32/  265]
train() client id: f_00001-1-1 loss: 0.575668  [   64/  265]
train() client id: f_00001-1-2 loss: 0.534575  [   96/  265]
train() client id: f_00001-1-3 loss: 0.383091  [  128/  265]
train() client id: f_00001-1-4 loss: 0.470048  [  160/  265]
train() client id: f_00001-1-5 loss: 0.451508  [  192/  265]
train() client id: f_00001-1-6 loss: 0.375093  [  224/  265]
train() client id: f_00001-1-7 loss: 0.537959  [  256/  265]
train() client id: f_00001-2-0 loss: 0.405908  [   32/  265]
train() client id: f_00001-2-1 loss: 0.395718  [   64/  265]
train() client id: f_00001-2-2 loss: 0.473147  [   96/  265]
train() client id: f_00001-2-3 loss: 0.415871  [  128/  265]
train() client id: f_00001-2-4 loss: 0.375320  [  160/  265]
train() client id: f_00001-2-5 loss: 0.463479  [  192/  265]
train() client id: f_00001-2-6 loss: 0.440632  [  224/  265]
train() client id: f_00001-2-7 loss: 0.606953  [  256/  265]
train() client id: f_00001-3-0 loss: 0.565484  [   32/  265]
train() client id: f_00001-3-1 loss: 0.340546  [   64/  265]
train() client id: f_00001-3-2 loss: 0.416602  [   96/  265]
train() client id: f_00001-3-3 loss: 0.676591  [  128/  265]
train() client id: f_00001-3-4 loss: 0.457632  [  160/  265]
train() client id: f_00001-3-5 loss: 0.421900  [  192/  265]
train() client id: f_00001-3-6 loss: 0.371800  [  224/  265]
train() client id: f_00001-3-7 loss: 0.416585  [  256/  265]
train() client id: f_00001-4-0 loss: 0.577453  [   32/  265]
train() client id: f_00001-4-1 loss: 0.488675  [   64/  265]
train() client id: f_00001-4-2 loss: 0.356838  [   96/  265]
train() client id: f_00001-4-3 loss: 0.367038  [  128/  265]
train() client id: f_00001-4-4 loss: 0.571398  [  160/  265]
train() client id: f_00001-4-5 loss: 0.416808  [  192/  265]
train() client id: f_00001-4-6 loss: 0.372426  [  224/  265]
train() client id: f_00001-4-7 loss: 0.495603  [  256/  265]
train() client id: f_00001-5-0 loss: 0.405307  [   32/  265]
train() client id: f_00001-5-1 loss: 0.426683  [   64/  265]
train() client id: f_00001-5-2 loss: 0.423915  [   96/  265]
train() client id: f_00001-5-3 loss: 0.377799  [  128/  265]
train() client id: f_00001-5-4 loss: 0.513812  [  160/  265]
train() client id: f_00001-5-5 loss: 0.521402  [  192/  265]
train() client id: f_00001-5-6 loss: 0.393443  [  224/  265]
train() client id: f_00001-5-7 loss: 0.547861  [  256/  265]
train() client id: f_00001-6-0 loss: 0.387547  [   32/  265]
train() client id: f_00001-6-1 loss: 0.430458  [   64/  265]
train() client id: f_00001-6-2 loss: 0.612875  [   96/  265]
train() client id: f_00001-6-3 loss: 0.429619  [  128/  265]
train() client id: f_00001-6-4 loss: 0.451152  [  160/  265]
train() client id: f_00001-6-5 loss: 0.377910  [  192/  265]
train() client id: f_00001-6-6 loss: 0.411468  [  224/  265]
train() client id: f_00001-6-7 loss: 0.492552  [  256/  265]
train() client id: f_00001-7-0 loss: 0.429308  [   32/  265]
train() client id: f_00001-7-1 loss: 0.397607  [   64/  265]
train() client id: f_00001-7-2 loss: 0.509956  [   96/  265]
train() client id: f_00001-7-3 loss: 0.367919  [  128/  265]
train() client id: f_00001-7-4 loss: 0.535858  [  160/  265]
train() client id: f_00001-7-5 loss: 0.349587  [  192/  265]
train() client id: f_00001-7-6 loss: 0.350729  [  224/  265]
train() client id: f_00001-7-7 loss: 0.588361  [  256/  265]
train() client id: f_00001-8-0 loss: 0.466153  [   32/  265]
train() client id: f_00001-8-1 loss: 0.572950  [   64/  265]
train() client id: f_00001-8-2 loss: 0.405197  [   96/  265]
train() client id: f_00001-8-3 loss: 0.354236  [  128/  265]
train() client id: f_00001-8-4 loss: 0.465348  [  160/  265]
train() client id: f_00001-8-5 loss: 0.387233  [  192/  265]
train() client id: f_00001-8-6 loss: 0.528231  [  224/  265]
train() client id: f_00001-8-7 loss: 0.357838  [  256/  265]
train() client id: f_00001-9-0 loss: 0.419811  [   32/  265]
train() client id: f_00001-9-1 loss: 0.323750  [   64/  265]
train() client id: f_00001-9-2 loss: 0.578837  [   96/  265]
train() client id: f_00001-9-3 loss: 0.498034  [  128/  265]
train() client id: f_00001-9-4 loss: 0.406052  [  160/  265]
train() client id: f_00001-9-5 loss: 0.425765  [  192/  265]
train() client id: f_00001-9-6 loss: 0.479729  [  224/  265]
train() client id: f_00001-9-7 loss: 0.429333  [  256/  265]
train() client id: f_00001-10-0 loss: 0.348099  [   32/  265]
train() client id: f_00001-10-1 loss: 0.517647  [   64/  265]
train() client id: f_00001-10-2 loss: 0.403810  [   96/  265]
train() client id: f_00001-10-3 loss: 0.477828  [  128/  265]
train() client id: f_00001-10-4 loss: 0.443016  [  160/  265]
train() client id: f_00001-10-5 loss: 0.456254  [  192/  265]
train() client id: f_00001-10-6 loss: 0.550239  [  224/  265]
train() client id: f_00001-10-7 loss: 0.357833  [  256/  265]
train() client id: f_00001-11-0 loss: 0.340515  [   32/  265]
train() client id: f_00001-11-1 loss: 0.575169  [   64/  265]
train() client id: f_00001-11-2 loss: 0.540342  [   96/  265]
train() client id: f_00001-11-3 loss: 0.392293  [  128/  265]
train() client id: f_00001-11-4 loss: 0.530423  [  160/  265]
train() client id: f_00001-11-5 loss: 0.415326  [  192/  265]
train() client id: f_00001-11-6 loss: 0.349836  [  224/  265]
train() client id: f_00001-11-7 loss: 0.414154  [  256/  265]
train() client id: f_00001-12-0 loss: 0.450955  [   32/  265]
train() client id: f_00001-12-1 loss: 0.501018  [   64/  265]
train() client id: f_00001-12-2 loss: 0.350773  [   96/  265]
train() client id: f_00001-12-3 loss: 0.355014  [  128/  265]
train() client id: f_00001-12-4 loss: 0.459530  [  160/  265]
train() client id: f_00001-12-5 loss: 0.494548  [  192/  265]
train() client id: f_00001-12-6 loss: 0.375282  [  224/  265]
train() client id: f_00001-12-7 loss: 0.556539  [  256/  265]
train() client id: f_00002-0-0 loss: 1.099848  [   32/  124]
train() client id: f_00002-0-1 loss: 0.782783  [   64/  124]
train() client id: f_00002-0-2 loss: 0.993924  [   96/  124]
train() client id: f_00002-1-0 loss: 0.853411  [   32/  124]
train() client id: f_00002-1-1 loss: 0.646974  [   64/  124]
train() client id: f_00002-1-2 loss: 1.046322  [   96/  124]
train() client id: f_00002-2-0 loss: 0.950483  [   32/  124]
train() client id: f_00002-2-1 loss: 0.770366  [   64/  124]
train() client id: f_00002-2-2 loss: 0.758313  [   96/  124]
train() client id: f_00002-3-0 loss: 0.786827  [   32/  124]
train() client id: f_00002-3-1 loss: 0.670396  [   64/  124]
train() client id: f_00002-3-2 loss: 0.901242  [   96/  124]
train() client id: f_00002-4-0 loss: 0.837212  [   32/  124]
train() client id: f_00002-4-1 loss: 0.777521  [   64/  124]
train() client id: f_00002-4-2 loss: 0.873083  [   96/  124]
train() client id: f_00002-5-0 loss: 0.936646  [   32/  124]
train() client id: f_00002-5-1 loss: 0.692601  [   64/  124]
train() client id: f_00002-5-2 loss: 0.817774  [   96/  124]
train() client id: f_00002-6-0 loss: 0.732613  [   32/  124]
train() client id: f_00002-6-1 loss: 0.824314  [   64/  124]
train() client id: f_00002-6-2 loss: 0.940744  [   96/  124]
train() client id: f_00002-7-0 loss: 0.726864  [   32/  124]
train() client id: f_00002-7-1 loss: 0.929695  [   64/  124]
train() client id: f_00002-7-2 loss: 0.688776  [   96/  124]
train() client id: f_00002-8-0 loss: 0.657640  [   32/  124]
train() client id: f_00002-8-1 loss: 0.735166  [   64/  124]
train() client id: f_00002-8-2 loss: 0.653409  [   96/  124]
train() client id: f_00002-9-0 loss: 0.893058  [   32/  124]
train() client id: f_00002-9-1 loss: 0.606693  [   64/  124]
train() client id: f_00002-9-2 loss: 0.810316  [   96/  124]
train() client id: f_00002-10-0 loss: 0.707693  [   32/  124]
train() client id: f_00002-10-1 loss: 0.735700  [   64/  124]
train() client id: f_00002-10-2 loss: 0.721260  [   96/  124]
train() client id: f_00002-11-0 loss: 0.793526  [   32/  124]
train() client id: f_00002-11-1 loss: 0.975297  [   64/  124]
train() client id: f_00002-11-2 loss: 0.493011  [   96/  124]
train() client id: f_00002-12-0 loss: 0.471574  [   32/  124]
train() client id: f_00002-12-1 loss: 0.750744  [   64/  124]
train() client id: f_00002-12-2 loss: 0.814448  [   96/  124]
train() client id: f_00003-0-0 loss: 0.894333  [   32/   43]
train() client id: f_00003-1-0 loss: 0.714776  [   32/   43]
train() client id: f_00003-2-0 loss: 0.646787  [   32/   43]
train() client id: f_00003-3-0 loss: 0.557749  [   32/   43]
train() client id: f_00003-4-0 loss: 0.711745  [   32/   43]
train() client id: f_00003-5-0 loss: 0.680227  [   32/   43]
train() client id: f_00003-6-0 loss: 0.830621  [   32/   43]
train() client id: f_00003-7-0 loss: 0.619541  [   32/   43]
train() client id: f_00003-8-0 loss: 0.524287  [   32/   43]
train() client id: f_00003-9-0 loss: 0.539459  [   32/   43]
train() client id: f_00003-10-0 loss: 0.494104  [   32/   43]
train() client id: f_00003-11-0 loss: 0.670342  [   32/   43]
train() client id: f_00003-12-0 loss: 0.617263  [   32/   43]
train() client id: f_00004-0-0 loss: 0.747618  [   32/  306]
train() client id: f_00004-0-1 loss: 0.820002  [   64/  306]
train() client id: f_00004-0-2 loss: 0.772966  [   96/  306]
train() client id: f_00004-0-3 loss: 0.735051  [  128/  306]
train() client id: f_00004-0-4 loss: 0.695039  [  160/  306]
train() client id: f_00004-0-5 loss: 0.847970  [  192/  306]
train() client id: f_00004-0-6 loss: 0.742021  [  224/  306]
train() client id: f_00004-0-7 loss: 0.675900  [  256/  306]
train() client id: f_00004-0-8 loss: 0.879221  [  288/  306]
train() client id: f_00004-1-0 loss: 0.857253  [   32/  306]
train() client id: f_00004-1-1 loss: 0.806146  [   64/  306]
train() client id: f_00004-1-2 loss: 0.701127  [   96/  306]
train() client id: f_00004-1-3 loss: 0.761631  [  128/  306]
train() client id: f_00004-1-4 loss: 0.658572  [  160/  306]
train() client id: f_00004-1-5 loss: 0.833765  [  192/  306]
train() client id: f_00004-1-6 loss: 0.865154  [  224/  306]
train() client id: f_00004-1-7 loss: 0.747956  [  256/  306]
train() client id: f_00004-1-8 loss: 0.689706  [  288/  306]
train() client id: f_00004-2-0 loss: 0.696073  [   32/  306]
train() client id: f_00004-2-1 loss: 0.779997  [   64/  306]
train() client id: f_00004-2-2 loss: 0.927317  [   96/  306]
train() client id: f_00004-2-3 loss: 0.709137  [  128/  306]
train() client id: f_00004-2-4 loss: 0.605067  [  160/  306]
train() client id: f_00004-2-5 loss: 0.819839  [  192/  306]
train() client id: f_00004-2-6 loss: 0.843445  [  224/  306]
train() client id: f_00004-2-7 loss: 0.886420  [  256/  306]
train() client id: f_00004-2-8 loss: 0.646760  [  288/  306]
train() client id: f_00004-3-0 loss: 0.786505  [   32/  306]
train() client id: f_00004-3-1 loss: 0.741164  [   64/  306]
train() client id: f_00004-3-2 loss: 0.817816  [   96/  306]
train() client id: f_00004-3-3 loss: 0.736897  [  128/  306]
train() client id: f_00004-3-4 loss: 0.820518  [  160/  306]
train() client id: f_00004-3-5 loss: 0.656883  [  192/  306]
train() client id: f_00004-3-6 loss: 0.738506  [  224/  306]
train() client id: f_00004-3-7 loss: 0.836283  [  256/  306]
train() client id: f_00004-3-8 loss: 0.726089  [  288/  306]
train() client id: f_00004-4-0 loss: 0.812612  [   32/  306]
train() client id: f_00004-4-1 loss: 0.841128  [   64/  306]
train() client id: f_00004-4-2 loss: 0.575927  [   96/  306]
train() client id: f_00004-4-3 loss: 0.819027  [  128/  306]
train() client id: f_00004-4-4 loss: 0.785141  [  160/  306]
train() client id: f_00004-4-5 loss: 0.902306  [  192/  306]
train() client id: f_00004-4-6 loss: 0.754547  [  224/  306]
train() client id: f_00004-4-7 loss: 0.845697  [  256/  306]
train() client id: f_00004-4-8 loss: 0.676770  [  288/  306]
train() client id: f_00004-5-0 loss: 0.802761  [   32/  306]
train() client id: f_00004-5-1 loss: 0.937935  [   64/  306]
train() client id: f_00004-5-2 loss: 0.699154  [   96/  306]
train() client id: f_00004-5-3 loss: 0.845435  [  128/  306]
train() client id: f_00004-5-4 loss: 0.670209  [  160/  306]
train() client id: f_00004-5-5 loss: 0.796738  [  192/  306]
train() client id: f_00004-5-6 loss: 0.741938  [  224/  306]
train() client id: f_00004-5-7 loss: 0.649275  [  256/  306]
train() client id: f_00004-5-8 loss: 0.791293  [  288/  306]
train() client id: f_00004-6-0 loss: 0.925194  [   32/  306]
train() client id: f_00004-6-1 loss: 0.662522  [   64/  306]
train() client id: f_00004-6-2 loss: 0.623825  [   96/  306]
train() client id: f_00004-6-3 loss: 0.798388  [  128/  306]
train() client id: f_00004-6-4 loss: 0.806491  [  160/  306]
train() client id: f_00004-6-5 loss: 0.781590  [  192/  306]
train() client id: f_00004-6-6 loss: 0.799535  [  224/  306]
train() client id: f_00004-6-7 loss: 0.793718  [  256/  306]
train() client id: f_00004-6-8 loss: 0.762299  [  288/  306]
train() client id: f_00004-7-0 loss: 0.693393  [   32/  306]
train() client id: f_00004-7-1 loss: 0.764971  [   64/  306]
train() client id: f_00004-7-2 loss: 0.807262  [   96/  306]
train() client id: f_00004-7-3 loss: 0.828319  [  128/  306]
train() client id: f_00004-7-4 loss: 0.820444  [  160/  306]
train() client id: f_00004-7-5 loss: 0.699744  [  192/  306]
train() client id: f_00004-7-6 loss: 0.731851  [  224/  306]
train() client id: f_00004-7-7 loss: 0.852044  [  256/  306]
train() client id: f_00004-7-8 loss: 0.733275  [  288/  306]
train() client id: f_00004-8-0 loss: 0.877272  [   32/  306]
train() client id: f_00004-8-1 loss: 0.783881  [   64/  306]
train() client id: f_00004-8-2 loss: 0.718303  [   96/  306]
train() client id: f_00004-8-3 loss: 0.773414  [  128/  306]
train() client id: f_00004-8-4 loss: 0.867503  [  160/  306]
train() client id: f_00004-8-5 loss: 0.645186  [  192/  306]
train() client id: f_00004-8-6 loss: 0.661648  [  224/  306]
train() client id: f_00004-8-7 loss: 0.825096  [  256/  306]
train() client id: f_00004-8-8 loss: 0.766594  [  288/  306]
train() client id: f_00004-9-0 loss: 0.796327  [   32/  306]
train() client id: f_00004-9-1 loss: 0.870566  [   64/  306]
train() client id: f_00004-9-2 loss: 0.723627  [   96/  306]
train() client id: f_00004-9-3 loss: 0.653972  [  128/  306]
train() client id: f_00004-9-4 loss: 0.762098  [  160/  306]
train() client id: f_00004-9-5 loss: 0.685702  [  192/  306]
train() client id: f_00004-9-6 loss: 0.651649  [  224/  306]
train() client id: f_00004-9-7 loss: 0.929195  [  256/  306]
train() client id: f_00004-9-8 loss: 0.875763  [  288/  306]
train() client id: f_00004-10-0 loss: 0.827826  [   32/  306]
train() client id: f_00004-10-1 loss: 0.916410  [   64/  306]
train() client id: f_00004-10-2 loss: 0.780590  [   96/  306]
train() client id: f_00004-10-3 loss: 0.830325  [  128/  306]
train() client id: f_00004-10-4 loss: 0.667212  [  160/  306]
train() client id: f_00004-10-5 loss: 0.793203  [  192/  306]
train() client id: f_00004-10-6 loss: 0.738753  [  224/  306]
train() client id: f_00004-10-7 loss: 0.770045  [  256/  306]
train() client id: f_00004-10-8 loss: 0.719798  [  288/  306]
train() client id: f_00004-11-0 loss: 0.924853  [   32/  306]
train() client id: f_00004-11-1 loss: 0.721335  [   64/  306]
train() client id: f_00004-11-2 loss: 0.691391  [   96/  306]
train() client id: f_00004-11-3 loss: 0.721552  [  128/  306]
train() client id: f_00004-11-4 loss: 0.684156  [  160/  306]
train() client id: f_00004-11-5 loss: 0.760356  [  192/  306]
train() client id: f_00004-11-6 loss: 0.785626  [  224/  306]
train() client id: f_00004-11-7 loss: 0.815570  [  256/  306]
train() client id: f_00004-11-8 loss: 0.843085  [  288/  306]
train() client id: f_00004-12-0 loss: 0.774267  [   32/  306]
train() client id: f_00004-12-1 loss: 0.781012  [   64/  306]
train() client id: f_00004-12-2 loss: 0.681408  [   96/  306]
train() client id: f_00004-12-3 loss: 0.759060  [  128/  306]
train() client id: f_00004-12-4 loss: 0.852621  [  160/  306]
train() client id: f_00004-12-5 loss: 0.746427  [  192/  306]
train() client id: f_00004-12-6 loss: 0.923574  [  224/  306]
train() client id: f_00004-12-7 loss: 0.773653  [  256/  306]
train() client id: f_00004-12-8 loss: 0.773551  [  288/  306]
train() client id: f_00005-0-0 loss: 0.497552  [   32/  146]
train() client id: f_00005-0-1 loss: 0.765735  [   64/  146]
train() client id: f_00005-0-2 loss: 0.615438  [   96/  146]
train() client id: f_00005-0-3 loss: 0.712335  [  128/  146]
train() client id: f_00005-1-0 loss: 0.708483  [   32/  146]
train() client id: f_00005-1-1 loss: 0.383331  [   64/  146]
train() client id: f_00005-1-2 loss: 0.668635  [   96/  146]
train() client id: f_00005-1-3 loss: 0.556020  [  128/  146]
train() client id: f_00005-2-0 loss: 0.820771  [   32/  146]
train() client id: f_00005-2-1 loss: 0.496257  [   64/  146]
train() client id: f_00005-2-2 loss: 0.817562  [   96/  146]
train() client id: f_00005-2-3 loss: 0.594189  [  128/  146]
train() client id: f_00005-3-0 loss: 0.631397  [   32/  146]
train() client id: f_00005-3-1 loss: 0.842632  [   64/  146]
train() client id: f_00005-3-2 loss: 0.656191  [   96/  146]
train() client id: f_00005-3-3 loss: 0.622986  [  128/  146]
train() client id: f_00005-4-0 loss: 0.658555  [   32/  146]
train() client id: f_00005-4-1 loss: 0.712739  [   64/  146]
train() client id: f_00005-4-2 loss: 0.709537  [   96/  146]
train() client id: f_00005-4-3 loss: 0.742156  [  128/  146]
train() client id: f_00005-5-0 loss: 0.718522  [   32/  146]
train() client id: f_00005-5-1 loss: 0.653875  [   64/  146]
train() client id: f_00005-5-2 loss: 0.596672  [   96/  146]
train() client id: f_00005-5-3 loss: 0.712913  [  128/  146]
train() client id: f_00005-6-0 loss: 0.637605  [   32/  146]
train() client id: f_00005-6-1 loss: 0.702518  [   64/  146]
train() client id: f_00005-6-2 loss: 0.681828  [   96/  146]
train() client id: f_00005-6-3 loss: 0.541406  [  128/  146]
train() client id: f_00005-7-0 loss: 0.545393  [   32/  146]
train() client id: f_00005-7-1 loss: 0.905673  [   64/  146]
train() client id: f_00005-7-2 loss: 0.527882  [   96/  146]
train() client id: f_00005-7-3 loss: 0.797008  [  128/  146]
train() client id: f_00005-8-0 loss: 0.578334  [   32/  146]
train() client id: f_00005-8-1 loss: 0.819319  [   64/  146]
train() client id: f_00005-8-2 loss: 0.624581  [   96/  146]
train() client id: f_00005-8-3 loss: 0.576551  [  128/  146]
train() client id: f_00005-9-0 loss: 0.826785  [   32/  146]
train() client id: f_00005-9-1 loss: 0.572571  [   64/  146]
train() client id: f_00005-9-2 loss: 0.664412  [   96/  146]
train() client id: f_00005-9-3 loss: 0.509998  [  128/  146]
train() client id: f_00005-10-0 loss: 0.648657  [   32/  146]
train() client id: f_00005-10-1 loss: 0.754877  [   64/  146]
train() client id: f_00005-10-2 loss: 0.501461  [   96/  146]
train() client id: f_00005-10-3 loss: 0.843596  [  128/  146]
train() client id: f_00005-11-0 loss: 0.623022  [   32/  146]
train() client id: f_00005-11-1 loss: 0.899290  [   64/  146]
train() client id: f_00005-11-2 loss: 0.680401  [   96/  146]
train() client id: f_00005-11-3 loss: 0.419237  [  128/  146]
train() client id: f_00005-12-0 loss: 0.695671  [   32/  146]
train() client id: f_00005-12-1 loss: 0.505591  [   64/  146]
train() client id: f_00005-12-2 loss: 0.704826  [   96/  146]
train() client id: f_00005-12-3 loss: 0.712038  [  128/  146]
train() client id: f_00006-0-0 loss: 0.497864  [   32/   54]
train() client id: f_00006-1-0 loss: 0.547959  [   32/   54]
train() client id: f_00006-2-0 loss: 0.552362  [   32/   54]
train() client id: f_00006-3-0 loss: 0.544150  [   32/   54]
train() client id: f_00006-4-0 loss: 0.509940  [   32/   54]
train() client id: f_00006-5-0 loss: 0.472930  [   32/   54]
train() client id: f_00006-6-0 loss: 0.539388  [   32/   54]
train() client id: f_00006-7-0 loss: 0.440211  [   32/   54]
train() client id: f_00006-8-0 loss: 0.494032  [   32/   54]
train() client id: f_00006-9-0 loss: 0.484357  [   32/   54]
train() client id: f_00006-10-0 loss: 0.495156  [   32/   54]
train() client id: f_00006-11-0 loss: 0.426849  [   32/   54]
train() client id: f_00006-12-0 loss: 0.520802  [   32/   54]
train() client id: f_00007-0-0 loss: 0.580787  [   32/  179]
train() client id: f_00007-0-1 loss: 0.386823  [   64/  179]
train() client id: f_00007-0-2 loss: 0.710449  [   96/  179]
train() client id: f_00007-0-3 loss: 0.802027  [  128/  179]
train() client id: f_00007-0-4 loss: 0.453032  [  160/  179]
train() client id: f_00007-1-0 loss: 0.795606  [   32/  179]
train() client id: f_00007-1-1 loss: 0.456674  [   64/  179]
train() client id: f_00007-1-2 loss: 0.428527  [   96/  179]
train() client id: f_00007-1-3 loss: 0.388709  [  128/  179]
train() client id: f_00007-1-4 loss: 0.633597  [  160/  179]
train() client id: f_00007-2-0 loss: 0.390628  [   32/  179]
train() client id: f_00007-2-1 loss: 0.804018  [   64/  179]
train() client id: f_00007-2-2 loss: 0.540945  [   96/  179]
train() client id: f_00007-2-3 loss: 0.470859  [  128/  179]
train() client id: f_00007-2-4 loss: 0.540290  [  160/  179]
train() client id: f_00007-3-0 loss: 0.619952  [   32/  179]
train() client id: f_00007-3-1 loss: 0.641401  [   64/  179]
train() client id: f_00007-3-2 loss: 0.386730  [   96/  179]
train() client id: f_00007-3-3 loss: 0.526561  [  128/  179]
train() client id: f_00007-3-4 loss: 0.485029  [  160/  179]
train() client id: f_00007-4-0 loss: 0.465292  [   32/  179]
train() client id: f_00007-4-1 loss: 0.644277  [   64/  179]
train() client id: f_00007-4-2 loss: 0.735620  [   96/  179]
train() client id: f_00007-4-3 loss: 0.383708  [  128/  179]
train() client id: f_00007-4-4 loss: 0.489655  [  160/  179]
train() client id: f_00007-5-0 loss: 0.354471  [   32/  179]
train() client id: f_00007-5-1 loss: 0.590329  [   64/  179]
train() client id: f_00007-5-2 loss: 0.611384  [   96/  179]
train() client id: f_00007-5-3 loss: 0.667957  [  128/  179]
train() client id: f_00007-5-4 loss: 0.461489  [  160/  179]
train() client id: f_00007-6-0 loss: 0.733956  [   32/  179]
train() client id: f_00007-6-1 loss: 0.346310  [   64/  179]
train() client id: f_00007-6-2 loss: 0.759623  [   96/  179]
train() client id: f_00007-6-3 loss: 0.356793  [  128/  179]
train() client id: f_00007-6-4 loss: 0.471677  [  160/  179]
train() client id: f_00007-7-0 loss: 0.675155  [   32/  179]
train() client id: f_00007-7-1 loss: 0.548543  [   64/  179]
train() client id: f_00007-7-2 loss: 0.523313  [   96/  179]
train() client id: f_00007-7-3 loss: 0.436308  [  128/  179]
train() client id: f_00007-7-4 loss: 0.379815  [  160/  179]
train() client id: f_00007-8-0 loss: 0.558369  [   32/  179]
train() client id: f_00007-8-1 loss: 0.642030  [   64/  179]
train() client id: f_00007-8-2 loss: 0.377108  [   96/  179]
train() client id: f_00007-8-3 loss: 0.349487  [  128/  179]
train() client id: f_00007-8-4 loss: 0.717151  [  160/  179]
train() client id: f_00007-9-0 loss: 0.637644  [   32/  179]
train() client id: f_00007-9-1 loss: 0.564369  [   64/  179]
train() client id: f_00007-9-2 loss: 0.451545  [   96/  179]
train() client id: f_00007-9-3 loss: 0.340135  [  128/  179]
train() client id: f_00007-9-4 loss: 0.423032  [  160/  179]
train() client id: f_00007-10-0 loss: 0.468531  [   32/  179]
train() client id: f_00007-10-1 loss: 0.525756  [   64/  179]
train() client id: f_00007-10-2 loss: 0.557636  [   96/  179]
train() client id: f_00007-10-3 loss: 0.341165  [  128/  179]
train() client id: f_00007-10-4 loss: 0.701958  [  160/  179]
train() client id: f_00007-11-0 loss: 0.336720  [   32/  179]
train() client id: f_00007-11-1 loss: 0.495950  [   64/  179]
train() client id: f_00007-11-2 loss: 0.556821  [   96/  179]
train() client id: f_00007-11-3 loss: 0.489019  [  128/  179]
train() client id: f_00007-11-4 loss: 0.334019  [  160/  179]
train() client id: f_00007-12-0 loss: 0.436650  [   32/  179]
train() client id: f_00007-12-1 loss: 0.551522  [   64/  179]
train() client id: f_00007-12-2 loss: 0.546572  [   96/  179]
train() client id: f_00007-12-3 loss: 0.570280  [  128/  179]
train() client id: f_00007-12-4 loss: 0.488109  [  160/  179]
train() client id: f_00008-0-0 loss: 0.683935  [   32/  130]
train() client id: f_00008-0-1 loss: 0.712407  [   64/  130]
train() client id: f_00008-0-2 loss: 0.681382  [   96/  130]
train() client id: f_00008-0-3 loss: 0.691559  [  128/  130]
train() client id: f_00008-1-0 loss: 0.741248  [   32/  130]
train() client id: f_00008-1-1 loss: 0.667906  [   64/  130]
train() client id: f_00008-1-2 loss: 0.630299  [   96/  130]
train() client id: f_00008-1-3 loss: 0.755020  [  128/  130]
train() client id: f_00008-2-0 loss: 0.618795  [   32/  130]
train() client id: f_00008-2-1 loss: 0.749096  [   64/  130]
train() client id: f_00008-2-2 loss: 0.665296  [   96/  130]
train() client id: f_00008-2-3 loss: 0.759080  [  128/  130]
train() client id: f_00008-3-0 loss: 0.676898  [   32/  130]
train() client id: f_00008-3-1 loss: 0.761979  [   64/  130]
train() client id: f_00008-3-2 loss: 0.662378  [   96/  130]
train() client id: f_00008-3-3 loss: 0.689093  [  128/  130]
train() client id: f_00008-4-0 loss: 0.617603  [   32/  130]
train() client id: f_00008-4-1 loss: 0.704224  [   64/  130]
train() client id: f_00008-4-2 loss: 0.751288  [   96/  130]
train() client id: f_00008-4-3 loss: 0.733188  [  128/  130]
train() client id: f_00008-5-0 loss: 0.794956  [   32/  130]
train() client id: f_00008-5-1 loss: 0.613158  [   64/  130]
train() client id: f_00008-5-2 loss: 0.737857  [   96/  130]
train() client id: f_00008-5-3 loss: 0.658832  [  128/  130]
train() client id: f_00008-6-0 loss: 0.686493  [   32/  130]
train() client id: f_00008-6-1 loss: 0.659859  [   64/  130]
train() client id: f_00008-6-2 loss: 0.774077  [   96/  130]
train() client id: f_00008-6-3 loss: 0.666737  [  128/  130]
train() client id: f_00008-7-0 loss: 0.594449  [   32/  130]
train() client id: f_00008-7-1 loss: 0.784342  [   64/  130]
train() client id: f_00008-7-2 loss: 0.630182  [   96/  130]
train() client id: f_00008-7-3 loss: 0.779846  [  128/  130]
train() client id: f_00008-8-0 loss: 0.740987  [   32/  130]
train() client id: f_00008-8-1 loss: 0.619907  [   64/  130]
train() client id: f_00008-8-2 loss: 0.728969  [   96/  130]
train() client id: f_00008-8-3 loss: 0.656394  [  128/  130]
train() client id: f_00008-9-0 loss: 0.613564  [   32/  130]
train() client id: f_00008-9-1 loss: 0.763801  [   64/  130]
train() client id: f_00008-9-2 loss: 0.755554  [   96/  130]
train() client id: f_00008-9-3 loss: 0.667055  [  128/  130]
train() client id: f_00008-10-0 loss: 0.562635  [   32/  130]
train() client id: f_00008-10-1 loss: 0.786592  [   64/  130]
train() client id: f_00008-10-2 loss: 0.612170  [   96/  130]
train() client id: f_00008-10-3 loss: 0.829500  [  128/  130]
train() client id: f_00008-11-0 loss: 0.618879  [   32/  130]
train() client id: f_00008-11-1 loss: 0.758972  [   64/  130]
train() client id: f_00008-11-2 loss: 0.724845  [   96/  130]
train() client id: f_00008-11-3 loss: 0.654954  [  128/  130]
train() client id: f_00008-12-0 loss: 0.651001  [   32/  130]
train() client id: f_00008-12-1 loss: 0.722790  [   64/  130]
train() client id: f_00008-12-2 loss: 0.751072  [   96/  130]
train() client id: f_00008-12-3 loss: 0.663164  [  128/  130]
train() client id: f_00009-0-0 loss: 1.104484  [   32/  118]
train() client id: f_00009-0-1 loss: 0.943457  [   64/  118]
train() client id: f_00009-0-2 loss: 1.004250  [   96/  118]
train() client id: f_00009-1-0 loss: 0.974106  [   32/  118]
train() client id: f_00009-1-1 loss: 1.008065  [   64/  118]
train() client id: f_00009-1-2 loss: 0.987251  [   96/  118]
train() client id: f_00009-2-0 loss: 0.959924  [   32/  118]
train() client id: f_00009-2-1 loss: 0.850822  [   64/  118]
train() client id: f_00009-2-2 loss: 0.936510  [   96/  118]
train() client id: f_00009-3-0 loss: 0.938782  [   32/  118]
train() client id: f_00009-3-1 loss: 0.937825  [   64/  118]
train() client id: f_00009-3-2 loss: 0.848978  [   96/  118]
train() client id: f_00009-4-0 loss: 0.972227  [   32/  118]
train() client id: f_00009-4-1 loss: 0.986865  [   64/  118]
train() client id: f_00009-4-2 loss: 0.741099  [   96/  118]
train() client id: f_00009-5-0 loss: 0.905458  [   32/  118]
train() client id: f_00009-5-1 loss: 0.926689  [   64/  118]
train() client id: f_00009-5-2 loss: 1.019973  [   96/  118]
train() client id: f_00009-6-0 loss: 0.930834  [   32/  118]
train() client id: f_00009-6-1 loss: 0.771064  [   64/  118]
train() client id: f_00009-6-2 loss: 0.862227  [   96/  118]
train() client id: f_00009-7-0 loss: 0.918913  [   32/  118]
train() client id: f_00009-7-1 loss: 0.843243  [   64/  118]
train() client id: f_00009-7-2 loss: 0.887877  [   96/  118]
train() client id: f_00009-8-0 loss: 0.973669  [   32/  118]
train() client id: f_00009-8-1 loss: 0.929025  [   64/  118]
train() client id: f_00009-8-2 loss: 0.892307  [   96/  118]
train() client id: f_00009-9-0 loss: 0.797106  [   32/  118]
train() client id: f_00009-9-1 loss: 1.024200  [   64/  118]
train() client id: f_00009-9-2 loss: 0.866299  [   96/  118]
train() client id: f_00009-10-0 loss: 0.872960  [   32/  118]
train() client id: f_00009-10-1 loss: 0.828272  [   64/  118]
train() client id: f_00009-10-2 loss: 0.837503  [   96/  118]
train() client id: f_00009-11-0 loss: 0.697449  [   32/  118]
train() client id: f_00009-11-1 loss: 0.977942  [   64/  118]
train() client id: f_00009-11-2 loss: 0.872173  [   96/  118]
train() client id: f_00009-12-0 loss: 0.829619  [   32/  118]
train() client id: f_00009-12-1 loss: 0.735316  [   64/  118]
train() client id: f_00009-12-2 loss: 0.900112  [   96/  118]
At round 49 accuracy: 0.6419098143236074
At round 49 training accuracy: 0.5935613682092555
At round 49 training loss: 0.821807387852473
gradient difference: 0.39468079805374146
train() client id: f_00000-0-0 loss: 1.197500  [   32/  126]
train() client id: f_00000-0-1 loss: 1.130218  [   64/  126]
train() client id: f_00000-0-2 loss: 0.980354  [   96/  126]
train() client id: f_00000-1-0 loss: 1.308238  [   32/  126]
train() client id: f_00000-1-1 loss: 1.068568  [   64/  126]
train() client id: f_00000-1-2 loss: 0.902251  [   96/  126]
train() client id: f_00000-2-0 loss: 1.200991  [   32/  126]
train() client id: f_00000-2-1 loss: 0.954768  [   64/  126]
train() client id: f_00000-2-2 loss: 0.708443  [   96/  126]
train() client id: f_00000-3-0 loss: 1.007420  [   32/  126]
train() client id: f_00000-3-1 loss: 0.970631  [   64/  126]
train() client id: f_00000-3-2 loss: 0.768299  [   96/  126]
train() client id: f_00000-4-0 loss: 1.003338  [   32/  126]
train() client id: f_00000-4-1 loss: 0.776873  [   64/  126]
train() client id: f_00000-4-2 loss: 0.733792  [   96/  126]
train() client id: f_00000-5-0 loss: 0.693838  [   32/  126]
train() client id: f_00000-5-1 loss: 0.896944  [   64/  126]
train() client id: f_00000-5-2 loss: 0.739359  [   96/  126]
train() client id: f_00000-6-0 loss: 0.939846  [   32/  126]
train() client id: f_00000-6-1 loss: 0.716538  [   64/  126]
train() client id: f_00000-6-2 loss: 0.725964  [   96/  126]
train() client id: f_00000-7-0 loss: 0.756990  [   32/  126]
train() client id: f_00000-7-1 loss: 0.780533  [   64/  126]
train() client id: f_00000-7-2 loss: 0.713542  [   96/  126]
train() client id: f_00000-8-0 loss: 0.750601  [   32/  126]
train() client id: f_00000-8-1 loss: 0.737699  [   64/  126]
train() client id: f_00000-8-2 loss: 0.756209  [   96/  126]
train() client id: f_00000-9-0 loss: 0.791140  [   32/  126]
train() client id: f_00000-9-1 loss: 0.728923  [   64/  126]
train() client id: f_00000-9-2 loss: 0.668870  [   96/  126]
train() client id: f_00000-10-0 loss: 0.740856  [   32/  126]
train() client id: f_00000-10-1 loss: 0.769415  [   64/  126]
train() client id: f_00000-10-2 loss: 0.738977  [   96/  126]
train() client id: f_00000-11-0 loss: 0.599286  [   32/  126]
train() client id: f_00000-11-1 loss: 0.815660  [   64/  126]
train() client id: f_00000-11-2 loss: 0.694699  [   96/  126]
train() client id: f_00000-12-0 loss: 0.773784  [   32/  126]
train() client id: f_00000-12-1 loss: 0.705021  [   64/  126]
train() client id: f_00000-12-2 loss: 0.720499  [   96/  126]
train() client id: f_00001-0-0 loss: 0.411860  [   32/  265]
train() client id: f_00001-0-1 loss: 0.247121  [   64/  265]
train() client id: f_00001-0-2 loss: 0.280207  [   96/  265]
train() client id: f_00001-0-3 loss: 0.313909  [  128/  265]
train() client id: f_00001-0-4 loss: 0.259394  [  160/  265]
train() client id: f_00001-0-5 loss: 0.509652  [  192/  265]
train() client id: f_00001-0-6 loss: 0.330655  [  224/  265]
train() client id: f_00001-0-7 loss: 0.368470  [  256/  265]
train() client id: f_00001-1-0 loss: 0.272491  [   32/  265]
train() client id: f_00001-1-1 loss: 0.364341  [   64/  265]
train() client id: f_00001-1-2 loss: 0.285305  [   96/  265]
train() client id: f_00001-1-3 loss: 0.363687  [  128/  265]
train() client id: f_00001-1-4 loss: 0.298486  [  160/  265]
train() client id: f_00001-1-5 loss: 0.323384  [  192/  265]
train() client id: f_00001-1-6 loss: 0.416475  [  224/  265]
train() client id: f_00001-1-7 loss: 0.379900  [  256/  265]
train() client id: f_00001-2-0 loss: 0.424893  [   32/  265]
train() client id: f_00001-2-1 loss: 0.327959  [   64/  265]
train() client id: f_00001-2-2 loss: 0.365199  [   96/  265]
train() client id: f_00001-2-3 loss: 0.295859  [  128/  265]
train() client id: f_00001-2-4 loss: 0.265097  [  160/  265]
train() client id: f_00001-2-5 loss: 0.265109  [  192/  265]
train() client id: f_00001-2-6 loss: 0.435574  [  224/  265]
train() client id: f_00001-2-7 loss: 0.237477  [  256/  265]
train() client id: f_00001-3-0 loss: 0.253229  [   32/  265]
train() client id: f_00001-3-1 loss: 0.356030  [   64/  265]
train() client id: f_00001-3-2 loss: 0.393610  [   96/  265]
train() client id: f_00001-3-3 loss: 0.367875  [  128/  265]
train() client id: f_00001-3-4 loss: 0.348578  [  160/  265]
train() client id: f_00001-3-5 loss: 0.238329  [  192/  265]
train() client id: f_00001-3-6 loss: 0.314762  [  224/  265]
train() client id: f_00001-3-7 loss: 0.369016  [  256/  265]
train() client id: f_00001-4-0 loss: 0.330998  [   32/  265]
train() client id: f_00001-4-1 loss: 0.247444  [   64/  265]
train() client id: f_00001-4-2 loss: 0.335240  [   96/  265]
train() client id: f_00001-4-3 loss: 0.369550  [  128/  265]
train() client id: f_00001-4-4 loss: 0.228928  [  160/  265]
train() client id: f_00001-4-5 loss: 0.425955  [  192/  265]
train() client id: f_00001-4-6 loss: 0.366275  [  224/  265]
train() client id: f_00001-4-7 loss: 0.226218  [  256/  265]
train() client id: f_00001-5-0 loss: 0.318261  [   32/  265]
train() client id: f_00001-5-1 loss: 0.212478  [   64/  265]
train() client id: f_00001-5-2 loss: 0.294171  [   96/  265]
train() client id: f_00001-5-3 loss: 0.350138  [  128/  265]
train() client id: f_00001-5-4 loss: 0.306383  [  160/  265]
train() client id: f_00001-5-5 loss: 0.347903  [  192/  265]
train() client id: f_00001-5-6 loss: 0.370878  [  224/  265]
train() client id: f_00001-5-7 loss: 0.353433  [  256/  265]
train() client id: f_00001-6-0 loss: 0.273440  [   32/  265]
train() client id: f_00001-6-1 loss: 0.286998  [   64/  265]
train() client id: f_00001-6-2 loss: 0.283324  [   96/  265]
train() client id: f_00001-6-3 loss: 0.292740  [  128/  265]
train() client id: f_00001-6-4 loss: 0.343380  [  160/  265]
train() client id: f_00001-6-5 loss: 0.369417  [  192/  265]
train() client id: f_00001-6-6 loss: 0.247538  [  224/  265]
train() client id: f_00001-6-7 loss: 0.387144  [  256/  265]
train() client id: f_00001-7-0 loss: 0.271759  [   32/  265]
train() client id: f_00001-7-1 loss: 0.217885  [   64/  265]
train() client id: f_00001-7-2 loss: 0.416628  [   96/  265]
train() client id: f_00001-7-3 loss: 0.236178  [  128/  265]
train() client id: f_00001-7-4 loss: 0.204738  [  160/  265]
train() client id: f_00001-7-5 loss: 0.384313  [  192/  265]
train() client id: f_00001-7-6 loss: 0.270289  [  224/  265]
train() client id: f_00001-7-7 loss: 0.434896  [  256/  265]
train() client id: f_00001-8-0 loss: 0.208681  [   32/  265]
train() client id: f_00001-8-1 loss: 0.211014  [   64/  265]
train() client id: f_00001-8-2 loss: 0.232827  [   96/  265]
train() client id: f_00001-8-3 loss: 0.374425  [  128/  265]
train() client id: f_00001-8-4 loss: 0.344951  [  160/  265]
train() client id: f_00001-8-5 loss: 0.359368  [  192/  265]
train() client id: f_00001-8-6 loss: 0.367483  [  224/  265]
train() client id: f_00001-8-7 loss: 0.401482  [  256/  265]
train() client id: f_00001-9-0 loss: 0.348729  [   32/  265]
train() client id: f_00001-9-1 loss: 0.272476  [   64/  265]
train() client id: f_00001-9-2 loss: 0.326477  [   96/  265]
train() client id: f_00001-9-3 loss: 0.423117  [  128/  265]
train() client id: f_00001-9-4 loss: 0.213838  [  160/  265]
train() client id: f_00001-9-5 loss: 0.259852  [  192/  265]
train() client id: f_00001-9-6 loss: 0.273923  [  224/  265]
train() client id: f_00001-9-7 loss: 0.368850  [  256/  265]
train() client id: f_00001-10-0 loss: 0.308250  [   32/  265]
train() client id: f_00001-10-1 loss: 0.284042  [   64/  265]
train() client id: f_00001-10-2 loss: 0.241841  [   96/  265]
train() client id: f_00001-10-3 loss: 0.380730  [  128/  265]
train() client id: f_00001-10-4 loss: 0.226467  [  160/  265]
train() client id: f_00001-10-5 loss: 0.365016  [  192/  265]
train() client id: f_00001-10-6 loss: 0.380063  [  224/  265]
train() client id: f_00001-10-7 loss: 0.258619  [  256/  265]
train() client id: f_00001-11-0 loss: 0.359169  [   32/  265]
train() client id: f_00001-11-1 loss: 0.202515  [   64/  265]
train() client id: f_00001-11-2 loss: 0.405407  [   96/  265]
train() client id: f_00001-11-3 loss: 0.306702  [  128/  265]
train() client id: f_00001-11-4 loss: 0.355369  [  160/  265]
train() client id: f_00001-11-5 loss: 0.271921  [  192/  265]
train() client id: f_00001-11-6 loss: 0.324859  [  224/  265]
train() client id: f_00001-11-7 loss: 0.244498  [  256/  265]
train() client id: f_00001-12-0 loss: 0.258711  [   32/  265]
train() client id: f_00001-12-1 loss: 0.310038  [   64/  265]
train() client id: f_00001-12-2 loss: 0.266521  [   96/  265]
train() client id: f_00001-12-3 loss: 0.281879  [  128/  265]
train() client id: f_00001-12-4 loss: 0.333447  [  160/  265]
train() client id: f_00001-12-5 loss: 0.339645  [  192/  265]
train() client id: f_00001-12-6 loss: 0.355241  [  224/  265]
train() client id: f_00001-12-7 loss: 0.305839  [  256/  265]
train() client id: f_00002-0-0 loss: 0.963813  [   32/  124]
train() client id: f_00002-0-1 loss: 0.893481  [   64/  124]
train() client id: f_00002-0-2 loss: 1.127511  [   96/  124]
train() client id: f_00002-1-0 loss: 0.966286  [   32/  124]
train() client id: f_00002-1-1 loss: 0.981504  [   64/  124]
train() client id: f_00002-1-2 loss: 1.061836  [   96/  124]
train() client id: f_00002-2-0 loss: 0.944477  [   32/  124]
train() client id: f_00002-2-1 loss: 0.897701  [   64/  124]
train() client id: f_00002-2-2 loss: 1.084469  [   96/  124]
train() client id: f_00002-3-0 loss: 0.934233  [   32/  124]
train() client id: f_00002-3-1 loss: 0.806936  [   64/  124]
train() client id: f_00002-3-2 loss: 0.892480  [   96/  124]
train() client id: f_00002-4-0 loss: 0.930327  [   32/  124]
train() client id: f_00002-4-1 loss: 0.834108  [   64/  124]
train() client id: f_00002-4-2 loss: 0.906278  [   96/  124]
train() client id: f_00002-5-0 loss: 0.850469  [   32/  124]
train() client id: f_00002-5-1 loss: 0.911990  [   64/  124]
train() client id: f_00002-5-2 loss: 0.947101  [   96/  124]
train() client id: f_00002-6-0 loss: 0.955669  [   32/  124]
train() client id: f_00002-6-1 loss: 0.942798  [   64/  124]
train() client id: f_00002-6-2 loss: 0.892440  [   96/  124]
train() client id: f_00002-7-0 loss: 1.060472  [   32/  124]
train() client id: f_00002-7-1 loss: 0.929900  [   64/  124]
train() client id: f_00002-7-2 loss: 0.829855  [   96/  124]
train() client id: f_00002-8-0 loss: 0.771438  [   32/  124]
train() client id: f_00002-8-1 loss: 0.804514  [   64/  124]
train() client id: f_00002-8-2 loss: 1.153287  [   96/  124]
train() client id: f_00002-9-0 loss: 0.954756  [   32/  124]
train() client id: f_00002-9-1 loss: 0.926281  [   64/  124]
train() client id: f_00002-9-2 loss: 0.855575  [   96/  124]
train() client id: f_00002-10-0 loss: 0.913172  [   32/  124]
train() client id: f_00002-10-1 loss: 0.769938  [   64/  124]
train() client id: f_00002-10-2 loss: 0.841111  [   96/  124]
train() client id: f_00002-11-0 loss: 0.776465  [   32/  124]
train() client id: f_00002-11-1 loss: 1.019391  [   64/  124]
train() client id: f_00002-11-2 loss: 0.930894  [   96/  124]
train() client id: f_00002-12-0 loss: 0.859390  [   32/  124]
train() client id: f_00002-12-1 loss: 0.984418  [   64/  124]
train() client id: f_00002-12-2 loss: 0.850505  [   96/  124]
train() client id: f_00003-0-0 loss: 0.675498  [   32/   43]
train() client id: f_00003-1-0 loss: 0.678788  [   32/   43]
train() client id: f_00003-2-0 loss: 0.746913  [   32/   43]
train() client id: f_00003-3-0 loss: 0.874988  [   32/   43]
train() client id: f_00003-4-0 loss: 0.780912  [   32/   43]
train() client id: f_00003-5-0 loss: 0.627499  [   32/   43]
train() client id: f_00003-6-0 loss: 0.895121  [   32/   43]
train() client id: f_00003-7-0 loss: 0.493497  [   32/   43]
train() client id: f_00003-8-0 loss: 0.563639  [   32/   43]
train() client id: f_00003-9-0 loss: 0.806270  [   32/   43]
train() client id: f_00003-10-0 loss: 0.662133  [   32/   43]
train() client id: f_00003-11-0 loss: 0.774920  [   32/   43]
train() client id: f_00003-12-0 loss: 0.701494  [   32/   43]
train() client id: f_00004-0-0 loss: 1.012160  [   32/  306]
train() client id: f_00004-0-1 loss: 0.803544  [   64/  306]
train() client id: f_00004-0-2 loss: 0.855951  [   96/  306]
train() client id: f_00004-0-3 loss: 1.158336  [  128/  306]
train() client id: f_00004-0-4 loss: 0.777428  [  160/  306]
train() client id: f_00004-0-5 loss: 0.690285  [  192/  306]
train() client id: f_00004-0-6 loss: 0.819748  [  224/  306]
train() client id: f_00004-0-7 loss: 0.948992  [  256/  306]
train() client id: f_00004-0-8 loss: 0.880063  [  288/  306]
train() client id: f_00004-1-0 loss: 0.825052  [   32/  306]
train() client id: f_00004-1-1 loss: 1.110321  [   64/  306]
train() client id: f_00004-1-2 loss: 0.916435  [   96/  306]
train() client id: f_00004-1-3 loss: 0.943250  [  128/  306]
train() client id: f_00004-1-4 loss: 0.805074  [  160/  306]
train() client id: f_00004-1-5 loss: 0.877637  [  192/  306]
train() client id: f_00004-1-6 loss: 0.832763  [  224/  306]
train() client id: f_00004-1-7 loss: 0.812545  [  256/  306]
train() client id: f_00004-1-8 loss: 0.742314  [  288/  306]
train() client id: f_00004-2-0 loss: 0.829442  [   32/  306]
train() client id: f_00004-2-1 loss: 0.877714  [   64/  306]
train() client id: f_00004-2-2 loss: 0.841731  [   96/  306]
train() client id: f_00004-2-3 loss: 0.813477  [  128/  306]
train() client id: f_00004-2-4 loss: 0.763060  [  160/  306]
train() client id: f_00004-2-5 loss: 0.969107  [  192/  306]
train() client id: f_00004-2-6 loss: 0.784179  [  224/  306]
train() client id: f_00004-2-7 loss: 0.997012  [  256/  306]
train() client id: f_00004-2-8 loss: 0.904232  [  288/  306]
train() client id: f_00004-3-0 loss: 0.844657  [   32/  306]
train() client id: f_00004-3-1 loss: 0.906583  [   64/  306]
train() client id: f_00004-3-2 loss: 0.824180  [   96/  306]
train() client id: f_00004-3-3 loss: 0.864989  [  128/  306]
train() client id: f_00004-3-4 loss: 0.766189  [  160/  306]
train() client id: f_00004-3-5 loss: 0.850116  [  192/  306]
train() client id: f_00004-3-6 loss: 0.914254  [  224/  306]
train() client id: f_00004-3-7 loss: 0.885123  [  256/  306]
train() client id: f_00004-3-8 loss: 0.896558  [  288/  306]
train() client id: f_00004-4-0 loss: 0.889210  [   32/  306]
train() client id: f_00004-4-1 loss: 0.914342  [   64/  306]
train() client id: f_00004-4-2 loss: 0.727114  [   96/  306]
train() client id: f_00004-4-3 loss: 0.883972  [  128/  306]
train() client id: f_00004-4-4 loss: 0.889463  [  160/  306]
train() client id: f_00004-4-5 loss: 1.052764  [  192/  306]
train() client id: f_00004-4-6 loss: 0.892842  [  224/  306]
train() client id: f_00004-4-7 loss: 0.839193  [  256/  306]
train() client id: f_00004-4-8 loss: 0.774864  [  288/  306]
train() client id: f_00004-5-0 loss: 0.916933  [   32/  306]
train() client id: f_00004-5-1 loss: 0.679397  [   64/  306]
train() client id: f_00004-5-2 loss: 0.921968  [   96/  306]
train() client id: f_00004-5-3 loss: 0.724551  [  128/  306]
train() client id: f_00004-5-4 loss: 0.903930  [  160/  306]
train() client id: f_00004-5-5 loss: 0.864581  [  192/  306]
train() client id: f_00004-5-6 loss: 1.020661  [  224/  306]
train() client id: f_00004-5-7 loss: 0.870054  [  256/  306]
train() client id: f_00004-5-8 loss: 0.888933  [  288/  306]
train() client id: f_00004-6-0 loss: 0.917686  [   32/  306]
train() client id: f_00004-6-1 loss: 0.975355  [   64/  306]
train() client id: f_00004-6-2 loss: 0.863784  [   96/  306]
train() client id: f_00004-6-3 loss: 0.885413  [  128/  306]
train() client id: f_00004-6-4 loss: 0.855038  [  160/  306]
train() client id: f_00004-6-5 loss: 0.957543  [  192/  306]
train() client id: f_00004-6-6 loss: 0.692705  [  224/  306]
train() client id: f_00004-6-7 loss: 0.907447  [  256/  306]
train() client id: f_00004-6-8 loss: 0.736974  [  288/  306]
train() client id: f_00004-7-0 loss: 0.887307  [   32/  306]
train() client id: f_00004-7-1 loss: 0.766776  [   64/  306]
train() client id: f_00004-7-2 loss: 0.957452  [   96/  306]
train() client id: f_00004-7-3 loss: 0.727813  [  128/  306]
train() client id: f_00004-7-4 loss: 0.833855  [  160/  306]
train() client id: f_00004-7-5 loss: 0.794763  [  192/  306]
train() client id: f_00004-7-6 loss: 0.890240  [  224/  306]
train() client id: f_00004-7-7 loss: 0.900616  [  256/  306]
train() client id: f_00004-7-8 loss: 0.988094  [  288/  306]
train() client id: f_00004-8-0 loss: 0.842183  [   32/  306]
train() client id: f_00004-8-1 loss: 0.881536  [   64/  306]
train() client id: f_00004-8-2 loss: 0.830280  [   96/  306]
train() client id: f_00004-8-3 loss: 0.842043  [  128/  306]
train() client id: f_00004-8-4 loss: 0.773527  [  160/  306]
train() client id: f_00004-8-5 loss: 1.131877  [  192/  306]
train() client id: f_00004-8-6 loss: 0.841435  [  224/  306]
train() client id: f_00004-8-7 loss: 0.975132  [  256/  306]
train() client id: f_00004-8-8 loss: 0.772962  [  288/  306]
train() client id: f_00004-9-0 loss: 0.866149  [   32/  306]
train() client id: f_00004-9-1 loss: 0.931941  [   64/  306]
train() client id: f_00004-9-2 loss: 0.736534  [   96/  306]
train() client id: f_00004-9-3 loss: 0.896556  [  128/  306]
train() client id: f_00004-9-4 loss: 0.754686  [  160/  306]
train() client id: f_00004-9-5 loss: 0.922446  [  192/  306]
train() client id: f_00004-9-6 loss: 0.809568  [  224/  306]
train() client id: f_00004-9-7 loss: 0.872659  [  256/  306]
train() client id: f_00004-9-8 loss: 0.966402  [  288/  306]
train() client id: f_00004-10-0 loss: 0.798398  [   32/  306]
train() client id: f_00004-10-1 loss: 0.822212  [   64/  306]
train() client id: f_00004-10-2 loss: 0.861985  [   96/  306]
train() client id: f_00004-10-3 loss: 0.924776  [  128/  306]
train() client id: f_00004-10-4 loss: 0.836275  [  160/  306]
train() client id: f_00004-10-5 loss: 0.867618  [  192/  306]
train() client id: f_00004-10-6 loss: 0.774972  [  224/  306]
train() client id: f_00004-10-7 loss: 0.996332  [  256/  306]
train() client id: f_00004-10-8 loss: 0.847237  [  288/  306]
train() client id: f_00004-11-0 loss: 0.913537  [   32/  306]
train() client id: f_00004-11-1 loss: 0.906458  [   64/  306]
train() client id: f_00004-11-2 loss: 0.773028  [   96/  306]
train() client id: f_00004-11-3 loss: 0.782270  [  128/  306]
train() client id: f_00004-11-4 loss: 0.930106  [  160/  306]
train() client id: f_00004-11-5 loss: 0.828494  [  192/  306]
train() client id: f_00004-11-6 loss: 0.845691  [  224/  306]
train() client id: f_00004-11-7 loss: 0.858928  [  256/  306]
train() client id: f_00004-11-8 loss: 0.877912  [  288/  306]
train() client id: f_00004-12-0 loss: 0.833094  [   32/  306]
train() client id: f_00004-12-1 loss: 0.861526  [   64/  306]
train() client id: f_00004-12-2 loss: 0.951075  [   96/  306]
train() client id: f_00004-12-3 loss: 0.995257  [  128/  306]
train() client id: f_00004-12-4 loss: 0.807077  [  160/  306]
train() client id: f_00004-12-5 loss: 0.773685  [  192/  306]
train() client id: f_00004-12-6 loss: 0.863695  [  224/  306]
train() client id: f_00004-12-7 loss: 0.850182  [  256/  306]
train() client id: f_00004-12-8 loss: 0.819307  [  288/  306]
train() client id: f_00005-0-0 loss: 0.435680  [   32/  146]
train() client id: f_00005-0-1 loss: 0.567157  [   64/  146]
train() client id: f_00005-0-2 loss: 0.730943  [   96/  146]
train() client id: f_00005-0-3 loss: 0.557054  [  128/  146]
train() client id: f_00005-1-0 loss: 0.410278  [   32/  146]
train() client id: f_00005-1-1 loss: 0.751152  [   64/  146]
train() client id: f_00005-1-2 loss: 0.533868  [   96/  146]
train() client id: f_00005-1-3 loss: 0.599687  [  128/  146]
train() client id: f_00005-2-0 loss: 0.718057  [   32/  146]
train() client id: f_00005-2-1 loss: 0.557320  [   64/  146]
train() client id: f_00005-2-2 loss: 0.313934  [   96/  146]
train() client id: f_00005-2-3 loss: 0.791284  [  128/  146]
train() client id: f_00005-3-0 loss: 0.836088  [   32/  146]
train() client id: f_00005-3-1 loss: 0.664705  [   64/  146]
train() client id: f_00005-3-2 loss: 0.651419  [   96/  146]
train() client id: f_00005-3-3 loss: 0.286255  [  128/  146]
train() client id: f_00005-4-0 loss: 0.441217  [   32/  146]
train() client id: f_00005-4-1 loss: 0.667887  [   64/  146]
train() client id: f_00005-4-2 loss: 0.524861  [   96/  146]
train() client id: f_00005-4-3 loss: 0.639960  [  128/  146]
train() client id: f_00005-5-0 loss: 0.552798  [   32/  146]
train() client id: f_00005-5-1 loss: 0.541887  [   64/  146]
train() client id: f_00005-5-2 loss: 0.538865  [   96/  146]
train() client id: f_00005-5-3 loss: 0.653399  [  128/  146]
train() client id: f_00005-6-0 loss: 0.558862  [   32/  146]
train() client id: f_00005-6-1 loss: 0.611658  [   64/  146]
train() client id: f_00005-6-2 loss: 0.544800  [   96/  146]
train() client id: f_00005-6-3 loss: 0.496512  [  128/  146]
train() client id: f_00005-7-0 loss: 0.866476  [   32/  146]
train() client id: f_00005-7-1 loss: 0.374696  [   64/  146]
train() client id: f_00005-7-2 loss: 0.448750  [   96/  146]
train() client id: f_00005-7-3 loss: 0.603445  [  128/  146]
train() client id: f_00005-8-0 loss: 0.415372  [   32/  146]
train() client id: f_00005-8-1 loss: 0.710698  [   64/  146]
train() client id: f_00005-8-2 loss: 0.504128  [   96/  146]
train() client id: f_00005-8-3 loss: 0.504545  [  128/  146]
train() client id: f_00005-9-0 loss: 0.739204  [   32/  146]
train() client id: f_00005-9-1 loss: 0.476857  [   64/  146]
train() client id: f_00005-9-2 loss: 0.387344  [   96/  146]
train() client id: f_00005-9-3 loss: 0.732653  [  128/  146]
train() client id: f_00005-10-0 loss: 0.533367  [   32/  146]
train() client id: f_00005-10-1 loss: 0.487057  [   64/  146]
train() client id: f_00005-10-2 loss: 0.520357  [   96/  146]
train() client id: f_00005-10-3 loss: 0.789793  [  128/  146]
train() client id: f_00005-11-0 loss: 0.669864  [   32/  146]
train() client id: f_00005-11-1 loss: 0.559360  [   64/  146]
train() client id: f_00005-11-2 loss: 0.631446  [   96/  146]
train() client id: f_00005-11-3 loss: 0.353479  [  128/  146]
train() client id: f_00005-12-0 loss: 0.555610  [   32/  146]
train() client id: f_00005-12-1 loss: 0.330057  [   64/  146]
train() client id: f_00005-12-2 loss: 0.720823  [   96/  146]
train() client id: f_00005-12-3 loss: 0.486735  [  128/  146]
train() client id: f_00006-0-0 loss: 0.505070  [   32/   54]
train() client id: f_00006-1-0 loss: 0.498191  [   32/   54]
train() client id: f_00006-2-0 loss: 0.502151  [   32/   54]
train() client id: f_00006-3-0 loss: 0.540941  [   32/   54]
train() client id: f_00006-4-0 loss: 0.542849  [   32/   54]
train() client id: f_00006-5-0 loss: 0.473409  [   32/   54]
train() client id: f_00006-6-0 loss: 0.507535  [   32/   54]
train() client id: f_00006-7-0 loss: 0.532802  [   32/   54]
train() client id: f_00006-8-0 loss: 0.529939  [   32/   54]
train() client id: f_00006-9-0 loss: 0.509987  [   32/   54]
train() client id: f_00006-10-0 loss: 0.482040  [   32/   54]
train() client id: f_00006-11-0 loss: 0.498029  [   32/   54]
train() client id: f_00006-12-0 loss: 0.541119  [   32/   54]
train() client id: f_00007-0-0 loss: 0.661873  [   32/  179]
train() client id: f_00007-0-1 loss: 0.520553  [   64/  179]
train() client id: f_00007-0-2 loss: 0.821989  [   96/  179]
train() client id: f_00007-0-3 loss: 0.538003  [  128/  179]
train() client id: f_00007-0-4 loss: 0.474880  [  160/  179]
train() client id: f_00007-1-0 loss: 0.682511  [   32/  179]
train() client id: f_00007-1-1 loss: 0.605501  [   64/  179]
train() client id: f_00007-1-2 loss: 0.584168  [   96/  179]
train() client id: f_00007-1-3 loss: 0.601293  [  128/  179]
train() client id: f_00007-1-4 loss: 0.475604  [  160/  179]
train() client id: f_00007-2-0 loss: 0.527840  [   32/  179]
train() client id: f_00007-2-1 loss: 0.572534  [   64/  179]
train() client id: f_00007-2-2 loss: 0.388761  [   96/  179]
train() client id: f_00007-2-3 loss: 0.707488  [  128/  179]
train() client id: f_00007-2-4 loss: 0.556566  [  160/  179]
train() client id: f_00007-3-0 loss: 0.534163  [   32/  179]
train() client id: f_00007-3-1 loss: 0.427336  [   64/  179]
train() client id: f_00007-3-2 loss: 0.601871  [   96/  179]
train() client id: f_00007-3-3 loss: 0.511629  [  128/  179]
train() client id: f_00007-3-4 loss: 0.721636  [  160/  179]
train() client id: f_00007-4-0 loss: 0.470702  [   32/  179]
train() client id: f_00007-4-1 loss: 0.744293  [   64/  179]
train() client id: f_00007-4-2 loss: 0.388084  [   96/  179]
train() client id: f_00007-4-3 loss: 0.704653  [  128/  179]
train() client id: f_00007-4-4 loss: 0.439141  [  160/  179]
train() client id: f_00007-5-0 loss: 0.569779  [   32/  179]
train() client id: f_00007-5-1 loss: 0.484706  [   64/  179]
train() client id: f_00007-5-2 loss: 0.522669  [   96/  179]
train() client id: f_00007-5-3 loss: 0.451015  [  128/  179]
train() client id: f_00007-5-4 loss: 0.714868  [  160/  179]
train() client id: f_00007-6-0 loss: 0.663143  [   32/  179]
train() client id: f_00007-6-1 loss: 0.490130  [   64/  179]
train() client id: f_00007-6-2 loss: 0.457494  [   96/  179]
train() client id: f_00007-6-3 loss: 0.433669  [  128/  179]
train() client id: f_00007-6-4 loss: 0.643986  [  160/  179]
train() client id: f_00007-7-0 loss: 0.445189  [   32/  179]
train() client id: f_00007-7-1 loss: 0.392541  [   64/  179]
train() client id: f_00007-7-2 loss: 0.707085  [   96/  179]
train() client id: f_00007-7-3 loss: 0.322775  [  128/  179]
train() client id: f_00007-7-4 loss: 0.540485  [  160/  179]
train() client id: f_00007-8-0 loss: 0.365563  [   32/  179]
train() client id: f_00007-8-1 loss: 0.428125  [   64/  179]
train() client id: f_00007-8-2 loss: 0.334788  [   96/  179]
train() client id: f_00007-8-3 loss: 0.488896  [  128/  179]
train() client id: f_00007-8-4 loss: 0.632161  [  160/  179]
train() client id: f_00007-9-0 loss: 0.670495  [   32/  179]
train() client id: f_00007-9-1 loss: 0.409288  [   64/  179]
train() client id: f_00007-9-2 loss: 0.396008  [   96/  179]
train() client id: f_00007-9-3 loss: 0.533961  [  128/  179]
train() client id: f_00007-9-4 loss: 0.444199  [  160/  179]
train() client id: f_00007-10-0 loss: 0.329298  [   32/  179]
train() client id: f_00007-10-1 loss: 0.635362  [   64/  179]
train() client id: f_00007-10-2 loss: 0.512151  [   96/  179]
train() client id: f_00007-10-3 loss: 0.484397  [  128/  179]
train() client id: f_00007-10-4 loss: 0.519700  [  160/  179]
train() client id: f_00007-11-0 loss: 0.315393  [   32/  179]
train() client id: f_00007-11-1 loss: 0.501903  [   64/  179]
train() client id: f_00007-11-2 loss: 0.382321  [   96/  179]
train() client id: f_00007-11-3 loss: 0.326001  [  128/  179]
train() client id: f_00007-11-4 loss: 0.625161  [  160/  179]
train() client id: f_00007-12-0 loss: 0.550423  [   32/  179]
train() client id: f_00007-12-1 loss: 0.463989  [   64/  179]
train() client id: f_00007-12-2 loss: 0.336108  [   96/  179]
train() client id: f_00007-12-3 loss: 0.780332  [  128/  179]
train() client id: f_00007-12-4 loss: 0.415625  [  160/  179]
train() client id: f_00008-0-0 loss: 0.712064  [   32/  130]
train() client id: f_00008-0-1 loss: 0.700421  [   64/  130]
train() client id: f_00008-0-2 loss: 0.902376  [   96/  130]
train() client id: f_00008-0-3 loss: 0.748643  [  128/  130]
train() client id: f_00008-1-0 loss: 0.692909  [   32/  130]
train() client id: f_00008-1-1 loss: 0.799225  [   64/  130]
train() client id: f_00008-1-2 loss: 0.793457  [   96/  130]
train() client id: f_00008-1-3 loss: 0.731063  [  128/  130]
train() client id: f_00008-2-0 loss: 0.742286  [   32/  130]
train() client id: f_00008-2-1 loss: 0.781676  [   64/  130]
train() client id: f_00008-2-2 loss: 0.696372  [   96/  130]
train() client id: f_00008-2-3 loss: 0.806511  [  128/  130]
train() client id: f_00008-3-0 loss: 0.915979  [   32/  130]
train() client id: f_00008-3-1 loss: 0.684601  [   64/  130]
train() client id: f_00008-3-2 loss: 0.665009  [   96/  130]
train() client id: f_00008-3-3 loss: 0.794385  [  128/  130]
train() client id: f_00008-4-0 loss: 0.632848  [   32/  130]
train() client id: f_00008-4-1 loss: 0.790751  [   64/  130]
train() client id: f_00008-4-2 loss: 0.766762  [   96/  130]
train() client id: f_00008-4-3 loss: 0.842250  [  128/  130]
train() client id: f_00008-5-0 loss: 0.896876  [   32/  130]
train() client id: f_00008-5-1 loss: 0.691132  [   64/  130]
train() client id: f_00008-5-2 loss: 0.832736  [   96/  130]
train() client id: f_00008-5-3 loss: 0.604613  [  128/  130]
train() client id: f_00008-6-0 loss: 0.761395  [   32/  130]
train() client id: f_00008-6-1 loss: 0.721197  [   64/  130]
train() client id: f_00008-6-2 loss: 0.798319  [   96/  130]
train() client id: f_00008-6-3 loss: 0.775966  [  128/  130]
train() client id: f_00008-7-0 loss: 0.741883  [   32/  130]
train() client id: f_00008-7-1 loss: 0.842950  [   64/  130]
train() client id: f_00008-7-2 loss: 0.774359  [   96/  130]
train() client id: f_00008-7-3 loss: 0.685472  [  128/  130]
train() client id: f_00008-8-0 loss: 0.724894  [   32/  130]
train() client id: f_00008-8-1 loss: 0.801971  [   64/  130]
train() client id: f_00008-8-2 loss: 0.715130  [   96/  130]
train() client id: f_00008-8-3 loss: 0.810811  [  128/  130]
train() client id: f_00008-9-0 loss: 0.591823  [   32/  130]
train() client id: f_00008-9-1 loss: 0.736217  [   64/  130]
train() client id: f_00008-9-2 loss: 0.911917  [   96/  130]
train() client id: f_00008-9-3 loss: 0.811096  [  128/  130]
train() client id: f_00008-10-0 loss: 0.736256  [   32/  130]
train() client id: f_00008-10-1 loss: 0.724156  [   64/  130]
train() client id: f_00008-10-2 loss: 0.810912  [   96/  130]
train() client id: f_00008-10-3 loss: 0.753543  [  128/  130]
train() client id: f_00008-11-0 loss: 0.775597  [   32/  130]
train() client id: f_00008-11-1 loss: 0.766813  [   64/  130]
train() client id: f_00008-11-2 loss: 0.656792  [   96/  130]
train() client id: f_00008-11-3 loss: 0.828070  [  128/  130]
train() client id: f_00008-12-0 loss: 0.694246  [   32/  130]
train() client id: f_00008-12-1 loss: 0.676143  [   64/  130]
train() client id: f_00008-12-2 loss: 0.846197  [   96/  130]
train() client id: f_00008-12-3 loss: 0.825060  [  128/  130]
train() client id: f_00009-0-0 loss: 1.180520  [   32/  118]
train() client id: f_00009-0-1 loss: 1.046577  [   64/  118]
train() client id: f_00009-0-2 loss: 1.172379  [   96/  118]
train() client id: f_00009-1-0 loss: 0.940070  [   32/  118]
train() client id: f_00009-1-1 loss: 0.985528  [   64/  118]
train() client id: f_00009-1-2 loss: 1.149666  [   96/  118]
train() client id: f_00009-2-0 loss: 0.949255  [   32/  118]
train() client id: f_00009-2-1 loss: 0.936181  [   64/  118]
train() client id: f_00009-2-2 loss: 1.134471  [   96/  118]
train() client id: f_00009-3-0 loss: 1.075659  [   32/  118]
train() client id: f_00009-3-1 loss: 0.748681  [   64/  118]
train() client id: f_00009-3-2 loss: 1.059391  [   96/  118]
train() client id: f_00009-4-0 loss: 0.955146  [   32/  118]
train() client id: f_00009-4-1 loss: 1.067268  [   64/  118]
train() client id: f_00009-4-2 loss: 0.738768  [   96/  118]
train() client id: f_00009-5-0 loss: 0.710899  [   32/  118]
train() client id: f_00009-5-1 loss: 0.925840  [   64/  118]
train() client id: f_00009-5-2 loss: 0.963035  [   96/  118]
train() client id: f_00009-6-0 loss: 1.035081  [   32/  118]
train() client id: f_00009-6-1 loss: 0.895154  [   64/  118]
train() client id: f_00009-6-2 loss: 0.775652  [   96/  118]
train() client id: f_00009-7-0 loss: 0.912256  [   32/  118]
train() client id: f_00009-7-1 loss: 0.872869  [   64/  118]
train() client id: f_00009-7-2 loss: 0.667551  [   96/  118]
train() client id: f_00009-8-0 loss: 0.838120  [   32/  118]
train() client id: f_00009-8-1 loss: 0.817574  [   64/  118]
train() client id: f_00009-8-2 loss: 0.904760  [   96/  118]
train() client id: f_00009-9-0 loss: 0.699397  [   32/  118]
train() client id: f_00009-9-1 loss: 0.800157  [   64/  118]
train() client id: f_00009-9-2 loss: 0.857558  [   96/  118]
train() client id: f_00009-10-0 loss: 0.876620  [   32/  118]
train() client id: f_00009-10-1 loss: 0.795199  [   64/  118]
train() client id: f_00009-10-2 loss: 0.739658  [   96/  118]
train() client id: f_00009-11-0 loss: 0.756813  [   32/  118]
train() client id: f_00009-11-1 loss: 0.887097  [   64/  118]
train() client id: f_00009-11-2 loss: 0.833338  [   96/  118]
train() client id: f_00009-12-0 loss: 0.706116  [   32/  118]
train() client id: f_00009-12-1 loss: 0.839966  [   64/  118]
train() client id: f_00009-12-2 loss: 0.804759  [   96/  118]
At round 50 accuracy: 0.6392572944297082
At round 50 training accuracy: 0.5888665325285044
At round 50 training loss: 0.8290839030519177
gradient difference: 0.36100777983665466
train() client id: f_00000-0-0 loss: 1.359866  [   32/  126]
train() client id: f_00000-0-1 loss: 1.133959  [   64/  126]
train() client id: f_00000-0-2 loss: 1.122912  [   96/  126]
train() client id: f_00000-1-0 loss: 0.987292  [   32/  126]
train() client id: f_00000-1-1 loss: 1.403293  [   64/  126]
train() client id: f_00000-1-2 loss: 0.891671  [   96/  126]
train() client id: f_00000-2-0 loss: 1.047404  [   32/  126]
train() client id: f_00000-2-1 loss: 0.807172  [   64/  126]
train() client id: f_00000-2-2 loss: 1.232663  [   96/  126]
train() client id: f_00000-3-0 loss: 1.036304  [   32/  126]
train() client id: f_00000-3-1 loss: 0.950950  [   64/  126]
train() client id: f_00000-3-2 loss: 0.979025  [   96/  126]
train() client id: f_00000-4-0 loss: 0.886693  [   32/  126]
train() client id: f_00000-4-1 loss: 0.920692  [   64/  126]
train() client id: f_00000-4-2 loss: 0.996480  [   96/  126]
train() client id: f_00000-5-0 loss: 0.882952  [   32/  126]
train() client id: f_00000-5-1 loss: 0.903221  [   64/  126]
train() client id: f_00000-5-2 loss: 0.862798  [   96/  126]
train() client id: f_00000-6-0 loss: 0.821636  [   32/  126]
train() client id: f_00000-6-1 loss: 0.815675  [   64/  126]
train() client id: f_00000-6-2 loss: 0.963021  [   96/  126]
train() client id: f_00000-7-0 loss: 0.941692  [   32/  126]
train() client id: f_00000-7-1 loss: 0.746629  [   64/  126]
train() client id: f_00000-7-2 loss: 0.744016  [   96/  126]
train() client id: f_00000-8-0 loss: 0.813545  [   32/  126]
train() client id: f_00000-8-1 loss: 0.748271  [   64/  126]
train() client id: f_00000-8-2 loss: 0.939729  [   96/  126]
train() client id: f_00000-9-0 loss: 0.826575  [   32/  126]
train() client id: f_00000-9-1 loss: 0.812670  [   64/  126]
train() client id: f_00000-9-2 loss: 0.821876  [   96/  126]
train() client id: f_00000-10-0 loss: 0.696276  [   32/  126]
train() client id: f_00000-10-1 loss: 0.904227  [   64/  126]
train() client id: f_00000-10-2 loss: 0.777821  [   96/  126]
train() client id: f_00000-11-0 loss: 0.826997  [   32/  126]
train() client id: f_00000-11-1 loss: 0.826545  [   64/  126]
train() client id: f_00000-11-2 loss: 0.764008  [   96/  126]
train() client id: f_00000-12-0 loss: 0.823249  [   32/  126]
train() client id: f_00000-12-1 loss: 0.822581  [   64/  126]
train() client id: f_00000-12-2 loss: 0.710688  [   96/  126]
train() client id: f_00001-0-0 loss: 0.353256  [   32/  265]
train() client id: f_00001-0-1 loss: 0.428940  [   64/  265]
train() client id: f_00001-0-2 loss: 0.607471  [   96/  265]
train() client id: f_00001-0-3 loss: 0.369253  [  128/  265]
train() client id: f_00001-0-4 loss: 0.350352  [  160/  265]
train() client id: f_00001-0-5 loss: 0.475589  [  192/  265]
train() client id: f_00001-0-6 loss: 0.455679  [  224/  265]
train() client id: f_00001-0-7 loss: 0.417863  [  256/  265]
train() client id: f_00001-1-0 loss: 0.349060  [   32/  265]
train() client id: f_00001-1-1 loss: 0.492570  [   64/  265]
train() client id: f_00001-1-2 loss: 0.408730  [   96/  265]
train() client id: f_00001-1-3 loss: 0.459179  [  128/  265]
train() client id: f_00001-1-4 loss: 0.360872  [  160/  265]
train() client id: f_00001-1-5 loss: 0.514960  [  192/  265]
train() client id: f_00001-1-6 loss: 0.338404  [  224/  265]
train() client id: f_00001-1-7 loss: 0.414145  [  256/  265]
train() client id: f_00001-2-0 loss: 0.446567  [   32/  265]
train() client id: f_00001-2-1 loss: 0.372410  [   64/  265]
train() client id: f_00001-2-2 loss: 0.440966  [   96/  265]
train() client id: f_00001-2-3 loss: 0.309733  [  128/  265]
train() client id: f_00001-2-4 loss: 0.427816  [  160/  265]
train() client id: f_00001-2-5 loss: 0.518816  [  192/  265]
train() client id: f_00001-2-6 loss: 0.331507  [  224/  265]
train() client id: f_00001-2-7 loss: 0.410995  [  256/  265]
train() client id: f_00001-3-0 loss: 0.396246  [   32/  265]
train() client id: f_00001-3-1 loss: 0.584387  [   64/  265]
train() client id: f_00001-3-2 loss: 0.323010  [   96/  265]
train() client id: f_00001-3-3 loss: 0.417372  [  128/  265]
train() client id: f_00001-3-4 loss: 0.429764  [  160/  265]
train() client id: f_00001-3-5 loss: 0.379102  [  192/  265]
train() client id: f_00001-3-6 loss: 0.401962  [  224/  265]
train() client id: f_00001-3-7 loss: 0.375850  [  256/  265]
train() client id: f_00001-4-0 loss: 0.394810  [   32/  265]
train() client id: f_00001-4-1 loss: 0.484414  [   64/  265]
train() client id: f_00001-4-2 loss: 0.362376  [   96/  265]
train() client id: f_00001-4-3 loss: 0.342123  [  128/  265]
train() client id: f_00001-4-4 loss: 0.363015  [  160/  265]
train() client id: f_00001-4-5 loss: 0.475830  [  192/  265]
train() client id: f_00001-4-6 loss: 0.498896  [  224/  265]
train() client id: f_00001-4-7 loss: 0.387056  [  256/  265]
train() client id: f_00001-5-0 loss: 0.325426  [   32/  265]
train() client id: f_00001-5-1 loss: 0.444632  [   64/  265]
train() client id: f_00001-5-2 loss: 0.490183  [   96/  265]
train() client id: f_00001-5-3 loss: 0.346963  [  128/  265]
train() client id: f_00001-5-4 loss: 0.480740  [  160/  265]
train() client id: f_00001-5-5 loss: 0.395878  [  192/  265]
train() client id: f_00001-5-6 loss: 0.376140  [  224/  265]
train() client id: f_00001-5-7 loss: 0.420524  [  256/  265]
train() client id: f_00001-6-0 loss: 0.566721  [   32/  265]
train() client id: f_00001-6-1 loss: 0.318822  [   64/  265]
train() client id: f_00001-6-2 loss: 0.428210  [   96/  265]
train() client id: f_00001-6-3 loss: 0.385059  [  128/  265]
train() client id: f_00001-6-4 loss: 0.401904  [  160/  265]
train() client id: f_00001-6-5 loss: 0.304820  [  192/  265]
train() client id: f_00001-6-6 loss: 0.460507  [  224/  265]
train() client id: f_00001-6-7 loss: 0.400192  [  256/  265]
train() client id: f_00001-7-0 loss: 0.335929  [   32/  265]
train() client id: f_00001-7-1 loss: 0.370729  [   64/  265]
train() client id: f_00001-7-2 loss: 0.378961  [   96/  265]
train() client id: f_00001-7-3 loss: 0.477338  [  128/  265]
train() client id: f_00001-7-4 loss: 0.484682  [  160/  265]
train() client id: f_00001-7-5 loss: 0.421654  [  192/  265]
train() client id: f_00001-7-6 loss: 0.392640  [  224/  265]
train() client id: f_00001-7-7 loss: 0.396949  [  256/  265]
train() client id: f_00001-8-0 loss: 0.400499  [   32/  265]
train() client id: f_00001-8-1 loss: 0.493631  [   64/  265]
train() client id: f_00001-8-2 loss: 0.365778  [   96/  265]
train() client id: f_00001-8-3 loss: 0.489235  [  128/  265]
train() client id: f_00001-8-4 loss: 0.312379  [  160/  265]
train() client id: f_00001-8-5 loss: 0.395596  [  192/  265]
train() client id: f_00001-8-6 loss: 0.386384  [  224/  265]
train() client id: f_00001-8-7 loss: 0.416936  [  256/  265]
train() client id: f_00001-9-0 loss: 0.398862  [   32/  265]
train() client id: f_00001-9-1 loss: 0.373272  [   64/  265]
train() client id: f_00001-9-2 loss: 0.382896  [   96/  265]
train() client id: f_00001-9-3 loss: 0.429289  [  128/  265]
train() client id: f_00001-9-4 loss: 0.517513  [  160/  265]
train() client id: f_00001-9-5 loss: 0.476111  [  192/  265]
train() client id: f_00001-9-6 loss: 0.304778  [  224/  265]
train() client id: f_00001-9-7 loss: 0.362356  [  256/  265]
train() client id: f_00001-10-0 loss: 0.442763  [   32/  265]
train() client id: f_00001-10-1 loss: 0.318758  [   64/  265]
train() client id: f_00001-10-2 loss: 0.341273  [   96/  265]
train() client id: f_00001-10-3 loss: 0.464278  [  128/  265]
train() client id: f_00001-10-4 loss: 0.323413  [  160/  265]
train() client id: f_00001-10-5 loss: 0.393464  [  192/  265]
train() client id: f_00001-10-6 loss: 0.465738  [  224/  265]
train() client id: f_00001-10-7 loss: 0.521776  [  256/  265]
train() client id: f_00001-11-0 loss: 0.492205  [   32/  265]
train() client id: f_00001-11-1 loss: 0.516074  [   64/  265]
train() client id: f_00001-11-2 loss: 0.380136  [   96/  265]
train() client id: f_00001-11-3 loss: 0.305705  [  128/  265]
train() client id: f_00001-11-4 loss: 0.391153  [  160/  265]
train() client id: f_00001-11-5 loss: 0.394028  [  192/  265]
train() client id: f_00001-11-6 loss: 0.351968  [  224/  265]
train() client id: f_00001-11-7 loss: 0.439272  [  256/  265]
train() client id: f_00001-12-0 loss: 0.411604  [   32/  265]
train() client id: f_00001-12-1 loss: 0.377730  [   64/  265]
train() client id: f_00001-12-2 loss: 0.504336  [   96/  265]
train() client id: f_00001-12-3 loss: 0.395106  [  128/  265]
train() client id: f_00001-12-4 loss: 0.295059  [  160/  265]
train() client id: f_00001-12-5 loss: 0.406954  [  192/  265]
train() client id: f_00001-12-6 loss: 0.398848  [  224/  265]
train() client id: f_00001-12-7 loss: 0.413528  [  256/  265]
train() client id: f_00002-0-0 loss: 1.422971  [   32/  124]
train() client id: f_00002-0-1 loss: 1.273746  [   64/  124]
train() client id: f_00002-0-2 loss: 1.281817  [   96/  124]
train() client id: f_00002-1-0 loss: 1.102538  [   32/  124]
train() client id: f_00002-1-1 loss: 1.241220  [   64/  124]
train() client id: f_00002-1-2 loss: 1.468509  [   96/  124]
train() client id: f_00002-2-0 loss: 1.200863  [   32/  124]
train() client id: f_00002-2-1 loss: 1.347253  [   64/  124]
train() client id: f_00002-2-2 loss: 1.177882  [   96/  124]
train() client id: f_00002-3-0 loss: 1.080332  [   32/  124]
train() client id: f_00002-3-1 loss: 1.272808  [   64/  124]
train() client id: f_00002-3-2 loss: 1.040192  [   96/  124]
train() client id: f_00002-4-0 loss: 1.091378  [   32/  124]
train() client id: f_00002-4-1 loss: 1.265411  [   64/  124]
train() client id: f_00002-4-2 loss: 1.123208  [   96/  124]
train() client id: f_00002-5-0 loss: 1.266653  [   32/  124]
train() client id: f_00002-5-1 loss: 0.977606  [   64/  124]
train() client id: f_00002-5-2 loss: 1.135396  [   96/  124]
train() client id: f_00002-6-0 loss: 1.210823  [   32/  124]
train() client id: f_00002-6-1 loss: 1.253162  [   64/  124]
train() client id: f_00002-6-2 loss: 0.853123  [   96/  124]
train() client id: f_00002-7-0 loss: 1.056526  [   32/  124]
train() client id: f_00002-7-1 loss: 0.988952  [   64/  124]
train() client id: f_00002-7-2 loss: 1.174181  [   96/  124]
train() client id: f_00002-8-0 loss: 1.180125  [   32/  124]
train() client id: f_00002-8-1 loss: 0.946220  [   64/  124]
train() client id: f_00002-8-2 loss: 1.204677  [   96/  124]
train() client id: f_00002-9-0 loss: 0.920425  [   32/  124]
train() client id: f_00002-9-1 loss: 1.117119  [   64/  124]
train() client id: f_00002-9-2 loss: 0.925565  [   96/  124]
train() client id: f_00002-10-0 loss: 1.175037  [   32/  124]
train() client id: f_00002-10-1 loss: 1.031605  [   64/  124]
train() client id: f_00002-10-2 loss: 0.900303  [   96/  124]
train() client id: f_00002-11-0 loss: 1.068733  [   32/  124]
train() client id: f_00002-11-1 loss: 0.883549  [   64/  124]
train() client id: f_00002-11-2 loss: 1.005057  [   96/  124]
train() client id: f_00002-12-0 loss: 0.921504  [   32/  124]
train() client id: f_00002-12-1 loss: 1.099690  [   64/  124]
train() client id: f_00002-12-2 loss: 1.037054  [   96/  124]
train() client id: f_00003-0-0 loss: 0.697475  [   32/   43]
train() client id: f_00003-1-0 loss: 0.722525  [   32/   43]
train() client id: f_00003-2-0 loss: 0.825086  [   32/   43]
train() client id: f_00003-3-0 loss: 0.718352  [   32/   43]
train() client id: f_00003-4-0 loss: 0.706460  [   32/   43]
train() client id: f_00003-5-0 loss: 0.785899  [   32/   43]
train() client id: f_00003-6-0 loss: 0.782523  [   32/   43]
train() client id: f_00003-7-0 loss: 0.575864  [   32/   43]
train() client id: f_00003-8-0 loss: 0.693173  [   32/   43]
train() client id: f_00003-9-0 loss: 0.863995  [   32/   43]
train() client id: f_00003-10-0 loss: 0.638736  [   32/   43]
train() client id: f_00003-11-0 loss: 0.592636  [   32/   43]
train() client id: f_00003-12-0 loss: 0.628016  [   32/   43]
train() client id: f_00004-0-0 loss: 0.778891  [   32/  306]
train() client id: f_00004-0-1 loss: 0.830707  [   64/  306]
train() client id: f_00004-0-2 loss: 0.819066  [   96/  306]
train() client id: f_00004-0-3 loss: 1.076724  [  128/  306]
train() client id: f_00004-0-4 loss: 0.848471  [  160/  306]
train() client id: f_00004-0-5 loss: 0.857219  [  192/  306]
train() client id: f_00004-0-6 loss: 0.881636  [  224/  306]
train() client id: f_00004-0-7 loss: 0.967819  [  256/  306]
train() client id: f_00004-0-8 loss: 1.014171  [  288/  306]
train() client id: f_00004-1-0 loss: 0.945459  [   32/  306]
train() client id: f_00004-1-1 loss: 1.001349  [   64/  306]
train() client id: f_00004-1-2 loss: 0.857308  [   96/  306]
train() client id: f_00004-1-3 loss: 0.832450  [  128/  306]
train() client id: f_00004-1-4 loss: 0.949392  [  160/  306]
train() client id: f_00004-1-5 loss: 0.838564  [  192/  306]
train() client id: f_00004-1-6 loss: 0.956111  [  224/  306]
train() client id: f_00004-1-7 loss: 0.759806  [  256/  306]
train() client id: f_00004-1-8 loss: 0.886654  [  288/  306]
train() client id: f_00004-2-0 loss: 0.904676  [   32/  306]
train() client id: f_00004-2-1 loss: 0.828122  [   64/  306]
train() client id: f_00004-2-2 loss: 0.998487  [   96/  306]
train() client id: f_00004-2-3 loss: 0.749032  [  128/  306]
train() client id: f_00004-2-4 loss: 0.915751  [  160/  306]
train() client id: f_00004-2-5 loss: 0.904433  [  192/  306]
train() client id: f_00004-2-6 loss: 0.953828  [  224/  306]
train() client id: f_00004-2-7 loss: 0.990677  [  256/  306]
train() client id: f_00004-2-8 loss: 0.884778  [  288/  306]
train() client id: f_00004-3-0 loss: 0.818992  [   32/  306]
train() client id: f_00004-3-1 loss: 0.880939  [   64/  306]
train() client id: f_00004-3-2 loss: 0.812312  [   96/  306]
train() client id: f_00004-3-3 loss: 0.860158  [  128/  306]
train() client id: f_00004-3-4 loss: 0.939161  [  160/  306]
train() client id: f_00004-3-5 loss: 0.954290  [  192/  306]
train() client id: f_00004-3-6 loss: 0.838125  [  224/  306]
train() client id: f_00004-3-7 loss: 0.943955  [  256/  306]
train() client id: f_00004-3-8 loss: 0.929126  [  288/  306]
train() client id: f_00004-4-0 loss: 0.840627  [   32/  306]
train() client id: f_00004-4-1 loss: 0.799313  [   64/  306]
train() client id: f_00004-4-2 loss: 0.849070  [   96/  306]
train() client id: f_00004-4-3 loss: 0.835761  [  128/  306]
train() client id: f_00004-4-4 loss: 0.910192  [  160/  306]
train() client id: f_00004-4-5 loss: 0.822240  [  192/  306]
train() client id: f_00004-4-6 loss: 1.004192  [  224/  306]
train() client id: f_00004-4-7 loss: 0.855676  [  256/  306]
train() client id: f_00004-4-8 loss: 0.921811  [  288/  306]
train() client id: f_00004-5-0 loss: 0.807036  [   32/  306]
train() client id: f_00004-5-1 loss: 0.877678  [   64/  306]
train() client id: f_00004-5-2 loss: 0.732598  [   96/  306]
train() client id: f_00004-5-3 loss: 0.948120  [  128/  306]
train() client id: f_00004-5-4 loss: 0.890953  [  160/  306]
train() client id: f_00004-5-5 loss: 1.057415  [  192/  306]
train() client id: f_00004-5-6 loss: 0.861635  [  224/  306]
train() client id: f_00004-5-7 loss: 0.792637  [  256/  306]
train() client id: f_00004-5-8 loss: 0.958682  [  288/  306]
train() client id: f_00004-6-0 loss: 0.978630  [   32/  306]
train() client id: f_00004-6-1 loss: 0.875769  [   64/  306]
train() client id: f_00004-6-2 loss: 0.989812  [   96/  306]
train() client id: f_00004-6-3 loss: 0.907618  [  128/  306]
train() client id: f_00004-6-4 loss: 0.930326  [  160/  306]
train() client id: f_00004-6-5 loss: 0.827936  [  192/  306]
train() client id: f_00004-6-6 loss: 0.887861  [  224/  306]
train() client id: f_00004-6-7 loss: 0.827109  [  256/  306]
train() client id: f_00004-6-8 loss: 0.798888  [  288/  306]
train() client id: f_00004-7-0 loss: 0.930827  [   32/  306]
train() client id: f_00004-7-1 loss: 0.896869  [   64/  306]
train() client id: f_00004-7-2 loss: 0.874130  [   96/  306]
train() client id: f_00004-7-3 loss: 0.900938  [  128/  306]
train() client id: f_00004-7-4 loss: 0.767805  [  160/  306]
train() client id: f_00004-7-5 loss: 0.797921  [  192/  306]
train() client id: f_00004-7-6 loss: 0.854636  [  224/  306]
train() client id: f_00004-7-7 loss: 0.915535  [  256/  306]
train() client id: f_00004-7-8 loss: 0.997308  [  288/  306]
train() client id: f_00004-8-0 loss: 1.036005  [   32/  306]
train() client id: f_00004-8-1 loss: 0.820938  [   64/  306]
train() client id: f_00004-8-2 loss: 0.882969  [   96/  306]
train() client id: f_00004-8-3 loss: 0.766600  [  128/  306]
train() client id: f_00004-8-4 loss: 0.975037  [  160/  306]
train() client id: f_00004-8-5 loss: 0.933220  [  192/  306]
train() client id: f_00004-8-6 loss: 0.717964  [  224/  306]
train() client id: f_00004-8-7 loss: 0.873767  [  256/  306]
train() client id: f_00004-8-8 loss: 0.924945  [  288/  306]
train() client id: f_00004-9-0 loss: 0.818771  [   32/  306]
train() client id: f_00004-9-1 loss: 1.022377  [   64/  306]
train() client id: f_00004-9-2 loss: 0.958483  [   96/  306]
train() client id: f_00004-9-3 loss: 0.824071  [  128/  306]
train() client id: f_00004-9-4 loss: 0.934477  [  160/  306]
train() client id: f_00004-9-5 loss: 0.869927  [  192/  306]
train() client id: f_00004-9-6 loss: 0.856462  [  224/  306]
train() client id: f_00004-9-7 loss: 0.859003  [  256/  306]
train() client id: f_00004-9-8 loss: 0.821091  [  288/  306]
train() client id: f_00004-10-0 loss: 0.832487  [   32/  306]
train() client id: f_00004-10-1 loss: 0.840940  [   64/  306]
train() client id: f_00004-10-2 loss: 0.896787  [   96/  306]
train() client id: f_00004-10-3 loss: 0.887208  [  128/  306]
train() client id: f_00004-10-4 loss: 0.929161  [  160/  306]
train() client id: f_00004-10-5 loss: 0.868798  [  192/  306]
train() client id: f_00004-10-6 loss: 0.878961  [  224/  306]
train() client id: f_00004-10-7 loss: 0.809420  [  256/  306]
train() client id: f_00004-10-8 loss: 1.034461  [  288/  306]
train() client id: f_00004-11-0 loss: 0.835341  [   32/  306]
train() client id: f_00004-11-1 loss: 0.871406  [   64/  306]
train() client id: f_00004-11-2 loss: 0.982572  [   96/  306]
train() client id: f_00004-11-3 loss: 0.891164  [  128/  306]
train() client id: f_00004-11-4 loss: 0.709942  [  160/  306]
train() client id: f_00004-11-5 loss: 0.892160  [  192/  306]
train() client id: f_00004-11-6 loss: 0.832006  [  224/  306]
train() client id: f_00004-11-7 loss: 1.035828  [  256/  306]
train() client id: f_00004-11-8 loss: 0.891214  [  288/  306]
train() client id: f_00004-12-0 loss: 0.833867  [   32/  306]
train() client id: f_00004-12-1 loss: 0.809438  [   64/  306]
train() client id: f_00004-12-2 loss: 0.935118  [   96/  306]
train() client id: f_00004-12-3 loss: 1.040933  [  128/  306]
train() client id: f_00004-12-4 loss: 0.754226  [  160/  306]
train() client id: f_00004-12-5 loss: 0.995271  [  192/  306]
train() client id: f_00004-12-6 loss: 0.849556  [  224/  306]
train() client id: f_00004-12-7 loss: 0.829263  [  256/  306]
train() client id: f_00004-12-8 loss: 0.891830  [  288/  306]
train() client id: f_00005-0-0 loss: 0.880389  [   32/  146]
train() client id: f_00005-0-1 loss: 0.625954  [   64/  146]
train() client id: f_00005-0-2 loss: 0.729274  [   96/  146]
train() client id: f_00005-0-3 loss: 0.684013  [  128/  146]
train() client id: f_00005-1-0 loss: 0.984540  [   32/  146]
train() client id: f_00005-1-1 loss: 0.702847  [   64/  146]
train() client id: f_00005-1-2 loss: 0.615533  [   96/  146]
train() client id: f_00005-1-3 loss: 0.644857  [  128/  146]
train() client id: f_00005-2-0 loss: 0.761967  [   32/  146]
train() client id: f_00005-2-1 loss: 0.798705  [   64/  146]
train() client id: f_00005-2-2 loss: 0.630093  [   96/  146]
train() client id: f_00005-2-3 loss: 0.787727  [  128/  146]
train() client id: f_00005-3-0 loss: 0.764606  [   32/  146]
train() client id: f_00005-3-1 loss: 0.834640  [   64/  146]
train() client id: f_00005-3-2 loss: 0.897960  [   96/  146]
train() client id: f_00005-3-3 loss: 0.527410  [  128/  146]
train() client id: f_00005-4-0 loss: 0.905640  [   32/  146]
train() client id: f_00005-4-1 loss: 0.708056  [   64/  146]
train() client id: f_00005-4-2 loss: 0.748610  [   96/  146]
train() client id: f_00005-4-3 loss: 0.512138  [  128/  146]
train() client id: f_00005-5-0 loss: 0.747179  [   32/  146]
train() client id: f_00005-5-1 loss: 0.652086  [   64/  146]
train() client id: f_00005-5-2 loss: 0.671472  [   96/  146]
train() client id: f_00005-5-3 loss: 0.877545  [  128/  146]
train() client id: f_00005-6-0 loss: 0.791974  [   32/  146]
train() client id: f_00005-6-1 loss: 0.711432  [   64/  146]
train() client id: f_00005-6-2 loss: 0.448420  [   96/  146]
train() client id: f_00005-6-3 loss: 0.759820  [  128/  146]
train() client id: f_00005-7-0 loss: 0.770030  [   32/  146]
train() client id: f_00005-7-1 loss: 0.588884  [   64/  146]
train() client id: f_00005-7-2 loss: 0.733913  [   96/  146]
train() client id: f_00005-7-3 loss: 0.756222  [  128/  146]
train() client id: f_00005-8-0 loss: 0.773917  [   32/  146]
train() client id: f_00005-8-1 loss: 0.695635  [   64/  146]
train() client id: f_00005-8-2 loss: 0.590525  [   96/  146]
train() client id: f_00005-8-3 loss: 0.789231  [  128/  146]
train() client id: f_00005-9-0 loss: 0.855316  [   32/  146]
train() client id: f_00005-9-1 loss: 0.671877  [   64/  146]
train() client id: f_00005-9-2 loss: 0.764758  [   96/  146]
train() client id: f_00005-9-3 loss: 0.610165  [  128/  146]
train() client id: f_00005-10-0 loss: 0.591384  [   32/  146]
train() client id: f_00005-10-1 loss: 0.614107  [   64/  146]
train() client id: f_00005-10-2 loss: 0.736450  [   96/  146]
train() client id: f_00005-10-3 loss: 0.825155  [  128/  146]
train() client id: f_00005-11-0 loss: 0.730277  [   32/  146]
train() client id: f_00005-11-1 loss: 0.552661  [   64/  146]
train() client id: f_00005-11-2 loss: 0.593355  [   96/  146]
train() client id: f_00005-11-3 loss: 1.008747  [  128/  146]
train() client id: f_00005-12-0 loss: 0.899646  [   32/  146]
train() client id: f_00005-12-1 loss: 0.678481  [   64/  146]
train() client id: f_00005-12-2 loss: 0.702631  [   96/  146]
train() client id: f_00005-12-3 loss: 0.691277  [  128/  146]
train() client id: f_00006-0-0 loss: 0.510210  [   32/   54]
train() client id: f_00006-1-0 loss: 0.436985  [   32/   54]
train() client id: f_00006-2-0 loss: 0.474949  [   32/   54]
train() client id: f_00006-3-0 loss: 0.421129  [   32/   54]
train() client id: f_00006-4-0 loss: 0.516681  [   32/   54]
train() client id: f_00006-5-0 loss: 0.492552  [   32/   54]
train() client id: f_00006-6-0 loss: 0.504719  [   32/   54]
train() client id: f_00006-7-0 loss: 0.504673  [   32/   54]
train() client id: f_00006-8-0 loss: 0.489839  [   32/   54]
train() client id: f_00006-9-0 loss: 0.432616  [   32/   54]
train() client id: f_00006-10-0 loss: 0.452522  [   32/   54]
train() client id: f_00006-11-0 loss: 0.380432  [   32/   54]
train() client id: f_00006-12-0 loss: 0.490660  [   32/   54]
train() client id: f_00007-0-0 loss: 0.555252  [   32/  179]
train() client id: f_00007-0-1 loss: 0.812832  [   64/  179]
train() client id: f_00007-0-2 loss: 0.651276  [   96/  179]
train() client id: f_00007-0-3 loss: 0.564987  [  128/  179]
train() client id: f_00007-0-4 loss: 0.533426  [  160/  179]
train() client id: f_00007-1-0 loss: 0.622680  [   32/  179]
train() client id: f_00007-1-1 loss: 0.635247  [   64/  179]
train() client id: f_00007-1-2 loss: 0.814016  [   96/  179]
train() client id: f_00007-1-3 loss: 0.441358  [  128/  179]
train() client id: f_00007-1-4 loss: 0.647743  [  160/  179]
train() client id: f_00007-2-0 loss: 0.518607  [   32/  179]
train() client id: f_00007-2-1 loss: 0.629932  [   64/  179]
train() client id: f_00007-2-2 loss: 0.557035  [   96/  179]
train() client id: f_00007-2-3 loss: 0.553800  [  128/  179]
train() client id: f_00007-2-4 loss: 0.678792  [  160/  179]
train() client id: f_00007-3-0 loss: 0.577571  [   32/  179]
train() client id: f_00007-3-1 loss: 0.658719  [   64/  179]
train() client id: f_00007-3-2 loss: 0.600740  [   96/  179]
train() client id: f_00007-3-3 loss: 0.691669  [  128/  179]
train() client id: f_00007-3-4 loss: 0.558393  [  160/  179]
train() client id: f_00007-4-0 loss: 0.513101  [   32/  179]
train() client id: f_00007-4-1 loss: 0.564812  [   64/  179]
train() client id: f_00007-4-2 loss: 0.605192  [   96/  179]
train() client id: f_00007-4-3 loss: 0.698807  [  128/  179]
train() client id: f_00007-4-4 loss: 0.584976  [  160/  179]
train() client id: f_00007-5-0 loss: 0.606362  [   32/  179]
train() client id: f_00007-5-1 loss: 0.523576  [   64/  179]
train() client id: f_00007-5-2 loss: 0.471151  [   96/  179]
train() client id: f_00007-5-3 loss: 0.640880  [  128/  179]
train() client id: f_00007-5-4 loss: 0.727680  [  160/  179]
train() client id: f_00007-6-0 loss: 0.484946  [   32/  179]
train() client id: f_00007-6-1 loss: 0.510614  [   64/  179]
train() client id: f_00007-6-2 loss: 0.658533  [   96/  179]
train() client id: f_00007-6-3 loss: 0.513952  [  128/  179]
train() client id: f_00007-6-4 loss: 0.616151  [  160/  179]
train() client id: f_00007-7-0 loss: 0.440479  [   32/  179]
train() client id: f_00007-7-1 loss: 0.640050  [   64/  179]
train() client id: f_00007-7-2 loss: 0.614637  [   96/  179]
train() client id: f_00007-7-3 loss: 0.592356  [  128/  179]
train() client id: f_00007-7-4 loss: 0.507296  [  160/  179]
train() client id: f_00007-8-0 loss: 0.541583  [   32/  179]
train() client id: f_00007-8-1 loss: 0.459648  [   64/  179]
train() client id: f_00007-8-2 loss: 0.401171  [   96/  179]
train() client id: f_00007-8-3 loss: 0.884323  [  128/  179]
train() client id: f_00007-8-4 loss: 0.700956  [  160/  179]
train() client id: f_00007-9-0 loss: 0.533965  [   32/  179]
train() client id: f_00007-9-1 loss: 0.655309  [   64/  179]
train() client id: f_00007-9-2 loss: 0.633877  [   96/  179]
train() client id: f_00007-9-3 loss: 0.519529  [  128/  179]
train() client id: f_00007-9-4 loss: 0.395411  [  160/  179]
train() client id: f_00007-10-0 loss: 0.624462  [   32/  179]
train() client id: f_00007-10-1 loss: 0.477675  [   64/  179]
train() client id: f_00007-10-2 loss: 0.775810  [   96/  179]
train() client id: f_00007-10-3 loss: 0.630048  [  128/  179]
train() client id: f_00007-10-4 loss: 0.465644  [  160/  179]
train() client id: f_00007-11-0 loss: 0.733520  [   32/  179]
train() client id: f_00007-11-1 loss: 0.512533  [   64/  179]
train() client id: f_00007-11-2 loss: 0.631128  [   96/  179]
train() client id: f_00007-11-3 loss: 0.393029  [  128/  179]
train() client id: f_00007-11-4 loss: 0.716972  [  160/  179]
train() client id: f_00007-12-0 loss: 0.619039  [   32/  179]
train() client id: f_00007-12-1 loss: 0.395860  [   64/  179]
train() client id: f_00007-12-2 loss: 0.840361  [   96/  179]
train() client id: f_00007-12-3 loss: 0.514261  [  128/  179]
train() client id: f_00007-12-4 loss: 0.414507  [  160/  179]
train() client id: f_00008-0-0 loss: 0.687720  [   32/  130]
train() client id: f_00008-0-1 loss: 0.658455  [   64/  130]
train() client id: f_00008-0-2 loss: 0.599327  [   96/  130]
train() client id: f_00008-0-3 loss: 0.680409  [  128/  130]
train() client id: f_00008-1-0 loss: 0.684767  [   32/  130]
train() client id: f_00008-1-1 loss: 0.757878  [   64/  130]
train() client id: f_00008-1-2 loss: 0.663235  [   96/  130]
train() client id: f_00008-1-3 loss: 0.567981  [  128/  130]
train() client id: f_00008-2-0 loss: 0.640204  [   32/  130]
train() client id: f_00008-2-1 loss: 0.684965  [   64/  130]
train() client id: f_00008-2-2 loss: 0.739938  [   96/  130]
train() client id: f_00008-2-3 loss: 0.578385  [  128/  130]
train() client id: f_00008-3-0 loss: 0.592822  [   32/  130]
train() client id: f_00008-3-1 loss: 0.550761  [   64/  130]
train() client id: f_00008-3-2 loss: 0.855420  [   96/  130]
train() client id: f_00008-3-3 loss: 0.686284  [  128/  130]
train() client id: f_00008-4-0 loss: 0.650651  [   32/  130]
train() client id: f_00008-4-1 loss: 0.675491  [   64/  130]
train() client id: f_00008-4-2 loss: 0.674017  [   96/  130]
train() client id: f_00008-4-3 loss: 0.641528  [  128/  130]
train() client id: f_00008-5-0 loss: 0.722998  [   32/  130]
train() client id: f_00008-5-1 loss: 0.685399  [   64/  130]
train() client id: f_00008-5-2 loss: 0.682020  [   96/  130]
train() client id: f_00008-5-3 loss: 0.602742  [  128/  130]
train() client id: f_00008-6-0 loss: 0.839043  [   32/  130]
train() client id: f_00008-6-1 loss: 0.694439  [   64/  130]
train() client id: f_00008-6-2 loss: 0.581096  [   96/  130]
train() client id: f_00008-6-3 loss: 0.575796  [  128/  130]
train() client id: f_00008-7-0 loss: 0.713239  [   32/  130]
train() client id: f_00008-7-1 loss: 0.733848  [   64/  130]
train() client id: f_00008-7-2 loss: 0.579242  [   96/  130]
train() client id: f_00008-7-3 loss: 0.635276  [  128/  130]
train() client id: f_00008-8-0 loss: 0.659639  [   32/  130]
train() client id: f_00008-8-1 loss: 0.680492  [   64/  130]
train() client id: f_00008-8-2 loss: 0.683169  [   96/  130]
train() client id: f_00008-8-3 loss: 0.655713  [  128/  130]
train() client id: f_00008-9-0 loss: 0.707153  [   32/  130]
train() client id: f_00008-9-1 loss: 0.694664  [   64/  130]
train() client id: f_00008-9-2 loss: 0.597776  [   96/  130]
train() client id: f_00008-9-3 loss: 0.669592  [  128/  130]
train() client id: f_00008-10-0 loss: 0.720102  [   32/  130]
train() client id: f_00008-10-1 loss: 0.586663  [   64/  130]
train() client id: f_00008-10-2 loss: 0.732108  [   96/  130]
train() client id: f_00008-10-3 loss: 0.660683  [  128/  130]
train() client id: f_00008-11-0 loss: 0.659478  [   32/  130]
train() client id: f_00008-11-1 loss: 0.623714  [   64/  130]
train() client id: f_00008-11-2 loss: 0.786238  [   96/  130]
train() client id: f_00008-11-3 loss: 0.618328  [  128/  130]
train() client id: f_00008-12-0 loss: 0.825582  [   32/  130]
train() client id: f_00008-12-1 loss: 0.595529  [   64/  130]
train() client id: f_00008-12-2 loss: 0.608061  [   96/  130]
train() client id: f_00008-12-3 loss: 0.676294  [  128/  130]
train() client id: f_00009-0-0 loss: 0.941344  [   32/  118]
train() client id: f_00009-0-1 loss: 1.299392  [   64/  118]
train() client id: f_00009-0-2 loss: 1.047979  [   96/  118]
train() client id: f_00009-1-0 loss: 0.923956  [   32/  118]
train() client id: f_00009-1-1 loss: 1.090200  [   64/  118]
train() client id: f_00009-1-2 loss: 0.925874  [   96/  118]
train() client id: f_00009-2-0 loss: 0.896469  [   32/  118]
train() client id: f_00009-2-1 loss: 1.051996  [   64/  118]
train() client id: f_00009-2-2 loss: 0.988869  [   96/  118]
train() client id: f_00009-3-0 loss: 0.881222  [   32/  118]
train() client id: f_00009-3-1 loss: 1.057266  [   64/  118]
train() client id: f_00009-3-2 loss: 0.892577  [   96/  118]
train() client id: f_00009-4-0 loss: 0.795283  [   32/  118]
train() client id: f_00009-4-1 loss: 0.809123  [   64/  118]
train() client id: f_00009-4-2 loss: 1.046905  [   96/  118]
train() client id: f_00009-5-0 loss: 0.782332  [   32/  118]
train() client id: f_00009-5-1 loss: 0.917181  [   64/  118]
train() client id: f_00009-5-2 loss: 0.828176  [   96/  118]
train() client id: f_00009-6-0 loss: 0.836687  [   32/  118]
train() client id: f_00009-6-1 loss: 0.766455  [   64/  118]
train() client id: f_00009-6-2 loss: 0.830179  [   96/  118]
train() client id: f_00009-7-0 loss: 0.660766  [   32/  118]
train() client id: f_00009-7-1 loss: 0.898040  [   64/  118]
train() client id: f_00009-7-2 loss: 0.939733  [   96/  118]
train() client id: f_00009-8-0 loss: 0.803384  [   32/  118]
train() client id: f_00009-8-1 loss: 0.948440  [   64/  118]
train() client id: f_00009-8-2 loss: 0.793961  [   96/  118]
train() client id: f_00009-9-0 loss: 0.735896  [   32/  118]
train() client id: f_00009-9-1 loss: 0.918024  [   64/  118]
train() client id: f_00009-9-2 loss: 0.768142  [   96/  118]
train() client id: f_00009-10-0 loss: 0.588454  [   32/  118]
train() client id: f_00009-10-1 loss: 0.709287  [   64/  118]
train() client id: f_00009-10-2 loss: 0.946154  [   96/  118]
train() client id: f_00009-11-0 loss: 0.708724  [   32/  118]
train() client id: f_00009-11-1 loss: 0.922143  [   64/  118]
train() client id: f_00009-11-2 loss: 0.686605  [   96/  118]
train() client id: f_00009-12-0 loss: 0.838220  [   32/  118]
train() client id: f_00009-12-1 loss: 0.806705  [   64/  118]
train() client id: f_00009-12-2 loss: 0.840235  [   96/  118]
At round 51 accuracy: 0.6392572944297082
At round 51 training accuracy: 0.5868544600938967
At round 51 training loss: 0.8331198788608831
gradient difference: 0.440213143825531
train() client id: f_00000-0-0 loss: 1.244415  [   32/  126]
train() client id: f_00000-0-1 loss: 1.029546  [   64/  126]
train() client id: f_00000-0-2 loss: 1.171562  [   96/  126]
train() client id: f_00000-1-0 loss: 1.073473  [   32/  126]
train() client id: f_00000-1-1 loss: 1.235584  [   64/  126]
train() client id: f_00000-1-2 loss: 0.888294  [   96/  126]
train() client id: f_00000-2-0 loss: 1.038545  [   32/  126]
train() client id: f_00000-2-1 loss: 0.857153  [   64/  126]
train() client id: f_00000-2-2 loss: 1.098312  [   96/  126]
train() client id: f_00000-3-0 loss: 1.123892  [   32/  126]
train() client id: f_00000-3-1 loss: 0.934291  [   64/  126]
train() client id: f_00000-3-2 loss: 0.916009  [   96/  126]
train() client id: f_00000-4-0 loss: 0.983252  [   32/  126]
train() client id: f_00000-4-1 loss: 1.090380  [   64/  126]
train() client id: f_00000-4-2 loss: 0.825440  [   96/  126]
train() client id: f_00000-5-0 loss: 0.901754  [   32/  126]
train() client id: f_00000-5-1 loss: 1.010116  [   64/  126]
train() client id: f_00000-5-2 loss: 0.905835  [   96/  126]
train() client id: f_00000-6-0 loss: 0.777799  [   32/  126]
train() client id: f_00000-6-1 loss: 1.031918  [   64/  126]
train() client id: f_00000-6-2 loss: 0.787307  [   96/  126]
train() client id: f_00000-7-0 loss: 1.030550  [   32/  126]
train() client id: f_00000-7-1 loss: 0.724653  [   64/  126]
train() client id: f_00000-7-2 loss: 0.808750  [   96/  126]
train() client id: f_00000-8-0 loss: 0.792043  [   32/  126]
train() client id: f_00000-8-1 loss: 0.834153  [   64/  126]
train() client id: f_00000-8-2 loss: 0.914656  [   96/  126]
train() client id: f_00000-9-0 loss: 0.898491  [   32/  126]
train() client id: f_00000-9-1 loss: 0.870320  [   64/  126]
train() client id: f_00000-9-2 loss: 0.914500  [   96/  126]
train() client id: f_00000-10-0 loss: 0.798977  [   32/  126]
train() client id: f_00000-10-1 loss: 0.902396  [   64/  126]
train() client id: f_00000-10-2 loss: 0.886850  [   96/  126]
train() client id: f_00000-11-0 loss: 0.906421  [   32/  126]
train() client id: f_00000-11-1 loss: 0.736604  [   64/  126]
train() client id: f_00000-11-2 loss: 0.832308  [   96/  126]
train() client id: f_00000-12-0 loss: 0.767901  [   32/  126]
train() client id: f_00000-12-1 loss: 0.892779  [   64/  126]
train() client id: f_00000-12-2 loss: 0.798491  [   96/  126]
train() client id: f_00001-0-0 loss: 0.486008  [   32/  265]
train() client id: f_00001-0-1 loss: 0.469856  [   64/  265]
train() client id: f_00001-0-2 loss: 0.329507  [   96/  265]
train() client id: f_00001-0-3 loss: 0.342836  [  128/  265]
train() client id: f_00001-0-4 loss: 0.434472  [  160/  265]
train() client id: f_00001-0-5 loss: 0.440013  [  192/  265]
train() client id: f_00001-0-6 loss: 0.472964  [  224/  265]
train() client id: f_00001-0-7 loss: 0.536257  [  256/  265]
train() client id: f_00001-1-0 loss: 0.412256  [   32/  265]
train() client id: f_00001-1-1 loss: 0.359101  [   64/  265]
train() client id: f_00001-1-2 loss: 0.490745  [   96/  265]
train() client id: f_00001-1-3 loss: 0.443517  [  128/  265]
train() client id: f_00001-1-4 loss: 0.467568  [  160/  265]
train() client id: f_00001-1-5 loss: 0.487068  [  192/  265]
train() client id: f_00001-1-6 loss: 0.359488  [  224/  265]
train() client id: f_00001-1-7 loss: 0.439696  [  256/  265]
train() client id: f_00001-2-0 loss: 0.332990  [   32/  265]
train() client id: f_00001-2-1 loss: 0.571614  [   64/  265]
train() client id: f_00001-2-2 loss: 0.353956  [   96/  265]
train() client id: f_00001-2-3 loss: 0.402472  [  128/  265]
train() client id: f_00001-2-4 loss: 0.364039  [  160/  265]
train() client id: f_00001-2-5 loss: 0.503612  [  192/  265]
train() client id: f_00001-2-6 loss: 0.539538  [  224/  265]
train() client id: f_00001-2-7 loss: 0.323075  [  256/  265]
train() client id: f_00001-3-0 loss: 0.414082  [   32/  265]
train() client id: f_00001-3-1 loss: 0.453237  [   64/  265]
train() client id: f_00001-3-2 loss: 0.328016  [   96/  265]
train() client id: f_00001-3-3 loss: 0.403259  [  128/  265]
train() client id: f_00001-3-4 loss: 0.378095  [  160/  265]
train() client id: f_00001-3-5 loss: 0.491850  [  192/  265]
train() client id: f_00001-3-6 loss: 0.383576  [  224/  265]
train() client id: f_00001-3-7 loss: 0.504035  [  256/  265]
train() client id: f_00001-4-0 loss: 0.374901  [   32/  265]
train() client id: f_00001-4-1 loss: 0.408713  [   64/  265]
train() client id: f_00001-4-2 loss: 0.419635  [   96/  265]
train() client id: f_00001-4-3 loss: 0.332687  [  128/  265]
train() client id: f_00001-4-4 loss: 0.378365  [  160/  265]
train() client id: f_00001-4-5 loss: 0.433268  [  192/  265]
train() client id: f_00001-4-6 loss: 0.380714  [  224/  265]
train() client id: f_00001-4-7 loss: 0.476601  [  256/  265]
train() client id: f_00001-5-0 loss: 0.332256  [   32/  265]
train() client id: f_00001-5-1 loss: 0.305309  [   64/  265]
train() client id: f_00001-5-2 loss: 0.508074  [   96/  265]
train() client id: f_00001-5-3 loss: 0.422752  [  128/  265]
train() client id: f_00001-5-4 loss: 0.447413  [  160/  265]
train() client id: f_00001-5-5 loss: 0.498404  [  192/  265]
train() client id: f_00001-5-6 loss: 0.360228  [  224/  265]
train() client id: f_00001-5-7 loss: 0.396359  [  256/  265]
train() client id: f_00001-6-0 loss: 0.396719  [   32/  265]
train() client id: f_00001-6-1 loss: 0.382563  [   64/  265]
train() client id: f_00001-6-2 loss: 0.384761  [   96/  265]
train() client id: f_00001-6-3 loss: 0.308387  [  128/  265]
train() client id: f_00001-6-4 loss: 0.466154  [  160/  265]
train() client id: f_00001-6-5 loss: 0.344156  [  192/  265]
train() client id: f_00001-6-6 loss: 0.522830  [  224/  265]
train() client id: f_00001-6-7 loss: 0.346681  [  256/  265]
train() client id: f_00001-7-0 loss: 0.473592  [   32/  265]
train() client id: f_00001-7-1 loss: 0.367005  [   64/  265]
train() client id: f_00001-7-2 loss: 0.327883  [   96/  265]
train() client id: f_00001-7-3 loss: 0.355948  [  128/  265]
train() client id: f_00001-7-4 loss: 0.372319  [  160/  265]
train() client id: f_00001-7-5 loss: 0.472869  [  192/  265]
train() client id: f_00001-7-6 loss: 0.398220  [  224/  265]
train() client id: f_00001-7-7 loss: 0.467142  [  256/  265]
train() client id: f_00001-8-0 loss: 0.409549  [   32/  265]
train() client id: f_00001-8-1 loss: 0.366720  [   64/  265]
train() client id: f_00001-8-2 loss: 0.479451  [   96/  265]
train() client id: f_00001-8-3 loss: 0.388419  [  128/  265]
train() client id: f_00001-8-4 loss: 0.468196  [  160/  265]
train() client id: f_00001-8-5 loss: 0.318642  [  192/  265]
train() client id: f_00001-8-6 loss: 0.296031  [  224/  265]
train() client id: f_00001-8-7 loss: 0.468126  [  256/  265]
train() client id: f_00001-9-0 loss: 0.402553  [   32/  265]
train() client id: f_00001-9-1 loss: 0.486989  [   64/  265]
train() client id: f_00001-9-2 loss: 0.385524  [   96/  265]
train() client id: f_00001-9-3 loss: 0.360074  [  128/  265]
train() client id: f_00001-9-4 loss: 0.383529  [  160/  265]
train() client id: f_00001-9-5 loss: 0.397663  [  192/  265]
train() client id: f_00001-9-6 loss: 0.370121  [  224/  265]
train() client id: f_00001-9-7 loss: 0.372301  [  256/  265]
train() client id: f_00001-10-0 loss: 0.563089  [   32/  265]
train() client id: f_00001-10-1 loss: 0.369743  [   64/  265]
train() client id: f_00001-10-2 loss: 0.409303  [   96/  265]
train() client id: f_00001-10-3 loss: 0.310247  [  128/  265]
train() client id: f_00001-10-4 loss: 0.410777  [  160/  265]
train() client id: f_00001-10-5 loss: 0.391068  [  192/  265]
train() client id: f_00001-10-6 loss: 0.466099  [  224/  265]
train() client id: f_00001-10-7 loss: 0.284298  [  256/  265]
train() client id: f_00001-11-0 loss: 0.465269  [   32/  265]
train() client id: f_00001-11-1 loss: 0.401774  [   64/  265]
train() client id: f_00001-11-2 loss: 0.341249  [   96/  265]
train() client id: f_00001-11-3 loss: 0.367762  [  128/  265]
train() client id: f_00001-11-4 loss: 0.372649  [  160/  265]
train() client id: f_00001-11-5 loss: 0.376100  [  192/  265]
train() client id: f_00001-11-6 loss: 0.508538  [  224/  265]
train() client id: f_00001-11-7 loss: 0.363253  [  256/  265]
train() client id: f_00001-12-0 loss: 0.377710  [   32/  265]
train() client id: f_00001-12-1 loss: 0.442493  [   64/  265]
train() client id: f_00001-12-2 loss: 0.378362  [   96/  265]
train() client id: f_00001-12-3 loss: 0.462064  [  128/  265]
train() client id: f_00001-12-4 loss: 0.299234  [  160/  265]
train() client id: f_00001-12-5 loss: 0.392744  [  192/  265]
train() client id: f_00001-12-6 loss: 0.375074  [  224/  265]
train() client id: f_00001-12-7 loss: 0.410475  [  256/  265]
train() client id: f_00002-0-0 loss: 0.976468  [   32/  124]
train() client id: f_00002-0-1 loss: 1.128211  [   64/  124]
train() client id: f_00002-0-2 loss: 1.154407  [   96/  124]
train() client id: f_00002-1-0 loss: 1.182025  [   32/  124]
train() client id: f_00002-1-1 loss: 0.893154  [   64/  124]
train() client id: f_00002-1-2 loss: 1.123725  [   96/  124]
train() client id: f_00002-2-0 loss: 0.987587  [   32/  124]
train() client id: f_00002-2-1 loss: 1.082688  [   64/  124]
train() client id: f_00002-2-2 loss: 1.085688  [   96/  124]
train() client id: f_00002-3-0 loss: 1.165683  [   32/  124]
train() client id: f_00002-3-1 loss: 0.903534  [   64/  124]
train() client id: f_00002-3-2 loss: 1.009815  [   96/  124]
train() client id: f_00002-4-0 loss: 0.931371  [   32/  124]
train() client id: f_00002-4-1 loss: 1.027268  [   64/  124]
train() client id: f_00002-4-2 loss: 0.840975  [   96/  124]
train() client id: f_00002-5-0 loss: 0.749268  [   32/  124]
train() client id: f_00002-5-1 loss: 0.926544  [   64/  124]
train() client id: f_00002-5-2 loss: 1.009412  [   96/  124]
train() client id: f_00002-6-0 loss: 0.963762  [   32/  124]
train() client id: f_00002-6-1 loss: 1.025026  [   64/  124]
train() client id: f_00002-6-2 loss: 0.947209  [   96/  124]
train() client id: f_00002-7-0 loss: 0.822042  [   32/  124]
train() client id: f_00002-7-1 loss: 0.959538  [   64/  124]
train() client id: f_00002-7-2 loss: 0.931853  [   96/  124]
train() client id: f_00002-8-0 loss: 0.931663  [   32/  124]
train() client id: f_00002-8-1 loss: 0.888011  [   64/  124]
train() client id: f_00002-8-2 loss: 0.737553  [   96/  124]
train() client id: f_00002-9-0 loss: 0.970720  [   32/  124]
train() client id: f_00002-9-1 loss: 0.896133  [   64/  124]
train() client id: f_00002-9-2 loss: 0.860346  [   96/  124]
train() client id: f_00002-10-0 loss: 0.894017  [   32/  124]
train() client id: f_00002-10-1 loss: 0.875814  [   64/  124]
train() client id: f_00002-10-2 loss: 0.915292  [   96/  124]
train() client id: f_00002-11-0 loss: 0.858904  [   32/  124]
train() client id: f_00002-11-1 loss: 0.939866  [   64/  124]
train() client id: f_00002-11-2 loss: 0.911766  [   96/  124]
train() client id: f_00002-12-0 loss: 0.820642  [   32/  124]
train() client id: f_00002-12-1 loss: 1.003505  [   64/  124]
train() client id: f_00002-12-2 loss: 0.922612  [   96/  124]
train() client id: f_00003-0-0 loss: 0.835939  [   32/   43]
train() client id: f_00003-1-0 loss: 0.506977  [   32/   43]
train() client id: f_00003-2-0 loss: 0.669266  [   32/   43]
train() client id: f_00003-3-0 loss: 0.726929  [   32/   43]
train() client id: f_00003-4-0 loss: 0.564751  [   32/   43]
train() client id: f_00003-5-0 loss: 0.653475  [   32/   43]
train() client id: f_00003-6-0 loss: 0.950186  [   32/   43]
train() client id: f_00003-7-0 loss: 0.720722  [   32/   43]
train() client id: f_00003-8-0 loss: 0.519609  [   32/   43]
train() client id: f_00003-9-0 loss: 0.724221  [   32/   43]
train() client id: f_00003-10-0 loss: 0.605326  [   32/   43]
train() client id: f_00003-11-0 loss: 0.835911  [   32/   43]
train() client id: f_00003-12-0 loss: 0.591202  [   32/   43]
train() client id: f_00004-0-0 loss: 0.669145  [   32/  306]
train() client id: f_00004-0-1 loss: 0.769259  [   64/  306]
train() client id: f_00004-0-2 loss: 0.854442  [   96/  306]
train() client id: f_00004-0-3 loss: 0.672491  [  128/  306]
train() client id: f_00004-0-4 loss: 0.756380  [  160/  306]
train() client id: f_00004-0-5 loss: 0.646671  [  192/  306]
train() client id: f_00004-0-6 loss: 0.991400  [  224/  306]
train() client id: f_00004-0-7 loss: 0.879653  [  256/  306]
train() client id: f_00004-0-8 loss: 0.644099  [  288/  306]
train() client id: f_00004-1-0 loss: 0.829954  [   32/  306]
train() client id: f_00004-1-1 loss: 0.614839  [   64/  306]
train() client id: f_00004-1-2 loss: 0.965921  [   96/  306]
train() client id: f_00004-1-3 loss: 0.701289  [  128/  306]
train() client id: f_00004-1-4 loss: 0.810944  [  160/  306]
train() client id: f_00004-1-5 loss: 0.817313  [  192/  306]
train() client id: f_00004-1-6 loss: 0.790194  [  224/  306]
train() client id: f_00004-1-7 loss: 0.701995  [  256/  306]
train() client id: f_00004-1-8 loss: 0.767764  [  288/  306]
train() client id: f_00004-2-0 loss: 0.933991  [   32/  306]
train() client id: f_00004-2-1 loss: 0.823951  [   64/  306]
train() client id: f_00004-2-2 loss: 0.748616  [   96/  306]
train() client id: f_00004-2-3 loss: 0.765967  [  128/  306]
train() client id: f_00004-2-4 loss: 0.839479  [  160/  306]
train() client id: f_00004-2-5 loss: 0.693648  [  192/  306]
train() client id: f_00004-2-6 loss: 0.771553  [  224/  306]
train() client id: f_00004-2-7 loss: 0.669720  [  256/  306]
train() client id: f_00004-2-8 loss: 0.773823  [  288/  306]
train() client id: f_00004-3-0 loss: 0.881140  [   32/  306]
train() client id: f_00004-3-1 loss: 0.875925  [   64/  306]
train() client id: f_00004-3-2 loss: 0.810391  [   96/  306]
train() client id: f_00004-3-3 loss: 0.740146  [  128/  306]
train() client id: f_00004-3-4 loss: 0.661502  [  160/  306]
train() client id: f_00004-3-5 loss: 0.884443  [  192/  306]
train() client id: f_00004-3-6 loss: 0.682821  [  224/  306]
train() client id: f_00004-3-7 loss: 0.675426  [  256/  306]
train() client id: f_00004-3-8 loss: 0.833129  [  288/  306]
train() client id: f_00004-4-0 loss: 0.828166  [   32/  306]
train() client id: f_00004-4-1 loss: 0.833932  [   64/  306]
train() client id: f_00004-4-2 loss: 0.676682  [   96/  306]
train() client id: f_00004-4-3 loss: 0.836581  [  128/  306]
train() client id: f_00004-4-4 loss: 0.819258  [  160/  306]
train() client id: f_00004-4-5 loss: 0.699113  [  192/  306]
train() client id: f_00004-4-6 loss: 0.840403  [  224/  306]
train() client id: f_00004-4-7 loss: 0.774807  [  256/  306]
train() client id: f_00004-4-8 loss: 0.644910  [  288/  306]
train() client id: f_00004-5-0 loss: 0.853160  [   32/  306]
train() client id: f_00004-5-1 loss: 0.919473  [   64/  306]
train() client id: f_00004-5-2 loss: 0.710578  [   96/  306]
train() client id: f_00004-5-3 loss: 0.726103  [  128/  306]
train() client id: f_00004-5-4 loss: 0.913915  [  160/  306]
train() client id: f_00004-5-5 loss: 0.735202  [  192/  306]
train() client id: f_00004-5-6 loss: 0.860441  [  224/  306]
train() client id: f_00004-5-7 loss: 0.699498  [  256/  306]
train() client id: f_00004-5-8 loss: 0.688578  [  288/  306]
train() client id: f_00004-6-0 loss: 0.665970  [   32/  306]
train() client id: f_00004-6-1 loss: 0.700143  [   64/  306]
train() client id: f_00004-6-2 loss: 0.875088  [   96/  306]
train() client id: f_00004-6-3 loss: 0.855484  [  128/  306]
train() client id: f_00004-6-4 loss: 0.729541  [  160/  306]
train() client id: f_00004-6-5 loss: 0.819604  [  192/  306]
train() client id: f_00004-6-6 loss: 0.769156  [  224/  306]
train() client id: f_00004-6-7 loss: 0.794302  [  256/  306]
train() client id: f_00004-6-8 loss: 0.786279  [  288/  306]
train() client id: f_00004-7-0 loss: 0.713121  [   32/  306]
train() client id: f_00004-7-1 loss: 0.840786  [   64/  306]
train() client id: f_00004-7-2 loss: 0.788824  [   96/  306]
train() client id: f_00004-7-3 loss: 0.767425  [  128/  306]
train() client id: f_00004-7-4 loss: 0.834444  [  160/  306]
train() client id: f_00004-7-5 loss: 0.719128  [  192/  306]
train() client id: f_00004-7-6 loss: 0.758678  [  224/  306]
train() client id: f_00004-7-7 loss: 0.888852  [  256/  306]
train() client id: f_00004-7-8 loss: 0.724777  [  288/  306]
train() client id: f_00004-8-0 loss: 0.791319  [   32/  306]
train() client id: f_00004-8-1 loss: 0.752678  [   64/  306]
train() client id: f_00004-8-2 loss: 0.705253  [   96/  306]
train() client id: f_00004-8-3 loss: 0.740176  [  128/  306]
train() client id: f_00004-8-4 loss: 0.832888  [  160/  306]
train() client id: f_00004-8-5 loss: 0.838077  [  192/  306]
train() client id: f_00004-8-6 loss: 0.793756  [  224/  306]
train() client id: f_00004-8-7 loss: 0.776431  [  256/  306]
train() client id: f_00004-8-8 loss: 0.741122  [  288/  306]
train() client id: f_00004-9-0 loss: 0.709384  [   32/  306]
train() client id: f_00004-9-1 loss: 0.916286  [   64/  306]
train() client id: f_00004-9-2 loss: 0.671434  [   96/  306]
train() client id: f_00004-9-3 loss: 0.821264  [  128/  306]
train() client id: f_00004-9-4 loss: 0.846324  [  160/  306]
train() client id: f_00004-9-5 loss: 0.902407  [  192/  306]
train() client id: f_00004-9-6 loss: 0.710092  [  224/  306]
train() client id: f_00004-9-7 loss: 0.708043  [  256/  306]
train() client id: f_00004-9-8 loss: 0.739699  [  288/  306]
train() client id: f_00004-10-0 loss: 0.681884  [   32/  306]
train() client id: f_00004-10-1 loss: 0.822447  [   64/  306]
train() client id: f_00004-10-2 loss: 0.809693  [   96/  306]
train() client id: f_00004-10-3 loss: 0.890819  [  128/  306]
train() client id: f_00004-10-4 loss: 0.704430  [  160/  306]
train() client id: f_00004-10-5 loss: 0.783978  [  192/  306]
train() client id: f_00004-10-6 loss: 0.633557  [  224/  306]
train() client id: f_00004-10-7 loss: 0.859022  [  256/  306]
train() client id: f_00004-10-8 loss: 0.826824  [  288/  306]
train() client id: f_00004-11-0 loss: 0.846119  [   32/  306]
train() client id: f_00004-11-1 loss: 0.763674  [   64/  306]
train() client id: f_00004-11-2 loss: 0.708827  [   96/  306]
train() client id: f_00004-11-3 loss: 0.759243  [  128/  306]
train() client id: f_00004-11-4 loss: 0.799709  [  160/  306]
train() client id: f_00004-11-5 loss: 0.820758  [  192/  306]
train() client id: f_00004-11-6 loss: 0.823794  [  224/  306]
train() client id: f_00004-11-7 loss: 0.800880  [  256/  306]
train() client id: f_00004-11-8 loss: 0.742310  [  288/  306]
train() client id: f_00004-12-0 loss: 0.784886  [   32/  306]
train() client id: f_00004-12-1 loss: 0.872381  [   64/  306]
train() client id: f_00004-12-2 loss: 0.865198  [   96/  306]
train() client id: f_00004-12-3 loss: 0.601598  [  128/  306]
train() client id: f_00004-12-4 loss: 0.771357  [  160/  306]
train() client id: f_00004-12-5 loss: 0.824883  [  192/  306]
train() client id: f_00004-12-6 loss: 0.758522  [  224/  306]
train() client id: f_00004-12-7 loss: 0.787627  [  256/  306]
train() client id: f_00004-12-8 loss: 0.821534  [  288/  306]
train() client id: f_00005-0-0 loss: 0.626524  [   32/  146]
train() client id: f_00005-0-1 loss: 0.702605  [   64/  146]
train() client id: f_00005-0-2 loss: 0.861570  [   96/  146]
train() client id: f_00005-0-3 loss: 0.520548  [  128/  146]
train() client id: f_00005-1-0 loss: 0.676903  [   32/  146]
train() client id: f_00005-1-1 loss: 0.765424  [   64/  146]
train() client id: f_00005-1-2 loss: 0.537628  [   96/  146]
train() client id: f_00005-1-3 loss: 0.747331  [  128/  146]
train() client id: f_00005-2-0 loss: 0.763220  [   32/  146]
train() client id: f_00005-2-1 loss: 0.540129  [   64/  146]
train() client id: f_00005-2-2 loss: 0.697824  [   96/  146]
train() client id: f_00005-2-3 loss: 0.663035  [  128/  146]
train() client id: f_00005-3-0 loss: 0.667675  [   32/  146]
train() client id: f_00005-3-1 loss: 0.640880  [   64/  146]
train() client id: f_00005-3-2 loss: 0.742560  [   96/  146]
train() client id: f_00005-3-3 loss: 0.659060  [  128/  146]
train() client id: f_00005-4-0 loss: 0.705756  [   32/  146]
train() client id: f_00005-4-1 loss: 0.553991  [   64/  146]
train() client id: f_00005-4-2 loss: 0.606429  [   96/  146]
train() client id: f_00005-4-3 loss: 0.650682  [  128/  146]
train() client id: f_00005-5-0 loss: 0.832737  [   32/  146]
train() client id: f_00005-5-1 loss: 0.913545  [   64/  146]
train() client id: f_00005-5-2 loss: 0.533265  [   96/  146]
train() client id: f_00005-5-3 loss: 0.428233  [  128/  146]
train() client id: f_00005-6-0 loss: 0.686459  [   32/  146]
train() client id: f_00005-6-1 loss: 0.807192  [   64/  146]
train() client id: f_00005-6-2 loss: 0.683540  [   96/  146]
train() client id: f_00005-6-3 loss: 0.400066  [  128/  146]
train() client id: f_00005-7-0 loss: 0.592065  [   32/  146]
train() client id: f_00005-7-1 loss: 0.555289  [   64/  146]
train() client id: f_00005-7-2 loss: 0.644153  [   96/  146]
train() client id: f_00005-7-3 loss: 0.973933  [  128/  146]
train() client id: f_00005-8-0 loss: 0.811188  [   32/  146]
train() client id: f_00005-8-1 loss: 0.572030  [   64/  146]
train() client id: f_00005-8-2 loss: 0.450999  [   96/  146]
train() client id: f_00005-8-3 loss: 0.775624  [  128/  146]
train() client id: f_00005-9-0 loss: 0.776125  [   32/  146]
train() client id: f_00005-9-1 loss: 0.524902  [   64/  146]
train() client id: f_00005-9-2 loss: 0.726357  [   96/  146]
train() client id: f_00005-9-3 loss: 0.603069  [  128/  146]
train() client id: f_00005-10-0 loss: 0.689198  [   32/  146]
train() client id: f_00005-10-1 loss: 0.776808  [   64/  146]
train() client id: f_00005-10-2 loss: 0.396381  [   96/  146]
train() client id: f_00005-10-3 loss: 0.746246  [  128/  146]
train() client id: f_00005-11-0 loss: 0.613542  [   32/  146]
train() client id: f_00005-11-1 loss: 0.803480  [   64/  146]
train() client id: f_00005-11-2 loss: 0.513534  [   96/  146]
train() client id: f_00005-11-3 loss: 0.772687  [  128/  146]
train() client id: f_00005-12-0 loss: 0.760787  [   32/  146]
train() client id: f_00005-12-1 loss: 0.633918  [   64/  146]
train() client id: f_00005-12-2 loss: 0.622355  [   96/  146]
train() client id: f_00005-12-3 loss: 0.632899  [  128/  146]
train() client id: f_00006-0-0 loss: 0.439047  [   32/   54]
train() client id: f_00006-1-0 loss: 0.504153  [   32/   54]
train() client id: f_00006-2-0 loss: 0.483702  [   32/   54]
train() client id: f_00006-3-0 loss: 0.450302  [   32/   54]
train() client id: f_00006-4-0 loss: 0.481533  [   32/   54]
train() client id: f_00006-5-0 loss: 0.435172  [   32/   54]
train() client id: f_00006-6-0 loss: 0.384793  [   32/   54]
train() client id: f_00006-7-0 loss: 0.437785  [   32/   54]
train() client id: f_00006-8-0 loss: 0.431269  [   32/   54]
train() client id: f_00006-9-0 loss: 0.491940  [   32/   54]
train() client id: f_00006-10-0 loss: 0.424613  [   32/   54]
train() client id: f_00006-11-0 loss: 0.490205  [   32/   54]
train() client id: f_00006-12-0 loss: 0.445343  [   32/   54]
train() client id: f_00007-0-0 loss: 0.778039  [   32/  179]
train() client id: f_00007-0-1 loss: 0.709987  [   64/  179]
train() client id: f_00007-0-2 loss: 0.851363  [   96/  179]
train() client id: f_00007-0-3 loss: 0.818640  [  128/  179]
train() client id: f_00007-0-4 loss: 0.652012  [  160/  179]
train() client id: f_00007-1-0 loss: 0.612573  [   32/  179]
train() client id: f_00007-1-1 loss: 0.881100  [   64/  179]
train() client id: f_00007-1-2 loss: 0.656160  [   96/  179]
train() client id: f_00007-1-3 loss: 0.713263  [  128/  179]
train() client id: f_00007-1-4 loss: 0.771903  [  160/  179]
train() client id: f_00007-2-0 loss: 0.679161  [   32/  179]
train() client id: f_00007-2-1 loss: 0.784610  [   64/  179]
train() client id: f_00007-2-2 loss: 0.802384  [   96/  179]
train() client id: f_00007-2-3 loss: 0.736044  [  128/  179]
train() client id: f_00007-2-4 loss: 0.633771  [  160/  179]
train() client id: f_00007-3-0 loss: 0.743023  [   32/  179]
train() client id: f_00007-3-1 loss: 0.658631  [   64/  179]
train() client id: f_00007-3-2 loss: 0.666944  [   96/  179]
train() client id: f_00007-3-3 loss: 0.662879  [  128/  179]
train() client id: f_00007-3-4 loss: 0.769994  [  160/  179]
train() client id: f_00007-4-0 loss: 0.696651  [   32/  179]
train() client id: f_00007-4-1 loss: 0.752959  [   64/  179]
train() client id: f_00007-4-2 loss: 0.579542  [   96/  179]
train() client id: f_00007-4-3 loss: 0.925750  [  128/  179]
train() client id: f_00007-4-4 loss: 0.567362  [  160/  179]
train() client id: f_00007-5-0 loss: 0.700740  [   32/  179]
train() client id: f_00007-5-1 loss: 0.533429  [   64/  179]
train() client id: f_00007-5-2 loss: 0.559808  [   96/  179]
train() client id: f_00007-5-3 loss: 1.024852  [  128/  179]
train() client id: f_00007-5-4 loss: 0.571923  [  160/  179]
train() client id: f_00007-6-0 loss: 0.709116  [   32/  179]
train() client id: f_00007-6-1 loss: 0.749725  [   64/  179]
train() client id: f_00007-6-2 loss: 0.902458  [   96/  179]
train() client id: f_00007-6-3 loss: 0.565574  [  128/  179]
train() client id: f_00007-6-4 loss: 0.642231  [  160/  179]
train() client id: f_00007-7-0 loss: 0.595084  [   32/  179]
train() client id: f_00007-7-1 loss: 0.823634  [   64/  179]
train() client id: f_00007-7-2 loss: 0.573934  [   96/  179]
train() client id: f_00007-7-3 loss: 0.656410  [  128/  179]
train() client id: f_00007-7-4 loss: 0.862062  [  160/  179]
train() client id: f_00007-8-0 loss: 0.572434  [   32/  179]
train() client id: f_00007-8-1 loss: 0.593883  [   64/  179]
train() client id: f_00007-8-2 loss: 0.534554  [   96/  179]
train() client id: f_00007-8-3 loss: 0.714918  [  128/  179]
train() client id: f_00007-8-4 loss: 1.000557  [  160/  179]
train() client id: f_00007-9-0 loss: 0.766647  [   32/  179]
train() client id: f_00007-9-1 loss: 0.585786  [   64/  179]
train() client id: f_00007-9-2 loss: 0.828032  [   96/  179]
train() client id: f_00007-9-3 loss: 0.706596  [  128/  179]
train() client id: f_00007-9-4 loss: 0.685186  [  160/  179]
train() client id: f_00007-10-0 loss: 0.689261  [   32/  179]
train() client id: f_00007-10-1 loss: 0.720267  [   64/  179]
train() client id: f_00007-10-2 loss: 0.582355  [   96/  179]
train() client id: f_00007-10-3 loss: 0.820544  [  128/  179]
train() client id: f_00007-10-4 loss: 0.769038  [  160/  179]
train() client id: f_00007-11-0 loss: 0.797535  [   32/  179]
train() client id: f_00007-11-1 loss: 0.673028  [   64/  179]
train() client id: f_00007-11-2 loss: 0.752486  [   96/  179]
train() client id: f_00007-11-3 loss: 0.707087  [  128/  179]
train() client id: f_00007-11-4 loss: 0.629540  [  160/  179]
train() client id: f_00007-12-0 loss: 0.764297  [   32/  179]
train() client id: f_00007-12-1 loss: 0.605390  [   64/  179]
train() client id: f_00007-12-2 loss: 0.514676  [   96/  179]
train() client id: f_00007-12-3 loss: 0.753108  [  128/  179]
train() client id: f_00007-12-4 loss: 0.827641  [  160/  179]
train() client id: f_00008-0-0 loss: 0.778360  [   32/  130]
train() client id: f_00008-0-1 loss: 0.679289  [   64/  130]
train() client id: f_00008-0-2 loss: 0.651315  [   96/  130]
train() client id: f_00008-0-3 loss: 0.775086  [  128/  130]
train() client id: f_00008-1-0 loss: 0.762819  [   32/  130]
train() client id: f_00008-1-1 loss: 0.684859  [   64/  130]
train() client id: f_00008-1-2 loss: 0.655749  [   96/  130]
train() client id: f_00008-1-3 loss: 0.769281  [  128/  130]
train() client id: f_00008-2-0 loss: 0.888398  [   32/  130]
train() client id: f_00008-2-1 loss: 0.700229  [   64/  130]
train() client id: f_00008-2-2 loss: 0.578209  [   96/  130]
train() client id: f_00008-2-3 loss: 0.668766  [  128/  130]
train() client id: f_00008-3-0 loss: 0.697000  [   32/  130]
train() client id: f_00008-3-1 loss: 0.739690  [   64/  130]
train() client id: f_00008-3-2 loss: 0.666609  [   96/  130]
train() client id: f_00008-3-3 loss: 0.781587  [  128/  130]
train() client id: f_00008-4-0 loss: 0.709640  [   32/  130]
train() client id: f_00008-4-1 loss: 0.775476  [   64/  130]
train() client id: f_00008-4-2 loss: 0.662128  [   96/  130]
train() client id: f_00008-4-3 loss: 0.726983  [  128/  130]
train() client id: f_00008-5-0 loss: 0.713899  [   32/  130]
train() client id: f_00008-5-1 loss: 0.665277  [   64/  130]
train() client id: f_00008-5-2 loss: 0.688954  [   96/  130]
train() client id: f_00008-5-3 loss: 0.808349  [  128/  130]
train() client id: f_00008-6-0 loss: 0.827991  [   32/  130]
train() client id: f_00008-6-1 loss: 0.730543  [   64/  130]
train() client id: f_00008-6-2 loss: 0.732107  [   96/  130]
train() client id: f_00008-6-3 loss: 0.589991  [  128/  130]
train() client id: f_00008-7-0 loss: 0.831969  [   32/  130]
train() client id: f_00008-7-1 loss: 0.707125  [   64/  130]
train() client id: f_00008-7-2 loss: 0.725136  [   96/  130]
train() client id: f_00008-7-3 loss: 0.620469  [  128/  130]
train() client id: f_00008-8-0 loss: 0.655444  [   32/  130]
train() client id: f_00008-8-1 loss: 0.732263  [   64/  130]
train() client id: f_00008-8-2 loss: 0.756090  [   96/  130]
train() client id: f_00008-8-3 loss: 0.735046  [  128/  130]
train() client id: f_00008-9-0 loss: 0.668633  [   32/  130]
train() client id: f_00008-9-1 loss: 0.716158  [   64/  130]
train() client id: f_00008-9-2 loss: 0.718365  [   96/  130]
train() client id: f_00008-9-3 loss: 0.769496  [  128/  130]
train() client id: f_00008-10-0 loss: 0.742975  [   32/  130]
train() client id: f_00008-10-1 loss: 0.655720  [   64/  130]
train() client id: f_00008-10-2 loss: 0.795292  [   96/  130]
train() client id: f_00008-10-3 loss: 0.689605  [  128/  130]
train() client id: f_00008-11-0 loss: 0.807539  [   32/  130]
train() client id: f_00008-11-1 loss: 0.723101  [   64/  130]
train() client id: f_00008-11-2 loss: 0.689766  [   96/  130]
train() client id: f_00008-11-3 loss: 0.661104  [  128/  130]
train() client id: f_00008-12-0 loss: 0.603053  [   32/  130]
train() client id: f_00008-12-1 loss: 0.756813  [   64/  130]
train() client id: f_00008-12-2 loss: 0.696457  [   96/  130]
train() client id: f_00008-12-3 loss: 0.803760  [  128/  130]
train() client id: f_00009-0-0 loss: 0.834611  [   32/  118]
train() client id: f_00009-0-1 loss: 0.896211  [   64/  118]
train() client id: f_00009-0-2 loss: 1.002196  [   96/  118]
train() client id: f_00009-1-0 loss: 1.019979  [   32/  118]
train() client id: f_00009-1-1 loss: 0.875742  [   64/  118]
train() client id: f_00009-1-2 loss: 0.862387  [   96/  118]
train() client id: f_00009-2-0 loss: 0.994874  [   32/  118]
train() client id: f_00009-2-1 loss: 0.769069  [   64/  118]
train() client id: f_00009-2-2 loss: 0.825615  [   96/  118]
train() client id: f_00009-3-0 loss: 0.660816  [   32/  118]
train() client id: f_00009-3-1 loss: 0.845815  [   64/  118]
train() client id: f_00009-3-2 loss: 0.805156  [   96/  118]
train() client id: f_00009-4-0 loss: 0.685822  [   32/  118]
train() client id: f_00009-4-1 loss: 0.743146  [   64/  118]
train() client id: f_00009-4-2 loss: 0.884993  [   96/  118]
train() client id: f_00009-5-0 loss: 0.724834  [   32/  118]
train() client id: f_00009-5-1 loss: 0.858803  [   64/  118]
train() client id: f_00009-5-2 loss: 0.782536  [   96/  118]
train() client id: f_00009-6-0 loss: 0.704213  [   32/  118]
train() client id: f_00009-6-1 loss: 0.835524  [   64/  118]
train() client id: f_00009-6-2 loss: 0.714009  [   96/  118]
train() client id: f_00009-7-0 loss: 0.657914  [   32/  118]
train() client id: f_00009-7-1 loss: 0.748986  [   64/  118]
train() client id: f_00009-7-2 loss: 0.913676  [   96/  118]
train() client id: f_00009-8-0 loss: 0.803163  [   32/  118]
train() client id: f_00009-8-1 loss: 0.606151  [   64/  118]
train() client id: f_00009-8-2 loss: 0.877721  [   96/  118]
train() client id: f_00009-9-0 loss: 0.618104  [   32/  118]
train() client id: f_00009-9-1 loss: 0.735136  [   64/  118]
train() client id: f_00009-9-2 loss: 0.941921  [   96/  118]
train() client id: f_00009-10-0 loss: 0.772062  [   32/  118]
train() client id: f_00009-10-1 loss: 0.912378  [   64/  118]
train() client id: f_00009-10-2 loss: 0.798235  [   96/  118]
train() client id: f_00009-11-0 loss: 0.751974  [   32/  118]
train() client id: f_00009-11-1 loss: 0.713485  [   64/  118]
train() client id: f_00009-11-2 loss: 0.722946  [   96/  118]
train() client id: f_00009-12-0 loss: 0.640599  [   32/  118]
train() client id: f_00009-12-1 loss: 0.894529  [   64/  118]
train() client id: f_00009-12-2 loss: 0.881118  [   96/  118]
At round 52 accuracy: 0.6392572944297082
At round 52 training accuracy: 0.5895372233400402
At round 52 training loss: 0.8348323435803074
gradient difference: 0.4072761535644531
train() client id: f_00000-0-0 loss: 1.095576  [   32/  126]
train() client id: f_00000-0-1 loss: 1.336920  [   64/  126]
train() client id: f_00000-0-2 loss: 1.073927  [   96/  126]
train() client id: f_00000-1-0 loss: 1.312842  [   32/  126]
train() client id: f_00000-1-1 loss: 1.000776  [   64/  126]
train() client id: f_00000-1-2 loss: 1.056625  [   96/  126]
train() client id: f_00000-2-0 loss: 1.073898  [   32/  126]
train() client id: f_00000-2-1 loss: 0.974407  [   64/  126]
train() client id: f_00000-2-2 loss: 0.910501  [   96/  126]
train() client id: f_00000-3-0 loss: 1.032637  [   32/  126]
train() client id: f_00000-3-1 loss: 1.007718  [   64/  126]
train() client id: f_00000-3-2 loss: 0.963256  [   96/  126]
train() client id: f_00000-4-0 loss: 1.098561  [   32/  126]
train() client id: f_00000-4-1 loss: 0.833127  [   64/  126]
train() client id: f_00000-4-2 loss: 0.895412  [   96/  126]
train() client id: f_00000-5-0 loss: 1.035887  [   32/  126]
train() client id: f_00000-5-1 loss: 0.838264  [   64/  126]
train() client id: f_00000-5-2 loss: 0.927395  [   96/  126]
train() client id: f_00000-6-0 loss: 0.936774  [   32/  126]
train() client id: f_00000-6-1 loss: 0.821649  [   64/  126]
train() client id: f_00000-6-2 loss: 0.745205  [   96/  126]
train() client id: f_00000-7-0 loss: 0.845355  [   32/  126]
train() client id: f_00000-7-1 loss: 0.875554  [   64/  126]
train() client id: f_00000-7-2 loss: 0.843570  [   96/  126]
train() client id: f_00000-8-0 loss: 0.864669  [   32/  126]
train() client id: f_00000-8-1 loss: 0.902904  [   64/  126]
train() client id: f_00000-8-2 loss: 0.832937  [   96/  126]
train() client id: f_00000-9-0 loss: 0.916865  [   32/  126]
train() client id: f_00000-9-1 loss: 0.819107  [   64/  126]
train() client id: f_00000-9-2 loss: 0.834377  [   96/  126]
train() client id: f_00000-10-0 loss: 0.774759  [   32/  126]
train() client id: f_00000-10-1 loss: 0.811069  [   64/  126]
train() client id: f_00000-10-2 loss: 0.934007  [   96/  126]
train() client id: f_00000-11-0 loss: 0.853980  [   32/  126]
train() client id: f_00000-11-1 loss: 0.781060  [   64/  126]
train() client id: f_00000-11-2 loss: 0.895657  [   96/  126]
train() client id: f_00000-12-0 loss: 0.585865  [   32/  126]
train() client id: f_00000-12-1 loss: 0.989778  [   64/  126]
train() client id: f_00000-12-2 loss: 0.960243  [   96/  126]
train() client id: f_00001-0-0 loss: 0.458706  [   32/  265]
train() client id: f_00001-0-1 loss: 0.519750  [   64/  265]
train() client id: f_00001-0-2 loss: 0.416889  [   96/  265]
train() client id: f_00001-0-3 loss: 0.358427  [  128/  265]
train() client id: f_00001-0-4 loss: 0.425069  [  160/  265]
train() client id: f_00001-0-5 loss: 0.437565  [  192/  265]
train() client id: f_00001-0-6 loss: 0.501186  [  224/  265]
train() client id: f_00001-0-7 loss: 0.447856  [  256/  265]
train() client id: f_00001-1-0 loss: 0.368130  [   32/  265]
train() client id: f_00001-1-1 loss: 0.335532  [   64/  265]
train() client id: f_00001-1-2 loss: 0.596924  [   96/  265]
train() client id: f_00001-1-3 loss: 0.330283  [  128/  265]
train() client id: f_00001-1-4 loss: 0.537023  [  160/  265]
train() client id: f_00001-1-5 loss: 0.414062  [  192/  265]
train() client id: f_00001-1-6 loss: 0.472248  [  224/  265]
train() client id: f_00001-1-7 loss: 0.439844  [  256/  265]
train() client id: f_00001-2-0 loss: 0.338550  [   32/  265]
train() client id: f_00001-2-1 loss: 0.425638  [   64/  265]
train() client id: f_00001-2-2 loss: 0.333732  [   96/  265]
train() client id: f_00001-2-3 loss: 0.348850  [  128/  265]
train() client id: f_00001-2-4 loss: 0.715422  [  160/  265]
train() client id: f_00001-2-5 loss: 0.378145  [  192/  265]
train() client id: f_00001-2-6 loss: 0.386123  [  224/  265]
train() client id: f_00001-2-7 loss: 0.468860  [  256/  265]
train() client id: f_00001-3-0 loss: 0.535514  [   32/  265]
train() client id: f_00001-3-1 loss: 0.308625  [   64/  265]
train() client id: f_00001-3-2 loss: 0.483738  [   96/  265]
train() client id: f_00001-3-3 loss: 0.363726  [  128/  265]
train() client id: f_00001-3-4 loss: 0.484830  [  160/  265]
train() client id: f_00001-3-5 loss: 0.350531  [  192/  265]
train() client id: f_00001-3-6 loss: 0.379717  [  224/  265]
train() client id: f_00001-3-7 loss: 0.479494  [  256/  265]
train() client id: f_00001-4-0 loss: 0.357738  [   32/  265]
train() client id: f_00001-4-1 loss: 0.441438  [   64/  265]
train() client id: f_00001-4-2 loss: 0.451594  [   96/  265]
train() client id: f_00001-4-3 loss: 0.391832  [  128/  265]
train() client id: f_00001-4-4 loss: 0.333795  [  160/  265]
train() client id: f_00001-4-5 loss: 0.646841  [  192/  265]
train() client id: f_00001-4-6 loss: 0.404190  [  224/  265]
train() client id: f_00001-4-7 loss: 0.308361  [  256/  265]
train() client id: f_00001-5-0 loss: 0.377208  [   32/  265]
train() client id: f_00001-5-1 loss: 0.472711  [   64/  265]
train() client id: f_00001-5-2 loss: 0.430286  [   96/  265]
train() client id: f_00001-5-3 loss: 0.324350  [  128/  265]
train() client id: f_00001-5-4 loss: 0.424965  [  160/  265]
train() client id: f_00001-5-5 loss: 0.438401  [  192/  265]
train() client id: f_00001-5-6 loss: 0.395035  [  224/  265]
train() client id: f_00001-5-7 loss: 0.460426  [  256/  265]
train() client id: f_00001-6-0 loss: 0.386570  [   32/  265]
train() client id: f_00001-6-1 loss: 0.421968  [   64/  265]
train() client id: f_00001-6-2 loss: 0.472849  [   96/  265]
train() client id: f_00001-6-3 loss: 0.482390  [  128/  265]
train() client id: f_00001-6-4 loss: 0.361137  [  160/  265]
train() client id: f_00001-6-5 loss: 0.450844  [  192/  265]
train() client id: f_00001-6-6 loss: 0.419908  [  224/  265]
train() client id: f_00001-6-7 loss: 0.315479  [  256/  265]
train() client id: f_00001-7-0 loss: 0.564586  [   32/  265]
train() client id: f_00001-7-1 loss: 0.347062  [   64/  265]
train() client id: f_00001-7-2 loss: 0.389222  [   96/  265]
train() client id: f_00001-7-3 loss: 0.426651  [  128/  265]
train() client id: f_00001-7-4 loss: 0.421195  [  160/  265]
train() client id: f_00001-7-5 loss: 0.345400  [  192/  265]
train() client id: f_00001-7-6 loss: 0.388990  [  224/  265]
train() client id: f_00001-7-7 loss: 0.395259  [  256/  265]
train() client id: f_00001-8-0 loss: 0.488541  [   32/  265]
train() client id: f_00001-8-1 loss: 0.438389  [   64/  265]
train() client id: f_00001-8-2 loss: 0.349778  [   96/  265]
train() client id: f_00001-8-3 loss: 0.434623  [  128/  265]
train() client id: f_00001-8-4 loss: 0.532399  [  160/  265]
train() client id: f_00001-8-5 loss: 0.330075  [  192/  265]
train() client id: f_00001-8-6 loss: 0.386889  [  224/  265]
train() client id: f_00001-8-7 loss: 0.301669  [  256/  265]
train() client id: f_00001-9-0 loss: 0.382103  [   32/  265]
train() client id: f_00001-9-1 loss: 0.472326  [   64/  265]
train() client id: f_00001-9-2 loss: 0.382747  [   96/  265]
train() client id: f_00001-9-3 loss: 0.316740  [  128/  265]
train() client id: f_00001-9-4 loss: 0.692628  [  160/  265]
train() client id: f_00001-9-5 loss: 0.383050  [  192/  265]
train() client id: f_00001-9-6 loss: 0.328494  [  224/  265]
train() client id: f_00001-9-7 loss: 0.294268  [  256/  265]
train() client id: f_00001-10-0 loss: 0.513141  [   32/  265]
train() client id: f_00001-10-1 loss: 0.299766  [   64/  265]
train() client id: f_00001-10-2 loss: 0.485584  [   96/  265]
train() client id: f_00001-10-3 loss: 0.382840  [  128/  265]
train() client id: f_00001-10-4 loss: 0.419204  [  160/  265]
train() client id: f_00001-10-5 loss: 0.365773  [  192/  265]
train() client id: f_00001-10-6 loss: 0.399446  [  224/  265]
train() client id: f_00001-10-7 loss: 0.376543  [  256/  265]
train() client id: f_00001-11-0 loss: 0.378906  [   32/  265]
train() client id: f_00001-11-1 loss: 0.480230  [   64/  265]
train() client id: f_00001-11-2 loss: 0.407998  [   96/  265]
train() client id: f_00001-11-3 loss: 0.536067  [  128/  265]
train() client id: f_00001-11-4 loss: 0.337606  [  160/  265]
train() client id: f_00001-11-5 loss: 0.370496  [  192/  265]
train() client id: f_00001-11-6 loss: 0.306786  [  224/  265]
train() client id: f_00001-11-7 loss: 0.419482  [  256/  265]
train() client id: f_00001-12-0 loss: 0.304534  [   32/  265]
train() client id: f_00001-12-1 loss: 0.479495  [   64/  265]
train() client id: f_00001-12-2 loss: 0.495878  [   96/  265]
train() client id: f_00001-12-3 loss: 0.375367  [  128/  265]
train() client id: f_00001-12-4 loss: 0.402864  [  160/  265]
train() client id: f_00001-12-5 loss: 0.390970  [  192/  265]
train() client id: f_00001-12-6 loss: 0.483030  [  224/  265]
train() client id: f_00001-12-7 loss: 0.305675  [  256/  265]
train() client id: f_00002-0-0 loss: 1.095821  [   32/  124]
train() client id: f_00002-0-1 loss: 1.213288  [   64/  124]
train() client id: f_00002-0-2 loss: 1.096681  [   96/  124]
train() client id: f_00002-1-0 loss: 1.026176  [   32/  124]
train() client id: f_00002-1-1 loss: 1.094825  [   64/  124]
train() client id: f_00002-1-2 loss: 1.071133  [   96/  124]
train() client id: f_00002-2-0 loss: 1.122531  [   32/  124]
train() client id: f_00002-2-1 loss: 0.984799  [   64/  124]
train() client id: f_00002-2-2 loss: 1.026167  [   96/  124]
train() client id: f_00002-3-0 loss: 1.096626  [   32/  124]
train() client id: f_00002-3-1 loss: 1.017282  [   64/  124]
train() client id: f_00002-3-2 loss: 1.105088  [   96/  124]
train() client id: f_00002-4-0 loss: 1.085352  [   32/  124]
train() client id: f_00002-4-1 loss: 0.940422  [   64/  124]
train() client id: f_00002-4-2 loss: 1.083591  [   96/  124]
train() client id: f_00002-5-0 loss: 0.943881  [   32/  124]
train() client id: f_00002-5-1 loss: 0.819872  [   64/  124]
train() client id: f_00002-5-2 loss: 1.119325  [   96/  124]
train() client id: f_00002-6-0 loss: 0.880440  [   32/  124]
train() client id: f_00002-6-1 loss: 0.988138  [   64/  124]
train() client id: f_00002-6-2 loss: 1.026240  [   96/  124]
train() client id: f_00002-7-0 loss: 0.826406  [   32/  124]
train() client id: f_00002-7-1 loss: 0.855697  [   64/  124]
train() client id: f_00002-7-2 loss: 1.075459  [   96/  124]
train() client id: f_00002-8-0 loss: 0.807653  [   32/  124]
train() client id: f_00002-8-1 loss: 0.928162  [   64/  124]
train() client id: f_00002-8-2 loss: 1.041938  [   96/  124]
train() client id: f_00002-9-0 loss: 0.993361  [   32/  124]
train() client id: f_00002-9-1 loss: 0.923923  [   64/  124]
train() client id: f_00002-9-2 loss: 0.690955  [   96/  124]
train() client id: f_00002-10-0 loss: 1.098595  [   32/  124]
train() client id: f_00002-10-1 loss: 0.727090  [   64/  124]
train() client id: f_00002-10-2 loss: 0.848370  [   96/  124]
train() client id: f_00002-11-0 loss: 1.060001  [   32/  124]
train() client id: f_00002-11-1 loss: 0.757260  [   64/  124]
train() client id: f_00002-11-2 loss: 1.077349  [   96/  124]
train() client id: f_00002-12-0 loss: 0.971297  [   32/  124]
train() client id: f_00002-12-1 loss: 0.872994  [   64/  124]
train() client id: f_00002-12-2 loss: 0.933031  [   96/  124]
train() client id: f_00003-0-0 loss: 0.816740  [   32/   43]
train() client id: f_00003-1-0 loss: 0.712435  [   32/   43]
train() client id: f_00003-2-0 loss: 0.825372  [   32/   43]
train() client id: f_00003-3-0 loss: 0.653659  [   32/   43]
train() client id: f_00003-4-0 loss: 0.610558  [   32/   43]
train() client id: f_00003-5-0 loss: 0.769556  [   32/   43]
train() client id: f_00003-6-0 loss: 0.657505  [   32/   43]
train() client id: f_00003-7-0 loss: 0.735249  [   32/   43]
train() client id: f_00003-8-0 loss: 0.816028  [   32/   43]
train() client id: f_00003-9-0 loss: 0.727392  [   32/   43]
train() client id: f_00003-10-0 loss: 0.766471  [   32/   43]
train() client id: f_00003-11-0 loss: 0.754988  [   32/   43]
train() client id: f_00003-12-0 loss: 0.865545  [   32/   43]
train() client id: f_00004-0-0 loss: 0.660610  [   32/  306]
train() client id: f_00004-0-1 loss: 0.885088  [   64/  306]
train() client id: f_00004-0-2 loss: 0.820283  [   96/  306]
train() client id: f_00004-0-3 loss: 0.848225  [  128/  306]
train() client id: f_00004-0-4 loss: 0.872604  [  160/  306]
train() client id: f_00004-0-5 loss: 0.809146  [  192/  306]
train() client id: f_00004-0-6 loss: 0.721964  [  224/  306]
train() client id: f_00004-0-7 loss: 0.776690  [  256/  306]
train() client id: f_00004-0-8 loss: 0.833442  [  288/  306]
train() client id: f_00004-1-0 loss: 0.807172  [   32/  306]
train() client id: f_00004-1-1 loss: 0.889882  [   64/  306]
train() client id: f_00004-1-2 loss: 0.707074  [   96/  306]
train() client id: f_00004-1-3 loss: 0.708032  [  128/  306]
train() client id: f_00004-1-4 loss: 0.885046  [  160/  306]
train() client id: f_00004-1-5 loss: 0.798133  [  192/  306]
train() client id: f_00004-1-6 loss: 0.783508  [  224/  306]
train() client id: f_00004-1-7 loss: 0.798696  [  256/  306]
train() client id: f_00004-1-8 loss: 0.694890  [  288/  306]
train() client id: f_00004-2-0 loss: 0.878687  [   32/  306]
train() client id: f_00004-2-1 loss: 0.857026  [   64/  306]
train() client id: f_00004-2-2 loss: 0.607754  [   96/  306]
train() client id: f_00004-2-3 loss: 0.939515  [  128/  306]
train() client id: f_00004-2-4 loss: 0.769029  [  160/  306]
train() client id: f_00004-2-5 loss: 0.822078  [  192/  306]
train() client id: f_00004-2-6 loss: 0.828003  [  224/  306]
train() client id: f_00004-2-7 loss: 0.561106  [  256/  306]
train() client id: f_00004-2-8 loss: 0.967764  [  288/  306]
train() client id: f_00004-3-0 loss: 0.854101  [   32/  306]
train() client id: f_00004-3-1 loss: 0.808070  [   64/  306]
train() client id: f_00004-3-2 loss: 0.846056  [   96/  306]
train() client id: f_00004-3-3 loss: 0.789522  [  128/  306]
train() client id: f_00004-3-4 loss: 0.880997  [  160/  306]
train() client id: f_00004-3-5 loss: 0.679659  [  192/  306]
train() client id: f_00004-3-6 loss: 0.800677  [  224/  306]
train() client id: f_00004-3-7 loss: 0.704560  [  256/  306]
train() client id: f_00004-3-8 loss: 0.763971  [  288/  306]
train() client id: f_00004-4-0 loss: 0.886795  [   32/  306]
train() client id: f_00004-4-1 loss: 0.804400  [   64/  306]
train() client id: f_00004-4-2 loss: 0.791114  [   96/  306]
train() client id: f_00004-4-3 loss: 0.768157  [  128/  306]
train() client id: f_00004-4-4 loss: 0.756631  [  160/  306]
train() client id: f_00004-4-5 loss: 0.748778  [  192/  306]
train() client id: f_00004-4-6 loss: 0.712075  [  224/  306]
train() client id: f_00004-4-7 loss: 0.917906  [  256/  306]
train() client id: f_00004-4-8 loss: 0.787646  [  288/  306]
train() client id: f_00004-5-0 loss: 0.700555  [   32/  306]
train() client id: f_00004-5-1 loss: 0.789619  [   64/  306]
train() client id: f_00004-5-2 loss: 0.835488  [   96/  306]
train() client id: f_00004-5-3 loss: 0.779797  [  128/  306]
train() client id: f_00004-5-4 loss: 0.748479  [  160/  306]
train() client id: f_00004-5-5 loss: 0.907096  [  192/  306]
train() client id: f_00004-5-6 loss: 0.749299  [  224/  306]
train() client id: f_00004-5-7 loss: 0.844700  [  256/  306]
train() client id: f_00004-5-8 loss: 0.795568  [  288/  306]
train() client id: f_00004-6-0 loss: 0.673608  [   32/  306]
train() client id: f_00004-6-1 loss: 0.780896  [   64/  306]
train() client id: f_00004-6-2 loss: 0.800648  [   96/  306]
train() client id: f_00004-6-3 loss: 0.951520  [  128/  306]
train() client id: f_00004-6-4 loss: 0.722192  [  160/  306]
train() client id: f_00004-6-5 loss: 0.735887  [  192/  306]
train() client id: f_00004-6-6 loss: 0.828965  [  224/  306]
train() client id: f_00004-6-7 loss: 0.772995  [  256/  306]
train() client id: f_00004-6-8 loss: 0.780364  [  288/  306]
train() client id: f_00004-7-0 loss: 0.915509  [   32/  306]
train() client id: f_00004-7-1 loss: 0.751630  [   64/  306]
train() client id: f_00004-7-2 loss: 0.855109  [   96/  306]
train() client id: f_00004-7-3 loss: 0.858077  [  128/  306]
train() client id: f_00004-7-4 loss: 0.794805  [  160/  306]
train() client id: f_00004-7-5 loss: 0.778654  [  192/  306]
train() client id: f_00004-7-6 loss: 0.802281  [  224/  306]
train() client id: f_00004-7-7 loss: 0.759981  [  256/  306]
train() client id: f_00004-7-8 loss: 0.736329  [  288/  306]
train() client id: f_00004-8-0 loss: 0.751450  [   32/  306]
train() client id: f_00004-8-1 loss: 0.711133  [   64/  306]
train() client id: f_00004-8-2 loss: 0.773270  [   96/  306]
train() client id: f_00004-8-3 loss: 0.791076  [  128/  306]
train() client id: f_00004-8-4 loss: 0.857533  [  160/  306]
train() client id: f_00004-8-5 loss: 0.905723  [  192/  306]
train() client id: f_00004-8-6 loss: 0.781794  [  224/  306]
train() client id: f_00004-8-7 loss: 0.809683  [  256/  306]
train() client id: f_00004-8-8 loss: 0.769161  [  288/  306]
train() client id: f_00004-9-0 loss: 0.836329  [   32/  306]
train() client id: f_00004-9-1 loss: 0.790008  [   64/  306]
train() client id: f_00004-9-2 loss: 0.776147  [   96/  306]
train() client id: f_00004-9-3 loss: 0.926874  [  128/  306]
train() client id: f_00004-9-4 loss: 0.754793  [  160/  306]
train() client id: f_00004-9-5 loss: 0.817156  [  192/  306]
train() client id: f_00004-9-6 loss: 0.808679  [  224/  306]
train() client id: f_00004-9-7 loss: 0.723410  [  256/  306]
train() client id: f_00004-9-8 loss: 0.818770  [  288/  306]
train() client id: f_00004-10-0 loss: 0.854146  [   32/  306]
train() client id: f_00004-10-1 loss: 0.787215  [   64/  306]
train() client id: f_00004-10-2 loss: 0.854519  [   96/  306]
train() client id: f_00004-10-3 loss: 0.737236  [  128/  306]
train() client id: f_00004-10-4 loss: 0.879795  [  160/  306]
train() client id: f_00004-10-5 loss: 0.819591  [  192/  306]
train() client id: f_00004-10-6 loss: 0.769770  [  224/  306]
train() client id: f_00004-10-7 loss: 0.688934  [  256/  306]
train() client id: f_00004-10-8 loss: 0.830183  [  288/  306]
train() client id: f_00004-11-0 loss: 0.775511  [   32/  306]
train() client id: f_00004-11-1 loss: 0.822770  [   64/  306]
train() client id: f_00004-11-2 loss: 0.777007  [   96/  306]
train() client id: f_00004-11-3 loss: 0.817647  [  128/  306]
train() client id: f_00004-11-4 loss: 0.742664  [  160/  306]
train() client id: f_00004-11-5 loss: 0.771537  [  192/  306]
train() client id: f_00004-11-6 loss: 0.803979  [  224/  306]
train() client id: f_00004-11-7 loss: 0.818441  [  256/  306]
train() client id: f_00004-11-8 loss: 0.801305  [  288/  306]
train() client id: f_00004-12-0 loss: 0.747328  [   32/  306]
train() client id: f_00004-12-1 loss: 0.782110  [   64/  306]
train() client id: f_00004-12-2 loss: 0.845602  [   96/  306]
train() client id: f_00004-12-3 loss: 0.772166  [  128/  306]
train() client id: f_00004-12-4 loss: 0.821414  [  160/  306]
train() client id: f_00004-12-5 loss: 0.774857  [  192/  306]
train() client id: f_00004-12-6 loss: 0.937866  [  224/  306]
train() client id: f_00004-12-7 loss: 0.735483  [  256/  306]
train() client id: f_00004-12-8 loss: 0.827678  [  288/  306]
train() client id: f_00005-0-0 loss: 0.661611  [   32/  146]
train() client id: f_00005-0-1 loss: 0.601392  [   64/  146]
train() client id: f_00005-0-2 loss: 0.601334  [   96/  146]
train() client id: f_00005-0-3 loss: 0.908523  [  128/  146]
train() client id: f_00005-1-0 loss: 0.542449  [   32/  146]
train() client id: f_00005-1-1 loss: 0.600825  [   64/  146]
train() client id: f_00005-1-2 loss: 0.906042  [   96/  146]
train() client id: f_00005-1-3 loss: 0.786085  [  128/  146]
train() client id: f_00005-2-0 loss: 0.580612  [   32/  146]
train() client id: f_00005-2-1 loss: 0.822428  [   64/  146]
train() client id: f_00005-2-2 loss: 0.534664  [   96/  146]
train() client id: f_00005-2-3 loss: 0.542517  [  128/  146]
train() client id: f_00005-3-0 loss: 0.553889  [   32/  146]
train() client id: f_00005-3-1 loss: 0.783571  [   64/  146]
train() client id: f_00005-3-2 loss: 0.502146  [   96/  146]
train() client id: f_00005-3-3 loss: 0.761127  [  128/  146]
train() client id: f_00005-4-0 loss: 0.562371  [   32/  146]
train() client id: f_00005-4-1 loss: 0.618497  [   64/  146]
train() client id: f_00005-4-2 loss: 0.551718  [   96/  146]
train() client id: f_00005-4-3 loss: 0.897071  [  128/  146]
train() client id: f_00005-5-0 loss: 0.586852  [   32/  146]
train() client id: f_00005-5-1 loss: 0.398236  [   64/  146]
train() client id: f_00005-5-2 loss: 0.944107  [   96/  146]
train() client id: f_00005-5-3 loss: 0.549941  [  128/  146]
train() client id: f_00005-6-0 loss: 0.755639  [   32/  146]
train() client id: f_00005-6-1 loss: 0.478345  [   64/  146]
train() client id: f_00005-6-2 loss: 0.757967  [   96/  146]
train() client id: f_00005-6-3 loss: 0.730684  [  128/  146]
train() client id: f_00005-7-0 loss: 0.485223  [   32/  146]
train() client id: f_00005-7-1 loss: 0.711341  [   64/  146]
train() client id: f_00005-7-2 loss: 0.682405  [   96/  146]
train() client id: f_00005-7-3 loss: 0.548270  [  128/  146]
train() client id: f_00005-8-0 loss: 0.543390  [   32/  146]
train() client id: f_00005-8-1 loss: 0.613448  [   64/  146]
train() client id: f_00005-8-2 loss: 0.785105  [   96/  146]
train() client id: f_00005-8-3 loss: 0.784209  [  128/  146]
train() client id: f_00005-9-0 loss: 0.589143  [   32/  146]
train() client id: f_00005-9-1 loss: 0.582183  [   64/  146]
train() client id: f_00005-9-2 loss: 0.571159  [   96/  146]
train() client id: f_00005-9-3 loss: 0.884083  [  128/  146]
train() client id: f_00005-10-0 loss: 0.694292  [   32/  146]
train() client id: f_00005-10-1 loss: 0.943868  [   64/  146]
train() client id: f_00005-10-2 loss: 0.415766  [   96/  146]
train() client id: f_00005-10-3 loss: 0.676899  [  128/  146]
train() client id: f_00005-11-0 loss: 0.909661  [   32/  146]
train() client id: f_00005-11-1 loss: 0.562284  [   64/  146]
train() client id: f_00005-11-2 loss: 0.557196  [   96/  146]
train() client id: f_00005-11-3 loss: 0.601068  [  128/  146]
train() client id: f_00005-12-0 loss: 0.380281  [   32/  146]
train() client id: f_00005-12-1 loss: 0.501213  [   64/  146]
train() client id: f_00005-12-2 loss: 0.821103  [   96/  146]
train() client id: f_00005-12-3 loss: 0.901644  [  128/  146]
train() client id: f_00006-0-0 loss: 0.544897  [   32/   54]
train() client id: f_00006-1-0 loss: 0.531818  [   32/   54]
train() client id: f_00006-2-0 loss: 0.486145  [   32/   54]
train() client id: f_00006-3-0 loss: 0.540451  [   32/   54]
train() client id: f_00006-4-0 loss: 0.440908  [   32/   54]
train() client id: f_00006-5-0 loss: 0.419955  [   32/   54]
train() client id: f_00006-6-0 loss: 0.464274  [   32/   54]
train() client id: f_00006-7-0 loss: 0.521984  [   32/   54]
train() client id: f_00006-8-0 loss: 0.468594  [   32/   54]
train() client id: f_00006-9-0 loss: 0.441790  [   32/   54]
train() client id: f_00006-10-0 loss: 0.533946  [   32/   54]
train() client id: f_00006-11-0 loss: 0.427688  [   32/   54]
train() client id: f_00006-12-0 loss: 0.474447  [   32/   54]
train() client id: f_00007-0-0 loss: 0.453607  [   32/  179]
train() client id: f_00007-0-1 loss: 0.339680  [   64/  179]
train() client id: f_00007-0-2 loss: 0.489326  [   96/  179]
train() client id: f_00007-0-3 loss: 0.377175  [  128/  179]
train() client id: f_00007-0-4 loss: 0.636291  [  160/  179]
train() client id: f_00007-1-0 loss: 0.525519  [   32/  179]
train() client id: f_00007-1-1 loss: 0.671593  [   64/  179]
train() client id: f_00007-1-2 loss: 0.327684  [   96/  179]
train() client id: f_00007-1-3 loss: 0.491361  [  128/  179]
train() client id: f_00007-1-4 loss: 0.301439  [  160/  179]
train() client id: f_00007-2-0 loss: 0.349006  [   32/  179]
train() client id: f_00007-2-1 loss: 0.414024  [   64/  179]
train() client id: f_00007-2-2 loss: 0.610015  [   96/  179]
train() client id: f_00007-2-3 loss: 0.310366  [  128/  179]
train() client id: f_00007-2-4 loss: 0.311360  [  160/  179]
train() client id: f_00007-3-0 loss: 0.367697  [   32/  179]
train() client id: f_00007-3-1 loss: 0.300234  [   64/  179]
train() client id: f_00007-3-2 loss: 0.231712  [   96/  179]
train() client id: f_00007-3-3 loss: 0.601754  [  128/  179]
train() client id: f_00007-3-4 loss: 0.664195  [  160/  179]
train() client id: f_00007-4-0 loss: 0.631054  [   32/  179]
train() client id: f_00007-4-1 loss: 0.366699  [   64/  179]
train() client id: f_00007-4-2 loss: 0.422750  [   96/  179]
train() client id: f_00007-4-3 loss: 0.458200  [  128/  179]
train() client id: f_00007-4-4 loss: 0.236813  [  160/  179]
train() client id: f_00007-5-0 loss: 0.327522  [   32/  179]
train() client id: f_00007-5-1 loss: 0.322123  [   64/  179]
train() client id: f_00007-5-2 loss: 0.654654  [   96/  179]
train() client id: f_00007-5-3 loss: 0.295824  [  128/  179]
train() client id: f_00007-5-4 loss: 0.218529  [  160/  179]
train() client id: f_00007-6-0 loss: 0.434001  [   32/  179]
train() client id: f_00007-6-1 loss: 0.506145  [   64/  179]
train() client id: f_00007-6-2 loss: 0.341641  [   96/  179]
train() client id: f_00007-6-3 loss: 0.293200  [  128/  179]
train() client id: f_00007-6-4 loss: 0.246261  [  160/  179]
train() client id: f_00007-7-0 loss: 0.292912  [   32/  179]
train() client id: f_00007-7-1 loss: 0.541368  [   64/  179]
train() client id: f_00007-7-2 loss: 0.219237  [   96/  179]
train() client id: f_00007-7-3 loss: 0.370593  [  128/  179]
train() client id: f_00007-7-4 loss: 0.508369  [  160/  179]
train() client id: f_00007-8-0 loss: 0.197147  [   32/  179]
train() client id: f_00007-8-1 loss: 0.371154  [   64/  179]
train() client id: f_00007-8-2 loss: 0.390011  [   96/  179]
train() client id: f_00007-8-3 loss: 0.552154  [  128/  179]
train() client id: f_00007-8-4 loss: 0.391754  [  160/  179]
train() client id: f_00007-9-0 loss: 0.532217  [   32/  179]
train() client id: f_00007-9-1 loss: 0.237012  [   64/  179]
train() client id: f_00007-9-2 loss: 0.301600  [   96/  179]
train() client id: f_00007-9-3 loss: 0.531859  [  128/  179]
train() client id: f_00007-9-4 loss: 0.296504  [  160/  179]
train() client id: f_00007-10-0 loss: 0.340332  [   32/  179]
train() client id: f_00007-10-1 loss: 0.505033  [   64/  179]
train() client id: f_00007-10-2 loss: 0.318567  [   96/  179]
train() client id: f_00007-10-3 loss: 0.479121  [  128/  179]
train() client id: f_00007-10-4 loss: 0.324478  [  160/  179]
train() client id: f_00007-11-0 loss: 0.350562  [   32/  179]
train() client id: f_00007-11-1 loss: 0.537347  [   64/  179]
train() client id: f_00007-11-2 loss: 0.424598  [   96/  179]
train() client id: f_00007-11-3 loss: 0.217155  [  128/  179]
train() client id: f_00007-11-4 loss: 0.430322  [  160/  179]
train() client id: f_00007-12-0 loss: 0.454041  [   32/  179]
train() client id: f_00007-12-1 loss: 0.302132  [   64/  179]
train() client id: f_00007-12-2 loss: 0.557333  [   96/  179]
train() client id: f_00007-12-3 loss: 0.263951  [  128/  179]
train() client id: f_00007-12-4 loss: 0.378037  [  160/  179]
train() client id: f_00008-0-0 loss: 0.655001  [   32/  130]
train() client id: f_00008-0-1 loss: 0.659862  [   64/  130]
train() client id: f_00008-0-2 loss: 0.684341  [   96/  130]
train() client id: f_00008-0-3 loss: 0.644090  [  128/  130]
train() client id: f_00008-1-0 loss: 0.686871  [   32/  130]
train() client id: f_00008-1-1 loss: 0.636599  [   64/  130]
train() client id: f_00008-1-2 loss: 0.572524  [   96/  130]
train() client id: f_00008-1-3 loss: 0.741709  [  128/  130]
train() client id: f_00008-2-0 loss: 0.655717  [   32/  130]
train() client id: f_00008-2-1 loss: 0.810660  [   64/  130]
train() client id: f_00008-2-2 loss: 0.674170  [   96/  130]
train() client id: f_00008-2-3 loss: 0.503410  [  128/  130]
train() client id: f_00008-3-0 loss: 0.600768  [   32/  130]
train() client id: f_00008-3-1 loss: 0.779719  [   64/  130]
train() client id: f_00008-3-2 loss: 0.657995  [   96/  130]
train() client id: f_00008-3-3 loss: 0.593979  [  128/  130]
train() client id: f_00008-4-0 loss: 0.616951  [   32/  130]
train() client id: f_00008-4-1 loss: 0.737645  [   64/  130]
train() client id: f_00008-4-2 loss: 0.669324  [   96/  130]
train() client id: f_00008-4-3 loss: 0.618868  [  128/  130]
train() client id: f_00008-5-0 loss: 0.691461  [   32/  130]
train() client id: f_00008-5-1 loss: 0.733389  [   64/  130]
train() client id: f_00008-5-2 loss: 0.554551  [   96/  130]
train() client id: f_00008-5-3 loss: 0.615864  [  128/  130]
train() client id: f_00008-6-0 loss: 0.627822  [   32/  130]
train() client id: f_00008-6-1 loss: 0.660236  [   64/  130]
train() client id: f_00008-6-2 loss: 0.647279  [   96/  130]
train() client id: f_00008-6-3 loss: 0.628715  [  128/  130]
train() client id: f_00008-7-0 loss: 0.655929  [   32/  130]
train() client id: f_00008-7-1 loss: 0.761559  [   64/  130]
train() client id: f_00008-7-2 loss: 0.525123  [   96/  130]
train() client id: f_00008-7-3 loss: 0.694538  [  128/  130]
train() client id: f_00008-8-0 loss: 0.614462  [   32/  130]
train() client id: f_00008-8-1 loss: 0.692010  [   64/  130]
train() client id: f_00008-8-2 loss: 0.600418  [   96/  130]
train() client id: f_00008-8-3 loss: 0.686810  [  128/  130]
train() client id: f_00008-9-0 loss: 0.591305  [   32/  130]
train() client id: f_00008-9-1 loss: 0.755494  [   64/  130]
train() client id: f_00008-9-2 loss: 0.697485  [   96/  130]
train() client id: f_00008-9-3 loss: 0.587231  [  128/  130]
train() client id: f_00008-10-0 loss: 0.658837  [   32/  130]
train() client id: f_00008-10-1 loss: 0.698218  [   64/  130]
train() client id: f_00008-10-2 loss: 0.638317  [   96/  130]
train() client id: f_00008-10-3 loss: 0.641828  [  128/  130]
train() client id: f_00008-11-0 loss: 0.646119  [   32/  130]
train() client id: f_00008-11-1 loss: 0.670774  [   64/  130]
train() client id: f_00008-11-2 loss: 0.677642  [   96/  130]
train() client id: f_00008-11-3 loss: 0.610890  [  128/  130]
train() client id: f_00008-12-0 loss: 0.615143  [   32/  130]
train() client id: f_00008-12-1 loss: 0.595348  [   64/  130]
train() client id: f_00008-12-2 loss: 0.686856  [   96/  130]
train() client id: f_00008-12-3 loss: 0.730517  [  128/  130]
train() client id: f_00009-0-0 loss: 0.924638  [   32/  118]
train() client id: f_00009-0-1 loss: 0.784212  [   64/  118]
train() client id: f_00009-0-2 loss: 0.827096  [   96/  118]
train() client id: f_00009-1-0 loss: 0.827132  [   32/  118]
train() client id: f_00009-1-1 loss: 0.966180  [   64/  118]
train() client id: f_00009-1-2 loss: 0.804845  [   96/  118]
train() client id: f_00009-2-0 loss: 0.828902  [   32/  118]
train() client id: f_00009-2-1 loss: 0.928422  [   64/  118]
train() client id: f_00009-2-2 loss: 0.653834  [   96/  118]
train() client id: f_00009-3-0 loss: 0.772392  [   32/  118]
train() client id: f_00009-3-1 loss: 0.947335  [   64/  118]
train() client id: f_00009-3-2 loss: 0.731379  [   96/  118]
train() client id: f_00009-4-0 loss: 0.862555  [   32/  118]
train() client id: f_00009-4-1 loss: 0.698020  [   64/  118]
train() client id: f_00009-4-2 loss: 0.674284  [   96/  118]
train() client id: f_00009-5-0 loss: 0.917325  [   32/  118]
train() client id: f_00009-5-1 loss: 0.583074  [   64/  118]
train() client id: f_00009-5-2 loss: 0.586643  [   96/  118]
train() client id: f_00009-6-0 loss: 0.795860  [   32/  118]
train() client id: f_00009-6-1 loss: 0.707177  [   64/  118]
train() client id: f_00009-6-2 loss: 0.732209  [   96/  118]
train() client id: f_00009-7-0 loss: 0.784251  [   32/  118]
train() client id: f_00009-7-1 loss: 0.618285  [   64/  118]
train() client id: f_00009-7-2 loss: 0.707592  [   96/  118]
train() client id: f_00009-8-0 loss: 0.776928  [   32/  118]
train() client id: f_00009-8-1 loss: 0.681733  [   64/  118]
train() client id: f_00009-8-2 loss: 0.640705  [   96/  118]
train() client id: f_00009-9-0 loss: 0.701503  [   32/  118]
train() client id: f_00009-9-1 loss: 0.624849  [   64/  118]
train() client id: f_00009-9-2 loss: 0.739959  [   96/  118]
train() client id: f_00009-10-0 loss: 0.882868  [   32/  118]
train() client id: f_00009-10-1 loss: 0.476286  [   64/  118]
train() client id: f_00009-10-2 loss: 0.683401  [   96/  118]
train() client id: f_00009-11-0 loss: 0.796524  [   32/  118]
train() client id: f_00009-11-1 loss: 0.584247  [   64/  118]
train() client id: f_00009-11-2 loss: 0.692850  [   96/  118]
train() client id: f_00009-12-0 loss: 0.649261  [   32/  118]
train() client id: f_00009-12-1 loss: 0.651940  [   64/  118]
train() client id: f_00009-12-2 loss: 0.760106  [   96/  118]
At round 53 accuracy: 0.6392572944297082
At round 53 training accuracy: 0.5975855130784709
At round 53 training loss: 0.8151480456769613
gradient difference: 0.4593058228492737
train() client id: f_00000-0-0 loss: 1.575974  [   32/  126]
train() client id: f_00000-0-1 loss: 1.123684  [   64/  126]
train() client id: f_00000-0-2 loss: 0.932856  [   96/  126]
train() client id: f_00000-1-0 loss: 1.159464  [   32/  126]
train() client id: f_00000-1-1 loss: 1.074766  [   64/  126]
train() client id: f_00000-1-2 loss: 1.066169  [   96/  126]
train() client id: f_00000-2-0 loss: 1.145849  [   32/  126]
train() client id: f_00000-2-1 loss: 0.859872  [   64/  126]
train() client id: f_00000-2-2 loss: 1.073853  [   96/  126]
train() client id: f_00000-3-0 loss: 1.078245  [   32/  126]
train() client id: f_00000-3-1 loss: 0.801272  [   64/  126]
train() client id: f_00000-3-2 loss: 0.880920  [   96/  126]
train() client id: f_00000-4-0 loss: 0.828910  [   32/  126]
train() client id: f_00000-4-1 loss: 0.897255  [   64/  126]
train() client id: f_00000-4-2 loss: 0.832801  [   96/  126]
train() client id: f_00000-5-0 loss: 0.864221  [   32/  126]
train() client id: f_00000-5-1 loss: 0.874394  [   64/  126]
train() client id: f_00000-5-2 loss: 0.819879  [   96/  126]
train() client id: f_00000-6-0 loss: 0.726025  [   32/  126]
train() client id: f_00000-6-1 loss: 0.842884  [   64/  126]
train() client id: f_00000-6-2 loss: 0.752313  [   96/  126]
train() client id: f_00000-7-0 loss: 0.760184  [   32/  126]
train() client id: f_00000-7-1 loss: 0.771509  [   64/  126]
train() client id: f_00000-7-2 loss: 0.836073  [   96/  126]
train() client id: f_00000-8-0 loss: 0.720088  [   32/  126]
train() client id: f_00000-8-1 loss: 0.753198  [   64/  126]
train() client id: f_00000-8-2 loss: 0.904906  [   96/  126]
train() client id: f_00000-9-0 loss: 0.850722  [   32/  126]
train() client id: f_00000-9-1 loss: 0.632073  [   64/  126]
train() client id: f_00000-9-2 loss: 0.750014  [   96/  126]
train() client id: f_00000-10-0 loss: 0.780762  [   32/  126]
train() client id: f_00000-10-1 loss: 0.743926  [   64/  126]
train() client id: f_00000-10-2 loss: 0.688694  [   96/  126]
train() client id: f_00000-11-0 loss: 0.854783  [   32/  126]
train() client id: f_00000-11-1 loss: 0.708265  [   64/  126]
train() client id: f_00000-11-2 loss: 0.785714  [   96/  126]
train() client id: f_00000-12-0 loss: 0.729063  [   32/  126]
train() client id: f_00000-12-1 loss: 0.615739  [   64/  126]
train() client id: f_00000-12-2 loss: 0.914036  [   96/  126]
train() client id: f_00001-0-0 loss: 0.594616  [   32/  265]
train() client id: f_00001-0-1 loss: 0.428710  [   64/  265]
train() client id: f_00001-0-2 loss: 0.517516  [   96/  265]
train() client id: f_00001-0-3 loss: 0.474747  [  128/  265]
train() client id: f_00001-0-4 loss: 0.502047  [  160/  265]
train() client id: f_00001-0-5 loss: 0.420400  [  192/  265]
train() client id: f_00001-0-6 loss: 0.649633  [  224/  265]
train() client id: f_00001-0-7 loss: 0.400023  [  256/  265]
train() client id: f_00001-1-0 loss: 0.571356  [   32/  265]
train() client id: f_00001-1-1 loss: 0.452129  [   64/  265]
train() client id: f_00001-1-2 loss: 0.464268  [   96/  265]
train() client id: f_00001-1-3 loss: 0.476251  [  128/  265]
train() client id: f_00001-1-4 loss: 0.411838  [  160/  265]
train() client id: f_00001-1-5 loss: 0.422540  [  192/  265]
train() client id: f_00001-1-6 loss: 0.594757  [  224/  265]
train() client id: f_00001-1-7 loss: 0.483180  [  256/  265]
train() client id: f_00001-2-0 loss: 0.482765  [   32/  265]
train() client id: f_00001-2-1 loss: 0.430917  [   64/  265]
train() client id: f_00001-2-2 loss: 0.617377  [   96/  265]
train() client id: f_00001-2-3 loss: 0.398250  [  128/  265]
train() client id: f_00001-2-4 loss: 0.483867  [  160/  265]
train() client id: f_00001-2-5 loss: 0.492804  [  192/  265]
train() client id: f_00001-2-6 loss: 0.482668  [  224/  265]
train() client id: f_00001-2-7 loss: 0.475745  [  256/  265]
train() client id: f_00001-3-0 loss: 0.422131  [   32/  265]
train() client id: f_00001-3-1 loss: 0.541513  [   64/  265]
train() client id: f_00001-3-2 loss: 0.446349  [   96/  265]
train() client id: f_00001-3-3 loss: 0.411414  [  128/  265]
train() client id: f_00001-3-4 loss: 0.536204  [  160/  265]
train() client id: f_00001-3-5 loss: 0.478913  [  192/  265]
train() client id: f_00001-3-6 loss: 0.391463  [  224/  265]
train() client id: f_00001-3-7 loss: 0.571240  [  256/  265]
train() client id: f_00001-4-0 loss: 0.500970  [   32/  265]
train() client id: f_00001-4-1 loss: 0.556418  [   64/  265]
train() client id: f_00001-4-2 loss: 0.404806  [   96/  265]
train() client id: f_00001-4-3 loss: 0.389630  [  128/  265]
train() client id: f_00001-4-4 loss: 0.541746  [  160/  265]
train() client id: f_00001-4-5 loss: 0.466364  [  192/  265]
train() client id: f_00001-4-6 loss: 0.417223  [  224/  265]
train() client id: f_00001-4-7 loss: 0.475955  [  256/  265]
train() client id: f_00001-5-0 loss: 0.422131  [   32/  265]
train() client id: f_00001-5-1 loss: 0.410186  [   64/  265]
train() client id: f_00001-5-2 loss: 0.500936  [   96/  265]
train() client id: f_00001-5-3 loss: 0.517228  [  128/  265]
train() client id: f_00001-5-4 loss: 0.472120  [  160/  265]
train() client id: f_00001-5-5 loss: 0.423250  [  192/  265]
train() client id: f_00001-5-6 loss: 0.555721  [  224/  265]
train() client id: f_00001-5-7 loss: 0.451039  [  256/  265]
train() client id: f_00001-6-0 loss: 0.637717  [   32/  265]
train() client id: f_00001-6-1 loss: 0.469013  [   64/  265]
train() client id: f_00001-6-2 loss: 0.367994  [   96/  265]
train() client id: f_00001-6-3 loss: 0.524556  [  128/  265]
train() client id: f_00001-6-4 loss: 0.480855  [  160/  265]
train() client id: f_00001-6-5 loss: 0.439848  [  192/  265]
train() client id: f_00001-6-6 loss: 0.369263  [  224/  265]
train() client id: f_00001-6-7 loss: 0.532302  [  256/  265]
train() client id: f_00001-7-0 loss: 0.374673  [   32/  265]
train() client id: f_00001-7-1 loss: 0.454652  [   64/  265]
train() client id: f_00001-7-2 loss: 0.476297  [   96/  265]
train() client id: f_00001-7-3 loss: 0.548060  [  128/  265]
train() client id: f_00001-7-4 loss: 0.549484  [  160/  265]
train() client id: f_00001-7-5 loss: 0.460215  [  192/  265]
train() client id: f_00001-7-6 loss: 0.411922  [  224/  265]
train() client id: f_00001-7-7 loss: 0.393966  [  256/  265]
train() client id: f_00001-8-0 loss: 0.498231  [   32/  265]
train() client id: f_00001-8-1 loss: 0.419564  [   64/  265]
train() client id: f_00001-8-2 loss: 0.639473  [   96/  265]
train() client id: f_00001-8-3 loss: 0.450480  [  128/  265]
train() client id: f_00001-8-4 loss: 0.502247  [  160/  265]
train() client id: f_00001-8-5 loss: 0.498675  [  192/  265]
train() client id: f_00001-8-6 loss: 0.389189  [  224/  265]
train() client id: f_00001-8-7 loss: 0.421892  [  256/  265]
train() client id: f_00001-9-0 loss: 0.398272  [   32/  265]
train() client id: f_00001-9-1 loss: 0.481771  [   64/  265]
train() client id: f_00001-9-2 loss: 0.408042  [   96/  265]
train() client id: f_00001-9-3 loss: 0.418640  [  128/  265]
train() client id: f_00001-9-4 loss: 0.547558  [  160/  265]
train() client id: f_00001-9-5 loss: 0.597889  [  192/  265]
train() client id: f_00001-9-6 loss: 0.412072  [  224/  265]
train() client id: f_00001-9-7 loss: 0.506716  [  256/  265]
train() client id: f_00001-10-0 loss: 0.392255  [   32/  265]
train() client id: f_00001-10-1 loss: 0.564022  [   64/  265]
train() client id: f_00001-10-2 loss: 0.521681  [   96/  265]
train() client id: f_00001-10-3 loss: 0.531736  [  128/  265]
train() client id: f_00001-10-4 loss: 0.355543  [  160/  265]
train() client id: f_00001-10-5 loss: 0.454838  [  192/  265]
train() client id: f_00001-10-6 loss: 0.642624  [  224/  265]
train() client id: f_00001-10-7 loss: 0.363075  [  256/  265]
train() client id: f_00001-11-0 loss: 0.596062  [   32/  265]
train() client id: f_00001-11-1 loss: 0.429983  [   64/  265]
train() client id: f_00001-11-2 loss: 0.444154  [   96/  265]
train() client id: f_00001-11-3 loss: 0.555399  [  128/  265]
train() client id: f_00001-11-4 loss: 0.405977  [  160/  265]
train() client id: f_00001-11-5 loss: 0.472602  [  192/  265]
train() client id: f_00001-11-6 loss: 0.496514  [  224/  265]
train() client id: f_00001-11-7 loss: 0.431712  [  256/  265]
train() client id: f_00001-12-0 loss: 0.523702  [   32/  265]
train() client id: f_00001-12-1 loss: 0.389753  [   64/  265]
train() client id: f_00001-12-2 loss: 0.503634  [   96/  265]
train() client id: f_00001-12-3 loss: 0.464740  [  128/  265]
train() client id: f_00001-12-4 loss: 0.607673  [  160/  265]
train() client id: f_00001-12-5 loss: 0.483499  [  192/  265]
train() client id: f_00001-12-6 loss: 0.412477  [  224/  265]
train() client id: f_00001-12-7 loss: 0.451421  [  256/  265]
train() client id: f_00002-0-0 loss: 1.251923  [   32/  124]
train() client id: f_00002-0-1 loss: 1.081917  [   64/  124]
train() client id: f_00002-0-2 loss: 1.025258  [   96/  124]
train() client id: f_00002-1-0 loss: 1.007421  [   32/  124]
train() client id: f_00002-1-1 loss: 0.936605  [   64/  124]
train() client id: f_00002-1-2 loss: 1.106812  [   96/  124]
train() client id: f_00002-2-0 loss: 1.086767  [   32/  124]
train() client id: f_00002-2-1 loss: 1.002688  [   64/  124]
train() client id: f_00002-2-2 loss: 1.001016  [   96/  124]
train() client id: f_00002-3-0 loss: 0.904031  [   32/  124]
train() client id: f_00002-3-1 loss: 1.275043  [   64/  124]
train() client id: f_00002-3-2 loss: 0.930904  [   96/  124]
train() client id: f_00002-4-0 loss: 1.083350  [   32/  124]
train() client id: f_00002-4-1 loss: 0.808972  [   64/  124]
train() client id: f_00002-4-2 loss: 0.869348  [   96/  124]
train() client id: f_00002-5-0 loss: 0.892594  [   32/  124]
train() client id: f_00002-5-1 loss: 1.083246  [   64/  124]
train() client id: f_00002-5-2 loss: 0.987152  [   96/  124]
train() client id: f_00002-6-0 loss: 1.003906  [   32/  124]
train() client id: f_00002-6-1 loss: 0.944252  [   64/  124]
train() client id: f_00002-6-2 loss: 0.869291  [   96/  124]
train() client id: f_00002-7-0 loss: 0.973515  [   32/  124]
train() client id: f_00002-7-1 loss: 0.895667  [   64/  124]
train() client id: f_00002-7-2 loss: 0.858512  [   96/  124]
train() client id: f_00002-8-0 loss: 1.071195  [   32/  124]
train() client id: f_00002-8-1 loss: 0.901821  [   64/  124]
train() client id: f_00002-8-2 loss: 0.853595  [   96/  124]
train() client id: f_00002-9-0 loss: 1.090706  [   32/  124]
train() client id: f_00002-9-1 loss: 0.904200  [   64/  124]
train() client id: f_00002-9-2 loss: 0.962157  [   96/  124]
train() client id: f_00002-10-0 loss: 1.184623  [   32/  124]
train() client id: f_00002-10-1 loss: 0.826963  [   64/  124]
train() client id: f_00002-10-2 loss: 0.807948  [   96/  124]
train() client id: f_00002-11-0 loss: 0.759501  [   32/  124]
train() client id: f_00002-11-1 loss: 1.134209  [   64/  124]
train() client id: f_00002-11-2 loss: 1.027566  [   96/  124]
train() client id: f_00002-12-0 loss: 0.995668  [   32/  124]
train() client id: f_00002-12-1 loss: 1.012769  [   64/  124]
train() client id: f_00002-12-2 loss: 1.014393  [   96/  124]
train() client id: f_00003-0-0 loss: 0.500194  [   32/   43]
train() client id: f_00003-1-0 loss: 0.582722  [   32/   43]
train() client id: f_00003-2-0 loss: 0.549125  [   32/   43]
train() client id: f_00003-3-0 loss: 0.502970  [   32/   43]
train() client id: f_00003-4-0 loss: 0.524395  [   32/   43]
train() client id: f_00003-5-0 loss: 0.453458  [   32/   43]
train() client id: f_00003-6-0 loss: 0.685579  [   32/   43]
train() client id: f_00003-7-0 loss: 0.577014  [   32/   43]
train() client id: f_00003-8-0 loss: 0.726968  [   32/   43]
train() client id: f_00003-9-0 loss: 0.434110  [   32/   43]
train() client id: f_00003-10-0 loss: 0.490957  [   32/   43]
train() client id: f_00003-11-0 loss: 0.479267  [   32/   43]
train() client id: f_00003-12-0 loss: 0.574909  [   32/   43]
train() client id: f_00004-0-0 loss: 0.898701  [   32/  306]
train() client id: f_00004-0-1 loss: 0.841709  [   64/  306]
train() client id: f_00004-0-2 loss: 0.626721  [   96/  306]
train() client id: f_00004-0-3 loss: 0.961797  [  128/  306]
train() client id: f_00004-0-4 loss: 0.823241  [  160/  306]
train() client id: f_00004-0-5 loss: 0.868011  [  192/  306]
train() client id: f_00004-0-6 loss: 0.680481  [  224/  306]
train() client id: f_00004-0-7 loss: 0.734309  [  256/  306]
train() client id: f_00004-0-8 loss: 0.911546  [  288/  306]
train() client id: f_00004-1-0 loss: 0.788970  [   32/  306]
train() client id: f_00004-1-1 loss: 0.825167  [   64/  306]
train() client id: f_00004-1-2 loss: 0.690256  [   96/  306]
train() client id: f_00004-1-3 loss: 0.947190  [  128/  306]
train() client id: f_00004-1-4 loss: 0.697513  [  160/  306]
train() client id: f_00004-1-5 loss: 0.804626  [  192/  306]
train() client id: f_00004-1-6 loss: 0.942322  [  224/  306]
train() client id: f_00004-1-7 loss: 0.760476  [  256/  306]
train() client id: f_00004-1-8 loss: 0.857383  [  288/  306]
train() client id: f_00004-2-0 loss: 0.729738  [   32/  306]
train() client id: f_00004-2-1 loss: 0.768598  [   64/  306]
train() client id: f_00004-2-2 loss: 0.836905  [   96/  306]
train() client id: f_00004-2-3 loss: 0.692600  [  128/  306]
train() client id: f_00004-2-4 loss: 0.969965  [  160/  306]
train() client id: f_00004-2-5 loss: 0.704819  [  192/  306]
train() client id: f_00004-2-6 loss: 0.951055  [  224/  306]
train() client id: f_00004-2-7 loss: 0.875539  [  256/  306]
train() client id: f_00004-2-8 loss: 0.835252  [  288/  306]
train() client id: f_00004-3-0 loss: 0.885079  [   32/  306]
train() client id: f_00004-3-1 loss: 0.923367  [   64/  306]
train() client id: f_00004-3-2 loss: 0.745524  [   96/  306]
train() client id: f_00004-3-3 loss: 0.773975  [  128/  306]
train() client id: f_00004-3-4 loss: 0.818676  [  160/  306]
train() client id: f_00004-3-5 loss: 0.854620  [  192/  306]
train() client id: f_00004-3-6 loss: 0.874358  [  224/  306]
train() client id: f_00004-3-7 loss: 0.736380  [  256/  306]
train() client id: f_00004-3-8 loss: 0.858795  [  288/  306]
train() client id: f_00004-4-0 loss: 0.764609  [   32/  306]
train() client id: f_00004-4-1 loss: 0.808393  [   64/  306]
train() client id: f_00004-4-2 loss: 0.776867  [   96/  306]
train() client id: f_00004-4-3 loss: 0.880090  [  128/  306]
train() client id: f_00004-4-4 loss: 0.746762  [  160/  306]
train() client id: f_00004-4-5 loss: 1.058416  [  192/  306]
train() client id: f_00004-4-6 loss: 0.776917  [  224/  306]
train() client id: f_00004-4-7 loss: 0.736414  [  256/  306]
train() client id: f_00004-4-8 loss: 0.749500  [  288/  306]
train() client id: f_00004-5-0 loss: 0.792302  [   32/  306]
train() client id: f_00004-5-1 loss: 0.881449  [   64/  306]
train() client id: f_00004-5-2 loss: 0.900063  [   96/  306]
train() client id: f_00004-5-3 loss: 0.792935  [  128/  306]
train() client id: f_00004-5-4 loss: 0.715465  [  160/  306]
train() client id: f_00004-5-5 loss: 0.709935  [  192/  306]
train() client id: f_00004-5-6 loss: 0.777375  [  224/  306]
train() client id: f_00004-5-7 loss: 0.882549  [  256/  306]
train() client id: f_00004-5-8 loss: 0.869299  [  288/  306]
train() client id: f_00004-6-0 loss: 0.757788  [   32/  306]
train() client id: f_00004-6-1 loss: 0.729206  [   64/  306]
train() client id: f_00004-6-2 loss: 0.797467  [   96/  306]
train() client id: f_00004-6-3 loss: 0.703010  [  128/  306]
train() client id: f_00004-6-4 loss: 1.036676  [  160/  306]
train() client id: f_00004-6-5 loss: 0.956956  [  192/  306]
train() client id: f_00004-6-6 loss: 0.750049  [  224/  306]
train() client id: f_00004-6-7 loss: 0.887041  [  256/  306]
train() client id: f_00004-6-8 loss: 0.755453  [  288/  306]
train() client id: f_00004-7-0 loss: 0.870384  [   32/  306]
train() client id: f_00004-7-1 loss: 0.748022  [   64/  306]
train() client id: f_00004-7-2 loss: 0.741010  [   96/  306]
train() client id: f_00004-7-3 loss: 0.898573  [  128/  306]
train() client id: f_00004-7-4 loss: 0.665306  [  160/  306]
train() client id: f_00004-7-5 loss: 0.935991  [  192/  306]
train() client id: f_00004-7-6 loss: 0.849328  [  224/  306]
train() client id: f_00004-7-7 loss: 0.797213  [  256/  306]
train() client id: f_00004-7-8 loss: 0.846916  [  288/  306]
train() client id: f_00004-8-0 loss: 0.799968  [   32/  306]
train() client id: f_00004-8-1 loss: 0.813668  [   64/  306]
train() client id: f_00004-8-2 loss: 0.774497  [   96/  306]
train() client id: f_00004-8-3 loss: 0.895883  [  128/  306]
train() client id: f_00004-8-4 loss: 0.806915  [  160/  306]
train() client id: f_00004-8-5 loss: 0.793399  [  192/  306]
train() client id: f_00004-8-6 loss: 0.807217  [  224/  306]
train() client id: f_00004-8-7 loss: 0.879542  [  256/  306]
train() client id: f_00004-8-8 loss: 0.815140  [  288/  306]
train() client id: f_00004-9-0 loss: 0.862248  [   32/  306]
train() client id: f_00004-9-1 loss: 0.843307  [   64/  306]
train() client id: f_00004-9-2 loss: 0.776672  [   96/  306]
train() client id: f_00004-9-3 loss: 0.704425  [  128/  306]
train() client id: f_00004-9-4 loss: 0.882527  [  160/  306]
train() client id: f_00004-9-5 loss: 0.766041  [  192/  306]
train() client id: f_00004-9-6 loss: 0.826431  [  224/  306]
train() client id: f_00004-9-7 loss: 0.761480  [  256/  306]
train() client id: f_00004-9-8 loss: 0.876966  [  288/  306]
train() client id: f_00004-10-0 loss: 0.788510  [   32/  306]
train() client id: f_00004-10-1 loss: 0.792417  [   64/  306]
train() client id: f_00004-10-2 loss: 0.786650  [   96/  306]
train() client id: f_00004-10-3 loss: 0.848753  [  128/  306]
train() client id: f_00004-10-4 loss: 0.778728  [  160/  306]
train() client id: f_00004-10-5 loss: 0.955839  [  192/  306]
train() client id: f_00004-10-6 loss: 0.705478  [  224/  306]
train() client id: f_00004-10-7 loss: 0.818221  [  256/  306]
train() client id: f_00004-10-8 loss: 0.859175  [  288/  306]
train() client id: f_00004-11-0 loss: 0.864835  [   32/  306]
train() client id: f_00004-11-1 loss: 0.711991  [   64/  306]
train() client id: f_00004-11-2 loss: 0.896675  [   96/  306]
train() client id: f_00004-11-3 loss: 0.749746  [  128/  306]
train() client id: f_00004-11-4 loss: 0.848028  [  160/  306]
train() client id: f_00004-11-5 loss: 0.794486  [  192/  306]
train() client id: f_00004-11-6 loss: 0.892711  [  224/  306]
train() client id: f_00004-11-7 loss: 0.886458  [  256/  306]
train() client id: f_00004-11-8 loss: 0.735210  [  288/  306]
train() client id: f_00004-12-0 loss: 0.901381  [   32/  306]
train() client id: f_00004-12-1 loss: 0.859224  [   64/  306]
train() client id: f_00004-12-2 loss: 0.703869  [   96/  306]
train() client id: f_00004-12-3 loss: 0.757145  [  128/  306]
train() client id: f_00004-12-4 loss: 0.728227  [  160/  306]
train() client id: f_00004-12-5 loss: 0.816543  [  192/  306]
train() client id: f_00004-12-6 loss: 0.837220  [  224/  306]
train() client id: f_00004-12-7 loss: 0.768367  [  256/  306]
train() client id: f_00004-12-8 loss: 0.874550  [  288/  306]
train() client id: f_00005-0-0 loss: 0.547339  [   32/  146]
train() client id: f_00005-0-1 loss: 0.182143  [   64/  146]
train() client id: f_00005-0-2 loss: 0.303711  [   96/  146]
train() client id: f_00005-0-3 loss: 0.378816  [  128/  146]
train() client id: f_00005-1-0 loss: 0.323637  [   32/  146]
train() client id: f_00005-1-1 loss: 0.074587  [   64/  146]
train() client id: f_00005-1-2 loss: 0.438361  [   96/  146]
train() client id: f_00005-1-3 loss: 0.688981  [  128/  146]
train() client id: f_00005-2-0 loss: 0.246725  [   32/  146]
train() client id: f_00005-2-1 loss: 0.410464  [   64/  146]
train() client id: f_00005-2-2 loss: 0.698352  [   96/  146]
train() client id: f_00005-2-3 loss: 0.321187  [  128/  146]
train() client id: f_00005-3-0 loss: 0.167334  [   32/  146]
train() client id: f_00005-3-1 loss: 0.457509  [   64/  146]
train() client id: f_00005-3-2 loss: 0.634716  [   96/  146]
train() client id: f_00005-3-3 loss: 0.208489  [  128/  146]
train() client id: f_00005-4-0 loss: 0.231481  [   32/  146]
train() client id: f_00005-4-1 loss: 0.520479  [   64/  146]
train() client id: f_00005-4-2 loss: 0.236177  [   96/  146]
train() client id: f_00005-4-3 loss: 0.349107  [  128/  146]
train() client id: f_00005-5-0 loss: 0.139110  [   32/  146]
train() client id: f_00005-5-1 loss: 0.274875  [   64/  146]
train() client id: f_00005-5-2 loss: 0.294438  [   96/  146]
train() client id: f_00005-5-3 loss: 0.803204  [  128/  146]
train() client id: f_00005-6-0 loss: 0.226538  [   32/  146]
train() client id: f_00005-6-1 loss: 0.530167  [   64/  146]
train() client id: f_00005-6-2 loss: 0.193693  [   96/  146]
train() client id: f_00005-6-3 loss: 0.524674  [  128/  146]
train() client id: f_00005-7-0 loss: 0.018154  [   32/  146]
train() client id: f_00005-7-1 loss: 0.443923  [   64/  146]
train() client id: f_00005-7-2 loss: 0.654533  [   96/  146]
train() client id: f_00005-7-3 loss: 0.358691  [  128/  146]
train() client id: f_00005-8-0 loss: 0.148864  [   32/  146]
train() client id: f_00005-8-1 loss: 0.555882  [   64/  146]
train() client id: f_00005-8-2 loss: 0.328635  [   96/  146]
train() client id: f_00005-8-3 loss: 0.170701  [  128/  146]
train() client id: f_00005-9-0 loss: 0.492439  [   32/  146]
train() client id: f_00005-9-1 loss: 0.320459  [   64/  146]
train() client id: f_00005-9-2 loss: 0.284564  [   96/  146]
train() client id: f_00005-9-3 loss: 0.325047  [  128/  146]
train() client id: f_00005-10-0 loss: 0.247784  [   32/  146]
train() client id: f_00005-10-1 loss: 0.553487  [   64/  146]
train() client id: f_00005-10-2 loss: 0.168834  [   96/  146]
train() client id: f_00005-10-3 loss: 0.572666  [  128/  146]
train() client id: f_00005-11-0 loss: 0.624996  [   32/  146]
train() client id: f_00005-11-1 loss: 0.157545  [   64/  146]
train() client id: f_00005-11-2 loss: 0.304885  [   96/  146]
train() client id: f_00005-11-3 loss: 0.269501  [  128/  146]
train() client id: f_00005-12-0 loss: 0.417232  [   32/  146]
train() client id: f_00005-12-1 loss: 0.535909  [   64/  146]
train() client id: f_00005-12-2 loss: 0.150532  [   96/  146]
train() client id: f_00005-12-3 loss: 0.249278  [  128/  146]
train() client id: f_00006-0-0 loss: 0.508841  [   32/   54]
train() client id: f_00006-1-0 loss: 0.509536  [   32/   54]
train() client id: f_00006-2-0 loss: 0.458328  [   32/   54]
train() client id: f_00006-3-0 loss: 0.528831  [   32/   54]
train() client id: f_00006-4-0 loss: 0.515108  [   32/   54]
train() client id: f_00006-5-0 loss: 0.496455  [   32/   54]
train() client id: f_00006-6-0 loss: 0.505995  [   32/   54]
train() client id: f_00006-7-0 loss: 0.493533  [   32/   54]
train() client id: f_00006-8-0 loss: 0.574112  [   32/   54]
train() client id: f_00006-9-0 loss: 0.511117  [   32/   54]
train() client id: f_00006-10-0 loss: 0.526667  [   32/   54]
train() client id: f_00006-11-0 loss: 0.516557  [   32/   54]
train() client id: f_00006-12-0 loss: 0.504393  [   32/   54]
train() client id: f_00007-0-0 loss: 0.476180  [   32/  179]
train() client id: f_00007-0-1 loss: 0.424416  [   64/  179]
train() client id: f_00007-0-2 loss: 0.743212  [   96/  179]
train() client id: f_00007-0-3 loss: 0.720697  [  128/  179]
train() client id: f_00007-0-4 loss: 0.569787  [  160/  179]
train() client id: f_00007-1-0 loss: 0.642768  [   32/  179]
train() client id: f_00007-1-1 loss: 0.530003  [   64/  179]
train() client id: f_00007-1-2 loss: 0.567114  [   96/  179]
train() client id: f_00007-1-3 loss: 0.603743  [  128/  179]
train() client id: f_00007-1-4 loss: 0.614045  [  160/  179]
train() client id: f_00007-2-0 loss: 0.444003  [   32/  179]
train() client id: f_00007-2-1 loss: 0.526967  [   64/  179]
train() client id: f_00007-2-2 loss: 0.564982  [   96/  179]
train() client id: f_00007-2-3 loss: 0.579968  [  128/  179]
train() client id: f_00007-2-4 loss: 0.538558  [  160/  179]
train() client id: f_00007-3-0 loss: 0.504000  [   32/  179]
train() client id: f_00007-3-1 loss: 0.510409  [   64/  179]
train() client id: f_00007-3-2 loss: 0.402017  [   96/  179]
train() client id: f_00007-3-3 loss: 0.789874  [  128/  179]
train() client id: f_00007-3-4 loss: 0.585953  [  160/  179]
train() client id: f_00007-4-0 loss: 0.471519  [   32/  179]
train() client id: f_00007-4-1 loss: 0.695004  [   64/  179]
train() client id: f_00007-4-2 loss: 0.702897  [   96/  179]
train() client id: f_00007-4-3 loss: 0.599243  [  128/  179]
train() client id: f_00007-4-4 loss: 0.435792  [  160/  179]
train() client id: f_00007-5-0 loss: 0.593865  [   32/  179]
train() client id: f_00007-5-1 loss: 0.670460  [   64/  179]
train() client id: f_00007-5-2 loss: 0.542164  [   96/  179]
train() client id: f_00007-5-3 loss: 0.396703  [  128/  179]
train() client id: f_00007-5-4 loss: 0.503554  [  160/  179]
train() client id: f_00007-6-0 loss: 0.647318  [   32/  179]
train() client id: f_00007-6-1 loss: 0.520346  [   64/  179]
train() client id: f_00007-6-2 loss: 0.554454  [   96/  179]
train() client id: f_00007-6-3 loss: 0.392097  [  128/  179]
train() client id: f_00007-6-4 loss: 0.748662  [  160/  179]
train() client id: f_00007-7-0 loss: 0.538613  [   32/  179]
train() client id: f_00007-7-1 loss: 0.523094  [   64/  179]
train() client id: f_00007-7-2 loss: 0.374991  [   96/  179]
train() client id: f_00007-7-3 loss: 0.603050  [  128/  179]
train() client id: f_00007-7-4 loss: 0.637080  [  160/  179]
train() client id: f_00007-8-0 loss: 0.838228  [   32/  179]
train() client id: f_00007-8-1 loss: 0.509653  [   64/  179]
train() client id: f_00007-8-2 loss: 0.690164  [   96/  179]
train() client id: f_00007-8-3 loss: 0.371399  [  128/  179]
train() client id: f_00007-8-4 loss: 0.463521  [  160/  179]
train() client id: f_00007-9-0 loss: 0.543607  [   32/  179]
train() client id: f_00007-9-1 loss: 0.571773  [   64/  179]
train() client id: f_00007-9-2 loss: 0.552610  [   96/  179]
train() client id: f_00007-9-3 loss: 0.705251  [  128/  179]
train() client id: f_00007-9-4 loss: 0.484670  [  160/  179]
train() client id: f_00007-10-0 loss: 0.592725  [   32/  179]
train() client id: f_00007-10-1 loss: 0.564341  [   64/  179]
train() client id: f_00007-10-2 loss: 0.520174  [   96/  179]
train() client id: f_00007-10-3 loss: 0.480436  [  128/  179]
train() client id: f_00007-10-4 loss: 0.601447  [  160/  179]
train() client id: f_00007-11-0 loss: 0.388491  [   32/  179]
train() client id: f_00007-11-1 loss: 0.540785  [   64/  179]
train() client id: f_00007-11-2 loss: 0.484688  [   96/  179]
train() client id: f_00007-11-3 loss: 0.488016  [  128/  179]
train() client id: f_00007-11-4 loss: 0.675020  [  160/  179]
train() client id: f_00007-12-0 loss: 0.632193  [   32/  179]
train() client id: f_00007-12-1 loss: 0.377566  [   64/  179]
train() client id: f_00007-12-2 loss: 0.412409  [   96/  179]
train() client id: f_00007-12-3 loss: 0.605997  [  128/  179]
train() client id: f_00007-12-4 loss: 0.692604  [  160/  179]
train() client id: f_00008-0-0 loss: 0.556151  [   32/  130]
train() client id: f_00008-0-1 loss: 0.570663  [   64/  130]
train() client id: f_00008-0-2 loss: 0.789700  [   96/  130]
train() client id: f_00008-0-3 loss: 0.643455  [  128/  130]
train() client id: f_00008-1-0 loss: 0.736209  [   32/  130]
train() client id: f_00008-1-1 loss: 0.596273  [   64/  130]
train() client id: f_00008-1-2 loss: 0.667544  [   96/  130]
train() client id: f_00008-1-3 loss: 0.555015  [  128/  130]
train() client id: f_00008-2-0 loss: 0.582574  [   32/  130]
train() client id: f_00008-2-1 loss: 0.701619  [   64/  130]
train() client id: f_00008-2-2 loss: 0.530653  [   96/  130]
train() client id: f_00008-2-3 loss: 0.733550  [  128/  130]
train() client id: f_00008-3-0 loss: 0.533318  [   32/  130]
train() client id: f_00008-3-1 loss: 0.599568  [   64/  130]
train() client id: f_00008-3-2 loss: 0.679405  [   96/  130]
train() client id: f_00008-3-3 loss: 0.733864  [  128/  130]
train() client id: f_00008-4-0 loss: 0.710222  [   32/  130]
train() client id: f_00008-4-1 loss: 0.586991  [   64/  130]
train() client id: f_00008-4-2 loss: 0.613913  [   96/  130]
train() client id: f_00008-4-3 loss: 0.641188  [  128/  130]
train() client id: f_00008-5-0 loss: 0.718311  [   32/  130]
train() client id: f_00008-5-1 loss: 0.612901  [   64/  130]
train() client id: f_00008-5-2 loss: 0.600173  [   96/  130]
train() client id: f_00008-5-3 loss: 0.601360  [  128/  130]
train() client id: f_00008-6-0 loss: 0.527177  [   32/  130]
train() client id: f_00008-6-1 loss: 0.609454  [   64/  130]
train() client id: f_00008-6-2 loss: 0.603426  [   96/  130]
train() client id: f_00008-6-3 loss: 0.819970  [  128/  130]
train() client id: f_00008-7-0 loss: 0.666752  [   32/  130]
train() client id: f_00008-7-1 loss: 0.582703  [   64/  130]
train() client id: f_00008-7-2 loss: 0.668602  [   96/  130]
train() client id: f_00008-7-3 loss: 0.644105  [  128/  130]
train() client id: f_00008-8-0 loss: 0.684383  [   32/  130]
train() client id: f_00008-8-1 loss: 0.508974  [   64/  130]
train() client id: f_00008-8-2 loss: 0.706809  [   96/  130]
train() client id: f_00008-8-3 loss: 0.672836  [  128/  130]
train() client id: f_00008-9-0 loss: 0.660396  [   32/  130]
train() client id: f_00008-9-1 loss: 0.772811  [   64/  130]
train() client id: f_00008-9-2 loss: 0.609762  [   96/  130]
train() client id: f_00008-9-3 loss: 0.531461  [  128/  130]
train() client id: f_00008-10-0 loss: 0.750548  [   32/  130]
train() client id: f_00008-10-1 loss: 0.659885  [   64/  130]
train() client id: f_00008-10-2 loss: 0.621564  [   96/  130]
train() client id: f_00008-10-3 loss: 0.515251  [  128/  130]
train() client id: f_00008-11-0 loss: 0.637573  [   32/  130]
train() client id: f_00008-11-1 loss: 0.528464  [   64/  130]
train() client id: f_00008-11-2 loss: 0.681948  [   96/  130]
train() client id: f_00008-11-3 loss: 0.728750  [  128/  130]
train() client id: f_00008-12-0 loss: 0.606680  [   32/  130]
train() client id: f_00008-12-1 loss: 0.606350  [   64/  130]
train() client id: f_00008-12-2 loss: 0.638201  [   96/  130]
train() client id: f_00008-12-3 loss: 0.719233  [  128/  130]
train() client id: f_00009-0-0 loss: 1.044981  [   32/  118]
train() client id: f_00009-0-1 loss: 0.952609  [   64/  118]
train() client id: f_00009-0-2 loss: 1.044332  [   96/  118]
train() client id: f_00009-1-0 loss: 1.011857  [   32/  118]
train() client id: f_00009-1-1 loss: 1.083365  [   64/  118]
train() client id: f_00009-1-2 loss: 0.940897  [   96/  118]
train() client id: f_00009-2-0 loss: 0.996878  [   32/  118]
train() client id: f_00009-2-1 loss: 0.885432  [   64/  118]
train() client id: f_00009-2-2 loss: 0.829004  [   96/  118]
train() client id: f_00009-3-0 loss: 0.938302  [   32/  118]
train() client id: f_00009-3-1 loss: 0.754475  [   64/  118]
train() client id: f_00009-3-2 loss: 0.955050  [   96/  118]
train() client id: f_00009-4-0 loss: 0.837568  [   32/  118]
train() client id: f_00009-4-1 loss: 0.819507  [   64/  118]
train() client id: f_00009-4-2 loss: 0.855668  [   96/  118]
train() client id: f_00009-5-0 loss: 0.956389  [   32/  118]
train() client id: f_00009-5-1 loss: 0.653312  [   64/  118]
train() client id: f_00009-5-2 loss: 0.971550  [   96/  118]
train() client id: f_00009-6-0 loss: 0.836830  [   32/  118]
train() client id: f_00009-6-1 loss: 0.663314  [   64/  118]
train() client id: f_00009-6-2 loss: 0.873063  [   96/  118]
train() client id: f_00009-7-0 loss: 0.777122  [   32/  118]
train() client id: f_00009-7-1 loss: 0.841386  [   64/  118]
train() client id: f_00009-7-2 loss: 0.722003  [   96/  118]
train() client id: f_00009-8-0 loss: 0.895771  [   32/  118]
train() client id: f_00009-8-1 loss: 0.925905  [   64/  118]
train() client id: f_00009-8-2 loss: 0.568430  [   96/  118]
train() client id: f_00009-9-0 loss: 0.823825  [   32/  118]
train() client id: f_00009-9-1 loss: 0.731368  [   64/  118]
train() client id: f_00009-9-2 loss: 0.674382  [   96/  118]
train() client id: f_00009-10-0 loss: 0.728000  [   32/  118]
train() client id: f_00009-10-1 loss: 0.822106  [   64/  118]
train() client id: f_00009-10-2 loss: 0.768965  [   96/  118]
train() client id: f_00009-11-0 loss: 0.732050  [   32/  118]
train() client id: f_00009-11-1 loss: 0.598571  [   64/  118]
train() client id: f_00009-11-2 loss: 0.944719  [   96/  118]
train() client id: f_00009-12-0 loss: 0.706740  [   32/  118]
train() client id: f_00009-12-1 loss: 0.636648  [   64/  118]
train() client id: f_00009-12-2 loss: 0.844632  [   96/  118]
At round 54 accuracy: 0.6419098143236074
At round 54 training accuracy: 0.5848423876592891
At round 54 training loss: 0.8354303245285887
gradient difference: 0.4023343026638031
train() client id: f_00000-0-0 loss: 0.841075  [   32/  126]
train() client id: f_00000-0-1 loss: 1.032383  [   64/  126]
train() client id: f_00000-0-2 loss: 1.158754  [   96/  126]
train() client id: f_00000-1-0 loss: 1.089285  [   32/  126]
train() client id: f_00000-1-1 loss: 0.963140  [   64/  126]
train() client id: f_00000-1-2 loss: 0.671972  [   96/  126]
train() client id: f_00000-2-0 loss: 0.716579  [   32/  126]
train() client id: f_00000-2-1 loss: 0.836134  [   64/  126]
train() client id: f_00000-2-2 loss: 0.988793  [   96/  126]
train() client id: f_00000-3-0 loss: 0.710560  [   32/  126]
train() client id: f_00000-3-1 loss: 0.776044  [   64/  126]
train() client id: f_00000-3-2 loss: 0.889789  [   96/  126]
train() client id: f_00000-4-0 loss: 0.773479  [   32/  126]
train() client id: f_00000-4-1 loss: 0.694174  [   64/  126]
train() client id: f_00000-4-2 loss: 0.823845  [   96/  126]
train() client id: f_00000-5-0 loss: 0.707516  [   32/  126]
train() client id: f_00000-5-1 loss: 0.737510  [   64/  126]
train() client id: f_00000-5-2 loss: 0.653521  [   96/  126]
train() client id: f_00000-6-0 loss: 0.586350  [   32/  126]
train() client id: f_00000-6-1 loss: 0.705630  [   64/  126]
train() client id: f_00000-6-2 loss: 0.718818  [   96/  126]
train() client id: f_00000-7-0 loss: 0.666371  [   32/  126]
train() client id: f_00000-7-1 loss: 0.642743  [   64/  126]
train() client id: f_00000-7-2 loss: 0.681061  [   96/  126]
train() client id: f_00000-8-0 loss: 0.602148  [   32/  126]
train() client id: f_00000-8-1 loss: 0.669683  [   64/  126]
train() client id: f_00000-8-2 loss: 0.666663  [   96/  126]
train() client id: f_00000-9-0 loss: 0.706446  [   32/  126]
train() client id: f_00000-9-1 loss: 0.659092  [   64/  126]
train() client id: f_00000-9-2 loss: 0.548975  [   96/  126]
train() client id: f_00000-10-0 loss: 0.642655  [   32/  126]
train() client id: f_00000-10-1 loss: 0.630243  [   64/  126]
train() client id: f_00000-10-2 loss: 0.667738  [   96/  126]
train() client id: f_00000-11-0 loss: 0.615335  [   32/  126]
train() client id: f_00000-11-1 loss: 0.640429  [   64/  126]
train() client id: f_00000-11-2 loss: 0.551891  [   96/  126]
train() client id: f_00000-12-0 loss: 0.618962  [   32/  126]
train() client id: f_00000-12-1 loss: 0.617489  [   64/  126]
train() client id: f_00000-12-2 loss: 0.740238  [   96/  126]
train() client id: f_00001-0-0 loss: 0.385400  [   32/  265]
train() client id: f_00001-0-1 loss: 0.518139  [   64/  265]
train() client id: f_00001-0-2 loss: 0.375750  [   96/  265]
train() client id: f_00001-0-3 loss: 0.400470  [  128/  265]
train() client id: f_00001-0-4 loss: 0.416153  [  160/  265]
train() client id: f_00001-0-5 loss: 0.428489  [  192/  265]
train() client id: f_00001-0-6 loss: 0.431462  [  224/  265]
train() client id: f_00001-0-7 loss: 0.605968  [  256/  265]
train() client id: f_00001-1-0 loss: 0.398116  [   32/  265]
train() client id: f_00001-1-1 loss: 0.464292  [   64/  265]
train() client id: f_00001-1-2 loss: 0.402828  [   96/  265]
train() client id: f_00001-1-3 loss: 0.377960  [  128/  265]
train() client id: f_00001-1-4 loss: 0.447791  [  160/  265]
train() client id: f_00001-1-5 loss: 0.427737  [  192/  265]
train() client id: f_00001-1-6 loss: 0.591887  [  224/  265]
train() client id: f_00001-1-7 loss: 0.426989  [  256/  265]
train() client id: f_00001-2-0 loss: 0.359633  [   32/  265]
train() client id: f_00001-2-1 loss: 0.384745  [   64/  265]
train() client id: f_00001-2-2 loss: 0.409570  [   96/  265]
train() client id: f_00001-2-3 loss: 0.395336  [  128/  265]
train() client id: f_00001-2-4 loss: 0.498480  [  160/  265]
train() client id: f_00001-2-5 loss: 0.485736  [  192/  265]
train() client id: f_00001-2-6 loss: 0.528168  [  224/  265]
train() client id: f_00001-2-7 loss: 0.386042  [  256/  265]
train() client id: f_00001-3-0 loss: 0.405858  [   32/  265]
train() client id: f_00001-3-1 loss: 0.365635  [   64/  265]
train() client id: f_00001-3-2 loss: 0.326788  [   96/  265]
train() client id: f_00001-3-3 loss: 0.423001  [  128/  265]
train() client id: f_00001-3-4 loss: 0.563238  [  160/  265]
train() client id: f_00001-3-5 loss: 0.396052  [  192/  265]
train() client id: f_00001-3-6 loss: 0.447056  [  224/  265]
train() client id: f_00001-3-7 loss: 0.485888  [  256/  265]
train() client id: f_00001-4-0 loss: 0.347608  [   32/  265]
train() client id: f_00001-4-1 loss: 0.314794  [   64/  265]
train() client id: f_00001-4-2 loss: 0.437669  [   96/  265]
train() client id: f_00001-4-3 loss: 0.409037  [  128/  265]
train() client id: f_00001-4-4 loss: 0.454116  [  160/  265]
train() client id: f_00001-4-5 loss: 0.508201  [  192/  265]
train() client id: f_00001-4-6 loss: 0.569895  [  224/  265]
train() client id: f_00001-4-7 loss: 0.404273  [  256/  265]
train() client id: f_00001-5-0 loss: 0.335455  [   32/  265]
train() client id: f_00001-5-1 loss: 0.482166  [   64/  265]
train() client id: f_00001-5-2 loss: 0.338245  [   96/  265]
train() client id: f_00001-5-3 loss: 0.520634  [  128/  265]
train() client id: f_00001-5-4 loss: 0.465232  [  160/  265]
train() client id: f_00001-5-5 loss: 0.435462  [  192/  265]
train() client id: f_00001-5-6 loss: 0.428709  [  224/  265]
train() client id: f_00001-5-7 loss: 0.421995  [  256/  265]
train() client id: f_00001-6-0 loss: 0.501907  [   32/  265]
train() client id: f_00001-6-1 loss: 0.458274  [   64/  265]
train() client id: f_00001-6-2 loss: 0.400751  [   96/  265]
train() client id: f_00001-6-3 loss: 0.325716  [  128/  265]
train() client id: f_00001-6-4 loss: 0.422645  [  160/  265]
train() client id: f_00001-6-5 loss: 0.590884  [  192/  265]
train() client id: f_00001-6-6 loss: 0.318371  [  224/  265]
train() client id: f_00001-6-7 loss: 0.343665  [  256/  265]
train() client id: f_00001-7-0 loss: 0.456432  [   32/  265]
train() client id: f_00001-7-1 loss: 0.482498  [   64/  265]
train() client id: f_00001-7-2 loss: 0.434590  [   96/  265]
train() client id: f_00001-7-3 loss: 0.420863  [  128/  265]
train() client id: f_00001-7-4 loss: 0.397922  [  160/  265]
train() client id: f_00001-7-5 loss: 0.451231  [  192/  265]
train() client id: f_00001-7-6 loss: 0.436203  [  224/  265]
train() client id: f_00001-7-7 loss: 0.326706  [  256/  265]
train() client id: f_00001-8-0 loss: 0.514441  [   32/  265]
train() client id: f_00001-8-1 loss: 0.454883  [   64/  265]
train() client id: f_00001-8-2 loss: 0.424258  [   96/  265]
train() client id: f_00001-8-3 loss: 0.319503  [  128/  265]
train() client id: f_00001-8-4 loss: 0.544797  [  160/  265]
train() client id: f_00001-8-5 loss: 0.429081  [  192/  265]
train() client id: f_00001-8-6 loss: 0.318619  [  224/  265]
train() client id: f_00001-8-7 loss: 0.383008  [  256/  265]
train() client id: f_00001-9-0 loss: 0.404039  [   32/  265]
train() client id: f_00001-9-1 loss: 0.454449  [   64/  265]
train() client id: f_00001-9-2 loss: 0.326305  [   96/  265]
train() client id: f_00001-9-3 loss: 0.386005  [  128/  265]
train() client id: f_00001-9-4 loss: 0.415016  [  160/  265]
train() client id: f_00001-9-5 loss: 0.506970  [  192/  265]
train() client id: f_00001-9-6 loss: 0.410379  [  224/  265]
train() client id: f_00001-9-7 loss: 0.494770  [  256/  265]
train() client id: f_00001-10-0 loss: 0.436777  [   32/  265]
train() client id: f_00001-10-1 loss: 0.373897  [   64/  265]
train() client id: f_00001-10-2 loss: 0.427869  [   96/  265]
train() client id: f_00001-10-3 loss: 0.311281  [  128/  265]
train() client id: f_00001-10-4 loss: 0.344502  [  160/  265]
train() client id: f_00001-10-5 loss: 0.531845  [  192/  265]
train() client id: f_00001-10-6 loss: 0.492858  [  224/  265]
train() client id: f_00001-10-7 loss: 0.466439  [  256/  265]
train() client id: f_00001-11-0 loss: 0.453126  [   32/  265]
train() client id: f_00001-11-1 loss: 0.459428  [   64/  265]
train() client id: f_00001-11-2 loss: 0.514789  [   96/  265]
train() client id: f_00001-11-3 loss: 0.503405  [  128/  265]
train() client id: f_00001-11-4 loss: 0.350750  [  160/  265]
train() client id: f_00001-11-5 loss: 0.345801  [  192/  265]
train() client id: f_00001-11-6 loss: 0.427032  [  224/  265]
train() client id: f_00001-11-7 loss: 0.338970  [  256/  265]
train() client id: f_00001-12-0 loss: 0.368528  [   32/  265]
train() client id: f_00001-12-1 loss: 0.359333  [   64/  265]
train() client id: f_00001-12-2 loss: 0.401430  [   96/  265]
train() client id: f_00001-12-3 loss: 0.402243  [  128/  265]
train() client id: f_00001-12-4 loss: 0.473297  [  160/  265]
train() client id: f_00001-12-5 loss: 0.337880  [  192/  265]
train() client id: f_00001-12-6 loss: 0.614256  [  224/  265]
train() client id: f_00001-12-7 loss: 0.439273  [  256/  265]
train() client id: f_00002-0-0 loss: 1.206952  [   32/  124]
train() client id: f_00002-0-1 loss: 1.183707  [   64/  124]
train() client id: f_00002-0-2 loss: 1.115576  [   96/  124]
train() client id: f_00002-1-0 loss: 1.037048  [   32/  124]
train() client id: f_00002-1-1 loss: 1.058565  [   64/  124]
train() client id: f_00002-1-2 loss: 1.035977  [   96/  124]
train() client id: f_00002-2-0 loss: 1.033967  [   32/  124]
train() client id: f_00002-2-1 loss: 0.952017  [   64/  124]
train() client id: f_00002-2-2 loss: 1.050774  [   96/  124]
train() client id: f_00002-3-0 loss: 1.133086  [   32/  124]
train() client id: f_00002-3-1 loss: 1.107053  [   64/  124]
train() client id: f_00002-3-2 loss: 0.787061  [   96/  124]
train() client id: f_00002-4-0 loss: 0.817005  [   32/  124]
train() client id: f_00002-4-1 loss: 1.048746  [   64/  124]
train() client id: f_00002-4-2 loss: 1.008519  [   96/  124]
train() client id: f_00002-5-0 loss: 1.080368  [   32/  124]
train() client id: f_00002-5-1 loss: 0.839013  [   64/  124]
train() client id: f_00002-5-2 loss: 0.879558  [   96/  124]
train() client id: f_00002-6-0 loss: 1.062070  [   32/  124]
train() client id: f_00002-6-1 loss: 1.086671  [   64/  124]
train() client id: f_00002-6-2 loss: 0.980124  [   96/  124]
train() client id: f_00002-7-0 loss: 1.153992  [   32/  124]
train() client id: f_00002-7-1 loss: 0.841524  [   64/  124]
train() client id: f_00002-7-2 loss: 0.968352  [   96/  124]
train() client id: f_00002-8-0 loss: 0.855119  [   32/  124]
train() client id: f_00002-8-1 loss: 0.955566  [   64/  124]
train() client id: f_00002-8-2 loss: 0.989971  [   96/  124]
train() client id: f_00002-9-0 loss: 0.854634  [   32/  124]
train() client id: f_00002-9-1 loss: 0.951383  [   64/  124]
train() client id: f_00002-9-2 loss: 1.019973  [   96/  124]
train() client id: f_00002-10-0 loss: 0.797919  [   32/  124]
train() client id: f_00002-10-1 loss: 1.024292  [   64/  124]
train() client id: f_00002-10-2 loss: 0.980236  [   96/  124]
train() client id: f_00002-11-0 loss: 0.712024  [   32/  124]
train() client id: f_00002-11-1 loss: 1.064622  [   64/  124]
train() client id: f_00002-11-2 loss: 0.902347  [   96/  124]
train() client id: f_00002-12-0 loss: 0.842062  [   32/  124]
train() client id: f_00002-12-1 loss: 0.741237  [   64/  124]
train() client id: f_00002-12-2 loss: 1.003052  [   96/  124]
train() client id: f_00003-0-0 loss: 0.540155  [   32/   43]
train() client id: f_00003-1-0 loss: 0.621813  [   32/   43]
train() client id: f_00003-2-0 loss: 0.711569  [   32/   43]
train() client id: f_00003-3-0 loss: 0.561513  [   32/   43]
train() client id: f_00003-4-0 loss: 0.507690  [   32/   43]
train() client id: f_00003-5-0 loss: 0.778783  [   32/   43]
train() client id: f_00003-6-0 loss: 0.647950  [   32/   43]
train() client id: f_00003-7-0 loss: 0.636471  [   32/   43]
train() client id: f_00003-8-0 loss: 0.443995  [   32/   43]
train() client id: f_00003-9-0 loss: 0.634230  [   32/   43]
train() client id: f_00003-10-0 loss: 0.629380  [   32/   43]
train() client id: f_00003-11-0 loss: 0.502668  [   32/   43]
train() client id: f_00003-12-0 loss: 0.523129  [   32/   43]
train() client id: f_00004-0-0 loss: 0.716299  [   32/  306]
train() client id: f_00004-0-1 loss: 0.855934  [   64/  306]
train() client id: f_00004-0-2 loss: 0.643153  [   96/  306]
train() client id: f_00004-0-3 loss: 0.787385  [  128/  306]
train() client id: f_00004-0-4 loss: 0.628309  [  160/  306]
train() client id: f_00004-0-5 loss: 0.850088  [  192/  306]
train() client id: f_00004-0-6 loss: 0.782401  [  224/  306]
train() client id: f_00004-0-7 loss: 0.686420  [  256/  306]
train() client id: f_00004-0-8 loss: 0.813722  [  288/  306]
train() client id: f_00004-1-0 loss: 0.553234  [   32/  306]
train() client id: f_00004-1-1 loss: 0.811925  [   64/  306]
train() client id: f_00004-1-2 loss: 0.785270  [   96/  306]
train() client id: f_00004-1-3 loss: 0.712141  [  128/  306]
train() client id: f_00004-1-4 loss: 0.660047  [  160/  306]
train() client id: f_00004-1-5 loss: 0.810455  [  192/  306]
train() client id: f_00004-1-6 loss: 0.769085  [  224/  306]
train() client id: f_00004-1-7 loss: 0.920183  [  256/  306]
train() client id: f_00004-1-8 loss: 0.785027  [  288/  306]
train() client id: f_00004-2-0 loss: 0.624562  [   32/  306]
train() client id: f_00004-2-1 loss: 0.829884  [   64/  306]
train() client id: f_00004-2-2 loss: 0.808865  [   96/  306]
train() client id: f_00004-2-3 loss: 0.839462  [  128/  306]
train() client id: f_00004-2-4 loss: 0.635762  [  160/  306]
train() client id: f_00004-2-5 loss: 0.725628  [  192/  306]
train() client id: f_00004-2-6 loss: 0.655640  [  224/  306]
train() client id: f_00004-2-7 loss: 0.806077  [  256/  306]
train() client id: f_00004-2-8 loss: 0.882506  [  288/  306]
train() client id: f_00004-3-0 loss: 0.822924  [   32/  306]
train() client id: f_00004-3-1 loss: 0.764834  [   64/  306]
train() client id: f_00004-3-2 loss: 0.694299  [   96/  306]
train() client id: f_00004-3-3 loss: 0.935313  [  128/  306]
train() client id: f_00004-3-4 loss: 0.699122  [  160/  306]
train() client id: f_00004-3-5 loss: 0.753927  [  192/  306]
train() client id: f_00004-3-6 loss: 0.711488  [  224/  306]
train() client id: f_00004-3-7 loss: 0.737382  [  256/  306]
train() client id: f_00004-3-8 loss: 0.757012  [  288/  306]
train() client id: f_00004-4-0 loss: 0.766801  [   32/  306]
train() client id: f_00004-4-1 loss: 0.726887  [   64/  306]
train() client id: f_00004-4-2 loss: 0.671978  [   96/  306]
train() client id: f_00004-4-3 loss: 0.743238  [  128/  306]
train() client id: f_00004-4-4 loss: 0.808850  [  160/  306]
train() client id: f_00004-4-5 loss: 0.770446  [  192/  306]
train() client id: f_00004-4-6 loss: 0.940664  [  224/  306]
train() client id: f_00004-4-7 loss: 0.671831  [  256/  306]
train() client id: f_00004-4-8 loss: 0.791624  [  288/  306]
train() client id: f_00004-5-0 loss: 0.784666  [   32/  306]
train() client id: f_00004-5-1 loss: 0.851534  [   64/  306]
train() client id: f_00004-5-2 loss: 0.806005  [   96/  306]
train() client id: f_00004-5-3 loss: 0.707520  [  128/  306]
train() client id: f_00004-5-4 loss: 0.901472  [  160/  306]
train() client id: f_00004-5-5 loss: 0.688146  [  192/  306]
train() client id: f_00004-5-6 loss: 0.765053  [  224/  306]
train() client id: f_00004-5-7 loss: 0.659566  [  256/  306]
train() client id: f_00004-5-8 loss: 0.738292  [  288/  306]
train() client id: f_00004-6-0 loss: 0.734845  [   32/  306]
train() client id: f_00004-6-1 loss: 0.732858  [   64/  306]
train() client id: f_00004-6-2 loss: 0.850197  [   96/  306]
train() client id: f_00004-6-3 loss: 0.783170  [  128/  306]
train() client id: f_00004-6-4 loss: 0.659613  [  160/  306]
train() client id: f_00004-6-5 loss: 0.712794  [  192/  306]
train() client id: f_00004-6-6 loss: 0.743488  [  224/  306]
train() client id: f_00004-6-7 loss: 0.796844  [  256/  306]
train() client id: f_00004-6-8 loss: 0.829358  [  288/  306]
train() client id: f_00004-7-0 loss: 0.681151  [   32/  306]
train() client id: f_00004-7-1 loss: 0.838349  [   64/  306]
train() client id: f_00004-7-2 loss: 0.775174  [   96/  306]
train() client id: f_00004-7-3 loss: 0.777908  [  128/  306]
train() client id: f_00004-7-4 loss: 0.868937  [  160/  306]
train() client id: f_00004-7-5 loss: 0.762480  [  192/  306]
train() client id: f_00004-7-6 loss: 0.809879  [  224/  306]
train() client id: f_00004-7-7 loss: 0.731947  [  256/  306]
train() client id: f_00004-7-8 loss: 0.756913  [  288/  306]
train() client id: f_00004-8-0 loss: 0.752917  [   32/  306]
train() client id: f_00004-8-1 loss: 0.763469  [   64/  306]
train() client id: f_00004-8-2 loss: 0.854695  [   96/  306]
train() client id: f_00004-8-3 loss: 0.689262  [  128/  306]
train() client id: f_00004-8-4 loss: 0.876154  [  160/  306]
train() client id: f_00004-8-5 loss: 0.788170  [  192/  306]
train() client id: f_00004-8-6 loss: 0.847817  [  224/  306]
train() client id: f_00004-8-7 loss: 0.662727  [  256/  306]
train() client id: f_00004-8-8 loss: 0.770007  [  288/  306]
train() client id: f_00004-9-0 loss: 0.767310  [   32/  306]
train() client id: f_00004-9-1 loss: 0.747233  [   64/  306]
train() client id: f_00004-9-2 loss: 0.814426  [   96/  306]
train() client id: f_00004-9-3 loss: 0.746803  [  128/  306]
train() client id: f_00004-9-4 loss: 0.752872  [  160/  306]
train() client id: f_00004-9-5 loss: 0.762404  [  192/  306]
train() client id: f_00004-9-6 loss: 0.932073  [  224/  306]
train() client id: f_00004-9-7 loss: 0.748147  [  256/  306]
train() client id: f_00004-9-8 loss: 0.800280  [  288/  306]
train() client id: f_00004-10-0 loss: 0.786685  [   32/  306]
train() client id: f_00004-10-1 loss: 0.799606  [   64/  306]
train() client id: f_00004-10-2 loss: 0.782778  [   96/  306]
train() client id: f_00004-10-3 loss: 0.791143  [  128/  306]
train() client id: f_00004-10-4 loss: 0.730186  [  160/  306]
train() client id: f_00004-10-5 loss: 0.795342  [  192/  306]
train() client id: f_00004-10-6 loss: 0.778308  [  224/  306]
train() client id: f_00004-10-7 loss: 0.931959  [  256/  306]
train() client id: f_00004-10-8 loss: 0.738460  [  288/  306]
train() client id: f_00004-11-0 loss: 0.855730  [   32/  306]
train() client id: f_00004-11-1 loss: 0.774134  [   64/  306]
train() client id: f_00004-11-2 loss: 0.691869  [   96/  306]
train() client id: f_00004-11-3 loss: 0.753317  [  128/  306]
train() client id: f_00004-11-4 loss: 0.691041  [  160/  306]
train() client id: f_00004-11-5 loss: 0.783974  [  192/  306]
train() client id: f_00004-11-6 loss: 0.889062  [  224/  306]
train() client id: f_00004-11-7 loss: 0.824701  [  256/  306]
train() client id: f_00004-11-8 loss: 0.854486  [  288/  306]
train() client id: f_00004-12-0 loss: 0.780459  [   32/  306]
train() client id: f_00004-12-1 loss: 0.742066  [   64/  306]
train() client id: f_00004-12-2 loss: 0.728443  [   96/  306]
train() client id: f_00004-12-3 loss: 0.862610  [  128/  306]
train() client id: f_00004-12-4 loss: 0.854251  [  160/  306]
train() client id: f_00004-12-5 loss: 0.770896  [  192/  306]
train() client id: f_00004-12-6 loss: 0.798684  [  224/  306]
train() client id: f_00004-12-7 loss: 0.811577  [  256/  306]
train() client id: f_00004-12-8 loss: 0.821720  [  288/  306]
train() client id: f_00005-0-0 loss: 0.596422  [   32/  146]
train() client id: f_00005-0-1 loss: 0.631670  [   64/  146]
train() client id: f_00005-0-2 loss: 0.924993  [   96/  146]
train() client id: f_00005-0-3 loss: 0.544696  [  128/  146]
train() client id: f_00005-1-0 loss: 0.725651  [   32/  146]
train() client id: f_00005-1-1 loss: 0.637724  [   64/  146]
train() client id: f_00005-1-2 loss: 0.837856  [   96/  146]
train() client id: f_00005-1-3 loss: 0.631242  [  128/  146]
train() client id: f_00005-2-0 loss: 0.733397  [   32/  146]
train() client id: f_00005-2-1 loss: 0.724171  [   64/  146]
train() client id: f_00005-2-2 loss: 0.850202  [   96/  146]
train() client id: f_00005-2-3 loss: 0.546004  [  128/  146]
train() client id: f_00005-3-0 loss: 0.626859  [   32/  146]
train() client id: f_00005-3-1 loss: 0.947879  [   64/  146]
train() client id: f_00005-3-2 loss: 0.628720  [   96/  146]
train() client id: f_00005-3-3 loss: 0.649894  [  128/  146]
train() client id: f_00005-4-0 loss: 0.832332  [   32/  146]
train() client id: f_00005-4-1 loss: 0.689333  [   64/  146]
train() client id: f_00005-4-2 loss: 0.769641  [   96/  146]
train() client id: f_00005-4-3 loss: 0.463125  [  128/  146]
train() client id: f_00005-5-0 loss: 0.859918  [   32/  146]
train() client id: f_00005-5-1 loss: 0.716952  [   64/  146]
train() client id: f_00005-5-2 loss: 0.587895  [   96/  146]
train() client id: f_00005-5-3 loss: 0.717934  [  128/  146]
train() client id: f_00005-6-0 loss: 0.844642  [   32/  146]
train() client id: f_00005-6-1 loss: 0.617253  [   64/  146]
train() client id: f_00005-6-2 loss: 0.868678  [   96/  146]
train() client id: f_00005-6-3 loss: 0.507972  [  128/  146]
train() client id: f_00005-7-0 loss: 0.686367  [   32/  146]
train() client id: f_00005-7-1 loss: 0.811513  [   64/  146]
train() client id: f_00005-7-2 loss: 0.772287  [   96/  146]
train() client id: f_00005-7-3 loss: 0.624624  [  128/  146]
train() client id: f_00005-8-0 loss: 0.909619  [   32/  146]
train() client id: f_00005-8-1 loss: 0.696169  [   64/  146]
train() client id: f_00005-8-2 loss: 0.651699  [   96/  146]
train() client id: f_00005-8-3 loss: 0.652683  [  128/  146]
train() client id: f_00005-9-0 loss: 0.454871  [   32/  146]
train() client id: f_00005-9-1 loss: 0.768815  [   64/  146]
train() client id: f_00005-9-2 loss: 0.864523  [   96/  146]
train() client id: f_00005-9-3 loss: 0.877672  [  128/  146]
train() client id: f_00005-10-0 loss: 0.413602  [   32/  146]
train() client id: f_00005-10-1 loss: 0.726861  [   64/  146]
train() client id: f_00005-10-2 loss: 0.739518  [   96/  146]
train() client id: f_00005-10-3 loss: 0.705326  [  128/  146]
train() client id: f_00005-11-0 loss: 0.770303  [   32/  146]
train() client id: f_00005-11-1 loss: 0.739889  [   64/  146]
train() client id: f_00005-11-2 loss: 0.648511  [   96/  146]
train() client id: f_00005-11-3 loss: 0.664599  [  128/  146]
train() client id: f_00005-12-0 loss: 0.413572  [   32/  146]
train() client id: f_00005-12-1 loss: 0.890572  [   64/  146]
train() client id: f_00005-12-2 loss: 1.002709  [   96/  146]
train() client id: f_00005-12-3 loss: 0.369587  [  128/  146]
train() client id: f_00006-0-0 loss: 0.532713  [   32/   54]
train() client id: f_00006-1-0 loss: 0.537449  [   32/   54]
train() client id: f_00006-2-0 loss: 0.503714  [   32/   54]
train() client id: f_00006-3-0 loss: 0.459555  [   32/   54]
train() client id: f_00006-4-0 loss: 0.470890  [   32/   54]
train() client id: f_00006-5-0 loss: 0.468990  [   32/   54]
train() client id: f_00006-6-0 loss: 0.534736  [   32/   54]
train() client id: f_00006-7-0 loss: 0.513951  [   32/   54]
train() client id: f_00006-8-0 loss: 0.490042  [   32/   54]
train() client id: f_00006-9-0 loss: 0.464498  [   32/   54]
train() client id: f_00006-10-0 loss: 0.537410  [   32/   54]
train() client id: f_00006-11-0 loss: 0.516943  [   32/   54]
train() client id: f_00006-12-0 loss: 0.457580  [   32/   54]
train() client id: f_00007-0-0 loss: 0.422043  [   32/  179]
train() client id: f_00007-0-1 loss: 0.371568  [   64/  179]
train() client id: f_00007-0-2 loss: 0.584762  [   96/  179]
train() client id: f_00007-0-3 loss: 0.379589  [  128/  179]
train() client id: f_00007-0-4 loss: 0.677807  [  160/  179]
train() client id: f_00007-1-0 loss: 0.572821  [   32/  179]
train() client id: f_00007-1-1 loss: 0.383779  [   64/  179]
train() client id: f_00007-1-2 loss: 0.388686  [   96/  179]
train() client id: f_00007-1-3 loss: 0.416811  [  128/  179]
train() client id: f_00007-1-4 loss: 0.493721  [  160/  179]
train() client id: f_00007-2-0 loss: 0.365311  [   32/  179]
train() client id: f_00007-2-1 loss: 0.709808  [   64/  179]
train() client id: f_00007-2-2 loss: 0.326563  [   96/  179]
train() client id: f_00007-2-3 loss: 0.328501  [  128/  179]
train() client id: f_00007-2-4 loss: 0.505259  [  160/  179]
train() client id: f_00007-3-0 loss: 0.423111  [   32/  179]
train() client id: f_00007-3-1 loss: 0.367231  [   64/  179]
train() client id: f_00007-3-2 loss: 0.272388  [   96/  179]
train() client id: f_00007-3-3 loss: 0.592259  [  128/  179]
train() client id: f_00007-3-4 loss: 0.523475  [  160/  179]
train() client id: f_00007-4-0 loss: 0.494692  [   32/  179]
train() client id: f_00007-4-1 loss: 0.430568  [   64/  179]
train() client id: f_00007-4-2 loss: 0.283131  [   96/  179]
train() client id: f_00007-4-3 loss: 0.359092  [  128/  179]
train() client id: f_00007-4-4 loss: 0.680812  [  160/  179]
train() client id: f_00007-5-0 loss: 0.294188  [   32/  179]
train() client id: f_00007-5-1 loss: 0.553343  [   64/  179]
train() client id: f_00007-5-2 loss: 0.266116  [   96/  179]
train() client id: f_00007-5-3 loss: 0.408244  [  128/  179]
train() client id: f_00007-5-4 loss: 0.650313  [  160/  179]
train() client id: f_00007-6-0 loss: 0.590552  [   32/  179]
train() client id: f_00007-6-1 loss: 0.243443  [   64/  179]
train() client id: f_00007-6-2 loss: 0.410628  [   96/  179]
train() client id: f_00007-6-3 loss: 0.418378  [  128/  179]
train() client id: f_00007-6-4 loss: 0.456582  [  160/  179]
train() client id: f_00007-7-0 loss: 0.426424  [   32/  179]
train() client id: f_00007-7-1 loss: 0.321316  [   64/  179]
train() client id: f_00007-7-2 loss: 0.560126  [   96/  179]
train() client id: f_00007-7-3 loss: 0.362012  [  128/  179]
train() client id: f_00007-7-4 loss: 0.316005  [  160/  179]
train() client id: f_00007-8-0 loss: 0.356108  [   32/  179]
train() client id: f_00007-8-1 loss: 0.522439  [   64/  179]
train() client id: f_00007-8-2 loss: 0.511661  [   96/  179]
train() client id: f_00007-8-3 loss: 0.342405  [  128/  179]
train() client id: f_00007-8-4 loss: 0.343642  [  160/  179]
train() client id: f_00007-9-0 loss: 0.465406  [   32/  179]
train() client id: f_00007-9-1 loss: 0.452551  [   64/  179]
train() client id: f_00007-9-2 loss: 0.265544  [   96/  179]
train() client id: f_00007-9-3 loss: 0.337338  [  128/  179]
train() client id: f_00007-9-4 loss: 0.509402  [  160/  179]
train() client id: f_00007-10-0 loss: 0.297374  [   32/  179]
train() client id: f_00007-10-1 loss: 0.411640  [   64/  179]
train() client id: f_00007-10-2 loss: 0.397294  [   96/  179]
train() client id: f_00007-10-3 loss: 0.344137  [  128/  179]
train() client id: f_00007-10-4 loss: 0.615747  [  160/  179]
train() client id: f_00007-11-0 loss: 0.352512  [   32/  179]
train() client id: f_00007-11-1 loss: 0.687225  [   64/  179]
train() client id: f_00007-11-2 loss: 0.343377  [   96/  179]
train() client id: f_00007-11-3 loss: 0.221266  [  128/  179]
train() client id: f_00007-11-4 loss: 0.453826  [  160/  179]
train() client id: f_00007-12-0 loss: 0.719745  [   32/  179]
train() client id: f_00007-12-1 loss: 0.339851  [   64/  179]
train() client id: f_00007-12-2 loss: 0.200549  [   96/  179]
train() client id: f_00007-12-3 loss: 0.308408  [  128/  179]
train() client id: f_00007-12-4 loss: 0.366129  [  160/  179]
train() client id: f_00008-0-0 loss: 0.642204  [   32/  130]
train() client id: f_00008-0-1 loss: 0.673883  [   64/  130]
train() client id: f_00008-0-2 loss: 0.615054  [   96/  130]
train() client id: f_00008-0-3 loss: 0.665875  [  128/  130]
train() client id: f_00008-1-0 loss: 0.747661  [   32/  130]
train() client id: f_00008-1-1 loss: 0.592983  [   64/  130]
train() client id: f_00008-1-2 loss: 0.609156  [   96/  130]
train() client id: f_00008-1-3 loss: 0.679269  [  128/  130]
train() client id: f_00008-2-0 loss: 0.572211  [   32/  130]
train() client id: f_00008-2-1 loss: 0.622227  [   64/  130]
train() client id: f_00008-2-2 loss: 0.631015  [   96/  130]
train() client id: f_00008-2-3 loss: 0.750226  [  128/  130]
train() client id: f_00008-3-0 loss: 0.676061  [   32/  130]
train() client id: f_00008-3-1 loss: 0.644939  [   64/  130]
train() client id: f_00008-3-2 loss: 0.661109  [   96/  130]
train() client id: f_00008-3-3 loss: 0.642413  [  128/  130]
train() client id: f_00008-4-0 loss: 0.734693  [   32/  130]
train() client id: f_00008-4-1 loss: 0.667478  [   64/  130]
train() client id: f_00008-4-2 loss: 0.637421  [   96/  130]
train() client id: f_00008-4-3 loss: 0.577035  [  128/  130]
train() client id: f_00008-5-0 loss: 0.622491  [   32/  130]
train() client id: f_00008-5-1 loss: 0.758941  [   64/  130]
train() client id: f_00008-5-2 loss: 0.624380  [   96/  130]
train() client id: f_00008-5-3 loss: 0.619533  [  128/  130]
train() client id: f_00008-6-0 loss: 0.593475  [   32/  130]
train() client id: f_00008-6-1 loss: 0.566789  [   64/  130]
train() client id: f_00008-6-2 loss: 0.764703  [   96/  130]
train() client id: f_00008-6-3 loss: 0.700912  [  128/  130]
train() client id: f_00008-7-0 loss: 0.758654  [   32/  130]
train() client id: f_00008-7-1 loss: 0.604945  [   64/  130]
train() client id: f_00008-7-2 loss: 0.646787  [   96/  130]
train() client id: f_00008-7-3 loss: 0.604119  [  128/  130]
train() client id: f_00008-8-0 loss: 0.668594  [   32/  130]
train() client id: f_00008-8-1 loss: 0.653321  [   64/  130]
train() client id: f_00008-8-2 loss: 0.756018  [   96/  130]
train() client id: f_00008-8-3 loss: 0.551800  [  128/  130]
train() client id: f_00008-9-0 loss: 0.622896  [   32/  130]
train() client id: f_00008-9-1 loss: 0.658769  [   64/  130]
train() client id: f_00008-9-2 loss: 0.800407  [   96/  130]
train() client id: f_00008-9-3 loss: 0.558857  [  128/  130]
train() client id: f_00008-10-0 loss: 0.720084  [   32/  130]
train() client id: f_00008-10-1 loss: 0.579190  [   64/  130]
train() client id: f_00008-10-2 loss: 0.654427  [   96/  130]
train() client id: f_00008-10-3 loss: 0.693101  [  128/  130]
train() client id: f_00008-11-0 loss: 0.605370  [   32/  130]
train() client id: f_00008-11-1 loss: 0.634700  [   64/  130]
train() client id: f_00008-11-2 loss: 0.756855  [   96/  130]
train() client id: f_00008-11-3 loss: 0.609277  [  128/  130]
train() client id: f_00008-12-0 loss: 0.656956  [   32/  130]
train() client id: f_00008-12-1 loss: 0.719164  [   64/  130]
train() client id: f_00008-12-2 loss: 0.613079  [   96/  130]
train() client id: f_00008-12-3 loss: 0.651744  [  128/  130]
train() client id: f_00009-0-0 loss: 1.005062  [   32/  118]
train() client id: f_00009-0-1 loss: 1.096422  [   64/  118]
train() client id: f_00009-0-2 loss: 0.897767  [   96/  118]
train() client id: f_00009-1-0 loss: 1.033873  [   32/  118]
train() client id: f_00009-1-1 loss: 0.876739  [   64/  118]
train() client id: f_00009-1-2 loss: 0.928492  [   96/  118]
train() client id: f_00009-2-0 loss: 0.718579  [   32/  118]
train() client id: f_00009-2-1 loss: 0.941344  [   64/  118]
train() client id: f_00009-2-2 loss: 0.962953  [   96/  118]
train() client id: f_00009-3-0 loss: 0.937183  [   32/  118]
train() client id: f_00009-3-1 loss: 0.883151  [   64/  118]
train() client id: f_00009-3-2 loss: 0.821800  [   96/  118]
train() client id: f_00009-4-0 loss: 0.670870  [   32/  118]
train() client id: f_00009-4-1 loss: 0.994283  [   64/  118]
train() client id: f_00009-4-2 loss: 0.817778  [   96/  118]
train() client id: f_00009-5-0 loss: 0.929107  [   32/  118]
train() client id: f_00009-5-1 loss: 0.687957  [   64/  118]
train() client id: f_00009-5-2 loss: 0.937004  [   96/  118]
train() client id: f_00009-6-0 loss: 0.870672  [   32/  118]
train() client id: f_00009-6-1 loss: 0.863963  [   64/  118]
train() client id: f_00009-6-2 loss: 0.650756  [   96/  118]
train() client id: f_00009-7-0 loss: 0.670552  [   32/  118]
train() client id: f_00009-7-1 loss: 0.823436  [   64/  118]
train() client id: f_00009-7-2 loss: 0.892197  [   96/  118]
train() client id: f_00009-8-0 loss: 0.882739  [   32/  118]
train() client id: f_00009-8-1 loss: 0.786892  [   64/  118]
train() client id: f_00009-8-2 loss: 0.799097  [   96/  118]
train() client id: f_00009-9-0 loss: 0.780741  [   32/  118]
train() client id: f_00009-9-1 loss: 0.759971  [   64/  118]
train() client id: f_00009-9-2 loss: 0.781215  [   96/  118]
train() client id: f_00009-10-0 loss: 0.917491  [   32/  118]
train() client id: f_00009-10-1 loss: 0.676982  [   64/  118]
train() client id: f_00009-10-2 loss: 0.736253  [   96/  118]
train() client id: f_00009-11-0 loss: 0.843687  [   32/  118]
train() client id: f_00009-11-1 loss: 0.775813  [   64/  118]
train() client id: f_00009-11-2 loss: 0.681744  [   96/  118]
train() client id: f_00009-12-0 loss: 0.910051  [   32/  118]
train() client id: f_00009-12-1 loss: 0.682989  [   64/  118]
train() client id: f_00009-12-2 loss: 0.787650  [   96/  118]
At round 55 accuracy: 0.6419098143236074
At round 55 training accuracy: 0.5902079141515761
At round 55 training loss: 0.8245970279371447
gradient difference: 0.36275967955589294
train() client id: f_00000-0-0 loss: 1.298791  [   32/  126]
train() client id: f_00000-0-1 loss: 1.305938  [   64/  126]
train() client id: f_00000-0-2 loss: 1.083441  [   96/  126]
train() client id: f_00000-1-0 loss: 1.118258  [   32/  126]
train() client id: f_00000-1-1 loss: 0.850845  [   64/  126]
train() client id: f_00000-1-2 loss: 1.183167  [   96/  126]
train() client id: f_00000-2-0 loss: 1.183053  [   32/  126]
train() client id: f_00000-2-1 loss: 0.931406  [   64/  126]
train() client id: f_00000-2-2 loss: 0.800468  [   96/  126]
train() client id: f_00000-3-0 loss: 0.926723  [   32/  126]
train() client id: f_00000-3-1 loss: 0.779666  [   64/  126]
train() client id: f_00000-3-2 loss: 0.796370  [   96/  126]
train() client id: f_00000-4-0 loss: 0.852487  [   32/  126]
train() client id: f_00000-4-1 loss: 0.827114  [   64/  126]
train() client id: f_00000-4-2 loss: 0.860525  [   96/  126]
train() client id: f_00000-5-0 loss: 0.823349  [   32/  126]
train() client id: f_00000-5-1 loss: 0.618012  [   64/  126]
train() client id: f_00000-5-2 loss: 0.887542  [   96/  126]
train() client id: f_00000-6-0 loss: 0.725558  [   32/  126]
train() client id: f_00000-6-1 loss: 0.688581  [   64/  126]
train() client id: f_00000-6-2 loss: 0.781394  [   96/  126]
train() client id: f_00000-7-0 loss: 0.658995  [   32/  126]
train() client id: f_00000-7-1 loss: 0.677205  [   64/  126]
train() client id: f_00000-7-2 loss: 0.735492  [   96/  126]
train() client id: f_00000-8-0 loss: 0.723855  [   32/  126]
train() client id: f_00000-8-1 loss: 0.861301  [   64/  126]
train() client id: f_00000-8-2 loss: 0.658248  [   96/  126]
train() client id: f_00000-9-0 loss: 0.654453  [   32/  126]
train() client id: f_00000-9-1 loss: 0.705295  [   64/  126]
train() client id: f_00000-9-2 loss: 0.687960  [   96/  126]
train() client id: f_00000-10-0 loss: 0.686439  [   32/  126]
train() client id: f_00000-10-1 loss: 0.831328  [   64/  126]
train() client id: f_00000-10-2 loss: 0.608717  [   96/  126]
train() client id: f_00000-11-0 loss: 0.595538  [   32/  126]
train() client id: f_00000-11-1 loss: 0.626813  [   64/  126]
train() client id: f_00000-11-2 loss: 0.725920  [   96/  126]
train() client id: f_00000-12-0 loss: 0.696092  [   32/  126]
train() client id: f_00000-12-1 loss: 0.564667  [   64/  126]
train() client id: f_00000-12-2 loss: 0.686462  [   96/  126]
train() client id: f_00001-0-0 loss: 0.495663  [   32/  265]
train() client id: f_00001-0-1 loss: 0.451459  [   64/  265]
train() client id: f_00001-0-2 loss: 0.396315  [   96/  265]
train() client id: f_00001-0-3 loss: 0.375349  [  128/  265]
train() client id: f_00001-0-4 loss: 0.416114  [  160/  265]
train() client id: f_00001-0-5 loss: 0.391568  [  192/  265]
train() client id: f_00001-0-6 loss: 0.367239  [  224/  265]
train() client id: f_00001-0-7 loss: 0.320805  [  256/  265]
train() client id: f_00001-1-0 loss: 0.410378  [   32/  265]
train() client id: f_00001-1-1 loss: 0.356271  [   64/  265]
train() client id: f_00001-1-2 loss: 0.415098  [   96/  265]
train() client id: f_00001-1-3 loss: 0.374861  [  128/  265]
train() client id: f_00001-1-4 loss: 0.552447  [  160/  265]
train() client id: f_00001-1-5 loss: 0.364677  [  192/  265]
train() client id: f_00001-1-6 loss: 0.366906  [  224/  265]
train() client id: f_00001-1-7 loss: 0.380776  [  256/  265]
train() client id: f_00001-2-0 loss: 0.424730  [   32/  265]
train() client id: f_00001-2-1 loss: 0.366260  [   64/  265]
train() client id: f_00001-2-2 loss: 0.426396  [   96/  265]
train() client id: f_00001-2-3 loss: 0.309511  [  128/  265]
train() client id: f_00001-2-4 loss: 0.371920  [  160/  265]
train() client id: f_00001-2-5 loss: 0.309413  [  192/  265]
train() client id: f_00001-2-6 loss: 0.544486  [  224/  265]
train() client id: f_00001-2-7 loss: 0.322395  [  256/  265]
train() client id: f_00001-3-0 loss: 0.310464  [   32/  265]
train() client id: f_00001-3-1 loss: 0.413026  [   64/  265]
train() client id: f_00001-3-2 loss: 0.382555  [   96/  265]
train() client id: f_00001-3-3 loss: 0.422126  [  128/  265]
train() client id: f_00001-3-4 loss: 0.333214  [  160/  265]
train() client id: f_00001-3-5 loss: 0.312930  [  192/  265]
train() client id: f_00001-3-6 loss: 0.420135  [  224/  265]
train() client id: f_00001-3-7 loss: 0.492042  [  256/  265]
train() client id: f_00001-4-0 loss: 0.274000  [   32/  265]
train() client id: f_00001-4-1 loss: 0.333011  [   64/  265]
train() client id: f_00001-4-2 loss: 0.406438  [   96/  265]
train() client id: f_00001-4-3 loss: 0.290246  [  128/  265]
train() client id: f_00001-4-4 loss: 0.383792  [  160/  265]
train() client id: f_00001-4-5 loss: 0.402975  [  192/  265]
train() client id: f_00001-4-6 loss: 0.439022  [  224/  265]
train() client id: f_00001-4-7 loss: 0.440157  [  256/  265]
train() client id: f_00001-5-0 loss: 0.482079  [   32/  265]
train() client id: f_00001-5-1 loss: 0.398988  [   64/  265]
train() client id: f_00001-5-2 loss: 0.357976  [   96/  265]
train() client id: f_00001-5-3 loss: 0.274966  [  128/  265]
train() client id: f_00001-5-4 loss: 0.420697  [  160/  265]
train() client id: f_00001-5-5 loss: 0.333385  [  192/  265]
train() client id: f_00001-5-6 loss: 0.353467  [  224/  265]
train() client id: f_00001-5-7 loss: 0.368993  [  256/  265]
train() client id: f_00001-6-0 loss: 0.431203  [   32/  265]
train() client id: f_00001-6-1 loss: 0.309649  [   64/  265]
train() client id: f_00001-6-2 loss: 0.396251  [   96/  265]
train() client id: f_00001-6-3 loss: 0.298534  [  128/  265]
train() client id: f_00001-6-4 loss: 0.370426  [  160/  265]
train() client id: f_00001-6-5 loss: 0.382909  [  192/  265]
train() client id: f_00001-6-6 loss: 0.474510  [  224/  265]
train() client id: f_00001-6-7 loss: 0.320930  [  256/  265]
train() client id: f_00001-7-0 loss: 0.446239  [   32/  265]
train() client id: f_00001-7-1 loss: 0.262498  [   64/  265]
train() client id: f_00001-7-2 loss: 0.485498  [   96/  265]
train() client id: f_00001-7-3 loss: 0.501755  [  128/  265]
train() client id: f_00001-7-4 loss: 0.293098  [  160/  265]
train() client id: f_00001-7-5 loss: 0.280777  [  192/  265]
train() client id: f_00001-7-6 loss: 0.287298  [  224/  265]
train() client id: f_00001-7-7 loss: 0.380342  [  256/  265]
train() client id: f_00001-8-0 loss: 0.442068  [   32/  265]
train() client id: f_00001-8-1 loss: 0.256177  [   64/  265]
train() client id: f_00001-8-2 loss: 0.458051  [   96/  265]
train() client id: f_00001-8-3 loss: 0.432577  [  128/  265]
train() client id: f_00001-8-4 loss: 0.293010  [  160/  265]
train() client id: f_00001-8-5 loss: 0.345282  [  192/  265]
train() client id: f_00001-8-6 loss: 0.265712  [  224/  265]
train() client id: f_00001-8-7 loss: 0.425827  [  256/  265]
train() client id: f_00001-9-0 loss: 0.284645  [   32/  265]
train() client id: f_00001-9-1 loss: 0.471163  [   64/  265]
train() client id: f_00001-9-2 loss: 0.275937  [   96/  265]
train() client id: f_00001-9-3 loss: 0.589792  [  128/  265]
train() client id: f_00001-9-4 loss: 0.453182  [  160/  265]
train() client id: f_00001-9-5 loss: 0.257148  [  192/  265]
train() client id: f_00001-9-6 loss: 0.283441  [  224/  265]
train() client id: f_00001-9-7 loss: 0.277289  [  256/  265]
train() client id: f_00001-10-0 loss: 0.348951  [   32/  265]
train() client id: f_00001-10-1 loss: 0.507709  [   64/  265]
train() client id: f_00001-10-2 loss: 0.300935  [   96/  265]
train() client id: f_00001-10-3 loss: 0.306474  [  128/  265]
train() client id: f_00001-10-4 loss: 0.413918  [  160/  265]
train() client id: f_00001-10-5 loss: 0.328194  [  192/  265]
train() client id: f_00001-10-6 loss: 0.368069  [  224/  265]
train() client id: f_00001-10-7 loss: 0.304681  [  256/  265]
train() client id: f_00001-11-0 loss: 0.441570  [   32/  265]
train() client id: f_00001-11-1 loss: 0.272786  [   64/  265]
train() client id: f_00001-11-2 loss: 0.428374  [   96/  265]
train() client id: f_00001-11-3 loss: 0.298906  [  128/  265]
train() client id: f_00001-11-4 loss: 0.368784  [  160/  265]
train() client id: f_00001-11-5 loss: 0.307687  [  192/  265]
train() client id: f_00001-11-6 loss: 0.256871  [  224/  265]
train() client id: f_00001-11-7 loss: 0.503383  [  256/  265]
train() client id: f_00001-12-0 loss: 0.374243  [   32/  265]
train() client id: f_00001-12-1 loss: 0.268073  [   64/  265]
train() client id: f_00001-12-2 loss: 0.320286  [   96/  265]
train() client id: f_00001-12-3 loss: 0.313553  [  128/  265]
train() client id: f_00001-12-4 loss: 0.412809  [  160/  265]
train() client id: f_00001-12-5 loss: 0.362273  [  192/  265]
train() client id: f_00001-12-6 loss: 0.340023  [  224/  265]
train() client id: f_00001-12-7 loss: 0.320671  [  256/  265]
train() client id: f_00002-0-0 loss: 1.056033  [   32/  124]
train() client id: f_00002-0-1 loss: 1.190489  [   64/  124]
train() client id: f_00002-0-2 loss: 1.090141  [   96/  124]
train() client id: f_00002-1-0 loss: 1.304416  [   32/  124]
train() client id: f_00002-1-1 loss: 0.851018  [   64/  124]
train() client id: f_00002-1-2 loss: 1.040708  [   96/  124]
train() client id: f_00002-2-0 loss: 1.135276  [   32/  124]
train() client id: f_00002-2-1 loss: 1.011181  [   64/  124]
train() client id: f_00002-2-2 loss: 0.964617  [   96/  124]
train() client id: f_00002-3-0 loss: 1.160026  [   32/  124]
train() client id: f_00002-3-1 loss: 0.919799  [   64/  124]
train() client id: f_00002-3-2 loss: 0.918228  [   96/  124]
train() client id: f_00002-4-0 loss: 1.052665  [   32/  124]
train() client id: f_00002-4-1 loss: 0.855840  [   64/  124]
train() client id: f_00002-4-2 loss: 0.852496  [   96/  124]
train() client id: f_00002-5-0 loss: 1.000154  [   32/  124]
train() client id: f_00002-5-1 loss: 0.887994  [   64/  124]
train() client id: f_00002-5-2 loss: 1.075119  [   96/  124]
train() client id: f_00002-6-0 loss: 0.865731  [   32/  124]
train() client id: f_00002-6-1 loss: 1.033364  [   64/  124]
train() client id: f_00002-6-2 loss: 0.896280  [   96/  124]
train() client id: f_00002-7-0 loss: 0.878542  [   32/  124]
train() client id: f_00002-7-1 loss: 0.915520  [   64/  124]
train() client id: f_00002-7-2 loss: 0.816760  [   96/  124]
train() client id: f_00002-8-0 loss: 0.811323  [   32/  124]
train() client id: f_00002-8-1 loss: 0.952428  [   64/  124]
train() client id: f_00002-8-2 loss: 0.912990  [   96/  124]
train() client id: f_00002-9-0 loss: 0.694212  [   32/  124]
train() client id: f_00002-9-1 loss: 0.938399  [   64/  124]
train() client id: f_00002-9-2 loss: 0.898265  [   96/  124]
train() client id: f_00002-10-0 loss: 0.800772  [   32/  124]
train() client id: f_00002-10-1 loss: 0.842882  [   64/  124]
train() client id: f_00002-10-2 loss: 0.858650  [   96/  124]
train() client id: f_00002-11-0 loss: 0.795932  [   32/  124]
train() client id: f_00002-11-1 loss: 0.853892  [   64/  124]
train() client id: f_00002-11-2 loss: 0.746139  [   96/  124]
train() client id: f_00002-12-0 loss: 0.786680  [   32/  124]
train() client id: f_00002-12-1 loss: 0.654955  [   64/  124]
train() client id: f_00002-12-2 loss: 0.798000  [   96/  124]
train() client id: f_00003-0-0 loss: 0.760379  [   32/   43]
train() client id: f_00003-1-0 loss: 0.638731  [   32/   43]
train() client id: f_00003-2-0 loss: 0.871786  [   32/   43]
train() client id: f_00003-3-0 loss: 0.540998  [   32/   43]
train() client id: f_00003-4-0 loss: 0.777384  [   32/   43]
train() client id: f_00003-5-0 loss: 0.814537  [   32/   43]
train() client id: f_00003-6-0 loss: 0.784041  [   32/   43]
train() client id: f_00003-7-0 loss: 0.752546  [   32/   43]
train() client id: f_00003-8-0 loss: 0.826543  [   32/   43]
train() client id: f_00003-9-0 loss: 0.722563  [   32/   43]
train() client id: f_00003-10-0 loss: 0.713280  [   32/   43]
train() client id: f_00003-11-0 loss: 0.719150  [   32/   43]
train() client id: f_00003-12-0 loss: 0.743688  [   32/   43]
train() client id: f_00004-0-0 loss: 0.707849  [   32/  306]
train() client id: f_00004-0-1 loss: 0.965428  [   64/  306]
train() client id: f_00004-0-2 loss: 0.842374  [   96/  306]
train() client id: f_00004-0-3 loss: 0.785171  [  128/  306]
train() client id: f_00004-0-4 loss: 0.631189  [  160/  306]
train() client id: f_00004-0-5 loss: 0.632686  [  192/  306]
train() client id: f_00004-0-6 loss: 0.851677  [  224/  306]
train() client id: f_00004-0-7 loss: 0.663563  [  256/  306]
train() client id: f_00004-0-8 loss: 0.857068  [  288/  306]
train() client id: f_00004-1-0 loss: 0.780044  [   32/  306]
train() client id: f_00004-1-1 loss: 0.731227  [   64/  306]
train() client id: f_00004-1-2 loss: 0.899254  [   96/  306]
train() client id: f_00004-1-3 loss: 0.757767  [  128/  306]
train() client id: f_00004-1-4 loss: 0.710626  [  160/  306]
train() client id: f_00004-1-5 loss: 0.854811  [  192/  306]
train() client id: f_00004-1-6 loss: 0.708835  [  224/  306]
train() client id: f_00004-1-7 loss: 0.680072  [  256/  306]
train() client id: f_00004-1-8 loss: 0.753335  [  288/  306]
train() client id: f_00004-2-0 loss: 0.910091  [   32/  306]
train() client id: f_00004-2-1 loss: 0.767978  [   64/  306]
train() client id: f_00004-2-2 loss: 0.666399  [   96/  306]
train() client id: f_00004-2-3 loss: 0.703183  [  128/  306]
train() client id: f_00004-2-4 loss: 0.888444  [  160/  306]
train() client id: f_00004-2-5 loss: 0.711454  [  192/  306]
train() client id: f_00004-2-6 loss: 0.679424  [  224/  306]
train() client id: f_00004-2-7 loss: 0.803543  [  256/  306]
train() client id: f_00004-2-8 loss: 0.783444  [  288/  306]
train() client id: f_00004-3-0 loss: 0.744417  [   32/  306]
train() client id: f_00004-3-1 loss: 0.572456  [   64/  306]
train() client id: f_00004-3-2 loss: 0.824123  [   96/  306]
train() client id: f_00004-3-3 loss: 0.805475  [  128/  306]
train() client id: f_00004-3-4 loss: 0.611610  [  160/  306]
train() client id: f_00004-3-5 loss: 1.033523  [  192/  306]
train() client id: f_00004-3-6 loss: 0.663395  [  224/  306]
train() client id: f_00004-3-7 loss: 0.751962  [  256/  306]
train() client id: f_00004-3-8 loss: 0.914059  [  288/  306]
train() client id: f_00004-4-0 loss: 0.728981  [   32/  306]
train() client id: f_00004-4-1 loss: 0.828766  [   64/  306]
train() client id: f_00004-4-2 loss: 0.784980  [   96/  306]
train() client id: f_00004-4-3 loss: 0.810444  [  128/  306]
train() client id: f_00004-4-4 loss: 0.884940  [  160/  306]
train() client id: f_00004-4-5 loss: 0.745365  [  192/  306]
train() client id: f_00004-4-6 loss: 0.765991  [  224/  306]
train() client id: f_00004-4-7 loss: 0.723889  [  256/  306]
train() client id: f_00004-4-8 loss: 0.681891  [  288/  306]
train() client id: f_00004-5-0 loss: 0.853726  [   32/  306]
train() client id: f_00004-5-1 loss: 0.775382  [   64/  306]
train() client id: f_00004-5-2 loss: 0.661506  [   96/  306]
train() client id: f_00004-5-3 loss: 0.731423  [  128/  306]
train() client id: f_00004-5-4 loss: 0.709028  [  160/  306]
train() client id: f_00004-5-5 loss: 0.752314  [  192/  306]
train() client id: f_00004-5-6 loss: 0.771664  [  224/  306]
train() client id: f_00004-5-7 loss: 0.711078  [  256/  306]
train() client id: f_00004-5-8 loss: 0.924239  [  288/  306]
train() client id: f_00004-6-0 loss: 0.757125  [   32/  306]
train() client id: f_00004-6-1 loss: 0.771214  [   64/  306]
train() client id: f_00004-6-2 loss: 0.737173  [   96/  306]
train() client id: f_00004-6-3 loss: 0.852096  [  128/  306]
train() client id: f_00004-6-4 loss: 0.775359  [  160/  306]
train() client id: f_00004-6-5 loss: 0.708102  [  192/  306]
train() client id: f_00004-6-6 loss: 0.774217  [  224/  306]
train() client id: f_00004-6-7 loss: 0.790678  [  256/  306]
train() client id: f_00004-6-8 loss: 0.857771  [  288/  306]
train() client id: f_00004-7-0 loss: 0.787975  [   32/  306]
train() client id: f_00004-7-1 loss: 0.883536  [   64/  306]
train() client id: f_00004-7-2 loss: 0.746039  [   96/  306]
train() client id: f_00004-7-3 loss: 0.734791  [  128/  306]
train() client id: f_00004-7-4 loss: 0.818683  [  160/  306]
train() client id: f_00004-7-5 loss: 0.751881  [  192/  306]
train() client id: f_00004-7-6 loss: 0.674890  [  224/  306]
train() client id: f_00004-7-7 loss: 0.773098  [  256/  306]
train() client id: f_00004-7-8 loss: 0.771103  [  288/  306]
train() client id: f_00004-8-0 loss: 0.729824  [   32/  306]
train() client id: f_00004-8-1 loss: 0.904227  [   64/  306]
train() client id: f_00004-8-2 loss: 0.752572  [   96/  306]
train() client id: f_00004-8-3 loss: 0.760320  [  128/  306]
train() client id: f_00004-8-4 loss: 0.809847  [  160/  306]
train() client id: f_00004-8-5 loss: 0.652529  [  192/  306]
train() client id: f_00004-8-6 loss: 0.661844  [  224/  306]
train() client id: f_00004-8-7 loss: 0.917249  [  256/  306]
train() client id: f_00004-8-8 loss: 0.701987  [  288/  306]
train() client id: f_00004-9-0 loss: 0.720616  [   32/  306]
train() client id: f_00004-9-1 loss: 0.702152  [   64/  306]
train() client id: f_00004-9-2 loss: 0.648780  [   96/  306]
train() client id: f_00004-9-3 loss: 0.812076  [  128/  306]
train() client id: f_00004-9-4 loss: 0.873218  [  160/  306]
train() client id: f_00004-9-5 loss: 0.857560  [  192/  306]
train() client id: f_00004-9-6 loss: 0.885367  [  224/  306]
train() client id: f_00004-9-7 loss: 0.849493  [  256/  306]
train() client id: f_00004-9-8 loss: 0.640324  [  288/  306]
train() client id: f_00004-10-0 loss: 0.712259  [   32/  306]
train() client id: f_00004-10-1 loss: 0.771185  [   64/  306]
train() client id: f_00004-10-2 loss: 0.870833  [   96/  306]
train() client id: f_00004-10-3 loss: 0.870706  [  128/  306]
train() client id: f_00004-10-4 loss: 0.732267  [  160/  306]
train() client id: f_00004-10-5 loss: 0.844194  [  192/  306]
train() client id: f_00004-10-6 loss: 0.766148  [  224/  306]
train() client id: f_00004-10-7 loss: 0.780826  [  256/  306]
train() client id: f_00004-10-8 loss: 0.711532  [  288/  306]
train() client id: f_00004-11-0 loss: 0.654876  [   32/  306]
train() client id: f_00004-11-1 loss: 0.766151  [   64/  306]
train() client id: f_00004-11-2 loss: 0.830781  [   96/  306]
train() client id: f_00004-11-3 loss: 0.722907  [  128/  306]
train() client id: f_00004-11-4 loss: 0.689969  [  160/  306]
train() client id: f_00004-11-5 loss: 0.807455  [  192/  306]
train() client id: f_00004-11-6 loss: 0.823989  [  224/  306]
train() client id: f_00004-11-7 loss: 0.800754  [  256/  306]
train() client id: f_00004-11-8 loss: 0.782245  [  288/  306]
train() client id: f_00004-12-0 loss: 0.762397  [   32/  306]
train() client id: f_00004-12-1 loss: 0.839831  [   64/  306]
train() client id: f_00004-12-2 loss: 0.767529  [   96/  306]
train() client id: f_00004-12-3 loss: 0.681123  [  128/  306]
train() client id: f_00004-12-4 loss: 0.670379  [  160/  306]
train() client id: f_00004-12-5 loss: 0.807565  [  192/  306]
train() client id: f_00004-12-6 loss: 0.810771  [  224/  306]
train() client id: f_00004-12-7 loss: 0.785941  [  256/  306]
train() client id: f_00004-12-8 loss: 0.813181  [  288/  306]
train() client id: f_00005-0-0 loss: 0.784966  [   32/  146]
train() client id: f_00005-0-1 loss: 0.866427  [   64/  146]
train() client id: f_00005-0-2 loss: 0.733270  [   96/  146]
train() client id: f_00005-0-3 loss: 1.056152  [  128/  146]
train() client id: f_00005-1-0 loss: 0.872851  [   32/  146]
train() client id: f_00005-1-1 loss: 1.084231  [   64/  146]
train() client id: f_00005-1-2 loss: 0.981575  [   96/  146]
train() client id: f_00005-1-3 loss: 0.758801  [  128/  146]
train() client id: f_00005-2-0 loss: 0.867972  [   32/  146]
train() client id: f_00005-2-1 loss: 0.845855  [   64/  146]
train() client id: f_00005-2-2 loss: 0.885428  [   96/  146]
train() client id: f_00005-2-3 loss: 0.928170  [  128/  146]
train() client id: f_00005-3-0 loss: 0.856710  [   32/  146]
train() client id: f_00005-3-1 loss: 1.043654  [   64/  146]
train() client id: f_00005-3-2 loss: 0.961368  [   96/  146]
train() client id: f_00005-3-3 loss: 0.722677  [  128/  146]
train() client id: f_00005-4-0 loss: 0.833775  [   32/  146]
train() client id: f_00005-4-1 loss: 1.044081  [   64/  146]
train() client id: f_00005-4-2 loss: 0.806508  [   96/  146]
train() client id: f_00005-4-3 loss: 0.698961  [  128/  146]
train() client id: f_00005-5-0 loss: 1.067749  [   32/  146]
train() client id: f_00005-5-1 loss: 0.831612  [   64/  146]
train() client id: f_00005-5-2 loss: 0.781394  [   96/  146]
train() client id: f_00005-5-3 loss: 0.792521  [  128/  146]
train() client id: f_00005-6-0 loss: 0.982067  [   32/  146]
train() client id: f_00005-6-1 loss: 0.819451  [   64/  146]
train() client id: f_00005-6-2 loss: 0.872405  [   96/  146]
train() client id: f_00005-6-3 loss: 0.740509  [  128/  146]
train() client id: f_00005-7-0 loss: 1.096077  [   32/  146]
train() client id: f_00005-7-1 loss: 0.869974  [   64/  146]
train() client id: f_00005-7-2 loss: 0.720839  [   96/  146]
train() client id: f_00005-7-3 loss: 0.870462  [  128/  146]
train() client id: f_00005-8-0 loss: 0.629624  [   32/  146]
train() client id: f_00005-8-1 loss: 1.079790  [   64/  146]
train() client id: f_00005-8-2 loss: 0.785215  [   96/  146]
train() client id: f_00005-8-3 loss: 0.915723  [  128/  146]
train() client id: f_00005-9-0 loss: 0.647748  [   32/  146]
train() client id: f_00005-9-1 loss: 0.994789  [   64/  146]
train() client id: f_00005-9-2 loss: 0.822683  [   96/  146]
train() client id: f_00005-9-3 loss: 1.265405  [  128/  146]
train() client id: f_00005-10-0 loss: 0.940151  [   32/  146]
train() client id: f_00005-10-1 loss: 1.053994  [   64/  146]
train() client id: f_00005-10-2 loss: 0.780667  [   96/  146]
train() client id: f_00005-10-3 loss: 0.879372  [  128/  146]
train() client id: f_00005-11-0 loss: 1.071617  [   32/  146]
train() client id: f_00005-11-1 loss: 1.078122  [   64/  146]
train() client id: f_00005-11-2 loss: 0.665090  [   96/  146]
train() client id: f_00005-11-3 loss: 0.834499  [  128/  146]
train() client id: f_00005-12-0 loss: 0.791751  [   32/  146]
train() client id: f_00005-12-1 loss: 0.987411  [   64/  146]
train() client id: f_00005-12-2 loss: 1.025572  [   96/  146]
train() client id: f_00005-12-3 loss: 0.837046  [  128/  146]
train() client id: f_00006-0-0 loss: 0.444181  [   32/   54]
train() client id: f_00006-1-0 loss: 0.570377  [   32/   54]
train() client id: f_00006-2-0 loss: 0.507777  [   32/   54]
train() client id: f_00006-3-0 loss: 0.507556  [   32/   54]
train() client id: f_00006-4-0 loss: 0.542859  [   32/   54]
train() client id: f_00006-5-0 loss: 0.553636  [   32/   54]
train() client id: f_00006-6-0 loss: 0.570917  [   32/   54]
train() client id: f_00006-7-0 loss: 0.501118  [   32/   54]
train() client id: f_00006-8-0 loss: 0.483750  [   32/   54]
train() client id: f_00006-9-0 loss: 0.567188  [   32/   54]
train() client id: f_00006-10-0 loss: 0.565628  [   32/   54]
train() client id: f_00006-11-0 loss: 0.513137  [   32/   54]
train() client id: f_00006-12-0 loss: 0.533879  [   32/   54]
train() client id: f_00007-0-0 loss: 0.629599  [   32/  179]
train() client id: f_00007-0-1 loss: 0.657210  [   64/  179]
train() client id: f_00007-0-2 loss: 0.803857  [   96/  179]
train() client id: f_00007-0-3 loss: 0.540552  [  128/  179]
train() client id: f_00007-0-4 loss: 0.478427  [  160/  179]
train() client id: f_00007-1-0 loss: 0.645714  [   32/  179]
train() client id: f_00007-1-1 loss: 0.712127  [   64/  179]
train() client id: f_00007-1-2 loss: 0.444670  [   96/  179]
train() client id: f_00007-1-3 loss: 0.762705  [  128/  179]
train() client id: f_00007-1-4 loss: 0.506924  [  160/  179]
train() client id: f_00007-2-0 loss: 0.647510  [   32/  179]
train() client id: f_00007-2-1 loss: 0.672932  [   64/  179]
train() client id: f_00007-2-2 loss: 0.541572  [   96/  179]
train() client id: f_00007-2-3 loss: 0.505987  [  128/  179]
train() client id: f_00007-2-4 loss: 0.428326  [  160/  179]
train() client id: f_00007-3-0 loss: 0.375735  [   32/  179]
train() client id: f_00007-3-1 loss: 0.477926  [   64/  179]
train() client id: f_00007-3-2 loss: 0.484255  [   96/  179]
train() client id: f_00007-3-3 loss: 0.774130  [  128/  179]
train() client id: f_00007-3-4 loss: 0.892888  [  160/  179]
train() client id: f_00007-4-0 loss: 0.451247  [   32/  179]
train() client id: f_00007-4-1 loss: 0.673863  [   64/  179]
train() client id: f_00007-4-2 loss: 0.541762  [   96/  179]
train() client id: f_00007-4-3 loss: 0.604165  [  128/  179]
train() client id: f_00007-4-4 loss: 0.639991  [  160/  179]
train() client id: f_00007-5-0 loss: 0.515932  [   32/  179]
train() client id: f_00007-5-1 loss: 0.443997  [   64/  179]
train() client id: f_00007-5-2 loss: 0.453751  [   96/  179]
train() client id: f_00007-5-3 loss: 0.666776  [  128/  179]
train() client id: f_00007-5-4 loss: 0.684907  [  160/  179]
train() client id: f_00007-6-0 loss: 0.553830  [   32/  179]
train() client id: f_00007-6-1 loss: 0.685566  [   64/  179]
train() client id: f_00007-6-2 loss: 0.485105  [   96/  179]
train() client id: f_00007-6-3 loss: 0.619228  [  128/  179]
train() client id: f_00007-6-4 loss: 0.596419  [  160/  179]
train() client id: f_00007-7-0 loss: 0.480927  [   32/  179]
train() client id: f_00007-7-1 loss: 0.557170  [   64/  179]
train() client id: f_00007-7-2 loss: 0.583933  [   96/  179]
train() client id: f_00007-7-3 loss: 0.493501  [  128/  179]
train() client id: f_00007-7-4 loss: 0.491747  [  160/  179]
train() client id: f_00007-8-0 loss: 0.430486  [   32/  179]
train() client id: f_00007-8-1 loss: 0.668242  [   64/  179]
train() client id: f_00007-8-2 loss: 0.552893  [   96/  179]
train() client id: f_00007-8-3 loss: 0.481758  [  128/  179]
train() client id: f_00007-8-4 loss: 0.699412  [  160/  179]
train() client id: f_00007-9-0 loss: 0.497821  [   32/  179]
train() client id: f_00007-9-1 loss: 0.552014  [   64/  179]
train() client id: f_00007-9-2 loss: 0.411952  [   96/  179]
train() client id: f_00007-9-3 loss: 0.658658  [  128/  179]
train() client id: f_00007-9-4 loss: 0.796110  [  160/  179]
train() client id: f_00007-10-0 loss: 0.408967  [   32/  179]
train() client id: f_00007-10-1 loss: 0.529855  [   64/  179]
train() client id: f_00007-10-2 loss: 0.609790  [   96/  179]
train() client id: f_00007-10-3 loss: 0.557878  [  128/  179]
train() client id: f_00007-10-4 loss: 0.478721  [  160/  179]
train() client id: f_00007-11-0 loss: 0.397554  [   32/  179]
train() client id: f_00007-11-1 loss: 0.572667  [   64/  179]
train() client id: f_00007-11-2 loss: 0.660968  [   96/  179]
train() client id: f_00007-11-3 loss: 0.574039  [  128/  179]
train() client id: f_00007-11-4 loss: 0.630747  [  160/  179]
train() client id: f_00007-12-0 loss: 0.721982  [   32/  179]
train() client id: f_00007-12-1 loss: 0.580260  [   64/  179]
train() client id: f_00007-12-2 loss: 0.539549  [   96/  179]
train() client id: f_00007-12-3 loss: 0.658739  [  128/  179]
train() client id: f_00007-12-4 loss: 0.408076  [  160/  179]
train() client id: f_00008-0-0 loss: 0.639656  [   32/  130]
train() client id: f_00008-0-1 loss: 0.665813  [   64/  130]
train() client id: f_00008-0-2 loss: 0.705385  [   96/  130]
train() client id: f_00008-0-3 loss: 0.761493  [  128/  130]
train() client id: f_00008-1-0 loss: 0.757655  [   32/  130]
train() client id: f_00008-1-1 loss: 0.686724  [   64/  130]
train() client id: f_00008-1-2 loss: 0.609243  [   96/  130]
train() client id: f_00008-1-3 loss: 0.695825  [  128/  130]
train() client id: f_00008-2-0 loss: 0.624538  [   32/  130]
train() client id: f_00008-2-1 loss: 0.722286  [   64/  130]
train() client id: f_00008-2-2 loss: 0.771809  [   96/  130]
train() client id: f_00008-2-3 loss: 0.680752  [  128/  130]
train() client id: f_00008-3-0 loss: 0.746919  [   32/  130]
train() client id: f_00008-3-1 loss: 0.632798  [   64/  130]
train() client id: f_00008-3-2 loss: 0.669415  [   96/  130]
train() client id: f_00008-3-3 loss: 0.754270  [  128/  130]
train() client id: f_00008-4-0 loss: 0.651831  [   32/  130]
train() client id: f_00008-4-1 loss: 0.634586  [   64/  130]
train() client id: f_00008-4-2 loss: 0.826840  [   96/  130]
train() client id: f_00008-4-3 loss: 0.651677  [  128/  130]
train() client id: f_00008-5-0 loss: 0.723814  [   32/  130]
train() client id: f_00008-5-1 loss: 0.737433  [   64/  130]
train() client id: f_00008-5-2 loss: 0.698137  [   96/  130]
train() client id: f_00008-5-3 loss: 0.601601  [  128/  130]
train() client id: f_00008-6-0 loss: 0.650791  [   32/  130]
train() client id: f_00008-6-1 loss: 0.764667  [   64/  130]
train() client id: f_00008-6-2 loss: 0.658890  [   96/  130]
train() client id: f_00008-6-3 loss: 0.722323  [  128/  130]
train() client id: f_00008-7-0 loss: 0.873226  [   32/  130]
train() client id: f_00008-7-1 loss: 0.627022  [   64/  130]
train() client id: f_00008-7-2 loss: 0.616842  [   96/  130]
train() client id: f_00008-7-3 loss: 0.678618  [  128/  130]
train() client id: f_00008-8-0 loss: 0.735213  [   32/  130]
train() client id: f_00008-8-1 loss: 0.711125  [   64/  130]
train() client id: f_00008-8-2 loss: 0.616048  [   96/  130]
train() client id: f_00008-8-3 loss: 0.744162  [  128/  130]
train() client id: f_00008-9-0 loss: 0.711943  [   32/  130]
train() client id: f_00008-9-1 loss: 0.737137  [   64/  130]
train() client id: f_00008-9-2 loss: 0.705014  [   96/  130]
train() client id: f_00008-9-3 loss: 0.644753  [  128/  130]
train() client id: f_00008-10-0 loss: 0.681072  [   32/  130]
train() client id: f_00008-10-1 loss: 0.805470  [   64/  130]
train() client id: f_00008-10-2 loss: 0.707312  [   96/  130]
train() client id: f_00008-10-3 loss: 0.613634  [  128/  130]
train() client id: f_00008-11-0 loss: 0.649627  [   32/  130]
train() client id: f_00008-11-1 loss: 0.713181  [   64/  130]
train() client id: f_00008-11-2 loss: 0.659088  [   96/  130]
train() client id: f_00008-11-3 loss: 0.778010  [  128/  130]
train() client id: f_00008-12-0 loss: 0.811240  [   32/  130]
train() client id: f_00008-12-1 loss: 0.662227  [   64/  130]
train() client id: f_00008-12-2 loss: 0.670378  [   96/  130]
train() client id: f_00008-12-3 loss: 0.621382  [  128/  130]
train() client id: f_00009-0-0 loss: 1.154550  [   32/  118]
train() client id: f_00009-0-1 loss: 1.254538  [   64/  118]
train() client id: f_00009-0-2 loss: 1.049711  [   96/  118]
train() client id: f_00009-1-0 loss: 1.134170  [   32/  118]
train() client id: f_00009-1-1 loss: 1.143876  [   64/  118]
train() client id: f_00009-1-2 loss: 1.072512  [   96/  118]
train() client id: f_00009-2-0 loss: 1.140264  [   32/  118]
train() client id: f_00009-2-1 loss: 1.032928  [   64/  118]
train() client id: f_00009-2-2 loss: 1.053984  [   96/  118]
train() client id: f_00009-3-0 loss: 0.867710  [   32/  118]
train() client id: f_00009-3-1 loss: 0.949999  [   64/  118]
train() client id: f_00009-3-2 loss: 1.094922  [   96/  118]
train() client id: f_00009-4-0 loss: 0.958404  [   32/  118]
train() client id: f_00009-4-1 loss: 0.942820  [   64/  118]
train() client id: f_00009-4-2 loss: 0.939421  [   96/  118]
train() client id: f_00009-5-0 loss: 0.976982  [   32/  118]
train() client id: f_00009-5-1 loss: 0.849817  [   64/  118]
train() client id: f_00009-5-2 loss: 0.855157  [   96/  118]
train() client id: f_00009-6-0 loss: 0.932076  [   32/  118]
train() client id: f_00009-6-1 loss: 0.889528  [   64/  118]
train() client id: f_00009-6-2 loss: 0.784103  [   96/  118]
train() client id: f_00009-7-0 loss: 0.870370  [   32/  118]
train() client id: f_00009-7-1 loss: 0.894693  [   64/  118]
train() client id: f_00009-7-2 loss: 0.896830  [   96/  118]
train() client id: f_00009-8-0 loss: 0.849093  [   32/  118]
train() client id: f_00009-8-1 loss: 0.853027  [   64/  118]
train() client id: f_00009-8-2 loss: 0.970631  [   96/  118]
train() client id: f_00009-9-0 loss: 1.017640  [   32/  118]
train() client id: f_00009-9-1 loss: 0.757906  [   64/  118]
train() client id: f_00009-9-2 loss: 0.933182  [   96/  118]
train() client id: f_00009-10-0 loss: 0.869177  [   32/  118]
train() client id: f_00009-10-1 loss: 0.799299  [   64/  118]
train() client id: f_00009-10-2 loss: 0.882842  [   96/  118]
train() client id: f_00009-11-0 loss: 0.888302  [   32/  118]
train() client id: f_00009-11-1 loss: 0.718537  [   64/  118]
train() client id: f_00009-11-2 loss: 0.800111  [   96/  118]
train() client id: f_00009-12-0 loss: 0.733403  [   32/  118]
train() client id: f_00009-12-1 loss: 0.852579  [   64/  118]
train() client id: f_00009-12-2 loss: 1.008520  [   96/  118]
At round 56 accuracy: 0.6419098143236074
At round 56 training accuracy: 0.5928906773977196
At round 56 training loss: 0.8217153306315903
gradient difference: 0.359016478061676
train() client id: f_00000-0-0 loss: 1.246369  [   32/  126]
train() client id: f_00000-0-1 loss: 0.918691  [   64/  126]
train() client id: f_00000-0-2 loss: 1.032571  [   96/  126]
train() client id: f_00000-1-0 loss: 0.981586  [   32/  126]
train() client id: f_00000-1-1 loss: 1.006042  [   64/  126]
train() client id: f_00000-1-2 loss: 0.948521  [   96/  126]
train() client id: f_00000-2-0 loss: 1.052058  [   32/  126]
train() client id: f_00000-2-1 loss: 0.973007  [   64/  126]
train() client id: f_00000-2-2 loss: 0.974104  [   96/  126]
train() client id: f_00000-3-0 loss: 0.899926  [   32/  126]
train() client id: f_00000-3-1 loss: 0.846442  [   64/  126]
train() client id: f_00000-3-2 loss: 0.833749  [   96/  126]
train() client id: f_00000-4-0 loss: 0.880546  [   32/  126]
train() client id: f_00000-4-1 loss: 0.883757  [   64/  126]
train() client id: f_00000-4-2 loss: 0.704985  [   96/  126]
train() client id: f_00000-5-0 loss: 0.931811  [   32/  126]
train() client id: f_00000-5-1 loss: 0.735704  [   64/  126]
train() client id: f_00000-5-2 loss: 0.700881  [   96/  126]
train() client id: f_00000-6-0 loss: 0.765255  [   32/  126]
train() client id: f_00000-6-1 loss: 0.673490  [   64/  126]
train() client id: f_00000-6-2 loss: 0.799066  [   96/  126]
train() client id: f_00000-7-0 loss: 0.716302  [   32/  126]
train() client id: f_00000-7-1 loss: 0.731433  [   64/  126]
train() client id: f_00000-7-2 loss: 0.810096  [   96/  126]
train() client id: f_00000-8-0 loss: 0.683575  [   32/  126]
train() client id: f_00000-8-1 loss: 0.829153  [   64/  126]
train() client id: f_00000-8-2 loss: 0.709483  [   96/  126]
train() client id: f_00000-9-0 loss: 0.651008  [   32/  126]
train() client id: f_00000-9-1 loss: 0.830086  [   64/  126]
train() client id: f_00000-9-2 loss: 0.742880  [   96/  126]
train() client id: f_00000-10-0 loss: 0.664824  [   32/  126]
train() client id: f_00000-10-1 loss: 0.870087  [   64/  126]
train() client id: f_00000-10-2 loss: 0.654975  [   96/  126]
train() client id: f_00000-11-0 loss: 0.849214  [   32/  126]
train() client id: f_00000-11-1 loss: 0.839281  [   64/  126]
train() client id: f_00000-11-2 loss: 0.632671  [   96/  126]
train() client id: f_00000-12-0 loss: 0.686010  [   32/  126]
train() client id: f_00000-12-1 loss: 0.795410  [   64/  126]
train() client id: f_00000-12-2 loss: 0.586771  [   96/  126]
train() client id: f_00001-0-0 loss: 0.411523  [   32/  265]
train() client id: f_00001-0-1 loss: 0.584219  [   64/  265]
train() client id: f_00001-0-2 loss: 0.492980  [   96/  265]
train() client id: f_00001-0-3 loss: 0.575367  [  128/  265]
train() client id: f_00001-0-4 loss: 0.379695  [  160/  265]
train() client id: f_00001-0-5 loss: 0.588580  [  192/  265]
train() client id: f_00001-0-6 loss: 0.465129  [  224/  265]
train() client id: f_00001-0-7 loss: 0.450748  [  256/  265]
train() client id: f_00001-1-0 loss: 0.489207  [   32/  265]
train() client id: f_00001-1-1 loss: 0.445389  [   64/  265]
train() client id: f_00001-1-2 loss: 0.577665  [   96/  265]
train() client id: f_00001-1-3 loss: 0.607648  [  128/  265]
train() client id: f_00001-1-4 loss: 0.460333  [  160/  265]
train() client id: f_00001-1-5 loss: 0.395385  [  192/  265]
train() client id: f_00001-1-6 loss: 0.447839  [  224/  265]
train() client id: f_00001-1-7 loss: 0.454562  [  256/  265]
train() client id: f_00001-2-0 loss: 0.450267  [   32/  265]
train() client id: f_00001-2-1 loss: 0.451403  [   64/  265]
train() client id: f_00001-2-2 loss: 0.370877  [   96/  265]
train() client id: f_00001-2-3 loss: 0.448407  [  128/  265]
train() client id: f_00001-2-4 loss: 0.507463  [  160/  265]
train() client id: f_00001-2-5 loss: 0.569845  [  192/  265]
train() client id: f_00001-2-6 loss: 0.391423  [  224/  265]
train() client id: f_00001-2-7 loss: 0.587516  [  256/  265]
train() client id: f_00001-3-0 loss: 0.442263  [   32/  265]
train() client id: f_00001-3-1 loss: 0.545569  [   64/  265]
train() client id: f_00001-3-2 loss: 0.400989  [   96/  265]
train() client id: f_00001-3-3 loss: 0.514795  [  128/  265]
train() client id: f_00001-3-4 loss: 0.514085  [  160/  265]
train() client id: f_00001-3-5 loss: 0.482688  [  192/  265]
train() client id: f_00001-3-6 loss: 0.425308  [  224/  265]
train() client id: f_00001-3-7 loss: 0.503853  [  256/  265]
train() client id: f_00001-4-0 loss: 0.470625  [   32/  265]
train() client id: f_00001-4-1 loss: 0.472961  [   64/  265]
train() client id: f_00001-4-2 loss: 0.524565  [   96/  265]
train() client id: f_00001-4-3 loss: 0.449669  [  128/  265]
train() client id: f_00001-4-4 loss: 0.394914  [  160/  265]
train() client id: f_00001-4-5 loss: 0.491142  [  192/  265]
train() client id: f_00001-4-6 loss: 0.616714  [  224/  265]
train() client id: f_00001-4-7 loss: 0.383495  [  256/  265]
train() client id: f_00001-5-0 loss: 0.554276  [   32/  265]
train() client id: f_00001-5-1 loss: 0.430640  [   64/  265]
train() client id: f_00001-5-2 loss: 0.480858  [   96/  265]
train() client id: f_00001-5-3 loss: 0.422825  [  128/  265]
train() client id: f_00001-5-4 loss: 0.472206  [  160/  265]
train() client id: f_00001-5-5 loss: 0.494136  [  192/  265]
train() client id: f_00001-5-6 loss: 0.425600  [  224/  265]
train() client id: f_00001-5-7 loss: 0.449753  [  256/  265]
train() client id: f_00001-6-0 loss: 0.436826  [   32/  265]
train() client id: f_00001-6-1 loss: 0.390771  [   64/  265]
train() client id: f_00001-6-2 loss: 0.624993  [   96/  265]
train() client id: f_00001-6-3 loss: 0.403802  [  128/  265]
train() client id: f_00001-6-4 loss: 0.612601  [  160/  265]
train() client id: f_00001-6-5 loss: 0.461024  [  192/  265]
train() client id: f_00001-6-6 loss: 0.404270  [  224/  265]
train() client id: f_00001-6-7 loss: 0.371545  [  256/  265]
train() client id: f_00001-7-0 loss: 0.474323  [   32/  265]
train() client id: f_00001-7-1 loss: 0.555452  [   64/  265]
train() client id: f_00001-7-2 loss: 0.409605  [   96/  265]
train() client id: f_00001-7-3 loss: 0.416619  [  128/  265]
train() client id: f_00001-7-4 loss: 0.398284  [  160/  265]
train() client id: f_00001-7-5 loss: 0.491299  [  192/  265]
train() client id: f_00001-7-6 loss: 0.377633  [  224/  265]
train() client id: f_00001-7-7 loss: 0.582072  [  256/  265]
train() client id: f_00001-8-0 loss: 0.385883  [   32/  265]
train() client id: f_00001-8-1 loss: 0.474900  [   64/  265]
train() client id: f_00001-8-2 loss: 0.550440  [   96/  265]
train() client id: f_00001-8-3 loss: 0.440101  [  128/  265]
train() client id: f_00001-8-4 loss: 0.507193  [  160/  265]
train() client id: f_00001-8-5 loss: 0.384926  [  192/  265]
train() client id: f_00001-8-6 loss: 0.417213  [  224/  265]
train() client id: f_00001-8-7 loss: 0.622499  [  256/  265]
train() client id: f_00001-9-0 loss: 0.509757  [   32/  265]
train() client id: f_00001-9-1 loss: 0.470480  [   64/  265]
train() client id: f_00001-9-2 loss: 0.422631  [   96/  265]
train() client id: f_00001-9-3 loss: 0.384050  [  128/  265]
train() client id: f_00001-9-4 loss: 0.633425  [  160/  265]
train() client id: f_00001-9-5 loss: 0.525867  [  192/  265]
train() client id: f_00001-9-6 loss: 0.459306  [  224/  265]
train() client id: f_00001-9-7 loss: 0.390624  [  256/  265]
train() client id: f_00001-10-0 loss: 0.449960  [   32/  265]
train() client id: f_00001-10-1 loss: 0.517511  [   64/  265]
train() client id: f_00001-10-2 loss: 0.571039  [   96/  265]
train() client id: f_00001-10-3 loss: 0.374831  [  128/  265]
train() client id: f_00001-10-4 loss: 0.511648  [  160/  265]
train() client id: f_00001-10-5 loss: 0.473954  [  192/  265]
train() client id: f_00001-10-6 loss: 0.467485  [  224/  265]
train() client id: f_00001-10-7 loss: 0.365944  [  256/  265]
train() client id: f_00001-11-0 loss: 0.438225  [   32/  265]
train() client id: f_00001-11-1 loss: 0.383214  [   64/  265]
train() client id: f_00001-11-2 loss: 0.385871  [   96/  265]
train() client id: f_00001-11-3 loss: 0.449586  [  128/  265]
train() client id: f_00001-11-4 loss: 0.491552  [  160/  265]
train() client id: f_00001-11-5 loss: 0.498907  [  192/  265]
train() client id: f_00001-11-6 loss: 0.593614  [  224/  265]
train() client id: f_00001-11-7 loss: 0.556471  [  256/  265]
train() client id: f_00001-12-0 loss: 0.428746  [   32/  265]
train() client id: f_00001-12-1 loss: 0.469718  [   64/  265]
train() client id: f_00001-12-2 loss: 0.493464  [   96/  265]
train() client id: f_00001-12-3 loss: 0.490860  [  128/  265]
train() client id: f_00001-12-4 loss: 0.466292  [  160/  265]
train() client id: f_00001-12-5 loss: 0.464176  [  192/  265]
train() client id: f_00001-12-6 loss: 0.460304  [  224/  265]
train() client id: f_00001-12-7 loss: 0.439023  [  256/  265]
train() client id: f_00002-0-0 loss: 1.176352  [   32/  124]
train() client id: f_00002-0-1 loss: 1.481909  [   64/  124]
train() client id: f_00002-0-2 loss: 1.296280  [   96/  124]
train() client id: f_00002-1-0 loss: 1.090078  [   32/  124]
train() client id: f_00002-1-1 loss: 1.157371  [   64/  124]
train() client id: f_00002-1-2 loss: 1.345701  [   96/  124]
train() client id: f_00002-2-0 loss: 1.074957  [   32/  124]
train() client id: f_00002-2-1 loss: 1.173718  [   64/  124]
train() client id: f_00002-2-2 loss: 1.030876  [   96/  124]
train() client id: f_00002-3-0 loss: 1.145882  [   32/  124]
train() client id: f_00002-3-1 loss: 1.180094  [   64/  124]
train() client id: f_00002-3-2 loss: 1.097847  [   96/  124]
train() client id: f_00002-4-0 loss: 1.168805  [   32/  124]
train() client id: f_00002-4-1 loss: 1.038259  [   64/  124]
train() client id: f_00002-4-2 loss: 1.070184  [   96/  124]
train() client id: f_00002-5-0 loss: 1.094201  [   32/  124]
train() client id: f_00002-5-1 loss: 1.005884  [   64/  124]
train() client id: f_00002-5-2 loss: 0.985535  [   96/  124]
train() client id: f_00002-6-0 loss: 1.002702  [   32/  124]
train() client id: f_00002-6-1 loss: 1.053311  [   64/  124]
train() client id: f_00002-6-2 loss: 1.131063  [   96/  124]
train() client id: f_00002-7-0 loss: 0.911612  [   32/  124]
train() client id: f_00002-7-1 loss: 1.205052  [   64/  124]
train() client id: f_00002-7-2 loss: 1.169246  [   96/  124]
train() client id: f_00002-8-0 loss: 0.967590  [   32/  124]
train() client id: f_00002-8-1 loss: 1.078746  [   64/  124]
train() client id: f_00002-8-2 loss: 0.982444  [   96/  124]
train() client id: f_00002-9-0 loss: 1.166059  [   32/  124]
train() client id: f_00002-9-1 loss: 0.946721  [   64/  124]
train() client id: f_00002-9-2 loss: 0.847868  [   96/  124]
train() client id: f_00002-10-0 loss: 1.179505  [   32/  124]
train() client id: f_00002-10-1 loss: 0.885868  [   64/  124]
train() client id: f_00002-10-2 loss: 0.832276  [   96/  124]
train() client id: f_00002-11-0 loss: 0.961518  [   32/  124]
train() client id: f_00002-11-1 loss: 1.061317  [   64/  124]
train() client id: f_00002-11-2 loss: 1.073729  [   96/  124]
train() client id: f_00002-12-0 loss: 0.846601  [   32/  124]
train() client id: f_00002-12-1 loss: 0.761129  [   64/  124]
train() client id: f_00002-12-2 loss: 1.209799  [   96/  124]
train() client id: f_00003-0-0 loss: 0.566941  [   32/   43]
train() client id: f_00003-1-0 loss: 0.579688  [   32/   43]
train() client id: f_00003-2-0 loss: 0.686528  [   32/   43]
train() client id: f_00003-3-0 loss: 0.615055  [   32/   43]
train() client id: f_00003-4-0 loss: 0.705601  [   32/   43]
train() client id: f_00003-5-0 loss: 0.755153  [   32/   43]
train() client id: f_00003-6-0 loss: 0.394760  [   32/   43]
train() client id: f_00003-7-0 loss: 0.854329  [   32/   43]
train() client id: f_00003-8-0 loss: 0.692644  [   32/   43]
train() client id: f_00003-9-0 loss: 0.463274  [   32/   43]
train() client id: f_00003-10-0 loss: 0.655408  [   32/   43]
train() client id: f_00003-11-0 loss: 0.480980  [   32/   43]
train() client id: f_00003-12-0 loss: 0.733422  [   32/   43]
train() client id: f_00004-0-0 loss: 0.822336  [   32/  306]
train() client id: f_00004-0-1 loss: 0.719993  [   64/  306]
train() client id: f_00004-0-2 loss: 0.771772  [   96/  306]
train() client id: f_00004-0-3 loss: 0.875125  [  128/  306]
train() client id: f_00004-0-4 loss: 0.758460  [  160/  306]
train() client id: f_00004-0-5 loss: 0.847589  [  192/  306]
train() client id: f_00004-0-6 loss: 0.690606  [  224/  306]
train() client id: f_00004-0-7 loss: 0.929628  [  256/  306]
train() client id: f_00004-0-8 loss: 0.836520  [  288/  306]
train() client id: f_00004-1-0 loss: 0.840715  [   32/  306]
train() client id: f_00004-1-1 loss: 0.712051  [   64/  306]
train() client id: f_00004-1-2 loss: 0.819519  [   96/  306]
train() client id: f_00004-1-3 loss: 0.712835  [  128/  306]
train() client id: f_00004-1-4 loss: 0.879614  [  160/  306]
train() client id: f_00004-1-5 loss: 0.811739  [  192/  306]
train() client id: f_00004-1-6 loss: 0.696125  [  224/  306]
train() client id: f_00004-1-7 loss: 0.866429  [  256/  306]
train() client id: f_00004-1-8 loss: 0.844563  [  288/  306]
train() client id: f_00004-2-0 loss: 0.855146  [   32/  306]
train() client id: f_00004-2-1 loss: 0.867561  [   64/  306]
train() client id: f_00004-2-2 loss: 0.814269  [   96/  306]
train() client id: f_00004-2-3 loss: 0.694920  [  128/  306]
train() client id: f_00004-2-4 loss: 0.828712  [  160/  306]
train() client id: f_00004-2-5 loss: 0.712082  [  192/  306]
train() client id: f_00004-2-6 loss: 0.738570  [  224/  306]
train() client id: f_00004-2-7 loss: 0.869921  [  256/  306]
train() client id: f_00004-2-8 loss: 0.727243  [  288/  306]
train() client id: f_00004-3-0 loss: 0.764322  [   32/  306]
train() client id: f_00004-3-1 loss: 0.806624  [   64/  306]
train() client id: f_00004-3-2 loss: 0.726539  [   96/  306]
train() client id: f_00004-3-3 loss: 0.682466  [  128/  306]
train() client id: f_00004-3-4 loss: 0.867468  [  160/  306]
train() client id: f_00004-3-5 loss: 0.895589  [  192/  306]
train() client id: f_00004-3-6 loss: 0.675237  [  224/  306]
train() client id: f_00004-3-7 loss: 0.823079  [  256/  306]
train() client id: f_00004-3-8 loss: 0.894655  [  288/  306]
train() client id: f_00004-4-0 loss: 0.813493  [   32/  306]
train() client id: f_00004-4-1 loss: 0.752978  [   64/  306]
train() client id: f_00004-4-2 loss: 0.837030  [   96/  306]
train() client id: f_00004-4-3 loss: 0.660533  [  128/  306]
train() client id: f_00004-4-4 loss: 0.951074  [  160/  306]
train() client id: f_00004-4-5 loss: 0.747189  [  192/  306]
train() client id: f_00004-4-6 loss: 0.782184  [  224/  306]
train() client id: f_00004-4-7 loss: 0.803155  [  256/  306]
train() client id: f_00004-4-8 loss: 0.745574  [  288/  306]
train() client id: f_00004-5-0 loss: 0.767577  [   32/  306]
train() client id: f_00004-5-1 loss: 0.636405  [   64/  306]
train() client id: f_00004-5-2 loss: 0.809761  [   96/  306]
train() client id: f_00004-5-3 loss: 0.715439  [  128/  306]
train() client id: f_00004-5-4 loss: 0.823932  [  160/  306]
train() client id: f_00004-5-5 loss: 0.941858  [  192/  306]
train() client id: f_00004-5-6 loss: 0.772176  [  224/  306]
train() client id: f_00004-5-7 loss: 0.778901  [  256/  306]
train() client id: f_00004-5-8 loss: 0.867097  [  288/  306]
train() client id: f_00004-6-0 loss: 0.775672  [   32/  306]
train() client id: f_00004-6-1 loss: 0.835451  [   64/  306]
train() client id: f_00004-6-2 loss: 0.811949  [   96/  306]
train() client id: f_00004-6-3 loss: 0.791555  [  128/  306]
train() client id: f_00004-6-4 loss: 0.661036  [  160/  306]
train() client id: f_00004-6-5 loss: 0.790256  [  192/  306]
train() client id: f_00004-6-6 loss: 0.785702  [  224/  306]
train() client id: f_00004-6-7 loss: 0.734362  [  256/  306]
train() client id: f_00004-6-8 loss: 0.823908  [  288/  306]
train() client id: f_00004-7-0 loss: 0.714176  [   32/  306]
train() client id: f_00004-7-1 loss: 0.734949  [   64/  306]
train() client id: f_00004-7-2 loss: 0.877158  [   96/  306]
train() client id: f_00004-7-3 loss: 0.689696  [  128/  306]
train() client id: f_00004-7-4 loss: 0.869246  [  160/  306]
train() client id: f_00004-7-5 loss: 0.829731  [  192/  306]
train() client id: f_00004-7-6 loss: 0.757557  [  224/  306]
train() client id: f_00004-7-7 loss: 0.902832  [  256/  306]
train() client id: f_00004-7-8 loss: 0.763459  [  288/  306]
train() client id: f_00004-8-0 loss: 0.796987  [   32/  306]
train() client id: f_00004-8-1 loss: 0.887992  [   64/  306]
train() client id: f_00004-8-2 loss: 0.765076  [   96/  306]
train() client id: f_00004-8-3 loss: 0.895781  [  128/  306]
train() client id: f_00004-8-4 loss: 0.846244  [  160/  306]
train() client id: f_00004-8-5 loss: 0.741167  [  192/  306]
train() client id: f_00004-8-6 loss: 0.739401  [  224/  306]
train() client id: f_00004-8-7 loss: 0.794816  [  256/  306]
train() client id: f_00004-8-8 loss: 0.632065  [  288/  306]
train() client id: f_00004-9-0 loss: 0.688790  [   32/  306]
train() client id: f_00004-9-1 loss: 0.746309  [   64/  306]
train() client id: f_00004-9-2 loss: 0.802111  [   96/  306]
train() client id: f_00004-9-3 loss: 0.772280  [  128/  306]
train() client id: f_00004-9-4 loss: 0.903659  [  160/  306]
train() client id: f_00004-9-5 loss: 0.883260  [  192/  306]
train() client id: f_00004-9-6 loss: 0.751743  [  224/  306]
train() client id: f_00004-9-7 loss: 0.777563  [  256/  306]
train() client id: f_00004-9-8 loss: 0.819593  [  288/  306]
train() client id: f_00004-10-0 loss: 0.764270  [   32/  306]
train() client id: f_00004-10-1 loss: 0.730631  [   64/  306]
train() client id: f_00004-10-2 loss: 0.732067  [   96/  306]
train() client id: f_00004-10-3 loss: 0.818383  [  128/  306]
train() client id: f_00004-10-4 loss: 0.836689  [  160/  306]
train() client id: f_00004-10-5 loss: 0.795827  [  192/  306]
train() client id: f_00004-10-6 loss: 0.741197  [  224/  306]
train() client id: f_00004-10-7 loss: 0.847586  [  256/  306]
train() client id: f_00004-10-8 loss: 0.750477  [  288/  306]
train() client id: f_00004-11-0 loss: 0.748710  [   32/  306]
train() client id: f_00004-11-1 loss: 0.621412  [   64/  306]
train() client id: f_00004-11-2 loss: 0.803769  [   96/  306]
train() client id: f_00004-11-3 loss: 0.687187  [  128/  306]
train() client id: f_00004-11-4 loss: 1.046063  [  160/  306]
train() client id: f_00004-11-5 loss: 0.863670  [  192/  306]
train() client id: f_00004-11-6 loss: 0.917226  [  224/  306]
train() client id: f_00004-11-7 loss: 0.658332  [  256/  306]
train() client id: f_00004-11-8 loss: 0.695717  [  288/  306]
train() client id: f_00004-12-0 loss: 0.686263  [   32/  306]
train() client id: f_00004-12-1 loss: 0.825848  [   64/  306]
train() client id: f_00004-12-2 loss: 0.807699  [   96/  306]
train() client id: f_00004-12-3 loss: 0.878930  [  128/  306]
train() client id: f_00004-12-4 loss: 0.764884  [  160/  306]
train() client id: f_00004-12-5 loss: 0.848994  [  192/  306]
train() client id: f_00004-12-6 loss: 0.835769  [  224/  306]
train() client id: f_00004-12-7 loss: 0.768311  [  256/  306]
train() client id: f_00004-12-8 loss: 0.685924  [  288/  306]
train() client id: f_00005-0-0 loss: 0.655736  [   32/  146]
train() client id: f_00005-0-1 loss: 0.746992  [   64/  146]
train() client id: f_00005-0-2 loss: 0.428817  [   96/  146]
train() client id: f_00005-0-3 loss: 0.704654  [  128/  146]
train() client id: f_00005-1-0 loss: 0.784430  [   32/  146]
train() client id: f_00005-1-1 loss: 0.742018  [   64/  146]
train() client id: f_00005-1-2 loss: 0.446183  [   96/  146]
train() client id: f_00005-1-3 loss: 0.732568  [  128/  146]
train() client id: f_00005-2-0 loss: 0.553007  [   32/  146]
train() client id: f_00005-2-1 loss: 0.565806  [   64/  146]
train() client id: f_00005-2-2 loss: 0.741064  [   96/  146]
train() client id: f_00005-2-3 loss: 0.682243  [  128/  146]
train() client id: f_00005-3-0 loss: 0.715707  [   32/  146]
train() client id: f_00005-3-1 loss: 0.522987  [   64/  146]
train() client id: f_00005-3-2 loss: 0.778323  [   96/  146]
train() client id: f_00005-3-3 loss: 0.681193  [  128/  146]
train() client id: f_00005-4-0 loss: 0.528436  [   32/  146]
train() client id: f_00005-4-1 loss: 0.829419  [   64/  146]
train() client id: f_00005-4-2 loss: 0.548392  [   96/  146]
train() client id: f_00005-4-3 loss: 0.735702  [  128/  146]
train() client id: f_00005-5-0 loss: 0.695543  [   32/  146]
train() client id: f_00005-5-1 loss: 0.844721  [   64/  146]
train() client id: f_00005-5-2 loss: 0.598258  [   96/  146]
train() client id: f_00005-5-3 loss: 0.552454  [  128/  146]
train() client id: f_00005-6-0 loss: 0.672302  [   32/  146]
train() client id: f_00005-6-1 loss: 0.811886  [   64/  146]
train() client id: f_00005-6-2 loss: 0.458192  [   96/  146]
train() client id: f_00005-6-3 loss: 0.765617  [  128/  146]
train() client id: f_00005-7-0 loss: 0.399041  [   32/  146]
train() client id: f_00005-7-1 loss: 0.634447  [   64/  146]
train() client id: f_00005-7-2 loss: 0.896265  [   96/  146]
train() client id: f_00005-7-3 loss: 0.431583  [  128/  146]
train() client id: f_00005-8-0 loss: 0.384566  [   32/  146]
train() client id: f_00005-8-1 loss: 0.650158  [   64/  146]
train() client id: f_00005-8-2 loss: 0.787961  [   96/  146]
train() client id: f_00005-8-3 loss: 0.686087  [  128/  146]
train() client id: f_00005-9-0 loss: 0.637083  [   32/  146]
train() client id: f_00005-9-1 loss: 0.755281  [   64/  146]
train() client id: f_00005-9-2 loss: 0.646425  [   96/  146]
train() client id: f_00005-9-3 loss: 0.483573  [  128/  146]
train() client id: f_00005-10-0 loss: 0.604263  [   32/  146]
train() client id: f_00005-10-1 loss: 0.664126  [   64/  146]
train() client id: f_00005-10-2 loss: 0.648815  [   96/  146]
train() client id: f_00005-10-3 loss: 0.496169  [  128/  146]
train() client id: f_00005-11-0 loss: 0.550015  [   32/  146]
train() client id: f_00005-11-1 loss: 0.434771  [   64/  146]
train() client id: f_00005-11-2 loss: 0.790812  [   96/  146]
train() client id: f_00005-11-3 loss: 0.804748  [  128/  146]
train() client id: f_00005-12-0 loss: 0.752683  [   32/  146]
train() client id: f_00005-12-1 loss: 0.809779  [   64/  146]
train() client id: f_00005-12-2 loss: 0.538725  [   96/  146]
train() client id: f_00005-12-3 loss: 0.570360  [  128/  146]
train() client id: f_00006-0-0 loss: 0.402117  [   32/   54]
train() client id: f_00006-1-0 loss: 0.414784  [   32/   54]
train() client id: f_00006-2-0 loss: 0.458730  [   32/   54]
train() client id: f_00006-3-0 loss: 0.423955  [   32/   54]
train() client id: f_00006-4-0 loss: 0.384344  [   32/   54]
train() client id: f_00006-5-0 loss: 0.379757  [   32/   54]
train() client id: f_00006-6-0 loss: 0.494720  [   32/   54]
train() client id: f_00006-7-0 loss: 0.486965  [   32/   54]
train() client id: f_00006-8-0 loss: 0.467555  [   32/   54]
train() client id: f_00006-9-0 loss: 0.438453  [   32/   54]
train() client id: f_00006-10-0 loss: 0.437792  [   32/   54]
train() client id: f_00006-11-0 loss: 0.429829  [   32/   54]
train() client id: f_00006-12-0 loss: 0.480201  [   32/   54]
train() client id: f_00007-0-0 loss: 0.599941  [   32/  179]
train() client id: f_00007-0-1 loss: 0.658951  [   64/  179]
train() client id: f_00007-0-2 loss: 0.814388  [   96/  179]
train() client id: f_00007-0-3 loss: 0.869852  [  128/  179]
train() client id: f_00007-0-4 loss: 0.779903  [  160/  179]
train() client id: f_00007-1-0 loss: 0.805569  [   32/  179]
train() client id: f_00007-1-1 loss: 0.521740  [   64/  179]
train() client id: f_00007-1-2 loss: 0.720623  [   96/  179]
train() client id: f_00007-1-3 loss: 1.016769  [  128/  179]
train() client id: f_00007-1-4 loss: 0.609979  [  160/  179]
train() client id: f_00007-2-0 loss: 0.853502  [   32/  179]
train() client id: f_00007-2-1 loss: 0.765352  [   64/  179]
train() client id: f_00007-2-2 loss: 0.706612  [   96/  179]
train() client id: f_00007-2-3 loss: 0.611746  [  128/  179]
train() client id: f_00007-2-4 loss: 0.698490  [  160/  179]
train() client id: f_00007-3-0 loss: 0.557556  [   32/  179]
train() client id: f_00007-3-1 loss: 0.678205  [   64/  179]
train() client id: f_00007-3-2 loss: 0.601236  [   96/  179]
train() client id: f_00007-3-3 loss: 0.799891  [  128/  179]
train() client id: f_00007-3-4 loss: 0.954991  [  160/  179]
train() client id: f_00007-4-0 loss: 0.652086  [   32/  179]
train() client id: f_00007-4-1 loss: 0.644513  [   64/  179]
train() client id: f_00007-4-2 loss: 0.595134  [   96/  179]
train() client id: f_00007-4-3 loss: 0.807963  [  128/  179]
train() client id: f_00007-4-4 loss: 0.655981  [  160/  179]
train() client id: f_00007-5-0 loss: 0.703430  [   32/  179]
train() client id: f_00007-5-1 loss: 0.855721  [   64/  179]
train() client id: f_00007-5-2 loss: 0.697601  [   96/  179]
train() client id: f_00007-5-3 loss: 0.723378  [  128/  179]
train() client id: f_00007-5-4 loss: 0.527500  [  160/  179]
train() client id: f_00007-6-0 loss: 0.842436  [   32/  179]
train() client id: f_00007-6-1 loss: 0.526704  [   64/  179]
train() client id: f_00007-6-2 loss: 0.559647  [   96/  179]
train() client id: f_00007-6-3 loss: 0.603411  [  128/  179]
train() client id: f_00007-6-4 loss: 0.823129  [  160/  179]
train() client id: f_00007-7-0 loss: 0.814344  [   32/  179]
train() client id: f_00007-7-1 loss: 0.590604  [   64/  179]
train() client id: f_00007-7-2 loss: 0.583468  [   96/  179]
train() client id: f_00007-7-3 loss: 0.631644  [  128/  179]
train() client id: f_00007-7-4 loss: 0.860625  [  160/  179]
train() client id: f_00007-8-0 loss: 0.719805  [   32/  179]
train() client id: f_00007-8-1 loss: 0.754663  [   64/  179]
train() client id: f_00007-8-2 loss: 0.532293  [   96/  179]
train() client id: f_00007-8-3 loss: 0.545864  [  128/  179]
train() client id: f_00007-8-4 loss: 0.810713  [  160/  179]
train() client id: f_00007-9-0 loss: 0.897478  [   32/  179]
train() client id: f_00007-9-1 loss: 0.630196  [   64/  179]
train() client id: f_00007-9-2 loss: 0.625178  [   96/  179]
train() client id: f_00007-9-3 loss: 0.650858  [  128/  179]
train() client id: f_00007-9-4 loss: 0.607410  [  160/  179]
train() client id: f_00007-10-0 loss: 0.636761  [   32/  179]
train() client id: f_00007-10-1 loss: 0.608705  [   64/  179]
train() client id: f_00007-10-2 loss: 0.908519  [   96/  179]
train() client id: f_00007-10-3 loss: 0.697081  [  128/  179]
train() client id: f_00007-10-4 loss: 0.644340  [  160/  179]
train() client id: f_00007-11-0 loss: 0.555443  [   32/  179]
train() client id: f_00007-11-1 loss: 0.526288  [   64/  179]
train() client id: f_00007-11-2 loss: 0.787772  [   96/  179]
train() client id: f_00007-11-3 loss: 0.981972  [  128/  179]
train() client id: f_00007-11-4 loss: 0.685291  [  160/  179]
train() client id: f_00007-12-0 loss: 0.720218  [   32/  179]
train() client id: f_00007-12-1 loss: 0.727969  [   64/  179]
train() client id: f_00007-12-2 loss: 0.910873  [   96/  179]
train() client id: f_00007-12-3 loss: 0.575246  [  128/  179]
train() client id: f_00007-12-4 loss: 0.612305  [  160/  179]
train() client id: f_00008-0-0 loss: 0.764419  [   32/  130]
train() client id: f_00008-0-1 loss: 0.704205  [   64/  130]
train() client id: f_00008-0-2 loss: 0.768031  [   96/  130]
train() client id: f_00008-0-3 loss: 0.781967  [  128/  130]
train() client id: f_00008-1-0 loss: 0.759339  [   32/  130]
train() client id: f_00008-1-1 loss: 0.796349  [   64/  130]
train() client id: f_00008-1-2 loss: 0.757729  [   96/  130]
train() client id: f_00008-1-3 loss: 0.648041  [  128/  130]
train() client id: f_00008-2-0 loss: 0.798359  [   32/  130]
train() client id: f_00008-2-1 loss: 0.677322  [   64/  130]
train() client id: f_00008-2-2 loss: 0.791759  [   96/  130]
train() client id: f_00008-2-3 loss: 0.712730  [  128/  130]
train() client id: f_00008-3-0 loss: 0.808418  [   32/  130]
train() client id: f_00008-3-1 loss: 0.791906  [   64/  130]
train() client id: f_00008-3-2 loss: 0.780406  [   96/  130]
train() client id: f_00008-3-3 loss: 0.618179  [  128/  130]
train() client id: f_00008-4-0 loss: 0.666701  [   32/  130]
train() client id: f_00008-4-1 loss: 0.671736  [   64/  130]
train() client id: f_00008-4-2 loss: 0.803638  [   96/  130]
train() client id: f_00008-4-3 loss: 0.805679  [  128/  130]
train() client id: f_00008-5-0 loss: 0.713200  [   32/  130]
train() client id: f_00008-5-1 loss: 0.732828  [   64/  130]
train() client id: f_00008-5-2 loss: 0.797134  [   96/  130]
train() client id: f_00008-5-3 loss: 0.754905  [  128/  130]
train() client id: f_00008-6-0 loss: 0.723386  [   32/  130]
train() client id: f_00008-6-1 loss: 0.799797  [   64/  130]
train() client id: f_00008-6-2 loss: 0.775710  [   96/  130]
train() client id: f_00008-6-3 loss: 0.691423  [  128/  130]
train() client id: f_00008-7-0 loss: 0.728443  [   32/  130]
train() client id: f_00008-7-1 loss: 0.722217  [   64/  130]
train() client id: f_00008-7-2 loss: 0.721587  [   96/  130]
train() client id: f_00008-7-3 loss: 0.831264  [  128/  130]
train() client id: f_00008-8-0 loss: 0.888935  [   32/  130]
train() client id: f_00008-8-1 loss: 0.649702  [   64/  130]
train() client id: f_00008-8-2 loss: 0.744432  [   96/  130]
train() client id: f_00008-8-3 loss: 0.711328  [  128/  130]
train() client id: f_00008-9-0 loss: 0.813751  [   32/  130]
train() client id: f_00008-9-1 loss: 0.740961  [   64/  130]
train() client id: f_00008-9-2 loss: 0.702324  [   96/  130]
train() client id: f_00008-9-3 loss: 0.735603  [  128/  130]
train() client id: f_00008-10-0 loss: 0.621609  [   32/  130]
train() client id: f_00008-10-1 loss: 0.613501  [   64/  130]
train() client id: f_00008-10-2 loss: 0.906931  [   96/  130]
train() client id: f_00008-10-3 loss: 0.865233  [  128/  130]
train() client id: f_00008-11-0 loss: 0.629350  [   32/  130]
train() client id: f_00008-11-1 loss: 0.890892  [   64/  130]
train() client id: f_00008-11-2 loss: 0.670393  [   96/  130]
train() client id: f_00008-11-3 loss: 0.817564  [  128/  130]
train() client id: f_00008-12-0 loss: 0.723469  [   32/  130]
train() client id: f_00008-12-1 loss: 0.853252  [   64/  130]
train() client id: f_00008-12-2 loss: 0.653527  [   96/  130]
train() client id: f_00008-12-3 loss: 0.756943  [  128/  130]
train() client id: f_00009-0-0 loss: 1.058726  [   32/  118]
train() client id: f_00009-0-1 loss: 0.941092  [   64/  118]
train() client id: f_00009-0-2 loss: 1.050886  [   96/  118]
train() client id: f_00009-1-0 loss: 0.830774  [   32/  118]
train() client id: f_00009-1-1 loss: 1.014724  [   64/  118]
train() client id: f_00009-1-2 loss: 0.939458  [   96/  118]
train() client id: f_00009-2-0 loss: 0.930671  [   32/  118]
train() client id: f_00009-2-1 loss: 0.915352  [   64/  118]
train() client id: f_00009-2-2 loss: 0.862179  [   96/  118]
train() client id: f_00009-3-0 loss: 0.875038  [   32/  118]
train() client id: f_00009-3-1 loss: 0.956581  [   64/  118]
train() client id: f_00009-3-2 loss: 0.743318  [   96/  118]
train() client id: f_00009-4-0 loss: 0.843517  [   32/  118]
train() client id: f_00009-4-1 loss: 0.698130  [   64/  118]
train() client id: f_00009-4-2 loss: 0.705451  [   96/  118]
train() client id: f_00009-5-0 loss: 0.750181  [   32/  118]
train() client id: f_00009-5-1 loss: 0.800240  [   64/  118]
train() client id: f_00009-5-2 loss: 0.860387  [   96/  118]
train() client id: f_00009-6-0 loss: 0.675795  [   32/  118]
train() client id: f_00009-6-1 loss: 0.694527  [   64/  118]
train() client id: f_00009-6-2 loss: 0.796854  [   96/  118]
train() client id: f_00009-7-0 loss: 0.666077  [   32/  118]
train() client id: f_00009-7-1 loss: 0.623207  [   64/  118]
train() client id: f_00009-7-2 loss: 0.801670  [   96/  118]
train() client id: f_00009-8-0 loss: 0.577210  [   32/  118]
train() client id: f_00009-8-1 loss: 0.806426  [   64/  118]
train() client id: f_00009-8-2 loss: 0.721825  [   96/  118]
train() client id: f_00009-9-0 loss: 0.564823  [   32/  118]
train() client id: f_00009-9-1 loss: 0.746618  [   64/  118]
train() client id: f_00009-9-2 loss: 0.652250  [   96/  118]
train() client id: f_00009-10-0 loss: 0.581463  [   32/  118]
train() client id: f_00009-10-1 loss: 0.799353  [   64/  118]
train() client id: f_00009-10-2 loss: 0.553671  [   96/  118]
train() client id: f_00009-11-0 loss: 0.671361  [   32/  118]
train() client id: f_00009-11-1 loss: 0.740357  [   64/  118]
train() client id: f_00009-11-2 loss: 0.505372  [   96/  118]
train() client id: f_00009-12-0 loss: 0.608103  [   32/  118]
train() client id: f_00009-12-1 loss: 0.544442  [   64/  118]
train() client id: f_00009-12-2 loss: 0.722554  [   96/  118]
At round 57 accuracy: 0.6392572944297082
At round 57 training accuracy: 0.5942320590207915
At round 57 training loss: 0.8239274052824354
gradient difference: 0.43980923295021057
train() client id: f_00000-0-0 loss: 1.260722  [   32/  126]
train() client id: f_00000-0-1 loss: 1.169188  [   64/  126]
train() client id: f_00000-0-2 loss: 1.298073  [   96/  126]
train() client id: f_00000-1-0 loss: 1.086211  [   32/  126]
train() client id: f_00000-1-1 loss: 1.189954  [   64/  126]
train() client id: f_00000-1-2 loss: 1.156412  [   96/  126]
train() client id: f_00000-2-0 loss: 1.049861  [   32/  126]
train() client id: f_00000-2-1 loss: 1.068106  [   64/  126]
train() client id: f_00000-2-2 loss: 1.160949  [   96/  126]
train() client id: f_00000-3-0 loss: 1.031800  [   32/  126]
train() client id: f_00000-3-1 loss: 0.985528  [   64/  126]
train() client id: f_00000-3-2 loss: 1.117261  [   96/  126]
train() client id: f_00000-4-0 loss: 0.971992  [   32/  126]
train() client id: f_00000-4-1 loss: 0.962453  [   64/  126]
train() client id: f_00000-4-2 loss: 1.011701  [   96/  126]
train() client id: f_00000-5-0 loss: 0.979198  [   32/  126]
train() client id: f_00000-5-1 loss: 0.962347  [   64/  126]
train() client id: f_00000-5-2 loss: 1.114804  [   96/  126]
train() client id: f_00000-6-0 loss: 1.042853  [   32/  126]
train() client id: f_00000-6-1 loss: 0.960634  [   64/  126]
train() client id: f_00000-6-2 loss: 0.948617  [   96/  126]
train() client id: f_00000-7-0 loss: 0.902932  [   32/  126]
train() client id: f_00000-7-1 loss: 0.817104  [   64/  126]
train() client id: f_00000-7-2 loss: 1.031251  [   96/  126]
train() client id: f_00000-8-0 loss: 0.890197  [   32/  126]
train() client id: f_00000-8-1 loss: 0.995693  [   64/  126]
train() client id: f_00000-8-2 loss: 0.832301  [   96/  126]
train() client id: f_00000-9-0 loss: 0.900412  [   32/  126]
train() client id: f_00000-9-1 loss: 1.070883  [   64/  126]
train() client id: f_00000-9-2 loss: 0.805185  [   96/  126]
train() client id: f_00000-10-0 loss: 0.843076  [   32/  126]
train() client id: f_00000-10-1 loss: 0.973683  [   64/  126]
train() client id: f_00000-10-2 loss: 0.911404  [   96/  126]
train() client id: f_00000-11-0 loss: 1.031133  [   32/  126]
train() client id: f_00000-11-1 loss: 0.968813  [   64/  126]
train() client id: f_00000-11-2 loss: 0.814476  [   96/  126]
train() client id: f_00000-12-0 loss: 1.039401  [   32/  126]
train() client id: f_00000-12-1 loss: 0.960810  [   64/  126]
train() client id: f_00000-12-2 loss: 0.838953  [   96/  126]
train() client id: f_00001-0-0 loss: 0.555743  [   32/  265]
train() client id: f_00001-0-1 loss: 0.601909  [   64/  265]
train() client id: f_00001-0-2 loss: 0.440019  [   96/  265]
train() client id: f_00001-0-3 loss: 0.374982  [  128/  265]
train() client id: f_00001-0-4 loss: 0.477595  [  160/  265]
train() client id: f_00001-0-5 loss: 0.447237  [  192/  265]
train() client id: f_00001-0-6 loss: 0.393151  [  224/  265]
train() client id: f_00001-0-7 loss: 0.385803  [  256/  265]
train() client id: f_00001-1-0 loss: 0.509084  [   32/  265]
train() client id: f_00001-1-1 loss: 0.539130  [   64/  265]
train() client id: f_00001-1-2 loss: 0.387729  [   96/  265]
train() client id: f_00001-1-3 loss: 0.394385  [  128/  265]
train() client id: f_00001-1-4 loss: 0.473447  [  160/  265]
train() client id: f_00001-1-5 loss: 0.431532  [  192/  265]
train() client id: f_00001-1-6 loss: 0.468850  [  224/  265]
train() client id: f_00001-1-7 loss: 0.352710  [  256/  265]
train() client id: f_00001-2-0 loss: 0.346877  [   32/  265]
train() client id: f_00001-2-1 loss: 0.563401  [   64/  265]
train() client id: f_00001-2-2 loss: 0.466793  [   96/  265]
train() client id: f_00001-2-3 loss: 0.506585  [  128/  265]
train() client id: f_00001-2-4 loss: 0.428135  [  160/  265]
train() client id: f_00001-2-5 loss: 0.413278  [  192/  265]
train() client id: f_00001-2-6 loss: 0.406128  [  224/  265]
train() client id: f_00001-2-7 loss: 0.423648  [  256/  265]
train() client id: f_00001-3-0 loss: 0.427975  [   32/  265]
train() client id: f_00001-3-1 loss: 0.344708  [   64/  265]
train() client id: f_00001-3-2 loss: 0.492023  [   96/  265]
train() client id: f_00001-3-3 loss: 0.472286  [  128/  265]
train() client id: f_00001-3-4 loss: 0.540530  [  160/  265]
train() client id: f_00001-3-5 loss: 0.509133  [  192/  265]
train() client id: f_00001-3-6 loss: 0.340749  [  224/  265]
train() client id: f_00001-3-7 loss: 0.392490  [  256/  265]
train() client id: f_00001-4-0 loss: 0.421429  [   32/  265]
train() client id: f_00001-4-1 loss: 0.420119  [   64/  265]
train() client id: f_00001-4-2 loss: 0.450692  [   96/  265]
train() client id: f_00001-4-3 loss: 0.508952  [  128/  265]
train() client id: f_00001-4-4 loss: 0.421551  [  160/  265]
train() client id: f_00001-4-5 loss: 0.345530  [  192/  265]
train() client id: f_00001-4-6 loss: 0.405591  [  224/  265]
train() client id: f_00001-4-7 loss: 0.514491  [  256/  265]
train() client id: f_00001-5-0 loss: 0.410682  [   32/  265]
train() client id: f_00001-5-1 loss: 0.490003  [   64/  265]
train() client id: f_00001-5-2 loss: 0.470739  [   96/  265]
train() client id: f_00001-5-3 loss: 0.362172  [  128/  265]
train() client id: f_00001-5-4 loss: 0.633894  [  160/  265]
train() client id: f_00001-5-5 loss: 0.403081  [  192/  265]
train() client id: f_00001-5-6 loss: 0.348545  [  224/  265]
train() client id: f_00001-5-7 loss: 0.349522  [  256/  265]
train() client id: f_00001-6-0 loss: 0.579045  [   32/  265]
train() client id: f_00001-6-1 loss: 0.428056  [   64/  265]
train() client id: f_00001-6-2 loss: 0.330483  [   96/  265]
train() client id: f_00001-6-3 loss: 0.460788  [  128/  265]
train() client id: f_00001-6-4 loss: 0.395576  [  160/  265]
train() client id: f_00001-6-5 loss: 0.368921  [  192/  265]
train() client id: f_00001-6-6 loss: 0.494479  [  224/  265]
train() client id: f_00001-6-7 loss: 0.403067  [  256/  265]
train() client id: f_00001-7-0 loss: 0.336620  [   32/  265]
train() client id: f_00001-7-1 loss: 0.401729  [   64/  265]
train() client id: f_00001-7-2 loss: 0.335301  [   96/  265]
train() client id: f_00001-7-3 loss: 0.507315  [  128/  265]
train() client id: f_00001-7-4 loss: 0.533026  [  160/  265]
train() client id: f_00001-7-5 loss: 0.355466  [  192/  265]
train() client id: f_00001-7-6 loss: 0.470486  [  224/  265]
train() client id: f_00001-7-7 loss: 0.496374  [  256/  265]
train() client id: f_00001-8-0 loss: 0.337696  [   32/  265]
train() client id: f_00001-8-1 loss: 0.449641  [   64/  265]
train() client id: f_00001-8-2 loss: 0.319561  [   96/  265]
train() client id: f_00001-8-3 loss: 0.562195  [  128/  265]
train() client id: f_00001-8-4 loss: 0.377418  [  160/  265]
train() client id: f_00001-8-5 loss: 0.414290  [  192/  265]
train() client id: f_00001-8-6 loss: 0.415721  [  224/  265]
train() client id: f_00001-8-7 loss: 0.553813  [  256/  265]
train() client id: f_00001-9-0 loss: 0.400206  [   32/  265]
train() client id: f_00001-9-1 loss: 0.639224  [   64/  265]
train() client id: f_00001-9-2 loss: 0.471257  [   96/  265]
train() client id: f_00001-9-3 loss: 0.470672  [  128/  265]
train() client id: f_00001-9-4 loss: 0.363281  [  160/  265]
train() client id: f_00001-9-5 loss: 0.367459  [  192/  265]
train() client id: f_00001-9-6 loss: 0.382334  [  224/  265]
train() client id: f_00001-9-7 loss: 0.346216  [  256/  265]
train() client id: f_00001-10-0 loss: 0.480249  [   32/  265]
train() client id: f_00001-10-1 loss: 0.400173  [   64/  265]
train() client id: f_00001-10-2 loss: 0.512609  [   96/  265]
train() client id: f_00001-10-3 loss: 0.441202  [  128/  265]
train() client id: f_00001-10-4 loss: 0.556462  [  160/  265]
train() client id: f_00001-10-5 loss: 0.351045  [  192/  265]
train() client id: f_00001-10-6 loss: 0.378876  [  224/  265]
train() client id: f_00001-10-7 loss: 0.317246  [  256/  265]
train() client id: f_00001-11-0 loss: 0.384469  [   32/  265]
train() client id: f_00001-11-1 loss: 0.357157  [   64/  265]
train() client id: f_00001-11-2 loss: 0.434947  [   96/  265]
train() client id: f_00001-11-3 loss: 0.478706  [  128/  265]
train() client id: f_00001-11-4 loss: 0.447741  [  160/  265]
train() client id: f_00001-11-5 loss: 0.350431  [  192/  265]
train() client id: f_00001-11-6 loss: 0.406431  [  224/  265]
train() client id: f_00001-11-7 loss: 0.555721  [  256/  265]
train() client id: f_00001-12-0 loss: 0.389805  [   32/  265]
train() client id: f_00001-12-1 loss: 0.324819  [   64/  265]
train() client id: f_00001-12-2 loss: 0.420952  [   96/  265]
train() client id: f_00001-12-3 loss: 0.443502  [  128/  265]
train() client id: f_00001-12-4 loss: 0.566731  [  160/  265]
train() client id: f_00001-12-5 loss: 0.372661  [  192/  265]
train() client id: f_00001-12-6 loss: 0.473298  [  224/  265]
train() client id: f_00001-12-7 loss: 0.413654  [  256/  265]
train() client id: f_00002-0-0 loss: 0.894603  [   32/  124]
train() client id: f_00002-0-1 loss: 0.910251  [   64/  124]
train() client id: f_00002-0-2 loss: 0.867915  [   96/  124]
train() client id: f_00002-1-0 loss: 0.886675  [   32/  124]
train() client id: f_00002-1-1 loss: 0.815321  [   64/  124]
train() client id: f_00002-1-2 loss: 0.867030  [   96/  124]
train() client id: f_00002-2-0 loss: 0.942351  [   32/  124]
train() client id: f_00002-2-1 loss: 0.976300  [   64/  124]
train() client id: f_00002-2-2 loss: 0.728601  [   96/  124]
train() client id: f_00002-3-0 loss: 0.809077  [   32/  124]
train() client id: f_00002-3-1 loss: 0.699559  [   64/  124]
train() client id: f_00002-3-2 loss: 0.802293  [   96/  124]
train() client id: f_00002-4-0 loss: 0.831582  [   32/  124]
train() client id: f_00002-4-1 loss: 0.629964  [   64/  124]
train() client id: f_00002-4-2 loss: 0.700638  [   96/  124]
train() client id: f_00002-5-0 loss: 0.827297  [   32/  124]
train() client id: f_00002-5-1 loss: 0.692750  [   64/  124]
train() client id: f_00002-5-2 loss: 0.721282  [   96/  124]
train() client id: f_00002-6-0 loss: 0.807245  [   32/  124]
train() client id: f_00002-6-1 loss: 0.786165  [   64/  124]
train() client id: f_00002-6-2 loss: 0.684376  [   96/  124]
train() client id: f_00002-7-0 loss: 0.696635  [   32/  124]
train() client id: f_00002-7-1 loss: 0.833674  [   64/  124]
train() client id: f_00002-7-2 loss: 0.632987  [   96/  124]
train() client id: f_00002-8-0 loss: 0.679554  [   32/  124]
train() client id: f_00002-8-1 loss: 0.564651  [   64/  124]
train() client id: f_00002-8-2 loss: 0.730160  [   96/  124]
train() client id: f_00002-9-0 loss: 0.603363  [   32/  124]
train() client id: f_00002-9-1 loss: 0.637455  [   64/  124]
train() client id: f_00002-9-2 loss: 0.883214  [   96/  124]
train() client id: f_00002-10-0 loss: 0.728220  [   32/  124]
train() client id: f_00002-10-1 loss: 0.555290  [   64/  124]
train() client id: f_00002-10-2 loss: 0.670853  [   96/  124]
train() client id: f_00002-11-0 loss: 0.716678  [   32/  124]
train() client id: f_00002-11-1 loss: 0.606913  [   64/  124]
train() client id: f_00002-11-2 loss: 0.810814  [   96/  124]
train() client id: f_00002-12-0 loss: 0.750704  [   32/  124]
train() client id: f_00002-12-1 loss: 0.679414  [   64/  124]
train() client id: f_00002-12-2 loss: 0.683035  [   96/  124]
train() client id: f_00003-0-0 loss: 0.583051  [   32/   43]
train() client id: f_00003-1-0 loss: 0.540255  [   32/   43]
train() client id: f_00003-2-0 loss: 0.511292  [   32/   43]
train() client id: f_00003-3-0 loss: 0.660905  [   32/   43]
train() client id: f_00003-4-0 loss: 0.617335  [   32/   43]
train() client id: f_00003-5-0 loss: 0.414493  [   32/   43]
train() client id: f_00003-6-0 loss: 0.580885  [   32/   43]
train() client id: f_00003-7-0 loss: 0.616309  [   32/   43]
train() client id: f_00003-8-0 loss: 0.731812  [   32/   43]
train() client id: f_00003-9-0 loss: 0.577813  [   32/   43]
train() client id: f_00003-10-0 loss: 0.574980  [   32/   43]
train() client id: f_00003-11-0 loss: 0.655270  [   32/   43]
train() client id: f_00003-12-0 loss: 0.552416  [   32/   43]
train() client id: f_00004-0-0 loss: 0.856357  [   32/  306]
train() client id: f_00004-0-1 loss: 1.126987  [   64/  306]
train() client id: f_00004-0-2 loss: 0.917345  [   96/  306]
train() client id: f_00004-0-3 loss: 0.940686  [  128/  306]
train() client id: f_00004-0-4 loss: 0.975520  [  160/  306]
train() client id: f_00004-0-5 loss: 0.861075  [  192/  306]
train() client id: f_00004-0-6 loss: 0.928751  [  224/  306]
train() client id: f_00004-0-7 loss: 0.980466  [  256/  306]
train() client id: f_00004-0-8 loss: 1.061779  [  288/  306]
train() client id: f_00004-1-0 loss: 0.996721  [   32/  306]
train() client id: f_00004-1-1 loss: 1.016006  [   64/  306]
train() client id: f_00004-1-2 loss: 1.093701  [   96/  306]
train() client id: f_00004-1-3 loss: 0.884260  [  128/  306]
train() client id: f_00004-1-4 loss: 1.015606  [  160/  306]
train() client id: f_00004-1-5 loss: 0.885944  [  192/  306]
train() client id: f_00004-1-6 loss: 0.980451  [  224/  306]
train() client id: f_00004-1-7 loss: 1.012056  [  256/  306]
train() client id: f_00004-1-8 loss: 0.878202  [  288/  306]
train() client id: f_00004-2-0 loss: 0.869578  [   32/  306]
train() client id: f_00004-2-1 loss: 0.919070  [   64/  306]
train() client id: f_00004-2-2 loss: 0.941558  [   96/  306]
train() client id: f_00004-2-3 loss: 0.935261  [  128/  306]
train() client id: f_00004-2-4 loss: 1.148039  [  160/  306]
train() client id: f_00004-2-5 loss: 0.996053  [  192/  306]
train() client id: f_00004-2-6 loss: 0.841183  [  224/  306]
train() client id: f_00004-2-7 loss: 1.038156  [  256/  306]
train() client id: f_00004-2-8 loss: 1.037978  [  288/  306]
train() client id: f_00004-3-0 loss: 0.923443  [   32/  306]
train() client id: f_00004-3-1 loss: 0.862822  [   64/  306]
train() client id: f_00004-3-2 loss: 1.085552  [   96/  306]
train() client id: f_00004-3-3 loss: 0.850944  [  128/  306]
train() client id: f_00004-3-4 loss: 1.033849  [  160/  306]
train() client id: f_00004-3-5 loss: 0.986373  [  192/  306]
train() client id: f_00004-3-6 loss: 0.899623  [  224/  306]
train() client id: f_00004-3-7 loss: 0.875153  [  256/  306]
train() client id: f_00004-3-8 loss: 1.016414  [  288/  306]
train() client id: f_00004-4-0 loss: 1.197271  [   32/  306]
train() client id: f_00004-4-1 loss: 0.956537  [   64/  306]
train() client id: f_00004-4-2 loss: 0.857143  [   96/  306]
train() client id: f_00004-4-3 loss: 1.065222  [  128/  306]
train() client id: f_00004-4-4 loss: 0.828269  [  160/  306]
train() client id: f_00004-4-5 loss: 0.923396  [  192/  306]
train() client id: f_00004-4-6 loss: 1.001378  [  224/  306]
train() client id: f_00004-4-7 loss: 0.811309  [  256/  306]
train() client id: f_00004-4-8 loss: 1.019506  [  288/  306]
train() client id: f_00004-5-0 loss: 0.961916  [   32/  306]
train() client id: f_00004-5-1 loss: 0.954872  [   64/  306]
train() client id: f_00004-5-2 loss: 1.124371  [   96/  306]
train() client id: f_00004-5-3 loss: 0.963279  [  128/  306]
train() client id: f_00004-5-4 loss: 0.902220  [  160/  306]
train() client id: f_00004-5-5 loss: 1.000379  [  192/  306]
train() client id: f_00004-5-6 loss: 0.912923  [  224/  306]
train() client id: f_00004-5-7 loss: 0.964080  [  256/  306]
train() client id: f_00004-5-8 loss: 0.893991  [  288/  306]
train() client id: f_00004-6-0 loss: 0.941077  [   32/  306]
train() client id: f_00004-6-1 loss: 0.953890  [   64/  306]
train() client id: f_00004-6-2 loss: 1.010115  [   96/  306]
train() client id: f_00004-6-3 loss: 0.878718  [  128/  306]
train() client id: f_00004-6-4 loss: 1.056709  [  160/  306]
train() client id: f_00004-6-5 loss: 0.909258  [  192/  306]
train() client id: f_00004-6-6 loss: 1.003876  [  224/  306]
train() client id: f_00004-6-7 loss: 0.911744  [  256/  306]
train() client id: f_00004-6-8 loss: 0.927719  [  288/  306]
train() client id: f_00004-7-0 loss: 0.959177  [   32/  306]
train() client id: f_00004-7-1 loss: 0.957690  [   64/  306]
train() client id: f_00004-7-2 loss: 1.025469  [   96/  306]
train() client id: f_00004-7-3 loss: 0.851337  [  128/  306]
train() client id: f_00004-7-4 loss: 0.866725  [  160/  306]
train() client id: f_00004-7-5 loss: 0.858104  [  192/  306]
train() client id: f_00004-7-6 loss: 1.084827  [  224/  306]
train() client id: f_00004-7-7 loss: 0.977116  [  256/  306]
train() client id: f_00004-7-8 loss: 0.980159  [  288/  306]
train() client id: f_00004-8-0 loss: 0.990921  [   32/  306]
train() client id: f_00004-8-1 loss: 0.888536  [   64/  306]
train() client id: f_00004-8-2 loss: 1.114037  [   96/  306]
train() client id: f_00004-8-3 loss: 0.915622  [  128/  306]
train() client id: f_00004-8-4 loss: 0.955987  [  160/  306]
train() client id: f_00004-8-5 loss: 0.880532  [  192/  306]
train() client id: f_00004-8-6 loss: 0.948089  [  224/  306]
train() client id: f_00004-8-7 loss: 0.978575  [  256/  306]
train() client id: f_00004-8-8 loss: 0.904126  [  288/  306]
train() client id: f_00004-9-0 loss: 0.814939  [   32/  306]
train() client id: f_00004-9-1 loss: 0.978475  [   64/  306]
train() client id: f_00004-9-2 loss: 0.984030  [   96/  306]
train() client id: f_00004-9-3 loss: 0.960416  [  128/  306]
train() client id: f_00004-9-4 loss: 1.021016  [  160/  306]
train() client id: f_00004-9-5 loss: 0.969092  [  192/  306]
train() client id: f_00004-9-6 loss: 1.011766  [  224/  306]
train() client id: f_00004-9-7 loss: 0.906893  [  256/  306]
train() client id: f_00004-9-8 loss: 0.885080  [  288/  306]
train() client id: f_00004-10-0 loss: 0.987434  [   32/  306]
train() client id: f_00004-10-1 loss: 1.026053  [   64/  306]
train() client id: f_00004-10-2 loss: 0.999836  [   96/  306]
train() client id: f_00004-10-3 loss: 0.922173  [  128/  306]
train() client id: f_00004-10-4 loss: 1.004273  [  160/  306]
train() client id: f_00004-10-5 loss: 0.900650  [  192/  306]
train() client id: f_00004-10-6 loss: 0.888216  [  224/  306]
train() client id: f_00004-10-7 loss: 0.951865  [  256/  306]
train() client id: f_00004-10-8 loss: 0.834363  [  288/  306]
train() client id: f_00004-11-0 loss: 0.956504  [   32/  306]
train() client id: f_00004-11-1 loss: 0.925742  [   64/  306]
train() client id: f_00004-11-2 loss: 1.001757  [   96/  306]
train() client id: f_00004-11-3 loss: 1.010912  [  128/  306]
train() client id: f_00004-11-4 loss: 0.942396  [  160/  306]
train() client id: f_00004-11-5 loss: 0.883413  [  192/  306]
train() client id: f_00004-11-6 loss: 0.879921  [  224/  306]
train() client id: f_00004-11-7 loss: 0.877969  [  256/  306]
train() client id: f_00004-11-8 loss: 0.920929  [  288/  306]
train() client id: f_00004-12-0 loss: 0.989927  [   32/  306]
train() client id: f_00004-12-1 loss: 0.904331  [   64/  306]
train() client id: f_00004-12-2 loss: 1.018218  [   96/  306]
train() client id: f_00004-12-3 loss: 0.909886  [  128/  306]
train() client id: f_00004-12-4 loss: 0.849092  [  160/  306]
train() client id: f_00004-12-5 loss: 1.023321  [  192/  306]
train() client id: f_00004-12-6 loss: 1.073100  [  224/  306]
train() client id: f_00004-12-7 loss: 0.897131  [  256/  306]
train() client id: f_00004-12-8 loss: 0.866650  [  288/  306]
train() client id: f_00005-0-0 loss: 0.859476  [   32/  146]
train() client id: f_00005-0-1 loss: 0.844379  [   64/  146]
train() client id: f_00005-0-2 loss: 0.528687  [   96/  146]
train() client id: f_00005-0-3 loss: 0.834321  [  128/  146]
train() client id: f_00005-1-0 loss: 0.677646  [   32/  146]
train() client id: f_00005-1-1 loss: 0.714583  [   64/  146]
train() client id: f_00005-1-2 loss: 0.757783  [   96/  146]
train() client id: f_00005-1-3 loss: 0.784593  [  128/  146]
train() client id: f_00005-2-0 loss: 0.735467  [   32/  146]
train() client id: f_00005-2-1 loss: 0.924325  [   64/  146]
train() client id: f_00005-2-2 loss: 0.480721  [   96/  146]
train() client id: f_00005-2-3 loss: 0.962452  [  128/  146]
train() client id: f_00005-3-0 loss: 1.034596  [   32/  146]
train() client id: f_00005-3-1 loss: 0.829760  [   64/  146]
train() client id: f_00005-3-2 loss: 0.691607  [   96/  146]
train() client id: f_00005-3-3 loss: 0.563022  [  128/  146]
train() client id: f_00005-4-0 loss: 0.702280  [   32/  146]
train() client id: f_00005-4-1 loss: 0.754844  [   64/  146]
train() client id: f_00005-4-2 loss: 0.936683  [   96/  146]
train() client id: f_00005-4-3 loss: 0.497095  [  128/  146]
train() client id: f_00005-5-0 loss: 0.441570  [   32/  146]
train() client id: f_00005-5-1 loss: 0.864714  [   64/  146]
train() client id: f_00005-5-2 loss: 1.065486  [   96/  146]
train() client id: f_00005-5-3 loss: 0.754917  [  128/  146]
train() client id: f_00005-6-0 loss: 0.721766  [   32/  146]
train() client id: f_00005-6-1 loss: 0.832028  [   64/  146]
train() client id: f_00005-6-2 loss: 0.728545  [   96/  146]
train() client id: f_00005-6-3 loss: 0.665968  [  128/  146]
train() client id: f_00005-7-0 loss: 0.766055  [   32/  146]
train() client id: f_00005-7-1 loss: 0.843634  [   64/  146]
train() client id: f_00005-7-2 loss: 0.618657  [   96/  146]
train() client id: f_00005-7-3 loss: 0.768265  [  128/  146]
train() client id: f_00005-8-0 loss: 0.544726  [   32/  146]
train() client id: f_00005-8-1 loss: 1.011761  [   64/  146]
train() client id: f_00005-8-2 loss: 0.769204  [   96/  146]
train() client id: f_00005-8-3 loss: 0.689586  [  128/  146]
train() client id: f_00005-9-0 loss: 0.780244  [   32/  146]
train() client id: f_00005-9-1 loss: 0.598408  [   64/  146]
train() client id: f_00005-9-2 loss: 0.464319  [   96/  146]
train() client id: f_00005-9-3 loss: 1.100138  [  128/  146]
train() client id: f_00005-10-0 loss: 0.991014  [   32/  146]
train() client id: f_00005-10-1 loss: 0.689832  [   64/  146]
train() client id: f_00005-10-2 loss: 0.699477  [   96/  146]
train() client id: f_00005-10-3 loss: 0.789256  [  128/  146]
train() client id: f_00005-11-0 loss: 0.726911  [   32/  146]
train() client id: f_00005-11-1 loss: 0.574783  [   64/  146]
train() client id: f_00005-11-2 loss: 0.887975  [   96/  146]
train() client id: f_00005-11-3 loss: 0.685623  [  128/  146]
train() client id: f_00005-12-0 loss: 0.968796  [   32/  146]
train() client id: f_00005-12-1 loss: 0.797446  [   64/  146]
train() client id: f_00005-12-2 loss: 0.517962  [   96/  146]
train() client id: f_00005-12-3 loss: 0.804488  [  128/  146]
train() client id: f_00006-0-0 loss: 0.383032  [   32/   54]
train() client id: f_00006-1-0 loss: 0.427218  [   32/   54]
train() client id: f_00006-2-0 loss: 0.498026  [   32/   54]
train() client id: f_00006-3-0 loss: 0.435947  [   32/   54]
train() client id: f_00006-4-0 loss: 0.415371  [   32/   54]
train() client id: f_00006-5-0 loss: 0.451743  [   32/   54]
train() client id: f_00006-6-0 loss: 0.490199  [   32/   54]
train() client id: f_00006-7-0 loss: 0.410484  [   32/   54]
train() client id: f_00006-8-0 loss: 0.429376  [   32/   54]
train() client id: f_00006-9-0 loss: 0.454261  [   32/   54]
train() client id: f_00006-10-0 loss: 0.454958  [   32/   54]
train() client id: f_00006-11-0 loss: 0.473993  [   32/   54]
train() client id: f_00006-12-0 loss: 0.428626  [   32/   54]
train() client id: f_00007-0-0 loss: 0.713848  [   32/  179]
train() client id: f_00007-0-1 loss: 0.897210  [   64/  179]
train() client id: f_00007-0-2 loss: 0.662251  [   96/  179]
train() client id: f_00007-0-3 loss: 0.496094  [  128/  179]
train() client id: f_00007-0-4 loss: 0.531301  [  160/  179]
train() client id: f_00007-1-0 loss: 0.684853  [   32/  179]
train() client id: f_00007-1-1 loss: 0.680279  [   64/  179]
train() client id: f_00007-1-2 loss: 0.753225  [   96/  179]
train() client id: f_00007-1-3 loss: 0.707906  [  128/  179]
train() client id: f_00007-1-4 loss: 0.500330  [  160/  179]
train() client id: f_00007-2-0 loss: 0.558613  [   32/  179]
train() client id: f_00007-2-1 loss: 0.891037  [   64/  179]
train() client id: f_00007-2-2 loss: 0.548543  [   96/  179]
train() client id: f_00007-2-3 loss: 0.667063  [  128/  179]
train() client id: f_00007-2-4 loss: 0.562264  [  160/  179]
train() client id: f_00007-3-0 loss: 0.564475  [   32/  179]
train() client id: f_00007-3-1 loss: 0.740690  [   64/  179]
train() client id: f_00007-3-2 loss: 0.653574  [   96/  179]
train() client id: f_00007-3-3 loss: 0.504208  [  128/  179]
train() client id: f_00007-3-4 loss: 0.668071  [  160/  179]
train() client id: f_00007-4-0 loss: 0.698882  [   32/  179]
train() client id: f_00007-4-1 loss: 0.725281  [   64/  179]
train() client id: f_00007-4-2 loss: 0.620721  [   96/  179]
train() client id: f_00007-4-3 loss: 0.575263  [  128/  179]
train() client id: f_00007-4-4 loss: 0.531697  [  160/  179]
train() client id: f_00007-5-0 loss: 0.545196  [   32/  179]
train() client id: f_00007-5-1 loss: 0.650276  [   64/  179]
train() client id: f_00007-5-2 loss: 0.519082  [   96/  179]
train() client id: f_00007-5-3 loss: 0.585226  [  128/  179]
train() client id: f_00007-5-4 loss: 0.714111  [  160/  179]
train() client id: f_00007-6-0 loss: 0.649908  [   32/  179]
train() client id: f_00007-6-1 loss: 0.547623  [   64/  179]
train() client id: f_00007-6-2 loss: 0.460213  [   96/  179]
train() client id: f_00007-6-3 loss: 0.730484  [  128/  179]
train() client id: f_00007-6-4 loss: 0.735213  [  160/  179]
train() client id: f_00007-7-0 loss: 0.731141  [   32/  179]
train() client id: f_00007-7-1 loss: 0.608361  [   64/  179]
train() client id: f_00007-7-2 loss: 0.443815  [   96/  179]
train() client id: f_00007-7-3 loss: 0.541049  [  128/  179]
train() client id: f_00007-7-4 loss: 0.628234  [  160/  179]
train() client id: f_00007-8-0 loss: 0.404670  [   32/  179]
train() client id: f_00007-8-1 loss: 0.634984  [   64/  179]
train() client id: f_00007-8-2 loss: 0.594890  [   96/  179]
train() client id: f_00007-8-3 loss: 0.412112  [  128/  179]
train() client id: f_00007-8-4 loss: 0.856815  [  160/  179]
train() client id: f_00007-9-0 loss: 0.566658  [   32/  179]
train() client id: f_00007-9-1 loss: 0.618010  [   64/  179]
train() client id: f_00007-9-2 loss: 0.602562  [   96/  179]
train() client id: f_00007-9-3 loss: 0.641597  [  128/  179]
train() client id: f_00007-9-4 loss: 0.553898  [  160/  179]
train() client id: f_00007-10-0 loss: 0.425657  [   32/  179]
train() client id: f_00007-10-1 loss: 0.873623  [   64/  179]
train() client id: f_00007-10-2 loss: 0.648104  [   96/  179]
train() client id: f_00007-10-3 loss: 0.388894  [  128/  179]
train() client id: f_00007-10-4 loss: 0.739126  [  160/  179]
train() client id: f_00007-11-0 loss: 0.610014  [   32/  179]
train() client id: f_00007-11-1 loss: 0.617555  [   64/  179]
train() client id: f_00007-11-2 loss: 0.401879  [   96/  179]
train() client id: f_00007-11-3 loss: 0.811467  [  128/  179]
train() client id: f_00007-11-4 loss: 0.602739  [  160/  179]
train() client id: f_00007-12-0 loss: 0.555153  [   32/  179]
train() client id: f_00007-12-1 loss: 0.552209  [   64/  179]
train() client id: f_00007-12-2 loss: 0.860454  [   96/  179]
train() client id: f_00007-12-3 loss: 0.421161  [  128/  179]
train() client id: f_00007-12-4 loss: 0.646977  [  160/  179]
train() client id: f_00008-0-0 loss: 0.718918  [   32/  130]
train() client id: f_00008-0-1 loss: 0.658521  [   64/  130]
train() client id: f_00008-0-2 loss: 0.753207  [   96/  130]
train() client id: f_00008-0-3 loss: 0.744640  [  128/  130]
train() client id: f_00008-1-0 loss: 0.846684  [   32/  130]
train() client id: f_00008-1-1 loss: 0.710278  [   64/  130]
train() client id: f_00008-1-2 loss: 0.656289  [   96/  130]
train() client id: f_00008-1-3 loss: 0.656022  [  128/  130]
train() client id: f_00008-2-0 loss: 0.725144  [   32/  130]
train() client id: f_00008-2-1 loss: 0.662129  [   64/  130]
train() client id: f_00008-2-2 loss: 0.740835  [   96/  130]
train() client id: f_00008-2-3 loss: 0.707718  [  128/  130]
train() client id: f_00008-3-0 loss: 0.737215  [   32/  130]
train() client id: f_00008-3-1 loss: 0.750582  [   64/  130]
train() client id: f_00008-3-2 loss: 0.657622  [   96/  130]
train() client id: f_00008-3-3 loss: 0.723421  [  128/  130]
train() client id: f_00008-4-0 loss: 0.746127  [   32/  130]
train() client id: f_00008-4-1 loss: 0.671996  [   64/  130]
train() client id: f_00008-4-2 loss: 0.754477  [   96/  130]
train() client id: f_00008-4-3 loss: 0.679397  [  128/  130]
train() client id: f_00008-5-0 loss: 0.674335  [   32/  130]
train() client id: f_00008-5-1 loss: 0.716379  [   64/  130]
train() client id: f_00008-5-2 loss: 0.731361  [   96/  130]
train() client id: f_00008-5-3 loss: 0.725364  [  128/  130]
train() client id: f_00008-6-0 loss: 0.717691  [   32/  130]
train() client id: f_00008-6-1 loss: 0.758574  [   64/  130]
train() client id: f_00008-6-2 loss: 0.657703  [   96/  130]
train() client id: f_00008-6-3 loss: 0.724164  [  128/  130]
train() client id: f_00008-7-0 loss: 0.645127  [   32/  130]
train() client id: f_00008-7-1 loss: 0.770676  [   64/  130]
train() client id: f_00008-7-2 loss: 0.613159  [   96/  130]
train() client id: f_00008-7-3 loss: 0.837676  [  128/  130]
train() client id: f_00008-8-0 loss: 0.781799  [   32/  130]
train() client id: f_00008-8-1 loss: 0.693589  [   64/  130]
train() client id: f_00008-8-2 loss: 0.710566  [   96/  130]
train() client id: f_00008-8-3 loss: 0.684646  [  128/  130]
train() client id: f_00008-9-0 loss: 0.663963  [   32/  130]
train() client id: f_00008-9-1 loss: 0.814039  [   64/  130]
train() client id: f_00008-9-2 loss: 0.626541  [   96/  130]
train() client id: f_00008-9-3 loss: 0.728030  [  128/  130]
train() client id: f_00008-10-0 loss: 0.699717  [   32/  130]
train() client id: f_00008-10-1 loss: 0.717369  [   64/  130]
train() client id: f_00008-10-2 loss: 0.685785  [   96/  130]
train() client id: f_00008-10-3 loss: 0.729679  [  128/  130]
train() client id: f_00008-11-0 loss: 0.627116  [   32/  130]
train() client id: f_00008-11-1 loss: 0.658321  [   64/  130]
train() client id: f_00008-11-2 loss: 0.821041  [   96/  130]
train() client id: f_00008-11-3 loss: 0.732620  [  128/  130]
train() client id: f_00008-12-0 loss: 0.657425  [   32/  130]
train() client id: f_00008-12-1 loss: 0.719495  [   64/  130]
train() client id: f_00008-12-2 loss: 0.799841  [   96/  130]
train() client id: f_00008-12-3 loss: 0.656634  [  128/  130]
train() client id: f_00009-0-0 loss: 1.028744  [   32/  118]
train() client id: f_00009-0-1 loss: 0.810244  [   64/  118]
train() client id: f_00009-0-2 loss: 0.971528  [   96/  118]
train() client id: f_00009-1-0 loss: 1.027151  [   32/  118]
train() client id: f_00009-1-1 loss: 0.916296  [   64/  118]
train() client id: f_00009-1-2 loss: 0.741537  [   96/  118]
train() client id: f_00009-2-0 loss: 0.860837  [   32/  118]
train() client id: f_00009-2-1 loss: 0.860201  [   64/  118]
train() client id: f_00009-2-2 loss: 0.839244  [   96/  118]
train() client id: f_00009-3-0 loss: 0.912722  [   32/  118]
train() client id: f_00009-3-1 loss: 0.778831  [   64/  118]
train() client id: f_00009-3-2 loss: 0.818093  [   96/  118]
train() client id: f_00009-4-0 loss: 0.675420  [   32/  118]
train() client id: f_00009-4-1 loss: 0.773457  [   64/  118]
train() client id: f_00009-4-2 loss: 0.788401  [   96/  118]
train() client id: f_00009-5-0 loss: 0.764880  [   32/  118]
train() client id: f_00009-5-1 loss: 0.756916  [   64/  118]
train() client id: f_00009-5-2 loss: 0.670361  [   96/  118]
train() client id: f_00009-6-0 loss: 0.745180  [   32/  118]
train() client id: f_00009-6-1 loss: 0.701741  [   64/  118]
train() client id: f_00009-6-2 loss: 0.742604  [   96/  118]
train() client id: f_00009-7-0 loss: 0.770831  [   32/  118]
train() client id: f_00009-7-1 loss: 0.724549  [   64/  118]
train() client id: f_00009-7-2 loss: 0.819870  [   96/  118]
train() client id: f_00009-8-0 loss: 0.878552  [   32/  118]
train() client id: f_00009-8-1 loss: 0.694934  [   64/  118]
train() client id: f_00009-8-2 loss: 0.660274  [   96/  118]
train() client id: f_00009-9-0 loss: 0.621692  [   32/  118]
train() client id: f_00009-9-1 loss: 0.631620  [   64/  118]
train() client id: f_00009-9-2 loss: 0.829459  [   96/  118]
train() client id: f_00009-10-0 loss: 0.672138  [   32/  118]
train() client id: f_00009-10-1 loss: 0.714917  [   64/  118]
train() client id: f_00009-10-2 loss: 0.608033  [   96/  118]
train() client id: f_00009-11-0 loss: 0.611433  [   32/  118]
train() client id: f_00009-11-1 loss: 0.805628  [   64/  118]
train() client id: f_00009-11-2 loss: 0.700311  [   96/  118]
train() client id: f_00009-12-0 loss: 0.768048  [   32/  118]
train() client id: f_00009-12-1 loss: 0.725862  [   64/  118]
train() client id: f_00009-12-2 loss: 0.579278  [   96/  118]
At round 58 accuracy: 0.6392572944297082
At round 58 training accuracy: 0.5915492957746479
At round 58 training loss: 0.8280590433021894
gradient difference: 0.4700406491756439
train() client id: f_00000-0-0 loss: 1.295021  [   32/  126]
train() client id: f_00000-0-1 loss: 1.115478  [   64/  126]
train() client id: f_00000-0-2 loss: 1.005480  [   96/  126]
train() client id: f_00000-1-0 loss: 1.217210  [   32/  126]
train() client id: f_00000-1-1 loss: 0.983209  [   64/  126]
train() client id: f_00000-1-2 loss: 1.043678  [   96/  126]
train() client id: f_00000-2-0 loss: 0.979252  [   32/  126]
train() client id: f_00000-2-1 loss: 0.943075  [   64/  126]
train() client id: f_00000-2-2 loss: 1.135159  [   96/  126]
train() client id: f_00000-3-0 loss: 0.818074  [   32/  126]
train() client id: f_00000-3-1 loss: 1.167786  [   64/  126]
train() client id: f_00000-3-2 loss: 0.964785  [   96/  126]
train() client id: f_00000-4-0 loss: 0.999732  [   32/  126]
train() client id: f_00000-4-1 loss: 0.965979  [   64/  126]
train() client id: f_00000-4-2 loss: 0.929659  [   96/  126]
train() client id: f_00000-5-0 loss: 0.902500  [   32/  126]
train() client id: f_00000-5-1 loss: 0.926208  [   64/  126]
train() client id: f_00000-5-2 loss: 0.936853  [   96/  126]
train() client id: f_00000-6-0 loss: 0.866791  [   32/  126]
train() client id: f_00000-6-1 loss: 0.791522  [   64/  126]
train() client id: f_00000-6-2 loss: 0.839939  [   96/  126]
train() client id: f_00000-7-0 loss: 0.810673  [   32/  126]
train() client id: f_00000-7-1 loss: 1.065851  [   64/  126]
train() client id: f_00000-7-2 loss: 0.728457  [   96/  126]
train() client id: f_00000-8-0 loss: 0.815013  [   32/  126]
train() client id: f_00000-8-1 loss: 0.811475  [   64/  126]
train() client id: f_00000-8-2 loss: 0.967293  [   96/  126]
train() client id: f_00000-9-0 loss: 0.928645  [   32/  126]
train() client id: f_00000-9-1 loss: 0.724939  [   64/  126]
train() client id: f_00000-9-2 loss: 0.947163  [   96/  126]
train() client id: f_00000-10-0 loss: 0.892134  [   32/  126]
train() client id: f_00000-10-1 loss: 0.831878  [   64/  126]
train() client id: f_00000-10-2 loss: 0.796928  [   96/  126]
train() client id: f_00000-11-0 loss: 0.813044  [   32/  126]
train() client id: f_00000-11-1 loss: 0.983944  [   64/  126]
train() client id: f_00000-11-2 loss: 0.834455  [   96/  126]
train() client id: f_00000-12-0 loss: 0.917983  [   32/  126]
train() client id: f_00000-12-1 loss: 0.901376  [   64/  126]
train() client id: f_00000-12-2 loss: 0.788818  [   96/  126]
train() client id: f_00001-0-0 loss: 0.438595  [   32/  265]
train() client id: f_00001-0-1 loss: 0.329008  [   64/  265]
train() client id: f_00001-0-2 loss: 0.436605  [   96/  265]
train() client id: f_00001-0-3 loss: 0.403463  [  128/  265]
train() client id: f_00001-0-4 loss: 0.469921  [  160/  265]
train() client id: f_00001-0-5 loss: 0.556947  [  192/  265]
train() client id: f_00001-0-6 loss: 0.408898  [  224/  265]
train() client id: f_00001-0-7 loss: 0.318071  [  256/  265]
train() client id: f_00001-1-0 loss: 0.369896  [   32/  265]
train() client id: f_00001-1-1 loss: 0.376907  [   64/  265]
train() client id: f_00001-1-2 loss: 0.486178  [   96/  265]
train() client id: f_00001-1-3 loss: 0.421406  [  128/  265]
train() client id: f_00001-1-4 loss: 0.318285  [  160/  265]
train() client id: f_00001-1-5 loss: 0.394646  [  192/  265]
train() client id: f_00001-1-6 loss: 0.520083  [  224/  265]
train() client id: f_00001-1-7 loss: 0.344007  [  256/  265]
train() client id: f_00001-2-0 loss: 0.461804  [   32/  265]
train() client id: f_00001-2-1 loss: 0.364664  [   64/  265]
train() client id: f_00001-2-2 loss: 0.420827  [   96/  265]
train() client id: f_00001-2-3 loss: 0.353162  [  128/  265]
train() client id: f_00001-2-4 loss: 0.382092  [  160/  265]
train() client id: f_00001-2-5 loss: 0.444378  [  192/  265]
train() client id: f_00001-2-6 loss: 0.412521  [  224/  265]
train() client id: f_00001-2-7 loss: 0.403017  [  256/  265]
train() client id: f_00001-3-0 loss: 0.353608  [   32/  265]
train() client id: f_00001-3-1 loss: 0.407553  [   64/  265]
train() client id: f_00001-3-2 loss: 0.372380  [   96/  265]
train() client id: f_00001-3-3 loss: 0.400246  [  128/  265]
train() client id: f_00001-3-4 loss: 0.485263  [  160/  265]
train() client id: f_00001-3-5 loss: 0.453136  [  192/  265]
train() client id: f_00001-3-6 loss: 0.368607  [  224/  265]
train() client id: f_00001-3-7 loss: 0.360575  [  256/  265]
train() client id: f_00001-4-0 loss: 0.685817  [   32/  265]
train() client id: f_00001-4-1 loss: 0.396550  [   64/  265]
train() client id: f_00001-4-2 loss: 0.465490  [   96/  265]
train() client id: f_00001-4-3 loss: 0.330587  [  128/  265]
train() client id: f_00001-4-4 loss: 0.361097  [  160/  265]
train() client id: f_00001-4-5 loss: 0.309998  [  192/  265]
train() client id: f_00001-4-6 loss: 0.350938  [  224/  265]
train() client id: f_00001-4-7 loss: 0.280621  [  256/  265]
train() client id: f_00001-5-0 loss: 0.350582  [   32/  265]
train() client id: f_00001-5-1 loss: 0.377558  [   64/  265]
train() client id: f_00001-5-2 loss: 0.375247  [   96/  265]
train() client id: f_00001-5-3 loss: 0.452080  [  128/  265]
train() client id: f_00001-5-4 loss: 0.528686  [  160/  265]
train() client id: f_00001-5-5 loss: 0.414497  [  192/  265]
train() client id: f_00001-5-6 loss: 0.307703  [  224/  265]
train() client id: f_00001-5-7 loss: 0.335558  [  256/  265]
train() client id: f_00001-6-0 loss: 0.440715  [   32/  265]
train() client id: f_00001-6-1 loss: 0.364008  [   64/  265]
train() client id: f_00001-6-2 loss: 0.365109  [   96/  265]
train() client id: f_00001-6-3 loss: 0.447440  [  128/  265]
train() client id: f_00001-6-4 loss: 0.360179  [  160/  265]
train() client id: f_00001-6-5 loss: 0.409478  [  192/  265]
train() client id: f_00001-6-6 loss: 0.433063  [  224/  265]
train() client id: f_00001-6-7 loss: 0.302322  [  256/  265]
train() client id: f_00001-7-0 loss: 0.390931  [   32/  265]
train() client id: f_00001-7-1 loss: 0.447458  [   64/  265]
train() client id: f_00001-7-2 loss: 0.300228  [   96/  265]
train() client id: f_00001-7-3 loss: 0.460003  [  128/  265]
train() client id: f_00001-7-4 loss: 0.336362  [  160/  265]
train() client id: f_00001-7-5 loss: 0.343519  [  192/  265]
train() client id: f_00001-7-6 loss: 0.383292  [  224/  265]
train() client id: f_00001-7-7 loss: 0.469963  [  256/  265]
train() client id: f_00001-8-0 loss: 0.408432  [   32/  265]
train() client id: f_00001-8-1 loss: 0.299746  [   64/  265]
train() client id: f_00001-8-2 loss: 0.343879  [   96/  265]
train() client id: f_00001-8-3 loss: 0.499844  [  128/  265]
train() client id: f_00001-8-4 loss: 0.381153  [  160/  265]
train() client id: f_00001-8-5 loss: 0.378254  [  192/  265]
train() client id: f_00001-8-6 loss: 0.388903  [  224/  265]
train() client id: f_00001-8-7 loss: 0.403217  [  256/  265]
train() client id: f_00001-9-0 loss: 0.377645  [   32/  265]
train() client id: f_00001-9-1 loss: 0.366708  [   64/  265]
train() client id: f_00001-9-2 loss: 0.311136  [   96/  265]
train() client id: f_00001-9-3 loss: 0.407936  [  128/  265]
train() client id: f_00001-9-4 loss: 0.284925  [  160/  265]
train() client id: f_00001-9-5 loss: 0.350776  [  192/  265]
train() client id: f_00001-9-6 loss: 0.544808  [  224/  265]
train() client id: f_00001-9-7 loss: 0.458335  [  256/  265]
train() client id: f_00001-10-0 loss: 0.478363  [   32/  265]
train() client id: f_00001-10-1 loss: 0.430469  [   64/  265]
train() client id: f_00001-10-2 loss: 0.427338  [   96/  265]
train() client id: f_00001-10-3 loss: 0.458899  [  128/  265]
train() client id: f_00001-10-4 loss: 0.352570  [  160/  265]
train() client id: f_00001-10-5 loss: 0.273214  [  192/  265]
train() client id: f_00001-10-6 loss: 0.390240  [  224/  265]
train() client id: f_00001-10-7 loss: 0.269862  [  256/  265]
train() client id: f_00001-11-0 loss: 0.354983  [   32/  265]
train() client id: f_00001-11-1 loss: 0.372191  [   64/  265]
train() client id: f_00001-11-2 loss: 0.381603  [   96/  265]
train() client id: f_00001-11-3 loss: 0.277154  [  128/  265]
train() client id: f_00001-11-4 loss: 0.460102  [  160/  265]
train() client id: f_00001-11-5 loss: 0.256056  [  192/  265]
train() client id: f_00001-11-6 loss: 0.612752  [  224/  265]
train() client id: f_00001-11-7 loss: 0.355385  [  256/  265]
train() client id: f_00001-12-0 loss: 0.372295  [   32/  265]
train() client id: f_00001-12-1 loss: 0.342842  [   64/  265]
train() client id: f_00001-12-2 loss: 0.414051  [   96/  265]
train() client id: f_00001-12-3 loss: 0.416576  [  128/  265]
train() client id: f_00001-12-4 loss: 0.505745  [  160/  265]
train() client id: f_00001-12-5 loss: 0.277454  [  192/  265]
train() client id: f_00001-12-6 loss: 0.473756  [  224/  265]
train() client id: f_00001-12-7 loss: 0.285019  [  256/  265]
train() client id: f_00002-0-0 loss: 1.085443  [   32/  124]
train() client id: f_00002-0-1 loss: 1.292122  [   64/  124]
train() client id: f_00002-0-2 loss: 1.102335  [   96/  124]
train() client id: f_00002-1-0 loss: 1.112345  [   32/  124]
train() client id: f_00002-1-1 loss: 1.089814  [   64/  124]
train() client id: f_00002-1-2 loss: 0.937040  [   96/  124]
train() client id: f_00002-2-0 loss: 1.079669  [   32/  124]
train() client id: f_00002-2-1 loss: 1.015174  [   64/  124]
train() client id: f_00002-2-2 loss: 1.024086  [   96/  124]
train() client id: f_00002-3-0 loss: 1.103162  [   32/  124]
train() client id: f_00002-3-1 loss: 0.989019  [   64/  124]
train() client id: f_00002-3-2 loss: 1.031698  [   96/  124]
train() client id: f_00002-4-0 loss: 1.073731  [   32/  124]
train() client id: f_00002-4-1 loss: 0.945969  [   64/  124]
train() client id: f_00002-4-2 loss: 0.920683  [   96/  124]
train() client id: f_00002-5-0 loss: 0.807446  [   32/  124]
train() client id: f_00002-5-1 loss: 1.018545  [   64/  124]
train() client id: f_00002-5-2 loss: 1.163801  [   96/  124]
train() client id: f_00002-6-0 loss: 1.178309  [   32/  124]
train() client id: f_00002-6-1 loss: 0.938805  [   64/  124]
train() client id: f_00002-6-2 loss: 0.931517  [   96/  124]
train() client id: f_00002-7-0 loss: 1.000604  [   32/  124]
train() client id: f_00002-7-1 loss: 0.928448  [   64/  124]
train() client id: f_00002-7-2 loss: 0.904778  [   96/  124]
train() client id: f_00002-8-0 loss: 1.098240  [   32/  124]
train() client id: f_00002-8-1 loss: 0.999280  [   64/  124]
train() client id: f_00002-8-2 loss: 0.967244  [   96/  124]
train() client id: f_00002-9-0 loss: 0.998791  [   32/  124]
train() client id: f_00002-9-1 loss: 0.927312  [   64/  124]
train() client id: f_00002-9-2 loss: 0.922469  [   96/  124]
train() client id: f_00002-10-0 loss: 0.946394  [   32/  124]
train() client id: f_00002-10-1 loss: 0.988155  [   64/  124]
train() client id: f_00002-10-2 loss: 0.890727  [   96/  124]
train() client id: f_00002-11-0 loss: 0.942288  [   32/  124]
train() client id: f_00002-11-1 loss: 1.055035  [   64/  124]
train() client id: f_00002-11-2 loss: 0.914863  [   96/  124]
train() client id: f_00002-12-0 loss: 0.804839  [   32/  124]
train() client id: f_00002-12-1 loss: 1.096821  [   64/  124]
train() client id: f_00002-12-2 loss: 1.044952  [   96/  124]
train() client id: f_00003-0-0 loss: 0.687878  [   32/   43]
train() client id: f_00003-1-0 loss: 0.563587  [   32/   43]
train() client id: f_00003-2-0 loss: 0.647381  [   32/   43]
train() client id: f_00003-3-0 loss: 0.815374  [   32/   43]
train() client id: f_00003-4-0 loss: 0.794463  [   32/   43]
train() client id: f_00003-5-0 loss: 0.737563  [   32/   43]
train() client id: f_00003-6-0 loss: 0.610669  [   32/   43]
train() client id: f_00003-7-0 loss: 0.718967  [   32/   43]
train() client id: f_00003-8-0 loss: 0.556151  [   32/   43]
train() client id: f_00003-9-0 loss: 0.556228  [   32/   43]
train() client id: f_00003-10-0 loss: 0.642477  [   32/   43]
train() client id: f_00003-11-0 loss: 0.734152  [   32/   43]
train() client id: f_00003-12-0 loss: 0.540465  [   32/   43]
train() client id: f_00004-0-0 loss: 0.877134  [   32/  306]
train() client id: f_00004-0-1 loss: 0.932045  [   64/  306]
train() client id: f_00004-0-2 loss: 0.910612  [   96/  306]
train() client id: f_00004-0-3 loss: 0.941422  [  128/  306]
train() client id: f_00004-0-4 loss: 1.010869  [  160/  306]
train() client id: f_00004-0-5 loss: 0.860422  [  192/  306]
train() client id: f_00004-0-6 loss: 1.038103  [  224/  306]
train() client id: f_00004-0-7 loss: 0.873963  [  256/  306]
train() client id: f_00004-0-8 loss: 1.025653  [  288/  306]
train() client id: f_00004-1-0 loss: 0.811487  [   32/  306]
train() client id: f_00004-1-1 loss: 0.746710  [   64/  306]
train() client id: f_00004-1-2 loss: 0.803161  [   96/  306]
train() client id: f_00004-1-3 loss: 0.926518  [  128/  306]
train() client id: f_00004-1-4 loss: 0.941701  [  160/  306]
train() client id: f_00004-1-5 loss: 1.144318  [  192/  306]
train() client id: f_00004-1-6 loss: 0.885408  [  224/  306]
train() client id: f_00004-1-7 loss: 0.885626  [  256/  306]
train() client id: f_00004-1-8 loss: 1.147367  [  288/  306]
train() client id: f_00004-2-0 loss: 0.973127  [   32/  306]
train() client id: f_00004-2-1 loss: 0.898201  [   64/  306]
train() client id: f_00004-2-2 loss: 0.783770  [   96/  306]
train() client id: f_00004-2-3 loss: 1.046177  [  128/  306]
train() client id: f_00004-2-4 loss: 0.898075  [  160/  306]
train() client id: f_00004-2-5 loss: 1.187153  [  192/  306]
train() client id: f_00004-2-6 loss: 0.920017  [  224/  306]
train() client id: f_00004-2-7 loss: 0.877425  [  256/  306]
train() client id: f_00004-2-8 loss: 0.932840  [  288/  306]
train() client id: f_00004-3-0 loss: 0.932435  [   32/  306]
train() client id: f_00004-3-1 loss: 0.970734  [   64/  306]
train() client id: f_00004-3-2 loss: 1.107694  [   96/  306]
train() client id: f_00004-3-3 loss: 0.983246  [  128/  306]
train() client id: f_00004-3-4 loss: 0.928707  [  160/  306]
train() client id: f_00004-3-5 loss: 0.847212  [  192/  306]
train() client id: f_00004-3-6 loss: 0.894414  [  224/  306]
train() client id: f_00004-3-7 loss: 0.887063  [  256/  306]
train() client id: f_00004-3-8 loss: 0.853861  [  288/  306]
train() client id: f_00004-4-0 loss: 0.955246  [   32/  306]
train() client id: f_00004-4-1 loss: 0.950405  [   64/  306]
train() client id: f_00004-4-2 loss: 0.830108  [   96/  306]
train() client id: f_00004-4-3 loss: 0.924172  [  128/  306]
train() client id: f_00004-4-4 loss: 0.886512  [  160/  306]
train() client id: f_00004-4-5 loss: 0.928071  [  192/  306]
train() client id: f_00004-4-6 loss: 1.025632  [  224/  306]
train() client id: f_00004-4-7 loss: 1.033152  [  256/  306]
train() client id: f_00004-4-8 loss: 0.774454  [  288/  306]
train() client id: f_00004-5-0 loss: 0.946947  [   32/  306]
train() client id: f_00004-5-1 loss: 0.818685  [   64/  306]
train() client id: f_00004-5-2 loss: 0.952152  [   96/  306]
train() client id: f_00004-5-3 loss: 0.912922  [  128/  306]
train() client id: f_00004-5-4 loss: 0.816148  [  160/  306]
train() client id: f_00004-5-5 loss: 0.806165  [  192/  306]
train() client id: f_00004-5-6 loss: 0.967740  [  224/  306]
train() client id: f_00004-5-7 loss: 0.901560  [  256/  306]
train() client id: f_00004-5-8 loss: 1.119298  [  288/  306]
train() client id: f_00004-6-0 loss: 0.870224  [   32/  306]
train() client id: f_00004-6-1 loss: 0.927593  [   64/  306]
train() client id: f_00004-6-2 loss: 0.960753  [   96/  306]
train() client id: f_00004-6-3 loss: 0.862034  [  128/  306]
train() client id: f_00004-6-4 loss: 0.997377  [  160/  306]
train() client id: f_00004-6-5 loss: 0.978030  [  192/  306]
train() client id: f_00004-6-6 loss: 0.851030  [  224/  306]
train() client id: f_00004-6-7 loss: 0.936938  [  256/  306]
train() client id: f_00004-6-8 loss: 0.988768  [  288/  306]
train() client id: f_00004-7-0 loss: 0.971512  [   32/  306]
train() client id: f_00004-7-1 loss: 0.820396  [   64/  306]
train() client id: f_00004-7-2 loss: 0.983551  [   96/  306]
train() client id: f_00004-7-3 loss: 0.836233  [  128/  306]
train() client id: f_00004-7-4 loss: 0.895004  [  160/  306]
train() client id: f_00004-7-5 loss: 0.860577  [  192/  306]
train() client id: f_00004-7-6 loss: 0.929297  [  224/  306]
train() client id: f_00004-7-7 loss: 1.037981  [  256/  306]
train() client id: f_00004-7-8 loss: 0.913383  [  288/  306]
train() client id: f_00004-8-0 loss: 0.950961  [   32/  306]
train() client id: f_00004-8-1 loss: 1.009950  [   64/  306]
train() client id: f_00004-8-2 loss: 0.875484  [   96/  306]
train() client id: f_00004-8-3 loss: 0.821313  [  128/  306]
train() client id: f_00004-8-4 loss: 1.061422  [  160/  306]
train() client id: f_00004-8-5 loss: 0.903255  [  192/  306]
train() client id: f_00004-8-6 loss: 0.821867  [  224/  306]
train() client id: f_00004-8-7 loss: 0.897623  [  256/  306]
train() client id: f_00004-8-8 loss: 0.810794  [  288/  306]
train() client id: f_00004-9-0 loss: 1.031657  [   32/  306]
train() client id: f_00004-9-1 loss: 0.991142  [   64/  306]
train() client id: f_00004-9-2 loss: 0.939886  [   96/  306]
train() client id: f_00004-9-3 loss: 0.857787  [  128/  306]
train() client id: f_00004-9-4 loss: 0.831121  [  160/  306]
train() client id: f_00004-9-5 loss: 0.849385  [  192/  306]
train() client id: f_00004-9-6 loss: 0.904392  [  224/  306]
train() client id: f_00004-9-7 loss: 0.903832  [  256/  306]
train() client id: f_00004-9-8 loss: 0.915141  [  288/  306]
train() client id: f_00004-10-0 loss: 0.937532  [   32/  306]
train() client id: f_00004-10-1 loss: 1.043491  [   64/  306]
train() client id: f_00004-10-2 loss: 0.837939  [   96/  306]
train() client id: f_00004-10-3 loss: 0.838252  [  128/  306]
train() client id: f_00004-10-4 loss: 0.895574  [  160/  306]
train() client id: f_00004-10-5 loss: 1.030144  [  192/  306]
train() client id: f_00004-10-6 loss: 0.919812  [  224/  306]
train() client id: f_00004-10-7 loss: 0.954893  [  256/  306]
train() client id: f_00004-10-8 loss: 0.812371  [  288/  306]
train() client id: f_00004-11-0 loss: 0.862296  [   32/  306]
train() client id: f_00004-11-1 loss: 0.806905  [   64/  306]
train() client id: f_00004-11-2 loss: 1.004855  [   96/  306]
train() client id: f_00004-11-3 loss: 0.937824  [  128/  306]
train() client id: f_00004-11-4 loss: 0.854360  [  160/  306]
train() client id: f_00004-11-5 loss: 0.866783  [  192/  306]
train() client id: f_00004-11-6 loss: 0.995533  [  224/  306]
train() client id: f_00004-11-7 loss: 0.954238  [  256/  306]
train() client id: f_00004-11-8 loss: 0.895861  [  288/  306]
train() client id: f_00004-12-0 loss: 0.975646  [   32/  306]
train() client id: f_00004-12-1 loss: 0.781659  [   64/  306]
train() client id: f_00004-12-2 loss: 1.007272  [   96/  306]
train() client id: f_00004-12-3 loss: 0.993986  [  128/  306]
train() client id: f_00004-12-4 loss: 1.036343  [  160/  306]
train() client id: f_00004-12-5 loss: 0.899207  [  192/  306]
train() client id: f_00004-12-6 loss: 0.840230  [  224/  306]
train() client id: f_00004-12-7 loss: 0.882417  [  256/  306]
train() client id: f_00004-12-8 loss: 0.841729  [  288/  306]
train() client id: f_00005-0-0 loss: 0.373495  [   32/  146]
train() client id: f_00005-0-1 loss: 0.776595  [   64/  146]
train() client id: f_00005-0-2 loss: 0.701032  [   96/  146]
train() client id: f_00005-0-3 loss: 0.598517  [  128/  146]
train() client id: f_00005-1-0 loss: 0.509059  [   32/  146]
train() client id: f_00005-1-1 loss: 0.364292  [   64/  146]
train() client id: f_00005-1-2 loss: 0.479739  [   96/  146]
train() client id: f_00005-1-3 loss: 1.006521  [  128/  146]
train() client id: f_00005-2-0 loss: 0.604622  [   32/  146]
train() client id: f_00005-2-1 loss: 0.554843  [   64/  146]
train() client id: f_00005-2-2 loss: 0.375866  [   96/  146]
train() client id: f_00005-2-3 loss: 0.715160  [  128/  146]
train() client id: f_00005-3-0 loss: 0.949020  [   32/  146]
train() client id: f_00005-3-1 loss: 0.346261  [   64/  146]
train() client id: f_00005-3-2 loss: 0.744154  [   96/  146]
train() client id: f_00005-3-3 loss: 0.421639  [  128/  146]
train() client id: f_00005-4-0 loss: 0.608319  [   32/  146]
train() client id: f_00005-4-1 loss: 0.741968  [   64/  146]
train() client id: f_00005-4-2 loss: 0.408789  [   96/  146]
train() client id: f_00005-4-3 loss: 0.340668  [  128/  146]
train() client id: f_00005-5-0 loss: 0.192249  [   32/  146]
train() client id: f_00005-5-1 loss: 0.683374  [   64/  146]
train() client id: f_00005-5-2 loss: 0.767059  [   96/  146]
train() client id: f_00005-5-3 loss: 0.579979  [  128/  146]
train() client id: f_00005-6-0 loss: 0.625900  [   32/  146]
train() client id: f_00005-6-1 loss: 0.703146  [   64/  146]
train() client id: f_00005-6-2 loss: 0.444238  [   96/  146]
train() client id: f_00005-6-3 loss: 0.412331  [  128/  146]
train() client id: f_00005-7-0 loss: 0.700316  [   32/  146]
train() client id: f_00005-7-1 loss: 0.430695  [   64/  146]
train() client id: f_00005-7-2 loss: 0.719321  [   96/  146]
train() client id: f_00005-7-3 loss: 0.420292  [  128/  146]
train() client id: f_00005-8-0 loss: 0.636106  [   32/  146]
train() client id: f_00005-8-1 loss: 0.558970  [   64/  146]
train() client id: f_00005-8-2 loss: 0.529397  [   96/  146]
train() client id: f_00005-8-3 loss: 0.611923  [  128/  146]
train() client id: f_00005-9-0 loss: 0.491836  [   32/  146]
train() client id: f_00005-9-1 loss: 0.580427  [   64/  146]
train() client id: f_00005-9-2 loss: 0.420290  [   96/  146]
train() client id: f_00005-9-3 loss: 0.621712  [  128/  146]
train() client id: f_00005-10-0 loss: 0.351562  [   32/  146]
train() client id: f_00005-10-1 loss: 0.464853  [   64/  146]
train() client id: f_00005-10-2 loss: 0.544941  [   96/  146]
train() client id: f_00005-10-3 loss: 0.779524  [  128/  146]
train() client id: f_00005-11-0 loss: 0.742360  [   32/  146]
train() client id: f_00005-11-1 loss: 0.526720  [   64/  146]
train() client id: f_00005-11-2 loss: 0.471447  [   96/  146]
train() client id: f_00005-11-3 loss: 0.414546  [  128/  146]
train() client id: f_00005-12-0 loss: 0.276473  [   32/  146]
train() client id: f_00005-12-1 loss: 0.436147  [   64/  146]
train() client id: f_00005-12-2 loss: 0.662417  [   96/  146]
train() client id: f_00005-12-3 loss: 0.613127  [  128/  146]
train() client id: f_00006-0-0 loss: 0.504179  [   32/   54]
train() client id: f_00006-1-0 loss: 0.574786  [   32/   54]
train() client id: f_00006-2-0 loss: 0.492403  [   32/   54]
train() client id: f_00006-3-0 loss: 0.495964  [   32/   54]
train() client id: f_00006-4-0 loss: 0.528852  [   32/   54]
train() client id: f_00006-5-0 loss: 0.540551  [   32/   54]
train() client id: f_00006-6-0 loss: 0.559748  [   32/   54]
train() client id: f_00006-7-0 loss: 0.550054  [   32/   54]
train() client id: f_00006-8-0 loss: 0.499758  [   32/   54]
train() client id: f_00006-9-0 loss: 0.559978  [   32/   54]
train() client id: f_00006-10-0 loss: 0.551522  [   32/   54]
train() client id: f_00006-11-0 loss: 0.522520  [   32/   54]
train() client id: f_00006-12-0 loss: 0.545513  [   32/   54]
train() client id: f_00007-0-0 loss: 0.787743  [   32/  179]
train() client id: f_00007-0-1 loss: 0.588390  [   64/  179]
train() client id: f_00007-0-2 loss: 0.351085  [   96/  179]
train() client id: f_00007-0-3 loss: 0.595471  [  128/  179]
train() client id: f_00007-0-4 loss: 0.531513  [  160/  179]
train() client id: f_00007-1-0 loss: 0.410189  [   32/  179]
train() client id: f_00007-1-1 loss: 0.539466  [   64/  179]
train() client id: f_00007-1-2 loss: 0.683614  [   96/  179]
train() client id: f_00007-1-3 loss: 0.477606  [  128/  179]
train() client id: f_00007-1-4 loss: 0.666135  [  160/  179]
train() client id: f_00007-2-0 loss: 0.714665  [   32/  179]
train() client id: f_00007-2-1 loss: 0.545196  [   64/  179]
train() client id: f_00007-2-2 loss: 0.487053  [   96/  179]
train() client id: f_00007-2-3 loss: 0.350658  [  128/  179]
train() client id: f_00007-2-4 loss: 0.381296  [  160/  179]
train() client id: f_00007-3-0 loss: 0.595499  [   32/  179]
train() client id: f_00007-3-1 loss: 0.435891  [   64/  179]
train() client id: f_00007-3-2 loss: 0.541060  [   96/  179]
train() client id: f_00007-3-3 loss: 0.368410  [  128/  179]
train() client id: f_00007-3-4 loss: 0.626761  [  160/  179]
train() client id: f_00007-4-0 loss: 0.384344  [   32/  179]
train() client id: f_00007-4-1 loss: 0.354690  [   64/  179]
train() client id: f_00007-4-2 loss: 0.560767  [   96/  179]
train() client id: f_00007-4-3 loss: 0.528428  [  128/  179]
train() client id: f_00007-4-4 loss: 0.528845  [  160/  179]
train() client id: f_00007-5-0 loss: 0.368563  [   32/  179]
train() client id: f_00007-5-1 loss: 0.638700  [   64/  179]
train() client id: f_00007-5-2 loss: 0.414047  [   96/  179]
train() client id: f_00007-5-3 loss: 0.458619  [  128/  179]
train() client id: f_00007-5-4 loss: 0.671590  [  160/  179]
train() client id: f_00007-6-0 loss: 0.661071  [   32/  179]
train() client id: f_00007-6-1 loss: 0.561439  [   64/  179]
train() client id: f_00007-6-2 loss: 0.399129  [   96/  179]
train() client id: f_00007-6-3 loss: 0.414095  [  128/  179]
train() client id: f_00007-6-4 loss: 0.333411  [  160/  179]
train() client id: f_00007-7-0 loss: 0.606966  [   32/  179]
train() client id: f_00007-7-1 loss: 0.534626  [   64/  179]
train() client id: f_00007-7-2 loss: 0.310003  [   96/  179]
train() client id: f_00007-7-3 loss: 0.552223  [  128/  179]
train() client id: f_00007-7-4 loss: 0.314861  [  160/  179]
train() client id: f_00007-8-0 loss: 0.474570  [   32/  179]
train() client id: f_00007-8-1 loss: 0.489080  [   64/  179]
train() client id: f_00007-8-2 loss: 0.354941  [   96/  179]
train() client id: f_00007-8-3 loss: 0.544502  [  128/  179]
train() client id: f_00007-8-4 loss: 0.416110  [  160/  179]
train() client id: f_00007-9-0 loss: 0.407056  [   32/  179]
train() client id: f_00007-9-1 loss: 0.544871  [   64/  179]
train() client id: f_00007-9-2 loss: 0.338777  [   96/  179]
train() client id: f_00007-9-3 loss: 0.562994  [  128/  179]
train() client id: f_00007-9-4 loss: 0.529638  [  160/  179]
train() client id: f_00007-10-0 loss: 0.740056  [   32/  179]
train() client id: f_00007-10-1 loss: 0.323413  [   64/  179]
train() client id: f_00007-10-2 loss: 0.397990  [   96/  179]
train() client id: f_00007-10-3 loss: 0.346330  [  128/  179]
train() client id: f_00007-10-4 loss: 0.561477  [  160/  179]
train() client id: f_00007-11-0 loss: 0.672249  [   32/  179]
train() client id: f_00007-11-1 loss: 0.356510  [   64/  179]
train() client id: f_00007-11-2 loss: 0.506254  [   96/  179]
train() client id: f_00007-11-3 loss: 0.435460  [  128/  179]
train() client id: f_00007-11-4 loss: 0.486741  [  160/  179]
train() client id: f_00007-12-0 loss: 0.424376  [   32/  179]
train() client id: f_00007-12-1 loss: 0.583237  [   64/  179]
train() client id: f_00007-12-2 loss: 0.311645  [   96/  179]
train() client id: f_00007-12-3 loss: 0.519081  [  128/  179]
train() client id: f_00007-12-4 loss: 0.534373  [  160/  179]
train() client id: f_00008-0-0 loss: 0.752236  [   32/  130]
train() client id: f_00008-0-1 loss: 0.745128  [   64/  130]
train() client id: f_00008-0-2 loss: 0.758785  [   96/  130]
train() client id: f_00008-0-3 loss: 0.917734  [  128/  130]
train() client id: f_00008-1-0 loss: 0.792661  [   32/  130]
train() client id: f_00008-1-1 loss: 0.672991  [   64/  130]
train() client id: f_00008-1-2 loss: 0.814647  [   96/  130]
train() client id: f_00008-1-3 loss: 0.833712  [  128/  130]
train() client id: f_00008-2-0 loss: 0.719586  [   32/  130]
train() client id: f_00008-2-1 loss: 0.881415  [   64/  130]
train() client id: f_00008-2-2 loss: 0.849434  [   96/  130]
train() client id: f_00008-2-3 loss: 0.722562  [  128/  130]
train() client id: f_00008-3-0 loss: 0.797878  [   32/  130]
train() client id: f_00008-3-1 loss: 0.787014  [   64/  130]
train() client id: f_00008-3-2 loss: 0.817468  [   96/  130]
train() client id: f_00008-3-3 loss: 0.697118  [  128/  130]
train() client id: f_00008-4-0 loss: 0.785992  [   32/  130]
train() client id: f_00008-4-1 loss: 0.757186  [   64/  130]
train() client id: f_00008-4-2 loss: 0.870555  [   96/  130]
train() client id: f_00008-4-3 loss: 0.752617  [  128/  130]
train() client id: f_00008-5-0 loss: 0.784026  [   32/  130]
train() client id: f_00008-5-1 loss: 0.754912  [   64/  130]
train() client id: f_00008-5-2 loss: 0.741578  [   96/  130]
train() client id: f_00008-5-3 loss: 0.856796  [  128/  130]
train() client id: f_00008-6-0 loss: 0.724314  [   32/  130]
train() client id: f_00008-6-1 loss: 0.776051  [   64/  130]
train() client id: f_00008-6-2 loss: 0.810632  [   96/  130]
train() client id: f_00008-6-3 loss: 0.834311  [  128/  130]
train() client id: f_00008-7-0 loss: 0.714624  [   32/  130]
train() client id: f_00008-7-1 loss: 0.736422  [   64/  130]
train() client id: f_00008-7-2 loss: 0.882117  [   96/  130]
train() client id: f_00008-7-3 loss: 0.824910  [  128/  130]
train() client id: f_00008-8-0 loss: 0.865831  [   32/  130]
train() client id: f_00008-8-1 loss: 0.802321  [   64/  130]
train() client id: f_00008-8-2 loss: 0.727292  [   96/  130]
train() client id: f_00008-8-3 loss: 0.760056  [  128/  130]
train() client id: f_00008-9-0 loss: 0.844912  [   32/  130]
train() client id: f_00008-9-1 loss: 0.731559  [   64/  130]
train() client id: f_00008-9-2 loss: 0.807925  [   96/  130]
train() client id: f_00008-9-3 loss: 0.770931  [  128/  130]
train() client id: f_00008-10-0 loss: 0.707912  [   32/  130]
train() client id: f_00008-10-1 loss: 0.788363  [   64/  130]
train() client id: f_00008-10-2 loss: 0.781029  [   96/  130]
train() client id: f_00008-10-3 loss: 0.857670  [  128/  130]
train() client id: f_00008-11-0 loss: 0.748936  [   32/  130]
train() client id: f_00008-11-1 loss: 0.836260  [   64/  130]
train() client id: f_00008-11-2 loss: 0.839760  [   96/  130]
train() client id: f_00008-11-3 loss: 0.730591  [  128/  130]
train() client id: f_00008-12-0 loss: 0.854968  [   32/  130]
train() client id: f_00008-12-1 loss: 0.689423  [   64/  130]
train() client id: f_00008-12-2 loss: 0.759571  [   96/  130]
train() client id: f_00008-12-3 loss: 0.847934  [  128/  130]
train() client id: f_00009-0-0 loss: 1.287535  [   32/  118]
train() client id: f_00009-0-1 loss: 1.042951  [   64/  118]
train() client id: f_00009-0-2 loss: 1.084276  [   96/  118]
train() client id: f_00009-1-0 loss: 1.111690  [   32/  118]
train() client id: f_00009-1-1 loss: 0.961267  [   64/  118]
train() client id: f_00009-1-2 loss: 1.178614  [   96/  118]
train() client id: f_00009-2-0 loss: 0.888776  [   32/  118]
train() client id: f_00009-2-1 loss: 1.080328  [   64/  118]
train() client id: f_00009-2-2 loss: 1.150932  [   96/  118]
train() client id: f_00009-3-0 loss: 0.945598  [   32/  118]
train() client id: f_00009-3-1 loss: 0.931753  [   64/  118]
train() client id: f_00009-3-2 loss: 1.082587  [   96/  118]
train() client id: f_00009-4-0 loss: 0.974622  [   32/  118]
train() client id: f_00009-4-1 loss: 0.966153  [   64/  118]
train() client id: f_00009-4-2 loss: 1.001881  [   96/  118]
train() client id: f_00009-5-0 loss: 0.813057  [   32/  118]
train() client id: f_00009-5-1 loss: 1.017535  [   64/  118]
train() client id: f_00009-5-2 loss: 0.997409  [   96/  118]
train() client id: f_00009-6-0 loss: 0.942077  [   32/  118]
train() client id: f_00009-6-1 loss: 1.018477  [   64/  118]
train() client id: f_00009-6-2 loss: 0.795414  [   96/  118]
train() client id: f_00009-7-0 loss: 0.878427  [   32/  118]
train() client id: f_00009-7-1 loss: 0.924819  [   64/  118]
train() client id: f_00009-7-2 loss: 0.919967  [   96/  118]
train() client id: f_00009-8-0 loss: 0.898250  [   32/  118]
train() client id: f_00009-8-1 loss: 1.112393  [   64/  118]
train() client id: f_00009-8-2 loss: 0.902899  [   96/  118]
train() client id: f_00009-9-0 loss: 0.880073  [   32/  118]
train() client id: f_00009-9-1 loss: 1.032900  [   64/  118]
train() client id: f_00009-9-2 loss: 0.780320  [   96/  118]
train() client id: f_00009-10-0 loss: 0.963684  [   32/  118]
train() client id: f_00009-10-1 loss: 1.029409  [   64/  118]
train() client id: f_00009-10-2 loss: 0.882621  [   96/  118]
train() client id: f_00009-11-0 loss: 0.845878  [   32/  118]
train() client id: f_00009-11-1 loss: 0.988141  [   64/  118]
train() client id: f_00009-11-2 loss: 0.847177  [   96/  118]
train() client id: f_00009-12-0 loss: 0.968793  [   32/  118]
train() client id: f_00009-12-1 loss: 0.778898  [   64/  118]
train() client id: f_00009-12-2 loss: 0.919721  [   96/  118]
At round 59 accuracy: 0.6392572944297082
At round 59 training accuracy: 0.5922199865861838
At round 59 training loss: 0.8256846821687243
gradient difference: 0.4478786885738373
train() client id: f_00000-0-0 loss: 1.211296  [   32/  126]
train() client id: f_00000-0-1 loss: 1.182652  [   64/  126]
train() client id: f_00000-0-2 loss: 1.134667  [   96/  126]
train() client id: f_00000-1-0 loss: 0.976184  [   32/  126]
train() client id: f_00000-1-1 loss: 1.153505  [   64/  126]
train() client id: f_00000-1-2 loss: 1.011103  [   96/  126]
train() client id: f_00000-2-0 loss: 1.039111  [   32/  126]
train() client id: f_00000-2-1 loss: 1.103613  [   64/  126]
train() client id: f_00000-2-2 loss: 1.096102  [   96/  126]
train() client id: f_00000-3-0 loss: 0.979566  [   32/  126]
train() client id: f_00000-3-1 loss: 0.967683  [   64/  126]
train() client id: f_00000-3-2 loss: 0.933599  [   96/  126]
train() client id: f_00000-4-0 loss: 0.942443  [   32/  126]
train() client id: f_00000-4-1 loss: 0.909877  [   64/  126]
train() client id: f_00000-4-2 loss: 0.952365  [   96/  126]
train() client id: f_00000-5-0 loss: 0.930376  [   32/  126]
train() client id: f_00000-5-1 loss: 0.997072  [   64/  126]
train() client id: f_00000-5-2 loss: 1.010292  [   96/  126]
train() client id: f_00000-6-0 loss: 0.766008  [   32/  126]
train() client id: f_00000-6-1 loss: 0.944885  [   64/  126]
train() client id: f_00000-6-2 loss: 0.851761  [   96/  126]
train() client id: f_00000-7-0 loss: 0.739346  [   32/  126]
train() client id: f_00000-7-1 loss: 1.015172  [   64/  126]
train() client id: f_00000-7-2 loss: 0.994167  [   96/  126]
train() client id: f_00000-8-0 loss: 0.849928  [   32/  126]
train() client id: f_00000-8-1 loss: 0.844997  [   64/  126]
train() client id: f_00000-8-2 loss: 0.938483  [   96/  126]
train() client id: f_00000-9-0 loss: 0.962194  [   32/  126]
train() client id: f_00000-9-1 loss: 0.837563  [   64/  126]
train() client id: f_00000-9-2 loss: 0.850309  [   96/  126]
train() client id: f_00000-10-0 loss: 0.787740  [   32/  126]
train() client id: f_00000-10-1 loss: 1.005349  [   64/  126]
train() client id: f_00000-10-2 loss: 0.934063  [   96/  126]
train() client id: f_00000-11-0 loss: 0.949154  [   32/  126]
train() client id: f_00000-11-1 loss: 0.834973  [   64/  126]
train() client id: f_00000-11-2 loss: 0.860870  [   96/  126]
train() client id: f_00000-12-0 loss: 0.816026  [   32/  126]
train() client id: f_00000-12-1 loss: 0.927130  [   64/  126]
train() client id: f_00000-12-2 loss: 0.836311  [   96/  126]
train() client id: f_00001-0-0 loss: 0.489302  [   32/  265]
train() client id: f_00001-0-1 loss: 0.474297  [   64/  265]
train() client id: f_00001-0-2 loss: 0.433331  [   96/  265]
train() client id: f_00001-0-3 loss: 0.467183  [  128/  265]
train() client id: f_00001-0-4 loss: 0.543308  [  160/  265]
train() client id: f_00001-0-5 loss: 0.648175  [  192/  265]
train() client id: f_00001-0-6 loss: 0.417709  [  224/  265]
train() client id: f_00001-0-7 loss: 0.405037  [  256/  265]
train() client id: f_00001-1-0 loss: 0.460296  [   32/  265]
train() client id: f_00001-1-1 loss: 0.427992  [   64/  265]
train() client id: f_00001-1-2 loss: 0.602849  [   96/  265]
train() client id: f_00001-1-3 loss: 0.523803  [  128/  265]
train() client id: f_00001-1-4 loss: 0.457818  [  160/  265]
train() client id: f_00001-1-5 loss: 0.383458  [  192/  265]
train() client id: f_00001-1-6 loss: 0.481921  [  224/  265]
train() client id: f_00001-1-7 loss: 0.421352  [  256/  265]
train() client id: f_00001-2-0 loss: 0.524586  [   32/  265]
train() client id: f_00001-2-1 loss: 0.491511  [   64/  265]
train() client id: f_00001-2-2 loss: 0.413095  [   96/  265]
train() client id: f_00001-2-3 loss: 0.376143  [  128/  265]
train() client id: f_00001-2-4 loss: 0.556583  [  160/  265]
train() client id: f_00001-2-5 loss: 0.476223  [  192/  265]
train() client id: f_00001-2-6 loss: 0.403830  [  224/  265]
train() client id: f_00001-2-7 loss: 0.541934  [  256/  265]
train() client id: f_00001-3-0 loss: 0.445028  [   32/  265]
train() client id: f_00001-3-1 loss: 0.379643  [   64/  265]
train() client id: f_00001-3-2 loss: 0.597982  [   96/  265]
train() client id: f_00001-3-3 loss: 0.426243  [  128/  265]
train() client id: f_00001-3-4 loss: 0.390816  [  160/  265]
train() client id: f_00001-3-5 loss: 0.419505  [  192/  265]
train() client id: f_00001-3-6 loss: 0.571769  [  224/  265]
train() client id: f_00001-3-7 loss: 0.512498  [  256/  265]
train() client id: f_00001-4-0 loss: 0.560774  [   32/  265]
train() client id: f_00001-4-1 loss: 0.494771  [   64/  265]
train() client id: f_00001-4-2 loss: 0.420463  [   96/  265]
train() client id: f_00001-4-3 loss: 0.547897  [  128/  265]
train() client id: f_00001-4-4 loss: 0.379266  [  160/  265]
train() client id: f_00001-4-5 loss: 0.502336  [  192/  265]
train() client id: f_00001-4-6 loss: 0.392663  [  224/  265]
train() client id: f_00001-4-7 loss: 0.444803  [  256/  265]
train() client id: f_00001-5-0 loss: 0.436591  [   32/  265]
train() client id: f_00001-5-1 loss: 0.514690  [   64/  265]
train() client id: f_00001-5-2 loss: 0.415505  [   96/  265]
train() client id: f_00001-5-3 loss: 0.439495  [  128/  265]
train() client id: f_00001-5-4 loss: 0.538970  [  160/  265]
train() client id: f_00001-5-5 loss: 0.473233  [  192/  265]
train() client id: f_00001-5-6 loss: 0.442204  [  224/  265]
train() client id: f_00001-5-7 loss: 0.376808  [  256/  265]
train() client id: f_00001-6-0 loss: 0.472351  [   32/  265]
train() client id: f_00001-6-1 loss: 0.407822  [   64/  265]
train() client id: f_00001-6-2 loss: 0.350993  [   96/  265]
train() client id: f_00001-6-3 loss: 0.546378  [  128/  265]
train() client id: f_00001-6-4 loss: 0.450401  [  160/  265]
train() client id: f_00001-6-5 loss: 0.378011  [  192/  265]
train() client id: f_00001-6-6 loss: 0.587191  [  224/  265]
train() client id: f_00001-6-7 loss: 0.469860  [  256/  265]
train() client id: f_00001-7-0 loss: 0.573977  [   32/  265]
train() client id: f_00001-7-1 loss: 0.506458  [   64/  265]
train() client id: f_00001-7-2 loss: 0.449905  [   96/  265]
train() client id: f_00001-7-3 loss: 0.459747  [  128/  265]
train() client id: f_00001-7-4 loss: 0.456574  [  160/  265]
train() client id: f_00001-7-5 loss: 0.503198  [  192/  265]
train() client id: f_00001-7-6 loss: 0.360168  [  224/  265]
train() client id: f_00001-7-7 loss: 0.394531  [  256/  265]
train() client id: f_00001-8-0 loss: 0.430263  [   32/  265]
train() client id: f_00001-8-1 loss: 0.433390  [   64/  265]
train() client id: f_00001-8-2 loss: 0.509934  [   96/  265]
train() client id: f_00001-8-3 loss: 0.492179  [  128/  265]
train() client id: f_00001-8-4 loss: 0.431677  [  160/  265]
train() client id: f_00001-8-5 loss: 0.384050  [  192/  265]
train() client id: f_00001-8-6 loss: 0.400533  [  224/  265]
train() client id: f_00001-8-7 loss: 0.537205  [  256/  265]
train() client id: f_00001-9-0 loss: 0.362146  [   32/  265]
train() client id: f_00001-9-1 loss: 0.352812  [   64/  265]
train() client id: f_00001-9-2 loss: 0.469679  [   96/  265]
train() client id: f_00001-9-3 loss: 0.452623  [  128/  265]
train() client id: f_00001-9-4 loss: 0.604143  [  160/  265]
train() client id: f_00001-9-5 loss: 0.592752  [  192/  265]
train() client id: f_00001-9-6 loss: 0.396878  [  224/  265]
train() client id: f_00001-9-7 loss: 0.457221  [  256/  265]
train() client id: f_00001-10-0 loss: 0.507517  [   32/  265]
train() client id: f_00001-10-1 loss: 0.480454  [   64/  265]
train() client id: f_00001-10-2 loss: 0.430386  [   96/  265]
train() client id: f_00001-10-3 loss: 0.389649  [  128/  265]
train() client id: f_00001-10-4 loss: 0.494765  [  160/  265]
train() client id: f_00001-10-5 loss: 0.566195  [  192/  265]
train() client id: f_00001-10-6 loss: 0.381085  [  224/  265]
train() client id: f_00001-10-7 loss: 0.485769  [  256/  265]
train() client id: f_00001-11-0 loss: 0.577680  [   32/  265]
train() client id: f_00001-11-1 loss: 0.516839  [   64/  265]
train() client id: f_00001-11-2 loss: 0.350551  [   96/  265]
train() client id: f_00001-11-3 loss: 0.423605  [  128/  265]
train() client id: f_00001-11-4 loss: 0.368870  [  160/  265]
train() client id: f_00001-11-5 loss: 0.461563  [  192/  265]
train() client id: f_00001-11-6 loss: 0.574759  [  224/  265]
train() client id: f_00001-11-7 loss: 0.377013  [  256/  265]
train() client id: f_00001-12-0 loss: 0.519432  [   32/  265]
train() client id: f_00001-12-1 loss: 0.439068  [   64/  265]
train() client id: f_00001-12-2 loss: 0.363254  [   96/  265]
train() client id: f_00001-12-3 loss: 0.523115  [  128/  265]
train() client id: f_00001-12-4 loss: 0.454997  [  160/  265]
train() client id: f_00001-12-5 loss: 0.544260  [  192/  265]
train() client id: f_00001-12-6 loss: 0.439851  [  224/  265]
train() client id: f_00001-12-7 loss: 0.361979  [  256/  265]
train() client id: f_00002-0-0 loss: 0.855557  [   32/  124]
train() client id: f_00002-0-1 loss: 0.993191  [   64/  124]
train() client id: f_00002-0-2 loss: 0.933590  [   96/  124]
train() client id: f_00002-1-0 loss: 0.930384  [   32/  124]
train() client id: f_00002-1-1 loss: 1.034849  [   64/  124]
train() client id: f_00002-1-2 loss: 0.966739  [   96/  124]
train() client id: f_00002-2-0 loss: 0.885752  [   32/  124]
train() client id: f_00002-2-1 loss: 0.901171  [   64/  124]
train() client id: f_00002-2-2 loss: 0.860711  [   96/  124]
train() client id: f_00002-3-0 loss: 0.797334  [   32/  124]
train() client id: f_00002-3-1 loss: 1.008250  [   64/  124]
train() client id: f_00002-3-2 loss: 0.987787  [   96/  124]
train() client id: f_00002-4-0 loss: 0.781859  [   32/  124]
train() client id: f_00002-4-1 loss: 1.030336  [   64/  124]
train() client id: f_00002-4-2 loss: 0.752334  [   96/  124]
train() client id: f_00002-5-0 loss: 0.943034  [   32/  124]
train() client id: f_00002-5-1 loss: 0.829224  [   64/  124]
train() client id: f_00002-5-2 loss: 0.697390  [   96/  124]
train() client id: f_00002-6-0 loss: 0.796849  [   32/  124]
train() client id: f_00002-6-1 loss: 1.016499  [   64/  124]
train() client id: f_00002-6-2 loss: 0.946156  [   96/  124]
train() client id: f_00002-7-0 loss: 0.894478  [   32/  124]
train() client id: f_00002-7-1 loss: 0.712497  [   64/  124]
train() client id: f_00002-7-2 loss: 0.934177  [   96/  124]
train() client id: f_00002-8-0 loss: 0.699914  [   32/  124]
train() client id: f_00002-8-1 loss: 1.170984  [   64/  124]
train() client id: f_00002-8-2 loss: 0.647132  [   96/  124]
train() client id: f_00002-9-0 loss: 0.849821  [   32/  124]
train() client id: f_00002-9-1 loss: 0.876288  [   64/  124]
train() client id: f_00002-9-2 loss: 0.959634  [   96/  124]
train() client id: f_00002-10-0 loss: 0.911636  [   32/  124]
train() client id: f_00002-10-1 loss: 0.790648  [   64/  124]
train() client id: f_00002-10-2 loss: 0.836757  [   96/  124]
train() client id: f_00002-11-0 loss: 0.895764  [   32/  124]
train() client id: f_00002-11-1 loss: 0.947638  [   64/  124]
train() client id: f_00002-11-2 loss: 0.789030  [   96/  124]
train() client id: f_00002-12-0 loss: 0.849901  [   32/  124]
train() client id: f_00002-12-1 loss: 0.874700  [   64/  124]
train() client id: f_00002-12-2 loss: 0.812487  [   96/  124]
train() client id: f_00003-0-0 loss: 0.714247  [   32/   43]
train() client id: f_00003-1-0 loss: 0.696223  [   32/   43]
train() client id: f_00003-2-0 loss: 0.907036  [   32/   43]
train() client id: f_00003-3-0 loss: 0.937610  [   32/   43]
train() client id: f_00003-4-0 loss: 0.819206  [   32/   43]
train() client id: f_00003-5-0 loss: 0.557711  [   32/   43]
train() client id: f_00003-6-0 loss: 0.808743  [   32/   43]
train() client id: f_00003-7-0 loss: 0.786402  [   32/   43]
train() client id: f_00003-8-0 loss: 0.793379  [   32/   43]
train() client id: f_00003-9-0 loss: 0.868011  [   32/   43]
train() client id: f_00003-10-0 loss: 0.816494  [   32/   43]
train() client id: f_00003-11-0 loss: 0.792925  [   32/   43]
train() client id: f_00003-12-0 loss: 0.733641  [   32/   43]
train() client id: f_00004-0-0 loss: 0.953885  [   32/  306]
train() client id: f_00004-0-1 loss: 0.922234  [   64/  306]
train() client id: f_00004-0-2 loss: 1.012654  [   96/  306]
train() client id: f_00004-0-3 loss: 0.732293  [  128/  306]
train() client id: f_00004-0-4 loss: 0.969697  [  160/  306]
train() client id: f_00004-0-5 loss: 0.876731  [  192/  306]
train() client id: f_00004-0-6 loss: 1.021742  [  224/  306]
train() client id: f_00004-0-7 loss: 0.981561  [  256/  306]
train() client id: f_00004-0-8 loss: 0.940304  [  288/  306]
train() client id: f_00004-1-0 loss: 0.872174  [   32/  306]
train() client id: f_00004-1-1 loss: 0.898907  [   64/  306]
train() client id: f_00004-1-2 loss: 0.993589  [   96/  306]
train() client id: f_00004-1-3 loss: 0.888340  [  128/  306]
train() client id: f_00004-1-4 loss: 0.899711  [  160/  306]
train() client id: f_00004-1-5 loss: 0.873773  [  192/  306]
train() client id: f_00004-1-6 loss: 0.986572  [  224/  306]
train() client id: f_00004-1-7 loss: 0.909051  [  256/  306]
train() client id: f_00004-1-8 loss: 0.974892  [  288/  306]
train() client id: f_00004-2-0 loss: 0.933279  [   32/  306]
train() client id: f_00004-2-1 loss: 0.857742  [   64/  306]
train() client id: f_00004-2-2 loss: 0.994437  [   96/  306]
train() client id: f_00004-2-3 loss: 0.904798  [  128/  306]
train() client id: f_00004-2-4 loss: 0.848350  [  160/  306]
train() client id: f_00004-2-5 loss: 1.027505  [  192/  306]
train() client id: f_00004-2-6 loss: 0.910721  [  224/  306]
train() client id: f_00004-2-7 loss: 0.996125  [  256/  306]
train() client id: f_00004-2-8 loss: 0.864018  [  288/  306]
train() client id: f_00004-3-0 loss: 0.847546  [   32/  306]
train() client id: f_00004-3-1 loss: 0.965632  [   64/  306]
train() client id: f_00004-3-2 loss: 1.020102  [   96/  306]
train() client id: f_00004-3-3 loss: 0.785011  [  128/  306]
train() client id: f_00004-3-4 loss: 0.952016  [  160/  306]
train() client id: f_00004-3-5 loss: 0.933761  [  192/  306]
train() client id: f_00004-3-6 loss: 0.807505  [  224/  306]
train() client id: f_00004-3-7 loss: 1.025722  [  256/  306]
train() client id: f_00004-3-8 loss: 0.895941  [  288/  306]
train() client id: f_00004-4-0 loss: 0.802176  [   32/  306]
train() client id: f_00004-4-1 loss: 0.949367  [   64/  306]
train() client id: f_00004-4-2 loss: 0.843923  [   96/  306]
train() client id: f_00004-4-3 loss: 0.915890  [  128/  306]
train() client id: f_00004-4-4 loss: 0.914059  [  160/  306]
train() client id: f_00004-4-5 loss: 0.886919  [  192/  306]
train() client id: f_00004-4-6 loss: 1.057865  [  224/  306]
train() client id: f_00004-4-7 loss: 0.818027  [  256/  306]
train() client id: f_00004-4-8 loss: 1.092437  [  288/  306]
train() client id: f_00004-5-0 loss: 0.955428  [   32/  306]
train() client id: f_00004-5-1 loss: 0.871711  [   64/  306]
train() client id: f_00004-5-2 loss: 0.980834  [   96/  306]
train() client id: f_00004-5-3 loss: 0.912046  [  128/  306]
train() client id: f_00004-5-4 loss: 0.893037  [  160/  306]
train() client id: f_00004-5-5 loss: 0.853308  [  192/  306]
train() client id: f_00004-5-6 loss: 1.112308  [  224/  306]
train() client id: f_00004-5-7 loss: 0.835471  [  256/  306]
train() client id: f_00004-5-8 loss: 0.949314  [  288/  306]
train() client id: f_00004-6-0 loss: 0.955199  [   32/  306]
train() client id: f_00004-6-1 loss: 0.882846  [   64/  306]
train() client id: f_00004-6-2 loss: 1.110023  [   96/  306]
train() client id: f_00004-6-3 loss: 0.903429  [  128/  306]
train() client id: f_00004-6-4 loss: 0.898469  [  160/  306]
train() client id: f_00004-6-5 loss: 0.851099  [  192/  306]
train() client id: f_00004-6-6 loss: 0.909520  [  224/  306]
train() client id: f_00004-6-7 loss: 0.855802  [  256/  306]
train() client id: f_00004-6-8 loss: 0.894295  [  288/  306]
train() client id: f_00004-7-0 loss: 0.928036  [   32/  306]
train() client id: f_00004-7-1 loss: 0.875612  [   64/  306]
train() client id: f_00004-7-2 loss: 0.849879  [   96/  306]
train() client id: f_00004-7-3 loss: 1.109550  [  128/  306]
train() client id: f_00004-7-4 loss: 0.848474  [  160/  306]
train() client id: f_00004-7-5 loss: 0.959838  [  192/  306]
train() client id: f_00004-7-6 loss: 0.938114  [  224/  306]
train() client id: f_00004-7-7 loss: 0.927516  [  256/  306]
train() client id: f_00004-7-8 loss: 0.816864  [  288/  306]
train() client id: f_00004-8-0 loss: 0.848952  [   32/  306]
train() client id: f_00004-8-1 loss: 0.751161  [   64/  306]
train() client id: f_00004-8-2 loss: 0.803471  [   96/  306]
train() client id: f_00004-8-3 loss: 0.907639  [  128/  306]
train() client id: f_00004-8-4 loss: 1.090967  [  160/  306]
train() client id: f_00004-8-5 loss: 0.955549  [  192/  306]
train() client id: f_00004-8-6 loss: 0.839522  [  224/  306]
train() client id: f_00004-8-7 loss: 1.002118  [  256/  306]
train() client id: f_00004-8-8 loss: 0.930039  [  288/  306]
train() client id: f_00004-9-0 loss: 0.929720  [   32/  306]
train() client id: f_00004-9-1 loss: 0.868345  [   64/  306]
train() client id: f_00004-9-2 loss: 0.883647  [   96/  306]
train() client id: f_00004-9-3 loss: 0.919438  [  128/  306]
train() client id: f_00004-9-4 loss: 0.868842  [  160/  306]
train() client id: f_00004-9-5 loss: 1.029765  [  192/  306]
train() client id: f_00004-9-6 loss: 0.948758  [  224/  306]
train() client id: f_00004-9-7 loss: 0.885286  [  256/  306]
train() client id: f_00004-9-8 loss: 0.897366  [  288/  306]
train() client id: f_00004-10-0 loss: 0.902323  [   32/  306]
train() client id: f_00004-10-1 loss: 1.030879  [   64/  306]
train() client id: f_00004-10-2 loss: 0.829494  [   96/  306]
train() client id: f_00004-10-3 loss: 0.960070  [  128/  306]
train() client id: f_00004-10-4 loss: 0.726593  [  160/  306]
train() client id: f_00004-10-5 loss: 0.899107  [  192/  306]
train() client id: f_00004-10-6 loss: 0.914735  [  224/  306]
train() client id: f_00004-10-7 loss: 1.099289  [  256/  306]
train() client id: f_00004-10-8 loss: 0.835588  [  288/  306]
train() client id: f_00004-11-0 loss: 0.955992  [   32/  306]
train() client id: f_00004-11-1 loss: 0.933878  [   64/  306]
train() client id: f_00004-11-2 loss: 0.857125  [   96/  306]
train() client id: f_00004-11-3 loss: 0.954040  [  128/  306]
train() client id: f_00004-11-4 loss: 0.931855  [  160/  306]
train() client id: f_00004-11-5 loss: 0.963911  [  192/  306]
train() client id: f_00004-11-6 loss: 0.787123  [  224/  306]
train() client id: f_00004-11-7 loss: 0.838216  [  256/  306]
train() client id: f_00004-11-8 loss: 0.934078  [  288/  306]
train() client id: f_00004-12-0 loss: 0.899791  [   32/  306]
train() client id: f_00004-12-1 loss: 0.940515  [   64/  306]
train() client id: f_00004-12-2 loss: 0.843969  [   96/  306]
train() client id: f_00004-12-3 loss: 0.835754  [  128/  306]
train() client id: f_00004-12-4 loss: 0.900949  [  160/  306]
train() client id: f_00004-12-5 loss: 0.884904  [  192/  306]
train() client id: f_00004-12-6 loss: 0.891831  [  224/  306]
train() client id: f_00004-12-7 loss: 1.056754  [  256/  306]
train() client id: f_00004-12-8 loss: 0.933599  [  288/  306]
train() client id: f_00005-0-0 loss: 0.568488  [   32/  146]
train() client id: f_00005-0-1 loss: 0.710249  [   64/  146]
train() client id: f_00005-0-2 loss: 0.419126  [   96/  146]
train() client id: f_00005-0-3 loss: 0.503296  [  128/  146]
train() client id: f_00005-1-0 loss: 0.771657  [   32/  146]
train() client id: f_00005-1-1 loss: 0.189231  [   64/  146]
train() client id: f_00005-1-2 loss: 0.674043  [   96/  146]
train() client id: f_00005-1-3 loss: 0.582198  [  128/  146]
train() client id: f_00005-2-0 loss: 0.621043  [   32/  146]
train() client id: f_00005-2-1 loss: 0.466014  [   64/  146]
train() client id: f_00005-2-2 loss: 0.597266  [   96/  146]
train() client id: f_00005-2-3 loss: 0.412329  [  128/  146]
train() client id: f_00005-3-0 loss: 0.704667  [   32/  146]
train() client id: f_00005-3-1 loss: 0.481790  [   64/  146]
train() client id: f_00005-3-2 loss: 0.481147  [   96/  146]
train() client id: f_00005-3-3 loss: 0.536891  [  128/  146]
train() client id: f_00005-4-0 loss: 0.549224  [   32/  146]
train() client id: f_00005-4-1 loss: 0.367873  [   64/  146]
train() client id: f_00005-4-2 loss: 0.750461  [   96/  146]
train() client id: f_00005-4-3 loss: 0.504541  [  128/  146]
train() client id: f_00005-5-0 loss: 0.403174  [   32/  146]
train() client id: f_00005-5-1 loss: 0.496636  [   64/  146]
train() client id: f_00005-5-2 loss: 0.545183  [   96/  146]
train() client id: f_00005-5-3 loss: 0.495649  [  128/  146]
train() client id: f_00005-6-0 loss: 0.589262  [   32/  146]
train() client id: f_00005-6-1 loss: 0.459087  [   64/  146]
train() client id: f_00005-6-2 loss: 0.732149  [   96/  146]
train() client id: f_00005-6-3 loss: 0.256355  [  128/  146]
train() client id: f_00005-7-0 loss: 0.560364  [   32/  146]
train() client id: f_00005-7-1 loss: 0.269336  [   64/  146]
train() client id: f_00005-7-2 loss: 0.653364  [   96/  146]
train() client id: f_00005-7-3 loss: 0.499687  [  128/  146]
train() client id: f_00005-8-0 loss: 0.630201  [   32/  146]
train() client id: f_00005-8-1 loss: 0.470955  [   64/  146]
train() client id: f_00005-8-2 loss: 0.516171  [   96/  146]
train() client id: f_00005-8-3 loss: 0.538837  [  128/  146]
train() client id: f_00005-9-0 loss: 0.269838  [   32/  146]
train() client id: f_00005-9-1 loss: 0.651386  [   64/  146]
train() client id: f_00005-9-2 loss: 0.523186  [   96/  146]
train() client id: f_00005-9-3 loss: 0.561233  [  128/  146]
train() client id: f_00005-10-0 loss: 0.411383  [   32/  146]
train() client id: f_00005-10-1 loss: 0.801290  [   64/  146]
train() client id: f_00005-10-2 loss: 0.369880  [   96/  146]
train() client id: f_00005-10-3 loss: 0.469247  [  128/  146]
train() client id: f_00005-11-0 loss: 0.409916  [   32/  146]
train() client id: f_00005-11-1 loss: 0.587690  [   64/  146]
train() client id: f_00005-11-2 loss: 0.440684  [   96/  146]
train() client id: f_00005-11-3 loss: 0.461488  [  128/  146]
train() client id: f_00005-12-0 loss: 0.429731  [   32/  146]
train() client id: f_00005-12-1 loss: 0.435871  [   64/  146]
train() client id: f_00005-12-2 loss: 0.880512  [   96/  146]
train() client id: f_00005-12-3 loss: 0.412927  [  128/  146]
train() client id: f_00006-0-0 loss: 0.475618  [   32/   54]
train() client id: f_00006-1-0 loss: 0.458656  [   32/   54]
train() client id: f_00006-2-0 loss: 0.452458  [   32/   54]
train() client id: f_00006-3-0 loss: 0.393923  [   32/   54]
train() client id: f_00006-4-0 loss: 0.468687  [   32/   54]
train() client id: f_00006-5-0 loss: 0.382797  [   32/   54]
train() client id: f_00006-6-0 loss: 0.412381  [   32/   54]
train() client id: f_00006-7-0 loss: 0.485234  [   32/   54]
train() client id: f_00006-8-0 loss: 0.445632  [   32/   54]
train() client id: f_00006-9-0 loss: 0.441157  [   32/   54]
train() client id: f_00006-10-0 loss: 0.442034  [   32/   54]
train() client id: f_00006-11-0 loss: 0.424599  [   32/   54]
train() client id: f_00006-12-0 loss: 0.440982  [   32/   54]
train() client id: f_00007-0-0 loss: 0.338951  [   32/  179]
train() client id: f_00007-0-1 loss: 0.504214  [   64/  179]
train() client id: f_00007-0-2 loss: 0.650199  [   96/  179]
train() client id: f_00007-0-3 loss: 0.556106  [  128/  179]
train() client id: f_00007-0-4 loss: 0.707512  [  160/  179]
train() client id: f_00007-1-0 loss: 0.551417  [   32/  179]
train() client id: f_00007-1-1 loss: 0.514679  [   64/  179]
train() client id: f_00007-1-2 loss: 0.390958  [   96/  179]
train() client id: f_00007-1-3 loss: 0.508312  [  128/  179]
train() client id: f_00007-1-4 loss: 0.426024  [  160/  179]
train() client id: f_00007-2-0 loss: 0.543972  [   32/  179]
train() client id: f_00007-2-1 loss: 0.429259  [   64/  179]
train() client id: f_00007-2-2 loss: 0.535767  [   96/  179]
train() client id: f_00007-2-3 loss: 0.607564  [  128/  179]
train() client id: f_00007-2-4 loss: 0.435826  [  160/  179]
train() client id: f_00007-3-0 loss: 0.535994  [   32/  179]
train() client id: f_00007-3-1 loss: 0.398889  [   64/  179]
train() client id: f_00007-3-2 loss: 0.580990  [   96/  179]
train() client id: f_00007-3-3 loss: 0.538841  [  128/  179]
train() client id: f_00007-3-4 loss: 0.350287  [  160/  179]
train() client id: f_00007-4-0 loss: 0.446078  [   32/  179]
train() client id: f_00007-4-1 loss: 0.501823  [   64/  179]
train() client id: f_00007-4-2 loss: 0.629240  [   96/  179]
train() client id: f_00007-4-3 loss: 0.539933  [  128/  179]
train() client id: f_00007-4-4 loss: 0.429263  [  160/  179]
train() client id: f_00007-5-0 loss: 0.429094  [   32/  179]
train() client id: f_00007-5-1 loss: 0.475729  [   64/  179]
train() client id: f_00007-5-2 loss: 0.621345  [   96/  179]
train() client id: f_00007-5-3 loss: 0.327847  [  128/  179]
train() client id: f_00007-5-4 loss: 0.447257  [  160/  179]
train() client id: f_00007-6-0 loss: 0.321436  [   32/  179]
train() client id: f_00007-6-1 loss: 0.543459  [   64/  179]
train() client id: f_00007-6-2 loss: 0.465491  [   96/  179]
train() client id: f_00007-6-3 loss: 0.575092  [  128/  179]
train() client id: f_00007-6-4 loss: 0.571432  [  160/  179]
train() client id: f_00007-7-0 loss: 0.819763  [   32/  179]
train() client id: f_00007-7-1 loss: 0.394795  [   64/  179]
train() client id: f_00007-7-2 loss: 0.414113  [   96/  179]
train() client id: f_00007-7-3 loss: 0.318097  [  128/  179]
train() client id: f_00007-7-4 loss: 0.437424  [  160/  179]
train() client id: f_00007-8-0 loss: 0.580482  [   32/  179]
train() client id: f_00007-8-1 loss: 0.301537  [   64/  179]
train() client id: f_00007-8-2 loss: 0.733891  [   96/  179]
train() client id: f_00007-8-3 loss: 0.378881  [  128/  179]
train() client id: f_00007-8-4 loss: 0.401339  [  160/  179]
train() client id: f_00007-9-0 loss: 0.654125  [   32/  179]
train() client id: f_00007-9-1 loss: 0.570298  [   64/  179]
train() client id: f_00007-9-2 loss: 0.429027  [   96/  179]
train() client id: f_00007-9-3 loss: 0.416260  [  128/  179]
train() client id: f_00007-9-4 loss: 0.375639  [  160/  179]
train() client id: f_00007-10-0 loss: 0.317502  [   32/  179]
train() client id: f_00007-10-1 loss: 0.430641  [   64/  179]
train() client id: f_00007-10-2 loss: 0.610348  [   96/  179]
train() client id: f_00007-10-3 loss: 0.621496  [  128/  179]
train() client id: f_00007-10-4 loss: 0.431039  [  160/  179]
train() client id: f_00007-11-0 loss: 0.676459  [   32/  179]
train() client id: f_00007-11-1 loss: 0.292643  [   64/  179]
train() client id: f_00007-11-2 loss: 0.406723  [   96/  179]
train() client id: f_00007-11-3 loss: 0.515131  [  128/  179]
train() client id: f_00007-11-4 loss: 0.327534  [  160/  179]
train() client id: f_00007-12-0 loss: 0.457257  [   32/  179]
train() client id: f_00007-12-1 loss: 0.325255  [   64/  179]
train() client id: f_00007-12-2 loss: 0.484743  [   96/  179]
train() client id: f_00007-12-3 loss: 0.556157  [  128/  179]
train() client id: f_00007-12-4 loss: 0.578597  [  160/  179]
train() client id: f_00008-0-0 loss: 0.635326  [   32/  130]
train() client id: f_00008-0-1 loss: 0.620802  [   64/  130]
train() client id: f_00008-0-2 loss: 0.660283  [   96/  130]
train() client id: f_00008-0-3 loss: 0.673326  [  128/  130]
train() client id: f_00008-1-0 loss: 0.674137  [   32/  130]
train() client id: f_00008-1-1 loss: 0.528520  [   64/  130]
train() client id: f_00008-1-2 loss: 0.676360  [   96/  130]
train() client id: f_00008-1-3 loss: 0.709236  [  128/  130]
train() client id: f_00008-2-0 loss: 0.752289  [   32/  130]
train() client id: f_00008-2-1 loss: 0.640843  [   64/  130]
train() client id: f_00008-2-2 loss: 0.559892  [   96/  130]
train() client id: f_00008-2-3 loss: 0.639014  [  128/  130]
train() client id: f_00008-3-0 loss: 0.545705  [   32/  130]
train() client id: f_00008-3-1 loss: 0.701266  [   64/  130]
train() client id: f_00008-3-2 loss: 0.703024  [   96/  130]
train() client id: f_00008-3-3 loss: 0.637461  [  128/  130]
train() client id: f_00008-4-0 loss: 0.648881  [   32/  130]
train() client id: f_00008-4-1 loss: 0.628161  [   64/  130]
train() client id: f_00008-4-2 loss: 0.668533  [   96/  130]
train() client id: f_00008-4-3 loss: 0.615444  [  128/  130]
train() client id: f_00008-5-0 loss: 0.708517  [   32/  130]
train() client id: f_00008-5-1 loss: 0.607590  [   64/  130]
train() client id: f_00008-5-2 loss: 0.737403  [   96/  130]
train() client id: f_00008-5-3 loss: 0.535825  [  128/  130]
train() client id: f_00008-6-0 loss: 0.673452  [   32/  130]
train() client id: f_00008-6-1 loss: 0.654770  [   64/  130]
train() client id: f_00008-6-2 loss: 0.667276  [   96/  130]
train() client id: f_00008-6-3 loss: 0.566359  [  128/  130]
train() client id: f_00008-7-0 loss: 0.673075  [   32/  130]
train() client id: f_00008-7-1 loss: 0.645536  [   64/  130]
train() client id: f_00008-7-2 loss: 0.531447  [   96/  130]
train() client id: f_00008-7-3 loss: 0.706774  [  128/  130]
train() client id: f_00008-8-0 loss: 0.616905  [   32/  130]
train() client id: f_00008-8-1 loss: 0.754299  [   64/  130]
train() client id: f_00008-8-2 loss: 0.629532  [   96/  130]
train() client id: f_00008-8-3 loss: 0.600190  [  128/  130]
train() client id: f_00008-9-0 loss: 0.644330  [   32/  130]
train() client id: f_00008-9-1 loss: 0.753681  [   64/  130]
train() client id: f_00008-9-2 loss: 0.514471  [   96/  130]
train() client id: f_00008-9-3 loss: 0.675521  [  128/  130]
train() client id: f_00008-10-0 loss: 0.614668  [   32/  130]
train() client id: f_00008-10-1 loss: 0.677115  [   64/  130]
train() client id: f_00008-10-2 loss: 0.569103  [   96/  130]
train() client id: f_00008-10-3 loss: 0.691025  [  128/  130]
train() client id: f_00008-11-0 loss: 0.678347  [   32/  130]
train() client id: f_00008-11-1 loss: 0.681764  [   64/  130]
train() client id: f_00008-11-2 loss: 0.578682  [   96/  130]
train() client id: f_00008-11-3 loss: 0.647279  [  128/  130]
train() client id: f_00008-12-0 loss: 0.614244  [   32/  130]
train() client id: f_00008-12-1 loss: 0.542968  [   64/  130]
train() client id: f_00008-12-2 loss: 0.679013  [   96/  130]
train() client id: f_00008-12-3 loss: 0.744447  [  128/  130]
train() client id: f_00009-0-0 loss: 1.153076  [   32/  118]
train() client id: f_00009-0-1 loss: 1.060946  [   64/  118]
train() client id: f_00009-0-2 loss: 1.101401  [   96/  118]
train() client id: f_00009-1-0 loss: 1.120792  [   32/  118]
train() client id: f_00009-1-1 loss: 1.095027  [   64/  118]
train() client id: f_00009-1-2 loss: 1.045229  [   96/  118]
train() client id: f_00009-2-0 loss: 1.127242  [   32/  118]
train() client id: f_00009-2-1 loss: 0.871838  [   64/  118]
train() client id: f_00009-2-2 loss: 1.020963  [   96/  118]
train() client id: f_00009-3-0 loss: 1.045761  [   32/  118]
train() client id: f_00009-3-1 loss: 0.904012  [   64/  118]
train() client id: f_00009-3-2 loss: 0.956363  [   96/  118]
train() client id: f_00009-4-0 loss: 0.997806  [   32/  118]
train() client id: f_00009-4-1 loss: 0.719796  [   64/  118]
train() client id: f_00009-4-2 loss: 0.990680  [   96/  118]
train() client id: f_00009-5-0 loss: 0.977377  [   32/  118]
train() client id: f_00009-5-1 loss: 0.886163  [   64/  118]
train() client id: f_00009-5-2 loss: 0.781795  [   96/  118]
train() client id: f_00009-6-0 loss: 0.899623  [   32/  118]
train() client id: f_00009-6-1 loss: 0.910873  [   64/  118]
train() client id: f_00009-6-2 loss: 0.840282  [   96/  118]
train() client id: f_00009-7-0 loss: 0.815140  [   32/  118]
train() client id: f_00009-7-1 loss: 0.906810  [   64/  118]
train() client id: f_00009-7-2 loss: 1.022966  [   96/  118]
train() client id: f_00009-8-0 loss: 0.883919  [   32/  118]
train() client id: f_00009-8-1 loss: 0.932734  [   64/  118]
train() client id: f_00009-8-2 loss: 0.852545  [   96/  118]
train() client id: f_00009-9-0 loss: 0.783127  [   32/  118]
train() client id: f_00009-9-1 loss: 0.871406  [   64/  118]
train() client id: f_00009-9-2 loss: 0.831646  [   96/  118]
train() client id: f_00009-10-0 loss: 0.703723  [   32/  118]
train() client id: f_00009-10-1 loss: 0.919408  [   64/  118]
train() client id: f_00009-10-2 loss: 0.826817  [   96/  118]
train() client id: f_00009-11-0 loss: 0.908295  [   32/  118]
train() client id: f_00009-11-1 loss: 0.785595  [   64/  118]
train() client id: f_00009-11-2 loss: 0.786462  [   96/  118]
train() client id: f_00009-12-0 loss: 0.781971  [   32/  118]
train() client id: f_00009-12-1 loss: 0.754710  [   64/  118]
train() client id: f_00009-12-2 loss: 0.860119  [   96/  118]
At round 60 accuracy: 0.6392572944297082
At round 60 training accuracy: 0.5895372233400402
At round 60 training loss: 0.8300604099314098
gradient difference: 0.5189903974533081
train() client id: f_00000-0-0 loss: 1.005772  [   32/  126]
train() client id: f_00000-0-1 loss: 0.898189  [   64/  126]
train() client id: f_00000-0-2 loss: 1.123350  [   96/  126]
train() client id: f_00000-1-0 loss: 1.052559  [   32/  126]
train() client id: f_00000-1-1 loss: 0.869897  [   64/  126]
train() client id: f_00000-1-2 loss: 1.148067  [   96/  126]
train() client id: f_00000-2-0 loss: 0.844418  [   32/  126]
train() client id: f_00000-2-1 loss: 1.003403  [   64/  126]
train() client id: f_00000-2-2 loss: 0.989541  [   96/  126]
train() client id: f_00000-3-0 loss: 0.920630  [   32/  126]
train() client id: f_00000-3-1 loss: 0.856874  [   64/  126]
train() client id: f_00000-3-2 loss: 0.924497  [   96/  126]
train() client id: f_00000-4-0 loss: 0.953297  [   32/  126]
train() client id: f_00000-4-1 loss: 0.813014  [   64/  126]
train() client id: f_00000-4-2 loss: 0.777060  [   96/  126]
train() client id: f_00000-5-0 loss: 1.013853  [   32/  126]
train() client id: f_00000-5-1 loss: 0.915747  [   64/  126]
train() client id: f_00000-5-2 loss: 0.800571  [   96/  126]
train() client id: f_00000-6-0 loss: 0.997253  [   32/  126]
train() client id: f_00000-6-1 loss: 0.901636  [   64/  126]
train() client id: f_00000-6-2 loss: 0.769449  [   96/  126]
train() client id: f_00000-7-0 loss: 0.761967  [   32/  126]
train() client id: f_00000-7-1 loss: 0.944841  [   64/  126]
train() client id: f_00000-7-2 loss: 0.859298  [   96/  126]
train() client id: f_00000-8-0 loss: 0.825839  [   32/  126]
train() client id: f_00000-8-1 loss: 0.734168  [   64/  126]
train() client id: f_00000-8-2 loss: 0.812811  [   96/  126]
train() client id: f_00000-9-0 loss: 0.914417  [   32/  126]
train() client id: f_00000-9-1 loss: 0.902249  [   64/  126]
train() client id: f_00000-9-2 loss: 0.771496  [   96/  126]
train() client id: f_00000-10-0 loss: 0.789078  [   32/  126]
train() client id: f_00000-10-1 loss: 0.851436  [   64/  126]
train() client id: f_00000-10-2 loss: 0.905988  [   96/  126]
train() client id: f_00000-11-0 loss: 0.778986  [   32/  126]
train() client id: f_00000-11-1 loss: 0.888492  [   64/  126]
train() client id: f_00000-11-2 loss: 0.902977  [   96/  126]
train() client id: f_00000-12-0 loss: 0.862994  [   32/  126]
train() client id: f_00000-12-1 loss: 0.790936  [   64/  126]
train() client id: f_00000-12-2 loss: 0.848555  [   96/  126]
train() client id: f_00001-0-0 loss: 0.496621  [   32/  265]
train() client id: f_00001-0-1 loss: 0.466376  [   64/  265]
train() client id: f_00001-0-2 loss: 0.464857  [   96/  265]
train() client id: f_00001-0-3 loss: 0.518421  [  128/  265]
train() client id: f_00001-0-4 loss: 0.603509  [  160/  265]
train() client id: f_00001-0-5 loss: 0.527453  [  192/  265]
train() client id: f_00001-0-6 loss: 0.407572  [  224/  265]
train() client id: f_00001-0-7 loss: 0.437620  [  256/  265]
train() client id: f_00001-1-0 loss: 0.477486  [   32/  265]
train() client id: f_00001-1-1 loss: 0.494233  [   64/  265]
train() client id: f_00001-1-2 loss: 0.556507  [   96/  265]
train() client id: f_00001-1-3 loss: 0.412721  [  128/  265]
train() client id: f_00001-1-4 loss: 0.418329  [  160/  265]
train() client id: f_00001-1-5 loss: 0.610120  [  192/  265]
train() client id: f_00001-1-6 loss: 0.463359  [  224/  265]
train() client id: f_00001-1-7 loss: 0.423149  [  256/  265]
train() client id: f_00001-2-0 loss: 0.467282  [   32/  265]
train() client id: f_00001-2-1 loss: 0.426309  [   64/  265]
train() client id: f_00001-2-2 loss: 0.474378  [   96/  265]
train() client id: f_00001-2-3 loss: 0.497860  [  128/  265]
train() client id: f_00001-2-4 loss: 0.398477  [  160/  265]
train() client id: f_00001-2-5 loss: 0.476197  [  192/  265]
train() client id: f_00001-2-6 loss: 0.405694  [  224/  265]
train() client id: f_00001-2-7 loss: 0.600484  [  256/  265]
train() client id: f_00001-3-0 loss: 0.490347  [   32/  265]
train() client id: f_00001-3-1 loss: 0.390852  [   64/  265]
train() client id: f_00001-3-2 loss: 0.690355  [   96/  265]
train() client id: f_00001-3-3 loss: 0.401019  [  128/  265]
train() client id: f_00001-3-4 loss: 0.460415  [  160/  265]
train() client id: f_00001-3-5 loss: 0.489469  [  192/  265]
train() client id: f_00001-3-6 loss: 0.402497  [  224/  265]
train() client id: f_00001-3-7 loss: 0.391831  [  256/  265]
train() client id: f_00001-4-0 loss: 0.395975  [   32/  265]
train() client id: f_00001-4-1 loss: 0.368722  [   64/  265]
train() client id: f_00001-4-2 loss: 0.452048  [   96/  265]
train() client id: f_00001-4-3 loss: 0.593799  [  128/  265]
train() client id: f_00001-4-4 loss: 0.408981  [  160/  265]
train() client id: f_00001-4-5 loss: 0.447601  [  192/  265]
train() client id: f_00001-4-6 loss: 0.456096  [  224/  265]
train() client id: f_00001-4-7 loss: 0.648081  [  256/  265]
train() client id: f_00001-5-0 loss: 0.364801  [   32/  265]
train() client id: f_00001-5-1 loss: 0.446896  [   64/  265]
train() client id: f_00001-5-2 loss: 0.590599  [   96/  265]
train() client id: f_00001-5-3 loss: 0.453586  [  128/  265]
train() client id: f_00001-5-4 loss: 0.474951  [  160/  265]
train() client id: f_00001-5-5 loss: 0.361767  [  192/  265]
train() client id: f_00001-5-6 loss: 0.471960  [  224/  265]
train() client id: f_00001-5-7 loss: 0.570512  [  256/  265]
train() client id: f_00001-6-0 loss: 0.429964  [   32/  265]
train() client id: f_00001-6-1 loss: 0.478557  [   64/  265]
train() client id: f_00001-6-2 loss: 0.556240  [   96/  265]
train() client id: f_00001-6-3 loss: 0.411987  [  128/  265]
train() client id: f_00001-6-4 loss: 0.457776  [  160/  265]
train() client id: f_00001-6-5 loss: 0.429494  [  192/  265]
train() client id: f_00001-6-6 loss: 0.508374  [  224/  265]
train() client id: f_00001-6-7 loss: 0.442593  [  256/  265]
train() client id: f_00001-7-0 loss: 0.536456  [   32/  265]
train() client id: f_00001-7-1 loss: 0.392246  [   64/  265]
train() client id: f_00001-7-2 loss: 0.477705  [   96/  265]
train() client id: f_00001-7-3 loss: 0.501119  [  128/  265]
train() client id: f_00001-7-4 loss: 0.526158  [  160/  265]
train() client id: f_00001-7-5 loss: 0.526981  [  192/  265]
train() client id: f_00001-7-6 loss: 0.369367  [  224/  265]
train() client id: f_00001-7-7 loss: 0.384857  [  256/  265]
train() client id: f_00001-8-0 loss: 0.505554  [   32/  265]
train() client id: f_00001-8-1 loss: 0.438431  [   64/  265]
train() client id: f_00001-8-2 loss: 0.385661  [   96/  265]
train() client id: f_00001-8-3 loss: 0.632175  [  128/  265]
train() client id: f_00001-8-4 loss: 0.438567  [  160/  265]
train() client id: f_00001-8-5 loss: 0.446270  [  192/  265]
train() client id: f_00001-8-6 loss: 0.424420  [  224/  265]
train() client id: f_00001-8-7 loss: 0.372093  [  256/  265]
train() client id: f_00001-9-0 loss: 0.562527  [   32/  265]
train() client id: f_00001-9-1 loss: 0.406812  [   64/  265]
train() client id: f_00001-9-2 loss: 0.361073  [   96/  265]
train() client id: f_00001-9-3 loss: 0.368476  [  128/  265]
train() client id: f_00001-9-4 loss: 0.432430  [  160/  265]
train() client id: f_00001-9-5 loss: 0.557033  [  192/  265]
train() client id: f_00001-9-6 loss: 0.562726  [  224/  265]
train() client id: f_00001-9-7 loss: 0.466278  [  256/  265]
train() client id: f_00001-10-0 loss: 0.460332  [   32/  265]
train() client id: f_00001-10-1 loss: 0.456091  [   64/  265]
train() client id: f_00001-10-2 loss: 0.516217  [   96/  265]
train() client id: f_00001-10-3 loss: 0.487815  [  128/  265]
train() client id: f_00001-10-4 loss: 0.508853  [  160/  265]
train() client id: f_00001-10-5 loss: 0.355104  [  192/  265]
train() client id: f_00001-10-6 loss: 0.479167  [  224/  265]
train() client id: f_00001-10-7 loss: 0.407862  [  256/  265]
train() client id: f_00001-11-0 loss: 0.360799  [   32/  265]
train() client id: f_00001-11-1 loss: 0.443987  [   64/  265]
train() client id: f_00001-11-2 loss: 0.357380  [   96/  265]
train() client id: f_00001-11-3 loss: 0.566749  [  128/  265]
train() client id: f_00001-11-4 loss: 0.631956  [  160/  265]
train() client id: f_00001-11-5 loss: 0.456699  [  192/  265]
train() client id: f_00001-11-6 loss: 0.420431  [  224/  265]
train() client id: f_00001-11-7 loss: 0.406156  [  256/  265]
train() client id: f_00001-12-0 loss: 0.445536  [   32/  265]
train() client id: f_00001-12-1 loss: 0.488797  [   64/  265]
train() client id: f_00001-12-2 loss: 0.393659  [   96/  265]
train() client id: f_00001-12-3 loss: 0.354513  [  128/  265]
train() client id: f_00001-12-4 loss: 0.398279  [  160/  265]
train() client id: f_00001-12-5 loss: 0.630240  [  192/  265]
train() client id: f_00001-12-6 loss: 0.566023  [  224/  265]
train() client id: f_00001-12-7 loss: 0.364092  [  256/  265]
train() client id: f_00002-0-0 loss: 1.096384  [   32/  124]
train() client id: f_00002-0-1 loss: 1.337671  [   64/  124]
train() client id: f_00002-0-2 loss: 1.249592  [   96/  124]
train() client id: f_00002-1-0 loss: 1.234691  [   32/  124]
train() client id: f_00002-1-1 loss: 1.218594  [   64/  124]
train() client id: f_00002-1-2 loss: 1.165446  [   96/  124]
train() client id: f_00002-2-0 loss: 1.261704  [   32/  124]
train() client id: f_00002-2-1 loss: 1.204300  [   64/  124]
train() client id: f_00002-2-2 loss: 1.130018  [   96/  124]
train() client id: f_00002-3-0 loss: 1.156383  [   32/  124]
train() client id: f_00002-3-1 loss: 1.110977  [   64/  124]
train() client id: f_00002-3-2 loss: 1.149812  [   96/  124]
train() client id: f_00002-4-0 loss: 0.992986  [   32/  124]
train() client id: f_00002-4-1 loss: 1.430043  [   64/  124]
train() client id: f_00002-4-2 loss: 1.019531  [   96/  124]
train() client id: f_00002-5-0 loss: 1.102513  [   32/  124]
train() client id: f_00002-5-1 loss: 1.070605  [   64/  124]
train() client id: f_00002-5-2 loss: 1.082543  [   96/  124]
train() client id: f_00002-6-0 loss: 1.295171  [   32/  124]
train() client id: f_00002-6-1 loss: 0.932598  [   64/  124]
train() client id: f_00002-6-2 loss: 1.018097  [   96/  124]
train() client id: f_00002-7-0 loss: 1.184393  [   32/  124]
train() client id: f_00002-7-1 loss: 1.140612  [   64/  124]
train() client id: f_00002-7-2 loss: 0.948415  [   96/  124]
train() client id: f_00002-8-0 loss: 0.899288  [   32/  124]
train() client id: f_00002-8-1 loss: 1.270879  [   64/  124]
train() client id: f_00002-8-2 loss: 0.995481  [   96/  124]
train() client id: f_00002-9-0 loss: 1.117653  [   32/  124]
train() client id: f_00002-9-1 loss: 1.081706  [   64/  124]
train() client id: f_00002-9-2 loss: 1.113018  [   96/  124]
train() client id: f_00002-10-0 loss: 1.097079  [   32/  124]
train() client id: f_00002-10-1 loss: 1.013095  [   64/  124]
train() client id: f_00002-10-2 loss: 0.961178  [   96/  124]
train() client id: f_00002-11-0 loss: 1.120912  [   32/  124]
train() client id: f_00002-11-1 loss: 0.957557  [   64/  124]
train() client id: f_00002-11-2 loss: 0.988256  [   96/  124]
train() client id: f_00002-12-0 loss: 1.130192  [   32/  124]
train() client id: f_00002-12-1 loss: 0.999121  [   64/  124]
train() client id: f_00002-12-2 loss: 1.014306  [   96/  124]
train() client id: f_00003-0-0 loss: 0.558174  [   32/   43]
train() client id: f_00003-1-0 loss: 0.616097  [   32/   43]
train() client id: f_00003-2-0 loss: 0.874627  [   32/   43]
train() client id: f_00003-3-0 loss: 0.766337  [   32/   43]
train() client id: f_00003-4-0 loss: 0.718589  [   32/   43]
train() client id: f_00003-5-0 loss: 0.731547  [   32/   43]
train() client id: f_00003-6-0 loss: 0.555827  [   32/   43]
train() client id: f_00003-7-0 loss: 0.775160  [   32/   43]
train() client id: f_00003-8-0 loss: 0.730804  [   32/   43]
train() client id: f_00003-9-0 loss: 0.750548  [   32/   43]
train() client id: f_00003-10-0 loss: 0.629430  [   32/   43]
train() client id: f_00003-11-0 loss: 0.724837  [   32/   43]
train() client id: f_00003-12-0 loss: 0.664015  [   32/   43]
train() client id: f_00004-0-0 loss: 0.850364  [   32/  306]
train() client id: f_00004-0-1 loss: 1.021117  [   64/  306]
train() client id: f_00004-0-2 loss: 0.785259  [   96/  306]
train() client id: f_00004-0-3 loss: 0.890449  [  128/  306]
train() client id: f_00004-0-4 loss: 1.045863  [  160/  306]
train() client id: f_00004-0-5 loss: 0.724302  [  192/  306]
train() client id: f_00004-0-6 loss: 0.932261  [  224/  306]
train() client id: f_00004-0-7 loss: 0.861755  [  256/  306]
train() client id: f_00004-0-8 loss: 1.008484  [  288/  306]
train() client id: f_00004-1-0 loss: 0.798024  [   32/  306]
train() client id: f_00004-1-1 loss: 1.015192  [   64/  306]
train() client id: f_00004-1-2 loss: 0.792783  [   96/  306]
train() client id: f_00004-1-3 loss: 0.747049  [  128/  306]
train() client id: f_00004-1-4 loss: 0.950235  [  160/  306]
train() client id: f_00004-1-5 loss: 0.846435  [  192/  306]
train() client id: f_00004-1-6 loss: 0.855056  [  224/  306]
train() client id: f_00004-1-7 loss: 0.913482  [  256/  306]
train() client id: f_00004-1-8 loss: 1.066479  [  288/  306]
train() client id: f_00004-2-0 loss: 0.844109  [   32/  306]
train() client id: f_00004-2-1 loss: 0.728579  [   64/  306]
train() client id: f_00004-2-2 loss: 0.817998  [   96/  306]
train() client id: f_00004-2-3 loss: 0.905130  [  128/  306]
train() client id: f_00004-2-4 loss: 0.857041  [  160/  306]
train() client id: f_00004-2-5 loss: 1.032317  [  192/  306]
train() client id: f_00004-2-6 loss: 1.022368  [  224/  306]
train() client id: f_00004-2-7 loss: 0.908788  [  256/  306]
train() client id: f_00004-2-8 loss: 0.814700  [  288/  306]
train() client id: f_00004-3-0 loss: 0.872409  [   32/  306]
train() client id: f_00004-3-1 loss: 0.817165  [   64/  306]
train() client id: f_00004-3-2 loss: 0.884923  [   96/  306]
train() client id: f_00004-3-3 loss: 0.921001  [  128/  306]
train() client id: f_00004-3-4 loss: 0.777010  [  160/  306]
train() client id: f_00004-3-5 loss: 0.914884  [  192/  306]
train() client id: f_00004-3-6 loss: 0.837210  [  224/  306]
train() client id: f_00004-3-7 loss: 0.935561  [  256/  306]
train() client id: f_00004-3-8 loss: 0.885991  [  288/  306]
train() client id: f_00004-4-0 loss: 0.900833  [   32/  306]
train() client id: f_00004-4-1 loss: 0.871818  [   64/  306]
train() client id: f_00004-4-2 loss: 0.805691  [   96/  306]
train() client id: f_00004-4-3 loss: 0.912158  [  128/  306]
train() client id: f_00004-4-4 loss: 0.915303  [  160/  306]
train() client id: f_00004-4-5 loss: 0.927002  [  192/  306]
train() client id: f_00004-4-6 loss: 0.764977  [  224/  306]
train() client id: f_00004-4-7 loss: 0.805004  [  256/  306]
train() client id: f_00004-4-8 loss: 0.862789  [  288/  306]
train() client id: f_00004-5-0 loss: 0.981086  [   32/  306]
train() client id: f_00004-5-1 loss: 0.768401  [   64/  306]
train() client id: f_00004-5-2 loss: 0.833290  [   96/  306]
train() client id: f_00004-5-3 loss: 0.899491  [  128/  306]
train() client id: f_00004-5-4 loss: 0.989777  [  160/  306]
train() client id: f_00004-5-5 loss: 0.827980  [  192/  306]
train() client id: f_00004-5-6 loss: 0.804856  [  224/  306]
train() client id: f_00004-5-7 loss: 0.891908  [  256/  306]
train() client id: f_00004-5-8 loss: 0.869381  [  288/  306]
train() client id: f_00004-6-0 loss: 0.847504  [   32/  306]
train() client id: f_00004-6-1 loss: 1.065486  [   64/  306]
train() client id: f_00004-6-2 loss: 0.755190  [   96/  306]
train() client id: f_00004-6-3 loss: 0.931201  [  128/  306]
train() client id: f_00004-6-4 loss: 0.770125  [  160/  306]
train() client id: f_00004-6-5 loss: 0.806721  [  192/  306]
train() client id: f_00004-6-6 loss: 0.910752  [  224/  306]
train() client id: f_00004-6-7 loss: 0.792224  [  256/  306]
train() client id: f_00004-6-8 loss: 0.921504  [  288/  306]
train() client id: f_00004-7-0 loss: 0.868122  [   32/  306]
train() client id: f_00004-7-1 loss: 0.890469  [   64/  306]
train() client id: f_00004-7-2 loss: 0.802260  [   96/  306]
train() client id: f_00004-7-3 loss: 0.890727  [  128/  306]
train() client id: f_00004-7-4 loss: 0.882999  [  160/  306]
train() client id: f_00004-7-5 loss: 0.805525  [  192/  306]
train() client id: f_00004-7-6 loss: 0.791240  [  224/  306]
train() client id: f_00004-7-7 loss: 1.011306  [  256/  306]
train() client id: f_00004-7-8 loss: 0.882645  [  288/  306]
train() client id: f_00004-8-0 loss: 0.815724  [   32/  306]
train() client id: f_00004-8-1 loss: 0.864648  [   64/  306]
train() client id: f_00004-8-2 loss: 0.655650  [   96/  306]
train() client id: f_00004-8-3 loss: 1.052373  [  128/  306]
train() client id: f_00004-8-4 loss: 0.870856  [  160/  306]
train() client id: f_00004-8-5 loss: 0.913545  [  192/  306]
train() client id: f_00004-8-6 loss: 0.897906  [  224/  306]
train() client id: f_00004-8-7 loss: 0.770177  [  256/  306]
train() client id: f_00004-8-8 loss: 0.916418  [  288/  306]
train() client id: f_00004-9-0 loss: 0.831839  [   32/  306]
train() client id: f_00004-9-1 loss: 0.893111  [   64/  306]
train() client id: f_00004-9-2 loss: 0.937324  [   96/  306]
train() client id: f_00004-9-3 loss: 0.766336  [  128/  306]
train() client id: f_00004-9-4 loss: 0.796359  [  160/  306]
train() client id: f_00004-9-5 loss: 0.835976  [  192/  306]
train() client id: f_00004-9-6 loss: 0.883964  [  224/  306]
train() client id: f_00004-9-7 loss: 0.756120  [  256/  306]
train() client id: f_00004-9-8 loss: 0.942762  [  288/  306]
train() client id: f_00004-10-0 loss: 0.916561  [   32/  306]
train() client id: f_00004-10-1 loss: 0.854269  [   64/  306]
train() client id: f_00004-10-2 loss: 0.926870  [   96/  306]
train() client id: f_00004-10-3 loss: 0.929218  [  128/  306]
train() client id: f_00004-10-4 loss: 0.901214  [  160/  306]
train() client id: f_00004-10-5 loss: 0.721455  [  192/  306]
train() client id: f_00004-10-6 loss: 0.757317  [  224/  306]
train() client id: f_00004-10-7 loss: 0.818261  [  256/  306]
train() client id: f_00004-10-8 loss: 0.870259  [  288/  306]
train() client id: f_00004-11-0 loss: 0.876685  [   32/  306]
train() client id: f_00004-11-1 loss: 0.749399  [   64/  306]
train() client id: f_00004-11-2 loss: 1.031740  [   96/  306]
train() client id: f_00004-11-3 loss: 0.767704  [  128/  306]
train() client id: f_00004-11-4 loss: 0.797702  [  160/  306]
train() client id: f_00004-11-5 loss: 0.835908  [  192/  306]
train() client id: f_00004-11-6 loss: 0.836275  [  224/  306]
train() client id: f_00004-11-7 loss: 0.898022  [  256/  306]
train() client id: f_00004-11-8 loss: 0.831644  [  288/  306]
train() client id: f_00004-12-0 loss: 0.890958  [   32/  306]
train() client id: f_00004-12-1 loss: 0.781133  [   64/  306]
train() client id: f_00004-12-2 loss: 0.864869  [   96/  306]
train() client id: f_00004-12-3 loss: 0.923869  [  128/  306]
train() client id: f_00004-12-4 loss: 0.790120  [  160/  306]
train() client id: f_00004-12-5 loss: 0.838116  [  192/  306]
train() client id: f_00004-12-6 loss: 0.732562  [  224/  306]
train() client id: f_00004-12-7 loss: 0.957010  [  256/  306]
train() client id: f_00004-12-8 loss: 0.944387  [  288/  306]
train() client id: f_00005-0-0 loss: 1.001539  [   32/  146]
train() client id: f_00005-0-1 loss: 0.698668  [   64/  146]
train() client id: f_00005-0-2 loss: 0.589571  [   96/  146]
train() client id: f_00005-0-3 loss: 0.566114  [  128/  146]
train() client id: f_00005-1-0 loss: 0.696036  [   32/  146]
train() client id: f_00005-1-1 loss: 0.755037  [   64/  146]
train() client id: f_00005-1-2 loss: 0.601401  [   96/  146]
train() client id: f_00005-1-3 loss: 0.928794  [  128/  146]
train() client id: f_00005-2-0 loss: 0.476806  [   32/  146]
train() client id: f_00005-2-1 loss: 0.642118  [   64/  146]
train() client id: f_00005-2-2 loss: 1.183685  [   96/  146]
train() client id: f_00005-2-3 loss: 0.516651  [  128/  146]
train() client id: f_00005-3-0 loss: 0.737185  [   32/  146]
train() client id: f_00005-3-1 loss: 0.610300  [   64/  146]
train() client id: f_00005-3-2 loss: 0.616428  [   96/  146]
train() client id: f_00005-3-3 loss: 0.761458  [  128/  146]
train() client id: f_00005-4-0 loss: 0.885076  [   32/  146]
train() client id: f_00005-4-1 loss: 0.699656  [   64/  146]
train() client id: f_00005-4-2 loss: 0.704733  [   96/  146]
train() client id: f_00005-4-3 loss: 0.426759  [  128/  146]
train() client id: f_00005-5-0 loss: 0.889291  [   32/  146]
train() client id: f_00005-5-1 loss: 0.699045  [   64/  146]
train() client id: f_00005-5-2 loss: 0.424437  [   96/  146]
train() client id: f_00005-5-3 loss: 0.932855  [  128/  146]
train() client id: f_00005-6-0 loss: 0.756317  [   32/  146]
train() client id: f_00005-6-1 loss: 0.866518  [   64/  146]
train() client id: f_00005-6-2 loss: 0.729240  [   96/  146]
train() client id: f_00005-6-3 loss: 0.542177  [  128/  146]
train() client id: f_00005-7-0 loss: 0.822542  [   32/  146]
train() client id: f_00005-7-1 loss: 0.444385  [   64/  146]
train() client id: f_00005-7-2 loss: 1.004417  [   96/  146]
train() client id: f_00005-7-3 loss: 0.483129  [  128/  146]
train() client id: f_00005-8-0 loss: 0.908317  [   32/  146]
train() client id: f_00005-8-1 loss: 0.493499  [   64/  146]
train() client id: f_00005-8-2 loss: 0.818238  [   96/  146]
train() client id: f_00005-8-3 loss: 0.620801  [  128/  146]
train() client id: f_00005-9-0 loss: 0.578751  [   32/  146]
train() client id: f_00005-9-1 loss: 0.941897  [   64/  146]
train() client id: f_00005-9-2 loss: 0.895264  [   96/  146]
train() client id: f_00005-9-3 loss: 0.444215  [  128/  146]
train() client id: f_00005-10-0 loss: 0.742637  [   32/  146]
train() client id: f_00005-10-1 loss: 0.607698  [   64/  146]
train() client id: f_00005-10-2 loss: 0.960292  [   96/  146]
train() client id: f_00005-10-3 loss: 0.657751  [  128/  146]
train() client id: f_00005-11-0 loss: 0.372092  [   32/  146]
train() client id: f_00005-11-1 loss: 0.837499  [   64/  146]
train() client id: f_00005-11-2 loss: 0.840152  [   96/  146]
train() client id: f_00005-11-3 loss: 0.795827  [  128/  146]
train() client id: f_00005-12-0 loss: 0.699929  [   32/  146]
train() client id: f_00005-12-1 loss: 0.610957  [   64/  146]
train() client id: f_00005-12-2 loss: 0.611413  [   96/  146]
train() client id: f_00005-12-3 loss: 0.838440  [  128/  146]
train() client id: f_00006-0-0 loss: 0.527947  [   32/   54]
train() client id: f_00006-1-0 loss: 0.495037  [   32/   54]
train() client id: f_00006-2-0 loss: 0.522693  [   32/   54]
train() client id: f_00006-3-0 loss: 0.458722  [   32/   54]
train() client id: f_00006-4-0 loss: 0.528648  [   32/   54]
train() client id: f_00006-5-0 loss: 0.511862  [   32/   54]
train() client id: f_00006-6-0 loss: 0.583683  [   32/   54]
train() client id: f_00006-7-0 loss: 0.545745  [   32/   54]
train() client id: f_00006-8-0 loss: 0.453533  [   32/   54]
train() client id: f_00006-9-0 loss: 0.576471  [   32/   54]
train() client id: f_00006-10-0 loss: 0.497455  [   32/   54]
train() client id: f_00006-11-0 loss: 0.508117  [   32/   54]
train() client id: f_00006-12-0 loss: 0.539294  [   32/   54]
train() client id: f_00007-0-0 loss: 0.546308  [   32/  179]
train() client id: f_00007-0-1 loss: 0.451175  [   64/  179]
train() client id: f_00007-0-2 loss: 0.497272  [   96/  179]
train() client id: f_00007-0-3 loss: 0.417485  [  128/  179]
train() client id: f_00007-0-4 loss: 0.373505  [  160/  179]
train() client id: f_00007-1-0 loss: 0.272782  [   32/  179]
train() client id: f_00007-1-1 loss: 0.334385  [   64/  179]
train() client id: f_00007-1-2 loss: 0.501315  [   96/  179]
train() client id: f_00007-1-3 loss: 0.377993  [  128/  179]
train() client id: f_00007-1-4 loss: 0.517326  [  160/  179]
train() client id: f_00007-2-0 loss: 0.300872  [   32/  179]
train() client id: f_00007-2-1 loss: 0.384835  [   64/  179]
train() client id: f_00007-2-2 loss: 0.544944  [   96/  179]
train() client id: f_00007-2-3 loss: 0.323084  [  128/  179]
train() client id: f_00007-2-4 loss: 0.295669  [  160/  179]
train() client id: f_00007-3-0 loss: 0.449603  [   32/  179]
train() client id: f_00007-3-1 loss: 0.366735  [   64/  179]
train() client id: f_00007-3-2 loss: 0.423957  [   96/  179]
train() client id: f_00007-3-3 loss: 0.248661  [  128/  179]
train() client id: f_00007-3-4 loss: 0.524103  [  160/  179]
train() client id: f_00007-4-0 loss: 0.355640  [   32/  179]
train() client id: f_00007-4-1 loss: 0.233257  [   64/  179]
train() client id: f_00007-4-2 loss: 0.446584  [   96/  179]
train() client id: f_00007-4-3 loss: 0.355015  [  128/  179]
train() client id: f_00007-4-4 loss: 0.545044  [  160/  179]
train() client id: f_00007-5-0 loss: 0.238922  [   32/  179]
train() client id: f_00007-5-1 loss: 0.249245  [   64/  179]
train() client id: f_00007-5-2 loss: 0.585820  [   96/  179]
train() client id: f_00007-5-3 loss: 0.478347  [  128/  179]
train() client id: f_00007-5-4 loss: 0.386048  [  160/  179]
train() client id: f_00007-6-0 loss: 0.306812  [   32/  179]
train() client id: f_00007-6-1 loss: 0.416000  [   64/  179]
train() client id: f_00007-6-2 loss: 0.449713  [   96/  179]
train() client id: f_00007-6-3 loss: 0.419763  [  128/  179]
train() client id: f_00007-6-4 loss: 0.341188  [  160/  179]
train() client id: f_00007-7-0 loss: 0.398005  [   32/  179]
train() client id: f_00007-7-1 loss: 0.374791  [   64/  179]
train() client id: f_00007-7-2 loss: 0.174362  [   96/  179]
train() client id: f_00007-7-3 loss: 0.393788  [  128/  179]
train() client id: f_00007-7-4 loss: 0.491209  [  160/  179]
train() client id: f_00007-8-0 loss: 0.205759  [   32/  179]
train() client id: f_00007-8-1 loss: 0.576236  [   64/  179]
train() client id: f_00007-8-2 loss: 0.298282  [   96/  179]
train() client id: f_00007-8-3 loss: 0.248753  [  128/  179]
train() client id: f_00007-8-4 loss: 0.374004  [  160/  179]
train() client id: f_00007-9-0 loss: 0.506076  [   32/  179]
train() client id: f_00007-9-1 loss: 0.293402  [   64/  179]
train() client id: f_00007-9-2 loss: 0.336922  [   96/  179]
train() client id: f_00007-9-3 loss: 0.332233  [  128/  179]
train() client id: f_00007-9-4 loss: 0.295462  [  160/  179]
train() client id: f_00007-10-0 loss: 0.543046  [   32/  179]
train() client id: f_00007-10-1 loss: 0.358963  [   64/  179]
train() client id: f_00007-10-2 loss: 0.462027  [   96/  179]
train() client id: f_00007-10-3 loss: 0.219692  [  128/  179]
train() client id: f_00007-10-4 loss: 0.280353  [  160/  179]
train() client id: f_00007-11-0 loss: 0.177006  [   32/  179]
train() client id: f_00007-11-1 loss: 0.422743  [   64/  179]
train() client id: f_00007-11-2 loss: 0.304266  [   96/  179]
train() client id: f_00007-11-3 loss: 0.388245  [  128/  179]
train() client id: f_00007-11-4 loss: 0.388092  [  160/  179]
train() client id: f_00007-12-0 loss: 0.286931  [   32/  179]
train() client id: f_00007-12-1 loss: 0.305570  [   64/  179]
train() client id: f_00007-12-2 loss: 0.562026  [   96/  179]
train() client id: f_00007-12-3 loss: 0.163724  [  128/  179]
train() client id: f_00007-12-4 loss: 0.410204  [  160/  179]
train() client id: f_00008-0-0 loss: 0.750870  [   32/  130]
train() client id: f_00008-0-1 loss: 0.617302  [   64/  130]
train() client id: f_00008-0-2 loss: 0.569630  [   96/  130]
train() client id: f_00008-0-3 loss: 0.661760  [  128/  130]
train() client id: f_00008-1-0 loss: 0.759069  [   32/  130]
train() client id: f_00008-1-1 loss: 0.606032  [   64/  130]
train() client id: f_00008-1-2 loss: 0.616032  [   96/  130]
train() client id: f_00008-1-3 loss: 0.577762  [  128/  130]
train() client id: f_00008-2-0 loss: 0.702824  [   32/  130]
train() client id: f_00008-2-1 loss: 0.561351  [   64/  130]
train() client id: f_00008-2-2 loss: 0.645698  [   96/  130]
train() client id: f_00008-2-3 loss: 0.671745  [  128/  130]
train() client id: f_00008-3-0 loss: 0.756294  [   32/  130]
train() client id: f_00008-3-1 loss: 0.535015  [   64/  130]
train() client id: f_00008-3-2 loss: 0.606601  [   96/  130]
train() client id: f_00008-3-3 loss: 0.663770  [  128/  130]
train() client id: f_00008-4-0 loss: 0.620197  [   32/  130]
train() client id: f_00008-4-1 loss: 0.592602  [   64/  130]
train() client id: f_00008-4-2 loss: 0.672439  [   96/  130]
train() client id: f_00008-4-3 loss: 0.672984  [  128/  130]
train() client id: f_00008-5-0 loss: 0.569730  [   32/  130]
train() client id: f_00008-5-1 loss: 0.653897  [   64/  130]
train() client id: f_00008-5-2 loss: 0.666044  [   96/  130]
train() client id: f_00008-5-3 loss: 0.661016  [  128/  130]
train() client id: f_00008-6-0 loss: 0.640897  [   32/  130]
train() client id: f_00008-6-1 loss: 0.650111  [   64/  130]
train() client id: f_00008-6-2 loss: 0.611064  [   96/  130]
train() client id: f_00008-6-3 loss: 0.624345  [  128/  130]
train() client id: f_00008-7-0 loss: 0.667162  [   32/  130]
train() client id: f_00008-7-1 loss: 0.708786  [   64/  130]
train() client id: f_00008-7-2 loss: 0.543980  [   96/  130]
train() client id: f_00008-7-3 loss: 0.662132  [  128/  130]
train() client id: f_00008-8-0 loss: 0.633948  [   32/  130]
train() client id: f_00008-8-1 loss: 0.667583  [   64/  130]
train() client id: f_00008-8-2 loss: 0.633235  [   96/  130]
train() client id: f_00008-8-3 loss: 0.644344  [  128/  130]
train() client id: f_00008-9-0 loss: 0.693680  [   32/  130]
train() client id: f_00008-9-1 loss: 0.646515  [   64/  130]
train() client id: f_00008-9-2 loss: 0.604202  [   96/  130]
train() client id: f_00008-9-3 loss: 0.640497  [  128/  130]
train() client id: f_00008-10-0 loss: 0.676729  [   32/  130]
train() client id: f_00008-10-1 loss: 0.639935  [   64/  130]
train() client id: f_00008-10-2 loss: 0.594332  [   96/  130]
train() client id: f_00008-10-3 loss: 0.677734  [  128/  130]
train() client id: f_00008-11-0 loss: 0.638356  [   32/  130]
train() client id: f_00008-11-1 loss: 0.743918  [   64/  130]
train() client id: f_00008-11-2 loss: 0.642993  [   96/  130]
train() client id: f_00008-11-3 loss: 0.564247  [  128/  130]
train() client id: f_00008-12-0 loss: 0.613249  [   32/  130]
train() client id: f_00008-12-1 loss: 0.773255  [   64/  130]
train() client id: f_00008-12-2 loss: 0.613302  [   96/  130]
train() client id: f_00008-12-3 loss: 0.566333  [  128/  130]
train() client id: f_00009-0-0 loss: 0.940528  [   32/  118]
train() client id: f_00009-0-1 loss: 0.789828  [   64/  118]
train() client id: f_00009-0-2 loss: 0.731817  [   96/  118]
train() client id: f_00009-1-0 loss: 0.794729  [   32/  118]
train() client id: f_00009-1-1 loss: 0.873022  [   64/  118]
train() client id: f_00009-1-2 loss: 0.675128  [   96/  118]
train() client id: f_00009-2-0 loss: 0.784779  [   32/  118]
train() client id: f_00009-2-1 loss: 0.805398  [   64/  118]
train() client id: f_00009-2-2 loss: 0.756189  [   96/  118]
train() client id: f_00009-3-0 loss: 0.694317  [   32/  118]
train() client id: f_00009-3-1 loss: 0.697101  [   64/  118]
train() client id: f_00009-3-2 loss: 0.817438  [   96/  118]
train() client id: f_00009-4-0 loss: 0.616799  [   32/  118]
train() client id: f_00009-4-1 loss: 0.920773  [   64/  118]
train() client id: f_00009-4-2 loss: 0.642694  [   96/  118]
train() client id: f_00009-5-0 loss: 0.764349  [   32/  118]
train() client id: f_00009-5-1 loss: 0.757473  [   64/  118]
train() client id: f_00009-5-2 loss: 0.675852  [   96/  118]
train() client id: f_00009-6-0 loss: 0.746540  [   32/  118]
train() client id: f_00009-6-1 loss: 0.530442  [   64/  118]
train() client id: f_00009-6-2 loss: 0.829584  [   96/  118]
train() client id: f_00009-7-0 loss: 0.624341  [   32/  118]
train() client id: f_00009-7-1 loss: 0.886584  [   64/  118]
train() client id: f_00009-7-2 loss: 0.770000  [   96/  118]
train() client id: f_00009-8-0 loss: 0.778265  [   32/  118]
train() client id: f_00009-8-1 loss: 0.646993  [   64/  118]
train() client id: f_00009-8-2 loss: 0.561904  [   96/  118]
train() client id: f_00009-9-0 loss: 0.623715  [   32/  118]
train() client id: f_00009-9-1 loss: 0.665426  [   64/  118]
train() client id: f_00009-9-2 loss: 0.965722  [   96/  118]
train() client id: f_00009-10-0 loss: 0.662655  [   32/  118]
train() client id: f_00009-10-1 loss: 0.863727  [   64/  118]
train() client id: f_00009-10-2 loss: 0.603142  [   96/  118]
train() client id: f_00009-11-0 loss: 0.610517  [   32/  118]
train() client id: f_00009-11-1 loss: 0.695876  [   64/  118]
train() client id: f_00009-11-2 loss: 0.748708  [   96/  118]
train() client id: f_00009-12-0 loss: 0.807298  [   32/  118]
train() client id: f_00009-12-1 loss: 0.761947  [   64/  118]
train() client id: f_00009-12-2 loss: 0.707467  [   96/  118]
At round 61 accuracy: 0.6392572944297082
At round 61 training accuracy: 0.5861837692823608
At round 61 training loss: 0.8365989971115583
gradient difference: 0.44952088594436646
train() client id: f_00000-0-0 loss: 1.180567  [   32/  126]
train() client id: f_00000-0-1 loss: 0.902841  [   64/  126]
train() client id: f_00000-0-2 loss: 1.041149  [   96/  126]
train() client id: f_00000-1-0 loss: 1.068496  [   32/  126]
train() client id: f_00000-1-1 loss: 0.851036  [   64/  126]
train() client id: f_00000-1-2 loss: 0.810079  [   96/  126]
train() client id: f_00000-2-0 loss: 0.750096  [   32/  126]
train() client id: f_00000-2-1 loss: 0.950976  [   64/  126]
train() client id: f_00000-2-2 loss: 1.125814  [   96/  126]
train() client id: f_00000-3-0 loss: 0.989130  [   32/  126]
train() client id: f_00000-3-1 loss: 0.886398  [   64/  126]
train() client id: f_00000-3-2 loss: 0.741660  [   96/  126]
train() client id: f_00000-4-0 loss: 0.824424  [   32/  126]
train() client id: f_00000-4-1 loss: 0.981929  [   64/  126]
train() client id: f_00000-4-2 loss: 0.764189  [   96/  126]
train() client id: f_00000-5-0 loss: 0.793284  [   32/  126]
train() client id: f_00000-5-1 loss: 0.815050  [   64/  126]
train() client id: f_00000-5-2 loss: 0.906133  [   96/  126]
train() client id: f_00000-6-0 loss: 0.885598  [   32/  126]
train() client id: f_00000-6-1 loss: 0.731444  [   64/  126]
train() client id: f_00000-6-2 loss: 0.907216  [   96/  126]
train() client id: f_00000-7-0 loss: 0.787996  [   32/  126]
train() client id: f_00000-7-1 loss: 0.763327  [   64/  126]
train() client id: f_00000-7-2 loss: 0.854799  [   96/  126]
train() client id: f_00000-8-0 loss: 0.858578  [   32/  126]
train() client id: f_00000-8-1 loss: 0.746894  [   64/  126]
train() client id: f_00000-8-2 loss: 0.840383  [   96/  126]
train() client id: f_00000-9-0 loss: 0.801155  [   32/  126]
train() client id: f_00000-9-1 loss: 0.767719  [   64/  126]
train() client id: f_00000-9-2 loss: 0.786778  [   96/  126]
train() client id: f_00000-10-0 loss: 0.801485  [   32/  126]
train() client id: f_00000-10-1 loss: 0.774059  [   64/  126]
train() client id: f_00000-10-2 loss: 0.791655  [   96/  126]
train() client id: f_00000-11-0 loss: 0.829056  [   32/  126]
train() client id: f_00000-11-1 loss: 0.753193  [   64/  126]
train() client id: f_00000-11-2 loss: 0.858183  [   96/  126]
train() client id: f_00000-12-0 loss: 0.806786  [   32/  126]
train() client id: f_00000-12-1 loss: 0.995044  [   64/  126]
train() client id: f_00000-12-2 loss: 0.718154  [   96/  126]
train() client id: f_00001-0-0 loss: 0.531312  [   32/  265]
train() client id: f_00001-0-1 loss: 0.520193  [   64/  265]
train() client id: f_00001-0-2 loss: 0.541058  [   96/  265]
train() client id: f_00001-0-3 loss: 0.491970  [  128/  265]
train() client id: f_00001-0-4 loss: 0.490034  [  160/  265]
train() client id: f_00001-0-5 loss: 0.521444  [  192/  265]
train() client id: f_00001-0-6 loss: 0.458430  [  224/  265]
train() client id: f_00001-0-7 loss: 0.468169  [  256/  265]
train() client id: f_00001-1-0 loss: 0.411258  [   32/  265]
train() client id: f_00001-1-1 loss: 0.510331  [   64/  265]
train() client id: f_00001-1-2 loss: 0.565312  [   96/  265]
train() client id: f_00001-1-3 loss: 0.580234  [  128/  265]
train() client id: f_00001-1-4 loss: 0.425105  [  160/  265]
train() client id: f_00001-1-5 loss: 0.480644  [  192/  265]
train() client id: f_00001-1-6 loss: 0.456973  [  224/  265]
train() client id: f_00001-1-7 loss: 0.486366  [  256/  265]
train() client id: f_00001-2-0 loss: 0.551812  [   32/  265]
train() client id: f_00001-2-1 loss: 0.483894  [   64/  265]
train() client id: f_00001-2-2 loss: 0.472063  [   96/  265]
train() client id: f_00001-2-3 loss: 0.395215  [  128/  265]
train() client id: f_00001-2-4 loss: 0.520555  [  160/  265]
train() client id: f_00001-2-5 loss: 0.499350  [  192/  265]
train() client id: f_00001-2-6 loss: 0.542731  [  224/  265]
train() client id: f_00001-2-7 loss: 0.409462  [  256/  265]
train() client id: f_00001-3-0 loss: 0.436189  [   32/  265]
train() client id: f_00001-3-1 loss: 0.575971  [   64/  265]
train() client id: f_00001-3-2 loss: 0.591715  [   96/  265]
train() client id: f_00001-3-3 loss: 0.506537  [  128/  265]
train() client id: f_00001-3-4 loss: 0.502698  [  160/  265]
train() client id: f_00001-3-5 loss: 0.503756  [  192/  265]
train() client id: f_00001-3-6 loss: 0.393409  [  224/  265]
train() client id: f_00001-3-7 loss: 0.385220  [  256/  265]
train() client id: f_00001-4-0 loss: 0.453519  [   32/  265]
train() client id: f_00001-4-1 loss: 0.534087  [   64/  265]
train() client id: f_00001-4-2 loss: 0.550107  [   96/  265]
train() client id: f_00001-4-3 loss: 0.537938  [  128/  265]
train() client id: f_00001-4-4 loss: 0.447327  [  160/  265]
train() client id: f_00001-4-5 loss: 0.503033  [  192/  265]
train() client id: f_00001-4-6 loss: 0.363056  [  224/  265]
train() client id: f_00001-4-7 loss: 0.465207  [  256/  265]
train() client id: f_00001-5-0 loss: 0.401703  [   32/  265]
train() client id: f_00001-5-1 loss: 0.506872  [   64/  265]
train() client id: f_00001-5-2 loss: 0.369150  [   96/  265]
train() client id: f_00001-5-3 loss: 0.510220  [  128/  265]
train() client id: f_00001-5-4 loss: 0.450876  [  160/  265]
train() client id: f_00001-5-5 loss: 0.504167  [  192/  265]
train() client id: f_00001-5-6 loss: 0.546087  [  224/  265]
train() client id: f_00001-5-7 loss: 0.425352  [  256/  265]
train() client id: f_00001-6-0 loss: 0.392838  [   32/  265]
train() client id: f_00001-6-1 loss: 0.467864  [   64/  265]
train() client id: f_00001-6-2 loss: 0.475633  [   96/  265]
train() client id: f_00001-6-3 loss: 0.462423  [  128/  265]
train() client id: f_00001-6-4 loss: 0.435849  [  160/  265]
train() client id: f_00001-6-5 loss: 0.478886  [  192/  265]
train() client id: f_00001-6-6 loss: 0.700562  [  224/  265]
train() client id: f_00001-6-7 loss: 0.396700  [  256/  265]
train() client id: f_00001-7-0 loss: 0.454829  [   32/  265]
train() client id: f_00001-7-1 loss: 0.562449  [   64/  265]
train() client id: f_00001-7-2 loss: 0.398623  [   96/  265]
train() client id: f_00001-7-3 loss: 0.466889  [  128/  265]
train() client id: f_00001-7-4 loss: 0.481750  [  160/  265]
train() client id: f_00001-7-5 loss: 0.399197  [  192/  265]
train() client id: f_00001-7-6 loss: 0.492838  [  224/  265]
train() client id: f_00001-7-7 loss: 0.598323  [  256/  265]
train() client id: f_00001-8-0 loss: 0.436082  [   32/  265]
train() client id: f_00001-8-1 loss: 0.483615  [   64/  265]
train() client id: f_00001-8-2 loss: 0.473459  [   96/  265]
train() client id: f_00001-8-3 loss: 0.532785  [  128/  265]
train() client id: f_00001-8-4 loss: 0.380093  [  160/  265]
train() client id: f_00001-8-5 loss: 0.561637  [  192/  265]
train() client id: f_00001-8-6 loss: 0.541772  [  224/  265]
train() client id: f_00001-8-7 loss: 0.438231  [  256/  265]
train() client id: f_00001-9-0 loss: 0.469964  [   32/  265]
train() client id: f_00001-9-1 loss: 0.487749  [   64/  265]
train() client id: f_00001-9-2 loss: 0.550536  [   96/  265]
train() client id: f_00001-9-3 loss: 0.440497  [  128/  265]
train() client id: f_00001-9-4 loss: 0.469541  [  160/  265]
train() client id: f_00001-9-5 loss: 0.462048  [  192/  265]
train() client id: f_00001-9-6 loss: 0.495731  [  224/  265]
train() client id: f_00001-9-7 loss: 0.456771  [  256/  265]
train() client id: f_00001-10-0 loss: 0.649586  [   32/  265]
train() client id: f_00001-10-1 loss: 0.479240  [   64/  265]
train() client id: f_00001-10-2 loss: 0.389767  [   96/  265]
train() client id: f_00001-10-3 loss: 0.437578  [  128/  265]
train() client id: f_00001-10-4 loss: 0.380609  [  160/  265]
train() client id: f_00001-10-5 loss: 0.528420  [  192/  265]
train() client id: f_00001-10-6 loss: 0.473186  [  224/  265]
train() client id: f_00001-10-7 loss: 0.457994  [  256/  265]
train() client id: f_00001-11-0 loss: 0.664165  [   32/  265]
train() client id: f_00001-11-1 loss: 0.415311  [   64/  265]
train() client id: f_00001-11-2 loss: 0.497417  [   96/  265]
train() client id: f_00001-11-3 loss: 0.542169  [  128/  265]
train() client id: f_00001-11-4 loss: 0.373048  [  160/  265]
train() client id: f_00001-11-5 loss: 0.441884  [  192/  265]
train() client id: f_00001-11-6 loss: 0.397303  [  224/  265]
train() client id: f_00001-11-7 loss: 0.512316  [  256/  265]
train() client id: f_00001-12-0 loss: 0.522545  [   32/  265]
train() client id: f_00001-12-1 loss: 0.375685  [   64/  265]
train() client id: f_00001-12-2 loss: 0.538527  [   96/  265]
train() client id: f_00001-12-3 loss: 0.392896  [  128/  265]
train() client id: f_00001-12-4 loss: 0.393484  [  160/  265]
train() client id: f_00001-12-5 loss: 0.664798  [  192/  265]
train() client id: f_00001-12-6 loss: 0.464253  [  224/  265]
train() client id: f_00001-12-7 loss: 0.468898  [  256/  265]
train() client id: f_00002-0-0 loss: 1.204115  [   32/  124]
train() client id: f_00002-0-1 loss: 1.102408  [   64/  124]
train() client id: f_00002-0-2 loss: 1.117567  [   96/  124]
train() client id: f_00002-1-0 loss: 1.248951  [   32/  124]
train() client id: f_00002-1-1 loss: 1.226513  [   64/  124]
train() client id: f_00002-1-2 loss: 1.026976  [   96/  124]
train() client id: f_00002-2-0 loss: 1.112068  [   32/  124]
train() client id: f_00002-2-1 loss: 1.187454  [   64/  124]
train() client id: f_00002-2-2 loss: 1.273540  [   96/  124]
train() client id: f_00002-3-0 loss: 1.341238  [   32/  124]
train() client id: f_00002-3-1 loss: 1.131692  [   64/  124]
train() client id: f_00002-3-2 loss: 0.979210  [   96/  124]
train() client id: f_00002-4-0 loss: 0.815319  [   32/  124]
train() client id: f_00002-4-1 loss: 1.255620  [   64/  124]
train() client id: f_00002-4-2 loss: 1.081950  [   96/  124]
train() client id: f_00002-5-0 loss: 0.933115  [   32/  124]
train() client id: f_00002-5-1 loss: 1.109138  [   64/  124]
train() client id: f_00002-5-2 loss: 0.997359  [   96/  124]
train() client id: f_00002-6-0 loss: 1.058876  [   32/  124]
train() client id: f_00002-6-1 loss: 0.916965  [   64/  124]
train() client id: f_00002-6-2 loss: 1.068939  [   96/  124]
train() client id: f_00002-7-0 loss: 0.974133  [   32/  124]
train() client id: f_00002-7-1 loss: 1.216619  [   64/  124]
train() client id: f_00002-7-2 loss: 0.912161  [   96/  124]
train() client id: f_00002-8-0 loss: 0.911870  [   32/  124]
train() client id: f_00002-8-1 loss: 0.934952  [   64/  124]
train() client id: f_00002-8-2 loss: 1.147880  [   96/  124]
train() client id: f_00002-9-0 loss: 0.948850  [   32/  124]
train() client id: f_00002-9-1 loss: 1.014022  [   64/  124]
train() client id: f_00002-9-2 loss: 1.158823  [   96/  124]
train() client id: f_00002-10-0 loss: 1.130868  [   32/  124]
train() client id: f_00002-10-1 loss: 0.887645  [   64/  124]
train() client id: f_00002-10-2 loss: 0.952263  [   96/  124]
train() client id: f_00002-11-0 loss: 1.003706  [   32/  124]
train() client id: f_00002-11-1 loss: 0.981161  [   64/  124]
train() client id: f_00002-11-2 loss: 0.905752  [   96/  124]
train() client id: f_00002-12-0 loss: 0.927035  [   32/  124]
train() client id: f_00002-12-1 loss: 1.011636  [   64/  124]
train() client id: f_00002-12-2 loss: 0.860920  [   96/  124]
train() client id: f_00003-0-0 loss: 0.424520  [   32/   43]
train() client id: f_00003-1-0 loss: 0.646662  [   32/   43]
train() client id: f_00003-2-0 loss: 0.710746  [   32/   43]
train() client id: f_00003-3-0 loss: 0.800717  [   32/   43]
train() client id: f_00003-4-0 loss: 0.826082  [   32/   43]
train() client id: f_00003-5-0 loss: 0.834083  [   32/   43]
train() client id: f_00003-6-0 loss: 0.797472  [   32/   43]
train() client id: f_00003-7-0 loss: 0.471309  [   32/   43]
train() client id: f_00003-8-0 loss: 0.443768  [   32/   43]
train() client id: f_00003-9-0 loss: 0.515537  [   32/   43]
train() client id: f_00003-10-0 loss: 0.633591  [   32/   43]
train() client id: f_00003-11-0 loss: 0.685357  [   32/   43]
train() client id: f_00003-12-0 loss: 0.616101  [   32/   43]
train() client id: f_00004-0-0 loss: 0.833887  [   32/  306]
train() client id: f_00004-0-1 loss: 0.755458  [   64/  306]
train() client id: f_00004-0-2 loss: 0.700235  [   96/  306]
train() client id: f_00004-0-3 loss: 0.667856  [  128/  306]
train() client id: f_00004-0-4 loss: 0.656864  [  160/  306]
train() client id: f_00004-0-5 loss: 0.780997  [  192/  306]
train() client id: f_00004-0-6 loss: 0.634801  [  224/  306]
train() client id: f_00004-0-7 loss: 0.804727  [  256/  306]
train() client id: f_00004-0-8 loss: 0.793799  [  288/  306]
train() client id: f_00004-1-0 loss: 0.793565  [   32/  306]
train() client id: f_00004-1-1 loss: 0.843046  [   64/  306]
train() client id: f_00004-1-2 loss: 0.851743  [   96/  306]
train() client id: f_00004-1-3 loss: 0.748904  [  128/  306]
train() client id: f_00004-1-4 loss: 0.644793  [  160/  306]
train() client id: f_00004-1-5 loss: 0.547191  [  192/  306]
train() client id: f_00004-1-6 loss: 0.768236  [  224/  306]
train() client id: f_00004-1-7 loss: 0.727619  [  256/  306]
train() client id: f_00004-1-8 loss: 0.755164  [  288/  306]
train() client id: f_00004-2-0 loss: 0.664239  [   32/  306]
train() client id: f_00004-2-1 loss: 0.634637  [   64/  306]
train() client id: f_00004-2-2 loss: 0.815488  [   96/  306]
train() client id: f_00004-2-3 loss: 0.777818  [  128/  306]
train() client id: f_00004-2-4 loss: 0.638146  [  160/  306]
train() client id: f_00004-2-5 loss: 0.726298  [  192/  306]
train() client id: f_00004-2-6 loss: 0.896806  [  224/  306]
train() client id: f_00004-2-7 loss: 0.788578  [  256/  306]
train() client id: f_00004-2-8 loss: 0.651770  [  288/  306]
train() client id: f_00004-3-0 loss: 0.744096  [   32/  306]
train() client id: f_00004-3-1 loss: 0.754364  [   64/  306]
train() client id: f_00004-3-2 loss: 0.777267  [   96/  306]
train() client id: f_00004-3-3 loss: 0.661373  [  128/  306]
train() client id: f_00004-3-4 loss: 0.680901  [  160/  306]
train() client id: f_00004-3-5 loss: 0.757099  [  192/  306]
train() client id: f_00004-3-6 loss: 0.601530  [  224/  306]
train() client id: f_00004-3-7 loss: 0.832193  [  256/  306]
train() client id: f_00004-3-8 loss: 0.834591  [  288/  306]
train() client id: f_00004-4-0 loss: 0.899114  [   32/  306]
train() client id: f_00004-4-1 loss: 0.632564  [   64/  306]
train() client id: f_00004-4-2 loss: 0.877621  [   96/  306]
train() client id: f_00004-4-3 loss: 0.753739  [  128/  306]
train() client id: f_00004-4-4 loss: 0.711627  [  160/  306]
train() client id: f_00004-4-5 loss: 0.615033  [  192/  306]
train() client id: f_00004-4-6 loss: 0.731624  [  224/  306]
train() client id: f_00004-4-7 loss: 0.629955  [  256/  306]
train() client id: f_00004-4-8 loss: 0.724460  [  288/  306]
train() client id: f_00004-5-0 loss: 0.740401  [   32/  306]
train() client id: f_00004-5-1 loss: 0.647467  [   64/  306]
train() client id: f_00004-5-2 loss: 0.826674  [   96/  306]
train() client id: f_00004-5-3 loss: 0.651379  [  128/  306]
train() client id: f_00004-5-4 loss: 0.784360  [  160/  306]
train() client id: f_00004-5-5 loss: 0.755153  [  192/  306]
train() client id: f_00004-5-6 loss: 0.733427  [  224/  306]
train() client id: f_00004-5-7 loss: 0.744491  [  256/  306]
train() client id: f_00004-5-8 loss: 0.676865  [  288/  306]
train() client id: f_00004-6-0 loss: 0.807009  [   32/  306]
train() client id: f_00004-6-1 loss: 0.612636  [   64/  306]
train() client id: f_00004-6-2 loss: 0.876239  [   96/  306]
train() client id: f_00004-6-3 loss: 0.744785  [  128/  306]
train() client id: f_00004-6-4 loss: 0.802264  [  160/  306]
train() client id: f_00004-6-5 loss: 0.658601  [  192/  306]
train() client id: f_00004-6-6 loss: 0.645273  [  224/  306]
train() client id: f_00004-6-7 loss: 0.736080  [  256/  306]
train() client id: f_00004-6-8 loss: 0.710277  [  288/  306]
train() client id: f_00004-7-0 loss: 0.886132  [   32/  306]
train() client id: f_00004-7-1 loss: 0.735340  [   64/  306]
train() client id: f_00004-7-2 loss: 0.673555  [   96/  306]
train() client id: f_00004-7-3 loss: 0.651623  [  128/  306]
train() client id: f_00004-7-4 loss: 0.809487  [  160/  306]
train() client id: f_00004-7-5 loss: 0.670449  [  192/  306]
train() client id: f_00004-7-6 loss: 0.832626  [  224/  306]
train() client id: f_00004-7-7 loss: 0.549906  [  256/  306]
train() client id: f_00004-7-8 loss: 0.796103  [  288/  306]
train() client id: f_00004-8-0 loss: 0.815102  [   32/  306]
train() client id: f_00004-8-1 loss: 0.723820  [   64/  306]
train() client id: f_00004-8-2 loss: 0.792160  [   96/  306]
train() client id: f_00004-8-3 loss: 0.718092  [  128/  306]
train() client id: f_00004-8-4 loss: 0.700111  [  160/  306]
train() client id: f_00004-8-5 loss: 0.713629  [  192/  306]
train() client id: f_00004-8-6 loss: 0.627977  [  224/  306]
train() client id: f_00004-8-7 loss: 0.839921  [  256/  306]
train() client id: f_00004-8-8 loss: 0.691063  [  288/  306]
train() client id: f_00004-9-0 loss: 0.730715  [   32/  306]
train() client id: f_00004-9-1 loss: 0.716181  [   64/  306]
train() client id: f_00004-9-2 loss: 0.661538  [   96/  306]
train() client id: f_00004-9-3 loss: 0.787809  [  128/  306]
train() client id: f_00004-9-4 loss: 0.807450  [  160/  306]
train() client id: f_00004-9-5 loss: 0.698258  [  192/  306]
train() client id: f_00004-9-6 loss: 0.778884  [  224/  306]
train() client id: f_00004-9-7 loss: 0.755472  [  256/  306]
train() client id: f_00004-9-8 loss: 0.691509  [  288/  306]
train() client id: f_00004-10-0 loss: 0.773696  [   32/  306]
train() client id: f_00004-10-1 loss: 0.723673  [   64/  306]
train() client id: f_00004-10-2 loss: 0.743916  [   96/  306]
train() client id: f_00004-10-3 loss: 0.811932  [  128/  306]
train() client id: f_00004-10-4 loss: 0.825119  [  160/  306]
train() client id: f_00004-10-5 loss: 0.632757  [  192/  306]
train() client id: f_00004-10-6 loss: 0.723418  [  224/  306]
train() client id: f_00004-10-7 loss: 0.699975  [  256/  306]
train() client id: f_00004-10-8 loss: 0.704386  [  288/  306]
train() client id: f_00004-11-0 loss: 0.868221  [   32/  306]
train() client id: f_00004-11-1 loss: 0.679316  [   64/  306]
train() client id: f_00004-11-2 loss: 0.619604  [   96/  306]
train() client id: f_00004-11-3 loss: 0.718338  [  128/  306]
train() client id: f_00004-11-4 loss: 0.698539  [  160/  306]
train() client id: f_00004-11-5 loss: 0.644901  [  192/  306]
train() client id: f_00004-11-6 loss: 0.818470  [  224/  306]
train() client id: f_00004-11-7 loss: 0.751948  [  256/  306]
train() client id: f_00004-11-8 loss: 0.761735  [  288/  306]
train() client id: f_00004-12-0 loss: 0.700417  [   32/  306]
train() client id: f_00004-12-1 loss: 0.727091  [   64/  306]
train() client id: f_00004-12-2 loss: 0.726407  [   96/  306]
train() client id: f_00004-12-3 loss: 0.722678  [  128/  306]
train() client id: f_00004-12-4 loss: 0.616439  [  160/  306]
train() client id: f_00004-12-5 loss: 0.826836  [  192/  306]
train() client id: f_00004-12-6 loss: 0.691785  [  224/  306]
train() client id: f_00004-12-7 loss: 0.769757  [  256/  306]
train() client id: f_00004-12-8 loss: 0.850768  [  288/  306]
train() client id: f_00005-0-0 loss: 0.310988  [   32/  146]
train() client id: f_00005-0-1 loss: 0.666972  [   64/  146]
train() client id: f_00005-0-2 loss: 0.500448  [   96/  146]
train() client id: f_00005-0-3 loss: 0.670388  [  128/  146]
train() client id: f_00005-1-0 loss: 0.383985  [   32/  146]
train() client id: f_00005-1-1 loss: 0.653043  [   64/  146]
train() client id: f_00005-1-2 loss: 0.715343  [   96/  146]
train() client id: f_00005-1-3 loss: 0.227033  [  128/  146]
train() client id: f_00005-2-0 loss: 0.228196  [   32/  146]
train() client id: f_00005-2-1 loss: 0.401743  [   64/  146]
train() client id: f_00005-2-2 loss: 0.699084  [   96/  146]
train() client id: f_00005-2-3 loss: 0.676949  [  128/  146]
train() client id: f_00005-3-0 loss: 0.603332  [   32/  146]
train() client id: f_00005-3-1 loss: 0.358656  [   64/  146]
train() client id: f_00005-3-2 loss: 0.352044  [   96/  146]
train() client id: f_00005-3-3 loss: 0.517819  [  128/  146]
train() client id: f_00005-4-0 loss: 0.514946  [   32/  146]
train() client id: f_00005-4-1 loss: 0.664370  [   64/  146]
train() client id: f_00005-4-2 loss: 0.213357  [   96/  146]
train() client id: f_00005-4-3 loss: 0.421981  [  128/  146]
train() client id: f_00005-5-0 loss: 0.409078  [   32/  146]
train() client id: f_00005-5-1 loss: 0.481056  [   64/  146]
train() client id: f_00005-5-2 loss: 0.424138  [   96/  146]
train() client id: f_00005-5-3 loss: 0.748456  [  128/  146]
train() client id: f_00005-6-0 loss: 0.392911  [   32/  146]
train() client id: f_00005-6-1 loss: 0.420766  [   64/  146]
train() client id: f_00005-6-2 loss: 0.595314  [   96/  146]
train() client id: f_00005-6-3 loss: 0.441208  [  128/  146]
train() client id: f_00005-7-0 loss: 0.532931  [   32/  146]
train() client id: f_00005-7-1 loss: 0.688120  [   64/  146]
train() client id: f_00005-7-2 loss: 0.437650  [   96/  146]
train() client id: f_00005-7-3 loss: 0.369026  [  128/  146]
train() client id: f_00005-8-0 loss: 0.555873  [   32/  146]
train() client id: f_00005-8-1 loss: 0.324800  [   64/  146]
train() client id: f_00005-8-2 loss: 0.556363  [   96/  146]
train() client id: f_00005-8-3 loss: 0.423973  [  128/  146]
train() client id: f_00005-9-0 loss: 0.593762  [   32/  146]
train() client id: f_00005-9-1 loss: 0.629903  [   64/  146]
train() client id: f_00005-9-2 loss: 0.349185  [   96/  146]
train() client id: f_00005-9-3 loss: 0.407301  [  128/  146]
train() client id: f_00005-10-0 loss: 0.616931  [   32/  146]
train() client id: f_00005-10-1 loss: 0.452148  [   64/  146]
train() client id: f_00005-10-2 loss: 0.453010  [   96/  146]
train() client id: f_00005-10-3 loss: 0.415657  [  128/  146]
train() client id: f_00005-11-0 loss: 0.211179  [   32/  146]
train() client id: f_00005-11-1 loss: 0.610561  [   64/  146]
train() client id: f_00005-11-2 loss: 0.263968  [   96/  146]
train() client id: f_00005-11-3 loss: 0.561616  [  128/  146]
train() client id: f_00005-12-0 loss: 0.626684  [   32/  146]
train() client id: f_00005-12-1 loss: 0.284944  [   64/  146]
train() client id: f_00005-12-2 loss: 0.615667  [   96/  146]
train() client id: f_00005-12-3 loss: 0.469894  [  128/  146]
train() client id: f_00006-0-0 loss: 0.459862  [   32/   54]
train() client id: f_00006-1-0 loss: 0.510694  [   32/   54]
train() client id: f_00006-2-0 loss: 0.398081  [   32/   54]
train() client id: f_00006-3-0 loss: 0.487784  [   32/   54]
train() client id: f_00006-4-0 loss: 0.488232  [   32/   54]
train() client id: f_00006-5-0 loss: 0.462028  [   32/   54]
train() client id: f_00006-6-0 loss: 0.452361  [   32/   54]
train() client id: f_00006-7-0 loss: 0.419739  [   32/   54]
train() client id: f_00006-8-0 loss: 0.394610  [   32/   54]
train() client id: f_00006-9-0 loss: 0.372312  [   32/   54]
train() client id: f_00006-10-0 loss: 0.434135  [   32/   54]
train() client id: f_00006-11-0 loss: 0.494295  [   32/   54]
train() client id: f_00006-12-0 loss: 0.485735  [   32/   54]
train() client id: f_00007-0-0 loss: 0.548688  [   32/  179]
train() client id: f_00007-0-1 loss: 0.448449  [   64/  179]
train() client id: f_00007-0-2 loss: 0.646980  [   96/  179]
train() client id: f_00007-0-3 loss: 0.724812  [  128/  179]
train() client id: f_00007-0-4 loss: 0.412407  [  160/  179]
train() client id: f_00007-1-0 loss: 0.515063  [   32/  179]
train() client id: f_00007-1-1 loss: 0.571912  [   64/  179]
train() client id: f_00007-1-2 loss: 0.445806  [   96/  179]
train() client id: f_00007-1-3 loss: 0.477426  [  128/  179]
train() client id: f_00007-1-4 loss: 0.518497  [  160/  179]
train() client id: f_00007-2-0 loss: 0.340518  [   32/  179]
train() client id: f_00007-2-1 loss: 0.501560  [   64/  179]
train() client id: f_00007-2-2 loss: 0.463126  [   96/  179]
train() client id: f_00007-2-3 loss: 0.542827  [  128/  179]
train() client id: f_00007-2-4 loss: 0.649554  [  160/  179]
train() client id: f_00007-3-0 loss: 0.428260  [   32/  179]
train() client id: f_00007-3-1 loss: 0.555422  [   64/  179]
train() client id: f_00007-3-2 loss: 0.382076  [   96/  179]
train() client id: f_00007-3-3 loss: 0.689192  [  128/  179]
train() client id: f_00007-3-4 loss: 0.533028  [  160/  179]
train() client id: f_00007-4-0 loss: 0.485429  [   32/  179]
train() client id: f_00007-4-1 loss: 0.642448  [   64/  179]
train() client id: f_00007-4-2 loss: 0.476018  [   96/  179]
train() client id: f_00007-4-3 loss: 0.445588  [  128/  179]
train() client id: f_00007-4-4 loss: 0.500070  [  160/  179]
train() client id: f_00007-5-0 loss: 0.870965  [   32/  179]
train() client id: f_00007-5-1 loss: 0.334160  [   64/  179]
train() client id: f_00007-5-2 loss: 0.569938  [   96/  179]
train() client id: f_00007-5-3 loss: 0.346798  [  128/  179]
train() client id: f_00007-5-4 loss: 0.398650  [  160/  179]
train() client id: f_00007-6-0 loss: 0.454119  [   32/  179]
train() client id: f_00007-6-1 loss: 0.566837  [   64/  179]
train() client id: f_00007-6-2 loss: 0.408376  [   96/  179]
train() client id: f_00007-6-3 loss: 0.280936  [  128/  179]
train() client id: f_00007-6-4 loss: 0.590675  [  160/  179]
train() client id: f_00007-7-0 loss: 0.551122  [   32/  179]
train() client id: f_00007-7-1 loss: 0.582202  [   64/  179]
train() client id: f_00007-7-2 loss: 0.315255  [   96/  179]
train() client id: f_00007-7-3 loss: 0.434001  [  128/  179]
train() client id: f_00007-7-4 loss: 0.323031  [  160/  179]
train() client id: f_00007-8-0 loss: 0.281151  [   32/  179]
train() client id: f_00007-8-1 loss: 0.604908  [   64/  179]
train() client id: f_00007-8-2 loss: 0.469245  [   96/  179]
train() client id: f_00007-8-3 loss: 0.417759  [  128/  179]
train() client id: f_00007-8-4 loss: 0.596390  [  160/  179]
train() client id: f_00007-9-0 loss: 0.653952  [   32/  179]
train() client id: f_00007-9-1 loss: 0.582231  [   64/  179]
train() client id: f_00007-9-2 loss: 0.336780  [   96/  179]
train() client id: f_00007-9-3 loss: 0.348403  [  128/  179]
train() client id: f_00007-9-4 loss: 0.412041  [  160/  179]
train() client id: f_00007-10-0 loss: 0.502492  [   32/  179]
train() client id: f_00007-10-1 loss: 0.485632  [   64/  179]
train() client id: f_00007-10-2 loss: 0.293168  [   96/  179]
train() client id: f_00007-10-3 loss: 0.553340  [  128/  179]
train() client id: f_00007-10-4 loss: 0.637302  [  160/  179]
train() client id: f_00007-11-0 loss: 0.632287  [   32/  179]
train() client id: f_00007-11-1 loss: 0.313272  [   64/  179]
train() client id: f_00007-11-2 loss: 0.501696  [   96/  179]
train() client id: f_00007-11-3 loss: 0.514211  [  128/  179]
train() client id: f_00007-11-4 loss: 0.511187  [  160/  179]
train() client id: f_00007-12-0 loss: 0.351558  [   32/  179]
train() client id: f_00007-12-1 loss: 0.466385  [   64/  179]
train() client id: f_00007-12-2 loss: 0.502229  [   96/  179]
train() client id: f_00007-12-3 loss: 0.629185  [  128/  179]
train() client id: f_00007-12-4 loss: 0.439128  [  160/  179]
train() client id: f_00008-0-0 loss: 0.746822  [   32/  130]
train() client id: f_00008-0-1 loss: 0.687966  [   64/  130]
train() client id: f_00008-0-2 loss: 0.609623  [   96/  130]
train() client id: f_00008-0-3 loss: 0.957623  [  128/  130]
train() client id: f_00008-1-0 loss: 0.796227  [   32/  130]
train() client id: f_00008-1-1 loss: 0.729356  [   64/  130]
train() client id: f_00008-1-2 loss: 0.804513  [   96/  130]
train() client id: f_00008-1-3 loss: 0.663402  [  128/  130]
train() client id: f_00008-2-0 loss: 0.809486  [   32/  130]
train() client id: f_00008-2-1 loss: 0.727184  [   64/  130]
train() client id: f_00008-2-2 loss: 0.695479  [   96/  130]
train() client id: f_00008-2-3 loss: 0.762593  [  128/  130]
train() client id: f_00008-3-0 loss: 0.776311  [   32/  130]
train() client id: f_00008-3-1 loss: 0.735873  [   64/  130]
train() client id: f_00008-3-2 loss: 0.707679  [   96/  130]
train() client id: f_00008-3-3 loss: 0.785951  [  128/  130]
train() client id: f_00008-4-0 loss: 0.752944  [   32/  130]
train() client id: f_00008-4-1 loss: 0.683107  [   64/  130]
train() client id: f_00008-4-2 loss: 0.785631  [   96/  130]
train() client id: f_00008-4-3 loss: 0.749269  [  128/  130]
train() client id: f_00008-5-0 loss: 0.787998  [   32/  130]
train() client id: f_00008-5-1 loss: 0.701787  [   64/  130]
train() client id: f_00008-5-2 loss: 0.820922  [   96/  130]
train() client id: f_00008-5-3 loss: 0.669666  [  128/  130]
train() client id: f_00008-6-0 loss: 0.678569  [   32/  130]
train() client id: f_00008-6-1 loss: 0.652638  [   64/  130]
train() client id: f_00008-6-2 loss: 0.782053  [   96/  130]
train() client id: f_00008-6-3 loss: 0.902724  [  128/  130]
train() client id: f_00008-7-0 loss: 0.813262  [   32/  130]
train() client id: f_00008-7-1 loss: 0.772214  [   64/  130]
train() client id: f_00008-7-2 loss: 0.701747  [   96/  130]
train() client id: f_00008-7-3 loss: 0.691126  [  128/  130]
train() client id: f_00008-8-0 loss: 0.827040  [   32/  130]
train() client id: f_00008-8-1 loss: 0.706425  [   64/  130]
train() client id: f_00008-8-2 loss: 0.656390  [   96/  130]
train() client id: f_00008-8-3 loss: 0.806288  [  128/  130]
train() client id: f_00008-9-0 loss: 0.646678  [   32/  130]
train() client id: f_00008-9-1 loss: 0.690722  [   64/  130]
train() client id: f_00008-9-2 loss: 0.852153  [   96/  130]
train() client id: f_00008-9-3 loss: 0.810715  [  128/  130]
train() client id: f_00008-10-0 loss: 0.716309  [   32/  130]
train() client id: f_00008-10-1 loss: 0.799965  [   64/  130]
train() client id: f_00008-10-2 loss: 0.754064  [   96/  130]
train() client id: f_00008-10-3 loss: 0.734052  [  128/  130]
train() client id: f_00008-11-0 loss: 0.687899  [   32/  130]
train() client id: f_00008-11-1 loss: 0.893224  [   64/  130]
train() client id: f_00008-11-2 loss: 0.731952  [   96/  130]
train() client id: f_00008-11-3 loss: 0.703726  [  128/  130]
train() client id: f_00008-12-0 loss: 0.830779  [   32/  130]
train() client id: f_00008-12-1 loss: 0.641276  [   64/  130]
train() client id: f_00008-12-2 loss: 0.866834  [   96/  130]
train() client id: f_00008-12-3 loss: 0.639256  [  128/  130]
train() client id: f_00009-0-0 loss: 1.050590  [   32/  118]
train() client id: f_00009-0-1 loss: 1.017596  [   64/  118]
train() client id: f_00009-0-2 loss: 1.042280  [   96/  118]
train() client id: f_00009-1-0 loss: 0.997343  [   32/  118]
train() client id: f_00009-1-1 loss: 1.011459  [   64/  118]
train() client id: f_00009-1-2 loss: 0.869560  [   96/  118]
train() client id: f_00009-2-0 loss: 0.899391  [   32/  118]
train() client id: f_00009-2-1 loss: 1.025712  [   64/  118]
train() client id: f_00009-2-2 loss: 0.982920  [   96/  118]
train() client id: f_00009-3-0 loss: 0.795782  [   32/  118]
train() client id: f_00009-3-1 loss: 0.857688  [   64/  118]
train() client id: f_00009-3-2 loss: 1.080397  [   96/  118]
train() client id: f_00009-4-0 loss: 1.004380  [   32/  118]
train() client id: f_00009-4-1 loss: 1.047316  [   64/  118]
train() client id: f_00009-4-2 loss: 0.785225  [   96/  118]
train() client id: f_00009-5-0 loss: 0.935015  [   32/  118]
train() client id: f_00009-5-1 loss: 0.670674  [   64/  118]
train() client id: f_00009-5-2 loss: 0.831835  [   96/  118]
train() client id: f_00009-6-0 loss: 0.775274  [   32/  118]
train() client id: f_00009-6-1 loss: 0.887341  [   64/  118]
train() client id: f_00009-6-2 loss: 0.899386  [   96/  118]
train() client id: f_00009-7-0 loss: 0.783696  [   32/  118]
train() client id: f_00009-7-1 loss: 0.747873  [   64/  118]
train() client id: f_00009-7-2 loss: 0.876326  [   96/  118]
train() client id: f_00009-8-0 loss: 0.854773  [   32/  118]
train() client id: f_00009-8-1 loss: 0.867999  [   64/  118]
train() client id: f_00009-8-2 loss: 0.888635  [   96/  118]
train() client id: f_00009-9-0 loss: 0.774937  [   32/  118]
train() client id: f_00009-9-1 loss: 0.728840  [   64/  118]
train() client id: f_00009-9-2 loss: 0.899845  [   96/  118]
train() client id: f_00009-10-0 loss: 0.767571  [   32/  118]
train() client id: f_00009-10-1 loss: 0.878119  [   64/  118]
train() client id: f_00009-10-2 loss: 0.789781  [   96/  118]
train() client id: f_00009-11-0 loss: 0.871235  [   32/  118]
train() client id: f_00009-11-1 loss: 0.667114  [   64/  118]
train() client id: f_00009-11-2 loss: 1.044165  [   96/  118]
train() client id: f_00009-12-0 loss: 0.859997  [   32/  118]
train() client id: f_00009-12-1 loss: 0.903694  [   64/  118]
train() client id: f_00009-12-2 loss: 0.770065  [   96/  118]
At round 62 accuracy: 0.6392572944297082
At round 62 training accuracy: 0.5881958417169685
At round 62 training loss: 0.8260611823957563
gradient difference: 0.420973539352417
train() client id: f_00000-0-0 loss: 1.386815  [   32/  126]
train() client id: f_00000-0-1 loss: 1.173031  [   64/  126]
train() client id: f_00000-0-2 loss: 1.278695  [   96/  126]
train() client id: f_00000-1-0 loss: 1.088615  [   32/  126]
train() client id: f_00000-1-1 loss: 1.190526  [   64/  126]
train() client id: f_00000-1-2 loss: 0.949650  [   96/  126]
train() client id: f_00000-2-0 loss: 1.140322  [   32/  126]
train() client id: f_00000-2-1 loss: 0.987372  [   64/  126]
train() client id: f_00000-2-2 loss: 0.976577  [   96/  126]
train() client id: f_00000-3-0 loss: 1.015677  [   32/  126]
train() client id: f_00000-3-1 loss: 1.073348  [   64/  126]
train() client id: f_00000-3-2 loss: 0.902793  [   96/  126]
train() client id: f_00000-4-0 loss: 0.931129  [   32/  126]
train() client id: f_00000-4-1 loss: 0.930373  [   64/  126]
train() client id: f_00000-4-2 loss: 0.941505  [   96/  126]
train() client id: f_00000-5-0 loss: 0.932552  [   32/  126]
train() client id: f_00000-5-1 loss: 0.951092  [   64/  126]
train() client id: f_00000-5-2 loss: 0.993944  [   96/  126]
train() client id: f_00000-6-0 loss: 0.932979  [   32/  126]
train() client id: f_00000-6-1 loss: 0.909275  [   64/  126]
train() client id: f_00000-6-2 loss: 0.973309  [   96/  126]
train() client id: f_00000-7-0 loss: 0.884794  [   32/  126]
train() client id: f_00000-7-1 loss: 0.890348  [   64/  126]
train() client id: f_00000-7-2 loss: 0.798569  [   96/  126]
train() client id: f_00000-8-0 loss: 0.969790  [   32/  126]
train() client id: f_00000-8-1 loss: 0.792330  [   64/  126]
train() client id: f_00000-8-2 loss: 0.868664  [   96/  126]
train() client id: f_00000-9-0 loss: 0.938536  [   32/  126]
train() client id: f_00000-9-1 loss: 0.758004  [   64/  126]
train() client id: f_00000-9-2 loss: 0.864207  [   96/  126]
train() client id: f_00000-10-0 loss: 0.817181  [   32/  126]
train() client id: f_00000-10-1 loss: 0.745383  [   64/  126]
train() client id: f_00000-10-2 loss: 0.801540  [   96/  126]
train() client id: f_00000-11-0 loss: 0.807911  [   32/  126]
train() client id: f_00000-11-1 loss: 1.041408  [   64/  126]
train() client id: f_00000-11-2 loss: 0.763950  [   96/  126]
train() client id: f_00000-12-0 loss: 0.796835  [   32/  126]
train() client id: f_00000-12-1 loss: 0.868414  [   64/  126]
train() client id: f_00000-12-2 loss: 0.778683  [   96/  126]
train() client id: f_00001-0-0 loss: 0.411956  [   32/  265]
train() client id: f_00001-0-1 loss: 0.364688  [   64/  265]
train() client id: f_00001-0-2 loss: 0.442671  [   96/  265]
train() client id: f_00001-0-3 loss: 0.430395  [  128/  265]
train() client id: f_00001-0-4 loss: 0.352626  [  160/  265]
train() client id: f_00001-0-5 loss: 0.363271  [  192/  265]
train() client id: f_00001-0-6 loss: 0.456599  [  224/  265]
train() client id: f_00001-0-7 loss: 0.605698  [  256/  265]
train() client id: f_00001-1-0 loss: 0.420553  [   32/  265]
train() client id: f_00001-1-1 loss: 0.538184  [   64/  265]
train() client id: f_00001-1-2 loss: 0.373050  [   96/  265]
train() client id: f_00001-1-3 loss: 0.358168  [  128/  265]
train() client id: f_00001-1-4 loss: 0.406505  [  160/  265]
train() client id: f_00001-1-5 loss: 0.448350  [  192/  265]
train() client id: f_00001-1-6 loss: 0.374390  [  224/  265]
train() client id: f_00001-1-7 loss: 0.442278  [  256/  265]
train() client id: f_00001-2-0 loss: 0.529862  [   32/  265]
train() client id: f_00001-2-1 loss: 0.405073  [   64/  265]
train() client id: f_00001-2-2 loss: 0.352795  [   96/  265]
train() client id: f_00001-2-3 loss: 0.591542  [  128/  265]
train() client id: f_00001-2-4 loss: 0.334477  [  160/  265]
train() client id: f_00001-2-5 loss: 0.388852  [  192/  265]
train() client id: f_00001-2-6 loss: 0.324568  [  224/  265]
train() client id: f_00001-2-7 loss: 0.376823  [  256/  265]
train() client id: f_00001-3-0 loss: 0.454987  [   32/  265]
train() client id: f_00001-3-1 loss: 0.436115  [   64/  265]
train() client id: f_00001-3-2 loss: 0.408554  [   96/  265]
train() client id: f_00001-3-3 loss: 0.325473  [  128/  265]
train() client id: f_00001-3-4 loss: 0.332731  [  160/  265]
train() client id: f_00001-3-5 loss: 0.375238  [  192/  265]
train() client id: f_00001-3-6 loss: 0.416452  [  224/  265]
train() client id: f_00001-3-7 loss: 0.487587  [  256/  265]
train() client id: f_00001-4-0 loss: 0.369453  [   32/  265]
train() client id: f_00001-4-1 loss: 0.321368  [   64/  265]
train() client id: f_00001-4-2 loss: 0.494306  [   96/  265]
train() client id: f_00001-4-3 loss: 0.530478  [  128/  265]
train() client id: f_00001-4-4 loss: 0.372853  [  160/  265]
train() client id: f_00001-4-5 loss: 0.317925  [  192/  265]
train() client id: f_00001-4-6 loss: 0.300533  [  224/  265]
train() client id: f_00001-4-7 loss: 0.507592  [  256/  265]
train() client id: f_00001-5-0 loss: 0.356007  [   32/  265]
train() client id: f_00001-5-1 loss: 0.392136  [   64/  265]
train() client id: f_00001-5-2 loss: 0.349604  [   96/  265]
train() client id: f_00001-5-3 loss: 0.376008  [  128/  265]
train() client id: f_00001-5-4 loss: 0.358214  [  160/  265]
train() client id: f_00001-5-5 loss: 0.502587  [  192/  265]
train() client id: f_00001-5-6 loss: 0.391398  [  224/  265]
train() client id: f_00001-5-7 loss: 0.402237  [  256/  265]
train() client id: f_00001-6-0 loss: 0.363349  [   32/  265]
train() client id: f_00001-6-1 loss: 0.293527  [   64/  265]
train() client id: f_00001-6-2 loss: 0.441990  [   96/  265]
train() client id: f_00001-6-3 loss: 0.447922  [  128/  265]
train() client id: f_00001-6-4 loss: 0.418749  [  160/  265]
train() client id: f_00001-6-5 loss: 0.298577  [  192/  265]
train() client id: f_00001-6-6 loss: 0.365932  [  224/  265]
train() client id: f_00001-6-7 loss: 0.401809  [  256/  265]
train() client id: f_00001-7-0 loss: 0.507813  [   32/  265]
train() client id: f_00001-7-1 loss: 0.364863  [   64/  265]
train() client id: f_00001-7-2 loss: 0.307945  [   96/  265]
train() client id: f_00001-7-3 loss: 0.327174  [  128/  265]
train() client id: f_00001-7-4 loss: 0.388637  [  160/  265]
train() client id: f_00001-7-5 loss: 0.448154  [  192/  265]
train() client id: f_00001-7-6 loss: 0.391022  [  224/  265]
train() client id: f_00001-7-7 loss: 0.421385  [  256/  265]
train() client id: f_00001-8-0 loss: 0.338889  [   32/  265]
train() client id: f_00001-8-1 loss: 0.378876  [   64/  265]
train() client id: f_00001-8-2 loss: 0.342933  [   96/  265]
train() client id: f_00001-8-3 loss: 0.403859  [  128/  265]
train() client id: f_00001-8-4 loss: 0.358247  [  160/  265]
train() client id: f_00001-8-5 loss: 0.387960  [  192/  265]
train() client id: f_00001-8-6 loss: 0.534717  [  224/  265]
train() client id: f_00001-8-7 loss: 0.403763  [  256/  265]
train() client id: f_00001-9-0 loss: 0.329173  [   32/  265]
train() client id: f_00001-9-1 loss: 0.552430  [   64/  265]
train() client id: f_00001-9-2 loss: 0.303403  [   96/  265]
train() client id: f_00001-9-3 loss: 0.379083  [  128/  265]
train() client id: f_00001-9-4 loss: 0.490884  [  160/  265]
train() client id: f_00001-9-5 loss: 0.339663  [  192/  265]
train() client id: f_00001-9-6 loss: 0.311680  [  224/  265]
train() client id: f_00001-9-7 loss: 0.313149  [  256/  265]
train() client id: f_00001-10-0 loss: 0.380548  [   32/  265]
train() client id: f_00001-10-1 loss: 0.317291  [   64/  265]
train() client id: f_00001-10-2 loss: 0.528541  [   96/  265]
train() client id: f_00001-10-3 loss: 0.407014  [  128/  265]
train() client id: f_00001-10-4 loss: 0.402347  [  160/  265]
train() client id: f_00001-10-5 loss: 0.290712  [  192/  265]
train() client id: f_00001-10-6 loss: 0.301530  [  224/  265]
train() client id: f_00001-10-7 loss: 0.506144  [  256/  265]
train() client id: f_00001-11-0 loss: 0.540971  [   32/  265]
train() client id: f_00001-11-1 loss: 0.463599  [   64/  265]
train() client id: f_00001-11-2 loss: 0.445753  [   96/  265]
train() client id: f_00001-11-3 loss: 0.327396  [  128/  265]
train() client id: f_00001-11-4 loss: 0.374092  [  160/  265]
train() client id: f_00001-11-5 loss: 0.304008  [  192/  265]
train() client id: f_00001-11-6 loss: 0.293176  [  224/  265]
train() client id: f_00001-11-7 loss: 0.297055  [  256/  265]
train() client id: f_00001-12-0 loss: 0.447651  [   32/  265]
train() client id: f_00001-12-1 loss: 0.459519  [   64/  265]
train() client id: f_00001-12-2 loss: 0.312469  [   96/  265]
train() client id: f_00001-12-3 loss: 0.300838  [  128/  265]
train() client id: f_00001-12-4 loss: 0.573025  [  160/  265]
train() client id: f_00001-12-5 loss: 0.333890  [  192/  265]
train() client id: f_00001-12-6 loss: 0.378472  [  224/  265]
train() client id: f_00001-12-7 loss: 0.313964  [  256/  265]
train() client id: f_00002-0-0 loss: 1.151569  [   32/  124]
train() client id: f_00002-0-1 loss: 1.261430  [   64/  124]
train() client id: f_00002-0-2 loss: 1.367746  [   96/  124]
train() client id: f_00002-1-0 loss: 1.370526  [   32/  124]
train() client id: f_00002-1-1 loss: 1.017734  [   64/  124]
train() client id: f_00002-1-2 loss: 1.176744  [   96/  124]
train() client id: f_00002-2-0 loss: 1.191426  [   32/  124]
train() client id: f_00002-2-1 loss: 1.139017  [   64/  124]
train() client id: f_00002-2-2 loss: 1.338036  [   96/  124]
train() client id: f_00002-3-0 loss: 1.220928  [   32/  124]
train() client id: f_00002-3-1 loss: 1.062871  [   64/  124]
train() client id: f_00002-3-2 loss: 1.133695  [   96/  124]
train() client id: f_00002-4-0 loss: 1.185993  [   32/  124]
train() client id: f_00002-4-1 loss: 1.206958  [   64/  124]
train() client id: f_00002-4-2 loss: 1.107259  [   96/  124]
train() client id: f_00002-5-0 loss: 1.021039  [   32/  124]
train() client id: f_00002-5-1 loss: 1.078428  [   64/  124]
train() client id: f_00002-5-2 loss: 1.257953  [   96/  124]
train() client id: f_00002-6-0 loss: 1.095281  [   32/  124]
train() client id: f_00002-6-1 loss: 1.056718  [   64/  124]
train() client id: f_00002-6-2 loss: 1.300009  [   96/  124]
train() client id: f_00002-7-0 loss: 0.954864  [   32/  124]
train() client id: f_00002-7-1 loss: 1.086723  [   64/  124]
train() client id: f_00002-7-2 loss: 1.295917  [   96/  124]
train() client id: f_00002-8-0 loss: 1.085571  [   32/  124]
train() client id: f_00002-8-1 loss: 1.102053  [   64/  124]
train() client id: f_00002-8-2 loss: 0.905275  [   96/  124]
train() client id: f_00002-9-0 loss: 1.164610  [   32/  124]
train() client id: f_00002-9-1 loss: 1.166749  [   64/  124]
train() client id: f_00002-9-2 loss: 1.015043  [   96/  124]
train() client id: f_00002-10-0 loss: 1.042845  [   32/  124]
train() client id: f_00002-10-1 loss: 1.020116  [   64/  124]
train() client id: f_00002-10-2 loss: 1.161248  [   96/  124]
train() client id: f_00002-11-0 loss: 1.015797  [   32/  124]
train() client id: f_00002-11-1 loss: 1.028421  [   64/  124]
train() client id: f_00002-11-2 loss: 1.173376  [   96/  124]
train() client id: f_00002-12-0 loss: 1.091126  [   32/  124]
train() client id: f_00002-12-1 loss: 1.268929  [   64/  124]
train() client id: f_00002-12-2 loss: 1.052942  [   96/  124]
train() client id: f_00003-0-0 loss: 0.728165  [   32/   43]
train() client id: f_00003-1-0 loss: 0.558661  [   32/   43]
train() client id: f_00003-2-0 loss: 0.752490  [   32/   43]
train() client id: f_00003-3-0 loss: 0.775131  [   32/   43]
train() client id: f_00003-4-0 loss: 0.581854  [   32/   43]
train() client id: f_00003-5-0 loss: 0.650255  [   32/   43]
train() client id: f_00003-6-0 loss: 0.718299  [   32/   43]
train() client id: f_00003-7-0 loss: 0.637195  [   32/   43]
train() client id: f_00003-8-0 loss: 0.595628  [   32/   43]
train() client id: f_00003-9-0 loss: 0.828728  [   32/   43]
train() client id: f_00003-10-0 loss: 0.616483  [   32/   43]
train() client id: f_00003-11-0 loss: 0.722063  [   32/   43]
train() client id: f_00003-12-0 loss: 0.644607  [   32/   43]
train() client id: f_00004-0-0 loss: 0.590976  [   32/  306]
train() client id: f_00004-0-1 loss: 0.723211  [   64/  306]
train() client id: f_00004-0-2 loss: 0.717389  [   96/  306]
train() client id: f_00004-0-3 loss: 0.600996  [  128/  306]
train() client id: f_00004-0-4 loss: 0.543966  [  160/  306]
train() client id: f_00004-0-5 loss: 0.813058  [  192/  306]
train() client id: f_00004-0-6 loss: 0.678165  [  224/  306]
train() client id: f_00004-0-7 loss: 0.581097  [  256/  306]
train() client id: f_00004-0-8 loss: 0.909989  [  288/  306]
train() client id: f_00004-1-0 loss: 0.619269  [   32/  306]
train() client id: f_00004-1-1 loss: 0.683542  [   64/  306]
train() client id: f_00004-1-2 loss: 0.724410  [   96/  306]
train() client id: f_00004-1-3 loss: 0.688701  [  128/  306]
train() client id: f_00004-1-4 loss: 0.697229  [  160/  306]
train() client id: f_00004-1-5 loss: 0.629553  [  192/  306]
train() client id: f_00004-1-6 loss: 0.775857  [  224/  306]
train() client id: f_00004-1-7 loss: 0.751904  [  256/  306]
train() client id: f_00004-1-8 loss: 0.553173  [  288/  306]
train() client id: f_00004-2-0 loss: 0.729201  [   32/  306]
train() client id: f_00004-2-1 loss: 0.796138  [   64/  306]
train() client id: f_00004-2-2 loss: 0.676751  [   96/  306]
train() client id: f_00004-2-3 loss: 0.679404  [  128/  306]
train() client id: f_00004-2-4 loss: 0.711186  [  160/  306]
train() client id: f_00004-2-5 loss: 0.611577  [  192/  306]
train() client id: f_00004-2-6 loss: 0.674390  [  224/  306]
train() client id: f_00004-2-7 loss: 0.709978  [  256/  306]
train() client id: f_00004-2-8 loss: 0.600997  [  288/  306]
train() client id: f_00004-3-0 loss: 0.603334  [   32/  306]
train() client id: f_00004-3-1 loss: 0.499788  [   64/  306]
train() client id: f_00004-3-2 loss: 0.784814  [   96/  306]
train() client id: f_00004-3-3 loss: 0.733516  [  128/  306]
train() client id: f_00004-3-4 loss: 0.731249  [  160/  306]
train() client id: f_00004-3-5 loss: 0.676716  [  192/  306]
train() client id: f_00004-3-6 loss: 0.672581  [  224/  306]
train() client id: f_00004-3-7 loss: 0.749853  [  256/  306]
train() client id: f_00004-3-8 loss: 0.691888  [  288/  306]
train() client id: f_00004-4-0 loss: 0.674711  [   32/  306]
train() client id: f_00004-4-1 loss: 0.675293  [   64/  306]
train() client id: f_00004-4-2 loss: 0.640263  [   96/  306]
train() client id: f_00004-4-3 loss: 0.631223  [  128/  306]
train() client id: f_00004-4-4 loss: 0.734292  [  160/  306]
train() client id: f_00004-4-5 loss: 0.660062  [  192/  306]
train() client id: f_00004-4-6 loss: 0.682650  [  224/  306]
train() client id: f_00004-4-7 loss: 0.771921  [  256/  306]
train() client id: f_00004-4-8 loss: 0.700933  [  288/  306]
train() client id: f_00004-5-0 loss: 0.573230  [   32/  306]
train() client id: f_00004-5-1 loss: 0.655341  [   64/  306]
train() client id: f_00004-5-2 loss: 0.622341  [   96/  306]
train() client id: f_00004-5-3 loss: 0.631549  [  128/  306]
train() client id: f_00004-5-4 loss: 0.569543  [  160/  306]
train() client id: f_00004-5-5 loss: 0.790023  [  192/  306]
train() client id: f_00004-5-6 loss: 0.826066  [  224/  306]
train() client id: f_00004-5-7 loss: 0.913134  [  256/  306]
train() client id: f_00004-5-8 loss: 0.646561  [  288/  306]
train() client id: f_00004-6-0 loss: 0.522333  [   32/  306]
train() client id: f_00004-6-1 loss: 0.652072  [   64/  306]
train() client id: f_00004-6-2 loss: 0.711721  [   96/  306]
train() client id: f_00004-6-3 loss: 0.727888  [  128/  306]
train() client id: f_00004-6-4 loss: 0.699356  [  160/  306]
train() client id: f_00004-6-5 loss: 0.734206  [  192/  306]
train() client id: f_00004-6-6 loss: 0.766601  [  224/  306]
train() client id: f_00004-6-7 loss: 0.779322  [  256/  306]
train() client id: f_00004-6-8 loss: 0.624712  [  288/  306]
train() client id: f_00004-7-0 loss: 0.756695  [   32/  306]
train() client id: f_00004-7-1 loss: 0.748388  [   64/  306]
train() client id: f_00004-7-2 loss: 0.712371  [   96/  306]
train() client id: f_00004-7-3 loss: 0.632318  [  128/  306]
train() client id: f_00004-7-4 loss: 0.849738  [  160/  306]
train() client id: f_00004-7-5 loss: 0.633372  [  192/  306]
train() client id: f_00004-7-6 loss: 0.567183  [  224/  306]
train() client id: f_00004-7-7 loss: 0.645753  [  256/  306]
train() client id: f_00004-7-8 loss: 0.648940  [  288/  306]
train() client id: f_00004-8-0 loss: 0.733079  [   32/  306]
train() client id: f_00004-8-1 loss: 0.691623  [   64/  306]
train() client id: f_00004-8-2 loss: 0.645123  [   96/  306]
train() client id: f_00004-8-3 loss: 0.680230  [  128/  306]
train() client id: f_00004-8-4 loss: 0.695880  [  160/  306]
train() client id: f_00004-8-5 loss: 0.697913  [  192/  306]
train() client id: f_00004-8-6 loss: 0.715795  [  224/  306]
train() client id: f_00004-8-7 loss: 0.615219  [  256/  306]
train() client id: f_00004-8-8 loss: 0.787466  [  288/  306]
train() client id: f_00004-9-0 loss: 0.678537  [   32/  306]
train() client id: f_00004-9-1 loss: 0.858935  [   64/  306]
train() client id: f_00004-9-2 loss: 0.558033  [   96/  306]
train() client id: f_00004-9-3 loss: 0.885742  [  128/  306]
train() client id: f_00004-9-4 loss: 0.628933  [  160/  306]
train() client id: f_00004-9-5 loss: 0.532922  [  192/  306]
train() client id: f_00004-9-6 loss: 0.685024  [  224/  306]
train() client id: f_00004-9-7 loss: 0.621324  [  256/  306]
train() client id: f_00004-9-8 loss: 0.748105  [  288/  306]
train() client id: f_00004-10-0 loss: 0.613922  [   32/  306]
train() client id: f_00004-10-1 loss: 0.569760  [   64/  306]
train() client id: f_00004-10-2 loss: 0.707643  [   96/  306]
train() client id: f_00004-10-3 loss: 0.574054  [  128/  306]
train() client id: f_00004-10-4 loss: 0.783821  [  160/  306]
train() client id: f_00004-10-5 loss: 0.686434  [  192/  306]
train() client id: f_00004-10-6 loss: 0.771708  [  224/  306]
train() client id: f_00004-10-7 loss: 0.765060  [  256/  306]
train() client id: f_00004-10-8 loss: 0.768884  [  288/  306]
train() client id: f_00004-11-0 loss: 0.675806  [   32/  306]
train() client id: f_00004-11-1 loss: 0.581058  [   64/  306]
train() client id: f_00004-11-2 loss: 0.751423  [   96/  306]
train() client id: f_00004-11-3 loss: 0.795704  [  128/  306]
train() client id: f_00004-11-4 loss: 0.768488  [  160/  306]
train() client id: f_00004-11-5 loss: 0.566410  [  192/  306]
train() client id: f_00004-11-6 loss: 0.711683  [  224/  306]
train() client id: f_00004-11-7 loss: 0.721526  [  256/  306]
train() client id: f_00004-11-8 loss: 0.631922  [  288/  306]
train() client id: f_00004-12-0 loss: 0.637066  [   32/  306]
train() client id: f_00004-12-1 loss: 0.706867  [   64/  306]
train() client id: f_00004-12-2 loss: 0.830057  [   96/  306]
train() client id: f_00004-12-3 loss: 0.592238  [  128/  306]
train() client id: f_00004-12-4 loss: 0.661010  [  160/  306]
train() client id: f_00004-12-5 loss: 0.690807  [  192/  306]
train() client id: f_00004-12-6 loss: 0.617801  [  224/  306]
train() client id: f_00004-12-7 loss: 0.699332  [  256/  306]
train() client id: f_00004-12-8 loss: 0.659617  [  288/  306]
train() client id: f_00005-0-0 loss: 0.728948  [   32/  146]
train() client id: f_00005-0-1 loss: 0.559351  [   64/  146]
train() client id: f_00005-0-2 loss: 0.852126  [   96/  146]
train() client id: f_00005-0-3 loss: 0.711656  [  128/  146]
train() client id: f_00005-1-0 loss: 0.935168  [   32/  146]
train() client id: f_00005-1-1 loss: 0.653287  [   64/  146]
train() client id: f_00005-1-2 loss: 0.635683  [   96/  146]
train() client id: f_00005-1-3 loss: 0.578685  [  128/  146]
train() client id: f_00005-2-0 loss: 0.581736  [   32/  146]
train() client id: f_00005-2-1 loss: 0.640225  [   64/  146]
train() client id: f_00005-2-2 loss: 0.573990  [   96/  146]
train() client id: f_00005-2-3 loss: 0.778600  [  128/  146]
train() client id: f_00005-3-0 loss: 0.890827  [   32/  146]
train() client id: f_00005-3-1 loss: 0.524992  [   64/  146]
train() client id: f_00005-3-2 loss: 0.614066  [   96/  146]
train() client id: f_00005-3-3 loss: 0.677383  [  128/  146]
train() client id: f_00005-4-0 loss: 0.759723  [   32/  146]
train() client id: f_00005-4-1 loss: 0.481952  [   64/  146]
train() client id: f_00005-4-2 loss: 0.772684  [   96/  146]
train() client id: f_00005-4-3 loss: 0.589727  [  128/  146]
train() client id: f_00005-5-0 loss: 0.757568  [   32/  146]
train() client id: f_00005-5-1 loss: 0.568012  [   64/  146]
train() client id: f_00005-5-2 loss: 0.507427  [   96/  146]
train() client id: f_00005-5-3 loss: 0.610924  [  128/  146]
train() client id: f_00005-6-0 loss: 0.547198  [   32/  146]
train() client id: f_00005-6-1 loss: 0.612618  [   64/  146]
train() client id: f_00005-6-2 loss: 0.720338  [   96/  146]
train() client id: f_00005-6-3 loss: 0.831488  [  128/  146]
train() client id: f_00005-7-0 loss: 0.640311  [   32/  146]
train() client id: f_00005-7-1 loss: 0.839194  [   64/  146]
train() client id: f_00005-7-2 loss: 0.570164  [   96/  146]
train() client id: f_00005-7-3 loss: 0.521067  [  128/  146]
train() client id: f_00005-8-0 loss: 0.826969  [   32/  146]
train() client id: f_00005-8-1 loss: 0.586721  [   64/  146]
train() client id: f_00005-8-2 loss: 0.495746  [   96/  146]
train() client id: f_00005-8-3 loss: 0.716303  [  128/  146]
train() client id: f_00005-9-0 loss: 0.658535  [   32/  146]
train() client id: f_00005-9-1 loss: 0.660188  [   64/  146]
train() client id: f_00005-9-2 loss: 0.599329  [   96/  146]
train() client id: f_00005-9-3 loss: 0.517146  [  128/  146]
train() client id: f_00005-10-0 loss: 0.434548  [   32/  146]
train() client id: f_00005-10-1 loss: 0.740360  [   64/  146]
train() client id: f_00005-10-2 loss: 0.596273  [   96/  146]
train() client id: f_00005-10-3 loss: 0.644598  [  128/  146]
train() client id: f_00005-11-0 loss: 0.789830  [   32/  146]
train() client id: f_00005-11-1 loss: 0.690117  [   64/  146]
train() client id: f_00005-11-2 loss: 0.704001  [   96/  146]
train() client id: f_00005-11-3 loss: 0.533961  [  128/  146]
train() client id: f_00005-12-0 loss: 0.675587  [   32/  146]
train() client id: f_00005-12-1 loss: 0.674102  [   64/  146]
train() client id: f_00005-12-2 loss: 0.602266  [   96/  146]
train() client id: f_00005-12-3 loss: 0.858459  [  128/  146]
train() client id: f_00006-0-0 loss: 0.411823  [   32/   54]
train() client id: f_00006-1-0 loss: 0.490156  [   32/   54]
train() client id: f_00006-2-0 loss: 0.503144  [   32/   54]
train() client id: f_00006-3-0 loss: 0.449044  [   32/   54]
train() client id: f_00006-4-0 loss: 0.431745  [   32/   54]
train() client id: f_00006-5-0 loss: 0.454986  [   32/   54]
train() client id: f_00006-6-0 loss: 0.483904  [   32/   54]
train() client id: f_00006-7-0 loss: 0.506392  [   32/   54]
train() client id: f_00006-8-0 loss: 0.455130  [   32/   54]
train() client id: f_00006-9-0 loss: 0.430006  [   32/   54]
train() client id: f_00006-10-0 loss: 0.464362  [   32/   54]
train() client id: f_00006-11-0 loss: 0.431929  [   32/   54]
train() client id: f_00006-12-0 loss: 0.489681  [   32/   54]
train() client id: f_00007-0-0 loss: 0.490430  [   32/  179]
train() client id: f_00007-0-1 loss: 0.529197  [   64/  179]
train() client id: f_00007-0-2 loss: 0.837629  [   96/  179]
train() client id: f_00007-0-3 loss: 0.663618  [  128/  179]
train() client id: f_00007-0-4 loss: 0.669304  [  160/  179]
train() client id: f_00007-1-0 loss: 0.542248  [   32/  179]
train() client id: f_00007-1-1 loss: 0.459015  [   64/  179]
train() client id: f_00007-1-2 loss: 0.415169  [   96/  179]
train() client id: f_00007-1-3 loss: 0.761832  [  128/  179]
train() client id: f_00007-1-4 loss: 0.877829  [  160/  179]
train() client id: f_00007-2-0 loss: 0.418765  [   32/  179]
train() client id: f_00007-2-1 loss: 0.509260  [   64/  179]
train() client id: f_00007-2-2 loss: 0.695102  [   96/  179]
train() client id: f_00007-2-3 loss: 0.630447  [  128/  179]
train() client id: f_00007-2-4 loss: 0.621376  [  160/  179]
train() client id: f_00007-3-0 loss: 0.500266  [   32/  179]
train() client id: f_00007-3-1 loss: 0.701049  [   64/  179]
train() client id: f_00007-3-2 loss: 0.642186  [   96/  179]
train() client id: f_00007-3-3 loss: 0.426979  [  128/  179]
train() client id: f_00007-3-4 loss: 0.725614  [  160/  179]
train() client id: f_00007-4-0 loss: 0.736001  [   32/  179]
train() client id: f_00007-4-1 loss: 0.391135  [   64/  179]
train() client id: f_00007-4-2 loss: 0.600800  [   96/  179]
train() client id: f_00007-4-3 loss: 0.536238  [  128/  179]
train() client id: f_00007-4-4 loss: 0.576455  [  160/  179]
train() client id: f_00007-5-0 loss: 0.570009  [   32/  179]
train() client id: f_00007-5-1 loss: 0.525337  [   64/  179]
train() client id: f_00007-5-2 loss: 0.585143  [   96/  179]
train() client id: f_00007-5-3 loss: 0.545856  [  128/  179]
train() client id: f_00007-5-4 loss: 0.724100  [  160/  179]
train() client id: f_00007-6-0 loss: 0.680549  [   32/  179]
train() client id: f_00007-6-1 loss: 0.712484  [   64/  179]
train() client id: f_00007-6-2 loss: 0.601371  [   96/  179]
train() client id: f_00007-6-3 loss: 0.460481  [  128/  179]
train() client id: f_00007-6-4 loss: 0.431147  [  160/  179]
train() client id: f_00007-7-0 loss: 0.562044  [   32/  179]
train() client id: f_00007-7-1 loss: 0.534931  [   64/  179]
train() client id: f_00007-7-2 loss: 0.592881  [   96/  179]
train() client id: f_00007-7-3 loss: 0.600109  [  128/  179]
train() client id: f_00007-7-4 loss: 0.398407  [  160/  179]
train() client id: f_00007-8-0 loss: 0.620934  [   32/  179]
train() client id: f_00007-8-1 loss: 0.619740  [   64/  179]
train() client id: f_00007-8-2 loss: 0.568325  [   96/  179]
train() client id: f_00007-8-3 loss: 0.393889  [  128/  179]
train() client id: f_00007-8-4 loss: 0.721588  [  160/  179]
train() client id: f_00007-9-0 loss: 0.654923  [   32/  179]
train() client id: f_00007-9-1 loss: 0.526134  [   64/  179]
train() client id: f_00007-9-2 loss: 0.588469  [   96/  179]
train() client id: f_00007-9-3 loss: 0.558042  [  128/  179]
train() client id: f_00007-9-4 loss: 0.545573  [  160/  179]
train() client id: f_00007-10-0 loss: 0.610962  [   32/  179]
train() client id: f_00007-10-1 loss: 0.611607  [   64/  179]
train() client id: f_00007-10-2 loss: 0.704706  [   96/  179]
train() client id: f_00007-10-3 loss: 0.489735  [  128/  179]
train() client id: f_00007-10-4 loss: 0.474745  [  160/  179]
train() client id: f_00007-11-0 loss: 0.516379  [   32/  179]
train() client id: f_00007-11-1 loss: 0.724588  [   64/  179]
train() client id: f_00007-11-2 loss: 0.440257  [   96/  179]
train() client id: f_00007-11-3 loss: 0.691036  [  128/  179]
train() client id: f_00007-11-4 loss: 0.506903  [  160/  179]
train() client id: f_00007-12-0 loss: 0.630643  [   32/  179]
train() client id: f_00007-12-1 loss: 0.674263  [   64/  179]
train() client id: f_00007-12-2 loss: 0.518348  [   96/  179]
train() client id: f_00007-12-3 loss: 0.596783  [  128/  179]
train() client id: f_00007-12-4 loss: 0.499073  [  160/  179]
train() client id: f_00008-0-0 loss: 0.760101  [   32/  130]
train() client id: f_00008-0-1 loss: 0.892523  [   64/  130]
train() client id: f_00008-0-2 loss: 0.839851  [   96/  130]
train() client id: f_00008-0-3 loss: 0.763395  [  128/  130]
train() client id: f_00008-1-0 loss: 0.842702  [   32/  130]
train() client id: f_00008-1-1 loss: 0.838032  [   64/  130]
train() client id: f_00008-1-2 loss: 0.822885  [   96/  130]
train() client id: f_00008-1-3 loss: 0.747906  [  128/  130]
train() client id: f_00008-2-0 loss: 0.862232  [   32/  130]
train() client id: f_00008-2-1 loss: 0.803469  [   64/  130]
train() client id: f_00008-2-2 loss: 0.809237  [   96/  130]
train() client id: f_00008-2-3 loss: 0.775544  [  128/  130]
train() client id: f_00008-3-0 loss: 0.836599  [   32/  130]
train() client id: f_00008-3-1 loss: 0.746748  [   64/  130]
train() client id: f_00008-3-2 loss: 0.769991  [   96/  130]
train() client id: f_00008-3-3 loss: 0.878667  [  128/  130]
train() client id: f_00008-4-0 loss: 0.890240  [   32/  130]
train() client id: f_00008-4-1 loss: 0.686506  [   64/  130]
train() client id: f_00008-4-2 loss: 0.836638  [   96/  130]
train() client id: f_00008-4-3 loss: 0.807525  [  128/  130]
train() client id: f_00008-5-0 loss: 0.687480  [   32/  130]
train() client id: f_00008-5-1 loss: 0.850209  [   64/  130]
train() client id: f_00008-5-2 loss: 0.662129  [   96/  130]
train() client id: f_00008-5-3 loss: 1.038386  [  128/  130]
train() client id: f_00008-6-0 loss: 0.861147  [   32/  130]
train() client id: f_00008-6-1 loss: 0.815045  [   64/  130]
train() client id: f_00008-6-2 loss: 0.847631  [   96/  130]
train() client id: f_00008-6-3 loss: 0.676173  [  128/  130]
train() client id: f_00008-7-0 loss: 0.835074  [   32/  130]
train() client id: f_00008-7-1 loss: 0.751632  [   64/  130]
train() client id: f_00008-7-2 loss: 0.830280  [   96/  130]
train() client id: f_00008-7-3 loss: 0.806770  [  128/  130]
train() client id: f_00008-8-0 loss: 0.861242  [   32/  130]
train() client id: f_00008-8-1 loss: 0.691744  [   64/  130]
train() client id: f_00008-8-2 loss: 0.805787  [   96/  130]
train() client id: f_00008-8-3 loss: 0.865900  [  128/  130]
train() client id: f_00008-9-0 loss: 0.715500  [   32/  130]
train() client id: f_00008-9-1 loss: 0.783094  [   64/  130]
train() client id: f_00008-9-2 loss: 0.944061  [   96/  130]
train() client id: f_00008-9-3 loss: 0.780512  [  128/  130]
train() client id: f_00008-10-0 loss: 0.804206  [   32/  130]
train() client id: f_00008-10-1 loss: 0.776634  [   64/  130]
train() client id: f_00008-10-2 loss: 0.770031  [   96/  130]
train() client id: f_00008-10-3 loss: 0.822988  [  128/  130]
train() client id: f_00008-11-0 loss: 0.833442  [   32/  130]
train() client id: f_00008-11-1 loss: 0.701786  [   64/  130]
train() client id: f_00008-11-2 loss: 0.746080  [   96/  130]
train() client id: f_00008-11-3 loss: 0.927650  [  128/  130]
train() client id: f_00008-12-0 loss: 0.842355  [   32/  130]
train() client id: f_00008-12-1 loss: 0.796624  [   64/  130]
train() client id: f_00008-12-2 loss: 0.756020  [   96/  130]
train() client id: f_00008-12-3 loss: 0.761294  [  128/  130]
train() client id: f_00009-0-0 loss: 1.351974  [   32/  118]
train() client id: f_00009-0-1 loss: 1.147575  [   64/  118]
train() client id: f_00009-0-2 loss: 1.058985  [   96/  118]
train() client id: f_00009-1-0 loss: 1.066499  [   32/  118]
train() client id: f_00009-1-1 loss: 1.242190  [   64/  118]
train() client id: f_00009-1-2 loss: 0.943860  [   96/  118]
train() client id: f_00009-2-0 loss: 1.221068  [   32/  118]
train() client id: f_00009-2-1 loss: 1.039201  [   64/  118]
train() client id: f_00009-2-2 loss: 1.023844  [   96/  118]
train() client id: f_00009-3-0 loss: 1.157646  [   32/  118]
train() client id: f_00009-3-1 loss: 0.995395  [   64/  118]
train() client id: f_00009-3-2 loss: 0.957977  [   96/  118]
train() client id: f_00009-4-0 loss: 0.971329  [   32/  118]
train() client id: f_00009-4-1 loss: 0.962001  [   64/  118]
train() client id: f_00009-4-2 loss: 1.090947  [   96/  118]
train() client id: f_00009-5-0 loss: 1.053469  [   32/  118]
train() client id: f_00009-5-1 loss: 0.913513  [   64/  118]
train() client id: f_00009-5-2 loss: 0.987311  [   96/  118]
train() client id: f_00009-6-0 loss: 1.030337  [   32/  118]
train() client id: f_00009-6-1 loss: 0.867119  [   64/  118]
train() client id: f_00009-6-2 loss: 0.872232  [   96/  118]
train() client id: f_00009-7-0 loss: 0.832178  [   32/  118]
train() client id: f_00009-7-1 loss: 0.907367  [   64/  118]
train() client id: f_00009-7-2 loss: 1.070472  [   96/  118]
train() client id: f_00009-8-0 loss: 0.832690  [   32/  118]
train() client id: f_00009-8-1 loss: 0.881565  [   64/  118]
train() client id: f_00009-8-2 loss: 0.975300  [   96/  118]
train() client id: f_00009-9-0 loss: 0.876900  [   32/  118]
train() client id: f_00009-9-1 loss: 0.843175  [   64/  118]
train() client id: f_00009-9-2 loss: 1.030296  [   96/  118]
train() client id: f_00009-10-0 loss: 0.824431  [   32/  118]
train() client id: f_00009-10-1 loss: 0.820150  [   64/  118]
train() client id: f_00009-10-2 loss: 0.944134  [   96/  118]
train() client id: f_00009-11-0 loss: 0.906742  [   32/  118]
train() client id: f_00009-11-1 loss: 0.791242  [   64/  118]
train() client id: f_00009-11-2 loss: 1.050625  [   96/  118]
train() client id: f_00009-12-0 loss: 0.963678  [   32/  118]
train() client id: f_00009-12-1 loss: 0.814395  [   64/  118]
train() client id: f_00009-12-2 loss: 0.964985  [   96/  118]
At round 63 accuracy: 0.6392572944297082
At round 63 training accuracy: 0.5881958417169685
At round 63 training loss: 0.8243156088504041
gradient difference: 0.4134882986545563
train() client id: f_00000-0-0 loss: 1.247622  [   32/  126]
train() client id: f_00000-0-1 loss: 1.343786  [   64/  126]
train() client id: f_00000-0-2 loss: 0.948947  [   96/  126]
train() client id: f_00000-1-0 loss: 1.094762  [   32/  126]
train() client id: f_00000-1-1 loss: 1.141688  [   64/  126]
train() client id: f_00000-1-2 loss: 0.995578  [   96/  126]
train() client id: f_00000-2-0 loss: 0.993128  [   32/  126]
train() client id: f_00000-2-1 loss: 1.164524  [   64/  126]
train() client id: f_00000-2-2 loss: 0.926647  [   96/  126]
train() client id: f_00000-3-0 loss: 0.957244  [   32/  126]
train() client id: f_00000-3-1 loss: 0.945435  [   64/  126]
train() client id: f_00000-3-2 loss: 1.143114  [   96/  126]
train() client id: f_00000-4-0 loss: 0.941935  [   32/  126]
train() client id: f_00000-4-1 loss: 0.917941  [   64/  126]
train() client id: f_00000-4-2 loss: 0.999045  [   96/  126]
train() client id: f_00000-5-0 loss: 0.839832  [   32/  126]
train() client id: f_00000-5-1 loss: 0.988475  [   64/  126]
train() client id: f_00000-5-2 loss: 0.901759  [   96/  126]
train() client id: f_00000-6-0 loss: 0.935027  [   32/  126]
train() client id: f_00000-6-1 loss: 0.928413  [   64/  126]
train() client id: f_00000-6-2 loss: 0.874347  [   96/  126]
train() client id: f_00000-7-0 loss: 0.992078  [   32/  126]
train() client id: f_00000-7-1 loss: 0.793727  [   64/  126]
train() client id: f_00000-7-2 loss: 0.836189  [   96/  126]
train() client id: f_00000-8-0 loss: 0.889622  [   32/  126]
train() client id: f_00000-8-1 loss: 0.995573  [   64/  126]
train() client id: f_00000-8-2 loss: 0.889222  [   96/  126]
train() client id: f_00000-9-0 loss: 0.872914  [   32/  126]
train() client id: f_00000-9-1 loss: 1.007803  [   64/  126]
train() client id: f_00000-9-2 loss: 0.802887  [   96/  126]
train() client id: f_00000-10-0 loss: 0.912663  [   32/  126]
train() client id: f_00000-10-1 loss: 0.809567  [   64/  126]
train() client id: f_00000-10-2 loss: 0.813916  [   96/  126]
train() client id: f_00000-11-0 loss: 0.893484  [   32/  126]
train() client id: f_00000-11-1 loss: 0.926750  [   64/  126]
train() client id: f_00000-11-2 loss: 0.874159  [   96/  126]
train() client id: f_00000-12-0 loss: 0.922757  [   32/  126]
train() client id: f_00000-12-1 loss: 0.794652  [   64/  126]
train() client id: f_00000-12-2 loss: 0.892820  [   96/  126]
train() client id: f_00001-0-0 loss: 0.441288  [   32/  265]
train() client id: f_00001-0-1 loss: 0.548424  [   64/  265]
train() client id: f_00001-0-2 loss: 0.429068  [   96/  265]
train() client id: f_00001-0-3 loss: 0.493518  [  128/  265]
train() client id: f_00001-0-4 loss: 0.486818  [  160/  265]
train() client id: f_00001-0-5 loss: 0.402311  [  192/  265]
train() client id: f_00001-0-6 loss: 0.498851  [  224/  265]
train() client id: f_00001-0-7 loss: 0.390020  [  256/  265]
train() client id: f_00001-1-0 loss: 0.423891  [   32/  265]
train() client id: f_00001-1-1 loss: 0.490162  [   64/  265]
train() client id: f_00001-1-2 loss: 0.545590  [   96/  265]
train() client id: f_00001-1-3 loss: 0.474102  [  128/  265]
train() client id: f_00001-1-4 loss: 0.590211  [  160/  265]
train() client id: f_00001-1-5 loss: 0.341604  [  192/  265]
train() client id: f_00001-1-6 loss: 0.362525  [  224/  265]
train() client id: f_00001-1-7 loss: 0.426880  [  256/  265]
train() client id: f_00001-2-0 loss: 0.366663  [   32/  265]
train() client id: f_00001-2-1 loss: 0.429580  [   64/  265]
train() client id: f_00001-2-2 loss: 0.545758  [   96/  265]
train() client id: f_00001-2-3 loss: 0.506935  [  128/  265]
train() client id: f_00001-2-4 loss: 0.584587  [  160/  265]
train() client id: f_00001-2-5 loss: 0.326741  [  192/  265]
train() client id: f_00001-2-6 loss: 0.424312  [  224/  265]
train() client id: f_00001-2-7 loss: 0.353542  [  256/  265]
train() client id: f_00001-3-0 loss: 0.369958  [   32/  265]
train() client id: f_00001-3-1 loss: 0.425077  [   64/  265]
train() client id: f_00001-3-2 loss: 0.516217  [   96/  265]
train() client id: f_00001-3-3 loss: 0.504243  [  128/  265]
train() client id: f_00001-3-4 loss: 0.420420  [  160/  265]
train() client id: f_00001-3-5 loss: 0.457932  [  192/  265]
train() client id: f_00001-3-6 loss: 0.419383  [  224/  265]
train() client id: f_00001-3-7 loss: 0.399765  [  256/  265]
train() client id: f_00001-4-0 loss: 0.446983  [   32/  265]
train() client id: f_00001-4-1 loss: 0.380895  [   64/  265]
train() client id: f_00001-4-2 loss: 0.543483  [   96/  265]
train() client id: f_00001-4-3 loss: 0.385788  [  128/  265]
train() client id: f_00001-4-4 loss: 0.459305  [  160/  265]
train() client id: f_00001-4-5 loss: 0.419761  [  192/  265]
train() client id: f_00001-4-6 loss: 0.447425  [  224/  265]
train() client id: f_00001-4-7 loss: 0.448413  [  256/  265]
train() client id: f_00001-5-0 loss: 0.433975  [   32/  265]
train() client id: f_00001-5-1 loss: 0.412693  [   64/  265]
train() client id: f_00001-5-2 loss: 0.516184  [   96/  265]
train() client id: f_00001-5-3 loss: 0.511829  [  128/  265]
train() client id: f_00001-5-4 loss: 0.394672  [  160/  265]
train() client id: f_00001-5-5 loss: 0.476830  [  192/  265]
train() client id: f_00001-5-6 loss: 0.355544  [  224/  265]
train() client id: f_00001-5-7 loss: 0.409069  [  256/  265]
train() client id: f_00001-6-0 loss: 0.466853  [   32/  265]
train() client id: f_00001-6-1 loss: 0.406094  [   64/  265]
train() client id: f_00001-6-2 loss: 0.514880  [   96/  265]
train() client id: f_00001-6-3 loss: 0.425782  [  128/  265]
train() client id: f_00001-6-4 loss: 0.354570  [  160/  265]
train() client id: f_00001-6-5 loss: 0.336230  [  192/  265]
train() client id: f_00001-6-6 loss: 0.555887  [  224/  265]
train() client id: f_00001-6-7 loss: 0.426421  [  256/  265]
train() client id: f_00001-7-0 loss: 0.527893  [   32/  265]
train() client id: f_00001-7-1 loss: 0.331361  [   64/  265]
train() client id: f_00001-7-2 loss: 0.461067  [   96/  265]
train() client id: f_00001-7-3 loss: 0.385070  [  128/  265]
train() client id: f_00001-7-4 loss: 0.378666  [  160/  265]
train() client id: f_00001-7-5 loss: 0.604116  [  192/  265]
train() client id: f_00001-7-6 loss: 0.392408  [  224/  265]
train() client id: f_00001-7-7 loss: 0.397501  [  256/  265]
train() client id: f_00001-8-0 loss: 0.350632  [   32/  265]
train() client id: f_00001-8-1 loss: 0.403736  [   64/  265]
train() client id: f_00001-8-2 loss: 0.433368  [   96/  265]
train() client id: f_00001-8-3 loss: 0.377770  [  128/  265]
train() client id: f_00001-8-4 loss: 0.326074  [  160/  265]
train() client id: f_00001-8-5 loss: 0.470745  [  192/  265]
train() client id: f_00001-8-6 loss: 0.470226  [  224/  265]
train() client id: f_00001-8-7 loss: 0.547662  [  256/  265]
train() client id: f_00001-9-0 loss: 0.515311  [   32/  265]
train() client id: f_00001-9-1 loss: 0.352278  [   64/  265]
train() client id: f_00001-9-2 loss: 0.354057  [   96/  265]
train() client id: f_00001-9-3 loss: 0.328083  [  128/  265]
train() client id: f_00001-9-4 loss: 0.322624  [  160/  265]
train() client id: f_00001-9-5 loss: 0.491533  [  192/  265]
train() client id: f_00001-9-6 loss: 0.350822  [  224/  265]
train() client id: f_00001-9-7 loss: 0.658800  [  256/  265]
train() client id: f_00001-10-0 loss: 0.476794  [   32/  265]
train() client id: f_00001-10-1 loss: 0.397939  [   64/  265]
train() client id: f_00001-10-2 loss: 0.723487  [   96/  265]
train() client id: f_00001-10-3 loss: 0.405322  [  128/  265]
train() client id: f_00001-10-4 loss: 0.374043  [  160/  265]
train() client id: f_00001-10-5 loss: 0.401908  [  192/  265]
train() client id: f_00001-10-6 loss: 0.311998  [  224/  265]
train() client id: f_00001-10-7 loss: 0.361083  [  256/  265]
train() client id: f_00001-11-0 loss: 0.329920  [   32/  265]
train() client id: f_00001-11-1 loss: 0.471236  [   64/  265]
train() client id: f_00001-11-2 loss: 0.472779  [   96/  265]
train() client id: f_00001-11-3 loss: 0.511412  [  128/  265]
train() client id: f_00001-11-4 loss: 0.439138  [  160/  265]
train() client id: f_00001-11-5 loss: 0.497794  [  192/  265]
train() client id: f_00001-11-6 loss: 0.323322  [  224/  265]
train() client id: f_00001-11-7 loss: 0.405423  [  256/  265]
train() client id: f_00001-12-0 loss: 0.320754  [   32/  265]
train() client id: f_00001-12-1 loss: 0.434135  [   64/  265]
train() client id: f_00001-12-2 loss: 0.365702  [   96/  265]
train() client id: f_00001-12-3 loss: 0.473288  [  128/  265]
train() client id: f_00001-12-4 loss: 0.432264  [  160/  265]
train() client id: f_00001-12-5 loss: 0.364220  [  192/  265]
train() client id: f_00001-12-6 loss: 0.549298  [  224/  265]
train() client id: f_00001-12-7 loss: 0.508664  [  256/  265]
train() client id: f_00002-0-0 loss: 1.329582  [   32/  124]
train() client id: f_00002-0-1 loss: 1.106628  [   64/  124]
train() client id: f_00002-0-2 loss: 1.139488  [   96/  124]
train() client id: f_00002-1-0 loss: 1.261441  [   32/  124]
train() client id: f_00002-1-1 loss: 1.118843  [   64/  124]
train() client id: f_00002-1-2 loss: 1.039692  [   96/  124]
train() client id: f_00002-2-0 loss: 0.962238  [   32/  124]
train() client id: f_00002-2-1 loss: 1.058327  [   64/  124]
train() client id: f_00002-2-2 loss: 1.067063  [   96/  124]
train() client id: f_00002-3-0 loss: 1.160097  [   32/  124]
train() client id: f_00002-3-1 loss: 1.292940  [   64/  124]
train() client id: f_00002-3-2 loss: 0.856470  [   96/  124]
train() client id: f_00002-4-0 loss: 1.278885  [   32/  124]
train() client id: f_00002-4-1 loss: 0.967763  [   64/  124]
train() client id: f_00002-4-2 loss: 0.919242  [   96/  124]
train() client id: f_00002-5-0 loss: 0.942583  [   32/  124]
train() client id: f_00002-5-1 loss: 1.085146  [   64/  124]
train() client id: f_00002-5-2 loss: 0.876843  [   96/  124]
train() client id: f_00002-6-0 loss: 1.043100  [   32/  124]
train() client id: f_00002-6-1 loss: 1.078382  [   64/  124]
train() client id: f_00002-6-2 loss: 0.986266  [   96/  124]
train() client id: f_00002-7-0 loss: 1.129944  [   32/  124]
train() client id: f_00002-7-1 loss: 0.896299  [   64/  124]
train() client id: f_00002-7-2 loss: 0.815027  [   96/  124]
train() client id: f_00002-8-0 loss: 0.852898  [   32/  124]
train() client id: f_00002-8-1 loss: 0.952061  [   64/  124]
train() client id: f_00002-8-2 loss: 0.978629  [   96/  124]
train() client id: f_00002-9-0 loss: 1.047809  [   32/  124]
train() client id: f_00002-9-1 loss: 1.009248  [   64/  124]
train() client id: f_00002-9-2 loss: 0.896686  [   96/  124]
train() client id: f_00002-10-0 loss: 1.089535  [   32/  124]
train() client id: f_00002-10-1 loss: 0.784119  [   64/  124]
train() client id: f_00002-10-2 loss: 0.984416  [   96/  124]
train() client id: f_00002-11-0 loss: 1.041009  [   32/  124]
train() client id: f_00002-11-1 loss: 1.027773  [   64/  124]
train() client id: f_00002-11-2 loss: 0.895896  [   96/  124]
train() client id: f_00002-12-0 loss: 0.850862  [   32/  124]
train() client id: f_00002-12-1 loss: 0.763372  [   64/  124]
train() client id: f_00002-12-2 loss: 1.292310  [   96/  124]
train() client id: f_00003-0-0 loss: 0.709512  [   32/   43]
train() client id: f_00003-1-0 loss: 0.552928  [   32/   43]
train() client id: f_00003-2-0 loss: 0.684252  [   32/   43]
train() client id: f_00003-3-0 loss: 0.575740  [   32/   43]
train() client id: f_00003-4-0 loss: 0.472887  [   32/   43]
train() client id: f_00003-5-0 loss: 0.776521  [   32/   43]
train() client id: f_00003-6-0 loss: 0.654635  [   32/   43]
train() client id: f_00003-7-0 loss: 0.704900  [   32/   43]
train() client id: f_00003-8-0 loss: 0.520597  [   32/   43]
train() client id: f_00003-9-0 loss: 0.626543  [   32/   43]
train() client id: f_00003-10-0 loss: 0.505007  [   32/   43]
train() client id: f_00003-11-0 loss: 0.597054  [   32/   43]
train() client id: f_00003-12-0 loss: 0.789820  [   32/   43]
train() client id: f_00004-0-0 loss: 0.852894  [   32/  306]
train() client id: f_00004-0-1 loss: 0.887811  [   64/  306]
train() client id: f_00004-0-2 loss: 0.924234  [   96/  306]
train() client id: f_00004-0-3 loss: 0.714273  [  128/  306]
train() client id: f_00004-0-4 loss: 0.860654  [  160/  306]
train() client id: f_00004-0-5 loss: 0.906557  [  192/  306]
train() client id: f_00004-0-6 loss: 0.762156  [  224/  306]
train() client id: f_00004-0-7 loss: 0.805847  [  256/  306]
train() client id: f_00004-0-8 loss: 0.907729  [  288/  306]
train() client id: f_00004-1-0 loss: 0.853834  [   32/  306]
train() client id: f_00004-1-1 loss: 0.895386  [   64/  306]
train() client id: f_00004-1-2 loss: 0.793662  [   96/  306]
train() client id: f_00004-1-3 loss: 0.825384  [  128/  306]
train() client id: f_00004-1-4 loss: 0.819523  [  160/  306]
train() client id: f_00004-1-5 loss: 0.935046  [  192/  306]
train() client id: f_00004-1-6 loss: 0.976474  [  224/  306]
train() client id: f_00004-1-7 loss: 0.665781  [  256/  306]
train() client id: f_00004-1-8 loss: 0.846074  [  288/  306]
train() client id: f_00004-2-0 loss: 0.706603  [   32/  306]
train() client id: f_00004-2-1 loss: 0.793213  [   64/  306]
train() client id: f_00004-2-2 loss: 0.766826  [   96/  306]
train() client id: f_00004-2-3 loss: 0.870397  [  128/  306]
train() client id: f_00004-2-4 loss: 0.857143  [  160/  306]
train() client id: f_00004-2-5 loss: 0.999777  [  192/  306]
train() client id: f_00004-2-6 loss: 0.749194  [  224/  306]
train() client id: f_00004-2-7 loss: 0.954359  [  256/  306]
train() client id: f_00004-2-8 loss: 0.815000  [  288/  306]
train() client id: f_00004-3-0 loss: 0.862372  [   32/  306]
train() client id: f_00004-3-1 loss: 0.845359  [   64/  306]
train() client id: f_00004-3-2 loss: 0.895618  [   96/  306]
train() client id: f_00004-3-3 loss: 0.799719  [  128/  306]
train() client id: f_00004-3-4 loss: 0.813474  [  160/  306]
train() client id: f_00004-3-5 loss: 0.909332  [  192/  306]
train() client id: f_00004-3-6 loss: 0.872859  [  224/  306]
train() client id: f_00004-3-7 loss: 0.928821  [  256/  306]
train() client id: f_00004-3-8 loss: 0.764875  [  288/  306]
train() client id: f_00004-4-0 loss: 0.933718  [   32/  306]
train() client id: f_00004-4-1 loss: 0.869940  [   64/  306]
train() client id: f_00004-4-2 loss: 0.956347  [   96/  306]
train() client id: f_00004-4-3 loss: 0.728214  [  128/  306]
train() client id: f_00004-4-4 loss: 0.802990  [  160/  306]
train() client id: f_00004-4-5 loss: 0.782500  [  192/  306]
train() client id: f_00004-4-6 loss: 0.928557  [  224/  306]
train() client id: f_00004-4-7 loss: 0.877987  [  256/  306]
train() client id: f_00004-4-8 loss: 0.768935  [  288/  306]
train() client id: f_00004-5-0 loss: 0.861156  [   32/  306]
train() client id: f_00004-5-1 loss: 0.806719  [   64/  306]
train() client id: f_00004-5-2 loss: 0.963523  [   96/  306]
train() client id: f_00004-5-3 loss: 0.810184  [  128/  306]
train() client id: f_00004-5-4 loss: 0.791849  [  160/  306]
train() client id: f_00004-5-5 loss: 0.947456  [  192/  306]
train() client id: f_00004-5-6 loss: 0.816912  [  224/  306]
train() client id: f_00004-5-7 loss: 0.875006  [  256/  306]
train() client id: f_00004-5-8 loss: 0.853800  [  288/  306]
train() client id: f_00004-6-0 loss: 0.749976  [   32/  306]
train() client id: f_00004-6-1 loss: 0.921687  [   64/  306]
train() client id: f_00004-6-2 loss: 0.825141  [   96/  306]
train() client id: f_00004-6-3 loss: 0.814981  [  128/  306]
train() client id: f_00004-6-4 loss: 0.792286  [  160/  306]
train() client id: f_00004-6-5 loss: 0.941102  [  192/  306]
train() client id: f_00004-6-6 loss: 0.846092  [  224/  306]
train() client id: f_00004-6-7 loss: 0.872849  [  256/  306]
train() client id: f_00004-6-8 loss: 0.876438  [  288/  306]
train() client id: f_00004-7-0 loss: 0.719830  [   32/  306]
train() client id: f_00004-7-1 loss: 0.935566  [   64/  306]
train() client id: f_00004-7-2 loss: 0.835733  [   96/  306]
train() client id: f_00004-7-3 loss: 0.769198  [  128/  306]
train() client id: f_00004-7-4 loss: 0.738254  [  160/  306]
train() client id: f_00004-7-5 loss: 0.845833  [  192/  306]
train() client id: f_00004-7-6 loss: 0.958999  [  224/  306]
train() client id: f_00004-7-7 loss: 1.009032  [  256/  306]
train() client id: f_00004-7-8 loss: 0.790088  [  288/  306]
train() client id: f_00004-8-0 loss: 0.838804  [   32/  306]
train() client id: f_00004-8-1 loss: 0.950958  [   64/  306]
train() client id: f_00004-8-2 loss: 0.853643  [   96/  306]
train() client id: f_00004-8-3 loss: 0.853004  [  128/  306]
train() client id: f_00004-8-4 loss: 0.871371  [  160/  306]
train() client id: f_00004-8-5 loss: 0.774189  [  192/  306]
train() client id: f_00004-8-6 loss: 0.961677  [  224/  306]
train() client id: f_00004-8-7 loss: 0.826250  [  256/  306]
train() client id: f_00004-8-8 loss: 0.842221  [  288/  306]
train() client id: f_00004-9-0 loss: 0.741651  [   32/  306]
train() client id: f_00004-9-1 loss: 0.920074  [   64/  306]
train() client id: f_00004-9-2 loss: 0.794950  [   96/  306]
train() client id: f_00004-9-3 loss: 0.888167  [  128/  306]
train() client id: f_00004-9-4 loss: 0.871325  [  160/  306]
train() client id: f_00004-9-5 loss: 0.717447  [  192/  306]
train() client id: f_00004-9-6 loss: 0.872854  [  224/  306]
train() client id: f_00004-9-7 loss: 0.895323  [  256/  306]
train() client id: f_00004-9-8 loss: 0.961348  [  288/  306]
train() client id: f_00004-10-0 loss: 1.007841  [   32/  306]
train() client id: f_00004-10-1 loss: 0.825289  [   64/  306]
train() client id: f_00004-10-2 loss: 0.738814  [   96/  306]
train() client id: f_00004-10-3 loss: 0.771031  [  128/  306]
train() client id: f_00004-10-4 loss: 0.957164  [  160/  306]
train() client id: f_00004-10-5 loss: 1.024578  [  192/  306]
train() client id: f_00004-10-6 loss: 0.942515  [  224/  306]
train() client id: f_00004-10-7 loss: 0.752513  [  256/  306]
train() client id: f_00004-10-8 loss: 0.768230  [  288/  306]
train() client id: f_00004-11-0 loss: 0.863101  [   32/  306]
train() client id: f_00004-11-1 loss: 0.896879  [   64/  306]
train() client id: f_00004-11-2 loss: 0.835827  [   96/  306]
train() client id: f_00004-11-3 loss: 0.888455  [  128/  306]
train() client id: f_00004-11-4 loss: 0.957578  [  160/  306]
train() client id: f_00004-11-5 loss: 0.855296  [  192/  306]
train() client id: f_00004-11-6 loss: 0.714045  [  224/  306]
train() client id: f_00004-11-7 loss: 0.824710  [  256/  306]
train() client id: f_00004-11-8 loss: 0.773841  [  288/  306]
train() client id: f_00004-12-0 loss: 0.752518  [   32/  306]
train() client id: f_00004-12-1 loss: 0.990740  [   64/  306]
train() client id: f_00004-12-2 loss: 0.777664  [   96/  306]
train() client id: f_00004-12-3 loss: 0.742739  [  128/  306]
train() client id: f_00004-12-4 loss: 0.834542  [  160/  306]
train() client id: f_00004-12-5 loss: 0.908900  [  192/  306]
train() client id: f_00004-12-6 loss: 0.878874  [  224/  306]
train() client id: f_00004-12-7 loss: 0.919679  [  256/  306]
train() client id: f_00004-12-8 loss: 0.916017  [  288/  306]
train() client id: f_00005-0-0 loss: 0.461471  [   32/  146]
train() client id: f_00005-0-1 loss: 0.499585  [   64/  146]
train() client id: f_00005-0-2 loss: 0.278852  [   96/  146]
train() client id: f_00005-0-3 loss: 0.546948  [  128/  146]
train() client id: f_00005-1-0 loss: 0.467782  [   32/  146]
train() client id: f_00005-1-1 loss: 0.540968  [   64/  146]
train() client id: f_00005-1-2 loss: 0.481536  [   96/  146]
train() client id: f_00005-1-3 loss: 0.132375  [  128/  146]
train() client id: f_00005-2-0 loss: 0.261539  [   32/  146]
train() client id: f_00005-2-1 loss: 0.442037  [   64/  146]
train() client id: f_00005-2-2 loss: 0.447828  [   96/  146]
train() client id: f_00005-2-3 loss: 0.488437  [  128/  146]
train() client id: f_00005-3-0 loss: 0.498508  [   32/  146]
train() client id: f_00005-3-1 loss: 0.366365  [   64/  146]
train() client id: f_00005-3-2 loss: 0.445310  [   96/  146]
train() client id: f_00005-3-3 loss: 0.271847  [  128/  146]
train() client id: f_00005-4-0 loss: 0.399306  [   32/  146]
train() client id: f_00005-4-1 loss: 0.368211  [   64/  146]
train() client id: f_00005-4-2 loss: 0.481125  [   96/  146]
train() client id: f_00005-4-3 loss: 0.242725  [  128/  146]
train() client id: f_00005-5-0 loss: 0.528784  [   32/  146]
train() client id: f_00005-5-1 loss: 0.410480  [   64/  146]
train() client id: f_00005-5-2 loss: 0.328855  [   96/  146]
train() client id: f_00005-5-3 loss: 0.386128  [  128/  146]
train() client id: f_00005-6-0 loss: 0.365810  [   32/  146]
train() client id: f_00005-6-1 loss: 0.544119  [   64/  146]
train() client id: f_00005-6-2 loss: 0.432160  [   96/  146]
train() client id: f_00005-6-3 loss: 0.276953  [  128/  146]
train() client id: f_00005-7-0 loss: 0.242473  [   32/  146]
train() client id: f_00005-7-1 loss: 0.386455  [   64/  146]
train() client id: f_00005-7-2 loss: 0.500400  [   96/  146]
train() client id: f_00005-7-3 loss: 0.516475  [  128/  146]
train() client id: f_00005-8-0 loss: 0.293600  [   32/  146]
train() client id: f_00005-8-1 loss: 0.446315  [   64/  146]
train() client id: f_00005-8-2 loss: 0.616838  [   96/  146]
train() client id: f_00005-8-3 loss: 0.266776  [  128/  146]
train() client id: f_00005-9-0 loss: 0.333968  [   32/  146]
train() client id: f_00005-9-1 loss: 0.392970  [   64/  146]
train() client id: f_00005-9-2 loss: 0.587539  [   96/  146]
train() client id: f_00005-9-3 loss: 0.341886  [  128/  146]
train() client id: f_00005-10-0 loss: 0.550320  [   32/  146]
train() client id: f_00005-10-1 loss: 0.264159  [   64/  146]
train() client id: f_00005-10-2 loss: 0.485603  [   96/  146]
train() client id: f_00005-10-3 loss: 0.122698  [  128/  146]
train() client id: f_00005-11-0 loss: 0.344793  [   32/  146]
train() client id: f_00005-11-1 loss: 0.374697  [   64/  146]
train() client id: f_00005-11-2 loss: 0.546089  [   96/  146]
train() client id: f_00005-11-3 loss: 0.322824  [  128/  146]
train() client id: f_00005-12-0 loss: 0.262115  [   32/  146]
train() client id: f_00005-12-1 loss: 0.319235  [   64/  146]
train() client id: f_00005-12-2 loss: 0.407787  [   96/  146]
train() client id: f_00005-12-3 loss: 0.671321  [  128/  146]
train() client id: f_00006-0-0 loss: 0.426284  [   32/   54]
train() client id: f_00006-1-0 loss: 0.434284  [   32/   54]
train() client id: f_00006-2-0 loss: 0.373836  [   32/   54]
train() client id: f_00006-3-0 loss: 0.475666  [   32/   54]
train() client id: f_00006-4-0 loss: 0.489936  [   32/   54]
train() client id: f_00006-5-0 loss: 0.459208  [   32/   54]
train() client id: f_00006-6-0 loss: 0.403633  [   32/   54]
train() client id: f_00006-7-0 loss: 0.444874  [   32/   54]
train() client id: f_00006-8-0 loss: 0.486542  [   32/   54]
train() client id: f_00006-9-0 loss: 0.425120  [   32/   54]
train() client id: f_00006-10-0 loss: 0.498651  [   32/   54]
train() client id: f_00006-11-0 loss: 0.446670  [   32/   54]
train() client id: f_00006-12-0 loss: 0.488534  [   32/   54]
train() client id: f_00007-0-0 loss: 0.693834  [   32/  179]
train() client id: f_00007-0-1 loss: 0.572017  [   64/  179]
train() client id: f_00007-0-2 loss: 0.534472  [   96/  179]
train() client id: f_00007-0-3 loss: 0.690819  [  128/  179]
train() client id: f_00007-0-4 loss: 0.546528  [  160/  179]
train() client id: f_00007-1-0 loss: 0.512662  [   32/  179]
train() client id: f_00007-1-1 loss: 0.617412  [   64/  179]
train() client id: f_00007-1-2 loss: 0.738290  [   96/  179]
train() client id: f_00007-1-3 loss: 0.593319  [  128/  179]
train() client id: f_00007-1-4 loss: 0.629602  [  160/  179]
train() client id: f_00007-2-0 loss: 0.642138  [   32/  179]
train() client id: f_00007-2-1 loss: 0.663125  [   64/  179]
train() client id: f_00007-2-2 loss: 0.490743  [   96/  179]
train() client id: f_00007-2-3 loss: 0.549488  [  128/  179]
train() client id: f_00007-2-4 loss: 0.714835  [  160/  179]
train() client id: f_00007-3-0 loss: 0.547399  [   32/  179]
train() client id: f_00007-3-1 loss: 0.586444  [   64/  179]
train() client id: f_00007-3-2 loss: 0.638182  [   96/  179]
train() client id: f_00007-3-3 loss: 0.731478  [  128/  179]
train() client id: f_00007-3-4 loss: 0.536025  [  160/  179]
train() client id: f_00007-4-0 loss: 0.676086  [   32/  179]
train() client id: f_00007-4-1 loss: 0.478223  [   64/  179]
train() client id: f_00007-4-2 loss: 0.613595  [   96/  179]
train() client id: f_00007-4-3 loss: 0.831758  [  128/  179]
train() client id: f_00007-4-4 loss: 0.484002  [  160/  179]
train() client id: f_00007-5-0 loss: 0.775690  [   32/  179]
train() client id: f_00007-5-1 loss: 0.483957  [   64/  179]
train() client id: f_00007-5-2 loss: 0.683693  [   96/  179]
train() client id: f_00007-5-3 loss: 0.524124  [  128/  179]
train() client id: f_00007-5-4 loss: 0.484115  [  160/  179]
train() client id: f_00007-6-0 loss: 0.793364  [   32/  179]
train() client id: f_00007-6-1 loss: 0.558046  [   64/  179]
train() client id: f_00007-6-2 loss: 0.549081  [   96/  179]
train() client id: f_00007-6-3 loss: 0.718087  [  128/  179]
train() client id: f_00007-6-4 loss: 0.451825  [  160/  179]
train() client id: f_00007-7-0 loss: 0.724773  [   32/  179]
train() client id: f_00007-7-1 loss: 0.408425  [   64/  179]
train() client id: f_00007-7-2 loss: 0.678026  [   96/  179]
train() client id: f_00007-7-3 loss: 0.529202  [  128/  179]
train() client id: f_00007-7-4 loss: 0.697162  [  160/  179]
train() client id: f_00007-8-0 loss: 0.509873  [   32/  179]
train() client id: f_00007-8-1 loss: 0.604553  [   64/  179]
train() client id: f_00007-8-2 loss: 0.878330  [   96/  179]
train() client id: f_00007-8-3 loss: 0.487438  [  128/  179]
train() client id: f_00007-8-4 loss: 0.435849  [  160/  179]
train() client id: f_00007-9-0 loss: 0.396701  [   32/  179]
train() client id: f_00007-9-1 loss: 0.653143  [   64/  179]
train() client id: f_00007-9-2 loss: 0.409942  [   96/  179]
train() client id: f_00007-9-3 loss: 0.885526  [  128/  179]
train() client id: f_00007-9-4 loss: 0.689457  [  160/  179]
train() client id: f_00007-10-0 loss: 0.501514  [   32/  179]
train() client id: f_00007-10-1 loss: 0.545385  [   64/  179]
train() client id: f_00007-10-2 loss: 0.896792  [   96/  179]
train() client id: f_00007-10-3 loss: 0.558020  [  128/  179]
train() client id: f_00007-10-4 loss: 0.435201  [  160/  179]
train() client id: f_00007-11-0 loss: 0.743280  [   32/  179]
train() client id: f_00007-11-1 loss: 0.689299  [   64/  179]
train() client id: f_00007-11-2 loss: 0.534431  [   96/  179]
train() client id: f_00007-11-3 loss: 0.524617  [  128/  179]
train() client id: f_00007-11-4 loss: 0.453880  [  160/  179]
train() client id: f_00007-12-0 loss: 0.485486  [   32/  179]
train() client id: f_00007-12-1 loss: 0.561032  [   64/  179]
train() client id: f_00007-12-2 loss: 0.438059  [   96/  179]
train() client id: f_00007-12-3 loss: 0.531424  [  128/  179]
train() client id: f_00007-12-4 loss: 0.850431  [  160/  179]
train() client id: f_00008-0-0 loss: 0.738530  [   32/  130]
train() client id: f_00008-0-1 loss: 0.703298  [   64/  130]
train() client id: f_00008-0-2 loss: 0.710345  [   96/  130]
train() client id: f_00008-0-3 loss: 0.785916  [  128/  130]
train() client id: f_00008-1-0 loss: 0.602778  [   32/  130]
train() client id: f_00008-1-1 loss: 0.708878  [   64/  130]
train() client id: f_00008-1-2 loss: 0.764442  [   96/  130]
train() client id: f_00008-1-3 loss: 0.849142  [  128/  130]
train() client id: f_00008-2-0 loss: 0.861915  [   32/  130]
train() client id: f_00008-2-1 loss: 0.631657  [   64/  130]
train() client id: f_00008-2-2 loss: 0.758804  [   96/  130]
train() client id: f_00008-2-3 loss: 0.691021  [  128/  130]
train() client id: f_00008-3-0 loss: 0.727044  [   32/  130]
train() client id: f_00008-3-1 loss: 0.706557  [   64/  130]
train() client id: f_00008-3-2 loss: 0.727177  [   96/  130]
train() client id: f_00008-3-3 loss: 0.776088  [  128/  130]
train() client id: f_00008-4-0 loss: 0.728510  [   32/  130]
train() client id: f_00008-4-1 loss: 0.720029  [   64/  130]
train() client id: f_00008-4-2 loss: 0.753419  [   96/  130]
train() client id: f_00008-4-3 loss: 0.723156  [  128/  130]
train() client id: f_00008-5-0 loss: 0.595788  [   32/  130]
train() client id: f_00008-5-1 loss: 0.855662  [   64/  130]
train() client id: f_00008-5-2 loss: 0.813020  [   96/  130]
train() client id: f_00008-5-3 loss: 0.670634  [  128/  130]
train() client id: f_00008-6-0 loss: 0.733758  [   32/  130]
train() client id: f_00008-6-1 loss: 0.818580  [   64/  130]
train() client id: f_00008-6-2 loss: 0.758502  [   96/  130]
train() client id: f_00008-6-3 loss: 0.620072  [  128/  130]
train() client id: f_00008-7-0 loss: 0.656259  [   32/  130]
train() client id: f_00008-7-1 loss: 0.700039  [   64/  130]
train() client id: f_00008-7-2 loss: 0.787017  [   96/  130]
train() client id: f_00008-7-3 loss: 0.786731  [  128/  130]
train() client id: f_00008-8-0 loss: 0.662442  [   32/  130]
train() client id: f_00008-8-1 loss: 0.816915  [   64/  130]
train() client id: f_00008-8-2 loss: 0.771634  [   96/  130]
train() client id: f_00008-8-3 loss: 0.660431  [  128/  130]
train() client id: f_00008-9-0 loss: 0.682284  [   32/  130]
train() client id: f_00008-9-1 loss: 0.735767  [   64/  130]
train() client id: f_00008-9-2 loss: 0.696627  [   96/  130]
train() client id: f_00008-9-3 loss: 0.820490  [  128/  130]
train() client id: f_00008-10-0 loss: 0.731144  [   32/  130]
train() client id: f_00008-10-1 loss: 0.625695  [   64/  130]
train() client id: f_00008-10-2 loss: 0.834573  [   96/  130]
train() client id: f_00008-10-3 loss: 0.744155  [  128/  130]
train() client id: f_00008-11-0 loss: 0.662231  [   32/  130]
train() client id: f_00008-11-1 loss: 0.723516  [   64/  130]
train() client id: f_00008-11-2 loss: 0.686571  [   96/  130]
train() client id: f_00008-11-3 loss: 0.826369  [  128/  130]
train() client id: f_00008-12-0 loss: 0.769459  [   32/  130]
train() client id: f_00008-12-1 loss: 0.712593  [   64/  130]
train() client id: f_00008-12-2 loss: 0.631609  [   96/  130]
train() client id: f_00008-12-3 loss: 0.809322  [  128/  130]
train() client id: f_00009-0-0 loss: 1.029343  [   32/  118]
train() client id: f_00009-0-1 loss: 0.981013  [   64/  118]
train() client id: f_00009-0-2 loss: 0.856979  [   96/  118]
train() client id: f_00009-1-0 loss: 1.003139  [   32/  118]
train() client id: f_00009-1-1 loss: 0.922220  [   64/  118]
train() client id: f_00009-1-2 loss: 0.794142  [   96/  118]
train() client id: f_00009-2-0 loss: 0.835912  [   32/  118]
train() client id: f_00009-2-1 loss: 0.943561  [   64/  118]
train() client id: f_00009-2-2 loss: 0.771934  [   96/  118]
train() client id: f_00009-3-0 loss: 0.754467  [   32/  118]
train() client id: f_00009-3-1 loss: 0.813017  [   64/  118]
train() client id: f_00009-3-2 loss: 0.766703  [   96/  118]
train() client id: f_00009-4-0 loss: 0.722259  [   32/  118]
train() client id: f_00009-4-1 loss: 0.646339  [   64/  118]
train() client id: f_00009-4-2 loss: 0.925724  [   96/  118]
train() client id: f_00009-5-0 loss: 0.693687  [   32/  118]
train() client id: f_00009-5-1 loss: 0.958944  [   64/  118]
train() client id: f_00009-5-2 loss: 0.666209  [   96/  118]
train() client id: f_00009-6-0 loss: 0.852969  [   32/  118]
train() client id: f_00009-6-1 loss: 0.671690  [   64/  118]
train() client id: f_00009-6-2 loss: 0.690415  [   96/  118]
train() client id: f_00009-7-0 loss: 0.636050  [   32/  118]
train() client id: f_00009-7-1 loss: 0.601892  [   64/  118]
train() client id: f_00009-7-2 loss: 0.950910  [   96/  118]
train() client id: f_00009-8-0 loss: 0.718188  [   32/  118]
train() client id: f_00009-8-1 loss: 0.743903  [   64/  118]
train() client id: f_00009-8-2 loss: 0.670440  [   96/  118]
train() client id: f_00009-9-0 loss: 0.574789  [   32/  118]
train() client id: f_00009-9-1 loss: 0.891638  [   64/  118]
train() client id: f_00009-9-2 loss: 0.594851  [   96/  118]
train() client id: f_00009-10-0 loss: 0.574017  [   32/  118]
train() client id: f_00009-10-1 loss: 0.749945  [   64/  118]
train() client id: f_00009-10-2 loss: 0.815718  [   96/  118]
train() client id: f_00009-11-0 loss: 0.682868  [   32/  118]
train() client id: f_00009-11-1 loss: 0.645073  [   64/  118]
train() client id: f_00009-11-2 loss: 0.783073  [   96/  118]
train() client id: f_00009-12-0 loss: 0.775194  [   32/  118]
train() client id: f_00009-12-1 loss: 0.674908  [   64/  118]
train() client id: f_00009-12-2 loss: 0.532135  [   96/  118]
At round 64 accuracy: 0.6392572944297082
At round 64 training accuracy: 0.5835010060362174
At round 64 training loss: 0.8375975929432178
gradient difference: 0.46946877241134644
train() client id: f_00000-0-0 loss: 0.992995  [   32/  126]
train() client id: f_00000-0-1 loss: 1.139583  [   64/  126]
train() client id: f_00000-0-2 loss: 0.889745  [   96/  126]
train() client id: f_00000-1-0 loss: 0.829141  [   32/  126]
train() client id: f_00000-1-1 loss: 0.853832  [   64/  126]
train() client id: f_00000-1-2 loss: 0.826083  [   96/  126]
train() client id: f_00000-2-0 loss: 0.783670  [   32/  126]
train() client id: f_00000-2-1 loss: 0.898360  [   64/  126]
train() client id: f_00000-2-2 loss: 0.806193  [   96/  126]
train() client id: f_00000-3-0 loss: 0.763885  [   32/  126]
train() client id: f_00000-3-1 loss: 0.972600  [   64/  126]
train() client id: f_00000-3-2 loss: 0.868272  [   96/  126]
train() client id: f_00000-4-0 loss: 0.739730  [   32/  126]
train() client id: f_00000-4-1 loss: 0.959579  [   64/  126]
train() client id: f_00000-4-2 loss: 0.749915  [   96/  126]
train() client id: f_00000-5-0 loss: 0.761027  [   32/  126]
train() client id: f_00000-5-1 loss: 0.810298  [   64/  126]
train() client id: f_00000-5-2 loss: 0.770375  [   96/  126]
train() client id: f_00000-6-0 loss: 0.916267  [   32/  126]
train() client id: f_00000-6-1 loss: 0.855105  [   64/  126]
train() client id: f_00000-6-2 loss: 0.724930  [   96/  126]
train() client id: f_00000-7-0 loss: 0.868313  [   32/  126]
train() client id: f_00000-7-1 loss: 0.664240  [   64/  126]
train() client id: f_00000-7-2 loss: 0.847867  [   96/  126]
train() client id: f_00000-8-0 loss: 0.754533  [   32/  126]
train() client id: f_00000-8-1 loss: 0.848984  [   64/  126]
train() client id: f_00000-8-2 loss: 0.667517  [   96/  126]
train() client id: f_00000-9-0 loss: 0.780470  [   32/  126]
train() client id: f_00000-9-1 loss: 0.691175  [   64/  126]
train() client id: f_00000-9-2 loss: 0.828735  [   96/  126]
train() client id: f_00000-10-0 loss: 0.837757  [   32/  126]
train() client id: f_00000-10-1 loss: 0.844478  [   64/  126]
train() client id: f_00000-10-2 loss: 0.725439  [   96/  126]
train() client id: f_00000-11-0 loss: 0.781057  [   32/  126]
train() client id: f_00000-11-1 loss: 0.924294  [   64/  126]
train() client id: f_00000-11-2 loss: 0.877851  [   96/  126]
train() client id: f_00000-12-0 loss: 0.849438  [   32/  126]
train() client id: f_00000-12-1 loss: 0.752678  [   64/  126]
train() client id: f_00000-12-2 loss: 0.782382  [   96/  126]
train() client id: f_00001-0-0 loss: 0.338183  [   32/  265]
train() client id: f_00001-0-1 loss: 0.485434  [   64/  265]
train() client id: f_00001-0-2 loss: 0.428557  [   96/  265]
train() client id: f_00001-0-3 loss: 0.428987  [  128/  265]
train() client id: f_00001-0-4 loss: 0.384837  [  160/  265]
train() client id: f_00001-0-5 loss: 0.374440  [  192/  265]
train() client id: f_00001-0-6 loss: 0.311397  [  224/  265]
train() client id: f_00001-0-7 loss: 0.360553  [  256/  265]
train() client id: f_00001-1-0 loss: 0.379077  [   32/  265]
train() client id: f_00001-1-1 loss: 0.299836  [   64/  265]
train() client id: f_00001-1-2 loss: 0.346448  [   96/  265]
train() client id: f_00001-1-3 loss: 0.347795  [  128/  265]
train() client id: f_00001-1-4 loss: 0.454967  [  160/  265]
train() client id: f_00001-1-5 loss: 0.391109  [  192/  265]
train() client id: f_00001-1-6 loss: 0.437518  [  224/  265]
train() client id: f_00001-1-7 loss: 0.346476  [  256/  265]
train() client id: f_00001-2-0 loss: 0.378586  [   32/  265]
train() client id: f_00001-2-1 loss: 0.391512  [   64/  265]
train() client id: f_00001-2-2 loss: 0.395032  [   96/  265]
train() client id: f_00001-2-3 loss: 0.371211  [  128/  265]
train() client id: f_00001-2-4 loss: 0.354726  [  160/  265]
train() client id: f_00001-2-5 loss: 0.422491  [  192/  265]
train() client id: f_00001-2-6 loss: 0.344592  [  224/  265]
train() client id: f_00001-2-7 loss: 0.301547  [  256/  265]
train() client id: f_00001-3-0 loss: 0.349855  [   32/  265]
train() client id: f_00001-3-1 loss: 0.268563  [   64/  265]
train() client id: f_00001-3-2 loss: 0.430722  [   96/  265]
train() client id: f_00001-3-3 loss: 0.368664  [  128/  265]
train() client id: f_00001-3-4 loss: 0.367539  [  160/  265]
train() client id: f_00001-3-5 loss: 0.403296  [  192/  265]
train() client id: f_00001-3-6 loss: 0.289587  [  224/  265]
train() client id: f_00001-3-7 loss: 0.337629  [  256/  265]
train() client id: f_00001-4-0 loss: 0.430574  [   32/  265]
train() client id: f_00001-4-1 loss: 0.299998  [   64/  265]
train() client id: f_00001-4-2 loss: 0.325356  [   96/  265]
train() client id: f_00001-4-3 loss: 0.273907  [  128/  265]
train() client id: f_00001-4-4 loss: 0.344613  [  160/  265]
train() client id: f_00001-4-5 loss: 0.556394  [  192/  265]
train() client id: f_00001-4-6 loss: 0.291186  [  224/  265]
train() client id: f_00001-4-7 loss: 0.322046  [  256/  265]
train() client id: f_00001-5-0 loss: 0.475934  [   32/  265]
train() client id: f_00001-5-1 loss: 0.347061  [   64/  265]
train() client id: f_00001-5-2 loss: 0.340953  [   96/  265]
train() client id: f_00001-5-3 loss: 0.274917  [  128/  265]
train() client id: f_00001-5-4 loss: 0.311575  [  160/  265]
train() client id: f_00001-5-5 loss: 0.379437  [  192/  265]
train() client id: f_00001-5-6 loss: 0.318806  [  224/  265]
train() client id: f_00001-5-7 loss: 0.275569  [  256/  265]
train() client id: f_00001-6-0 loss: 0.250908  [   32/  265]
train() client id: f_00001-6-1 loss: 0.424138  [   64/  265]
train() client id: f_00001-6-2 loss: 0.247979  [   96/  265]
train() client id: f_00001-6-3 loss: 0.411066  [  128/  265]
train() client id: f_00001-6-4 loss: 0.419344  [  160/  265]
train() client id: f_00001-6-5 loss: 0.287478  [  192/  265]
train() client id: f_00001-6-6 loss: 0.348105  [  224/  265]
train() client id: f_00001-6-7 loss: 0.382489  [  256/  265]
train() client id: f_00001-7-0 loss: 0.284206  [   32/  265]
train() client id: f_00001-7-1 loss: 0.345302  [   64/  265]
train() client id: f_00001-7-2 loss: 0.328077  [   96/  265]
train() client id: f_00001-7-3 loss: 0.535457  [  128/  265]
train() client id: f_00001-7-4 loss: 0.314552  [  160/  265]
train() client id: f_00001-7-5 loss: 0.323893  [  192/  265]
train() client id: f_00001-7-6 loss: 0.365311  [  224/  265]
train() client id: f_00001-7-7 loss: 0.252527  [  256/  265]
train() client id: f_00001-8-0 loss: 0.267686  [   32/  265]
train() client id: f_00001-8-1 loss: 0.310317  [   64/  265]
train() client id: f_00001-8-2 loss: 0.304369  [   96/  265]
train() client id: f_00001-8-3 loss: 0.381528  [  128/  265]
train() client id: f_00001-8-4 loss: 0.263791  [  160/  265]
train() client id: f_00001-8-5 loss: 0.296228  [  192/  265]
train() client id: f_00001-8-6 loss: 0.658226  [  224/  265]
train() client id: f_00001-8-7 loss: 0.244454  [  256/  265]
train() client id: f_00001-9-0 loss: 0.435162  [   32/  265]
train() client id: f_00001-9-1 loss: 0.273042  [   64/  265]
train() client id: f_00001-9-2 loss: 0.335610  [   96/  265]
train() client id: f_00001-9-3 loss: 0.331123  [  128/  265]
train() client id: f_00001-9-4 loss: 0.324217  [  160/  265]
train() client id: f_00001-9-5 loss: 0.260540  [  192/  265]
train() client id: f_00001-9-6 loss: 0.238991  [  224/  265]
train() client id: f_00001-9-7 loss: 0.376213  [  256/  265]
train() client id: f_00001-10-0 loss: 0.294126  [   32/  265]
train() client id: f_00001-10-1 loss: 0.272766  [   64/  265]
train() client id: f_00001-10-2 loss: 0.218095  [   96/  265]
train() client id: f_00001-10-3 loss: 0.369772  [  128/  265]
train() client id: f_00001-10-4 loss: 0.407326  [  160/  265]
train() client id: f_00001-10-5 loss: 0.319358  [  192/  265]
train() client id: f_00001-10-6 loss: 0.406121  [  224/  265]
train() client id: f_00001-10-7 loss: 0.389690  [  256/  265]
train() client id: f_00001-11-0 loss: 0.439398  [   32/  265]
train() client id: f_00001-11-1 loss: 0.237093  [   64/  265]
train() client id: f_00001-11-2 loss: 0.254256  [   96/  265]
train() client id: f_00001-11-3 loss: 0.321743  [  128/  265]
train() client id: f_00001-11-4 loss: 0.314098  [  160/  265]
train() client id: f_00001-11-5 loss: 0.401742  [  192/  265]
train() client id: f_00001-11-6 loss: 0.459296  [  224/  265]
train() client id: f_00001-11-7 loss: 0.242124  [  256/  265]
train() client id: f_00001-12-0 loss: 0.261744  [   32/  265]
train() client id: f_00001-12-1 loss: 0.356386  [   64/  265]
train() client id: f_00001-12-2 loss: 0.417513  [   96/  265]
train() client id: f_00001-12-3 loss: 0.270352  [  128/  265]
train() client id: f_00001-12-4 loss: 0.356812  [  160/  265]
train() client id: f_00001-12-5 loss: 0.243964  [  192/  265]
train() client id: f_00001-12-6 loss: 0.358551  [  224/  265]
train() client id: f_00001-12-7 loss: 0.420678  [  256/  265]
train() client id: f_00002-0-0 loss: 0.767994  [   32/  124]
train() client id: f_00002-0-1 loss: 0.853736  [   64/  124]
train() client id: f_00002-0-2 loss: 0.757892  [   96/  124]
train() client id: f_00002-1-0 loss: 0.628074  [   32/  124]
train() client id: f_00002-1-1 loss: 0.747872  [   64/  124]
train() client id: f_00002-1-2 loss: 0.996143  [   96/  124]
train() client id: f_00002-2-0 loss: 0.846383  [   32/  124]
train() client id: f_00002-2-1 loss: 0.846726  [   64/  124]
train() client id: f_00002-2-2 loss: 0.544725  [   96/  124]
train() client id: f_00002-3-0 loss: 0.646362  [   32/  124]
train() client id: f_00002-3-1 loss: 0.680346  [   64/  124]
train() client id: f_00002-3-2 loss: 0.855195  [   96/  124]
train() client id: f_00002-4-0 loss: 0.633693  [   32/  124]
train() client id: f_00002-4-1 loss: 0.755861  [   64/  124]
train() client id: f_00002-4-2 loss: 0.453891  [   96/  124]
train() client id: f_00002-5-0 loss: 0.737573  [   32/  124]
train() client id: f_00002-5-1 loss: 0.618261  [   64/  124]
train() client id: f_00002-5-2 loss: 0.455441  [   96/  124]
train() client id: f_00002-6-0 loss: 0.667350  [   32/  124]
train() client id: f_00002-6-1 loss: 0.651009  [   64/  124]
train() client id: f_00002-6-2 loss: 0.478480  [   96/  124]
train() client id: f_00002-7-0 loss: 0.579934  [   32/  124]
train() client id: f_00002-7-1 loss: 0.700565  [   64/  124]
train() client id: f_00002-7-2 loss: 0.494208  [   96/  124]
train() client id: f_00002-8-0 loss: 0.697501  [   32/  124]
train() client id: f_00002-8-1 loss: 0.534620  [   64/  124]
train() client id: f_00002-8-2 loss: 0.424023  [   96/  124]
train() client id: f_00002-9-0 loss: 0.609875  [   32/  124]
train() client id: f_00002-9-1 loss: 0.607630  [   64/  124]
train() client id: f_00002-9-2 loss: 0.555800  [   96/  124]
train() client id: f_00002-10-0 loss: 0.677958  [   32/  124]
train() client id: f_00002-10-1 loss: 0.586592  [   64/  124]
train() client id: f_00002-10-2 loss: 0.620057  [   96/  124]
train() client id: f_00002-11-0 loss: 0.675266  [   32/  124]
train() client id: f_00002-11-1 loss: 0.555240  [   64/  124]
train() client id: f_00002-11-2 loss: 0.609613  [   96/  124]
train() client id: f_00002-12-0 loss: 0.529881  [   32/  124]
train() client id: f_00002-12-1 loss: 0.624488  [   64/  124]
train() client id: f_00002-12-2 loss: 0.615640  [   96/  124]
train() client id: f_00003-0-0 loss: 0.315460  [   32/   43]
train() client id: f_00003-1-0 loss: 0.524292  [   32/   43]
train() client id: f_00003-2-0 loss: 0.739826  [   32/   43]
train() client id: f_00003-3-0 loss: 0.487578  [   32/   43]
train() client id: f_00003-4-0 loss: 0.517578  [   32/   43]
train() client id: f_00003-5-0 loss: 0.560046  [   32/   43]
train() client id: f_00003-6-0 loss: 0.622737  [   32/   43]
train() client id: f_00003-7-0 loss: 0.358076  [   32/   43]
train() client id: f_00003-8-0 loss: 0.532509  [   32/   43]
train() client id: f_00003-9-0 loss: 0.391884  [   32/   43]
train() client id: f_00003-10-0 loss: 0.583229  [   32/   43]
train() client id: f_00003-11-0 loss: 0.521702  [   32/   43]
train() client id: f_00003-12-0 loss: 0.507605  [   32/   43]
train() client id: f_00004-0-0 loss: 0.760848  [   32/  306]
train() client id: f_00004-0-1 loss: 0.791007  [   64/  306]
train() client id: f_00004-0-2 loss: 0.665250  [   96/  306]
train() client id: f_00004-0-3 loss: 0.745849  [  128/  306]
train() client id: f_00004-0-4 loss: 0.658571  [  160/  306]
train() client id: f_00004-0-5 loss: 0.842638  [  192/  306]
train() client id: f_00004-0-6 loss: 0.729136  [  224/  306]
train() client id: f_00004-0-7 loss: 0.670366  [  256/  306]
train() client id: f_00004-0-8 loss: 0.909153  [  288/  306]
train() client id: f_00004-1-0 loss: 0.758325  [   32/  306]
train() client id: f_00004-1-1 loss: 0.830946  [   64/  306]
train() client id: f_00004-1-2 loss: 0.811838  [   96/  306]
train() client id: f_00004-1-3 loss: 0.731856  [  128/  306]
train() client id: f_00004-1-4 loss: 0.812679  [  160/  306]
train() client id: f_00004-1-5 loss: 0.670027  [  192/  306]
train() client id: f_00004-1-6 loss: 0.723967  [  224/  306]
train() client id: f_00004-1-7 loss: 0.828157  [  256/  306]
train() client id: f_00004-1-8 loss: 0.592128  [  288/  306]
train() client id: f_00004-2-0 loss: 0.809082  [   32/  306]
train() client id: f_00004-2-1 loss: 0.669215  [   64/  306]
train() client id: f_00004-2-2 loss: 0.701177  [   96/  306]
train() client id: f_00004-2-3 loss: 1.002118  [  128/  306]
train() client id: f_00004-2-4 loss: 0.561699  [  160/  306]
train() client id: f_00004-2-5 loss: 0.699408  [  192/  306]
train() client id: f_00004-2-6 loss: 0.649656  [  224/  306]
train() client id: f_00004-2-7 loss: 0.793265  [  256/  306]
train() client id: f_00004-2-8 loss: 0.667376  [  288/  306]
train() client id: f_00004-3-0 loss: 0.799713  [   32/  306]
train() client id: f_00004-3-1 loss: 0.703213  [   64/  306]
train() client id: f_00004-3-2 loss: 0.618707  [   96/  306]
train() client id: f_00004-3-3 loss: 0.895655  [  128/  306]
train() client id: f_00004-3-4 loss: 0.698418  [  160/  306]
train() client id: f_00004-3-5 loss: 0.640718  [  192/  306]
train() client id: f_00004-3-6 loss: 0.853979  [  224/  306]
train() client id: f_00004-3-7 loss: 0.719034  [  256/  306]
train() client id: f_00004-3-8 loss: 0.664835  [  288/  306]
train() client id: f_00004-4-0 loss: 0.705919  [   32/  306]
train() client id: f_00004-4-1 loss: 0.697412  [   64/  306]
train() client id: f_00004-4-2 loss: 0.820099  [   96/  306]
train() client id: f_00004-4-3 loss: 0.782115  [  128/  306]
train() client id: f_00004-4-4 loss: 0.622184  [  160/  306]
train() client id: f_00004-4-5 loss: 0.822106  [  192/  306]
train() client id: f_00004-4-6 loss: 0.711659  [  224/  306]
train() client id: f_00004-4-7 loss: 0.748622  [  256/  306]
train() client id: f_00004-4-8 loss: 0.754227  [  288/  306]
train() client id: f_00004-5-0 loss: 0.721642  [   32/  306]
train() client id: f_00004-5-1 loss: 0.683071  [   64/  306]
train() client id: f_00004-5-2 loss: 0.844922  [   96/  306]
train() client id: f_00004-5-3 loss: 0.889064  [  128/  306]
train() client id: f_00004-5-4 loss: 0.765988  [  160/  306]
train() client id: f_00004-5-5 loss: 0.863667  [  192/  306]
train() client id: f_00004-5-6 loss: 0.561088  [  224/  306]
train() client id: f_00004-5-7 loss: 0.703947  [  256/  306]
train() client id: f_00004-5-8 loss: 0.699657  [  288/  306]
train() client id: f_00004-6-0 loss: 0.694650  [   32/  306]
train() client id: f_00004-6-1 loss: 0.659793  [   64/  306]
train() client id: f_00004-6-2 loss: 0.661846  [   96/  306]
train() client id: f_00004-6-3 loss: 0.805259  [  128/  306]
train() client id: f_00004-6-4 loss: 0.816995  [  160/  306]
train() client id: f_00004-6-5 loss: 0.650357  [  192/  306]
train() client id: f_00004-6-6 loss: 0.799473  [  224/  306]
train() client id: f_00004-6-7 loss: 0.750516  [  256/  306]
train() client id: f_00004-6-8 loss: 0.864168  [  288/  306]
train() client id: f_00004-7-0 loss: 0.808965  [   32/  306]
train() client id: f_00004-7-1 loss: 0.759424  [   64/  306]
train() client id: f_00004-7-2 loss: 0.673328  [   96/  306]
train() client id: f_00004-7-3 loss: 0.686139  [  128/  306]
train() client id: f_00004-7-4 loss: 0.753751  [  160/  306]
train() client id: f_00004-7-5 loss: 0.725954  [  192/  306]
train() client id: f_00004-7-6 loss: 0.755193  [  224/  306]
train() client id: f_00004-7-7 loss: 0.816705  [  256/  306]
train() client id: f_00004-7-8 loss: 0.686605  [  288/  306]
train() client id: f_00004-8-0 loss: 0.695055  [   32/  306]
train() client id: f_00004-8-1 loss: 0.665371  [   64/  306]
train() client id: f_00004-8-2 loss: 0.813991  [   96/  306]
train() client id: f_00004-8-3 loss: 0.806365  [  128/  306]
train() client id: f_00004-8-4 loss: 0.712866  [  160/  306]
train() client id: f_00004-8-5 loss: 0.635260  [  192/  306]
train() client id: f_00004-8-6 loss: 0.765987  [  224/  306]
train() client id: f_00004-8-7 loss: 0.813492  [  256/  306]
train() client id: f_00004-8-8 loss: 0.743054  [  288/  306]
train() client id: f_00004-9-0 loss: 0.888729  [   32/  306]
train() client id: f_00004-9-1 loss: 0.674880  [   64/  306]
train() client id: f_00004-9-2 loss: 0.705818  [   96/  306]
train() client id: f_00004-9-3 loss: 0.708503  [  128/  306]
train() client id: f_00004-9-4 loss: 0.708128  [  160/  306]
train() client id: f_00004-9-5 loss: 0.831653  [  192/  306]
train() client id: f_00004-9-6 loss: 0.611668  [  224/  306]
train() client id: f_00004-9-7 loss: 0.764765  [  256/  306]
train() client id: f_00004-9-8 loss: 0.814526  [  288/  306]
train() client id: f_00004-10-0 loss: 0.760679  [   32/  306]
train() client id: f_00004-10-1 loss: 0.894339  [   64/  306]
train() client id: f_00004-10-2 loss: 0.724277  [   96/  306]
train() client id: f_00004-10-3 loss: 0.723276  [  128/  306]
train() client id: f_00004-10-4 loss: 0.626247  [  160/  306]
train() client id: f_00004-10-5 loss: 0.857712  [  192/  306]
train() client id: f_00004-10-6 loss: 0.817559  [  224/  306]
train() client id: f_00004-10-7 loss: 0.666695  [  256/  306]
train() client id: f_00004-10-8 loss: 0.646093  [  288/  306]
train() client id: f_00004-11-0 loss: 0.854089  [   32/  306]
train() client id: f_00004-11-1 loss: 0.577262  [   64/  306]
train() client id: f_00004-11-2 loss: 0.926304  [   96/  306]
train() client id: f_00004-11-3 loss: 0.757347  [  128/  306]
train() client id: f_00004-11-4 loss: 0.705267  [  160/  306]
train() client id: f_00004-11-5 loss: 0.745412  [  192/  306]
train() client id: f_00004-11-6 loss: 0.772753  [  224/  306]
train() client id: f_00004-11-7 loss: 0.673873  [  256/  306]
train() client id: f_00004-11-8 loss: 0.709200  [  288/  306]
train() client id: f_00004-12-0 loss: 0.686615  [   32/  306]
train() client id: f_00004-12-1 loss: 0.705788  [   64/  306]
train() client id: f_00004-12-2 loss: 0.681221  [   96/  306]
train() client id: f_00004-12-3 loss: 0.698104  [  128/  306]
train() client id: f_00004-12-4 loss: 0.917646  [  160/  306]
train() client id: f_00004-12-5 loss: 0.776921  [  192/  306]
train() client id: f_00004-12-6 loss: 0.713036  [  224/  306]
train() client id: f_00004-12-7 loss: 0.736645  [  256/  306]
train() client id: f_00004-12-8 loss: 0.803898  [  288/  306]
train() client id: f_00005-0-0 loss: 0.469459  [   32/  146]
train() client id: f_00005-0-1 loss: 0.186813  [   64/  146]
train() client id: f_00005-0-2 loss: 0.533966  [   96/  146]
train() client id: f_00005-0-3 loss: 0.306251  [  128/  146]
train() client id: f_00005-1-0 loss: 0.548325  [   32/  146]
train() client id: f_00005-1-1 loss: 0.056434  [   64/  146]
train() client id: f_00005-1-2 loss: 0.248047  [   96/  146]
train() client id: f_00005-1-3 loss: 0.560944  [  128/  146]
train() client id: f_00005-2-0 loss: 0.462628  [   32/  146]
train() client id: f_00005-2-1 loss: 0.186936  [   64/  146]
train() client id: f_00005-2-2 loss: 0.414550  [   96/  146]
train() client id: f_00005-2-3 loss: 0.177610  [  128/  146]
train() client id: f_00005-3-0 loss: 0.251761  [   32/  146]
train() client id: f_00005-3-1 loss: 0.415642  [   64/  146]
train() client id: f_00005-3-2 loss: 0.375273  [   96/  146]
train() client id: f_00005-3-3 loss: 0.564824  [  128/  146]
train() client id: f_00005-4-0 loss: 0.297730  [   32/  146]
train() client id: f_00005-4-1 loss: 0.188695  [   64/  146]
train() client id: f_00005-4-2 loss: 0.531849  [   96/  146]
train() client id: f_00005-4-3 loss: 0.288385  [  128/  146]
train() client id: f_00005-5-0 loss: 0.374651  [   32/  146]
train() client id: f_00005-5-1 loss: 0.403399  [   64/  146]
train() client id: f_00005-5-2 loss: 0.405381  [   96/  146]
train() client id: f_00005-5-3 loss: 0.383606  [  128/  146]
train() client id: f_00005-6-0 loss: 0.392084  [   32/  146]
train() client id: f_00005-6-1 loss: 0.478501  [   64/  146]
train() client id: f_00005-6-2 loss: 0.401554  [   96/  146]
train() client id: f_00005-6-3 loss: 0.251184  [  128/  146]
train() client id: f_00005-7-0 loss: 0.369525  [   32/  146]
train() client id: f_00005-7-1 loss: 0.386393  [   64/  146]
train() client id: f_00005-7-2 loss: 0.406063  [   96/  146]
train() client id: f_00005-7-3 loss: 0.279998  [  128/  146]
train() client id: f_00005-8-0 loss: 0.131112  [   32/  146]
train() client id: f_00005-8-1 loss: 0.360560  [   64/  146]
train() client id: f_00005-8-2 loss: 0.468529  [   96/  146]
train() client id: f_00005-8-3 loss: 0.213610  [  128/  146]
train() client id: f_00005-9-0 loss: 0.493617  [   32/  146]
train() client id: f_00005-9-1 loss: 0.414354  [   64/  146]
train() client id: f_00005-9-2 loss: 0.385665  [   96/  146]
train() client id: f_00005-9-3 loss: 0.174685  [  128/  146]
train() client id: f_00005-10-0 loss: 0.171417  [   32/  146]
train() client id: f_00005-10-1 loss: 0.322435  [   64/  146]
train() client id: f_00005-10-2 loss: 0.497425  [   96/  146]
train() client id: f_00005-10-3 loss: 0.466295  [  128/  146]
train() client id: f_00005-11-0 loss: 0.110724  [   32/  146]
train() client id: f_00005-11-1 loss: 0.486655  [   64/  146]
train() client id: f_00005-11-2 loss: 0.001206  [   96/  146]
train() client id: f_00005-11-3 loss: 0.914944  [  128/  146]
train() client id: f_00005-12-0 loss: 0.305216  [   32/  146]
train() client id: f_00005-12-1 loss: 0.129338  [   64/  146]
train() client id: f_00005-12-2 loss: 0.419842  [   96/  146]
train() client id: f_00005-12-3 loss: 0.531156  [  128/  146]
train() client id: f_00006-0-0 loss: 0.508692  [   32/   54]
train() client id: f_00006-1-0 loss: 0.411298  [   32/   54]
train() client id: f_00006-2-0 loss: 0.430276  [   32/   54]
train() client id: f_00006-3-0 loss: 0.395545  [   32/   54]
train() client id: f_00006-4-0 loss: 0.434164  [   32/   54]
train() client id: f_00006-5-0 loss: 0.411339  [   32/   54]
train() client id: f_00006-6-0 loss: 0.449287  [   32/   54]
train() client id: f_00006-7-0 loss: 0.446900  [   32/   54]
train() client id: f_00006-8-0 loss: 0.463362  [   32/   54]
train() client id: f_00006-9-0 loss: 0.485331  [   32/   54]
train() client id: f_00006-10-0 loss: 0.520740  [   32/   54]
train() client id: f_00006-11-0 loss: 0.426960  [   32/   54]
train() client id: f_00006-12-0 loss: 0.447513  [   32/   54]
train() client id: f_00007-0-0 loss: 0.237306  [   32/  179]
train() client id: f_00007-0-1 loss: 0.467688  [   64/  179]
train() client id: f_00007-0-2 loss: 0.332276  [   96/  179]
train() client id: f_00007-0-3 loss: 0.312415  [  128/  179]
train() client id: f_00007-0-4 loss: 0.534375  [  160/  179]
train() client id: f_00007-1-0 loss: 0.332731  [   32/  179]
train() client id: f_00007-1-1 loss: 0.296389  [   64/  179]
train() client id: f_00007-1-2 loss: 0.320615  [   96/  179]
train() client id: f_00007-1-3 loss: 0.194009  [  128/  179]
train() client id: f_00007-1-4 loss: 0.689442  [  160/  179]
train() client id: f_00007-2-0 loss: 0.206101  [   32/  179]
train() client id: f_00007-2-1 loss: 0.354667  [   64/  179]
train() client id: f_00007-2-2 loss: 0.311580  [   96/  179]
train() client id: f_00007-2-3 loss: 0.337174  [  128/  179]
train() client id: f_00007-2-4 loss: 0.325751  [  160/  179]
train() client id: f_00007-3-0 loss: 0.211974  [   32/  179]
train() client id: f_00007-3-1 loss: 0.174374  [   64/  179]
train() client id: f_00007-3-2 loss: 0.295591  [   96/  179]
train() client id: f_00007-3-3 loss: 0.490564  [  128/  179]
train() client id: f_00007-3-4 loss: 0.413881  [  160/  179]
train() client id: f_00007-4-0 loss: 0.455788  [   32/  179]
train() client id: f_00007-4-1 loss: 0.119501  [   64/  179]
train() client id: f_00007-4-2 loss: 0.362180  [   96/  179]
train() client id: f_00007-4-3 loss: 0.325678  [  128/  179]
train() client id: f_00007-4-4 loss: 0.332204  [  160/  179]
train() client id: f_00007-5-0 loss: 0.136243  [   32/  179]
train() client id: f_00007-5-1 loss: 0.344837  [   64/  179]
train() client id: f_00007-5-2 loss: 0.224061  [   96/  179]
train() client id: f_00007-5-3 loss: 0.282042  [  128/  179]
train() client id: f_00007-5-4 loss: 0.375607  [  160/  179]
train() client id: f_00007-6-0 loss: 0.342645  [   32/  179]
train() client id: f_00007-6-1 loss: 0.351153  [   64/  179]
train() client id: f_00007-6-2 loss: 0.461886  [   96/  179]
train() client id: f_00007-6-3 loss: 0.144752  [  128/  179]
train() client id: f_00007-6-4 loss: 0.277770  [  160/  179]
train() client id: f_00007-7-0 loss: 0.422663  [   32/  179]
train() client id: f_00007-7-1 loss: 0.184304  [   64/  179]
train() client id: f_00007-7-2 loss: 0.136389  [   96/  179]
train() client id: f_00007-7-3 loss: 0.385447  [  128/  179]
train() client id: f_00007-7-4 loss: 0.427095  [  160/  179]
train() client id: f_00007-8-0 loss: 0.361282  [   32/  179]
train() client id: f_00007-8-1 loss: 0.332419  [   64/  179]
train() client id: f_00007-8-2 loss: 0.255128  [   96/  179]
train() client id: f_00007-8-3 loss: 0.205287  [  128/  179]
train() client id: f_00007-8-4 loss: 0.321534  [  160/  179]
train() client id: f_00007-9-0 loss: 0.153426  [   32/  179]
train() client id: f_00007-9-1 loss: 0.294832  [   64/  179]
train() client id: f_00007-9-2 loss: 0.293682  [   96/  179]
train() client id: f_00007-9-3 loss: 0.413559  [  128/  179]
train() client id: f_00007-9-4 loss: 0.345761  [  160/  179]
train() client id: f_00007-10-0 loss: 0.311095  [   32/  179]
train() client id: f_00007-10-1 loss: 0.201273  [   64/  179]
train() client id: f_00007-10-2 loss: 0.375140  [   96/  179]
train() client id: f_00007-10-3 loss: 0.381788  [  128/  179]
train() client id: f_00007-10-4 loss: 0.155724  [  160/  179]
train() client id: f_00007-11-0 loss: 0.345773  [   32/  179]
train() client id: f_00007-11-1 loss: 0.479293  [   64/  179]
train() client id: f_00007-11-2 loss: 0.186126  [   96/  179]
train() client id: f_00007-11-3 loss: 0.159700  [  128/  179]
train() client id: f_00007-11-4 loss: 0.308262  [  160/  179]
train() client id: f_00007-12-0 loss: 0.256586  [   32/  179]
train() client id: f_00007-12-1 loss: 0.415306  [   64/  179]
train() client id: f_00007-12-2 loss: 0.230901  [   96/  179]
train() client id: f_00007-12-3 loss: 0.196444  [  128/  179]
train() client id: f_00007-12-4 loss: 0.284390  [  160/  179]
train() client id: f_00008-0-0 loss: 0.616914  [   32/  130]
train() client id: f_00008-0-1 loss: 0.539349  [   64/  130]
train() client id: f_00008-0-2 loss: 0.630445  [   96/  130]
train() client id: f_00008-0-3 loss: 0.639394  [  128/  130]
train() client id: f_00008-1-0 loss: 0.530769  [   32/  130]
train() client id: f_00008-1-1 loss: 0.712212  [   64/  130]
train() client id: f_00008-1-2 loss: 0.573800  [   96/  130]
train() client id: f_00008-1-3 loss: 0.609633  [  128/  130]
train() client id: f_00008-2-0 loss: 0.707456  [   32/  130]
train() client id: f_00008-2-1 loss: 0.512879  [   64/  130]
train() client id: f_00008-2-2 loss: 0.554852  [   96/  130]
train() client id: f_00008-2-3 loss: 0.646677  [  128/  130]
train() client id: f_00008-3-0 loss: 0.501071  [   32/  130]
train() client id: f_00008-3-1 loss: 0.643492  [   64/  130]
train() client id: f_00008-3-2 loss: 0.649136  [   96/  130]
train() client id: f_00008-3-3 loss: 0.674206  [  128/  130]
train() client id: f_00008-4-0 loss: 0.680086  [   32/  130]
train() client id: f_00008-4-1 loss: 0.550517  [   64/  130]
train() client id: f_00008-4-2 loss: 0.636706  [   96/  130]
train() client id: f_00008-4-3 loss: 0.566004  [  128/  130]
train() client id: f_00008-5-0 loss: 0.708232  [   32/  130]
train() client id: f_00008-5-1 loss: 0.581079  [   64/  130]
train() client id: f_00008-5-2 loss: 0.606560  [   96/  130]
train() client id: f_00008-5-3 loss: 0.588127  [  128/  130]
train() client id: f_00008-6-0 loss: 0.659947  [   32/  130]
train() client id: f_00008-6-1 loss: 0.598801  [   64/  130]
train() client id: f_00008-6-2 loss: 0.603730  [   96/  130]
train() client id: f_00008-6-3 loss: 0.616731  [  128/  130]
train() client id: f_00008-7-0 loss: 0.637583  [   32/  130]
train() client id: f_00008-7-1 loss: 0.589861  [   64/  130]
train() client id: f_00008-7-2 loss: 0.594156  [   96/  130]
train() client id: f_00008-7-3 loss: 0.655515  [  128/  130]
train() client id: f_00008-8-0 loss: 0.500327  [   32/  130]
train() client id: f_00008-8-1 loss: 0.623861  [   64/  130]
train() client id: f_00008-8-2 loss: 0.585147  [   96/  130]
train() client id: f_00008-8-3 loss: 0.728003  [  128/  130]
train() client id: f_00008-9-0 loss: 0.689228  [   32/  130]
train() client id: f_00008-9-1 loss: 0.529472  [   64/  130]
train() client id: f_00008-9-2 loss: 0.689498  [   96/  130]
train() client id: f_00008-9-3 loss: 0.572652  [  128/  130]
train() client id: f_00008-10-0 loss: 0.531145  [   32/  130]
train() client id: f_00008-10-1 loss: 0.725746  [   64/  130]
train() client id: f_00008-10-2 loss: 0.610447  [   96/  130]
train() client id: f_00008-10-3 loss: 0.623372  [  128/  130]
train() client id: f_00008-11-0 loss: 0.533336  [   32/  130]
train() client id: f_00008-11-1 loss: 0.629482  [   64/  130]
train() client id: f_00008-11-2 loss: 0.658434  [   96/  130]
train() client id: f_00008-11-3 loss: 0.631826  [  128/  130]
train() client id: f_00008-12-0 loss: 0.613699  [   32/  130]
train() client id: f_00008-12-1 loss: 0.581674  [   64/  130]
train() client id: f_00008-12-2 loss: 0.621914  [   96/  130]
train() client id: f_00008-12-3 loss: 0.615497  [  128/  130]
train() client id: f_00009-0-0 loss: 1.171456  [   32/  118]
train() client id: f_00009-0-1 loss: 1.324669  [   64/  118]
train() client id: f_00009-0-2 loss: 1.017291  [   96/  118]
train() client id: f_00009-1-0 loss: 1.071683  [   32/  118]
train() client id: f_00009-1-1 loss: 1.175362  [   64/  118]
train() client id: f_00009-1-2 loss: 1.164325  [   96/  118]
train() client id: f_00009-2-0 loss: 1.207078  [   32/  118]
train() client id: f_00009-2-1 loss: 1.054993  [   64/  118]
train() client id: f_00009-2-2 loss: 1.038707  [   96/  118]
train() client id: f_00009-3-0 loss: 0.972408  [   32/  118]
train() client id: f_00009-3-1 loss: 1.012029  [   64/  118]
train() client id: f_00009-3-2 loss: 1.176109  [   96/  118]
train() client id: f_00009-4-0 loss: 1.085006  [   32/  118]
train() client id: f_00009-4-1 loss: 0.977235  [   64/  118]
train() client id: f_00009-4-2 loss: 1.009142  [   96/  118]
train() client id: f_00009-5-0 loss: 0.916201  [   32/  118]
train() client id: f_00009-5-1 loss: 1.006202  [   64/  118]
train() client id: f_00009-5-2 loss: 0.921050  [   96/  118]
train() client id: f_00009-6-0 loss: 1.046933  [   32/  118]
train() client id: f_00009-6-1 loss: 1.056554  [   64/  118]
train() client id: f_00009-6-2 loss: 0.848912  [   96/  118]
train() client id: f_00009-7-0 loss: 0.947433  [   32/  118]
train() client id: f_00009-7-1 loss: 1.081186  [   64/  118]
train() client id: f_00009-7-2 loss: 0.906778  [   96/  118]
train() client id: f_00009-8-0 loss: 0.828651  [   32/  118]
train() client id: f_00009-8-1 loss: 1.132336  [   64/  118]
train() client id: f_00009-8-2 loss: 0.949528  [   96/  118]
train() client id: f_00009-9-0 loss: 0.905019  [   32/  118]
train() client id: f_00009-9-1 loss: 1.024408  [   64/  118]
train() client id: f_00009-9-2 loss: 1.041979  [   96/  118]
train() client id: f_00009-10-0 loss: 1.009394  [   32/  118]
train() client id: f_00009-10-1 loss: 0.838817  [   64/  118]
train() client id: f_00009-10-2 loss: 1.076420  [   96/  118]
train() client id: f_00009-11-0 loss: 1.044466  [   32/  118]
train() client id: f_00009-11-1 loss: 0.985366  [   64/  118]
train() client id: f_00009-11-2 loss: 0.943227  [   96/  118]
train() client id: f_00009-12-0 loss: 1.223384  [   32/  118]
train() client id: f_00009-12-1 loss: 0.822768  [   64/  118]
train() client id: f_00009-12-2 loss: 0.818488  [   96/  118]
At round 65 accuracy: 0.636604774535809
At round 65 training accuracy: 0.5855130784708249
At round 65 training loss: 0.8303264969000841
gradient difference: 0.4514521658420563
train() client id: f_00000-0-0 loss: 1.028710  [   32/  126]
train() client id: f_00000-0-1 loss: 0.910493  [   64/  126]
train() client id: f_00000-0-2 loss: 0.953409  [   96/  126]
train() client id: f_00000-1-0 loss: 1.082083  [   32/  126]
train() client id: f_00000-1-1 loss: 0.914343  [   64/  126]
train() client id: f_00000-1-2 loss: 0.741663  [   96/  126]
train() client id: f_00000-2-0 loss: 1.111132  [   32/  126]
train() client id: f_00000-2-1 loss: 0.698897  [   64/  126]
train() client id: f_00000-2-2 loss: 0.942444  [   96/  126]
train() client id: f_00000-3-0 loss: 0.882295  [   32/  126]
train() client id: f_00000-3-1 loss: 0.916440  [   64/  126]
train() client id: f_00000-3-2 loss: 0.783476  [   96/  126]
train() client id: f_00000-4-0 loss: 0.795043  [   32/  126]
train() client id: f_00000-4-1 loss: 0.869189  [   64/  126]
train() client id: f_00000-4-2 loss: 0.690785  [   96/  126]
train() client id: f_00000-5-0 loss: 0.734861  [   32/  126]
train() client id: f_00000-5-1 loss: 0.769692  [   64/  126]
train() client id: f_00000-5-2 loss: 0.739428  [   96/  126]
train() client id: f_00000-6-0 loss: 0.805117  [   32/  126]
train() client id: f_00000-6-1 loss: 0.889381  [   64/  126]
train() client id: f_00000-6-2 loss: 0.762910  [   96/  126]
train() client id: f_00000-7-0 loss: 0.876881  [   32/  126]
train() client id: f_00000-7-1 loss: 0.800618  [   64/  126]
train() client id: f_00000-7-2 loss: 0.798437  [   96/  126]
train() client id: f_00000-8-0 loss: 0.777952  [   32/  126]
train() client id: f_00000-8-1 loss: 0.821306  [   64/  126]
train() client id: f_00000-8-2 loss: 0.760529  [   96/  126]
train() client id: f_00000-9-0 loss: 0.659438  [   32/  126]
train() client id: f_00000-9-1 loss: 0.859105  [   64/  126]
train() client id: f_00000-9-2 loss: 0.831737  [   96/  126]
train() client id: f_00000-10-0 loss: 0.762681  [   32/  126]
train() client id: f_00000-10-1 loss: 0.892727  [   64/  126]
train() client id: f_00000-10-2 loss: 0.729159  [   96/  126]
train() client id: f_00000-11-0 loss: 0.861602  [   32/  126]
train() client id: f_00000-11-1 loss: 0.769177  [   64/  126]
train() client id: f_00000-11-2 loss: 0.675564  [   96/  126]
train() client id: f_00000-12-0 loss: 0.857576  [   32/  126]
train() client id: f_00000-12-1 loss: 0.661571  [   64/  126]
train() client id: f_00000-12-2 loss: 0.808083  [   96/  126]
train() client id: f_00001-0-0 loss: 0.329891  [   32/  265]
train() client id: f_00001-0-1 loss: 0.381975  [   64/  265]
train() client id: f_00001-0-2 loss: 0.452679  [   96/  265]
train() client id: f_00001-0-3 loss: 0.360672  [  128/  265]
train() client id: f_00001-0-4 loss: 0.266121  [  160/  265]
train() client id: f_00001-0-5 loss: 0.466036  [  192/  265]
train() client id: f_00001-0-6 loss: 0.365777  [  224/  265]
train() client id: f_00001-0-7 loss: 0.443040  [  256/  265]
train() client id: f_00001-1-0 loss: 0.315627  [   32/  265]
train() client id: f_00001-1-1 loss: 0.287016  [   64/  265]
train() client id: f_00001-1-2 loss: 0.429763  [   96/  265]
train() client id: f_00001-1-3 loss: 0.346420  [  128/  265]
train() client id: f_00001-1-4 loss: 0.474760  [  160/  265]
train() client id: f_00001-1-5 loss: 0.388750  [  192/  265]
train() client id: f_00001-1-6 loss: 0.410963  [  224/  265]
train() client id: f_00001-1-7 loss: 0.310831  [  256/  265]
train() client id: f_00001-2-0 loss: 0.278255  [   32/  265]
train() client id: f_00001-2-1 loss: 0.504488  [   64/  265]
train() client id: f_00001-2-2 loss: 0.270803  [   96/  265]
train() client id: f_00001-2-3 loss: 0.430410  [  128/  265]
train() client id: f_00001-2-4 loss: 0.321584  [  160/  265]
train() client id: f_00001-2-5 loss: 0.406470  [  192/  265]
train() client id: f_00001-2-6 loss: 0.397855  [  224/  265]
train() client id: f_00001-2-7 loss: 0.295002  [  256/  265]
train() client id: f_00001-3-0 loss: 0.301804  [   32/  265]
train() client id: f_00001-3-1 loss: 0.477121  [   64/  265]
train() client id: f_00001-3-2 loss: 0.398188  [   96/  265]
train() client id: f_00001-3-3 loss: 0.342244  [  128/  265]
train() client id: f_00001-3-4 loss: 0.344054  [  160/  265]
train() client id: f_00001-3-5 loss: 0.323304  [  192/  265]
train() client id: f_00001-3-6 loss: 0.333613  [  224/  265]
train() client id: f_00001-3-7 loss: 0.340280  [  256/  265]
train() client id: f_00001-4-0 loss: 0.252787  [   32/  265]
train() client id: f_00001-4-1 loss: 0.346769  [   64/  265]
train() client id: f_00001-4-2 loss: 0.354514  [   96/  265]
train() client id: f_00001-4-3 loss: 0.399410  [  128/  265]
train() client id: f_00001-4-4 loss: 0.297213  [  160/  265]
train() client id: f_00001-4-5 loss: 0.403128  [  192/  265]
train() client id: f_00001-4-6 loss: 0.462683  [  224/  265]
train() client id: f_00001-4-7 loss: 0.310817  [  256/  265]
train() client id: f_00001-5-0 loss: 0.514659  [   32/  265]
train() client id: f_00001-5-1 loss: 0.326467  [   64/  265]
train() client id: f_00001-5-2 loss: 0.330146  [   96/  265]
train() client id: f_00001-5-3 loss: 0.254152  [  128/  265]
train() client id: f_00001-5-4 loss: 0.315993  [  160/  265]
train() client id: f_00001-5-5 loss: 0.373229  [  192/  265]
train() client id: f_00001-5-6 loss: 0.371876  [  224/  265]
train() client id: f_00001-5-7 loss: 0.312901  [  256/  265]
train() client id: f_00001-6-0 loss: 0.478423  [   32/  265]
train() client id: f_00001-6-1 loss: 0.256974  [   64/  265]
train() client id: f_00001-6-2 loss: 0.332003  [   96/  265]
train() client id: f_00001-6-3 loss: 0.390489  [  128/  265]
train() client id: f_00001-6-4 loss: 0.262439  [  160/  265]
train() client id: f_00001-6-5 loss: 0.443369  [  192/  265]
train() client id: f_00001-6-6 loss: 0.246736  [  224/  265]
train() client id: f_00001-6-7 loss: 0.324840  [  256/  265]
train() client id: f_00001-7-0 loss: 0.419948  [   32/  265]
train() client id: f_00001-7-1 loss: 0.345500  [   64/  265]
train() client id: f_00001-7-2 loss: 0.480590  [   96/  265]
train() client id: f_00001-7-3 loss: 0.333183  [  128/  265]
train() client id: f_00001-7-4 loss: 0.354505  [  160/  265]
train() client id: f_00001-7-5 loss: 0.267196  [  192/  265]
train() client id: f_00001-7-6 loss: 0.248621  [  224/  265]
train() client id: f_00001-7-7 loss: 0.304369  [  256/  265]
train() client id: f_00001-8-0 loss: 0.626690  [   32/  265]
train() client id: f_00001-8-1 loss: 0.342220  [   64/  265]
train() client id: f_00001-8-2 loss: 0.285536  [   96/  265]
train() client id: f_00001-8-3 loss: 0.347350  [  128/  265]
train() client id: f_00001-8-4 loss: 0.258025  [  160/  265]
train() client id: f_00001-8-5 loss: 0.385099  [  192/  265]
train() client id: f_00001-8-6 loss: 0.251571  [  224/  265]
train() client id: f_00001-8-7 loss: 0.243286  [  256/  265]
train() client id: f_00001-9-0 loss: 0.399141  [   32/  265]
train() client id: f_00001-9-1 loss: 0.298355  [   64/  265]
train() client id: f_00001-9-2 loss: 0.242734  [   96/  265]
train() client id: f_00001-9-3 loss: 0.308852  [  128/  265]
train() client id: f_00001-9-4 loss: 0.249746  [  160/  265]
train() client id: f_00001-9-5 loss: 0.392268  [  192/  265]
train() client id: f_00001-9-6 loss: 0.486432  [  224/  265]
train() client id: f_00001-9-7 loss: 0.315947  [  256/  265]
train() client id: f_00001-10-0 loss: 0.255357  [   32/  265]
train() client id: f_00001-10-1 loss: 0.332181  [   64/  265]
train() client id: f_00001-10-2 loss: 0.475334  [   96/  265]
train() client id: f_00001-10-3 loss: 0.278190  [  128/  265]
train() client id: f_00001-10-4 loss: 0.276516  [  160/  265]
train() client id: f_00001-10-5 loss: 0.329546  [  192/  265]
train() client id: f_00001-10-6 loss: 0.425287  [  224/  265]
train() client id: f_00001-10-7 loss: 0.257382  [  256/  265]
train() client id: f_00001-11-0 loss: 0.424159  [   32/  265]
train() client id: f_00001-11-1 loss: 0.403133  [   64/  265]
train() client id: f_00001-11-2 loss: 0.280884  [   96/  265]
train() client id: f_00001-11-3 loss: 0.290074  [  128/  265]
train() client id: f_00001-11-4 loss: 0.248579  [  160/  265]
train() client id: f_00001-11-5 loss: 0.241264  [  192/  265]
train() client id: f_00001-11-6 loss: 0.410285  [  224/  265]
train() client id: f_00001-11-7 loss: 0.366267  [  256/  265]
train() client id: f_00001-12-0 loss: 0.366682  [   32/  265]
train() client id: f_00001-12-1 loss: 0.265912  [   64/  265]
train() client id: f_00001-12-2 loss: 0.495760  [   96/  265]
train() client id: f_00001-12-3 loss: 0.249680  [  128/  265]
train() client id: f_00001-12-4 loss: 0.354161  [  160/  265]
train() client id: f_00001-12-5 loss: 0.333578  [  192/  265]
train() client id: f_00001-12-6 loss: 0.280897  [  224/  265]
train() client id: f_00001-12-7 loss: 0.348971  [  256/  265]
train() client id: f_00002-0-0 loss: 1.104982  [   32/  124]
train() client id: f_00002-0-1 loss: 0.946784  [   64/  124]
train() client id: f_00002-0-2 loss: 1.185180  [   96/  124]
train() client id: f_00002-1-0 loss: 1.338701  [   32/  124]
train() client id: f_00002-1-1 loss: 0.988727  [   64/  124]
train() client id: f_00002-1-2 loss: 0.941853  [   96/  124]
train() client id: f_00002-2-0 loss: 1.014644  [   32/  124]
train() client id: f_00002-2-1 loss: 0.995129  [   64/  124]
train() client id: f_00002-2-2 loss: 0.987043  [   96/  124]
train() client id: f_00002-3-0 loss: 0.920687  [   32/  124]
train() client id: f_00002-3-1 loss: 1.080711  [   64/  124]
train() client id: f_00002-3-2 loss: 1.007223  [   96/  124]
train() client id: f_00002-4-0 loss: 0.959515  [   32/  124]
train() client id: f_00002-4-1 loss: 1.117787  [   64/  124]
train() client id: f_00002-4-2 loss: 0.953716  [   96/  124]
train() client id: f_00002-5-0 loss: 0.918680  [   32/  124]
train() client id: f_00002-5-1 loss: 0.955694  [   64/  124]
train() client id: f_00002-5-2 loss: 1.086466  [   96/  124]
train() client id: f_00002-6-0 loss: 0.731144  [   32/  124]
train() client id: f_00002-6-1 loss: 1.034125  [   64/  124]
train() client id: f_00002-6-2 loss: 1.113539  [   96/  124]
train() client id: f_00002-7-0 loss: 0.832903  [   32/  124]
train() client id: f_00002-7-1 loss: 0.886731  [   64/  124]
train() client id: f_00002-7-2 loss: 1.141529  [   96/  124]
train() client id: f_00002-8-0 loss: 1.097994  [   32/  124]
train() client id: f_00002-8-1 loss: 1.039470  [   64/  124]
train() client id: f_00002-8-2 loss: 0.921212  [   96/  124]
train() client id: f_00002-9-0 loss: 0.910542  [   32/  124]
train() client id: f_00002-9-1 loss: 0.992205  [   64/  124]
train() client id: f_00002-9-2 loss: 0.798494  [   96/  124]
train() client id: f_00002-10-0 loss: 0.926206  [   32/  124]
train() client id: f_00002-10-1 loss: 1.027804  [   64/  124]
train() client id: f_00002-10-2 loss: 0.827518  [   96/  124]
train() client id: f_00002-11-0 loss: 0.814887  [   32/  124]
train() client id: f_00002-11-1 loss: 1.050535  [   64/  124]
train() client id: f_00002-11-2 loss: 1.049157  [   96/  124]
train() client id: f_00002-12-0 loss: 1.024743  [   32/  124]
train() client id: f_00002-12-1 loss: 0.812984  [   64/  124]
train() client id: f_00002-12-2 loss: 0.737481  [   96/  124]
train() client id: f_00003-0-0 loss: 0.664430  [   32/   43]
train() client id: f_00003-1-0 loss: 0.766668  [   32/   43]
train() client id: f_00003-2-0 loss: 0.770164  [   32/   43]
train() client id: f_00003-3-0 loss: 0.706633  [   32/   43]
train() client id: f_00003-4-0 loss: 0.552259  [   32/   43]
train() client id: f_00003-5-0 loss: 0.595671  [   32/   43]
train() client id: f_00003-6-0 loss: 0.500120  [   32/   43]
train() client id: f_00003-7-0 loss: 0.745205  [   32/   43]
train() client id: f_00003-8-0 loss: 0.737900  [   32/   43]
train() client id: f_00003-9-0 loss: 0.458195  [   32/   43]
train() client id: f_00003-10-0 loss: 0.622156  [   32/   43]
train() client id: f_00003-11-0 loss: 0.501353  [   32/   43]
train() client id: f_00003-12-0 loss: 0.531951  [   32/   43]
train() client id: f_00004-0-0 loss: 0.697522  [   32/  306]
train() client id: f_00004-0-1 loss: 0.662950  [   64/  306]
train() client id: f_00004-0-2 loss: 0.713045  [   96/  306]
train() client id: f_00004-0-3 loss: 0.860735  [  128/  306]
train() client id: f_00004-0-4 loss: 0.705084  [  160/  306]
train() client id: f_00004-0-5 loss: 0.870906  [  192/  306]
train() client id: f_00004-0-6 loss: 0.822905  [  224/  306]
train() client id: f_00004-0-7 loss: 0.775090  [  256/  306]
train() client id: f_00004-0-8 loss: 0.955848  [  288/  306]
train() client id: f_00004-1-0 loss: 0.723135  [   32/  306]
train() client id: f_00004-1-1 loss: 0.618003  [   64/  306]
train() client id: f_00004-1-2 loss: 0.784102  [   96/  306]
train() client id: f_00004-1-3 loss: 0.771236  [  128/  306]
train() client id: f_00004-1-4 loss: 0.910839  [  160/  306]
train() client id: f_00004-1-5 loss: 0.782068  [  192/  306]
train() client id: f_00004-1-6 loss: 0.960174  [  224/  306]
train() client id: f_00004-1-7 loss: 0.759368  [  256/  306]
train() client id: f_00004-1-8 loss: 0.694495  [  288/  306]
train() client id: f_00004-2-0 loss: 0.835857  [   32/  306]
train() client id: f_00004-2-1 loss: 0.766900  [   64/  306]
train() client id: f_00004-2-2 loss: 0.838826  [   96/  306]
train() client id: f_00004-2-3 loss: 0.827678  [  128/  306]
train() client id: f_00004-2-4 loss: 0.774846  [  160/  306]
train() client id: f_00004-2-5 loss: 0.672781  [  192/  306]
train() client id: f_00004-2-6 loss: 0.811906  [  224/  306]
train() client id: f_00004-2-7 loss: 0.767546  [  256/  306]
train() client id: f_00004-2-8 loss: 0.681112  [  288/  306]
train() client id: f_00004-3-0 loss: 0.865313  [   32/  306]
train() client id: f_00004-3-1 loss: 0.772320  [   64/  306]
train() client id: f_00004-3-2 loss: 0.845632  [   96/  306]
train() client id: f_00004-3-3 loss: 0.748896  [  128/  306]
train() client id: f_00004-3-4 loss: 0.823323  [  160/  306]
train() client id: f_00004-3-5 loss: 0.713608  [  192/  306]
train() client id: f_00004-3-6 loss: 0.668655  [  224/  306]
train() client id: f_00004-3-7 loss: 0.721379  [  256/  306]
train() client id: f_00004-3-8 loss: 0.831174  [  288/  306]
train() client id: f_00004-4-0 loss: 0.704289  [   32/  306]
train() client id: f_00004-4-1 loss: 0.802643  [   64/  306]
train() client id: f_00004-4-2 loss: 0.952253  [   96/  306]
train() client id: f_00004-4-3 loss: 0.754269  [  128/  306]
train() client id: f_00004-4-4 loss: 0.721385  [  160/  306]
train() client id: f_00004-4-5 loss: 0.880061  [  192/  306]
train() client id: f_00004-4-6 loss: 0.817660  [  224/  306]
train() client id: f_00004-4-7 loss: 0.722925  [  256/  306]
train() client id: f_00004-4-8 loss: 0.716319  [  288/  306]
train() client id: f_00004-5-0 loss: 0.761922  [   32/  306]
train() client id: f_00004-5-1 loss: 0.690591  [   64/  306]
train() client id: f_00004-5-2 loss: 0.849198  [   96/  306]
train() client id: f_00004-5-3 loss: 0.766057  [  128/  306]
train() client id: f_00004-5-4 loss: 0.813152  [  160/  306]
train() client id: f_00004-5-5 loss: 0.780775  [  192/  306]
train() client id: f_00004-5-6 loss: 0.792096  [  224/  306]
train() client id: f_00004-5-7 loss: 0.691336  [  256/  306]
train() client id: f_00004-5-8 loss: 0.753164  [  288/  306]
train() client id: f_00004-6-0 loss: 0.800901  [   32/  306]
train() client id: f_00004-6-1 loss: 0.819179  [   64/  306]
train() client id: f_00004-6-2 loss: 0.864516  [   96/  306]
train() client id: f_00004-6-3 loss: 0.701869  [  128/  306]
train() client id: f_00004-6-4 loss: 0.784736  [  160/  306]
train() client id: f_00004-6-5 loss: 0.847864  [  192/  306]
train() client id: f_00004-6-6 loss: 0.657335  [  224/  306]
train() client id: f_00004-6-7 loss: 0.743189  [  256/  306]
train() client id: f_00004-6-8 loss: 0.866828  [  288/  306]
train() client id: f_00004-7-0 loss: 0.712530  [   32/  306]
train() client id: f_00004-7-1 loss: 0.776302  [   64/  306]
train() client id: f_00004-7-2 loss: 0.799651  [   96/  306]
train() client id: f_00004-7-3 loss: 0.819824  [  128/  306]
train() client id: f_00004-7-4 loss: 0.818062  [  160/  306]
train() client id: f_00004-7-5 loss: 0.841077  [  192/  306]
train() client id: f_00004-7-6 loss: 0.763943  [  224/  306]
train() client id: f_00004-7-7 loss: 0.816029  [  256/  306]
train() client id: f_00004-7-8 loss: 0.671979  [  288/  306]
train() client id: f_00004-8-0 loss: 0.738313  [   32/  306]
train() client id: f_00004-8-1 loss: 0.737732  [   64/  306]
train() client id: f_00004-8-2 loss: 0.843544  [   96/  306]
train() client id: f_00004-8-3 loss: 0.777631  [  128/  306]
train() client id: f_00004-8-4 loss: 0.691011  [  160/  306]
train() client id: f_00004-8-5 loss: 0.789756  [  192/  306]
train() client id: f_00004-8-6 loss: 0.873991  [  224/  306]
train() client id: f_00004-8-7 loss: 0.759757  [  256/  306]
train() client id: f_00004-8-8 loss: 0.762793  [  288/  306]
train() client id: f_00004-9-0 loss: 0.822026  [   32/  306]
train() client id: f_00004-9-1 loss: 0.797131  [   64/  306]
train() client id: f_00004-9-2 loss: 0.878139  [   96/  306]
train() client id: f_00004-9-3 loss: 0.677327  [  128/  306]
train() client id: f_00004-9-4 loss: 0.783426  [  160/  306]
train() client id: f_00004-9-5 loss: 0.741143  [  192/  306]
train() client id: f_00004-9-6 loss: 0.770225  [  224/  306]
train() client id: f_00004-9-7 loss: 0.735306  [  256/  306]
train() client id: f_00004-9-8 loss: 0.803693  [  288/  306]
train() client id: f_00004-10-0 loss: 0.627915  [   32/  306]
train() client id: f_00004-10-1 loss: 0.873622  [   64/  306]
train() client id: f_00004-10-2 loss: 0.721461  [   96/  306]
train() client id: f_00004-10-3 loss: 0.898842  [  128/  306]
train() client id: f_00004-10-4 loss: 0.788417  [  160/  306]
train() client id: f_00004-10-5 loss: 0.762028  [  192/  306]
train() client id: f_00004-10-6 loss: 0.807902  [  224/  306]
train() client id: f_00004-10-7 loss: 0.818401  [  256/  306]
train() client id: f_00004-10-8 loss: 0.815672  [  288/  306]
train() client id: f_00004-11-0 loss: 0.775780  [   32/  306]
train() client id: f_00004-11-1 loss: 0.997338  [   64/  306]
train() client id: f_00004-11-2 loss: 0.746918  [   96/  306]
train() client id: f_00004-11-3 loss: 0.659362  [  128/  306]
train() client id: f_00004-11-4 loss: 0.716176  [  160/  306]
train() client id: f_00004-11-5 loss: 0.793066  [  192/  306]
train() client id: f_00004-11-6 loss: 0.789855  [  224/  306]
train() client id: f_00004-11-7 loss: 0.868824  [  256/  306]
train() client id: f_00004-11-8 loss: 0.761804  [  288/  306]
train() client id: f_00004-12-0 loss: 0.815653  [   32/  306]
train() client id: f_00004-12-1 loss: 0.763869  [   64/  306]
train() client id: f_00004-12-2 loss: 0.778955  [   96/  306]
train() client id: f_00004-12-3 loss: 0.886945  [  128/  306]
train() client id: f_00004-12-4 loss: 0.809735  [  160/  306]
train() client id: f_00004-12-5 loss: 0.696921  [  192/  306]
train() client id: f_00004-12-6 loss: 0.830175  [  224/  306]
train() client id: f_00004-12-7 loss: 0.689971  [  256/  306]
train() client id: f_00004-12-8 loss: 0.770710  [  288/  306]
train() client id: f_00005-0-0 loss: 0.329552  [   32/  146]
train() client id: f_00005-0-1 loss: 0.354786  [   64/  146]
train() client id: f_00005-0-2 loss: 0.688428  [   96/  146]
train() client id: f_00005-0-3 loss: 0.547495  [  128/  146]
train() client id: f_00005-1-0 loss: 0.481548  [   32/  146]
train() client id: f_00005-1-1 loss: 0.617814  [   64/  146]
train() client id: f_00005-1-2 loss: 0.255058  [   96/  146]
train() client id: f_00005-1-3 loss: 0.368672  [  128/  146]
train() client id: f_00005-2-0 loss: 0.653338  [   32/  146]
train() client id: f_00005-2-1 loss: 0.526894  [   64/  146]
train() client id: f_00005-2-2 loss: 0.331505  [   96/  146]
train() client id: f_00005-2-3 loss: 0.246440  [  128/  146]
train() client id: f_00005-3-0 loss: 0.516721  [   32/  146]
train() client id: f_00005-3-1 loss: 0.317786  [   64/  146]
train() client id: f_00005-3-2 loss: 0.641742  [   96/  146]
train() client id: f_00005-3-3 loss: 0.395333  [  128/  146]
train() client id: f_00005-4-0 loss: 0.495657  [   32/  146]
train() client id: f_00005-4-1 loss: 0.519227  [   64/  146]
train() client id: f_00005-4-2 loss: 0.506545  [   96/  146]
train() client id: f_00005-4-3 loss: 0.376677  [  128/  146]
train() client id: f_00005-5-0 loss: 0.230162  [   32/  146]
train() client id: f_00005-5-1 loss: 0.656053  [   64/  146]
train() client id: f_00005-5-2 loss: 0.834898  [   96/  146]
train() client id: f_00005-5-3 loss: 0.262429  [  128/  146]
train() client id: f_00005-6-0 loss: 0.358628  [   32/  146]
train() client id: f_00005-6-1 loss: 0.332280  [   64/  146]
train() client id: f_00005-6-2 loss: 0.680271  [   96/  146]
train() client id: f_00005-6-3 loss: 0.550696  [  128/  146]
train() client id: f_00005-7-0 loss: 0.623444  [   32/  146]
train() client id: f_00005-7-1 loss: 0.411437  [   64/  146]
train() client id: f_00005-7-2 loss: 0.190555  [   96/  146]
train() client id: f_00005-7-3 loss: 0.685601  [  128/  146]
train() client id: f_00005-8-0 loss: 0.326082  [   32/  146]
train() client id: f_00005-8-1 loss: 0.689098  [   64/  146]
train() client id: f_00005-8-2 loss: 0.371052  [   96/  146]
train() client id: f_00005-8-3 loss: 0.451018  [  128/  146]
train() client id: f_00005-9-0 loss: 0.213426  [   32/  146]
train() client id: f_00005-9-1 loss: 0.537138  [   64/  146]
train() client id: f_00005-9-2 loss: 0.488244  [   96/  146]
train() client id: f_00005-9-3 loss: 0.425242  [  128/  146]
train() client id: f_00005-10-0 loss: 0.498714  [   32/  146]
train() client id: f_00005-10-1 loss: 0.569554  [   64/  146]
train() client id: f_00005-10-2 loss: 0.370461  [   96/  146]
train() client id: f_00005-10-3 loss: 0.227872  [  128/  146]
train() client id: f_00005-11-0 loss: 0.397491  [   32/  146]
train() client id: f_00005-11-1 loss: 0.649230  [   64/  146]
train() client id: f_00005-11-2 loss: 0.210440  [   96/  146]
train() client id: f_00005-11-3 loss: 0.440256  [  128/  146]
train() client id: f_00005-12-0 loss: 0.519701  [   32/  146]
train() client id: f_00005-12-1 loss: 0.155058  [   64/  146]
train() client id: f_00005-12-2 loss: 0.619341  [   96/  146]
train() client id: f_00005-12-3 loss: 0.439449  [  128/  146]
train() client id: f_00006-0-0 loss: 0.468273  [   32/   54]
train() client id: f_00006-1-0 loss: 0.422977  [   32/   54]
train() client id: f_00006-2-0 loss: 0.521140  [   32/   54]
train() client id: f_00006-3-0 loss: 0.408302  [   32/   54]
train() client id: f_00006-4-0 loss: 0.504756  [   32/   54]
train() client id: f_00006-5-0 loss: 0.524935  [   32/   54]
train() client id: f_00006-6-0 loss: 0.478229  [   32/   54]
train() client id: f_00006-7-0 loss: 0.525297  [   32/   54]
train() client id: f_00006-8-0 loss: 0.430983  [   32/   54]
train() client id: f_00006-9-0 loss: 0.510239  [   32/   54]
train() client id: f_00006-10-0 loss: 0.476476  [   32/   54]
train() client id: f_00006-11-0 loss: 0.455107  [   32/   54]
train() client id: f_00006-12-0 loss: 0.521690  [   32/   54]
train() client id: f_00007-0-0 loss: 0.584825  [   32/  179]
train() client id: f_00007-0-1 loss: 0.780226  [   64/  179]
train() client id: f_00007-0-2 loss: 0.633790  [   96/  179]
train() client id: f_00007-0-3 loss: 0.408841  [  128/  179]
train() client id: f_00007-0-4 loss: 0.659713  [  160/  179]
train() client id: f_00007-1-0 loss: 0.592116  [   32/  179]
train() client id: f_00007-1-1 loss: 0.647912  [   64/  179]
train() client id: f_00007-1-2 loss: 0.629485  [   96/  179]
train() client id: f_00007-1-3 loss: 0.509063  [  128/  179]
train() client id: f_00007-1-4 loss: 0.487905  [  160/  179]
train() client id: f_00007-2-0 loss: 0.439035  [   32/  179]
train() client id: f_00007-2-1 loss: 0.785716  [   64/  179]
train() client id: f_00007-2-2 loss: 0.578187  [   96/  179]
train() client id: f_00007-2-3 loss: 0.495067  [  128/  179]
train() client id: f_00007-2-4 loss: 0.373333  [  160/  179]
train() client id: f_00007-3-0 loss: 0.577962  [   32/  179]
train() client id: f_00007-3-1 loss: 0.617660  [   64/  179]
train() client id: f_00007-3-2 loss: 0.469030  [   96/  179]
train() client id: f_00007-3-3 loss: 0.499293  [  128/  179]
train() client id: f_00007-3-4 loss: 0.588662  [  160/  179]
train() client id: f_00007-4-0 loss: 0.738973  [   32/  179]
train() client id: f_00007-4-1 loss: 0.693196  [   64/  179]
train() client id: f_00007-4-2 loss: 0.395753  [   96/  179]
train() client id: f_00007-4-3 loss: 0.453127  [  128/  179]
train() client id: f_00007-4-4 loss: 0.461502  [  160/  179]
train() client id: f_00007-5-0 loss: 0.409407  [   32/  179]
train() client id: f_00007-5-1 loss: 0.565618  [   64/  179]
train() client id: f_00007-5-2 loss: 0.524602  [   96/  179]
train() client id: f_00007-5-3 loss: 0.476266  [  128/  179]
train() client id: f_00007-5-4 loss: 0.679388  [  160/  179]
train() client id: f_00007-6-0 loss: 0.670246  [   32/  179]
train() client id: f_00007-6-1 loss: 0.488674  [   64/  179]
train() client id: f_00007-6-2 loss: 0.575475  [   96/  179]
train() client id: f_00007-6-3 loss: 0.434337  [  128/  179]
train() client id: f_00007-6-4 loss: 0.610398  [  160/  179]
train() client id: f_00007-7-0 loss: 0.821500  [   32/  179]
train() client id: f_00007-7-1 loss: 0.480648  [   64/  179]
train() client id: f_00007-7-2 loss: 0.515289  [   96/  179]
train() client id: f_00007-7-3 loss: 0.563549  [  128/  179]
train() client id: f_00007-7-4 loss: 0.361786  [  160/  179]
train() client id: f_00007-8-0 loss: 0.625541  [   32/  179]
train() client id: f_00007-8-1 loss: 0.487237  [   64/  179]
train() client id: f_00007-8-2 loss: 0.448659  [   96/  179]
train() client id: f_00007-8-3 loss: 0.440673  [  128/  179]
train() client id: f_00007-8-4 loss: 0.506105  [  160/  179]
train() client id: f_00007-9-0 loss: 0.865397  [   32/  179]
train() client id: f_00007-9-1 loss: 0.481473  [   64/  179]
train() client id: f_00007-9-2 loss: 0.551262  [   96/  179]
train() client id: f_00007-9-3 loss: 0.365632  [  128/  179]
train() client id: f_00007-9-4 loss: 0.479963  [  160/  179]
train() client id: f_00007-10-0 loss: 0.456506  [   32/  179]
train() client id: f_00007-10-1 loss: 0.435038  [   64/  179]
train() client id: f_00007-10-2 loss: 0.643887  [   96/  179]
train() client id: f_00007-10-3 loss: 0.663508  [  128/  179]
train() client id: f_00007-10-4 loss: 0.506505  [  160/  179]
train() client id: f_00007-11-0 loss: 0.700462  [   32/  179]
train() client id: f_00007-11-1 loss: 0.387139  [   64/  179]
train() client id: f_00007-11-2 loss: 0.570357  [   96/  179]
train() client id: f_00007-11-3 loss: 0.637661  [  128/  179]
train() client id: f_00007-11-4 loss: 0.328337  [  160/  179]
train() client id: f_00007-12-0 loss: 0.349042  [   32/  179]
train() client id: f_00007-12-1 loss: 0.465571  [   64/  179]
train() client id: f_00007-12-2 loss: 0.451177  [   96/  179]
train() client id: f_00007-12-3 loss: 0.775307  [  128/  179]
train() client id: f_00007-12-4 loss: 0.490085  [  160/  179]
train() client id: f_00008-0-0 loss: 0.774277  [   32/  130]
train() client id: f_00008-0-1 loss: 0.671323  [   64/  130]
train() client id: f_00008-0-2 loss: 0.689722  [   96/  130]
train() client id: f_00008-0-3 loss: 0.627470  [  128/  130]
train() client id: f_00008-1-0 loss: 0.769940  [   32/  130]
train() client id: f_00008-1-1 loss: 0.611607  [   64/  130]
train() client id: f_00008-1-2 loss: 0.692238  [   96/  130]
train() client id: f_00008-1-3 loss: 0.683299  [  128/  130]
train() client id: f_00008-2-0 loss: 0.674970  [   32/  130]
train() client id: f_00008-2-1 loss: 0.752286  [   64/  130]
train() client id: f_00008-2-2 loss: 0.698653  [   96/  130]
train() client id: f_00008-2-3 loss: 0.591535  [  128/  130]
train() client id: f_00008-3-0 loss: 0.687993  [   32/  130]
train() client id: f_00008-3-1 loss: 0.805822  [   64/  130]
train() client id: f_00008-3-2 loss: 0.667188  [   96/  130]
train() client id: f_00008-3-3 loss: 0.605812  [  128/  130]
train() client id: f_00008-4-0 loss: 0.649416  [   32/  130]
train() client id: f_00008-4-1 loss: 0.594806  [   64/  130]
train() client id: f_00008-4-2 loss: 0.751781  [   96/  130]
train() client id: f_00008-4-3 loss: 0.729775  [  128/  130]
train() client id: f_00008-5-0 loss: 0.587929  [   32/  130]
train() client id: f_00008-5-1 loss: 0.742819  [   64/  130]
train() client id: f_00008-5-2 loss: 0.704868  [   96/  130]
train() client id: f_00008-5-3 loss: 0.717620  [  128/  130]
train() client id: f_00008-6-0 loss: 0.744174  [   32/  130]
train() client id: f_00008-6-1 loss: 0.696451  [   64/  130]
train() client id: f_00008-6-2 loss: 0.592414  [   96/  130]
train() client id: f_00008-6-3 loss: 0.695366  [  128/  130]
train() client id: f_00008-7-0 loss: 0.660402  [   32/  130]
train() client id: f_00008-7-1 loss: 0.640406  [   64/  130]
train() client id: f_00008-7-2 loss: 0.841777  [   96/  130]
train() client id: f_00008-7-3 loss: 0.620411  [  128/  130]
train() client id: f_00008-8-0 loss: 0.677225  [   32/  130]
train() client id: f_00008-8-1 loss: 0.623840  [   64/  130]
train() client id: f_00008-8-2 loss: 0.730784  [   96/  130]
train() client id: f_00008-8-3 loss: 0.716600  [  128/  130]
train() client id: f_00008-9-0 loss: 0.670399  [   32/  130]
train() client id: f_00008-9-1 loss: 0.645017  [   64/  130]
train() client id: f_00008-9-2 loss: 0.788435  [   96/  130]
train() client id: f_00008-9-3 loss: 0.647403  [  128/  130]
train() client id: f_00008-10-0 loss: 0.802727  [   32/  130]
train() client id: f_00008-10-1 loss: 0.641049  [   64/  130]
train() client id: f_00008-10-2 loss: 0.628047  [   96/  130]
train() client id: f_00008-10-3 loss: 0.686408  [  128/  130]
train() client id: f_00008-11-0 loss: 0.604685  [   32/  130]
train() client id: f_00008-11-1 loss: 0.720050  [   64/  130]
train() client id: f_00008-11-2 loss: 0.639997  [   96/  130]
train() client id: f_00008-11-3 loss: 0.800169  [  128/  130]
train() client id: f_00008-12-0 loss: 0.610178  [   32/  130]
train() client id: f_00008-12-1 loss: 0.713679  [   64/  130]
train() client id: f_00008-12-2 loss: 0.701107  [   96/  130]
train() client id: f_00008-12-3 loss: 0.736998  [  128/  130]
train() client id: f_00009-0-0 loss: 1.215533  [   32/  118]
train() client id: f_00009-0-1 loss: 1.110206  [   64/  118]
train() client id: f_00009-0-2 loss: 1.261517  [   96/  118]
train() client id: f_00009-1-0 loss: 1.246684  [   32/  118]
train() client id: f_00009-1-1 loss: 1.153494  [   64/  118]
train() client id: f_00009-1-2 loss: 1.148103  [   96/  118]
train() client id: f_00009-2-0 loss: 1.175898  [   32/  118]
train() client id: f_00009-2-1 loss: 1.091710  [   64/  118]
train() client id: f_00009-2-2 loss: 1.043557  [   96/  118]
train() client id: f_00009-3-0 loss: 1.090472  [   32/  118]
train() client id: f_00009-3-1 loss: 1.094609  [   64/  118]
train() client id: f_00009-3-2 loss: 1.019067  [   96/  118]
train() client id: f_00009-4-0 loss: 1.061130  [   32/  118]
train() client id: f_00009-4-1 loss: 1.062701  [   64/  118]
train() client id: f_00009-4-2 loss: 1.079339  [   96/  118]
train() client id: f_00009-5-0 loss: 0.893788  [   32/  118]
train() client id: f_00009-5-1 loss: 1.003192  [   64/  118]
train() client id: f_00009-5-2 loss: 1.046929  [   96/  118]
train() client id: f_00009-6-0 loss: 1.120009  [   32/  118]
train() client id: f_00009-6-1 loss: 0.827527  [   64/  118]
train() client id: f_00009-6-2 loss: 1.034640  [   96/  118]
train() client id: f_00009-7-0 loss: 0.979729  [   32/  118]
train() client id: f_00009-7-1 loss: 1.036921  [   64/  118]
train() client id: f_00009-7-2 loss: 1.001948  [   96/  118]
train() client id: f_00009-8-0 loss: 0.835004  [   32/  118]
train() client id: f_00009-8-1 loss: 1.015782  [   64/  118]
train() client id: f_00009-8-2 loss: 1.049282  [   96/  118]
train() client id: f_00009-9-0 loss: 0.891457  [   32/  118]
train() client id: f_00009-9-1 loss: 0.911592  [   64/  118]
train() client id: f_00009-9-2 loss: 1.037228  [   96/  118]
train() client id: f_00009-10-0 loss: 0.904379  [   32/  118]
train() client id: f_00009-10-1 loss: 0.873636  [   64/  118]
train() client id: f_00009-10-2 loss: 0.923697  [   96/  118]
train() client id: f_00009-11-0 loss: 0.991576  [   32/  118]
train() client id: f_00009-11-1 loss: 0.987323  [   64/  118]
train() client id: f_00009-11-2 loss: 0.923555  [   96/  118]
train() client id: f_00009-12-0 loss: 0.943754  [   32/  118]
train() client id: f_00009-12-1 loss: 1.026824  [   64/  118]
train() client id: f_00009-12-2 loss: 0.813526  [   96/  118]
At round 66 accuracy: 0.636604774535809
At round 66 training accuracy: 0.5868544600938967
At round 66 training loss: 0.8272423290960506
gradient difference: 0.3953595757484436
train() client id: f_00000-0-0 loss: 1.389079  [   32/  126]
train() client id: f_00000-0-1 loss: 1.121501  [   64/  126]
train() client id: f_00000-0-2 loss: 1.108010  [   96/  126]
train() client id: f_00000-1-0 loss: 1.162901  [   32/  126]
train() client id: f_00000-1-1 loss: 0.993899  [   64/  126]
train() client id: f_00000-1-2 loss: 1.145965  [   96/  126]
train() client id: f_00000-2-0 loss: 1.195646  [   32/  126]
train() client id: f_00000-2-1 loss: 1.010241  [   64/  126]
train() client id: f_00000-2-2 loss: 0.878538  [   96/  126]
train() client id: f_00000-3-0 loss: 0.844532  [   32/  126]
train() client id: f_00000-3-1 loss: 0.992623  [   64/  126]
train() client id: f_00000-3-2 loss: 1.037225  [   96/  126]
train() client id: f_00000-4-0 loss: 1.017093  [   32/  126]
train() client id: f_00000-4-1 loss: 0.928927  [   64/  126]
train() client id: f_00000-4-2 loss: 0.965309  [   96/  126]
train() client id: f_00000-5-0 loss: 0.851399  [   32/  126]
train() client id: f_00000-5-1 loss: 0.906201  [   64/  126]
train() client id: f_00000-5-2 loss: 0.894203  [   96/  126]
train() client id: f_00000-6-0 loss: 1.024201  [   32/  126]
train() client id: f_00000-6-1 loss: 0.979877  [   64/  126]
train() client id: f_00000-6-2 loss: 0.728283  [   96/  126]
train() client id: f_00000-7-0 loss: 0.853575  [   32/  126]
train() client id: f_00000-7-1 loss: 0.724790  [   64/  126]
train() client id: f_00000-7-2 loss: 0.942196  [   96/  126]
train() client id: f_00000-8-0 loss: 0.775844  [   32/  126]
train() client id: f_00000-8-1 loss: 0.808924  [   64/  126]
train() client id: f_00000-8-2 loss: 0.768750  [   96/  126]
train() client id: f_00000-9-0 loss: 0.909629  [   32/  126]
train() client id: f_00000-9-1 loss: 0.900439  [   64/  126]
train() client id: f_00000-9-2 loss: 0.832370  [   96/  126]
train() client id: f_00000-10-0 loss: 0.963184  [   32/  126]
train() client id: f_00000-10-1 loss: 0.789532  [   64/  126]
train() client id: f_00000-10-2 loss: 0.796593  [   96/  126]
train() client id: f_00000-11-0 loss: 0.756376  [   32/  126]
train() client id: f_00000-11-1 loss: 0.765609  [   64/  126]
train() client id: f_00000-11-2 loss: 0.908988  [   96/  126]
train() client id: f_00000-12-0 loss: 0.724475  [   32/  126]
train() client id: f_00000-12-1 loss: 0.769787  [   64/  126]
train() client id: f_00000-12-2 loss: 0.946874  [   96/  126]
train() client id: f_00001-0-0 loss: 0.518137  [   32/  265]
train() client id: f_00001-0-1 loss: 0.480693  [   64/  265]
train() client id: f_00001-0-2 loss: 0.370391  [   96/  265]
train() client id: f_00001-0-3 loss: 0.352183  [  128/  265]
train() client id: f_00001-0-4 loss: 0.357368  [  160/  265]
train() client id: f_00001-0-5 loss: 0.388602  [  192/  265]
train() client id: f_00001-0-6 loss: 0.398351  [  224/  265]
train() client id: f_00001-0-7 loss: 0.417000  [  256/  265]
train() client id: f_00001-1-0 loss: 0.278261  [   32/  265]
train() client id: f_00001-1-1 loss: 0.422134  [   64/  265]
train() client id: f_00001-1-2 loss: 0.470081  [   96/  265]
train() client id: f_00001-1-3 loss: 0.430122  [  128/  265]
train() client id: f_00001-1-4 loss: 0.352969  [  160/  265]
train() client id: f_00001-1-5 loss: 0.494989  [  192/  265]
train() client id: f_00001-1-6 loss: 0.319553  [  224/  265]
train() client id: f_00001-1-7 loss: 0.497604  [  256/  265]
train() client id: f_00001-2-0 loss: 0.447670  [   32/  265]
train() client id: f_00001-2-1 loss: 0.357875  [   64/  265]
train() client id: f_00001-2-2 loss: 0.311375  [   96/  265]
train() client id: f_00001-2-3 loss: 0.339220  [  128/  265]
train() client id: f_00001-2-4 loss: 0.521108  [  160/  265]
train() client id: f_00001-2-5 loss: 0.339524  [  192/  265]
train() client id: f_00001-2-6 loss: 0.368509  [  224/  265]
train() client id: f_00001-2-7 loss: 0.459169  [  256/  265]
train() client id: f_00001-3-0 loss: 0.305126  [   32/  265]
train() client id: f_00001-3-1 loss: 0.523736  [   64/  265]
train() client id: f_00001-3-2 loss: 0.306303  [   96/  265]
train() client id: f_00001-3-3 loss: 0.510640  [  128/  265]
train() client id: f_00001-3-4 loss: 0.416837  [  160/  265]
train() client id: f_00001-3-5 loss: 0.312074  [  192/  265]
train() client id: f_00001-3-6 loss: 0.320785  [  224/  265]
train() client id: f_00001-3-7 loss: 0.374601  [  256/  265]
train() client id: f_00001-4-0 loss: 0.327375  [   32/  265]
train() client id: f_00001-4-1 loss: 0.344908  [   64/  265]
train() client id: f_00001-4-2 loss: 0.502342  [   96/  265]
train() client id: f_00001-4-3 loss: 0.421939  [  128/  265]
train() client id: f_00001-4-4 loss: 0.358598  [  160/  265]
train() client id: f_00001-4-5 loss: 0.443680  [  192/  265]
train() client id: f_00001-4-6 loss: 0.384034  [  224/  265]
train() client id: f_00001-4-7 loss: 0.321245  [  256/  265]
train() client id: f_00001-5-0 loss: 0.364518  [   32/  265]
train() client id: f_00001-5-1 loss: 0.278754  [   64/  265]
train() client id: f_00001-5-2 loss: 0.279951  [   96/  265]
train() client id: f_00001-5-3 loss: 0.342379  [  128/  265]
train() client id: f_00001-5-4 loss: 0.370218  [  160/  265]
train() client id: f_00001-5-5 loss: 0.389729  [  192/  265]
train() client id: f_00001-5-6 loss: 0.547200  [  224/  265]
train() client id: f_00001-5-7 loss: 0.510790  [  256/  265]
train() client id: f_00001-6-0 loss: 0.405979  [   32/  265]
train() client id: f_00001-6-1 loss: 0.379069  [   64/  265]
train() client id: f_00001-6-2 loss: 0.291680  [   96/  265]
train() client id: f_00001-6-3 loss: 0.452494  [  128/  265]
train() client id: f_00001-6-4 loss: 0.281431  [  160/  265]
train() client id: f_00001-6-5 loss: 0.340794  [  192/  265]
train() client id: f_00001-6-6 loss: 0.392049  [  224/  265]
train() client id: f_00001-6-7 loss: 0.423075  [  256/  265]
train() client id: f_00001-7-0 loss: 0.352486  [   32/  265]
train() client id: f_00001-7-1 loss: 0.589767  [   64/  265]
train() client id: f_00001-7-2 loss: 0.367509  [   96/  265]
train() client id: f_00001-7-3 loss: 0.294296  [  128/  265]
train() client id: f_00001-7-4 loss: 0.329111  [  160/  265]
train() client id: f_00001-7-5 loss: 0.430025  [  192/  265]
train() client id: f_00001-7-6 loss: 0.398080  [  224/  265]
train() client id: f_00001-7-7 loss: 0.287942  [  256/  265]
train() client id: f_00001-8-0 loss: 0.298792  [   32/  265]
train() client id: f_00001-8-1 loss: 0.470434  [   64/  265]
train() client id: f_00001-8-2 loss: 0.371861  [   96/  265]
train() client id: f_00001-8-3 loss: 0.376685  [  128/  265]
train() client id: f_00001-8-4 loss: 0.289901  [  160/  265]
train() client id: f_00001-8-5 loss: 0.313229  [  192/  265]
train() client id: f_00001-8-6 loss: 0.547131  [  224/  265]
train() client id: f_00001-8-7 loss: 0.327434  [  256/  265]
train() client id: f_00001-9-0 loss: 0.365825  [   32/  265]
train() client id: f_00001-9-1 loss: 0.353290  [   64/  265]
train() client id: f_00001-9-2 loss: 0.270788  [   96/  265]
train() client id: f_00001-9-3 loss: 0.479535  [  128/  265]
train() client id: f_00001-9-4 loss: 0.318402  [  160/  265]
train() client id: f_00001-9-5 loss: 0.365893  [  192/  265]
train() client id: f_00001-9-6 loss: 0.334678  [  224/  265]
train() client id: f_00001-9-7 loss: 0.470813  [  256/  265]
train() client id: f_00001-10-0 loss: 0.302229  [   32/  265]
train() client id: f_00001-10-1 loss: 0.360359  [   64/  265]
train() client id: f_00001-10-2 loss: 0.321141  [   96/  265]
train() client id: f_00001-10-3 loss: 0.453470  [  128/  265]
train() client id: f_00001-10-4 loss: 0.469190  [  160/  265]
train() client id: f_00001-10-5 loss: 0.441628  [  192/  265]
train() client id: f_00001-10-6 loss: 0.314242  [  224/  265]
train() client id: f_00001-10-7 loss: 0.335047  [  256/  265]
train() client id: f_00001-11-0 loss: 0.425557  [   32/  265]
train() client id: f_00001-11-1 loss: 0.428749  [   64/  265]
train() client id: f_00001-11-2 loss: 0.281233  [   96/  265]
train() client id: f_00001-11-3 loss: 0.369662  [  128/  265]
train() client id: f_00001-11-4 loss: 0.516244  [  160/  265]
train() client id: f_00001-11-5 loss: 0.286641  [  192/  265]
train() client id: f_00001-11-6 loss: 0.338960  [  224/  265]
train() client id: f_00001-11-7 loss: 0.264633  [  256/  265]
train() client id: f_00001-12-0 loss: 0.453034  [   32/  265]
train() client id: f_00001-12-1 loss: 0.370969  [   64/  265]
train() client id: f_00001-12-2 loss: 0.359924  [   96/  265]
train() client id: f_00001-12-3 loss: 0.293899  [  128/  265]
train() client id: f_00001-12-4 loss: 0.395587  [  160/  265]
train() client id: f_00001-12-5 loss: 0.294176  [  192/  265]
train() client id: f_00001-12-6 loss: 0.487265  [  224/  265]
train() client id: f_00001-12-7 loss: 0.340227  [  256/  265]
train() client id: f_00002-0-0 loss: 1.266915  [   32/  124]
train() client id: f_00002-0-1 loss: 1.426557  [   64/  124]
train() client id: f_00002-0-2 loss: 1.477551  [   96/  124]
train() client id: f_00002-1-0 loss: 1.185302  [   32/  124]
train() client id: f_00002-1-1 loss: 1.234091  [   64/  124]
train() client id: f_00002-1-2 loss: 1.392661  [   96/  124]
train() client id: f_00002-2-0 loss: 1.469833  [   32/  124]
train() client id: f_00002-2-1 loss: 1.169606  [   64/  124]
train() client id: f_00002-2-2 loss: 1.270169  [   96/  124]
train() client id: f_00002-3-0 loss: 1.361621  [   32/  124]
train() client id: f_00002-3-1 loss: 1.468315  [   64/  124]
train() client id: f_00002-3-2 loss: 1.091244  [   96/  124]
train() client id: f_00002-4-0 loss: 1.184417  [   32/  124]
train() client id: f_00002-4-1 loss: 1.168872  [   64/  124]
train() client id: f_00002-4-2 loss: 1.347982  [   96/  124]
train() client id: f_00002-5-0 loss: 1.151628  [   32/  124]
train() client id: f_00002-5-1 loss: 1.017456  [   64/  124]
train() client id: f_00002-5-2 loss: 1.368206  [   96/  124]
train() client id: f_00002-6-0 loss: 1.309566  [   32/  124]
train() client id: f_00002-6-1 loss: 1.094013  [   64/  124]
train() client id: f_00002-6-2 loss: 1.158792  [   96/  124]
train() client id: f_00002-7-0 loss: 1.300136  [   32/  124]
train() client id: f_00002-7-1 loss: 0.936904  [   64/  124]
train() client id: f_00002-7-2 loss: 1.267792  [   96/  124]
train() client id: f_00002-8-0 loss: 1.255912  [   32/  124]
train() client id: f_00002-8-1 loss: 1.020914  [   64/  124]
train() client id: f_00002-8-2 loss: 1.168422  [   96/  124]
train() client id: f_00002-9-0 loss: 1.253288  [   32/  124]
train() client id: f_00002-9-1 loss: 0.956932  [   64/  124]
train() client id: f_00002-9-2 loss: 1.293214  [   96/  124]
train() client id: f_00002-10-0 loss: 1.223265  [   32/  124]
train() client id: f_00002-10-1 loss: 1.226419  [   64/  124]
train() client id: f_00002-10-2 loss: 1.114675  [   96/  124]
train() client id: f_00002-11-0 loss: 1.133718  [   32/  124]
train() client id: f_00002-11-1 loss: 1.214197  [   64/  124]
train() client id: f_00002-11-2 loss: 1.278808  [   96/  124]
train() client id: f_00002-12-0 loss: 1.178105  [   32/  124]
train() client id: f_00002-12-1 loss: 1.214869  [   64/  124]
train() client id: f_00002-12-2 loss: 1.121876  [   96/  124]
train() client id: f_00003-0-0 loss: 0.573325  [   32/   43]
train() client id: f_00003-1-0 loss: 0.793509  [   32/   43]
train() client id: f_00003-2-0 loss: 0.863403  [   32/   43]
train() client id: f_00003-3-0 loss: 0.802911  [   32/   43]
train() client id: f_00003-4-0 loss: 0.768528  [   32/   43]
train() client id: f_00003-5-0 loss: 0.516267  [   32/   43]
train() client id: f_00003-6-0 loss: 0.702075  [   32/   43]
train() client id: f_00003-7-0 loss: 0.619409  [   32/   43]
train() client id: f_00003-8-0 loss: 0.594072  [   32/   43]
train() client id: f_00003-9-0 loss: 0.872631  [   32/   43]
train() client id: f_00003-10-0 loss: 0.694908  [   32/   43]
train() client id: f_00003-11-0 loss: 0.847667  [   32/   43]
train() client id: f_00003-12-0 loss: 0.685189  [   32/   43]
train() client id: f_00004-0-0 loss: 0.822784  [   32/  306]
train() client id: f_00004-0-1 loss: 0.938467  [   64/  306]
train() client id: f_00004-0-2 loss: 0.896668  [   96/  306]
train() client id: f_00004-0-3 loss: 0.795117  [  128/  306]
train() client id: f_00004-0-4 loss: 0.883658  [  160/  306]
train() client id: f_00004-0-5 loss: 0.835969  [  192/  306]
train() client id: f_00004-0-6 loss: 0.815706  [  224/  306]
train() client id: f_00004-0-7 loss: 0.827431  [  256/  306]
train() client id: f_00004-0-8 loss: 0.740611  [  288/  306]
train() client id: f_00004-1-0 loss: 0.751749  [   32/  306]
train() client id: f_00004-1-1 loss: 0.716744  [   64/  306]
train() client id: f_00004-1-2 loss: 0.864000  [   96/  306]
train() client id: f_00004-1-3 loss: 0.993458  [  128/  306]
train() client id: f_00004-1-4 loss: 0.770542  [  160/  306]
train() client id: f_00004-1-5 loss: 0.867939  [  192/  306]
train() client id: f_00004-1-6 loss: 0.799305  [  224/  306]
train() client id: f_00004-1-7 loss: 0.779880  [  256/  306]
train() client id: f_00004-1-8 loss: 0.835997  [  288/  306]
train() client id: f_00004-2-0 loss: 0.999592  [   32/  306]
train() client id: f_00004-2-1 loss: 0.950673  [   64/  306]
train() client id: f_00004-2-2 loss: 0.870519  [   96/  306]
train() client id: f_00004-2-3 loss: 0.737528  [  128/  306]
train() client id: f_00004-2-4 loss: 0.771541  [  160/  306]
train() client id: f_00004-2-5 loss: 0.844095  [  192/  306]
train() client id: f_00004-2-6 loss: 0.959439  [  224/  306]
train() client id: f_00004-2-7 loss: 0.696359  [  256/  306]
train() client id: f_00004-2-8 loss: 0.673885  [  288/  306]
train() client id: f_00004-3-0 loss: 0.799724  [   32/  306]
train() client id: f_00004-3-1 loss: 0.621520  [   64/  306]
train() client id: f_00004-3-2 loss: 0.744039  [   96/  306]
train() client id: f_00004-3-3 loss: 0.792193  [  128/  306]
train() client id: f_00004-3-4 loss: 0.938688  [  160/  306]
train() client id: f_00004-3-5 loss: 0.809786  [  192/  306]
train() client id: f_00004-3-6 loss: 0.884916  [  224/  306]
train() client id: f_00004-3-7 loss: 0.999033  [  256/  306]
train() client id: f_00004-3-8 loss: 0.936843  [  288/  306]
train() client id: f_00004-4-0 loss: 0.958637  [   32/  306]
train() client id: f_00004-4-1 loss: 0.866442  [   64/  306]
train() client id: f_00004-4-2 loss: 0.827252  [   96/  306]
train() client id: f_00004-4-3 loss: 0.912119  [  128/  306]
train() client id: f_00004-4-4 loss: 0.808667  [  160/  306]
train() client id: f_00004-4-5 loss: 0.926066  [  192/  306]
train() client id: f_00004-4-6 loss: 0.645536  [  224/  306]
train() client id: f_00004-4-7 loss: 0.852232  [  256/  306]
train() client id: f_00004-4-8 loss: 0.793894  [  288/  306]
train() client id: f_00004-5-0 loss: 0.870807  [   32/  306]
train() client id: f_00004-5-1 loss: 0.884372  [   64/  306]
train() client id: f_00004-5-2 loss: 0.707709  [   96/  306]
train() client id: f_00004-5-3 loss: 1.006941  [  128/  306]
train() client id: f_00004-5-4 loss: 0.723366  [  160/  306]
train() client id: f_00004-5-5 loss: 0.769636  [  192/  306]
train() client id: f_00004-5-6 loss: 0.710172  [  224/  306]
train() client id: f_00004-5-7 loss: 0.819455  [  256/  306]
train() client id: f_00004-5-8 loss: 0.982992  [  288/  306]
train() client id: f_00004-6-0 loss: 0.861133  [   32/  306]
train() client id: f_00004-6-1 loss: 0.863426  [   64/  306]
train() client id: f_00004-6-2 loss: 0.791699  [   96/  306]
train() client id: f_00004-6-3 loss: 0.610633  [  128/  306]
train() client id: f_00004-6-4 loss: 0.902631  [  160/  306]
train() client id: f_00004-6-5 loss: 0.781076  [  192/  306]
train() client id: f_00004-6-6 loss: 0.943837  [  224/  306]
train() client id: f_00004-6-7 loss: 0.812080  [  256/  306]
train() client id: f_00004-6-8 loss: 0.907365  [  288/  306]
train() client id: f_00004-7-0 loss: 0.868107  [   32/  306]
train() client id: f_00004-7-1 loss: 0.971585  [   64/  306]
train() client id: f_00004-7-2 loss: 0.844446  [   96/  306]
train() client id: f_00004-7-3 loss: 0.786890  [  128/  306]
train() client id: f_00004-7-4 loss: 0.844659  [  160/  306]
train() client id: f_00004-7-5 loss: 0.773564  [  192/  306]
train() client id: f_00004-7-6 loss: 0.785950  [  224/  306]
train() client id: f_00004-7-7 loss: 0.747236  [  256/  306]
train() client id: f_00004-7-8 loss: 0.713015  [  288/  306]
train() client id: f_00004-8-0 loss: 0.798180  [   32/  306]
train() client id: f_00004-8-1 loss: 0.823712  [   64/  306]
train() client id: f_00004-8-2 loss: 0.881520  [   96/  306]
train() client id: f_00004-8-3 loss: 0.803857  [  128/  306]
train() client id: f_00004-8-4 loss: 0.752292  [  160/  306]
train() client id: f_00004-8-5 loss: 0.909070  [  192/  306]
train() client id: f_00004-8-6 loss: 0.918594  [  224/  306]
train() client id: f_00004-8-7 loss: 0.720298  [  256/  306]
train() client id: f_00004-8-8 loss: 0.933135  [  288/  306]
train() client id: f_00004-9-0 loss: 0.732631  [   32/  306]
train() client id: f_00004-9-1 loss: 0.783906  [   64/  306]
train() client id: f_00004-9-2 loss: 0.940123  [   96/  306]
train() client id: f_00004-9-3 loss: 0.832489  [  128/  306]
train() client id: f_00004-9-4 loss: 0.759272  [  160/  306]
train() client id: f_00004-9-5 loss: 0.873404  [  192/  306]
train() client id: f_00004-9-6 loss: 0.763349  [  224/  306]
train() client id: f_00004-9-7 loss: 0.951078  [  256/  306]
train() client id: f_00004-9-8 loss: 0.882939  [  288/  306]
train() client id: f_00004-10-0 loss: 0.860366  [   32/  306]
train() client id: f_00004-10-1 loss: 0.777151  [   64/  306]
train() client id: f_00004-10-2 loss: 0.877489  [   96/  306]
train() client id: f_00004-10-3 loss: 0.820396  [  128/  306]
train() client id: f_00004-10-4 loss: 0.805494  [  160/  306]
train() client id: f_00004-10-5 loss: 0.907925  [  192/  306]
train() client id: f_00004-10-6 loss: 0.749241  [  224/  306]
train() client id: f_00004-10-7 loss: 0.901748  [  256/  306]
train() client id: f_00004-10-8 loss: 0.772289  [  288/  306]
train() client id: f_00004-11-0 loss: 0.887990  [   32/  306]
train() client id: f_00004-11-1 loss: 0.842638  [   64/  306]
train() client id: f_00004-11-2 loss: 0.835346  [   96/  306]
train() client id: f_00004-11-3 loss: 0.649112  [  128/  306]
train() client id: f_00004-11-4 loss: 0.811182  [  160/  306]
train() client id: f_00004-11-5 loss: 0.783348  [  192/  306]
train() client id: f_00004-11-6 loss: 0.925140  [  224/  306]
train() client id: f_00004-11-7 loss: 0.924130  [  256/  306]
train() client id: f_00004-11-8 loss: 0.813440  [  288/  306]
train() client id: f_00004-12-0 loss: 0.851978  [   32/  306]
train() client id: f_00004-12-1 loss: 0.700235  [   64/  306]
train() client id: f_00004-12-2 loss: 0.920747  [   96/  306]
train() client id: f_00004-12-3 loss: 0.914470  [  128/  306]
train() client id: f_00004-12-4 loss: 0.828951  [  160/  306]
train() client id: f_00004-12-5 loss: 0.834153  [  192/  306]
train() client id: f_00004-12-6 loss: 0.813281  [  224/  306]
train() client id: f_00004-12-7 loss: 0.878264  [  256/  306]
train() client id: f_00004-12-8 loss: 0.685189  [  288/  306]
train() client id: f_00005-0-0 loss: 0.606697  [   32/  146]
train() client id: f_00005-0-1 loss: 0.478812  [   64/  146]
train() client id: f_00005-0-2 loss: 0.418253  [   96/  146]
train() client id: f_00005-0-3 loss: 0.829863  [  128/  146]
train() client id: f_00005-1-0 loss: 0.573024  [   32/  146]
train() client id: f_00005-1-1 loss: 0.607504  [   64/  146]
train() client id: f_00005-1-2 loss: 0.535651  [   96/  146]
train() client id: f_00005-1-3 loss: 0.429111  [  128/  146]
train() client id: f_00005-2-0 loss: 0.741741  [   32/  146]
train() client id: f_00005-2-1 loss: 0.478820  [   64/  146]
train() client id: f_00005-2-2 loss: 0.704302  [   96/  146]
train() client id: f_00005-2-3 loss: 0.581385  [  128/  146]
train() client id: f_00005-3-0 loss: 0.571203  [   32/  146]
train() client id: f_00005-3-1 loss: 0.468266  [   64/  146]
train() client id: f_00005-3-2 loss: 0.719611  [   96/  146]
train() client id: f_00005-3-3 loss: 0.638715  [  128/  146]
train() client id: f_00005-4-0 loss: 0.370381  [   32/  146]
train() client id: f_00005-4-1 loss: 0.706656  [   64/  146]
train() client id: f_00005-4-2 loss: 0.417860  [   96/  146]
train() client id: f_00005-4-3 loss: 0.683663  [  128/  146]
train() client id: f_00005-5-0 loss: 0.685729  [   32/  146]
train() client id: f_00005-5-1 loss: 0.504077  [   64/  146]
train() client id: f_00005-5-2 loss: 0.785846  [   96/  146]
train() client id: f_00005-5-3 loss: 0.361135  [  128/  146]
train() client id: f_00005-6-0 loss: 0.698216  [   32/  146]
train() client id: f_00005-6-1 loss: 0.709948  [   64/  146]
train() client id: f_00005-6-2 loss: 0.326519  [   96/  146]
train() client id: f_00005-6-3 loss: 0.665308  [  128/  146]
train() client id: f_00005-7-0 loss: 0.849146  [   32/  146]
train() client id: f_00005-7-1 loss: 0.331594  [   64/  146]
train() client id: f_00005-7-2 loss: 0.279055  [   96/  146]
train() client id: f_00005-7-3 loss: 0.890600  [  128/  146]
train() client id: f_00005-8-0 loss: 0.739703  [   32/  146]
train() client id: f_00005-8-1 loss: 0.350032  [   64/  146]
train() client id: f_00005-8-2 loss: 0.796141  [   96/  146]
train() client id: f_00005-8-3 loss: 0.411454  [  128/  146]
train() client id: f_00005-9-0 loss: 0.537392  [   32/  146]
train() client id: f_00005-9-1 loss: 0.579934  [   64/  146]
train() client id: f_00005-9-2 loss: 0.473572  [   96/  146]
train() client id: f_00005-9-3 loss: 0.722119  [  128/  146]
train() client id: f_00005-10-0 loss: 0.775558  [   32/  146]
train() client id: f_00005-10-1 loss: 0.460519  [   64/  146]
train() client id: f_00005-10-2 loss: 0.357430  [   96/  146]
train() client id: f_00005-10-3 loss: 0.370698  [  128/  146]
train() client id: f_00005-11-0 loss: 0.539206  [   32/  146]
train() client id: f_00005-11-1 loss: 0.484446  [   64/  146]
train() client id: f_00005-11-2 loss: 0.440478  [   96/  146]
train() client id: f_00005-11-3 loss: 0.898060  [  128/  146]
train() client id: f_00005-12-0 loss: 0.449803  [   32/  146]
train() client id: f_00005-12-1 loss: 0.426068  [   64/  146]
train() client id: f_00005-12-2 loss: 0.735596  [   96/  146]
train() client id: f_00005-12-3 loss: 0.820652  [  128/  146]
train() client id: f_00006-0-0 loss: 0.439651  [   32/   54]
train() client id: f_00006-1-0 loss: 0.456932  [   32/   54]
train() client id: f_00006-2-0 loss: 0.411907  [   32/   54]
train() client id: f_00006-3-0 loss: 0.406878  [   32/   54]
train() client id: f_00006-4-0 loss: 0.425524  [   32/   54]
train() client id: f_00006-5-0 loss: 0.438830  [   32/   54]
train() client id: f_00006-6-0 loss: 0.477175  [   32/   54]
train() client id: f_00006-7-0 loss: 0.376614  [   32/   54]
train() client id: f_00006-8-0 loss: 0.349547  [   32/   54]
train() client id: f_00006-9-0 loss: 0.481150  [   32/   54]
train() client id: f_00006-10-0 loss: 0.469672  [   32/   54]
train() client id: f_00006-11-0 loss: 0.438623  [   32/   54]
train() client id: f_00006-12-0 loss: 0.456320  [   32/   54]
train() client id: f_00007-0-0 loss: 0.806449  [   32/  179]
train() client id: f_00007-0-1 loss: 0.449561  [   64/  179]
train() client id: f_00007-0-2 loss: 0.701461  [   96/  179]
train() client id: f_00007-0-3 loss: 0.570404  [  128/  179]
train() client id: f_00007-0-4 loss: 0.540315  [  160/  179]
train() client id: f_00007-1-0 loss: 0.583268  [   32/  179]
train() client id: f_00007-1-1 loss: 0.461147  [   64/  179]
train() client id: f_00007-1-2 loss: 0.611023  [   96/  179]
train() client id: f_00007-1-3 loss: 0.575365  [  128/  179]
train() client id: f_00007-1-4 loss: 0.681687  [  160/  179]
train() client id: f_00007-2-0 loss: 0.608616  [   32/  179]
train() client id: f_00007-2-1 loss: 0.576724  [   64/  179]
train() client id: f_00007-2-2 loss: 0.493366  [   96/  179]
train() client id: f_00007-2-3 loss: 0.670580  [  128/  179]
train() client id: f_00007-2-4 loss: 0.658937  [  160/  179]
train() client id: f_00007-3-0 loss: 0.507052  [   32/  179]
train() client id: f_00007-3-1 loss: 0.726083  [   64/  179]
train() client id: f_00007-3-2 loss: 0.593734  [   96/  179]
train() client id: f_00007-3-3 loss: 0.616257  [  128/  179]
train() client id: f_00007-3-4 loss: 0.492250  [  160/  179]
train() client id: f_00007-4-0 loss: 0.389838  [   32/  179]
train() client id: f_00007-4-1 loss: 0.797052  [   64/  179]
train() client id: f_00007-4-2 loss: 0.634765  [   96/  179]
train() client id: f_00007-4-3 loss: 0.489187  [  128/  179]
train() client id: f_00007-4-4 loss: 0.609523  [  160/  179]
train() client id: f_00007-5-0 loss: 0.600546  [   32/  179]
train() client id: f_00007-5-1 loss: 0.499700  [   64/  179]
train() client id: f_00007-5-2 loss: 0.520824  [   96/  179]
train() client id: f_00007-5-3 loss: 0.639612  [  128/  179]
train() client id: f_00007-5-4 loss: 0.516386  [  160/  179]
train() client id: f_00007-6-0 loss: 0.411845  [   32/  179]
train() client id: f_00007-6-1 loss: 0.861986  [   64/  179]
train() client id: f_00007-6-2 loss: 0.672215  [   96/  179]
train() client id: f_00007-6-3 loss: 0.398497  [  128/  179]
train() client id: f_00007-6-4 loss: 0.526554  [  160/  179]
train() client id: f_00007-7-0 loss: 0.464987  [   32/  179]
train() client id: f_00007-7-1 loss: 0.388821  [   64/  179]
train() client id: f_00007-7-2 loss: 0.538774  [   96/  179]
train() client id: f_00007-7-3 loss: 0.647542  [  128/  179]
train() client id: f_00007-7-4 loss: 0.446624  [  160/  179]
train() client id: f_00007-8-0 loss: 0.795615  [   32/  179]
train() client id: f_00007-8-1 loss: 0.416238  [   64/  179]
train() client id: f_00007-8-2 loss: 0.558593  [   96/  179]
train() client id: f_00007-8-3 loss: 0.507427  [  128/  179]
train() client id: f_00007-8-4 loss: 0.559228  [  160/  179]
train() client id: f_00007-9-0 loss: 0.655189  [   32/  179]
train() client id: f_00007-9-1 loss: 0.613242  [   64/  179]
train() client id: f_00007-9-2 loss: 0.411814  [   96/  179]
train() client id: f_00007-9-3 loss: 0.496750  [  128/  179]
train() client id: f_00007-9-4 loss: 0.699654  [  160/  179]
train() client id: f_00007-10-0 loss: 0.573685  [   32/  179]
train() client id: f_00007-10-1 loss: 0.819945  [   64/  179]
train() client id: f_00007-10-2 loss: 0.483238  [   96/  179]
train() client id: f_00007-10-3 loss: 0.444886  [  128/  179]
train() client id: f_00007-10-4 loss: 0.594529  [  160/  179]
train() client id: f_00007-11-0 loss: 0.435712  [   32/  179]
train() client id: f_00007-11-1 loss: 1.125740  [   64/  179]
train() client id: f_00007-11-2 loss: 0.400290  [   96/  179]
train() client id: f_00007-11-3 loss: 0.401585  [  128/  179]
train() client id: f_00007-11-4 loss: 0.442477  [  160/  179]
train() client id: f_00007-12-0 loss: 0.618324  [   32/  179]
train() client id: f_00007-12-1 loss: 0.432800  [   64/  179]
train() client id: f_00007-12-2 loss: 0.477561  [   96/  179]
train() client id: f_00007-12-3 loss: 0.594583  [  128/  179]
train() client id: f_00007-12-4 loss: 0.796273  [  160/  179]
train() client id: f_00008-0-0 loss: 0.534667  [   32/  130]
train() client id: f_00008-0-1 loss: 0.537113  [   64/  130]
train() client id: f_00008-0-2 loss: 0.756148  [   96/  130]
train() client id: f_00008-0-3 loss: 0.692238  [  128/  130]
train() client id: f_00008-1-0 loss: 0.666186  [   32/  130]
train() client id: f_00008-1-1 loss: 0.644772  [   64/  130]
train() client id: f_00008-1-2 loss: 0.595975  [   96/  130]
train() client id: f_00008-1-3 loss: 0.616082  [  128/  130]
train() client id: f_00008-2-0 loss: 0.696838  [   32/  130]
train() client id: f_00008-2-1 loss: 0.574792  [   64/  130]
train() client id: f_00008-2-2 loss: 0.567178  [   96/  130]
train() client id: f_00008-2-3 loss: 0.684881  [  128/  130]
train() client id: f_00008-3-0 loss: 0.699461  [   32/  130]
train() client id: f_00008-3-1 loss: 0.655105  [   64/  130]
train() client id: f_00008-3-2 loss: 0.513593  [   96/  130]
train() client id: f_00008-3-3 loss: 0.662291  [  128/  130]
train() client id: f_00008-4-0 loss: 0.647203  [   32/  130]
train() client id: f_00008-4-1 loss: 0.553601  [   64/  130]
train() client id: f_00008-4-2 loss: 0.602625  [   96/  130]
train() client id: f_00008-4-3 loss: 0.718644  [  128/  130]
train() client id: f_00008-5-0 loss: 0.661406  [   32/  130]
train() client id: f_00008-5-1 loss: 0.640346  [   64/  130]
train() client id: f_00008-5-2 loss: 0.600527  [   96/  130]
train() client id: f_00008-5-3 loss: 0.588734  [  128/  130]
train() client id: f_00008-6-0 loss: 0.515821  [   32/  130]
train() client id: f_00008-6-1 loss: 0.642798  [   64/  130]
train() client id: f_00008-6-2 loss: 0.573619  [   96/  130]
train() client id: f_00008-6-3 loss: 0.744029  [  128/  130]
train() client id: f_00008-7-0 loss: 0.484221  [   32/  130]
train() client id: f_00008-7-1 loss: 0.614362  [   64/  130]
train() client id: f_00008-7-2 loss: 0.730418  [   96/  130]
train() client id: f_00008-7-3 loss: 0.697282  [  128/  130]
train() client id: f_00008-8-0 loss: 0.611830  [   32/  130]
train() client id: f_00008-8-1 loss: 0.565207  [   64/  130]
train() client id: f_00008-8-2 loss: 0.669601  [   96/  130]
train() client id: f_00008-8-3 loss: 0.641531  [  128/  130]
train() client id: f_00008-9-0 loss: 0.589278  [   32/  130]
train() client id: f_00008-9-1 loss: 0.688523  [   64/  130]
train() client id: f_00008-9-2 loss: 0.540112  [   96/  130]
train() client id: f_00008-9-3 loss: 0.691100  [  128/  130]
train() client id: f_00008-10-0 loss: 0.613326  [   32/  130]
train() client id: f_00008-10-1 loss: 0.669821  [   64/  130]
train() client id: f_00008-10-2 loss: 0.658205  [   96/  130]
train() client id: f_00008-10-3 loss: 0.591268  [  128/  130]
train() client id: f_00008-11-0 loss: 0.640611  [   32/  130]
train() client id: f_00008-11-1 loss: 0.707305  [   64/  130]
train() client id: f_00008-11-2 loss: 0.510428  [   96/  130]
train() client id: f_00008-11-3 loss: 0.671299  [  128/  130]
train() client id: f_00008-12-0 loss: 0.571349  [   32/  130]
train() client id: f_00008-12-1 loss: 0.644646  [   64/  130]
train() client id: f_00008-12-2 loss: 0.519719  [   96/  130]
train() client id: f_00008-12-3 loss: 0.760949  [  128/  130]
train() client id: f_00009-0-0 loss: 1.235511  [   32/  118]
train() client id: f_00009-0-1 loss: 1.133559  [   64/  118]
train() client id: f_00009-0-2 loss: 1.155206  [   96/  118]
train() client id: f_00009-1-0 loss: 1.132393  [   32/  118]
train() client id: f_00009-1-1 loss: 1.204352  [   64/  118]
train() client id: f_00009-1-2 loss: 0.983266  [   96/  118]
train() client id: f_00009-2-0 loss: 1.119447  [   32/  118]
train() client id: f_00009-2-1 loss: 1.051777  [   64/  118]
train() client id: f_00009-2-2 loss: 1.025887  [   96/  118]
train() client id: f_00009-3-0 loss: 1.137724  [   32/  118]
train() client id: f_00009-3-1 loss: 1.062485  [   64/  118]
train() client id: f_00009-3-2 loss: 0.948970  [   96/  118]
train() client id: f_00009-4-0 loss: 1.076340  [   32/  118]
train() client id: f_00009-4-1 loss: 0.867704  [   64/  118]
train() client id: f_00009-4-2 loss: 0.981551  [   96/  118]
train() client id: f_00009-5-0 loss: 1.031034  [   32/  118]
train() client id: f_00009-5-1 loss: 1.032282  [   64/  118]
train() client id: f_00009-5-2 loss: 0.936951  [   96/  118]
train() client id: f_00009-6-0 loss: 0.942701  [   32/  118]
train() client id: f_00009-6-1 loss: 0.965335  [   64/  118]
train() client id: f_00009-6-2 loss: 0.967816  [   96/  118]
train() client id: f_00009-7-0 loss: 0.957245  [   32/  118]
train() client id: f_00009-7-1 loss: 1.037152  [   64/  118]
train() client id: f_00009-7-2 loss: 0.920100  [   96/  118]
train() client id: f_00009-8-0 loss: 0.942727  [   32/  118]
train() client id: f_00009-8-1 loss: 0.999192  [   64/  118]
train() client id: f_00009-8-2 loss: 0.933942  [   96/  118]
train() client id: f_00009-9-0 loss: 0.880045  [   32/  118]
train() client id: f_00009-9-1 loss: 0.991245  [   64/  118]
train() client id: f_00009-9-2 loss: 0.918200  [   96/  118]
train() client id: f_00009-10-0 loss: 0.987199  [   32/  118]
train() client id: f_00009-10-1 loss: 0.888169  [   64/  118]
train() client id: f_00009-10-2 loss: 0.822404  [   96/  118]
train() client id: f_00009-11-0 loss: 0.796903  [   32/  118]
train() client id: f_00009-11-1 loss: 0.950369  [   64/  118]
train() client id: f_00009-11-2 loss: 0.755271  [   96/  118]
train() client id: f_00009-12-0 loss: 0.859038  [   32/  118]
train() client id: f_00009-12-1 loss: 0.886112  [   64/  118]
train() client id: f_00009-12-2 loss: 0.972920  [   96/  118]
At round 67 accuracy: 0.636604774535809
At round 67 training accuracy: 0.5881958417169685
At round 67 training loss: 0.8312852589249038
gradient difference: 0.47908473014831543
train() client id: f_00000-0-0 loss: 0.855556  [   32/  126]
train() client id: f_00000-0-1 loss: 1.030326  [   64/  126]
train() client id: f_00000-0-2 loss: 0.973315  [   96/  126]
train() client id: f_00000-1-0 loss: 0.670350  [   32/  126]
train() client id: f_00000-1-1 loss: 0.981975  [   64/  126]
train() client id: f_00000-1-2 loss: 1.024617  [   96/  126]
train() client id: f_00000-2-0 loss: 0.852931  [   32/  126]
train() client id: f_00000-2-1 loss: 0.965588  [   64/  126]
train() client id: f_00000-2-2 loss: 0.691263  [   96/  126]
train() client id: f_00000-3-0 loss: 0.939716  [   32/  126]
train() client id: f_00000-3-1 loss: 0.747464  [   64/  126]
train() client id: f_00000-3-2 loss: 0.721619  [   96/  126]
train() client id: f_00000-4-0 loss: 0.871322  [   32/  126]
train() client id: f_00000-4-1 loss: 0.728139  [   64/  126]
train() client id: f_00000-4-2 loss: 0.661835  [   96/  126]
train() client id: f_00000-5-0 loss: 0.739312  [   32/  126]
train() client id: f_00000-5-1 loss: 0.623861  [   64/  126]
train() client id: f_00000-5-2 loss: 0.667693  [   96/  126]
train() client id: f_00000-6-0 loss: 0.747486  [   32/  126]
train() client id: f_00000-6-1 loss: 0.684341  [   64/  126]
train() client id: f_00000-6-2 loss: 0.755157  [   96/  126]
train() client id: f_00000-7-0 loss: 0.648885  [   32/  126]
train() client id: f_00000-7-1 loss: 0.659775  [   64/  126]
train() client id: f_00000-7-2 loss: 0.738470  [   96/  126]
train() client id: f_00000-8-0 loss: 0.748133  [   32/  126]
train() client id: f_00000-8-1 loss: 0.654812  [   64/  126]
train() client id: f_00000-8-2 loss: 0.553829  [   96/  126]
train() client id: f_00000-9-0 loss: 0.499876  [   32/  126]
train() client id: f_00000-9-1 loss: 0.618291  [   64/  126]
train() client id: f_00000-9-2 loss: 0.736591  [   96/  126]
train() client id: f_00000-10-0 loss: 0.801388  [   32/  126]
train() client id: f_00000-10-1 loss: 0.562591  [   64/  126]
train() client id: f_00000-10-2 loss: 0.750507  [   96/  126]
train() client id: f_00000-11-0 loss: 0.562295  [   32/  126]
train() client id: f_00000-11-1 loss: 0.663271  [   64/  126]
train() client id: f_00000-11-2 loss: 0.726099  [   96/  126]
train() client id: f_00000-12-0 loss: 0.646595  [   32/  126]
train() client id: f_00000-12-1 loss: 0.609435  [   64/  126]
train() client id: f_00000-12-2 loss: 0.738967  [   96/  126]
train() client id: f_00001-0-0 loss: 0.373652  [   32/  265]
train() client id: f_00001-0-1 loss: 0.365971  [   64/  265]
train() client id: f_00001-0-2 loss: 0.475419  [   96/  265]
train() client id: f_00001-0-3 loss: 0.500318  [  128/  265]
train() client id: f_00001-0-4 loss: 0.399199  [  160/  265]
train() client id: f_00001-0-5 loss: 0.477600  [  192/  265]
train() client id: f_00001-0-6 loss: 0.325734  [  224/  265]
train() client id: f_00001-0-7 loss: 0.352111  [  256/  265]
train() client id: f_00001-1-0 loss: 0.332995  [   32/  265]
train() client id: f_00001-1-1 loss: 0.304309  [   64/  265]
train() client id: f_00001-1-2 loss: 0.410290  [   96/  265]
train() client id: f_00001-1-3 loss: 0.476151  [  128/  265]
train() client id: f_00001-1-4 loss: 0.385137  [  160/  265]
train() client id: f_00001-1-5 loss: 0.515857  [  192/  265]
train() client id: f_00001-1-6 loss: 0.440961  [  224/  265]
train() client id: f_00001-1-7 loss: 0.369221  [  256/  265]
train() client id: f_00001-2-0 loss: 0.361635  [   32/  265]
train() client id: f_00001-2-1 loss: 0.341263  [   64/  265]
train() client id: f_00001-2-2 loss: 0.460052  [   96/  265]
train() client id: f_00001-2-3 loss: 0.393409  [  128/  265]
train() client id: f_00001-2-4 loss: 0.382625  [  160/  265]
train() client id: f_00001-2-5 loss: 0.301858  [  192/  265]
train() client id: f_00001-2-6 loss: 0.381853  [  224/  265]
train() client id: f_00001-2-7 loss: 0.528618  [  256/  265]
train() client id: f_00001-3-0 loss: 0.372398  [   32/  265]
train() client id: f_00001-3-1 loss: 0.389462  [   64/  265]
train() client id: f_00001-3-2 loss: 0.401219  [   96/  265]
train() client id: f_00001-3-3 loss: 0.344610  [  128/  265]
train() client id: f_00001-3-4 loss: 0.389811  [  160/  265]
train() client id: f_00001-3-5 loss: 0.483767  [  192/  265]
train() client id: f_00001-3-6 loss: 0.365898  [  224/  265]
train() client id: f_00001-3-7 loss: 0.356145  [  256/  265]
train() client id: f_00001-4-0 loss: 0.472167  [   32/  265]
train() client id: f_00001-4-1 loss: 0.471502  [   64/  265]
train() client id: f_00001-4-2 loss: 0.315308  [   96/  265]
train() client id: f_00001-4-3 loss: 0.301410  [  128/  265]
train() client id: f_00001-4-4 loss: 0.298823  [  160/  265]
train() client id: f_00001-4-5 loss: 0.277102  [  192/  265]
train() client id: f_00001-4-6 loss: 0.285442  [  224/  265]
train() client id: f_00001-4-7 loss: 0.370329  [  256/  265]
train() client id: f_00001-5-0 loss: 0.452213  [   32/  265]
train() client id: f_00001-5-1 loss: 0.288221  [   64/  265]
train() client id: f_00001-5-2 loss: 0.448378  [   96/  265]
train() client id: f_00001-5-3 loss: 0.288362  [  128/  265]
train() client id: f_00001-5-4 loss: 0.524443  [  160/  265]
train() client id: f_00001-5-5 loss: 0.331351  [  192/  265]
train() client id: f_00001-5-6 loss: 0.333579  [  224/  265]
train() client id: f_00001-5-7 loss: 0.353471  [  256/  265]
train() client id: f_00001-6-0 loss: 0.261993  [   32/  265]
train() client id: f_00001-6-1 loss: 0.329263  [   64/  265]
train() client id: f_00001-6-2 loss: 0.466099  [   96/  265]
train() client id: f_00001-6-3 loss: 0.322442  [  128/  265]
train() client id: f_00001-6-4 loss: 0.421387  [  160/  265]
train() client id: f_00001-6-5 loss: 0.274873  [  192/  265]
train() client id: f_00001-6-6 loss: 0.400470  [  224/  265]
train() client id: f_00001-6-7 loss: 0.372007  [  256/  265]
train() client id: f_00001-7-0 loss: 0.388251  [   32/  265]
train() client id: f_00001-7-1 loss: 0.354906  [   64/  265]
train() client id: f_00001-7-2 loss: 0.381315  [   96/  265]
train() client id: f_00001-7-3 loss: 0.280476  [  128/  265]
train() client id: f_00001-7-4 loss: 0.379464  [  160/  265]
train() client id: f_00001-7-5 loss: 0.304465  [  192/  265]
train() client id: f_00001-7-6 loss: 0.320778  [  224/  265]
train() client id: f_00001-7-7 loss: 0.465879  [  256/  265]
train() client id: f_00001-8-0 loss: 0.361276  [   32/  265]
train() client id: f_00001-8-1 loss: 0.510809  [   64/  265]
train() client id: f_00001-8-2 loss: 0.273384  [   96/  265]
train() client id: f_00001-8-3 loss: 0.366788  [  128/  265]
train() client id: f_00001-8-4 loss: 0.356190  [  160/  265]
train() client id: f_00001-8-5 loss: 0.312076  [  192/  265]
train() client id: f_00001-8-6 loss: 0.397645  [  224/  265]
train() client id: f_00001-8-7 loss: 0.371385  [  256/  265]
train() client id: f_00001-9-0 loss: 0.263763  [   32/  265]
train() client id: f_00001-9-1 loss: 0.409422  [   64/  265]
train() client id: f_00001-9-2 loss: 0.480792  [   96/  265]
train() client id: f_00001-9-3 loss: 0.319481  [  128/  265]
train() client id: f_00001-9-4 loss: 0.348831  [  160/  265]
train() client id: f_00001-9-5 loss: 0.431138  [  192/  265]
train() client id: f_00001-9-6 loss: 0.357350  [  224/  265]
train() client id: f_00001-9-7 loss: 0.304825  [  256/  265]
train() client id: f_00001-10-0 loss: 0.314962  [   32/  265]
train() client id: f_00001-10-1 loss: 0.362766  [   64/  265]
train() client id: f_00001-10-2 loss: 0.337265  [   96/  265]
train() client id: f_00001-10-3 loss: 0.326813  [  128/  265]
train() client id: f_00001-10-4 loss: 0.542822  [  160/  265]
train() client id: f_00001-10-5 loss: 0.358511  [  192/  265]
train() client id: f_00001-10-6 loss: 0.346174  [  224/  265]
train() client id: f_00001-10-7 loss: 0.321442  [  256/  265]
train() client id: f_00001-11-0 loss: 0.280606  [   32/  265]
train() client id: f_00001-11-1 loss: 0.315816  [   64/  265]
train() client id: f_00001-11-2 loss: 0.351691  [   96/  265]
train() client id: f_00001-11-3 loss: 0.641291  [  128/  265]
train() client id: f_00001-11-4 loss: 0.469273  [  160/  265]
train() client id: f_00001-11-5 loss: 0.279027  [  192/  265]
train() client id: f_00001-11-6 loss: 0.275322  [  224/  265]
train() client id: f_00001-11-7 loss: 0.301021  [  256/  265]
train() client id: f_00001-12-0 loss: 0.455468  [   32/  265]
train() client id: f_00001-12-1 loss: 0.329976  [   64/  265]
train() client id: f_00001-12-2 loss: 0.450463  [   96/  265]
train() client id: f_00001-12-3 loss: 0.373987  [  128/  265]
train() client id: f_00001-12-4 loss: 0.344996  [  160/  265]
train() client id: f_00001-12-5 loss: 0.252069  [  192/  265]
train() client id: f_00001-12-6 loss: 0.362891  [  224/  265]
train() client id: f_00001-12-7 loss: 0.342154  [  256/  265]
train() client id: f_00002-0-0 loss: 0.854584  [   32/  124]
train() client id: f_00002-0-1 loss: 1.047903  [   64/  124]
train() client id: f_00002-0-2 loss: 1.198380  [   96/  124]
train() client id: f_00002-1-0 loss: 1.073666  [   32/  124]
train() client id: f_00002-1-1 loss: 1.092416  [   64/  124]
train() client id: f_00002-1-2 loss: 0.981888  [   96/  124]
train() client id: f_00002-2-0 loss: 0.856724  [   32/  124]
train() client id: f_00002-2-1 loss: 1.090839  [   64/  124]
train() client id: f_00002-2-2 loss: 1.050923  [   96/  124]
train() client id: f_00002-3-0 loss: 1.127855  [   32/  124]
train() client id: f_00002-3-1 loss: 1.021181  [   64/  124]
train() client id: f_00002-3-2 loss: 0.972078  [   96/  124]
train() client id: f_00002-4-0 loss: 0.866026  [   32/  124]
train() client id: f_00002-4-1 loss: 1.092404  [   64/  124]
train() client id: f_00002-4-2 loss: 0.945557  [   96/  124]
train() client id: f_00002-5-0 loss: 1.158185  [   32/  124]
train() client id: f_00002-5-1 loss: 0.898809  [   64/  124]
train() client id: f_00002-5-2 loss: 0.825169  [   96/  124]
train() client id: f_00002-6-0 loss: 0.996765  [   32/  124]
train() client id: f_00002-6-1 loss: 1.295604  [   64/  124]
train() client id: f_00002-6-2 loss: 0.883713  [   96/  124]
train() client id: f_00002-7-0 loss: 1.098214  [   32/  124]
train() client id: f_00002-7-1 loss: 0.897952  [   64/  124]
train() client id: f_00002-7-2 loss: 0.950961  [   96/  124]
train() client id: f_00002-8-0 loss: 1.154582  [   32/  124]
train() client id: f_00002-8-1 loss: 0.959301  [   64/  124]
train() client id: f_00002-8-2 loss: 0.836837  [   96/  124]
train() client id: f_00002-9-0 loss: 0.861480  [   32/  124]
train() client id: f_00002-9-1 loss: 0.951433  [   64/  124]
train() client id: f_00002-9-2 loss: 1.178773  [   96/  124]
train() client id: f_00002-10-0 loss: 0.827084  [   32/  124]
train() client id: f_00002-10-1 loss: 1.064638  [   64/  124]
train() client id: f_00002-10-2 loss: 0.944729  [   96/  124]
train() client id: f_00002-11-0 loss: 1.137799  [   32/  124]
train() client id: f_00002-11-1 loss: 0.828828  [   64/  124]
train() client id: f_00002-11-2 loss: 1.021485  [   96/  124]
train() client id: f_00002-12-0 loss: 1.132886  [   32/  124]
train() client id: f_00002-12-1 loss: 0.997539  [   64/  124]
train() client id: f_00002-12-2 loss: 0.774449  [   96/  124]
train() client id: f_00003-0-0 loss: 0.760263  [   32/   43]
train() client id: f_00003-1-0 loss: 0.814011  [   32/   43]
train() client id: f_00003-2-0 loss: 0.794921  [   32/   43]
train() client id: f_00003-3-0 loss: 1.005722  [   32/   43]
train() client id: f_00003-4-0 loss: 0.690811  [   32/   43]
train() client id: f_00003-5-0 loss: 0.960503  [   32/   43]
train() client id: f_00003-6-0 loss: 0.754657  [   32/   43]
train() client id: f_00003-7-0 loss: 0.591865  [   32/   43]
train() client id: f_00003-8-0 loss: 0.812069  [   32/   43]
train() client id: f_00003-9-0 loss: 0.708337  [   32/   43]
train() client id: f_00003-10-0 loss: 0.753968  [   32/   43]
train() client id: f_00003-11-0 loss: 0.833086  [   32/   43]
train() client id: f_00003-12-0 loss: 0.614027  [   32/   43]
train() client id: f_00004-0-0 loss: 0.971620  [   32/  306]
train() client id: f_00004-0-1 loss: 0.850744  [   64/  306]
train() client id: f_00004-0-2 loss: 0.964641  [   96/  306]
train() client id: f_00004-0-3 loss: 0.922302  [  128/  306]
train() client id: f_00004-0-4 loss: 1.026231  [  160/  306]
train() client id: f_00004-0-5 loss: 0.986730  [  192/  306]
train() client id: f_00004-0-6 loss: 0.920042  [  224/  306]
train() client id: f_00004-0-7 loss: 0.950214  [  256/  306]
train() client id: f_00004-0-8 loss: 0.882777  [  288/  306]
train() client id: f_00004-1-0 loss: 0.839431  [   32/  306]
train() client id: f_00004-1-1 loss: 1.030731  [   64/  306]
train() client id: f_00004-1-2 loss: 0.877553  [   96/  306]
train() client id: f_00004-1-3 loss: 1.029788  [  128/  306]
train() client id: f_00004-1-4 loss: 0.815086  [  160/  306]
train() client id: f_00004-1-5 loss: 1.006854  [  192/  306]
train() client id: f_00004-1-6 loss: 0.961547  [  224/  306]
train() client id: f_00004-1-7 loss: 1.035178  [  256/  306]
train() client id: f_00004-1-8 loss: 1.008474  [  288/  306]
train() client id: f_00004-2-0 loss: 0.917522  [   32/  306]
train() client id: f_00004-2-1 loss: 1.008775  [   64/  306]
train() client id: f_00004-2-2 loss: 1.068044  [   96/  306]
train() client id: f_00004-2-3 loss: 0.745370  [  128/  306]
train() client id: f_00004-2-4 loss: 0.874125  [  160/  306]
train() client id: f_00004-2-5 loss: 0.893250  [  192/  306]
train() client id: f_00004-2-6 loss: 1.049242  [  224/  306]
train() client id: f_00004-2-7 loss: 0.949424  [  256/  306]
train() client id: f_00004-2-8 loss: 0.969464  [  288/  306]
train() client id: f_00004-3-0 loss: 1.069261  [   32/  306]
train() client id: f_00004-3-1 loss: 0.796590  [   64/  306]
train() client id: f_00004-3-2 loss: 0.842714  [   96/  306]
train() client id: f_00004-3-3 loss: 1.111353  [  128/  306]
train() client id: f_00004-3-4 loss: 0.901197  [  160/  306]
train() client id: f_00004-3-5 loss: 0.944749  [  192/  306]
train() client id: f_00004-3-6 loss: 0.955498  [  224/  306]
train() client id: f_00004-3-7 loss: 0.926756  [  256/  306]
train() client id: f_00004-3-8 loss: 1.058925  [  288/  306]
train() client id: f_00004-4-0 loss: 0.946881  [   32/  306]
train() client id: f_00004-4-1 loss: 0.993115  [   64/  306]
train() client id: f_00004-4-2 loss: 1.010756  [   96/  306]
train() client id: f_00004-4-3 loss: 0.970837  [  128/  306]
train() client id: f_00004-4-4 loss: 0.889018  [  160/  306]
train() client id: f_00004-4-5 loss: 0.915573  [  192/  306]
train() client id: f_00004-4-6 loss: 0.899537  [  224/  306]
train() client id: f_00004-4-7 loss: 0.826154  [  256/  306]
train() client id: f_00004-4-8 loss: 1.001161  [  288/  306]
train() client id: f_00004-5-0 loss: 0.942168  [   32/  306]
train() client id: f_00004-5-1 loss: 0.885982  [   64/  306]
train() client id: f_00004-5-2 loss: 0.963109  [   96/  306]
train() client id: f_00004-5-3 loss: 0.927459  [  128/  306]
train() client id: f_00004-5-4 loss: 1.026269  [  160/  306]
train() client id: f_00004-5-5 loss: 0.880714  [  192/  306]
train() client id: f_00004-5-6 loss: 0.970289  [  224/  306]
train() client id: f_00004-5-7 loss: 0.941255  [  256/  306]
train() client id: f_00004-5-8 loss: 0.954985  [  288/  306]
train() client id: f_00004-6-0 loss: 0.848664  [   32/  306]
train() client id: f_00004-6-1 loss: 1.058363  [   64/  306]
train() client id: f_00004-6-2 loss: 0.873478  [   96/  306]
train() client id: f_00004-6-3 loss: 1.010177  [  128/  306]
train() client id: f_00004-6-4 loss: 0.935626  [  160/  306]
train() client id: f_00004-6-5 loss: 0.818603  [  192/  306]
train() client id: f_00004-6-6 loss: 1.012138  [  224/  306]
train() client id: f_00004-6-7 loss: 0.964327  [  256/  306]
train() client id: f_00004-6-8 loss: 0.849178  [  288/  306]
train() client id: f_00004-7-0 loss: 0.930854  [   32/  306]
train() client id: f_00004-7-1 loss: 0.917045  [   64/  306]
train() client id: f_00004-7-2 loss: 0.839825  [   96/  306]
train() client id: f_00004-7-3 loss: 0.932154  [  128/  306]
train() client id: f_00004-7-4 loss: 0.979559  [  160/  306]
train() client id: f_00004-7-5 loss: 0.862103  [  192/  306]
train() client id: f_00004-7-6 loss: 0.973350  [  224/  306]
train() client id: f_00004-7-7 loss: 1.065607  [  256/  306]
train() client id: f_00004-7-8 loss: 0.940658  [  288/  306]
train() client id: f_00004-8-0 loss: 0.952892  [   32/  306]
train() client id: f_00004-8-1 loss: 0.976623  [   64/  306]
train() client id: f_00004-8-2 loss: 0.936879  [   96/  306]
train() client id: f_00004-8-3 loss: 0.947706  [  128/  306]
train() client id: f_00004-8-4 loss: 0.977800  [  160/  306]
train() client id: f_00004-8-5 loss: 0.868547  [  192/  306]
train() client id: f_00004-8-6 loss: 0.989689  [  224/  306]
train() client id: f_00004-8-7 loss: 0.876131  [  256/  306]
train() client id: f_00004-8-8 loss: 1.020896  [  288/  306]
train() client id: f_00004-9-0 loss: 0.910451  [   32/  306]
train() client id: f_00004-9-1 loss: 1.051972  [   64/  306]
train() client id: f_00004-9-2 loss: 0.900200  [   96/  306]
train() client id: f_00004-9-3 loss: 0.972800  [  128/  306]
train() client id: f_00004-9-4 loss: 0.850190  [  160/  306]
train() client id: f_00004-9-5 loss: 0.909164  [  192/  306]
train() client id: f_00004-9-6 loss: 1.090736  [  224/  306]
train() client id: f_00004-9-7 loss: 0.933431  [  256/  306]
train() client id: f_00004-9-8 loss: 0.885185  [  288/  306]
train() client id: f_00004-10-0 loss: 0.854131  [   32/  306]
train() client id: f_00004-10-1 loss: 0.835610  [   64/  306]
train() client id: f_00004-10-2 loss: 0.948337  [   96/  306]
train() client id: f_00004-10-3 loss: 1.072953  [  128/  306]
train() client id: f_00004-10-4 loss: 1.022041  [  160/  306]
train() client id: f_00004-10-5 loss: 0.960457  [  192/  306]
train() client id: f_00004-10-6 loss: 0.847249  [  224/  306]
train() client id: f_00004-10-7 loss: 0.895003  [  256/  306]
train() client id: f_00004-10-8 loss: 1.085149  [  288/  306]
train() client id: f_00004-11-0 loss: 0.918144  [   32/  306]
train() client id: f_00004-11-1 loss: 0.908718  [   64/  306]
train() client id: f_00004-11-2 loss: 0.975575  [   96/  306]
train() client id: f_00004-11-3 loss: 0.971414  [  128/  306]
train() client id: f_00004-11-4 loss: 1.087814  [  160/  306]
train() client id: f_00004-11-5 loss: 0.894676  [  192/  306]
train() client id: f_00004-11-6 loss: 0.787860  [  224/  306]
train() client id: f_00004-11-7 loss: 0.818997  [  256/  306]
train() client id: f_00004-11-8 loss: 1.119063  [  288/  306]
train() client id: f_00004-12-0 loss: 0.872513  [   32/  306]
train() client id: f_00004-12-1 loss: 0.967815  [   64/  306]
train() client id: f_00004-12-2 loss: 0.878253  [   96/  306]
train() client id: f_00004-12-3 loss: 0.943474  [  128/  306]
train() client id: f_00004-12-4 loss: 1.012138  [  160/  306]
train() client id: f_00004-12-5 loss: 0.868129  [  192/  306]
train() client id: f_00004-12-6 loss: 1.028458  [  224/  306]
train() client id: f_00004-12-7 loss: 0.953766  [  256/  306]
train() client id: f_00004-12-8 loss: 0.920453  [  288/  306]
train() client id: f_00005-0-0 loss: 0.759995  [   32/  146]
train() client id: f_00005-0-1 loss: 0.336745  [   64/  146]
train() client id: f_00005-0-2 loss: 0.198526  [   96/  146]
train() client id: f_00005-0-3 loss: 0.191649  [  128/  146]
train() client id: f_00005-1-0 loss: 0.157390  [   32/  146]
train() client id: f_00005-1-1 loss: 0.321944  [   64/  146]
train() client id: f_00005-1-2 loss: 0.348397  [   96/  146]
train() client id: f_00005-1-3 loss: 0.642559  [  128/  146]
train() client id: f_00005-2-0 loss: 0.485595  [   32/  146]
train() client id: f_00005-2-1 loss: 0.449260  [   64/  146]
train() client id: f_00005-2-2 loss: 0.413643  [   96/  146]
train() client id: f_00005-2-3 loss: 0.019965  [  128/  146]
train() client id: f_00005-3-0 loss: 0.494320  [   32/  146]
train() client id: f_00005-3-1 loss: 0.202067  [   64/  146]
train() client id: f_00005-3-2 loss: 0.275994  [   96/  146]
train() client id: f_00005-3-3 loss: 0.351411  [  128/  146]
train() client id: f_00005-4-0 loss: 0.220820  [   32/  146]
train() client id: f_00005-4-1 loss: 0.422083  [   64/  146]
train() client id: f_00005-4-2 loss: 0.300564  [   96/  146]
train() client id: f_00005-4-3 loss: 0.242408  [  128/  146]
train() client id: f_00005-5-0 loss: 0.267150  [   32/  146]
train() client id: f_00005-5-1 loss: 0.671926  [   64/  146]
train() client id: f_00005-5-2 loss: 0.512725  [   96/  146]
train() client id: f_00005-5-3 loss: 0.103545  [  128/  146]
train() client id: f_00005-6-0 loss: 0.136351  [   32/  146]
train() client id: f_00005-6-1 loss: 0.469731  [   64/  146]
train() client id: f_00005-6-2 loss: 0.446829  [   96/  146]
train() client id: f_00005-6-3 loss: 0.373790  [  128/  146]
train() client id: f_00005-7-0 loss: 0.591308  [   32/  146]
train() client id: f_00005-7-1 loss: 0.199010  [   64/  146]
train() client id: f_00005-7-2 loss: 0.296246  [   96/  146]
train() client id: f_00005-7-3 loss: 0.405838  [  128/  146]
train() client id: f_00005-8-0 loss: 0.280441  [   32/  146]
train() client id: f_00005-8-1 loss: 0.498321  [   64/  146]
train() client id: f_00005-8-2 loss: 0.408548  [   96/  146]
train() client id: f_00005-8-3 loss: 0.156766  [  128/  146]
train() client id: f_00005-9-0 loss: 0.275158  [   32/  146]
train() client id: f_00005-9-1 loss: 0.188672  [   64/  146]
train() client id: f_00005-9-2 loss: 0.278324  [   96/  146]
train() client id: f_00005-9-3 loss: 0.681805  [  128/  146]
train() client id: f_00005-10-0 loss: 0.349312  [   32/  146]
train() client id: f_00005-10-1 loss: 0.225059  [   64/  146]
train() client id: f_00005-10-2 loss: 0.314184  [   96/  146]
train() client id: f_00005-10-3 loss: 0.489456  [  128/  146]
train() client id: f_00005-11-0 loss: 0.159463  [   32/  146]
train() client id: f_00005-11-1 loss: 0.479961  [   64/  146]
train() client id: f_00005-11-2 loss: 0.284075  [   96/  146]
train() client id: f_00005-11-3 loss: 0.677909  [  128/  146]
train() client id: f_00005-12-0 loss: 0.301310  [   32/  146]
train() client id: f_00005-12-1 loss: 0.340476  [   64/  146]
train() client id: f_00005-12-2 loss: 0.213707  [   96/  146]
train() client id: f_00005-12-3 loss: 0.540102  [  128/  146]
train() client id: f_00006-0-0 loss: 0.497259  [   32/   54]
train() client id: f_00006-1-0 loss: 0.455468  [   32/   54]
train() client id: f_00006-2-0 loss: 0.473855  [   32/   54]
train() client id: f_00006-3-0 loss: 0.527869  [   32/   54]
train() client id: f_00006-4-0 loss: 0.517979  [   32/   54]
train() client id: f_00006-5-0 loss: 0.470943  [   32/   54]
train() client id: f_00006-6-0 loss: 0.545398  [   32/   54]
train() client id: f_00006-7-0 loss: 0.524125  [   32/   54]
train() client id: f_00006-8-0 loss: 0.492316  [   32/   54]
train() client id: f_00006-9-0 loss: 0.470720  [   32/   54]
train() client id: f_00006-10-0 loss: 0.530097  [   32/   54]
train() client id: f_00006-11-0 loss: 0.469548  [   32/   54]
train() client id: f_00006-12-0 loss: 0.447933  [   32/   54]
train() client id: f_00007-0-0 loss: 0.591015  [   32/  179]
train() client id: f_00007-0-1 loss: 0.197467  [   64/  179]
train() client id: f_00007-0-2 loss: 0.444665  [   96/  179]
train() client id: f_00007-0-3 loss: 0.240753  [  128/  179]
train() client id: f_00007-0-4 loss: 0.412186  [  160/  179]
train() client id: f_00007-1-0 loss: 0.371860  [   32/  179]
train() client id: f_00007-1-1 loss: 0.392162  [   64/  179]
train() client id: f_00007-1-2 loss: 0.208058  [   96/  179]
train() client id: f_00007-1-3 loss: 0.331217  [  128/  179]
train() client id: f_00007-1-4 loss: 0.305643  [  160/  179]
train() client id: f_00007-2-0 loss: 0.160349  [   32/  179]
train() client id: f_00007-2-1 loss: 0.455010  [   64/  179]
train() client id: f_00007-2-2 loss: 0.514433  [   96/  179]
train() client id: f_00007-2-3 loss: 0.157131  [  128/  179]
train() client id: f_00007-2-4 loss: 0.298994  [  160/  179]
train() client id: f_00007-3-0 loss: 0.278406  [   32/  179]
train() client id: f_00007-3-1 loss: 0.161015  [   64/  179]
train() client id: f_00007-3-2 loss: 0.342224  [   96/  179]
train() client id: f_00007-3-3 loss: 0.360257  [  128/  179]
train() client id: f_00007-3-4 loss: 0.294435  [  160/  179]
train() client id: f_00007-4-0 loss: 0.242315  [   32/  179]
train() client id: f_00007-4-1 loss: 0.307906  [   64/  179]
train() client id: f_00007-4-2 loss: 0.303741  [   96/  179]
train() client id: f_00007-4-3 loss: 0.500665  [  128/  179]
train() client id: f_00007-4-4 loss: 0.172610  [  160/  179]
train() client id: f_00007-5-0 loss: 0.404924  [   32/  179]
train() client id: f_00007-5-1 loss: 0.258482  [   64/  179]
train() client id: f_00007-5-2 loss: 0.377377  [   96/  179]
train() client id: f_00007-5-3 loss: 0.131569  [  128/  179]
train() client id: f_00007-5-4 loss: 0.499774  [  160/  179]
train() client id: f_00007-6-0 loss: 0.164105  [   32/  179]
train() client id: f_00007-6-1 loss: 0.228340  [   64/  179]
train() client id: f_00007-6-2 loss: 0.308996  [   96/  179]
train() client id: f_00007-6-3 loss: 0.339950  [  128/  179]
train() client id: f_00007-6-4 loss: 0.442482  [  160/  179]
train() client id: f_00007-7-0 loss: 0.230195  [   32/  179]
train() client id: f_00007-7-1 loss: 0.293380  [   64/  179]
train() client id: f_00007-7-2 loss: 0.415800  [   96/  179]
train() client id: f_00007-7-3 loss: 0.291254  [  128/  179]
train() client id: f_00007-7-4 loss: 0.354161  [  160/  179]
train() client id: f_00007-8-0 loss: 0.333069  [   32/  179]
train() client id: f_00007-8-1 loss: 0.161626  [   64/  179]
train() client id: f_00007-8-2 loss: 0.332694  [   96/  179]
train() client id: f_00007-8-3 loss: 0.238719  [  128/  179]
train() client id: f_00007-8-4 loss: 0.357863  [  160/  179]
train() client id: f_00007-9-0 loss: 0.530382  [   32/  179]
train() client id: f_00007-9-1 loss: 0.270012  [   64/  179]
train() client id: f_00007-9-2 loss: 0.219180  [   96/  179]
train() client id: f_00007-9-3 loss: 0.170046  [  128/  179]
train() client id: f_00007-9-4 loss: 0.241061  [  160/  179]
train() client id: f_00007-10-0 loss: 0.307233  [   32/  179]
train() client id: f_00007-10-1 loss: 0.242389  [   64/  179]
train() client id: f_00007-10-2 loss: 0.177812  [   96/  179]
train() client id: f_00007-10-3 loss: 0.366470  [  128/  179]
train() client id: f_00007-10-4 loss: 0.178764  [  160/  179]
train() client id: f_00007-11-0 loss: 0.449629  [   32/  179]
train() client id: f_00007-11-1 loss: 0.189103  [   64/  179]
train() client id: f_00007-11-2 loss: 0.239275  [   96/  179]
train() client id: f_00007-11-3 loss: 0.259391  [  128/  179]
train() client id: f_00007-11-4 loss: 0.301195  [  160/  179]
train() client id: f_00007-12-0 loss: 0.208303  [   32/  179]
train() client id: f_00007-12-1 loss: 0.244890  [   64/  179]
train() client id: f_00007-12-2 loss: 0.242623  [   96/  179]
train() client id: f_00007-12-3 loss: 0.241344  [  128/  179]
train() client id: f_00007-12-4 loss: 0.422867  [  160/  179]
train() client id: f_00008-0-0 loss: 0.692530  [   32/  130]
train() client id: f_00008-0-1 loss: 0.692129  [   64/  130]
train() client id: f_00008-0-2 loss: 0.544965  [   96/  130]
train() client id: f_00008-0-3 loss: 0.530460  [  128/  130]
train() client id: f_00008-1-0 loss: 0.582421  [   32/  130]
train() client id: f_00008-1-1 loss: 0.596843  [   64/  130]
train() client id: f_00008-1-2 loss: 0.564916  [   96/  130]
train() client id: f_00008-1-3 loss: 0.708154  [  128/  130]
train() client id: f_00008-2-0 loss: 0.585676  [   32/  130]
train() client id: f_00008-2-1 loss: 0.630248  [   64/  130]
train() client id: f_00008-2-2 loss: 0.573234  [   96/  130]
train() client id: f_00008-2-3 loss: 0.672697  [  128/  130]
train() client id: f_00008-3-0 loss: 0.620666  [   32/  130]
train() client id: f_00008-3-1 loss: 0.653745  [   64/  130]
train() client id: f_00008-3-2 loss: 0.621556  [   96/  130]
train() client id: f_00008-3-3 loss: 0.558678  [  128/  130]
train() client id: f_00008-4-0 loss: 0.662049  [   32/  130]
train() client id: f_00008-4-1 loss: 0.596382  [   64/  130]
train() client id: f_00008-4-2 loss: 0.639503  [   96/  130]
train() client id: f_00008-4-3 loss: 0.547569  [  128/  130]
train() client id: f_00008-5-0 loss: 0.589205  [   32/  130]
train() client id: f_00008-5-1 loss: 0.760481  [   64/  130]
train() client id: f_00008-5-2 loss: 0.623742  [   96/  130]
train() client id: f_00008-5-3 loss: 0.488505  [  128/  130]
train() client id: f_00008-6-0 loss: 0.636391  [   32/  130]
train() client id: f_00008-6-1 loss: 0.653709  [   64/  130]
train() client id: f_00008-6-2 loss: 0.584234  [   96/  130]
train() client id: f_00008-6-3 loss: 0.553325  [  128/  130]
train() client id: f_00008-7-0 loss: 0.635668  [   32/  130]
train() client id: f_00008-7-1 loss: 0.504740  [   64/  130]
train() client id: f_00008-7-2 loss: 0.565374  [   96/  130]
train() client id: f_00008-7-3 loss: 0.759899  [  128/  130]
train() client id: f_00008-8-0 loss: 0.523345  [   32/  130]
train() client id: f_00008-8-1 loss: 0.706913  [   64/  130]
train() client id: f_00008-8-2 loss: 0.704505  [   96/  130]
train() client id: f_00008-8-3 loss: 0.547679  [  128/  130]
train() client id: f_00008-9-0 loss: 0.630549  [   32/  130]
train() client id: f_00008-9-1 loss: 0.524916  [   64/  130]
train() client id: f_00008-9-2 loss: 0.676274  [   96/  130]
train() client id: f_00008-9-3 loss: 0.643548  [  128/  130]
train() client id: f_00008-10-0 loss: 0.696559  [   32/  130]
train() client id: f_00008-10-1 loss: 0.578101  [   64/  130]
train() client id: f_00008-10-2 loss: 0.624437  [   96/  130]
train() client id: f_00008-10-3 loss: 0.582355  [  128/  130]
train() client id: f_00008-11-0 loss: 0.598235  [   32/  130]
train() client id: f_00008-11-1 loss: 0.606707  [   64/  130]
train() client id: f_00008-11-2 loss: 0.625430  [   96/  130]
train() client id: f_00008-11-3 loss: 0.658020  [  128/  130]
train() client id: f_00008-12-0 loss: 0.677847  [   32/  130]
train() client id: f_00008-12-1 loss: 0.630033  [   64/  130]
train() client id: f_00008-12-2 loss: 0.601537  [   96/  130]
train() client id: f_00008-12-3 loss: 0.573860  [  128/  130]
train() client id: f_00009-0-0 loss: 0.941232  [   32/  118]
train() client id: f_00009-0-1 loss: 1.056394  [   64/  118]
train() client id: f_00009-0-2 loss: 1.015559  [   96/  118]
train() client id: f_00009-1-0 loss: 0.773484  [   32/  118]
train() client id: f_00009-1-1 loss: 0.892550  [   64/  118]
train() client id: f_00009-1-2 loss: 1.118161  [   96/  118]
train() client id: f_00009-2-0 loss: 0.696326  [   32/  118]
train() client id: f_00009-2-1 loss: 0.944186  [   64/  118]
train() client id: f_00009-2-2 loss: 0.932305  [   96/  118]
train() client id: f_00009-3-0 loss: 0.696821  [   32/  118]
train() client id: f_00009-3-1 loss: 0.973069  [   64/  118]
train() client id: f_00009-3-2 loss: 0.937664  [   96/  118]
train() client id: f_00009-4-0 loss: 0.777622  [   32/  118]
train() client id: f_00009-4-1 loss: 0.851355  [   64/  118]
train() client id: f_00009-4-2 loss: 0.847962  [   96/  118]
train() client id: f_00009-5-0 loss: 0.826151  [   32/  118]
train() client id: f_00009-5-1 loss: 0.715182  [   64/  118]
train() client id: f_00009-5-2 loss: 0.743080  [   96/  118]
train() client id: f_00009-6-0 loss: 0.757690  [   32/  118]
train() client id: f_00009-6-1 loss: 0.921928  [   64/  118]
train() client id: f_00009-6-2 loss: 0.666105  [   96/  118]
train() client id: f_00009-7-0 loss: 0.759427  [   32/  118]
train() client id: f_00009-7-1 loss: 0.699014  [   64/  118]
train() client id: f_00009-7-2 loss: 0.691424  [   96/  118]
train() client id: f_00009-8-0 loss: 0.761192  [   32/  118]
train() client id: f_00009-8-1 loss: 0.626502  [   64/  118]
train() client id: f_00009-8-2 loss: 0.808879  [   96/  118]
train() client id: f_00009-9-0 loss: 0.750039  [   32/  118]
train() client id: f_00009-9-1 loss: 0.850492  [   64/  118]
train() client id: f_00009-9-2 loss: 0.688179  [   96/  118]
train() client id: f_00009-10-0 loss: 0.648675  [   32/  118]
train() client id: f_00009-10-1 loss: 0.765588  [   64/  118]
train() client id: f_00009-10-2 loss: 0.749849  [   96/  118]
train() client id: f_00009-11-0 loss: 0.743647  [   32/  118]
train() client id: f_00009-11-1 loss: 0.642978  [   64/  118]
train() client id: f_00009-11-2 loss: 0.877999  [   96/  118]
train() client id: f_00009-12-0 loss: 0.875683  [   32/  118]
train() client id: f_00009-12-1 loss: 0.747089  [   64/  118]
train() client id: f_00009-12-2 loss: 0.752520  [   96/  118]
At round 68 accuracy: 0.636604774535809
At round 68 training accuracy: 0.5841716968477532
At round 68 training loss: 0.8439453898280487
gradient difference: 0.4254569113254547
train() client id: f_00000-0-0 loss: 1.252202  [   32/  126]
train() client id: f_00000-0-1 loss: 1.216527  [   64/  126]
train() client id: f_00000-0-2 loss: 1.014355  [   96/  126]
train() client id: f_00000-1-0 loss: 1.061385  [   32/  126]
train() client id: f_00000-1-1 loss: 0.965711  [   64/  126]
train() client id: f_00000-1-2 loss: 1.164858  [   96/  126]
train() client id: f_00000-2-0 loss: 1.113688  [   32/  126]
train() client id: f_00000-2-1 loss: 0.957201  [   64/  126]
train() client id: f_00000-2-2 loss: 0.832959  [   96/  126]
train() client id: f_00000-3-0 loss: 0.928564  [   32/  126]
train() client id: f_00000-3-1 loss: 0.933142  [   64/  126]
train() client id: f_00000-3-2 loss: 0.927090  [   96/  126]
train() client id: f_00000-4-0 loss: 0.903960  [   32/  126]
train() client id: f_00000-4-1 loss: 0.949580  [   64/  126]
train() client id: f_00000-4-2 loss: 0.840613  [   96/  126]
train() client id: f_00000-5-0 loss: 0.844229  [   32/  126]
train() client id: f_00000-5-1 loss: 0.968664  [   64/  126]
train() client id: f_00000-5-2 loss: 0.857611  [   96/  126]
train() client id: f_00000-6-0 loss: 0.866300  [   32/  126]
train() client id: f_00000-6-1 loss: 0.904217  [   64/  126]
train() client id: f_00000-6-2 loss: 0.747132  [   96/  126]
train() client id: f_00000-7-0 loss: 0.742047  [   32/  126]
train() client id: f_00000-7-1 loss: 0.907361  [   64/  126]
train() client id: f_00000-7-2 loss: 0.876182  [   96/  126]
train() client id: f_00000-8-0 loss: 0.768608  [   32/  126]
train() client id: f_00000-8-1 loss: 0.771553  [   64/  126]
train() client id: f_00000-8-2 loss: 0.831969  [   96/  126]
train() client id: f_00000-9-0 loss: 0.749007  [   32/  126]
train() client id: f_00000-9-1 loss: 0.687045  [   64/  126]
train() client id: f_00000-9-2 loss: 0.752198  [   96/  126]
train() client id: f_00000-10-0 loss: 0.798602  [   32/  126]
train() client id: f_00000-10-1 loss: 0.723665  [   64/  126]
train() client id: f_00000-10-2 loss: 0.845885  [   96/  126]
train() client id: f_00000-11-0 loss: 0.897181  [   32/  126]
train() client id: f_00000-11-1 loss: 0.706315  [   64/  126]
train() client id: f_00000-11-2 loss: 0.774958  [   96/  126]
train() client id: f_00000-12-0 loss: 0.705741  [   32/  126]
train() client id: f_00000-12-1 loss: 0.808234  [   64/  126]
train() client id: f_00000-12-2 loss: 0.735921  [   96/  126]
train() client id: f_00001-0-0 loss: 0.373579  [   32/  265]
train() client id: f_00001-0-1 loss: 0.469795  [   64/  265]
train() client id: f_00001-0-2 loss: 0.509874  [   96/  265]
train() client id: f_00001-0-3 loss: 0.484283  [  128/  265]
train() client id: f_00001-0-4 loss: 0.493936  [  160/  265]
train() client id: f_00001-0-5 loss: 0.432155  [  192/  265]
train() client id: f_00001-0-6 loss: 0.366507  [  224/  265]
train() client id: f_00001-0-7 loss: 0.448692  [  256/  265]
train() client id: f_00001-1-0 loss: 0.552549  [   32/  265]
train() client id: f_00001-1-1 loss: 0.394436  [   64/  265]
train() client id: f_00001-1-2 loss: 0.394530  [   96/  265]
train() client id: f_00001-1-3 loss: 0.455297  [  128/  265]
train() client id: f_00001-1-4 loss: 0.308411  [  160/  265]
train() client id: f_00001-1-5 loss: 0.555289  [  192/  265]
train() client id: f_00001-1-6 loss: 0.462058  [  224/  265]
train() client id: f_00001-1-7 loss: 0.339990  [  256/  265]
train() client id: f_00001-2-0 loss: 0.456998  [   32/  265]
train() client id: f_00001-2-1 loss: 0.527863  [   64/  265]
train() client id: f_00001-2-2 loss: 0.314165  [   96/  265]
train() client id: f_00001-2-3 loss: 0.425734  [  128/  265]
train() client id: f_00001-2-4 loss: 0.411445  [  160/  265]
train() client id: f_00001-2-5 loss: 0.374793  [  192/  265]
train() client id: f_00001-2-6 loss: 0.505351  [  224/  265]
train() client id: f_00001-2-7 loss: 0.446403  [  256/  265]
train() client id: f_00001-3-0 loss: 0.480029  [   32/  265]
train() client id: f_00001-3-1 loss: 0.512137  [   64/  265]
train() client id: f_00001-3-2 loss: 0.352483  [   96/  265]
train() client id: f_00001-3-3 loss: 0.358736  [  128/  265]
train() client id: f_00001-3-4 loss: 0.422042  [  160/  265]
train() client id: f_00001-3-5 loss: 0.361793  [  192/  265]
train() client id: f_00001-3-6 loss: 0.479345  [  224/  265]
train() client id: f_00001-3-7 loss: 0.423962  [  256/  265]
train() client id: f_00001-4-0 loss: 0.390704  [   32/  265]
train() client id: f_00001-4-1 loss: 0.393694  [   64/  265]
train() client id: f_00001-4-2 loss: 0.354655  [   96/  265]
train() client id: f_00001-4-3 loss: 0.389990  [  128/  265]
train() client id: f_00001-4-4 loss: 0.464551  [  160/  265]
train() client id: f_00001-4-5 loss: 0.527366  [  192/  265]
train() client id: f_00001-4-6 loss: 0.577011  [  224/  265]
train() client id: f_00001-4-7 loss: 0.340495  [  256/  265]
train() client id: f_00001-5-0 loss: 0.490804  [   32/  265]
train() client id: f_00001-5-1 loss: 0.405571  [   64/  265]
train() client id: f_00001-5-2 loss: 0.419006  [   96/  265]
train() client id: f_00001-5-3 loss: 0.488346  [  128/  265]
train() client id: f_00001-5-4 loss: 0.430991  [  160/  265]
train() client id: f_00001-5-5 loss: 0.322505  [  192/  265]
train() client id: f_00001-5-6 loss: 0.330852  [  224/  265]
train() client id: f_00001-5-7 loss: 0.478796  [  256/  265]
train() client id: f_00001-6-0 loss: 0.367587  [   32/  265]
train() client id: f_00001-6-1 loss: 0.314873  [   64/  265]
train() client id: f_00001-6-2 loss: 0.573560  [   96/  265]
train() client id: f_00001-6-3 loss: 0.435198  [  128/  265]
train() client id: f_00001-6-4 loss: 0.365645  [  160/  265]
train() client id: f_00001-6-5 loss: 0.415853  [  192/  265]
train() client id: f_00001-6-6 loss: 0.518461  [  224/  265]
train() client id: f_00001-6-7 loss: 0.368633  [  256/  265]
train() client id: f_00001-7-0 loss: 0.382787  [   32/  265]
train() client id: f_00001-7-1 loss: 0.396311  [   64/  265]
train() client id: f_00001-7-2 loss: 0.447890  [   96/  265]
train() client id: f_00001-7-3 loss: 0.349028  [  128/  265]
train() client id: f_00001-7-4 loss: 0.519911  [  160/  265]
train() client id: f_00001-7-5 loss: 0.486104  [  192/  265]
train() client id: f_00001-7-6 loss: 0.385357  [  224/  265]
train() client id: f_00001-7-7 loss: 0.343054  [  256/  265]
train() client id: f_00001-8-0 loss: 0.325393  [   32/  265]
train() client id: f_00001-8-1 loss: 0.678949  [   64/  265]
train() client id: f_00001-8-2 loss: 0.338628  [   96/  265]
train() client id: f_00001-8-3 loss: 0.376766  [  128/  265]
train() client id: f_00001-8-4 loss: 0.411815  [  160/  265]
train() client id: f_00001-8-5 loss: 0.376898  [  192/  265]
train() client id: f_00001-8-6 loss: 0.521545  [  224/  265]
train() client id: f_00001-8-7 loss: 0.366032  [  256/  265]
train() client id: f_00001-9-0 loss: 0.341384  [   32/  265]
train() client id: f_00001-9-1 loss: 0.390932  [   64/  265]
train() client id: f_00001-9-2 loss: 0.381611  [   96/  265]
train() client id: f_00001-9-3 loss: 0.318789  [  128/  265]
train() client id: f_00001-9-4 loss: 0.634518  [  160/  265]
train() client id: f_00001-9-5 loss: 0.350546  [  192/  265]
train() client id: f_00001-9-6 loss: 0.414354  [  224/  265]
train() client id: f_00001-9-7 loss: 0.420631  [  256/  265]
train() client id: f_00001-10-0 loss: 0.313731  [   32/  265]
train() client id: f_00001-10-1 loss: 0.429278  [   64/  265]
train() client id: f_00001-10-2 loss: 0.386337  [   96/  265]
train() client id: f_00001-10-3 loss: 0.420469  [  128/  265]
train() client id: f_00001-10-4 loss: 0.488661  [  160/  265]
train() client id: f_00001-10-5 loss: 0.450130  [  192/  265]
train() client id: f_00001-10-6 loss: 0.402994  [  224/  265]
train() client id: f_00001-10-7 loss: 0.414450  [  256/  265]
train() client id: f_00001-11-0 loss: 0.467723  [   32/  265]
train() client id: f_00001-11-1 loss: 0.316122  [   64/  265]
train() client id: f_00001-11-2 loss: 0.388273  [   96/  265]
train() client id: f_00001-11-3 loss: 0.422829  [  128/  265]
train() client id: f_00001-11-4 loss: 0.333306  [  160/  265]
train() client id: f_00001-11-5 loss: 0.451481  [  192/  265]
train() client id: f_00001-11-6 loss: 0.512893  [  224/  265]
train() client id: f_00001-11-7 loss: 0.434000  [  256/  265]
train() client id: f_00001-12-0 loss: 0.369312  [   32/  265]
train() client id: f_00001-12-1 loss: 0.555758  [   64/  265]
train() client id: f_00001-12-2 loss: 0.464174  [   96/  265]
train() client id: f_00001-12-3 loss: 0.424678  [  128/  265]
train() client id: f_00001-12-4 loss: 0.389375  [  160/  265]
train() client id: f_00001-12-5 loss: 0.417662  [  192/  265]
train() client id: f_00001-12-6 loss: 0.407939  [  224/  265]
train() client id: f_00001-12-7 loss: 0.363107  [  256/  265]
train() client id: f_00002-0-0 loss: 1.187829  [   32/  124]
train() client id: f_00002-0-1 loss: 1.329372  [   64/  124]
train() client id: f_00002-0-2 loss: 1.455882  [   96/  124]
train() client id: f_00002-1-0 loss: 1.332360  [   32/  124]
train() client id: f_00002-1-1 loss: 1.302899  [   64/  124]
train() client id: f_00002-1-2 loss: 1.313865  [   96/  124]
train() client id: f_00002-2-0 loss: 1.372283  [   32/  124]
train() client id: f_00002-2-1 loss: 1.499953  [   64/  124]
train() client id: f_00002-2-2 loss: 1.097606  [   96/  124]
train() client id: f_00002-3-0 loss: 1.187988  [   32/  124]
train() client id: f_00002-3-1 loss: 1.407859  [   64/  124]
train() client id: f_00002-3-2 loss: 1.179362  [   96/  124]
train() client id: f_00002-4-0 loss: 1.302051  [   32/  124]
train() client id: f_00002-4-1 loss: 1.141304  [   64/  124]
train() client id: f_00002-4-2 loss: 1.451868  [   96/  124]
train() client id: f_00002-5-0 loss: 1.217260  [   32/  124]
train() client id: f_00002-5-1 loss: 1.357865  [   64/  124]
train() client id: f_00002-5-2 loss: 1.137470  [   96/  124]
train() client id: f_00002-6-0 loss: 1.141257  [   32/  124]
train() client id: f_00002-6-1 loss: 1.079278  [   64/  124]
train() client id: f_00002-6-2 loss: 1.426930  [   96/  124]
train() client id: f_00002-7-0 loss: 1.145981  [   32/  124]
train() client id: f_00002-7-1 loss: 1.217146  [   64/  124]
train() client id: f_00002-7-2 loss: 1.137641  [   96/  124]
train() client id: f_00002-8-0 loss: 1.160889  [   32/  124]
train() client id: f_00002-8-1 loss: 1.217217  [   64/  124]
train() client id: f_00002-8-2 loss: 1.178525  [   96/  124]
train() client id: f_00002-9-0 loss: 1.329174  [   32/  124]
train() client id: f_00002-9-1 loss: 1.211981  [   64/  124]
train() client id: f_00002-9-2 loss: 0.982491  [   96/  124]
train() client id: f_00002-10-0 loss: 1.207488  [   32/  124]
train() client id: f_00002-10-1 loss: 1.141867  [   64/  124]
train() client id: f_00002-10-2 loss: 1.171179  [   96/  124]
train() client id: f_00002-11-0 loss: 1.139295  [   32/  124]
train() client id: f_00002-11-1 loss: 1.215563  [   64/  124]
train() client id: f_00002-11-2 loss: 1.082736  [   96/  124]
train() client id: f_00002-12-0 loss: 1.245783  [   32/  124]
train() client id: f_00002-12-1 loss: 1.151219  [   64/  124]
train() client id: f_00002-12-2 loss: 1.233266  [   96/  124]
train() client id: f_00003-0-0 loss: 0.856729  [   32/   43]
train() client id: f_00003-1-0 loss: 0.681119  [   32/   43]
train() client id: f_00003-2-0 loss: 0.614092  [   32/   43]
train() client id: f_00003-3-0 loss: 0.775496  [   32/   43]
train() client id: f_00003-4-0 loss: 0.645052  [   32/   43]
train() client id: f_00003-5-0 loss: 0.729989  [   32/   43]
train() client id: f_00003-6-0 loss: 0.879064  [   32/   43]
train() client id: f_00003-7-0 loss: 0.679819  [   32/   43]
train() client id: f_00003-8-0 loss: 0.750782  [   32/   43]
train() client id: f_00003-9-0 loss: 0.850380  [   32/   43]
train() client id: f_00003-10-0 loss: 0.765979  [   32/   43]
train() client id: f_00003-11-0 loss: 0.784897  [   32/   43]
train() client id: f_00003-12-0 loss: 0.689367  [   32/   43]
train() client id: f_00004-0-0 loss: 0.815409  [   32/  306]
train() client id: f_00004-0-1 loss: 0.967857  [   64/  306]
train() client id: f_00004-0-2 loss: 0.907517  [   96/  306]
train() client id: f_00004-0-3 loss: 0.833086  [  128/  306]
train() client id: f_00004-0-4 loss: 0.980034  [  160/  306]
train() client id: f_00004-0-5 loss: 1.033879  [  192/  306]
train() client id: f_00004-0-6 loss: 0.857996  [  224/  306]
train() client id: f_00004-0-7 loss: 0.769483  [  256/  306]
train() client id: f_00004-0-8 loss: 0.901096  [  288/  306]
train() client id: f_00004-1-0 loss: 0.838130  [   32/  306]
train() client id: f_00004-1-1 loss: 0.935548  [   64/  306]
train() client id: f_00004-1-2 loss: 1.030920  [   96/  306]
train() client id: f_00004-1-3 loss: 1.023876  [  128/  306]
train() client id: f_00004-1-4 loss: 0.868456  [  160/  306]
train() client id: f_00004-1-5 loss: 0.722412  [  192/  306]
train() client id: f_00004-1-6 loss: 0.927002  [  224/  306]
train() client id: f_00004-1-7 loss: 0.866098  [  256/  306]
train() client id: f_00004-1-8 loss: 0.780273  [  288/  306]
train() client id: f_00004-2-0 loss: 0.960382  [   32/  306]
train() client id: f_00004-2-1 loss: 0.883357  [   64/  306]
train() client id: f_00004-2-2 loss: 0.913328  [   96/  306]
train() client id: f_00004-2-3 loss: 0.804187  [  128/  306]
train() client id: f_00004-2-4 loss: 0.717180  [  160/  306]
train() client id: f_00004-2-5 loss: 1.087807  [  192/  306]
train() client id: f_00004-2-6 loss: 0.897101  [  224/  306]
train() client id: f_00004-2-7 loss: 0.874061  [  256/  306]
train() client id: f_00004-2-8 loss: 0.825239  [  288/  306]
train() client id: f_00004-3-0 loss: 0.743055  [   32/  306]
train() client id: f_00004-3-1 loss: 0.812716  [   64/  306]
train() client id: f_00004-3-2 loss: 0.815261  [   96/  306]
train() client id: f_00004-3-3 loss: 0.858051  [  128/  306]
train() client id: f_00004-3-4 loss: 0.797542  [  160/  306]
train() client id: f_00004-3-5 loss: 0.912576  [  192/  306]
train() client id: f_00004-3-6 loss: 1.028907  [  224/  306]
train() client id: f_00004-3-7 loss: 0.988821  [  256/  306]
train() client id: f_00004-3-8 loss: 0.979302  [  288/  306]
train() client id: f_00004-4-0 loss: 0.993367  [   32/  306]
train() client id: f_00004-4-1 loss: 0.942546  [   64/  306]
train() client id: f_00004-4-2 loss: 0.837327  [   96/  306]
train() client id: f_00004-4-3 loss: 0.991644  [  128/  306]
train() client id: f_00004-4-4 loss: 0.913523  [  160/  306]
train() client id: f_00004-4-5 loss: 0.844201  [  192/  306]
train() client id: f_00004-4-6 loss: 0.822895  [  224/  306]
train() client id: f_00004-4-7 loss: 0.836050  [  256/  306]
train() client id: f_00004-4-8 loss: 0.719862  [  288/  306]
train() client id: f_00004-5-0 loss: 0.885370  [   32/  306]
train() client id: f_00004-5-1 loss: 0.920920  [   64/  306]
train() client id: f_00004-5-2 loss: 0.819400  [   96/  306]
train() client id: f_00004-5-3 loss: 0.913365  [  128/  306]
train() client id: f_00004-5-4 loss: 0.861597  [  160/  306]
train() client id: f_00004-5-5 loss: 0.927662  [  192/  306]
train() client id: f_00004-5-6 loss: 0.777870  [  224/  306]
train() client id: f_00004-5-7 loss: 0.744313  [  256/  306]
train() client id: f_00004-5-8 loss: 0.938906  [  288/  306]
train() client id: f_00004-6-0 loss: 0.818347  [   32/  306]
train() client id: f_00004-6-1 loss: 0.824278  [   64/  306]
train() client id: f_00004-6-2 loss: 0.833504  [   96/  306]
train() client id: f_00004-6-3 loss: 0.863098  [  128/  306]
train() client id: f_00004-6-4 loss: 0.943359  [  160/  306]
train() client id: f_00004-6-5 loss: 0.698411  [  192/  306]
train() client id: f_00004-6-6 loss: 0.918770  [  224/  306]
train() client id: f_00004-6-7 loss: 0.897373  [  256/  306]
train() client id: f_00004-6-8 loss: 0.925443  [  288/  306]
train() client id: f_00004-7-0 loss: 0.733572  [   32/  306]
train() client id: f_00004-7-1 loss: 0.831927  [   64/  306]
train() client id: f_00004-7-2 loss: 0.931363  [   96/  306]
train() client id: f_00004-7-3 loss: 0.977883  [  128/  306]
train() client id: f_00004-7-4 loss: 0.879034  [  160/  306]
train() client id: f_00004-7-5 loss: 0.855120  [  192/  306]
train() client id: f_00004-7-6 loss: 0.872984  [  224/  306]
train() client id: f_00004-7-7 loss: 0.979077  [  256/  306]
train() client id: f_00004-7-8 loss: 0.762376  [  288/  306]
train() client id: f_00004-8-0 loss: 0.930257  [   32/  306]
train() client id: f_00004-8-1 loss: 0.835031  [   64/  306]
train() client id: f_00004-8-2 loss: 1.012190  [   96/  306]
train() client id: f_00004-8-3 loss: 0.787565  [  128/  306]
train() client id: f_00004-8-4 loss: 0.747685  [  160/  306]
train() client id: f_00004-8-5 loss: 0.839725  [  192/  306]
train() client id: f_00004-8-6 loss: 0.826407  [  224/  306]
train() client id: f_00004-8-7 loss: 0.941587  [  256/  306]
train() client id: f_00004-8-8 loss: 0.895729  [  288/  306]
train() client id: f_00004-9-0 loss: 0.931872  [   32/  306]
train() client id: f_00004-9-1 loss: 0.830311  [   64/  306]
train() client id: f_00004-9-2 loss: 0.877200  [   96/  306]
train() client id: f_00004-9-3 loss: 0.774774  [  128/  306]
train() client id: f_00004-9-4 loss: 0.856032  [  160/  306]
train() client id: f_00004-9-5 loss: 0.771706  [  192/  306]
train() client id: f_00004-9-6 loss: 0.760359  [  224/  306]
train() client id: f_00004-9-7 loss: 0.821692  [  256/  306]
train() client id: f_00004-9-8 loss: 1.017843  [  288/  306]
train() client id: f_00004-10-0 loss: 0.817598  [   32/  306]
train() client id: f_00004-10-1 loss: 0.939151  [   64/  306]
train() client id: f_00004-10-2 loss: 0.952519  [   96/  306]
train() client id: f_00004-10-3 loss: 0.869234  [  128/  306]
train() client id: f_00004-10-4 loss: 0.891654  [  160/  306]
train() client id: f_00004-10-5 loss: 0.874773  [  192/  306]
train() client id: f_00004-10-6 loss: 0.729422  [  224/  306]
train() client id: f_00004-10-7 loss: 0.847336  [  256/  306]
train() client id: f_00004-10-8 loss: 0.826867  [  288/  306]
train() client id: f_00004-11-0 loss: 0.820995  [   32/  306]
train() client id: f_00004-11-1 loss: 0.900797  [   64/  306]
train() client id: f_00004-11-2 loss: 0.788994  [   96/  306]
train() client id: f_00004-11-3 loss: 0.958665  [  128/  306]
train() client id: f_00004-11-4 loss: 0.839666  [  160/  306]
train() client id: f_00004-11-5 loss: 0.912416  [  192/  306]
train() client id: f_00004-11-6 loss: 0.814920  [  224/  306]
train() client id: f_00004-11-7 loss: 0.917986  [  256/  306]
train() client id: f_00004-11-8 loss: 0.806671  [  288/  306]
train() client id: f_00004-12-0 loss: 0.887479  [   32/  306]
train() client id: f_00004-12-1 loss: 0.854171  [   64/  306]
train() client id: f_00004-12-2 loss: 0.960032  [   96/  306]
train() client id: f_00004-12-3 loss: 0.872637  [  128/  306]
train() client id: f_00004-12-4 loss: 0.838993  [  160/  306]
train() client id: f_00004-12-5 loss: 0.775661  [  192/  306]
train() client id: f_00004-12-6 loss: 0.932694  [  224/  306]
train() client id: f_00004-12-7 loss: 0.791680  [  256/  306]
train() client id: f_00004-12-8 loss: 0.848180  [  288/  306]
train() client id: f_00005-0-0 loss: 0.174725  [   32/  146]
train() client id: f_00005-0-1 loss: 0.486756  [   64/  146]
train() client id: f_00005-0-2 loss: 0.216261  [   96/  146]
train() client id: f_00005-0-3 loss: 0.575864  [  128/  146]
train() client id: f_00005-1-0 loss: 0.240505  [   32/  146]
train() client id: f_00005-1-1 loss: 0.335577  [   64/  146]
train() client id: f_00005-1-2 loss: 0.299232  [   96/  146]
train() client id: f_00005-1-3 loss: 0.667388  [  128/  146]
train() client id: f_00005-2-0 loss: 0.293915  [   32/  146]
train() client id: f_00005-2-1 loss: 0.568915  [   64/  146]
train() client id: f_00005-2-2 loss: 0.485460  [   96/  146]
train() client id: f_00005-2-3 loss: 0.281640  [  128/  146]
train() client id: f_00005-3-0 loss: 0.167577  [   32/  146]
train() client id: f_00005-3-1 loss: 0.493436  [   64/  146]
train() client id: f_00005-3-2 loss: 0.304172  [   96/  146]
train() client id: f_00005-3-3 loss: 0.506247  [  128/  146]
train() client id: f_00005-4-0 loss: 0.182828  [   32/  146]
train() client id: f_00005-4-1 loss: 0.296943  [   64/  146]
train() client id: f_00005-4-2 loss: 0.511101  [   96/  146]
train() client id: f_00005-4-3 loss: 0.413795  [  128/  146]
train() client id: f_00005-5-0 loss: 0.381296  [   32/  146]
train() client id: f_00005-5-1 loss: 0.332464  [   64/  146]
train() client id: f_00005-5-2 loss: 0.469068  [   96/  146]
train() client id: f_00005-5-3 loss: 0.382627  [  128/  146]
train() client id: f_00005-6-0 loss: 0.567810  [   32/  146]
train() client id: f_00005-6-1 loss: 0.392587  [   64/  146]
train() client id: f_00005-6-2 loss: 0.223138  [   96/  146]
train() client id: f_00005-6-3 loss: 0.333155  [  128/  146]
train() client id: f_00005-7-0 loss: 0.435015  [   32/  146]
train() client id: f_00005-7-1 loss: 0.270985  [   64/  146]
train() client id: f_00005-7-2 loss: 0.325615  [   96/  146]
train() client id: f_00005-7-3 loss: 0.245855  [  128/  146]
train() client id: f_00005-8-0 loss: 0.148342  [   32/  146]
train() client id: f_00005-8-1 loss: 0.394036  [   64/  146]
train() client id: f_00005-8-2 loss: 0.335739  [   96/  146]
train() client id: f_00005-8-3 loss: 0.197986  [  128/  146]
train() client id: f_00005-9-0 loss: 0.322853  [   32/  146]
train() client id: f_00005-9-1 loss: 0.329960  [   64/  146]
train() client id: f_00005-9-2 loss: 0.565648  [   96/  146]
train() client id: f_00005-9-3 loss: 0.286819  [  128/  146]
train() client id: f_00005-10-0 loss: 0.204076  [   32/  146]
train() client id: f_00005-10-1 loss: 0.257700  [   64/  146]
train() client id: f_00005-10-2 loss: 0.274946  [   96/  146]
train() client id: f_00005-10-3 loss: 0.577177  [  128/  146]
train() client id: f_00005-11-0 loss: 0.118378  [   32/  146]
train() client id: f_00005-11-1 loss: 0.348576  [   64/  146]
train() client id: f_00005-11-2 loss: 0.509014  [   96/  146]
train() client id: f_00005-11-3 loss: 0.316720  [  128/  146]
train() client id: f_00005-12-0 loss: 0.309619  [   32/  146]
train() client id: f_00005-12-1 loss: 0.343767  [   64/  146]
train() client id: f_00005-12-2 loss: 0.326739  [   96/  146]
train() client id: f_00005-12-3 loss: 0.356967  [  128/  146]
train() client id: f_00006-0-0 loss: 0.542716  [   32/   54]
train() client id: f_00006-1-0 loss: 0.487820  [   32/   54]
train() client id: f_00006-2-0 loss: 0.525936  [   32/   54]
train() client id: f_00006-3-0 loss: 0.489962  [   32/   54]
train() client id: f_00006-4-0 loss: 0.467676  [   32/   54]
train() client id: f_00006-5-0 loss: 0.521550  [   32/   54]
train() client id: f_00006-6-0 loss: 0.557480  [   32/   54]
train() client id: f_00006-7-0 loss: 0.559362  [   32/   54]
train() client id: f_00006-8-0 loss: 0.463710  [   32/   54]
train() client id: f_00006-9-0 loss: 0.540778  [   32/   54]
train() client id: f_00006-10-0 loss: 0.538806  [   32/   54]
train() client id: f_00006-11-0 loss: 0.516133  [   32/   54]
train() client id: f_00006-12-0 loss: 0.522629  [   32/   54]
train() client id: f_00007-0-0 loss: 0.431521  [   32/  179]
train() client id: f_00007-0-1 loss: 0.437609  [   64/  179]
train() client id: f_00007-0-2 loss: 0.434235  [   96/  179]
train() client id: f_00007-0-3 loss: 0.539161  [  128/  179]
train() client id: f_00007-0-4 loss: 0.584028  [  160/  179]
train() client id: f_00007-1-0 loss: 0.447142  [   32/  179]
train() client id: f_00007-1-1 loss: 0.302639  [   64/  179]
train() client id: f_00007-1-2 loss: 0.499623  [   96/  179]
train() client id: f_00007-1-3 loss: 0.388907  [  128/  179]
train() client id: f_00007-1-4 loss: 0.562234  [  160/  179]
train() client id: f_00007-2-0 loss: 0.557670  [   32/  179]
train() client id: f_00007-2-1 loss: 0.558655  [   64/  179]
train() client id: f_00007-2-2 loss: 0.357666  [   96/  179]
train() client id: f_00007-2-3 loss: 0.384509  [  128/  179]
train() client id: f_00007-2-4 loss: 0.403395  [  160/  179]
train() client id: f_00007-3-0 loss: 0.481939  [   32/  179]
train() client id: f_00007-3-1 loss: 0.515993  [   64/  179]
train() client id: f_00007-3-2 loss: 0.240586  [   96/  179]
train() client id: f_00007-3-3 loss: 0.459639  [  128/  179]
train() client id: f_00007-3-4 loss: 0.327839  [  160/  179]
train() client id: f_00007-4-0 loss: 0.485456  [   32/  179]
train() client id: f_00007-4-1 loss: 0.370372  [   64/  179]
train() client id: f_00007-4-2 loss: 0.494108  [   96/  179]
train() client id: f_00007-4-3 loss: 0.458530  [  128/  179]
train() client id: f_00007-4-4 loss: 0.361327  [  160/  179]
train() client id: f_00007-5-0 loss: 0.408916  [   32/  179]
train() client id: f_00007-5-1 loss: 0.391845  [   64/  179]
train() client id: f_00007-5-2 loss: 0.477887  [   96/  179]
train() client id: f_00007-5-3 loss: 0.418451  [  128/  179]
train() client id: f_00007-5-4 loss: 0.294040  [  160/  179]
train() client id: f_00007-6-0 loss: 0.333387  [   32/  179]
train() client id: f_00007-6-1 loss: 0.467585  [   64/  179]
train() client id: f_00007-6-2 loss: 0.436900  [   96/  179]
train() client id: f_00007-6-3 loss: 0.344589  [  128/  179]
train() client id: f_00007-6-4 loss: 0.542509  [  160/  179]
train() client id: f_00007-7-0 loss: 0.697444  [   32/  179]
train() client id: f_00007-7-1 loss: 0.197108  [   64/  179]
train() client id: f_00007-7-2 loss: 0.403774  [   96/  179]
train() client id: f_00007-7-3 loss: 0.320530  [  128/  179]
train() client id: f_00007-7-4 loss: 0.374058  [  160/  179]
train() client id: f_00007-8-0 loss: 0.298140  [   32/  179]
train() client id: f_00007-8-1 loss: 0.321795  [   64/  179]
train() client id: f_00007-8-2 loss: 0.455564  [   96/  179]
train() client id: f_00007-8-3 loss: 0.471271  [  128/  179]
train() client id: f_00007-8-4 loss: 0.538928  [  160/  179]
train() client id: f_00007-9-0 loss: 0.406361  [   32/  179]
train() client id: f_00007-9-1 loss: 0.317318  [   64/  179]
train() client id: f_00007-9-2 loss: 0.292160  [   96/  179]
train() client id: f_00007-9-3 loss: 0.217522  [  128/  179]
train() client id: f_00007-9-4 loss: 0.813607  [  160/  179]
train() client id: f_00007-10-0 loss: 0.450517  [   32/  179]
train() client id: f_00007-10-1 loss: 0.211961  [   64/  179]
train() client id: f_00007-10-2 loss: 0.464352  [   96/  179]
train() client id: f_00007-10-3 loss: 0.433634  [  128/  179]
train() client id: f_00007-10-4 loss: 0.443869  [  160/  179]
train() client id: f_00007-11-0 loss: 0.464835  [   32/  179]
train() client id: f_00007-11-1 loss: 0.481347  [   64/  179]
train() client id: f_00007-11-2 loss: 0.306784  [   96/  179]
train() client id: f_00007-11-3 loss: 0.290487  [  128/  179]
train() client id: f_00007-11-4 loss: 0.463103  [  160/  179]
train() client id: f_00007-12-0 loss: 0.427409  [   32/  179]
train() client id: f_00007-12-1 loss: 0.306264  [   64/  179]
train() client id: f_00007-12-2 loss: 0.772647  [   96/  179]
train() client id: f_00007-12-3 loss: 0.241150  [  128/  179]
train() client id: f_00007-12-4 loss: 0.245518  [  160/  179]
train() client id: f_00008-0-0 loss: 0.725312  [   32/  130]
train() client id: f_00008-0-1 loss: 0.711068  [   64/  130]
train() client id: f_00008-0-2 loss: 0.783102  [   96/  130]
train() client id: f_00008-0-3 loss: 0.790719  [  128/  130]
train() client id: f_00008-1-0 loss: 0.630521  [   32/  130]
train() client id: f_00008-1-1 loss: 0.678963  [   64/  130]
train() client id: f_00008-1-2 loss: 0.921561  [   96/  130]
train() client id: f_00008-1-3 loss: 0.799837  [  128/  130]
train() client id: f_00008-2-0 loss: 0.858891  [   32/  130]
train() client id: f_00008-2-1 loss: 0.760897  [   64/  130]
train() client id: f_00008-2-2 loss: 0.634227  [   96/  130]
train() client id: f_00008-2-3 loss: 0.740282  [  128/  130]
train() client id: f_00008-3-0 loss: 0.744046  [   32/  130]
train() client id: f_00008-3-1 loss: 0.714895  [   64/  130]
train() client id: f_00008-3-2 loss: 0.725510  [   96/  130]
train() client id: f_00008-3-3 loss: 0.843835  [  128/  130]
train() client id: f_00008-4-0 loss: 0.790361  [   32/  130]
train() client id: f_00008-4-1 loss: 0.716640  [   64/  130]
train() client id: f_00008-4-2 loss: 0.763417  [   96/  130]
train() client id: f_00008-4-3 loss: 0.678606  [  128/  130]
train() client id: f_00008-5-0 loss: 0.650623  [   32/  130]
train() client id: f_00008-5-1 loss: 0.829842  [   64/  130]
train() client id: f_00008-5-2 loss: 0.609760  [   96/  130]
train() client id: f_00008-5-3 loss: 0.880999  [  128/  130]
train() client id: f_00008-6-0 loss: 0.752928  [   32/  130]
train() client id: f_00008-6-1 loss: 0.663413  [   64/  130]
train() client id: f_00008-6-2 loss: 0.837386  [   96/  130]
train() client id: f_00008-6-3 loss: 0.728108  [  128/  130]
train() client id: f_00008-7-0 loss: 0.793304  [   32/  130]
train() client id: f_00008-7-1 loss: 0.712147  [   64/  130]
train() client id: f_00008-7-2 loss: 0.758052  [   96/  130]
train() client id: f_00008-7-3 loss: 0.710516  [  128/  130]
train() client id: f_00008-8-0 loss: 0.711309  [   32/  130]
train() client id: f_00008-8-1 loss: 0.746233  [   64/  130]
train() client id: f_00008-8-2 loss: 0.755796  [   96/  130]
train() client id: f_00008-8-3 loss: 0.773090  [  128/  130]
train() client id: f_00008-9-0 loss: 0.772709  [   32/  130]
train() client id: f_00008-9-1 loss: 0.773104  [   64/  130]
train() client id: f_00008-9-2 loss: 0.693522  [   96/  130]
train() client id: f_00008-9-3 loss: 0.733624  [  128/  130]
train() client id: f_00008-10-0 loss: 0.767922  [   32/  130]
train() client id: f_00008-10-1 loss: 0.784823  [   64/  130]
train() client id: f_00008-10-2 loss: 0.711039  [   96/  130]
train() client id: f_00008-10-3 loss: 0.737792  [  128/  130]
train() client id: f_00008-11-0 loss: 0.748733  [   32/  130]
train() client id: f_00008-11-1 loss: 0.693539  [   64/  130]
train() client id: f_00008-11-2 loss: 0.712301  [   96/  130]
train() client id: f_00008-11-3 loss: 0.833185  [  128/  130]
train() client id: f_00008-12-0 loss: 0.738296  [   32/  130]
train() client id: f_00008-12-1 loss: 0.753238  [   64/  130]
train() client id: f_00008-12-2 loss: 0.746791  [   96/  130]
train() client id: f_00008-12-3 loss: 0.730655  [  128/  130]
train() client id: f_00009-0-0 loss: 1.014935  [   32/  118]
train() client id: f_00009-0-1 loss: 0.867286  [   64/  118]
train() client id: f_00009-0-2 loss: 0.984026  [   96/  118]
train() client id: f_00009-1-0 loss: 0.959560  [   32/  118]
train() client id: f_00009-1-1 loss: 0.800384  [   64/  118]
train() client id: f_00009-1-2 loss: 0.989852  [   96/  118]
train() client id: f_00009-2-0 loss: 0.812284  [   32/  118]
train() client id: f_00009-2-1 loss: 1.034014  [   64/  118]
train() client id: f_00009-2-2 loss: 0.825129  [   96/  118]
train() client id: f_00009-3-0 loss: 0.954295  [   32/  118]
train() client id: f_00009-3-1 loss: 0.763564  [   64/  118]
train() client id: f_00009-3-2 loss: 0.827682  [   96/  118]
train() client id: f_00009-4-0 loss: 0.748717  [   32/  118]
train() client id: f_00009-4-1 loss: 0.879298  [   64/  118]
train() client id: f_00009-4-2 loss: 0.890807  [   96/  118]
train() client id: f_00009-5-0 loss: 0.737008  [   32/  118]
train() client id: f_00009-5-1 loss: 0.745049  [   64/  118]
train() client id: f_00009-5-2 loss: 1.071299  [   96/  118]
train() client id: f_00009-6-0 loss: 0.828435  [   32/  118]
train() client id: f_00009-6-1 loss: 0.610329  [   64/  118]
train() client id: f_00009-6-2 loss: 0.798438  [   96/  118]
train() client id: f_00009-7-0 loss: 0.751813  [   32/  118]
train() client id: f_00009-7-1 loss: 0.926872  [   64/  118]
train() client id: f_00009-7-2 loss: 0.804791  [   96/  118]
train() client id: f_00009-8-0 loss: 0.909470  [   32/  118]
train() client id: f_00009-8-1 loss: 0.628419  [   64/  118]
train() client id: f_00009-8-2 loss: 0.727935  [   96/  118]
train() client id: f_00009-9-0 loss: 0.909633  [   32/  118]
train() client id: f_00009-9-1 loss: 0.895893  [   64/  118]
train() client id: f_00009-9-2 loss: 0.569895  [   96/  118]
train() client id: f_00009-10-0 loss: 0.994718  [   32/  118]
train() client id: f_00009-10-1 loss: 0.722623  [   64/  118]
train() client id: f_00009-10-2 loss: 0.680750  [   96/  118]
train() client id: f_00009-11-0 loss: 0.729712  [   32/  118]
train() client id: f_00009-11-1 loss: 0.902761  [   64/  118]
train() client id: f_00009-11-2 loss: 0.790537  [   96/  118]
train() client id: f_00009-12-0 loss: 0.828198  [   32/  118]
train() client id: f_00009-12-1 loss: 0.756125  [   64/  118]
train() client id: f_00009-12-2 loss: 0.763053  [   96/  118]
At round 69 accuracy: 0.636604774535809
At round 69 training accuracy: 0.5835010060362174
At round 69 training loss: 0.8377571666804358
gradient difference: 0.39865660667419434
train() client id: f_00000-0-0 loss: 1.492792  [   32/  126]
train() client id: f_00000-0-1 loss: 1.078950  [   64/  126]
train() client id: f_00000-0-2 loss: 1.062155  [   96/  126]
train() client id: f_00000-1-0 loss: 1.095691  [   32/  126]
train() client id: f_00000-1-1 loss: 1.072608  [   64/  126]
train() client id: f_00000-1-2 loss: 1.014078  [   96/  126]
train() client id: f_00000-2-0 loss: 1.108853  [   32/  126]
train() client id: f_00000-2-1 loss: 0.983701  [   64/  126]
train() client id: f_00000-2-2 loss: 0.998097  [   96/  126]
train() client id: f_00000-3-0 loss: 0.949282  [   32/  126]
train() client id: f_00000-3-1 loss: 0.959676  [   64/  126]
train() client id: f_00000-3-2 loss: 0.919939  [   96/  126]
train() client id: f_00000-4-0 loss: 0.943894  [   32/  126]
train() client id: f_00000-4-1 loss: 0.977257  [   64/  126]
train() client id: f_00000-4-2 loss: 0.880602  [   96/  126]
train() client id: f_00000-5-0 loss: 0.809249  [   32/  126]
train() client id: f_00000-5-1 loss: 0.935224  [   64/  126]
train() client id: f_00000-5-2 loss: 0.904810  [   96/  126]
train() client id: f_00000-6-0 loss: 0.966073  [   32/  126]
train() client id: f_00000-6-1 loss: 0.740241  [   64/  126]
train() client id: f_00000-6-2 loss: 0.918633  [   96/  126]
train() client id: f_00000-7-0 loss: 0.895249  [   32/  126]
train() client id: f_00000-7-1 loss: 0.975331  [   64/  126]
train() client id: f_00000-7-2 loss: 0.810451  [   96/  126]
train() client id: f_00000-8-0 loss: 0.829424  [   32/  126]
train() client id: f_00000-8-1 loss: 0.858336  [   64/  126]
train() client id: f_00000-8-2 loss: 0.739084  [   96/  126]
train() client id: f_00000-9-0 loss: 0.874017  [   32/  126]
train() client id: f_00000-9-1 loss: 0.766331  [   64/  126]
train() client id: f_00000-9-2 loss: 0.775731  [   96/  126]
train() client id: f_00000-10-0 loss: 0.891451  [   32/  126]
train() client id: f_00000-10-1 loss: 0.894479  [   64/  126]
train() client id: f_00000-10-2 loss: 0.801988  [   96/  126]
train() client id: f_00000-11-0 loss: 0.842821  [   32/  126]
train() client id: f_00000-11-1 loss: 0.912064  [   64/  126]
train() client id: f_00000-11-2 loss: 0.775961  [   96/  126]
train() client id: f_00000-12-0 loss: 0.781384  [   32/  126]
train() client id: f_00000-12-1 loss: 0.798349  [   64/  126]
train() client id: f_00000-12-2 loss: 0.836558  [   96/  126]
train() client id: f_00001-0-0 loss: 0.479361  [   32/  265]
train() client id: f_00001-0-1 loss: 0.504111  [   64/  265]
train() client id: f_00001-0-2 loss: 0.396962  [   96/  265]
train() client id: f_00001-0-3 loss: 0.487307  [  128/  265]
train() client id: f_00001-0-4 loss: 0.398498  [  160/  265]
train() client id: f_00001-0-5 loss: 0.436315  [  192/  265]
train() client id: f_00001-0-6 loss: 0.554342  [  224/  265]
train() client id: f_00001-0-7 loss: 0.437648  [  256/  265]
train() client id: f_00001-1-0 loss: 0.391376  [   32/  265]
train() client id: f_00001-1-1 loss: 0.564415  [   64/  265]
train() client id: f_00001-1-2 loss: 0.571576  [   96/  265]
train() client id: f_00001-1-3 loss: 0.421665  [  128/  265]
train() client id: f_00001-1-4 loss: 0.417337  [  160/  265]
train() client id: f_00001-1-5 loss: 0.374281  [  192/  265]
train() client id: f_00001-1-6 loss: 0.400573  [  224/  265]
train() client id: f_00001-1-7 loss: 0.504680  [  256/  265]
train() client id: f_00001-2-0 loss: 0.535930  [   32/  265]
train() client id: f_00001-2-1 loss: 0.473617  [   64/  265]
train() client id: f_00001-2-2 loss: 0.356004  [   96/  265]
train() client id: f_00001-2-3 loss: 0.375103  [  128/  265]
train() client id: f_00001-2-4 loss: 0.443829  [  160/  265]
train() client id: f_00001-2-5 loss: 0.394901  [  192/  265]
train() client id: f_00001-2-6 loss: 0.517247  [  224/  265]
train() client id: f_00001-2-7 loss: 0.506131  [  256/  265]
train() client id: f_00001-3-0 loss: 0.410446  [   32/  265]
train() client id: f_00001-3-1 loss: 0.446856  [   64/  265]
train() client id: f_00001-3-2 loss: 0.353883  [   96/  265]
train() client id: f_00001-3-3 loss: 0.665168  [  128/  265]
train() client id: f_00001-3-4 loss: 0.447629  [  160/  265]
train() client id: f_00001-3-5 loss: 0.555676  [  192/  265]
train() client id: f_00001-3-6 loss: 0.408968  [  224/  265]
train() client id: f_00001-3-7 loss: 0.356768  [  256/  265]
train() client id: f_00001-4-0 loss: 0.397490  [   32/  265]
train() client id: f_00001-4-1 loss: 0.418310  [   64/  265]
train() client id: f_00001-4-2 loss: 0.465713  [   96/  265]
train() client id: f_00001-4-3 loss: 0.647715  [  128/  265]
train() client id: f_00001-4-4 loss: 0.541045  [  160/  265]
train() client id: f_00001-4-5 loss: 0.436212  [  192/  265]
train() client id: f_00001-4-6 loss: 0.334802  [  224/  265]
train() client id: f_00001-4-7 loss: 0.380192  [  256/  265]
train() client id: f_00001-5-0 loss: 0.369041  [   32/  265]
train() client id: f_00001-5-1 loss: 0.563634  [   64/  265]
train() client id: f_00001-5-2 loss: 0.401192  [   96/  265]
train() client id: f_00001-5-3 loss: 0.650180  [  128/  265]
train() client id: f_00001-5-4 loss: 0.490514  [  160/  265]
train() client id: f_00001-5-5 loss: 0.397885  [  192/  265]
train() client id: f_00001-5-6 loss: 0.352795  [  224/  265]
train() client id: f_00001-5-7 loss: 0.367179  [  256/  265]
train() client id: f_00001-6-0 loss: 0.431835  [   32/  265]
train() client id: f_00001-6-1 loss: 0.362480  [   64/  265]
train() client id: f_00001-6-2 loss: 0.457322  [   96/  265]
train() client id: f_00001-6-3 loss: 0.390443  [  128/  265]
train() client id: f_00001-6-4 loss: 0.493170  [  160/  265]
train() client id: f_00001-6-5 loss: 0.557002  [  192/  265]
train() client id: f_00001-6-6 loss: 0.407773  [  224/  265]
train() client id: f_00001-6-7 loss: 0.479722  [  256/  265]
train() client id: f_00001-7-0 loss: 0.444563  [   32/  265]
train() client id: f_00001-7-1 loss: 0.440150  [   64/  265]
train() client id: f_00001-7-2 loss: 0.543689  [   96/  265]
train() client id: f_00001-7-3 loss: 0.457660  [  128/  265]
train() client id: f_00001-7-4 loss: 0.385537  [  160/  265]
train() client id: f_00001-7-5 loss: 0.435568  [  192/  265]
train() client id: f_00001-7-6 loss: 0.534453  [  224/  265]
train() client id: f_00001-7-7 loss: 0.343920  [  256/  265]
train() client id: f_00001-8-0 loss: 0.490301  [   32/  265]
train() client id: f_00001-8-1 loss: 0.371580  [   64/  265]
train() client id: f_00001-8-2 loss: 0.374800  [   96/  265]
train() client id: f_00001-8-3 loss: 0.398939  [  128/  265]
train() client id: f_00001-8-4 loss: 0.463619  [  160/  265]
train() client id: f_00001-8-5 loss: 0.366370  [  192/  265]
train() client id: f_00001-8-6 loss: 0.561007  [  224/  265]
train() client id: f_00001-8-7 loss: 0.565521  [  256/  265]
train() client id: f_00001-9-0 loss: 0.363642  [   32/  265]
train() client id: f_00001-9-1 loss: 0.453518  [   64/  265]
train() client id: f_00001-9-2 loss: 0.476146  [   96/  265]
train() client id: f_00001-9-3 loss: 0.387409  [  128/  265]
train() client id: f_00001-9-4 loss: 0.433653  [  160/  265]
train() client id: f_00001-9-5 loss: 0.365756  [  192/  265]
train() client id: f_00001-9-6 loss: 0.512905  [  224/  265]
train() client id: f_00001-9-7 loss: 0.583946  [  256/  265]
train() client id: f_00001-10-0 loss: 0.507736  [   32/  265]
train() client id: f_00001-10-1 loss: 0.484291  [   64/  265]
train() client id: f_00001-10-2 loss: 0.463676  [   96/  265]
train() client id: f_00001-10-3 loss: 0.474498  [  128/  265]
train() client id: f_00001-10-4 loss: 0.346686  [  160/  265]
train() client id: f_00001-10-5 loss: 0.472260  [  192/  265]
train() client id: f_00001-10-6 loss: 0.422143  [  224/  265]
train() client id: f_00001-10-7 loss: 0.421780  [  256/  265]
train() client id: f_00001-11-0 loss: 0.567206  [   32/  265]
train() client id: f_00001-11-1 loss: 0.380878  [   64/  265]
train() client id: f_00001-11-2 loss: 0.414011  [   96/  265]
train() client id: f_00001-11-3 loss: 0.447903  [  128/  265]
train() client id: f_00001-11-4 loss: 0.357662  [  160/  265]
train() client id: f_00001-11-5 loss: 0.519574  [  192/  265]
train() client id: f_00001-11-6 loss: 0.414800  [  224/  265]
train() client id: f_00001-11-7 loss: 0.390366  [  256/  265]
train() client id: f_00001-12-0 loss: 0.368719  [   32/  265]
train() client id: f_00001-12-1 loss: 0.528791  [   64/  265]
train() client id: f_00001-12-2 loss: 0.370559  [   96/  265]
train() client id: f_00001-12-3 loss: 0.395416  [  128/  265]
train() client id: f_00001-12-4 loss: 0.333426  [  160/  265]
train() client id: f_00001-12-5 loss: 0.607014  [  192/  265]
train() client id: f_00001-12-6 loss: 0.519269  [  224/  265]
train() client id: f_00001-12-7 loss: 0.378825  [  256/  265]
train() client id: f_00002-0-0 loss: 1.305301  [   32/  124]
train() client id: f_00002-0-1 loss: 1.205827  [   64/  124]
train() client id: f_00002-0-2 loss: 1.007347  [   96/  124]
train() client id: f_00002-1-0 loss: 1.164425  [   32/  124]
train() client id: f_00002-1-1 loss: 1.127456  [   64/  124]
train() client id: f_00002-1-2 loss: 1.133725  [   96/  124]
train() client id: f_00002-2-0 loss: 0.994789  [   32/  124]
train() client id: f_00002-2-1 loss: 1.086915  [   64/  124]
train() client id: f_00002-2-2 loss: 0.989140  [   96/  124]
train() client id: f_00002-3-0 loss: 0.931709  [   32/  124]
train() client id: f_00002-3-1 loss: 1.153348  [   64/  124]
train() client id: f_00002-3-2 loss: 1.122427  [   96/  124]
train() client id: f_00002-4-0 loss: 0.843761  [   32/  124]
train() client id: f_00002-4-1 loss: 1.002775  [   64/  124]
train() client id: f_00002-4-2 loss: 1.084333  [   96/  124]
train() client id: f_00002-5-0 loss: 1.074804  [   32/  124]
train() client id: f_00002-5-1 loss: 0.992976  [   64/  124]
train() client id: f_00002-5-2 loss: 0.947777  [   96/  124]
train() client id: f_00002-6-0 loss: 1.147234  [   32/  124]
train() client id: f_00002-6-1 loss: 0.998032  [   64/  124]
train() client id: f_00002-6-2 loss: 0.711944  [   96/  124]
train() client id: f_00002-7-0 loss: 0.993058  [   32/  124]
train() client id: f_00002-7-1 loss: 0.944294  [   64/  124]
train() client id: f_00002-7-2 loss: 0.889864  [   96/  124]
train() client id: f_00002-8-0 loss: 1.007648  [   32/  124]
train() client id: f_00002-8-1 loss: 0.724122  [   64/  124]
train() client id: f_00002-8-2 loss: 0.875878  [   96/  124]
train() client id: f_00002-9-0 loss: 0.677697  [   32/  124]
train() client id: f_00002-9-1 loss: 1.062363  [   64/  124]
train() client id: f_00002-9-2 loss: 0.855754  [   96/  124]
train() client id: f_00002-10-0 loss: 1.029832  [   32/  124]
train() client id: f_00002-10-1 loss: 0.817216  [   64/  124]
train() client id: f_00002-10-2 loss: 0.897688  [   96/  124]
train() client id: f_00002-11-0 loss: 0.946713  [   32/  124]
train() client id: f_00002-11-1 loss: 0.775038  [   64/  124]
train() client id: f_00002-11-2 loss: 0.837520  [   96/  124]
train() client id: f_00002-12-0 loss: 0.823538  [   32/  124]
train() client id: f_00002-12-1 loss: 0.805975  [   64/  124]
train() client id: f_00002-12-2 loss: 1.029029  [   96/  124]
train() client id: f_00003-0-0 loss: 0.735504  [   32/   43]
train() client id: f_00003-1-0 loss: 0.714460  [   32/   43]
train() client id: f_00003-2-0 loss: 0.849909  [   32/   43]
train() client id: f_00003-3-0 loss: 0.534530  [   32/   43]
train() client id: f_00003-4-0 loss: 0.660909  [   32/   43]
train() client id: f_00003-5-0 loss: 0.684155  [   32/   43]
train() client id: f_00003-6-0 loss: 0.490765  [   32/   43]
train() client id: f_00003-7-0 loss: 0.616655  [   32/   43]
train() client id: f_00003-8-0 loss: 0.780590  [   32/   43]
train() client id: f_00003-9-0 loss: 0.680334  [   32/   43]
train() client id: f_00003-10-0 loss: 0.651442  [   32/   43]
train() client id: f_00003-11-0 loss: 0.531775  [   32/   43]
train() client id: f_00003-12-0 loss: 0.683094  [   32/   43]
train() client id: f_00004-0-0 loss: 0.903117  [   32/  306]
train() client id: f_00004-0-1 loss: 0.970798  [   64/  306]
train() client id: f_00004-0-2 loss: 0.933531  [   96/  306]
train() client id: f_00004-0-3 loss: 0.896213  [  128/  306]
train() client id: f_00004-0-4 loss: 0.782255  [  160/  306]
train() client id: f_00004-0-5 loss: 0.785250  [  192/  306]
train() client id: f_00004-0-6 loss: 0.658839  [  224/  306]
train() client id: f_00004-0-7 loss: 0.836041  [  256/  306]
train() client id: f_00004-0-8 loss: 0.767755  [  288/  306]
train() client id: f_00004-1-0 loss: 0.832963  [   32/  306]
train() client id: f_00004-1-1 loss: 0.885043  [   64/  306]
train() client id: f_00004-1-2 loss: 0.871473  [   96/  306]
train() client id: f_00004-1-3 loss: 0.754519  [  128/  306]
train() client id: f_00004-1-4 loss: 0.859601  [  160/  306]
train() client id: f_00004-1-5 loss: 0.825385  [  192/  306]
train() client id: f_00004-1-6 loss: 0.835089  [  224/  306]
train() client id: f_00004-1-7 loss: 0.976613  [  256/  306]
train() client id: f_00004-1-8 loss: 0.654673  [  288/  306]
train() client id: f_00004-2-0 loss: 0.900053  [   32/  306]
train() client id: f_00004-2-1 loss: 0.863367  [   64/  306]
train() client id: f_00004-2-2 loss: 0.762829  [   96/  306]
train() client id: f_00004-2-3 loss: 0.690858  [  128/  306]
train() client id: f_00004-2-4 loss: 0.916901  [  160/  306]
train() client id: f_00004-2-5 loss: 0.731101  [  192/  306]
train() client id: f_00004-2-6 loss: 0.882037  [  224/  306]
train() client id: f_00004-2-7 loss: 0.756349  [  256/  306]
train() client id: f_00004-2-8 loss: 0.928205  [  288/  306]
train() client id: f_00004-3-0 loss: 0.824630  [   32/  306]
train() client id: f_00004-3-1 loss: 0.710409  [   64/  306]
train() client id: f_00004-3-2 loss: 0.703608  [   96/  306]
train() client id: f_00004-3-3 loss: 0.814187  [  128/  306]
train() client id: f_00004-3-4 loss: 0.923135  [  160/  306]
train() client id: f_00004-3-5 loss: 0.889525  [  192/  306]
train() client id: f_00004-3-6 loss: 0.851938  [  224/  306]
train() client id: f_00004-3-7 loss: 0.865837  [  256/  306]
train() client id: f_00004-3-8 loss: 0.754643  [  288/  306]
train() client id: f_00004-4-0 loss: 0.835562  [   32/  306]
train() client id: f_00004-4-1 loss: 0.788515  [   64/  306]
train() client id: f_00004-4-2 loss: 0.875097  [   96/  306]
train() client id: f_00004-4-3 loss: 0.765696  [  128/  306]
train() client id: f_00004-4-4 loss: 0.924634  [  160/  306]
train() client id: f_00004-4-5 loss: 0.898708  [  192/  306]
train() client id: f_00004-4-6 loss: 0.815036  [  224/  306]
train() client id: f_00004-4-7 loss: 0.799842  [  256/  306]
train() client id: f_00004-4-8 loss: 0.828730  [  288/  306]
train() client id: f_00004-5-0 loss: 0.810852  [   32/  306]
train() client id: f_00004-5-1 loss: 0.789388  [   64/  306]
train() client id: f_00004-5-2 loss: 0.992199  [   96/  306]
train() client id: f_00004-5-3 loss: 0.789597  [  128/  306]
train() client id: f_00004-5-4 loss: 0.853781  [  160/  306]
train() client id: f_00004-5-5 loss: 0.916365  [  192/  306]
train() client id: f_00004-5-6 loss: 0.736315  [  224/  306]
train() client id: f_00004-5-7 loss: 0.764660  [  256/  306]
train() client id: f_00004-5-8 loss: 0.788745  [  288/  306]
train() client id: f_00004-6-0 loss: 0.798671  [   32/  306]
train() client id: f_00004-6-1 loss: 0.934997  [   64/  306]
train() client id: f_00004-6-2 loss: 0.880967  [   96/  306]
train() client id: f_00004-6-3 loss: 0.861912  [  128/  306]
train() client id: f_00004-6-4 loss: 0.934485  [  160/  306]
train() client id: f_00004-6-5 loss: 0.883090  [  192/  306]
train() client id: f_00004-6-6 loss: 0.718747  [  224/  306]
train() client id: f_00004-6-7 loss: 0.801598  [  256/  306]
train() client id: f_00004-6-8 loss: 0.670575  [  288/  306]
train() client id: f_00004-7-0 loss: 0.918202  [   32/  306]
train() client id: f_00004-7-1 loss: 0.833361  [   64/  306]
train() client id: f_00004-7-2 loss: 0.737150  [   96/  306]
train() client id: f_00004-7-3 loss: 0.738105  [  128/  306]
train() client id: f_00004-7-4 loss: 0.791168  [  160/  306]
train() client id: f_00004-7-5 loss: 0.861082  [  192/  306]
train() client id: f_00004-7-6 loss: 0.891554  [  224/  306]
train() client id: f_00004-7-7 loss: 0.906806  [  256/  306]
train() client id: f_00004-7-8 loss: 0.844304  [  288/  306]
train() client id: f_00004-8-0 loss: 0.952828  [   32/  306]
train() client id: f_00004-8-1 loss: 0.836436  [   64/  306]
train() client id: f_00004-8-2 loss: 0.755539  [   96/  306]
train() client id: f_00004-8-3 loss: 0.909640  [  128/  306]
train() client id: f_00004-8-4 loss: 0.732773  [  160/  306]
train() client id: f_00004-8-5 loss: 0.841341  [  192/  306]
train() client id: f_00004-8-6 loss: 0.720025  [  224/  306]
train() client id: f_00004-8-7 loss: 0.894616  [  256/  306]
train() client id: f_00004-8-8 loss: 0.863858  [  288/  306]
train() client id: f_00004-9-0 loss: 0.761828  [   32/  306]
train() client id: f_00004-9-1 loss: 0.839535  [   64/  306]
train() client id: f_00004-9-2 loss: 0.869601  [   96/  306]
train() client id: f_00004-9-3 loss: 0.761052  [  128/  306]
train() client id: f_00004-9-4 loss: 0.872745  [  160/  306]
train() client id: f_00004-9-5 loss: 0.815396  [  192/  306]
train() client id: f_00004-9-6 loss: 0.786782  [  224/  306]
train() client id: f_00004-9-7 loss: 0.873058  [  256/  306]
train() client id: f_00004-9-8 loss: 0.845157  [  288/  306]
train() client id: f_00004-10-0 loss: 0.936393  [   32/  306]
train() client id: f_00004-10-1 loss: 0.818310  [   64/  306]
train() client id: f_00004-10-2 loss: 0.759113  [   96/  306]
train() client id: f_00004-10-3 loss: 0.813272  [  128/  306]
train() client id: f_00004-10-4 loss: 0.759964  [  160/  306]
train() client id: f_00004-10-5 loss: 0.815973  [  192/  306]
train() client id: f_00004-10-6 loss: 0.949213  [  224/  306]
train() client id: f_00004-10-7 loss: 0.774753  [  256/  306]
train() client id: f_00004-10-8 loss: 0.783588  [  288/  306]
train() client id: f_00004-11-0 loss: 0.829727  [   32/  306]
train() client id: f_00004-11-1 loss: 0.872160  [   64/  306]
train() client id: f_00004-11-2 loss: 0.847015  [   96/  306]
train() client id: f_00004-11-3 loss: 0.800131  [  128/  306]
train() client id: f_00004-11-4 loss: 0.840791  [  160/  306]
train() client id: f_00004-11-5 loss: 0.768722  [  192/  306]
train() client id: f_00004-11-6 loss: 0.841925  [  224/  306]
train() client id: f_00004-11-7 loss: 0.818768  [  256/  306]
train() client id: f_00004-11-8 loss: 0.782123  [  288/  306]
train() client id: f_00004-12-0 loss: 0.876507  [   32/  306]
train() client id: f_00004-12-1 loss: 0.799677  [   64/  306]
train() client id: f_00004-12-2 loss: 0.860026  [   96/  306]
train() client id: f_00004-12-3 loss: 0.808278  [  128/  306]
train() client id: f_00004-12-4 loss: 0.906117  [  160/  306]
train() client id: f_00004-12-5 loss: 0.741072  [  192/  306]
train() client id: f_00004-12-6 loss: 0.816661  [  224/  306]
train() client id: f_00004-12-7 loss: 0.796633  [  256/  306]
train() client id: f_00004-12-8 loss: 0.882375  [  288/  306]
train() client id: f_00005-0-0 loss: 0.908231  [   32/  146]
train() client id: f_00005-0-1 loss: 0.635960  [   64/  146]
train() client id: f_00005-0-2 loss: 0.378538  [   96/  146]
train() client id: f_00005-0-3 loss: 0.613808  [  128/  146]
train() client id: f_00005-1-0 loss: 0.632595  [   32/  146]
train() client id: f_00005-1-1 loss: 0.727800  [   64/  146]
train() client id: f_00005-1-2 loss: 0.548797  [   96/  146]
train() client id: f_00005-1-3 loss: 0.559913  [  128/  146]
train() client id: f_00005-2-0 loss: 0.418321  [   32/  146]
train() client id: f_00005-2-1 loss: 0.694182  [   64/  146]
train() client id: f_00005-2-2 loss: 0.519990  [   96/  146]
train() client id: f_00005-2-3 loss: 0.837617  [  128/  146]
train() client id: f_00005-3-0 loss: 0.640464  [   32/  146]
train() client id: f_00005-3-1 loss: 0.507418  [   64/  146]
train() client id: f_00005-3-2 loss: 0.658337  [   96/  146]
train() client id: f_00005-3-3 loss: 0.605547  [  128/  146]
train() client id: f_00005-4-0 loss: 0.582849  [   32/  146]
train() client id: f_00005-4-1 loss: 0.592635  [   64/  146]
train() client id: f_00005-4-2 loss: 0.670102  [   96/  146]
train() client id: f_00005-4-3 loss: 0.503009  [  128/  146]
train() client id: f_00005-5-0 loss: 0.745398  [   32/  146]
train() client id: f_00005-5-1 loss: 1.006323  [   64/  146]
train() client id: f_00005-5-2 loss: 0.340847  [   96/  146]
train() client id: f_00005-5-3 loss: 0.484905  [  128/  146]
train() client id: f_00005-6-0 loss: 0.554449  [   32/  146]
train() client id: f_00005-6-1 loss: 0.640184  [   64/  146]
train() client id: f_00005-6-2 loss: 0.745649  [   96/  146]
train() client id: f_00005-6-3 loss: 0.585474  [  128/  146]
train() client id: f_00005-7-0 loss: 0.711514  [   32/  146]
train() client id: f_00005-7-1 loss: 0.605712  [   64/  146]
train() client id: f_00005-7-2 loss: 0.388976  [   96/  146]
train() client id: f_00005-7-3 loss: 0.603295  [  128/  146]
train() client id: f_00005-8-0 loss: 0.427199  [   32/  146]
train() client id: f_00005-8-1 loss: 0.450177  [   64/  146]
train() client id: f_00005-8-2 loss: 1.026342  [   96/  146]
train() client id: f_00005-8-3 loss: 0.531853  [  128/  146]
train() client id: f_00005-9-0 loss: 0.710410  [   32/  146]
train() client id: f_00005-9-1 loss: 0.571388  [   64/  146]
train() client id: f_00005-9-2 loss: 0.864712  [   96/  146]
train() client id: f_00005-9-3 loss: 0.408159  [  128/  146]
train() client id: f_00005-10-0 loss: 0.753186  [   32/  146]
train() client id: f_00005-10-1 loss: 0.674108  [   64/  146]
train() client id: f_00005-10-2 loss: 0.492820  [   96/  146]
train() client id: f_00005-10-3 loss: 0.557746  [  128/  146]
train() client id: f_00005-11-0 loss: 0.617094  [   32/  146]
train() client id: f_00005-11-1 loss: 0.632790  [   64/  146]
train() client id: f_00005-11-2 loss: 0.444348  [   96/  146]
train() client id: f_00005-11-3 loss: 0.709838  [  128/  146]
train() client id: f_00005-12-0 loss: 0.328525  [   32/  146]
train() client id: f_00005-12-1 loss: 0.708155  [   64/  146]
train() client id: f_00005-12-2 loss: 0.594537  [   96/  146]
train() client id: f_00005-12-3 loss: 0.621360  [  128/  146]
train() client id: f_00006-0-0 loss: 0.443781  [   32/   54]
train() client id: f_00006-1-0 loss: 0.469109  [   32/   54]
train() client id: f_00006-2-0 loss: 0.488252  [   32/   54]
train() client id: f_00006-3-0 loss: 0.540940  [   32/   54]
train() client id: f_00006-4-0 loss: 0.526243  [   32/   54]
train() client id: f_00006-5-0 loss: 0.480679  [   32/   54]
train() client id: f_00006-6-0 loss: 0.490630  [   32/   54]
train() client id: f_00006-7-0 loss: 0.475160  [   32/   54]
train() client id: f_00006-8-0 loss: 0.520314  [   32/   54]
train() client id: f_00006-9-0 loss: 0.515405  [   32/   54]
train() client id: f_00006-10-0 loss: 0.479210  [   32/   54]
train() client id: f_00006-11-0 loss: 0.506076  [   32/   54]
train() client id: f_00006-12-0 loss: 0.448672  [   32/   54]
train() client id: f_00007-0-0 loss: 0.670662  [   32/  179]
train() client id: f_00007-0-1 loss: 0.539785  [   64/  179]
train() client id: f_00007-0-2 loss: 0.832063  [   96/  179]
train() client id: f_00007-0-3 loss: 0.822383  [  128/  179]
train() client id: f_00007-0-4 loss: 0.657168  [  160/  179]
train() client id: f_00007-1-0 loss: 0.840049  [   32/  179]
train() client id: f_00007-1-1 loss: 0.546821  [   64/  179]
train() client id: f_00007-1-2 loss: 0.664583  [   96/  179]
train() client id: f_00007-1-3 loss: 0.880535  [  128/  179]
train() client id: f_00007-1-4 loss: 0.631234  [  160/  179]
train() client id: f_00007-2-0 loss: 0.782027  [   32/  179]
train() client id: f_00007-2-1 loss: 0.523402  [   64/  179]
train() client id: f_00007-2-2 loss: 0.837206  [   96/  179]
train() client id: f_00007-2-3 loss: 0.701466  [  128/  179]
train() client id: f_00007-2-4 loss: 0.640614  [  160/  179]
train() client id: f_00007-3-0 loss: 0.512281  [   32/  179]
train() client id: f_00007-3-1 loss: 0.586090  [   64/  179]
train() client id: f_00007-3-2 loss: 0.683490  [   96/  179]
train() client id: f_00007-3-3 loss: 0.709588  [  128/  179]
train() client id: f_00007-3-4 loss: 0.991512  [  160/  179]
train() client id: f_00007-4-0 loss: 0.751726  [   32/  179]
train() client id: f_00007-4-1 loss: 0.560112  [   64/  179]
train() client id: f_00007-4-2 loss: 0.687768  [   96/  179]
train() client id: f_00007-4-3 loss: 0.620426  [  128/  179]
train() client id: f_00007-4-4 loss: 0.820987  [  160/  179]
train() client id: f_00007-5-0 loss: 0.884662  [   32/  179]
train() client id: f_00007-5-1 loss: 0.673546  [   64/  179]
train() client id: f_00007-5-2 loss: 0.527222  [   96/  179]
train() client id: f_00007-5-3 loss: 0.730188  [  128/  179]
train() client id: f_00007-5-4 loss: 0.517908  [  160/  179]
train() client id: f_00007-6-0 loss: 0.635906  [   32/  179]
train() client id: f_00007-6-1 loss: 0.614711  [   64/  179]
train() client id: f_00007-6-2 loss: 0.628408  [   96/  179]
train() client id: f_00007-6-3 loss: 0.817377  [  128/  179]
train() client id: f_00007-6-4 loss: 0.702501  [  160/  179]
train() client id: f_00007-7-0 loss: 0.532642  [   32/  179]
train() client id: f_00007-7-1 loss: 0.724587  [   64/  179]
train() client id: f_00007-7-2 loss: 0.949930  [   96/  179]
train() client id: f_00007-7-3 loss: 0.630414  [  128/  179]
train() client id: f_00007-7-4 loss: 0.576187  [  160/  179]
train() client id: f_00007-8-0 loss: 0.521073  [   32/  179]
train() client id: f_00007-8-1 loss: 0.498538  [   64/  179]
train() client id: f_00007-8-2 loss: 0.634489  [   96/  179]
train() client id: f_00007-8-3 loss: 0.746031  [  128/  179]
train() client id: f_00007-8-4 loss: 0.831511  [  160/  179]
train() client id: f_00007-9-0 loss: 0.630674  [   32/  179]
train() client id: f_00007-9-1 loss: 0.496138  [   64/  179]
train() client id: f_00007-9-2 loss: 1.013995  [   96/  179]
train() client id: f_00007-9-3 loss: 0.589529  [  128/  179]
train() client id: f_00007-9-4 loss: 0.611312  [  160/  179]
train() client id: f_00007-10-0 loss: 0.629299  [   32/  179]
train() client id: f_00007-10-1 loss: 0.888736  [   64/  179]
train() client id: f_00007-10-2 loss: 0.608176  [   96/  179]
train() client id: f_00007-10-3 loss: 0.506392  [  128/  179]
train() client id: f_00007-10-4 loss: 0.699787  [  160/  179]
train() client id: f_00007-11-0 loss: 0.769225  [   32/  179]
train() client id: f_00007-11-1 loss: 0.593747  [   64/  179]
train() client id: f_00007-11-2 loss: 0.699470  [   96/  179]
train() client id: f_00007-11-3 loss: 0.628209  [  128/  179]
train() client id: f_00007-11-4 loss: 0.711642  [  160/  179]
train() client id: f_00007-12-0 loss: 0.624415  [   32/  179]
train() client id: f_00007-12-1 loss: 0.595658  [   64/  179]
train() client id: f_00007-12-2 loss: 1.027492  [   96/  179]
train() client id: f_00007-12-3 loss: 0.585335  [  128/  179]
train() client id: f_00007-12-4 loss: 0.601997  [  160/  179]
train() client id: f_00008-0-0 loss: 0.708501  [   32/  130]
train() client id: f_00008-0-1 loss: 0.692135  [   64/  130]
train() client id: f_00008-0-2 loss: 0.699575  [   96/  130]
train() client id: f_00008-0-3 loss: 0.609283  [  128/  130]
train() client id: f_00008-1-0 loss: 0.559335  [   32/  130]
train() client id: f_00008-1-1 loss: 0.705660  [   64/  130]
train() client id: f_00008-1-2 loss: 0.792465  [   96/  130]
train() client id: f_00008-1-3 loss: 0.641549  [  128/  130]
train() client id: f_00008-2-0 loss: 0.706423  [   32/  130]
train() client id: f_00008-2-1 loss: 0.621795  [   64/  130]
train() client id: f_00008-2-2 loss: 0.697188  [   96/  130]
train() client id: f_00008-2-3 loss: 0.684848  [  128/  130]
train() client id: f_00008-3-0 loss: 0.577114  [   32/  130]
train() client id: f_00008-3-1 loss: 0.622961  [   64/  130]
train() client id: f_00008-3-2 loss: 0.682680  [   96/  130]
train() client id: f_00008-3-3 loss: 0.817980  [  128/  130]
train() client id: f_00008-4-0 loss: 0.747945  [   32/  130]
train() client id: f_00008-4-1 loss: 0.558646  [   64/  130]
train() client id: f_00008-4-2 loss: 0.687840  [   96/  130]
train() client id: f_00008-4-3 loss: 0.711927  [  128/  130]
train() client id: f_00008-5-0 loss: 0.666730  [   32/  130]
train() client id: f_00008-5-1 loss: 0.672042  [   64/  130]
train() client id: f_00008-5-2 loss: 0.619300  [   96/  130]
train() client id: f_00008-5-3 loss: 0.720839  [  128/  130]
train() client id: f_00008-6-0 loss: 0.770403  [   32/  130]
train() client id: f_00008-6-1 loss: 0.560783  [   64/  130]
train() client id: f_00008-6-2 loss: 0.688328  [   96/  130]
train() client id: f_00008-6-3 loss: 0.674385  [  128/  130]
train() client id: f_00008-7-0 loss: 0.714763  [   32/  130]
train() client id: f_00008-7-1 loss: 0.676340  [   64/  130]
train() client id: f_00008-7-2 loss: 0.654344  [   96/  130]
train() client id: f_00008-7-3 loss: 0.660120  [  128/  130]
train() client id: f_00008-8-0 loss: 0.803889  [   32/  130]
train() client id: f_00008-8-1 loss: 0.734245  [   64/  130]
train() client id: f_00008-8-2 loss: 0.484817  [   96/  130]
train() client id: f_00008-8-3 loss: 0.684603  [  128/  130]
train() client id: f_00008-9-0 loss: 0.583328  [   32/  130]
train() client id: f_00008-9-1 loss: 0.788212  [   64/  130]
train() client id: f_00008-9-2 loss: 0.606848  [   96/  130]
train() client id: f_00008-9-3 loss: 0.703799  [  128/  130]
train() client id: f_00008-10-0 loss: 0.654271  [   32/  130]
train() client id: f_00008-10-1 loss: 0.688069  [   64/  130]
train() client id: f_00008-10-2 loss: 0.709592  [   96/  130]
train() client id: f_00008-10-3 loss: 0.652178  [  128/  130]
train() client id: f_00008-11-0 loss: 0.771440  [   32/  130]
train() client id: f_00008-11-1 loss: 0.685195  [   64/  130]
train() client id: f_00008-11-2 loss: 0.620674  [   96/  130]
train() client id: f_00008-11-3 loss: 0.612526  [  128/  130]
train() client id: f_00008-12-0 loss: 0.647877  [   32/  130]
train() client id: f_00008-12-1 loss: 0.627847  [   64/  130]
train() client id: f_00008-12-2 loss: 0.721866  [   96/  130]
train() client id: f_00008-12-3 loss: 0.678314  [  128/  130]
train() client id: f_00009-0-0 loss: 1.152625  [   32/  118]
train() client id: f_00009-0-1 loss: 1.022413  [   64/  118]
train() client id: f_00009-0-2 loss: 1.067061  [   96/  118]
train() client id: f_00009-1-0 loss: 1.133349  [   32/  118]
train() client id: f_00009-1-1 loss: 1.041656  [   64/  118]
train() client id: f_00009-1-2 loss: 1.096490  [   96/  118]
train() client id: f_00009-2-0 loss: 1.152094  [   32/  118]
train() client id: f_00009-2-1 loss: 0.934899  [   64/  118]
train() client id: f_00009-2-2 loss: 0.919950  [   96/  118]
train() client id: f_00009-3-0 loss: 1.081469  [   32/  118]
train() client id: f_00009-3-1 loss: 0.950405  [   64/  118]
train() client id: f_00009-3-2 loss: 0.846277  [   96/  118]
train() client id: f_00009-4-0 loss: 0.849845  [   32/  118]
train() client id: f_00009-4-1 loss: 1.040021  [   64/  118]
train() client id: f_00009-4-2 loss: 0.886070  [   96/  118]
train() client id: f_00009-5-0 loss: 0.964909  [   32/  118]
train() client id: f_00009-5-1 loss: 0.954126  [   64/  118]
train() client id: f_00009-5-2 loss: 0.802595  [   96/  118]
train() client id: f_00009-6-0 loss: 0.777889  [   32/  118]
train() client id: f_00009-6-1 loss: 1.045919  [   64/  118]
train() client id: f_00009-6-2 loss: 0.786871  [   96/  118]
train() client id: f_00009-7-0 loss: 0.913820  [   32/  118]
train() client id: f_00009-7-1 loss: 0.836880  [   64/  118]
train() client id: f_00009-7-2 loss: 0.883476  [   96/  118]
train() client id: f_00009-8-0 loss: 0.993365  [   32/  118]
train() client id: f_00009-8-1 loss: 0.791724  [   64/  118]
train() client id: f_00009-8-2 loss: 0.839924  [   96/  118]
train() client id: f_00009-9-0 loss: 0.926289  [   32/  118]
train() client id: f_00009-9-1 loss: 0.816645  [   64/  118]
train() client id: f_00009-9-2 loss: 0.821847  [   96/  118]
train() client id: f_00009-10-0 loss: 0.849065  [   32/  118]
train() client id: f_00009-10-1 loss: 0.939156  [   64/  118]
train() client id: f_00009-10-2 loss: 0.728652  [   96/  118]
train() client id: f_00009-11-0 loss: 0.835105  [   32/  118]
train() client id: f_00009-11-1 loss: 0.805400  [   64/  118]
train() client id: f_00009-11-2 loss: 0.963019  [   96/  118]
train() client id: f_00009-12-0 loss: 0.719125  [   32/  118]
train() client id: f_00009-12-1 loss: 0.867827  [   64/  118]
train() client id: f_00009-12-2 loss: 0.834766  [   96/  118]
At round 70 accuracy: 0.636604774535809
At round 70 training accuracy: 0.5868544600938967
At round 70 training loss: 0.8417049378128346
gradient difference: 0.4246906340122223
train() client id: f_00000-0-0 loss: 0.932144  [   32/  126]
train() client id: f_00000-0-1 loss: 0.983288  [   64/  126]
train() client id: f_00000-0-2 loss: 1.136279  [   96/  126]
train() client id: f_00000-1-0 loss: 1.033282  [   32/  126]
train() client id: f_00000-1-1 loss: 0.799148  [   64/  126]
train() client id: f_00000-1-2 loss: 0.973611  [   96/  126]
train() client id: f_00000-2-0 loss: 0.861681  [   32/  126]
train() client id: f_00000-2-1 loss: 0.799413  [   64/  126]
train() client id: f_00000-2-2 loss: 0.800561  [   96/  126]
train() client id: f_00000-3-0 loss: 0.769522  [   32/  126]
train() client id: f_00000-3-1 loss: 0.844035  [   64/  126]
train() client id: f_00000-3-2 loss: 0.813238  [   96/  126]
train() client id: f_00000-4-0 loss: 0.830509  [   32/  126]
train() client id: f_00000-4-1 loss: 0.772402  [   64/  126]
train() client id: f_00000-4-2 loss: 0.923110  [   96/  126]
train() client id: f_00000-5-0 loss: 0.700255  [   32/  126]
train() client id: f_00000-5-1 loss: 0.842418  [   64/  126]
train() client id: f_00000-5-2 loss: 0.742579  [   96/  126]
train() client id: f_00000-6-0 loss: 0.717041  [   32/  126]
train() client id: f_00000-6-1 loss: 0.944334  [   64/  126]
train() client id: f_00000-6-2 loss: 0.722432  [   96/  126]
train() client id: f_00000-7-0 loss: 0.763978  [   32/  126]
train() client id: f_00000-7-1 loss: 0.897450  [   64/  126]
train() client id: f_00000-7-2 loss: 0.639016  [   96/  126]
train() client id: f_00000-8-0 loss: 0.704379  [   32/  126]
train() client id: f_00000-8-1 loss: 0.749968  [   64/  126]
train() client id: f_00000-8-2 loss: 0.841280  [   96/  126]
train() client id: f_00000-9-0 loss: 0.736846  [   32/  126]
train() client id: f_00000-9-1 loss: 0.834532  [   64/  126]
train() client id: f_00000-9-2 loss: 0.784758  [   96/  126]
train() client id: f_00000-10-0 loss: 0.703292  [   32/  126]
train() client id: f_00000-10-1 loss: 0.879652  [   64/  126]
train() client id: f_00000-10-2 loss: 0.738220  [   96/  126]
train() client id: f_00000-11-0 loss: 0.887501  [   32/  126]
train() client id: f_00000-11-1 loss: 0.744166  [   64/  126]
train() client id: f_00000-11-2 loss: 0.695233  [   96/  126]
train() client id: f_00000-12-0 loss: 0.878999  [   32/  126]
train() client id: f_00000-12-1 loss: 0.795395  [   64/  126]
train() client id: f_00000-12-2 loss: 0.659506  [   96/  126]
train() client id: f_00001-0-0 loss: 0.515142  [   32/  265]
train() client id: f_00001-0-1 loss: 0.403695  [   64/  265]
train() client id: f_00001-0-2 loss: 0.484853  [   96/  265]
train() client id: f_00001-0-3 loss: 0.389876  [  128/  265]
train() client id: f_00001-0-4 loss: 0.482124  [  160/  265]
train() client id: f_00001-0-5 loss: 0.413197  [  192/  265]
train() client id: f_00001-0-6 loss: 0.608701  [  224/  265]
train() client id: f_00001-0-7 loss: 0.459645  [  256/  265]
train() client id: f_00001-1-0 loss: 0.542275  [   32/  265]
train() client id: f_00001-1-1 loss: 0.406765  [   64/  265]
train() client id: f_00001-1-2 loss: 0.564507  [   96/  265]
train() client id: f_00001-1-3 loss: 0.395316  [  128/  265]
train() client id: f_00001-1-4 loss: 0.485566  [  160/  265]
train() client id: f_00001-1-5 loss: 0.353925  [  192/  265]
train() client id: f_00001-1-6 loss: 0.479732  [  224/  265]
train() client id: f_00001-1-7 loss: 0.482137  [  256/  265]
train() client id: f_00001-2-0 loss: 0.412891  [   32/  265]
train() client id: f_00001-2-1 loss: 0.385491  [   64/  265]
train() client id: f_00001-2-2 loss: 0.457916  [   96/  265]
train() client id: f_00001-2-3 loss: 0.441910  [  128/  265]
train() client id: f_00001-2-4 loss: 0.581247  [  160/  265]
train() client id: f_00001-2-5 loss: 0.542601  [  192/  265]
train() client id: f_00001-2-6 loss: 0.419028  [  224/  265]
train() client id: f_00001-2-7 loss: 0.416318  [  256/  265]
train() client id: f_00001-3-0 loss: 0.467905  [   32/  265]
train() client id: f_00001-3-1 loss: 0.454824  [   64/  265]
train() client id: f_00001-3-2 loss: 0.511314  [   96/  265]
train() client id: f_00001-3-3 loss: 0.592379  [  128/  265]
train() client id: f_00001-3-4 loss: 0.378693  [  160/  265]
train() client id: f_00001-3-5 loss: 0.359084  [  192/  265]
train() client id: f_00001-3-6 loss: 0.496908  [  224/  265]
train() client id: f_00001-3-7 loss: 0.344853  [  256/  265]
train() client id: f_00001-4-0 loss: 0.328646  [   32/  265]
train() client id: f_00001-4-1 loss: 0.461747  [   64/  265]
train() client id: f_00001-4-2 loss: 0.527117  [   96/  265]
train() client id: f_00001-4-3 loss: 0.413990  [  128/  265]
train() client id: f_00001-4-4 loss: 0.465494  [  160/  265]
train() client id: f_00001-4-5 loss: 0.482154  [  192/  265]
train() client id: f_00001-4-6 loss: 0.501410  [  224/  265]
train() client id: f_00001-4-7 loss: 0.420353  [  256/  265]
train() client id: f_00001-5-0 loss: 0.424118  [   32/  265]
train() client id: f_00001-5-1 loss: 0.590243  [   64/  265]
train() client id: f_00001-5-2 loss: 0.380086  [   96/  265]
train() client id: f_00001-5-3 loss: 0.523119  [  128/  265]
train() client id: f_00001-5-4 loss: 0.394718  [  160/  265]
train() client id: f_00001-5-5 loss: 0.417604  [  192/  265]
train() client id: f_00001-5-6 loss: 0.418840  [  224/  265]
train() client id: f_00001-5-7 loss: 0.413054  [  256/  265]
train() client id: f_00001-6-0 loss: 0.447861  [   32/  265]
train() client id: f_00001-6-1 loss: 0.430673  [   64/  265]
train() client id: f_00001-6-2 loss: 0.410631  [   96/  265]
train() client id: f_00001-6-3 loss: 0.370253  [  128/  265]
train() client id: f_00001-6-4 loss: 0.480290  [  160/  265]
train() client id: f_00001-6-5 loss: 0.482762  [  192/  265]
train() client id: f_00001-6-6 loss: 0.563550  [  224/  265]
train() client id: f_00001-6-7 loss: 0.374938  [  256/  265]
train() client id: f_00001-7-0 loss: 0.490259  [   32/  265]
train() client id: f_00001-7-1 loss: 0.369275  [   64/  265]
train() client id: f_00001-7-2 loss: 0.352947  [   96/  265]
train() client id: f_00001-7-3 loss: 0.519764  [  128/  265]
train() client id: f_00001-7-4 loss: 0.368367  [  160/  265]
train() client id: f_00001-7-5 loss: 0.607305  [  192/  265]
train() client id: f_00001-7-6 loss: 0.394745  [  224/  265]
train() client id: f_00001-7-7 loss: 0.436405  [  256/  265]
train() client id: f_00001-8-0 loss: 0.509269  [   32/  265]
train() client id: f_00001-8-1 loss: 0.496999  [   64/  265]
train() client id: f_00001-8-2 loss: 0.394409  [   96/  265]
train() client id: f_00001-8-3 loss: 0.509047  [  128/  265]
train() client id: f_00001-8-4 loss: 0.418492  [  160/  265]
train() client id: f_00001-8-5 loss: 0.461886  [  192/  265]
train() client id: f_00001-8-6 loss: 0.389967  [  224/  265]
train() client id: f_00001-8-7 loss: 0.358580  [  256/  265]
train() client id: f_00001-9-0 loss: 0.355346  [   32/  265]
train() client id: f_00001-9-1 loss: 0.474472  [   64/  265]
train() client id: f_00001-9-2 loss: 0.340914  [   96/  265]
train() client id: f_00001-9-3 loss: 0.515319  [  128/  265]
train() client id: f_00001-9-4 loss: 0.432651  [  160/  265]
train() client id: f_00001-9-5 loss: 0.388420  [  192/  265]
train() client id: f_00001-9-6 loss: 0.511586  [  224/  265]
train() client id: f_00001-9-7 loss: 0.508815  [  256/  265]
train() client id: f_00001-10-0 loss: 0.370036  [   32/  265]
train() client id: f_00001-10-1 loss: 0.412022  [   64/  265]
train() client id: f_00001-10-2 loss: 0.405680  [   96/  265]
train() client id: f_00001-10-3 loss: 0.522704  [  128/  265]
train() client id: f_00001-10-4 loss: 0.367889  [  160/  265]
train() client id: f_00001-10-5 loss: 0.444165  [  192/  265]
train() client id: f_00001-10-6 loss: 0.471289  [  224/  265]
train() client id: f_00001-10-7 loss: 0.471798  [  256/  265]
train() client id: f_00001-11-0 loss: 0.436451  [   32/  265]
train() client id: f_00001-11-1 loss: 0.424218  [   64/  265]
train() client id: f_00001-11-2 loss: 0.440104  [   96/  265]
train() client id: f_00001-11-3 loss: 0.451563  [  128/  265]
train() client id: f_00001-11-4 loss: 0.345240  [  160/  265]
train() client id: f_00001-11-5 loss: 0.432201  [  192/  265]
train() client id: f_00001-11-6 loss: 0.380911  [  224/  265]
train() client id: f_00001-11-7 loss: 0.568031  [  256/  265]
train() client id: f_00001-12-0 loss: 0.354798  [   32/  265]
train() client id: f_00001-12-1 loss: 0.489426  [   64/  265]
train() client id: f_00001-12-2 loss: 0.385803  [   96/  265]
train() client id: f_00001-12-3 loss: 0.520724  [  128/  265]
train() client id: f_00001-12-4 loss: 0.462113  [  160/  265]
train() client id: f_00001-12-5 loss: 0.414126  [  192/  265]
train() client id: f_00001-12-6 loss: 0.576894  [  224/  265]
train() client id: f_00001-12-7 loss: 0.332677  [  256/  265]
train() client id: f_00002-0-0 loss: 0.922277  [   32/  124]
train() client id: f_00002-0-1 loss: 1.134958  [   64/  124]
train() client id: f_00002-0-2 loss: 1.060317  [   96/  124]
train() client id: f_00002-1-0 loss: 1.122115  [   32/  124]
train() client id: f_00002-1-1 loss: 0.873412  [   64/  124]
train() client id: f_00002-1-2 loss: 1.029552  [   96/  124]
train() client id: f_00002-2-0 loss: 1.139519  [   32/  124]
train() client id: f_00002-2-1 loss: 0.842436  [   64/  124]
train() client id: f_00002-2-2 loss: 0.968514  [   96/  124]
train() client id: f_00002-3-0 loss: 1.083531  [   32/  124]
train() client id: f_00002-3-1 loss: 0.937326  [   64/  124]
train() client id: f_00002-3-2 loss: 0.829883  [   96/  124]
train() client id: f_00002-4-0 loss: 1.117290  [   32/  124]
train() client id: f_00002-4-1 loss: 0.816359  [   64/  124]
train() client id: f_00002-4-2 loss: 0.845951  [   96/  124]
train() client id: f_00002-5-0 loss: 1.047648  [   32/  124]
train() client id: f_00002-5-1 loss: 0.694317  [   64/  124]
train() client id: f_00002-5-2 loss: 0.808713  [   96/  124]
train() client id: f_00002-6-0 loss: 0.827651  [   32/  124]
train() client id: f_00002-6-1 loss: 1.064290  [   64/  124]
train() client id: f_00002-6-2 loss: 0.803027  [   96/  124]
train() client id: f_00002-7-0 loss: 0.837882  [   32/  124]
train() client id: f_00002-7-1 loss: 0.874144  [   64/  124]
train() client id: f_00002-7-2 loss: 0.953850  [   96/  124]
train() client id: f_00002-8-0 loss: 0.848724  [   32/  124]
train() client id: f_00002-8-1 loss: 0.814644  [   64/  124]
train() client id: f_00002-8-2 loss: 0.856594  [   96/  124]
train() client id: f_00002-9-0 loss: 0.998160  [   32/  124]
train() client id: f_00002-9-1 loss: 0.965171  [   64/  124]
train() client id: f_00002-9-2 loss: 0.667205  [   96/  124]
train() client id: f_00002-10-0 loss: 1.140209  [   32/  124]
train() client id: f_00002-10-1 loss: 0.527444  [   64/  124]
train() client id: f_00002-10-2 loss: 0.730127  [   96/  124]
train() client id: f_00002-11-0 loss: 0.777994  [   32/  124]
train() client id: f_00002-11-1 loss: 0.854254  [   64/  124]
train() client id: f_00002-11-2 loss: 0.850332  [   96/  124]
train() client id: f_00002-12-0 loss: 0.766291  [   32/  124]
train() client id: f_00002-12-1 loss: 0.973288  [   64/  124]
train() client id: f_00002-12-2 loss: 0.659035  [   96/  124]
train() client id: f_00003-0-0 loss: 0.668573  [   32/   43]
train() client id: f_00003-1-0 loss: 0.594361  [   32/   43]
train() client id: f_00003-2-0 loss: 0.638895  [   32/   43]
train() client id: f_00003-3-0 loss: 0.758062  [   32/   43]
train() client id: f_00003-4-0 loss: 0.560676  [   32/   43]
train() client id: f_00003-5-0 loss: 0.503179  [   32/   43]
train() client id: f_00003-6-0 loss: 0.732922  [   32/   43]
train() client id: f_00003-7-0 loss: 0.672946  [   32/   43]
train() client id: f_00003-8-0 loss: 0.594542  [   32/   43]
train() client id: f_00003-9-0 loss: 0.767091  [   32/   43]
train() client id: f_00003-10-0 loss: 0.752259  [   32/   43]
train() client id: f_00003-11-0 loss: 0.562033  [   32/   43]
train() client id: f_00003-12-0 loss: 0.682039  [   32/   43]
train() client id: f_00004-0-0 loss: 0.890361  [   32/  306]
train() client id: f_00004-0-1 loss: 0.717443  [   64/  306]
train() client id: f_00004-0-2 loss: 0.820434  [   96/  306]
train() client id: f_00004-0-3 loss: 0.916337  [  128/  306]
train() client id: f_00004-0-4 loss: 0.814255  [  160/  306]
train() client id: f_00004-0-5 loss: 0.948095  [  192/  306]
train() client id: f_00004-0-6 loss: 0.711125  [  224/  306]
train() client id: f_00004-0-7 loss: 0.758759  [  256/  306]
train() client id: f_00004-0-8 loss: 0.743432  [  288/  306]
train() client id: f_00004-1-0 loss: 0.699064  [   32/  306]
train() client id: f_00004-1-1 loss: 0.784042  [   64/  306]
train() client id: f_00004-1-2 loss: 0.897015  [   96/  306]
train() client id: f_00004-1-3 loss: 0.888434  [  128/  306]
train() client id: f_00004-1-4 loss: 0.924101  [  160/  306]
train() client id: f_00004-1-5 loss: 0.695517  [  192/  306]
train() client id: f_00004-1-6 loss: 0.609376  [  224/  306]
train() client id: f_00004-1-7 loss: 0.847613  [  256/  306]
train() client id: f_00004-1-8 loss: 0.777874  [  288/  306]
train() client id: f_00004-2-0 loss: 0.898393  [   32/  306]
train() client id: f_00004-2-1 loss: 0.627782  [   64/  306]
train() client id: f_00004-2-2 loss: 0.802235  [   96/  306]
train() client id: f_00004-2-3 loss: 0.685599  [  128/  306]
train() client id: f_00004-2-4 loss: 0.888742  [  160/  306]
train() client id: f_00004-2-5 loss: 0.795691  [  192/  306]
train() client id: f_00004-2-6 loss: 0.830460  [  224/  306]
train() client id: f_00004-2-7 loss: 0.823913  [  256/  306]
train() client id: f_00004-2-8 loss: 0.810364  [  288/  306]
train() client id: f_00004-3-0 loss: 0.772901  [   32/  306]
train() client id: f_00004-3-1 loss: 0.812357  [   64/  306]
train() client id: f_00004-3-2 loss: 0.799685  [   96/  306]
train() client id: f_00004-3-3 loss: 0.809187  [  128/  306]
train() client id: f_00004-3-4 loss: 0.825161  [  160/  306]
train() client id: f_00004-3-5 loss: 0.764337  [  192/  306]
train() client id: f_00004-3-6 loss: 0.886858  [  224/  306]
train() client id: f_00004-3-7 loss: 0.775970  [  256/  306]
train() client id: f_00004-3-8 loss: 0.654235  [  288/  306]
train() client id: f_00004-4-0 loss: 0.776948  [   32/  306]
train() client id: f_00004-4-1 loss: 0.935990  [   64/  306]
train() client id: f_00004-4-2 loss: 0.640799  [   96/  306]
train() client id: f_00004-4-3 loss: 0.678483  [  128/  306]
train() client id: f_00004-4-4 loss: 0.886653  [  160/  306]
train() client id: f_00004-4-5 loss: 0.839663  [  192/  306]
train() client id: f_00004-4-6 loss: 0.875063  [  224/  306]
train() client id: f_00004-4-7 loss: 0.735466  [  256/  306]
train() client id: f_00004-4-8 loss: 0.850434  [  288/  306]
train() client id: f_00004-5-0 loss: 0.880424  [   32/  306]
train() client id: f_00004-5-1 loss: 0.711165  [   64/  306]
train() client id: f_00004-5-2 loss: 0.843281  [   96/  306]
train() client id: f_00004-5-3 loss: 0.736572  [  128/  306]
train() client id: f_00004-5-4 loss: 0.872952  [  160/  306]
train() client id: f_00004-5-5 loss: 0.783746  [  192/  306]
train() client id: f_00004-5-6 loss: 0.781045  [  224/  306]
train() client id: f_00004-5-7 loss: 0.875004  [  256/  306]
train() client id: f_00004-5-8 loss: 0.710753  [  288/  306]
train() client id: f_00004-6-0 loss: 0.881295  [   32/  306]
train() client id: f_00004-6-1 loss: 0.732662  [   64/  306]
train() client id: f_00004-6-2 loss: 0.790787  [   96/  306]
train() client id: f_00004-6-3 loss: 0.725243  [  128/  306]
train() client id: f_00004-6-4 loss: 0.717813  [  160/  306]
train() client id: f_00004-6-5 loss: 0.727882  [  192/  306]
train() client id: f_00004-6-6 loss: 0.925126  [  224/  306]
train() client id: f_00004-6-7 loss: 0.890332  [  256/  306]
train() client id: f_00004-6-8 loss: 0.804431  [  288/  306]
train() client id: f_00004-7-0 loss: 0.836264  [   32/  306]
train() client id: f_00004-7-1 loss: 0.719313  [   64/  306]
train() client id: f_00004-7-2 loss: 0.613705  [   96/  306]
train() client id: f_00004-7-3 loss: 0.842158  [  128/  306]
train() client id: f_00004-7-4 loss: 0.746212  [  160/  306]
train() client id: f_00004-7-5 loss: 0.817011  [  192/  306]
train() client id: f_00004-7-6 loss: 0.792904  [  224/  306]
train() client id: f_00004-7-7 loss: 0.724143  [  256/  306]
train() client id: f_00004-7-8 loss: 0.977501  [  288/  306]
train() client id: f_00004-8-0 loss: 0.821007  [   32/  306]
train() client id: f_00004-8-1 loss: 0.816522  [   64/  306]
train() client id: f_00004-8-2 loss: 0.756263  [   96/  306]
train() client id: f_00004-8-3 loss: 0.714607  [  128/  306]
train() client id: f_00004-8-4 loss: 0.719293  [  160/  306]
train() client id: f_00004-8-5 loss: 0.749799  [  192/  306]
train() client id: f_00004-8-6 loss: 0.792529  [  224/  306]
train() client id: f_00004-8-7 loss: 0.810588  [  256/  306]
train() client id: f_00004-8-8 loss: 0.923056  [  288/  306]
train() client id: f_00004-9-0 loss: 0.824816  [   32/  306]
train() client id: f_00004-9-1 loss: 0.696299  [   64/  306]
train() client id: f_00004-9-2 loss: 0.949566  [   96/  306]
train() client id: f_00004-9-3 loss: 0.776673  [  128/  306]
train() client id: f_00004-9-4 loss: 0.738576  [  160/  306]
train() client id: f_00004-9-5 loss: 0.690717  [  192/  306]
train() client id: f_00004-9-6 loss: 0.746708  [  224/  306]
train() client id: f_00004-9-7 loss: 0.866380  [  256/  306]
train() client id: f_00004-9-8 loss: 0.837740  [  288/  306]
train() client id: f_00004-10-0 loss: 0.704998  [   32/  306]
train() client id: f_00004-10-1 loss: 0.850550  [   64/  306]
train() client id: f_00004-10-2 loss: 0.811744  [   96/  306]
train() client id: f_00004-10-3 loss: 0.732692  [  128/  306]
train() client id: f_00004-10-4 loss: 0.828738  [  160/  306]
train() client id: f_00004-10-5 loss: 0.844562  [  192/  306]
train() client id: f_00004-10-6 loss: 0.762483  [  224/  306]
train() client id: f_00004-10-7 loss: 0.754625  [  256/  306]
train() client id: f_00004-10-8 loss: 0.789070  [  288/  306]
train() client id: f_00004-11-0 loss: 0.823576  [   32/  306]
train() client id: f_00004-11-1 loss: 0.688364  [   64/  306]
train() client id: f_00004-11-2 loss: 0.844591  [   96/  306]
train() client id: f_00004-11-3 loss: 0.901592  [  128/  306]
train() client id: f_00004-11-4 loss: 0.693887  [  160/  306]
train() client id: f_00004-11-5 loss: 0.843494  [  192/  306]
train() client id: f_00004-11-6 loss: 0.688411  [  224/  306]
train() client id: f_00004-11-7 loss: 0.784535  [  256/  306]
train() client id: f_00004-11-8 loss: 0.811990  [  288/  306]
train() client id: f_00004-12-0 loss: 0.821726  [   32/  306]
train() client id: f_00004-12-1 loss: 0.708809  [   64/  306]
train() client id: f_00004-12-2 loss: 0.820196  [   96/  306]
train() client id: f_00004-12-3 loss: 0.853464  [  128/  306]
train() client id: f_00004-12-4 loss: 0.691342  [  160/  306]
train() client id: f_00004-12-5 loss: 0.794282  [  192/  306]
train() client id: f_00004-12-6 loss: 0.818895  [  224/  306]
train() client id: f_00004-12-7 loss: 0.782188  [  256/  306]
train() client id: f_00004-12-8 loss: 0.774540  [  288/  306]
train() client id: f_00005-0-0 loss: 0.512821  [   32/  146]
train() client id: f_00005-0-1 loss: 0.704282  [   64/  146]
train() client id: f_00005-0-2 loss: 0.481884  [   96/  146]
train() client id: f_00005-0-3 loss: 0.646376  [  128/  146]
train() client id: f_00005-1-0 loss: 0.471570  [   32/  146]
train() client id: f_00005-1-1 loss: 0.546330  [   64/  146]
train() client id: f_00005-1-2 loss: 0.531470  [   96/  146]
train() client id: f_00005-1-3 loss: 1.093333  [  128/  146]
train() client id: f_00005-2-0 loss: 0.759257  [   32/  146]
train() client id: f_00005-2-1 loss: 0.382248  [   64/  146]
train() client id: f_00005-2-2 loss: 0.738176  [   96/  146]
train() client id: f_00005-2-3 loss: 0.519341  [  128/  146]
train() client id: f_00005-3-0 loss: 0.519863  [   32/  146]
train() client id: f_00005-3-1 loss: 0.744049  [   64/  146]
train() client id: f_00005-3-2 loss: 0.802180  [   96/  146]
train() client id: f_00005-3-3 loss: 0.570471  [  128/  146]
train() client id: f_00005-4-0 loss: 0.621299  [   32/  146]
train() client id: f_00005-4-1 loss: 0.452720  [   64/  146]
train() client id: f_00005-4-2 loss: 0.503596  [   96/  146]
train() client id: f_00005-4-3 loss: 0.588064  [  128/  146]
train() client id: f_00005-5-0 loss: 0.804875  [   32/  146]
train() client id: f_00005-5-1 loss: 0.446467  [   64/  146]
train() client id: f_00005-5-2 loss: 0.707851  [   96/  146]
train() client id: f_00005-5-3 loss: 0.500033  [  128/  146]
train() client id: f_00005-6-0 loss: 0.505142  [   32/  146]
train() client id: f_00005-6-1 loss: 0.740908  [   64/  146]
train() client id: f_00005-6-2 loss: 0.529724  [   96/  146]
train() client id: f_00005-6-3 loss: 0.661795  [  128/  146]
train() client id: f_00005-7-0 loss: 0.493854  [   32/  146]
train() client id: f_00005-7-1 loss: 0.705949  [   64/  146]
train() client id: f_00005-7-2 loss: 0.345391  [   96/  146]
train() client id: f_00005-7-3 loss: 0.871773  [  128/  146]
train() client id: f_00005-8-0 loss: 0.506233  [   32/  146]
train() client id: f_00005-8-1 loss: 0.716832  [   64/  146]
train() client id: f_00005-8-2 loss: 0.794092  [   96/  146]
train() client id: f_00005-8-3 loss: 0.665879  [  128/  146]
train() client id: f_00005-9-0 loss: 0.653357  [   32/  146]
train() client id: f_00005-9-1 loss: 0.387686  [   64/  146]
train() client id: f_00005-9-2 loss: 0.933785  [   96/  146]
train() client id: f_00005-9-3 loss: 0.569512  [  128/  146]
train() client id: f_00005-10-0 loss: 0.705461  [   32/  146]
train() client id: f_00005-10-1 loss: 0.549874  [   64/  146]
train() client id: f_00005-10-2 loss: 0.592688  [   96/  146]
train() client id: f_00005-10-3 loss: 0.570203  [  128/  146]
train() client id: f_00005-11-0 loss: 0.743607  [   32/  146]
train() client id: f_00005-11-1 loss: 0.484606  [   64/  146]
train() client id: f_00005-11-2 loss: 0.658624  [   96/  146]
train() client id: f_00005-11-3 loss: 0.586031  [  128/  146]
train() client id: f_00005-12-0 loss: 0.768404  [   32/  146]
train() client id: f_00005-12-1 loss: 0.407310  [   64/  146]
train() client id: f_00005-12-2 loss: 0.783880  [   96/  146]
train() client id: f_00005-12-3 loss: 0.567756  [  128/  146]
train() client id: f_00006-0-0 loss: 0.511036  [   32/   54]
train() client id: f_00006-1-0 loss: 0.485891  [   32/   54]
train() client id: f_00006-2-0 loss: 0.457261  [   32/   54]
train() client id: f_00006-3-0 loss: 0.550536  [   32/   54]
train() client id: f_00006-4-0 loss: 0.507794  [   32/   54]
train() client id: f_00006-5-0 loss: 0.514827  [   32/   54]
train() client id: f_00006-6-0 loss: 0.496622  [   32/   54]
train() client id: f_00006-7-0 loss: 0.497716  [   32/   54]
train() client id: f_00006-8-0 loss: 0.536551  [   32/   54]
train() client id: f_00006-9-0 loss: 0.483444  [   32/   54]
train() client id: f_00006-10-0 loss: 0.550169  [   32/   54]
train() client id: f_00006-11-0 loss: 0.497916  [   32/   54]
train() client id: f_00006-12-0 loss: 0.496837  [   32/   54]
train() client id: f_00007-0-0 loss: 0.575805  [   32/  179]
train() client id: f_00007-0-1 loss: 0.644201  [   64/  179]
train() client id: f_00007-0-2 loss: 0.741565  [   96/  179]
train() client id: f_00007-0-3 loss: 0.606238  [  128/  179]
train() client id: f_00007-0-4 loss: 0.633053  [  160/  179]
train() client id: f_00007-1-0 loss: 0.558665  [   32/  179]
train() client id: f_00007-1-1 loss: 0.521194  [   64/  179]
train() client id: f_00007-1-2 loss: 0.813269  [   96/  179]
train() client id: f_00007-1-3 loss: 0.569680  [  128/  179]
train() client id: f_00007-1-4 loss: 0.539052  [  160/  179]
train() client id: f_00007-2-0 loss: 0.553273  [   32/  179]
train() client id: f_00007-2-1 loss: 0.477259  [   64/  179]
train() client id: f_00007-2-2 loss: 0.746086  [   96/  179]
train() client id: f_00007-2-3 loss: 0.687557  [  128/  179]
train() client id: f_00007-2-4 loss: 0.478145  [  160/  179]
train() client id: f_00007-3-0 loss: 0.443274  [   32/  179]
train() client id: f_00007-3-1 loss: 0.543578  [   64/  179]
train() client id: f_00007-3-2 loss: 0.382690  [   96/  179]
train() client id: f_00007-3-3 loss: 0.734190  [  128/  179]
train() client id: f_00007-3-4 loss: 0.739096  [  160/  179]
train() client id: f_00007-4-0 loss: 0.509577  [   32/  179]
train() client id: f_00007-4-1 loss: 0.556576  [   64/  179]
train() client id: f_00007-4-2 loss: 0.692989  [   96/  179]
train() client id: f_00007-4-3 loss: 0.381919  [  128/  179]
train() client id: f_00007-4-4 loss: 0.787806  [  160/  179]
train() client id: f_00007-5-0 loss: 0.510046  [   32/  179]
train() client id: f_00007-5-1 loss: 0.552620  [   64/  179]
train() client id: f_00007-5-2 loss: 0.609018  [   96/  179]
train() client id: f_00007-5-3 loss: 0.721295  [  128/  179]
train() client id: f_00007-5-4 loss: 0.498815  [  160/  179]
train() client id: f_00007-6-0 loss: 0.463617  [   32/  179]
train() client id: f_00007-6-1 loss: 0.403834  [   64/  179]
train() client id: f_00007-6-2 loss: 0.460040  [   96/  179]
train() client id: f_00007-6-3 loss: 0.610094  [  128/  179]
train() client id: f_00007-6-4 loss: 0.738684  [  160/  179]
train() client id: f_00007-7-0 loss: 0.425233  [   32/  179]
train() client id: f_00007-7-1 loss: 0.608194  [   64/  179]
train() client id: f_00007-7-2 loss: 0.513281  [   96/  179]
train() client id: f_00007-7-3 loss: 0.733424  [  128/  179]
train() client id: f_00007-7-4 loss: 0.521855  [  160/  179]
train() client id: f_00007-8-0 loss: 0.520393  [   32/  179]
train() client id: f_00007-8-1 loss: 0.479660  [   64/  179]
train() client id: f_00007-8-2 loss: 0.458731  [   96/  179]
train() client id: f_00007-8-3 loss: 0.862082  [  128/  179]
train() client id: f_00007-8-4 loss: 0.407794  [  160/  179]
train() client id: f_00007-9-0 loss: 0.508498  [   32/  179]
train() client id: f_00007-9-1 loss: 0.809110  [   64/  179]
train() client id: f_00007-9-2 loss: 0.494052  [   96/  179]
train() client id: f_00007-9-3 loss: 0.405013  [  128/  179]
train() client id: f_00007-9-4 loss: 0.448840  [  160/  179]
train() client id: f_00007-10-0 loss: 0.704776  [   32/  179]
train() client id: f_00007-10-1 loss: 0.404848  [   64/  179]
train() client id: f_00007-10-2 loss: 0.466696  [   96/  179]
train() client id: f_00007-10-3 loss: 0.516014  [  128/  179]
train() client id: f_00007-10-4 loss: 0.610190  [  160/  179]
train() client id: f_00007-11-0 loss: 0.426007  [   32/  179]
train() client id: f_00007-11-1 loss: 0.602637  [   64/  179]
train() client id: f_00007-11-2 loss: 0.710950  [   96/  179]
train() client id: f_00007-11-3 loss: 0.493149  [  128/  179]
train() client id: f_00007-11-4 loss: 0.360974  [  160/  179]
train() client id: f_00007-12-0 loss: 0.577915  [   32/  179]
train() client id: f_00007-12-1 loss: 0.578384  [   64/  179]
train() client id: f_00007-12-2 loss: 0.431128  [   96/  179]
train() client id: f_00007-12-3 loss: 0.637910  [  128/  179]
train() client id: f_00007-12-4 loss: 0.589598  [  160/  179]
train() client id: f_00008-0-0 loss: 0.720622  [   32/  130]
train() client id: f_00008-0-1 loss: 0.656503  [   64/  130]
train() client id: f_00008-0-2 loss: 0.634682  [   96/  130]
train() client id: f_00008-0-3 loss: 0.749887  [  128/  130]
train() client id: f_00008-1-0 loss: 0.758718  [   32/  130]
train() client id: f_00008-1-1 loss: 0.664152  [   64/  130]
train() client id: f_00008-1-2 loss: 0.639057  [   96/  130]
train() client id: f_00008-1-3 loss: 0.671200  [  128/  130]
train() client id: f_00008-2-0 loss: 0.601859  [   32/  130]
train() client id: f_00008-2-1 loss: 0.754163  [   64/  130]
train() client id: f_00008-2-2 loss: 0.789443  [   96/  130]
train() client id: f_00008-2-3 loss: 0.618140  [  128/  130]
train() client id: f_00008-3-0 loss: 0.675135  [   32/  130]
train() client id: f_00008-3-1 loss: 0.668715  [   64/  130]
train() client id: f_00008-3-2 loss: 0.658944  [   96/  130]
train() client id: f_00008-3-3 loss: 0.712405  [  128/  130]
train() client id: f_00008-4-0 loss: 0.746810  [   32/  130]
train() client id: f_00008-4-1 loss: 0.678021  [   64/  130]
train() client id: f_00008-4-2 loss: 0.587384  [   96/  130]
train() client id: f_00008-4-3 loss: 0.751588  [  128/  130]
train() client id: f_00008-5-0 loss: 0.653350  [   32/  130]
train() client id: f_00008-5-1 loss: 0.704742  [   64/  130]
train() client id: f_00008-5-2 loss: 0.690807  [   96/  130]
train() client id: f_00008-5-3 loss: 0.691200  [  128/  130]
train() client id: f_00008-6-0 loss: 0.799076  [   32/  130]
train() client id: f_00008-6-1 loss: 0.594133  [   64/  130]
train() client id: f_00008-6-2 loss: 0.612963  [   96/  130]
train() client id: f_00008-6-3 loss: 0.726532  [  128/  130]
train() client id: f_00008-7-0 loss: 0.704545  [   32/  130]
train() client id: f_00008-7-1 loss: 0.666943  [   64/  130]
train() client id: f_00008-7-2 loss: 0.726830  [   96/  130]
train() client id: f_00008-7-3 loss: 0.630252  [  128/  130]
train() client id: f_00008-8-0 loss: 0.729766  [   32/  130]
train() client id: f_00008-8-1 loss: 0.680468  [   64/  130]
train() client id: f_00008-8-2 loss: 0.756737  [   96/  130]
train() client id: f_00008-8-3 loss: 0.580821  [  128/  130]
train() client id: f_00008-9-0 loss: 0.618758  [   32/  130]
train() client id: f_00008-9-1 loss: 0.843633  [   64/  130]
train() client id: f_00008-9-2 loss: 0.644865  [   96/  130]
train() client id: f_00008-9-3 loss: 0.659816  [  128/  130]
train() client id: f_00008-10-0 loss: 0.646839  [   32/  130]
train() client id: f_00008-10-1 loss: 0.872611  [   64/  130]
train() client id: f_00008-10-2 loss: 0.616870  [   96/  130]
train() client id: f_00008-10-3 loss: 0.591294  [  128/  130]
train() client id: f_00008-11-0 loss: 0.670482  [   32/  130]
train() client id: f_00008-11-1 loss: 0.707354  [   64/  130]
train() client id: f_00008-11-2 loss: 0.738256  [   96/  130]
train() client id: f_00008-11-3 loss: 0.623864  [  128/  130]
train() client id: f_00008-12-0 loss: 0.749790  [   32/  130]
train() client id: f_00008-12-1 loss: 0.636075  [   64/  130]
train() client id: f_00008-12-2 loss: 0.753846  [   96/  130]
train() client id: f_00008-12-3 loss: 0.586070  [  128/  130]
train() client id: f_00009-0-0 loss: 1.126053  [   32/  118]
train() client id: f_00009-0-1 loss: 0.885239  [   64/  118]
train() client id: f_00009-0-2 loss: 1.067685  [   96/  118]
train() client id: f_00009-1-0 loss: 1.114004  [   32/  118]
train() client id: f_00009-1-1 loss: 0.938518  [   64/  118]
train() client id: f_00009-1-2 loss: 0.899839  [   96/  118]
train() client id: f_00009-2-0 loss: 0.933731  [   32/  118]
train() client id: f_00009-2-1 loss: 0.827764  [   64/  118]
train() client id: f_00009-2-2 loss: 0.971904  [   96/  118]
train() client id: f_00009-3-0 loss: 0.820877  [   32/  118]
train() client id: f_00009-3-1 loss: 0.941000  [   64/  118]
train() client id: f_00009-3-2 loss: 0.960446  [   96/  118]
train() client id: f_00009-4-0 loss: 0.867290  [   32/  118]
train() client id: f_00009-4-1 loss: 0.745029  [   64/  118]
train() client id: f_00009-4-2 loss: 0.968935  [   96/  118]
train() client id: f_00009-5-0 loss: 0.839970  [   32/  118]
train() client id: f_00009-5-1 loss: 0.928722  [   64/  118]
train() client id: f_00009-5-2 loss: 0.901717  [   96/  118]
train() client id: f_00009-6-0 loss: 0.763296  [   32/  118]
train() client id: f_00009-6-1 loss: 0.851187  [   64/  118]
train() client id: f_00009-6-2 loss: 0.750651  [   96/  118]
train() client id: f_00009-7-0 loss: 0.708676  [   32/  118]
train() client id: f_00009-7-1 loss: 0.764383  [   64/  118]
train() client id: f_00009-7-2 loss: 0.924665  [   96/  118]
train() client id: f_00009-8-0 loss: 0.947747  [   32/  118]
train() client id: f_00009-8-1 loss: 0.839317  [   64/  118]
train() client id: f_00009-8-2 loss: 0.734940  [   96/  118]
train() client id: f_00009-9-0 loss: 0.844498  [   32/  118]
train() client id: f_00009-9-1 loss: 0.729546  [   64/  118]
train() client id: f_00009-9-2 loss: 0.762021  [   96/  118]
train() client id: f_00009-10-0 loss: 0.789683  [   32/  118]
train() client id: f_00009-10-1 loss: 0.866623  [   64/  118]
train() client id: f_00009-10-2 loss: 0.879584  [   96/  118]
train() client id: f_00009-11-0 loss: 0.948406  [   32/  118]
train() client id: f_00009-11-1 loss: 0.838897  [   64/  118]
train() client id: f_00009-11-2 loss: 0.691584  [   96/  118]
train() client id: f_00009-12-0 loss: 0.736868  [   32/  118]
train() client id: f_00009-12-1 loss: 0.915569  [   64/  118]
train() client id: f_00009-12-2 loss: 0.649663  [   96/  118]
At round 71 accuracy: 0.636604774535809
At round 71 training accuracy: 0.5868544600938967
At round 71 training loss: 0.836167483600579
gradient difference: 0.4813898205757141
train() client id: f_00000-0-0 loss: 1.374249  [   32/  126]
train() client id: f_00000-0-1 loss: 1.176799  [   64/  126]
train() client id: f_00000-0-2 loss: 0.979927  [   96/  126]
train() client id: f_00000-1-0 loss: 1.429500  [   32/  126]
train() client id: f_00000-1-1 loss: 0.906216  [   64/  126]
train() client id: f_00000-1-2 loss: 1.025729  [   96/  126]
train() client id: f_00000-2-0 loss: 0.881985  [   32/  126]
train() client id: f_00000-2-1 loss: 1.112171  [   64/  126]
train() client id: f_00000-2-2 loss: 1.107197  [   96/  126]
train() client id: f_00000-3-0 loss: 1.020009  [   32/  126]
train() client id: f_00000-3-1 loss: 0.988990  [   64/  126]
train() client id: f_00000-3-2 loss: 1.011415  [   96/  126]
train() client id: f_00000-4-0 loss: 1.131472  [   32/  126]
train() client id: f_00000-4-1 loss: 0.960050  [   64/  126]
train() client id: f_00000-4-2 loss: 0.852997  [   96/  126]
train() client id: f_00000-5-0 loss: 0.956077  [   32/  126]
train() client id: f_00000-5-1 loss: 0.970924  [   64/  126]
train() client id: f_00000-5-2 loss: 0.904303  [   96/  126]
train() client id: f_00000-6-0 loss: 0.937130  [   32/  126]
train() client id: f_00000-6-1 loss: 0.859202  [   64/  126]
train() client id: f_00000-6-2 loss: 0.819072  [   96/  126]
train() client id: f_00000-7-0 loss: 1.006292  [   32/  126]
train() client id: f_00000-7-1 loss: 0.906102  [   64/  126]
train() client id: f_00000-7-2 loss: 0.746900  [   96/  126]
train() client id: f_00000-8-0 loss: 0.954914  [   32/  126]
train() client id: f_00000-8-1 loss: 0.816261  [   64/  126]
train() client id: f_00000-8-2 loss: 0.963186  [   96/  126]
train() client id: f_00000-9-0 loss: 0.910360  [   32/  126]
train() client id: f_00000-9-1 loss: 0.779506  [   64/  126]
train() client id: f_00000-9-2 loss: 0.890976  [   96/  126]
train() client id: f_00000-10-0 loss: 0.911505  [   32/  126]
train() client id: f_00000-10-1 loss: 0.981865  [   64/  126]
train() client id: f_00000-10-2 loss: 0.790174  [   96/  126]
train() client id: f_00000-11-0 loss: 0.898815  [   32/  126]
train() client id: f_00000-11-1 loss: 0.963031  [   64/  126]
train() client id: f_00000-11-2 loss: 1.018416  [   96/  126]
train() client id: f_00000-12-0 loss: 0.787427  [   32/  126]
train() client id: f_00000-12-1 loss: 0.990266  [   64/  126]
train() client id: f_00000-12-2 loss: 0.888522  [   96/  126]
train() client id: f_00001-0-0 loss: 0.472962  [   32/  265]
train() client id: f_00001-0-1 loss: 0.436646  [   64/  265]
train() client id: f_00001-0-2 loss: 0.542303  [   96/  265]
train() client id: f_00001-0-3 loss: 0.421663  [  128/  265]
train() client id: f_00001-0-4 loss: 0.544563  [  160/  265]
train() client id: f_00001-0-5 loss: 0.475527  [  192/  265]
train() client id: f_00001-0-6 loss: 0.545688  [  224/  265]
train() client id: f_00001-0-7 loss: 0.466605  [  256/  265]
train() client id: f_00001-1-0 loss: 0.407270  [   32/  265]
train() client id: f_00001-1-1 loss: 0.462522  [   64/  265]
train() client id: f_00001-1-2 loss: 0.499590  [   96/  265]
train() client id: f_00001-1-3 loss: 0.390663  [  128/  265]
train() client id: f_00001-1-4 loss: 0.537764  [  160/  265]
train() client id: f_00001-1-5 loss: 0.615879  [  192/  265]
train() client id: f_00001-1-6 loss: 0.385636  [  224/  265]
train() client id: f_00001-1-7 loss: 0.486084  [  256/  265]
train() client id: f_00001-2-0 loss: 0.389714  [   32/  265]
train() client id: f_00001-2-1 loss: 0.588605  [   64/  265]
train() client id: f_00001-2-2 loss: 0.464121  [   96/  265]
train() client id: f_00001-2-3 loss: 0.532343  [  128/  265]
train() client id: f_00001-2-4 loss: 0.461809  [  160/  265]
train() client id: f_00001-2-5 loss: 0.382929  [  192/  265]
train() client id: f_00001-2-6 loss: 0.452211  [  224/  265]
train() client id: f_00001-2-7 loss: 0.507066  [  256/  265]
train() client id: f_00001-3-0 loss: 0.381235  [   32/  265]
train() client id: f_00001-3-1 loss: 0.482414  [   64/  265]
train() client id: f_00001-3-2 loss: 0.488956  [   96/  265]
train() client id: f_00001-3-3 loss: 0.442812  [  128/  265]
train() client id: f_00001-3-4 loss: 0.439288  [  160/  265]
train() client id: f_00001-3-5 loss: 0.485607  [  192/  265]
train() client id: f_00001-3-6 loss: 0.491979  [  224/  265]
train() client id: f_00001-3-7 loss: 0.478967  [  256/  265]
train() client id: f_00001-4-0 loss: 0.400242  [   32/  265]
train() client id: f_00001-4-1 loss: 0.495134  [   64/  265]
train() client id: f_00001-4-2 loss: 0.420827  [   96/  265]
train() client id: f_00001-4-3 loss: 0.419176  [  128/  265]
train() client id: f_00001-4-4 loss: 0.584256  [  160/  265]
train() client id: f_00001-4-5 loss: 0.368527  [  192/  265]
train() client id: f_00001-4-6 loss: 0.374703  [  224/  265]
train() client id: f_00001-4-7 loss: 0.674693  [  256/  265]
train() client id: f_00001-5-0 loss: 0.592214  [   32/  265]
train() client id: f_00001-5-1 loss: 0.499425  [   64/  265]
train() client id: f_00001-5-2 loss: 0.403680  [   96/  265]
train() client id: f_00001-5-3 loss: 0.393232  [  128/  265]
train() client id: f_00001-5-4 loss: 0.391043  [  160/  265]
train() client id: f_00001-5-5 loss: 0.524874  [  192/  265]
train() client id: f_00001-5-6 loss: 0.480528  [  224/  265]
train() client id: f_00001-5-7 loss: 0.410218  [  256/  265]
train() client id: f_00001-6-0 loss: 0.366317  [   32/  265]
train() client id: f_00001-6-1 loss: 0.411303  [   64/  265]
train() client id: f_00001-6-2 loss: 0.383381  [   96/  265]
train() client id: f_00001-6-3 loss: 0.457979  [  128/  265]
train() client id: f_00001-6-4 loss: 0.431699  [  160/  265]
train() client id: f_00001-6-5 loss: 0.450824  [  192/  265]
train() client id: f_00001-6-6 loss: 0.630466  [  224/  265]
train() client id: f_00001-6-7 loss: 0.561455  [  256/  265]
train() client id: f_00001-7-0 loss: 0.395585  [   32/  265]
train() client id: f_00001-7-1 loss: 0.653386  [   64/  265]
train() client id: f_00001-7-2 loss: 0.429115  [   96/  265]
train() client id: f_00001-7-3 loss: 0.584220  [  128/  265]
train() client id: f_00001-7-4 loss: 0.412816  [  160/  265]
train() client id: f_00001-7-5 loss: 0.374796  [  192/  265]
train() client id: f_00001-7-6 loss: 0.364959  [  224/  265]
train() client id: f_00001-7-7 loss: 0.472897  [  256/  265]
train() client id: f_00001-8-0 loss: 0.568599  [   32/  265]
train() client id: f_00001-8-1 loss: 0.416118  [   64/  265]
train() client id: f_00001-8-2 loss: 0.430711  [   96/  265]
train() client id: f_00001-8-3 loss: 0.376607  [  128/  265]
train() client id: f_00001-8-4 loss: 0.429340  [  160/  265]
train() client id: f_00001-8-5 loss: 0.396422  [  192/  265]
train() client id: f_00001-8-6 loss: 0.628251  [  224/  265]
train() client id: f_00001-8-7 loss: 0.435551  [  256/  265]
train() client id: f_00001-9-0 loss: 0.361075  [   32/  265]
train() client id: f_00001-9-1 loss: 0.681777  [   64/  265]
train() client id: f_00001-9-2 loss: 0.524754  [   96/  265]
train() client id: f_00001-9-3 loss: 0.482464  [  128/  265]
train() client id: f_00001-9-4 loss: 0.505724  [  160/  265]
train() client id: f_00001-9-5 loss: 0.393171  [  192/  265]
train() client id: f_00001-9-6 loss: 0.377107  [  224/  265]
train() client id: f_00001-9-7 loss: 0.358402  [  256/  265]
train() client id: f_00001-10-0 loss: 0.354894  [   32/  265]
train() client id: f_00001-10-1 loss: 0.458510  [   64/  265]
train() client id: f_00001-10-2 loss: 0.557854  [   96/  265]
train() client id: f_00001-10-3 loss: 0.367183  [  128/  265]
train() client id: f_00001-10-4 loss: 0.423506  [  160/  265]
train() client id: f_00001-10-5 loss: 0.521224  [  192/  265]
train() client id: f_00001-10-6 loss: 0.464519  [  224/  265]
train() client id: f_00001-10-7 loss: 0.467887  [  256/  265]
train() client id: f_00001-11-0 loss: 0.402684  [   32/  265]
train() client id: f_00001-11-1 loss: 0.375711  [   64/  265]
train() client id: f_00001-11-2 loss: 0.494357  [   96/  265]
train() client id: f_00001-11-3 loss: 0.464178  [  128/  265]
train() client id: f_00001-11-4 loss: 0.453116  [  160/  265]
train() client id: f_00001-11-5 loss: 0.506032  [  192/  265]
train() client id: f_00001-11-6 loss: 0.402818  [  224/  265]
train() client id: f_00001-11-7 loss: 0.405282  [  256/  265]
train() client id: f_00001-12-0 loss: 0.458258  [   32/  265]
train() client id: f_00001-12-1 loss: 0.527264  [   64/  265]
train() client id: f_00001-12-2 loss: 0.597076  [   96/  265]
train() client id: f_00001-12-3 loss: 0.352939  [  128/  265]
train() client id: f_00001-12-4 loss: 0.372405  [  160/  265]
train() client id: f_00001-12-5 loss: 0.596033  [  192/  265]
train() client id: f_00001-12-6 loss: 0.416661  [  224/  265]
train() client id: f_00001-12-7 loss: 0.361642  [  256/  265]
train() client id: f_00002-0-0 loss: 1.095823  [   32/  124]
train() client id: f_00002-0-1 loss: 1.182864  [   64/  124]
train() client id: f_00002-0-2 loss: 1.411900  [   96/  124]
train() client id: f_00002-1-0 loss: 1.113671  [   32/  124]
train() client id: f_00002-1-1 loss: 1.165469  [   64/  124]
train() client id: f_00002-1-2 loss: 1.286887  [   96/  124]
train() client id: f_00002-2-0 loss: 1.203047  [   32/  124]
train() client id: f_00002-2-1 loss: 1.018634  [   64/  124]
train() client id: f_00002-2-2 loss: 1.243683  [   96/  124]
train() client id: f_00002-3-0 loss: 1.260368  [   32/  124]
train() client id: f_00002-3-1 loss: 1.143636  [   64/  124]
train() client id: f_00002-3-2 loss: 1.131118  [   96/  124]
train() client id: f_00002-4-0 loss: 1.047689  [   32/  124]
train() client id: f_00002-4-1 loss: 1.038275  [   64/  124]
train() client id: f_00002-4-2 loss: 1.067935  [   96/  124]
train() client id: f_00002-5-0 loss: 1.135719  [   32/  124]
train() client id: f_00002-5-1 loss: 0.987897  [   64/  124]
train() client id: f_00002-5-2 loss: 1.235777  [   96/  124]
train() client id: f_00002-6-0 loss: 1.012741  [   32/  124]
train() client id: f_00002-6-1 loss: 1.045655  [   64/  124]
train() client id: f_00002-6-2 loss: 1.247535  [   96/  124]
train() client id: f_00002-7-0 loss: 1.005892  [   32/  124]
train() client id: f_00002-7-1 loss: 0.983721  [   64/  124]
train() client id: f_00002-7-2 loss: 1.252434  [   96/  124]
train() client id: f_00002-8-0 loss: 0.972631  [   32/  124]
train() client id: f_00002-8-1 loss: 1.248545  [   64/  124]
train() client id: f_00002-8-2 loss: 0.961138  [   96/  124]
train() client id: f_00002-9-0 loss: 0.964779  [   32/  124]
train() client id: f_00002-9-1 loss: 1.061058  [   64/  124]
train() client id: f_00002-9-2 loss: 1.210505  [   96/  124]
train() client id: f_00002-10-0 loss: 1.076877  [   32/  124]
train() client id: f_00002-10-1 loss: 1.073043  [   64/  124]
train() client id: f_00002-10-2 loss: 1.050859  [   96/  124]
train() client id: f_00002-11-0 loss: 1.109000  [   32/  124]
train() client id: f_00002-11-1 loss: 0.983843  [   64/  124]
train() client id: f_00002-11-2 loss: 0.983449  [   96/  124]
train() client id: f_00002-12-0 loss: 1.065584  [   32/  124]
train() client id: f_00002-12-1 loss: 1.134253  [   64/  124]
train() client id: f_00002-12-2 loss: 1.057689  [   96/  124]
train() client id: f_00003-0-0 loss: 0.819676  [   32/   43]
train() client id: f_00003-1-0 loss: 0.544584  [   32/   43]
train() client id: f_00003-2-0 loss: 0.566498  [   32/   43]
train() client id: f_00003-3-0 loss: 0.620685  [   32/   43]
train() client id: f_00003-4-0 loss: 0.651673  [   32/   43]
train() client id: f_00003-5-0 loss: 0.470685  [   32/   43]
train() client id: f_00003-6-0 loss: 0.706532  [   32/   43]
train() client id: f_00003-7-0 loss: 0.614854  [   32/   43]
train() client id: f_00003-8-0 loss: 0.565556  [   32/   43]
train() client id: f_00003-9-0 loss: 0.613201  [   32/   43]
train() client id: f_00003-10-0 loss: 0.635094  [   32/   43]
train() client id: f_00003-11-0 loss: 0.473989  [   32/   43]
train() client id: f_00003-12-0 loss: 0.557278  [   32/   43]
train() client id: f_00004-0-0 loss: 0.942485  [   32/  306]
train() client id: f_00004-0-1 loss: 0.800056  [   64/  306]
train() client id: f_00004-0-2 loss: 0.882676  [   96/  306]
train() client id: f_00004-0-3 loss: 0.919693  [  128/  306]
train() client id: f_00004-0-4 loss: 0.640534  [  160/  306]
train() client id: f_00004-0-5 loss: 0.666769  [  192/  306]
train() client id: f_00004-0-6 loss: 0.795212  [  224/  306]
train() client id: f_00004-0-7 loss: 0.786658  [  256/  306]
train() client id: f_00004-0-8 loss: 0.886746  [  288/  306]
train() client id: f_00004-1-0 loss: 0.746003  [   32/  306]
train() client id: f_00004-1-1 loss: 0.874517  [   64/  306]
train() client id: f_00004-1-2 loss: 0.648409  [   96/  306]
train() client id: f_00004-1-3 loss: 0.780358  [  128/  306]
train() client id: f_00004-1-4 loss: 0.884740  [  160/  306]
train() client id: f_00004-1-5 loss: 0.791834  [  192/  306]
train() client id: f_00004-1-6 loss: 0.777841  [  224/  306]
train() client id: f_00004-1-7 loss: 0.757724  [  256/  306]
train() client id: f_00004-1-8 loss: 0.936591  [  288/  306]
train() client id: f_00004-2-0 loss: 0.899981  [   32/  306]
train() client id: f_00004-2-1 loss: 0.770625  [   64/  306]
train() client id: f_00004-2-2 loss: 0.759114  [   96/  306]
train() client id: f_00004-2-3 loss: 0.662132  [  128/  306]
train() client id: f_00004-2-4 loss: 0.915342  [  160/  306]
train() client id: f_00004-2-5 loss: 0.809444  [  192/  306]
train() client id: f_00004-2-6 loss: 0.860439  [  224/  306]
train() client id: f_00004-2-7 loss: 0.837377  [  256/  306]
train() client id: f_00004-2-8 loss: 0.807213  [  288/  306]
train() client id: f_00004-3-0 loss: 0.652138  [   32/  306]
train() client id: f_00004-3-1 loss: 0.790042  [   64/  306]
train() client id: f_00004-3-2 loss: 0.722086  [   96/  306]
train() client id: f_00004-3-3 loss: 0.818539  [  128/  306]
train() client id: f_00004-3-4 loss: 0.699852  [  160/  306]
train() client id: f_00004-3-5 loss: 0.886671  [  192/  306]
train() client id: f_00004-3-6 loss: 0.814579  [  224/  306]
train() client id: f_00004-3-7 loss: 0.835207  [  256/  306]
train() client id: f_00004-3-8 loss: 0.904867  [  288/  306]
train() client id: f_00004-4-0 loss: 0.755137  [   32/  306]
train() client id: f_00004-4-1 loss: 0.746696  [   64/  306]
train() client id: f_00004-4-2 loss: 0.910046  [   96/  306]
train() client id: f_00004-4-3 loss: 0.824052  [  128/  306]
train() client id: f_00004-4-4 loss: 0.821304  [  160/  306]
train() client id: f_00004-4-5 loss: 0.728258  [  192/  306]
train() client id: f_00004-4-6 loss: 0.811880  [  224/  306]
train() client id: f_00004-4-7 loss: 0.912285  [  256/  306]
train() client id: f_00004-4-8 loss: 0.769616  [  288/  306]
train() client id: f_00004-5-0 loss: 0.719414  [   32/  306]
train() client id: f_00004-5-1 loss: 0.839912  [   64/  306]
train() client id: f_00004-5-2 loss: 0.694332  [   96/  306]
train() client id: f_00004-5-3 loss: 0.763764  [  128/  306]
train() client id: f_00004-5-4 loss: 0.961888  [  160/  306]
train() client id: f_00004-5-5 loss: 0.859768  [  192/  306]
train() client id: f_00004-5-6 loss: 0.771187  [  224/  306]
train() client id: f_00004-5-7 loss: 0.929023  [  256/  306]
train() client id: f_00004-5-8 loss: 0.696429  [  288/  306]
train() client id: f_00004-6-0 loss: 0.805145  [   32/  306]
train() client id: f_00004-6-1 loss: 0.952926  [   64/  306]
train() client id: f_00004-6-2 loss: 0.820656  [   96/  306]
train() client id: f_00004-6-3 loss: 0.682973  [  128/  306]
train() client id: f_00004-6-4 loss: 0.823026  [  160/  306]
train() client id: f_00004-6-5 loss: 0.785121  [  192/  306]
train() client id: f_00004-6-6 loss: 0.869526  [  224/  306]
train() client id: f_00004-6-7 loss: 0.902756  [  256/  306]
train() client id: f_00004-6-8 loss: 0.733622  [  288/  306]
train() client id: f_00004-7-0 loss: 0.618309  [   32/  306]
train() client id: f_00004-7-1 loss: 0.716582  [   64/  306]
train() client id: f_00004-7-2 loss: 1.004773  [   96/  306]
train() client id: f_00004-7-3 loss: 0.715105  [  128/  306]
train() client id: f_00004-7-4 loss: 0.836587  [  160/  306]
train() client id: f_00004-7-5 loss: 0.804024  [  192/  306]
train() client id: f_00004-7-6 loss: 0.817518  [  224/  306]
train() client id: f_00004-7-7 loss: 0.943152  [  256/  306]
train() client id: f_00004-7-8 loss: 0.699843  [  288/  306]
train() client id: f_00004-8-0 loss: 0.661250  [   32/  306]
train() client id: f_00004-8-1 loss: 0.825885  [   64/  306]
train() client id: f_00004-8-2 loss: 0.871358  [   96/  306]
train() client id: f_00004-8-3 loss: 0.798598  [  128/  306]
train() client id: f_00004-8-4 loss: 0.819726  [  160/  306]
train() client id: f_00004-8-5 loss: 0.880684  [  192/  306]
train() client id: f_00004-8-6 loss: 0.823952  [  224/  306]
train() client id: f_00004-8-7 loss: 0.840129  [  256/  306]
train() client id: f_00004-8-8 loss: 0.726425  [  288/  306]
train() client id: f_00004-9-0 loss: 0.832699  [   32/  306]
train() client id: f_00004-9-1 loss: 0.782652  [   64/  306]
train() client id: f_00004-9-2 loss: 0.859084  [   96/  306]
train() client id: f_00004-9-3 loss: 0.780349  [  128/  306]
train() client id: f_00004-9-4 loss: 0.928497  [  160/  306]
train() client id: f_00004-9-5 loss: 0.758135  [  192/  306]
train() client id: f_00004-9-6 loss: 0.857934  [  224/  306]
train() client id: f_00004-9-7 loss: 0.851937  [  256/  306]
train() client id: f_00004-9-8 loss: 0.687915  [  288/  306]
train() client id: f_00004-10-0 loss: 0.948454  [   32/  306]
train() client id: f_00004-10-1 loss: 0.761097  [   64/  306]
train() client id: f_00004-10-2 loss: 0.840192  [   96/  306]
train() client id: f_00004-10-3 loss: 0.745119  [  128/  306]
train() client id: f_00004-10-4 loss: 0.787464  [  160/  306]
train() client id: f_00004-10-5 loss: 0.839397  [  192/  306]
train() client id: f_00004-10-6 loss: 0.761127  [  224/  306]
train() client id: f_00004-10-7 loss: 0.796922  [  256/  306]
train() client id: f_00004-10-8 loss: 0.869404  [  288/  306]
train() client id: f_00004-11-0 loss: 0.691366  [   32/  306]
train() client id: f_00004-11-1 loss: 0.838572  [   64/  306]
train() client id: f_00004-11-2 loss: 0.781492  [   96/  306]
train() client id: f_00004-11-3 loss: 0.943758  [  128/  306]
train() client id: f_00004-11-4 loss: 0.764800  [  160/  306]
train() client id: f_00004-11-5 loss: 0.675165  [  192/  306]
train() client id: f_00004-11-6 loss: 0.802148  [  224/  306]
train() client id: f_00004-11-7 loss: 0.920272  [  256/  306]
train() client id: f_00004-11-8 loss: 0.889302  [  288/  306]
train() client id: f_00004-12-0 loss: 0.800750  [   32/  306]
train() client id: f_00004-12-1 loss: 0.828409  [   64/  306]
train() client id: f_00004-12-2 loss: 0.765590  [   96/  306]
train() client id: f_00004-12-3 loss: 0.969941  [  128/  306]
train() client id: f_00004-12-4 loss: 0.904172  [  160/  306]
train() client id: f_00004-12-5 loss: 0.762348  [  192/  306]
train() client id: f_00004-12-6 loss: 0.703232  [  224/  306]
train() client id: f_00004-12-7 loss: 0.747948  [  256/  306]
train() client id: f_00004-12-8 loss: 0.863928  [  288/  306]
train() client id: f_00005-0-0 loss: 0.923829  [   32/  146]
train() client id: f_00005-0-1 loss: 0.742992  [   64/  146]
train() client id: f_00005-0-2 loss: 0.677790  [   96/  146]
train() client id: f_00005-0-3 loss: 0.533786  [  128/  146]
train() client id: f_00005-1-0 loss: 0.542785  [   32/  146]
train() client id: f_00005-1-1 loss: 0.886811  [   64/  146]
train() client id: f_00005-1-2 loss: 0.733575  [   96/  146]
train() client id: f_00005-1-3 loss: 0.510300  [  128/  146]
train() client id: f_00005-2-0 loss: 0.688352  [   32/  146]
train() client id: f_00005-2-1 loss: 0.680938  [   64/  146]
train() client id: f_00005-2-2 loss: 0.479704  [   96/  146]
train() client id: f_00005-2-3 loss: 0.846284  [  128/  146]
train() client id: f_00005-3-0 loss: 0.365602  [   32/  146]
train() client id: f_00005-3-1 loss: 0.778549  [   64/  146]
train() client id: f_00005-3-2 loss: 0.655210  [   96/  146]
train() client id: f_00005-3-3 loss: 0.616796  [  128/  146]
train() client id: f_00005-4-0 loss: 0.716385  [   32/  146]
train() client id: f_00005-4-1 loss: 0.518057  [   64/  146]
train() client id: f_00005-4-2 loss: 0.696232  [   96/  146]
train() client id: f_00005-4-3 loss: 0.566661  [  128/  146]
train() client id: f_00005-5-0 loss: 0.474863  [   32/  146]
train() client id: f_00005-5-1 loss: 0.732576  [   64/  146]
train() client id: f_00005-5-2 loss: 0.618416  [   96/  146]
train() client id: f_00005-5-3 loss: 0.751918  [  128/  146]
train() client id: f_00005-6-0 loss: 0.523671  [   32/  146]
train() client id: f_00005-6-1 loss: 0.600174  [   64/  146]
train() client id: f_00005-6-2 loss: 0.947618  [   96/  146]
train() client id: f_00005-6-3 loss: 0.711651  [  128/  146]
train() client id: f_00005-7-0 loss: 0.655597  [   32/  146]
train() client id: f_00005-7-1 loss: 0.807433  [   64/  146]
train() client id: f_00005-7-2 loss: 0.546135  [   96/  146]
train() client id: f_00005-7-3 loss: 0.460083  [  128/  146]
train() client id: f_00005-8-0 loss: 0.532564  [   32/  146]
train() client id: f_00005-8-1 loss: 0.506129  [   64/  146]
train() client id: f_00005-8-2 loss: 0.761519  [   96/  146]
train() client id: f_00005-8-3 loss: 0.675287  [  128/  146]
train() client id: f_00005-9-0 loss: 0.714111  [   32/  146]
train() client id: f_00005-9-1 loss: 0.479205  [   64/  146]
train() client id: f_00005-9-2 loss: 0.665754  [   96/  146]
train() client id: f_00005-9-3 loss: 0.505597  [  128/  146]
train() client id: f_00005-10-0 loss: 0.561300  [   32/  146]
train() client id: f_00005-10-1 loss: 0.780485  [   64/  146]
train() client id: f_00005-10-2 loss: 0.483137  [   96/  146]
train() client id: f_00005-10-3 loss: 0.638703  [  128/  146]
train() client id: f_00005-11-0 loss: 0.717562  [   32/  146]
train() client id: f_00005-11-1 loss: 0.541293  [   64/  146]
train() client id: f_00005-11-2 loss: 0.593005  [   96/  146]
train() client id: f_00005-11-3 loss: 0.499540  [  128/  146]
train() client id: f_00005-12-0 loss: 0.691482  [   32/  146]
train() client id: f_00005-12-1 loss: 0.405106  [   64/  146]
train() client id: f_00005-12-2 loss: 0.673950  [   96/  146]
train() client id: f_00005-12-3 loss: 0.868272  [  128/  146]
train() client id: f_00006-0-0 loss: 0.487450  [   32/   54]
train() client id: f_00006-1-0 loss: 0.522229  [   32/   54]
train() client id: f_00006-2-0 loss: 0.512989  [   32/   54]
train() client id: f_00006-3-0 loss: 0.542204  [   32/   54]
train() client id: f_00006-4-0 loss: 0.558149  [   32/   54]
train() client id: f_00006-5-0 loss: 0.552839  [   32/   54]
train() client id: f_00006-6-0 loss: 0.486791  [   32/   54]
train() client id: f_00006-7-0 loss: 0.499378  [   32/   54]
train() client id: f_00006-8-0 loss: 0.502894  [   32/   54]
train() client id: f_00006-9-0 loss: 0.568175  [   32/   54]
train() client id: f_00006-10-0 loss: 0.519991  [   32/   54]
train() client id: f_00006-11-0 loss: 0.481463  [   32/   54]
train() client id: f_00006-12-0 loss: 0.563390  [   32/   54]
train() client id: f_00007-0-0 loss: 0.451758  [   32/  179]
train() client id: f_00007-0-1 loss: 0.536046  [   64/  179]
train() client id: f_00007-0-2 loss: 0.336715  [   96/  179]
train() client id: f_00007-0-3 loss: 0.534156  [  128/  179]
train() client id: f_00007-0-4 loss: 0.715608  [  160/  179]
train() client id: f_00007-1-0 loss: 0.355025  [   32/  179]
train() client id: f_00007-1-1 loss: 0.496261  [   64/  179]
train() client id: f_00007-1-2 loss: 0.570504  [   96/  179]
train() client id: f_00007-1-3 loss: 0.667505  [  128/  179]
train() client id: f_00007-1-4 loss: 0.513747  [  160/  179]
train() client id: f_00007-2-0 loss: 0.616459  [   32/  179]
train() client id: f_00007-2-1 loss: 0.381547  [   64/  179]
train() client id: f_00007-2-2 loss: 0.529577  [   96/  179]
train() client id: f_00007-2-3 loss: 0.520504  [  128/  179]
train() client id: f_00007-2-4 loss: 0.452301  [  160/  179]
train() client id: f_00007-3-0 loss: 0.464518  [   32/  179]
train() client id: f_00007-3-1 loss: 0.805226  [   64/  179]
train() client id: f_00007-3-2 loss: 0.332789  [   96/  179]
train() client id: f_00007-3-3 loss: 0.354672  [  128/  179]
train() client id: f_00007-3-4 loss: 0.432146  [  160/  179]
train() client id: f_00007-4-0 loss: 0.439589  [   32/  179]
train() client id: f_00007-4-1 loss: 0.591978  [   64/  179]
train() client id: f_00007-4-2 loss: 0.329938  [   96/  179]
train() client id: f_00007-4-3 loss: 0.681033  [  128/  179]
train() client id: f_00007-4-4 loss: 0.422317  [  160/  179]
train() client id: f_00007-5-0 loss: 0.489378  [   32/  179]
train() client id: f_00007-5-1 loss: 0.563104  [   64/  179]
train() client id: f_00007-5-2 loss: 0.343418  [   96/  179]
train() client id: f_00007-5-3 loss: 0.451666  [  128/  179]
train() client id: f_00007-5-4 loss: 0.583303  [  160/  179]
train() client id: f_00007-6-0 loss: 0.535572  [   32/  179]
train() client id: f_00007-6-1 loss: 0.421638  [   64/  179]
train() client id: f_00007-6-2 loss: 0.348283  [   96/  179]
train() client id: f_00007-6-3 loss: 0.430900  [  128/  179]
train() client id: f_00007-6-4 loss: 0.617335  [  160/  179]
train() client id: f_00007-7-0 loss: 0.355038  [   32/  179]
train() client id: f_00007-7-1 loss: 0.757352  [   64/  179]
train() client id: f_00007-7-2 loss: 0.437187  [   96/  179]
train() client id: f_00007-7-3 loss: 0.561602  [  128/  179]
train() client id: f_00007-7-4 loss: 0.428811  [  160/  179]
train() client id: f_00007-8-0 loss: 0.399545  [   32/  179]
train() client id: f_00007-8-1 loss: 0.441893  [   64/  179]
train() client id: f_00007-8-2 loss: 0.350179  [   96/  179]
train() client id: f_00007-8-3 loss: 0.296612  [  128/  179]
train() client id: f_00007-8-4 loss: 0.700213  [  160/  179]
train() client id: f_00007-9-0 loss: 0.459437  [   32/  179]
train() client id: f_00007-9-1 loss: 0.406376  [   64/  179]
train() client id: f_00007-9-2 loss: 0.330481  [   96/  179]
train() client id: f_00007-9-3 loss: 0.623141  [  128/  179]
train() client id: f_00007-9-4 loss: 0.506886  [  160/  179]
train() client id: f_00007-10-0 loss: 0.516355  [   32/  179]
train() client id: f_00007-10-1 loss: 0.429032  [   64/  179]
train() client id: f_00007-10-2 loss: 0.522515  [   96/  179]
train() client id: f_00007-10-3 loss: 0.409399  [  128/  179]
train() client id: f_00007-10-4 loss: 0.542412  [  160/  179]
train() client id: f_00007-11-0 loss: 0.412186  [   32/  179]
train() client id: f_00007-11-1 loss: 0.486774  [   64/  179]
train() client id: f_00007-11-2 loss: 0.603822  [   96/  179]
train() client id: f_00007-11-3 loss: 0.491375  [  128/  179]
train() client id: f_00007-11-4 loss: 0.334580  [  160/  179]
train() client id: f_00007-12-0 loss: 0.541908  [   32/  179]
train() client id: f_00007-12-1 loss: 0.590647  [   64/  179]
train() client id: f_00007-12-2 loss: 0.327742  [   96/  179]
train() client id: f_00007-12-3 loss: 0.630893  [  128/  179]
train() client id: f_00007-12-4 loss: 0.411876  [  160/  179]
train() client id: f_00008-0-0 loss: 0.793423  [   32/  130]
train() client id: f_00008-0-1 loss: 0.755123  [   64/  130]
train() client id: f_00008-0-2 loss: 0.794596  [   96/  130]
train() client id: f_00008-0-3 loss: 0.740571  [  128/  130]
train() client id: f_00008-1-0 loss: 0.919296  [   32/  130]
train() client id: f_00008-1-1 loss: 0.818359  [   64/  130]
train() client id: f_00008-1-2 loss: 0.755651  [   96/  130]
train() client id: f_00008-1-3 loss: 0.579287  [  128/  130]
train() client id: f_00008-2-0 loss: 0.729565  [   32/  130]
train() client id: f_00008-2-1 loss: 0.789730  [   64/  130]
train() client id: f_00008-2-2 loss: 0.677827  [   96/  130]
train() client id: f_00008-2-3 loss: 0.876179  [  128/  130]
train() client id: f_00008-3-0 loss: 0.719476  [   32/  130]
train() client id: f_00008-3-1 loss: 0.740205  [   64/  130]
train() client id: f_00008-3-2 loss: 0.726680  [   96/  130]
train() client id: f_00008-3-3 loss: 0.856691  [  128/  130]
train() client id: f_00008-4-0 loss: 0.847387  [   32/  130]
train() client id: f_00008-4-1 loss: 0.664154  [   64/  130]
train() client id: f_00008-4-2 loss: 0.670986  [   96/  130]
train() client id: f_00008-4-3 loss: 0.858444  [  128/  130]
train() client id: f_00008-5-0 loss: 0.742746  [   32/  130]
train() client id: f_00008-5-1 loss: 0.779945  [   64/  130]
train() client id: f_00008-5-2 loss: 0.807981  [   96/  130]
train() client id: f_00008-5-3 loss: 0.728729  [  128/  130]
train() client id: f_00008-6-0 loss: 0.734010  [   32/  130]
train() client id: f_00008-6-1 loss: 0.763229  [   64/  130]
train() client id: f_00008-6-2 loss: 0.820178  [   96/  130]
train() client id: f_00008-6-3 loss: 0.708585  [  128/  130]
train() client id: f_00008-7-0 loss: 0.677353  [   32/  130]
train() client id: f_00008-7-1 loss: 0.773898  [   64/  130]
train() client id: f_00008-7-2 loss: 0.788752  [   96/  130]
train() client id: f_00008-7-3 loss: 0.812519  [  128/  130]
train() client id: f_00008-8-0 loss: 0.691746  [   32/  130]
train() client id: f_00008-8-1 loss: 0.666331  [   64/  130]
train() client id: f_00008-8-2 loss: 0.880846  [   96/  130]
train() client id: f_00008-8-3 loss: 0.812952  [  128/  130]
train() client id: f_00008-9-0 loss: 0.775029  [   32/  130]
train() client id: f_00008-9-1 loss: 0.692338  [   64/  130]
train() client id: f_00008-9-2 loss: 0.733279  [   96/  130]
train() client id: f_00008-9-3 loss: 0.850642  [  128/  130]
train() client id: f_00008-10-0 loss: 0.759490  [   32/  130]
train() client id: f_00008-10-1 loss: 0.784079  [   64/  130]
train() client id: f_00008-10-2 loss: 0.787922  [   96/  130]
train() client id: f_00008-10-3 loss: 0.715009  [  128/  130]
train() client id: f_00008-11-0 loss: 0.748807  [   32/  130]
train() client id: f_00008-11-1 loss: 0.765173  [   64/  130]
train() client id: f_00008-11-2 loss: 0.718717  [   96/  130]
train() client id: f_00008-11-3 loss: 0.785316  [  128/  130]
train() client id: f_00008-12-0 loss: 0.758847  [   32/  130]
train() client id: f_00008-12-1 loss: 0.786230  [   64/  130]
train() client id: f_00008-12-2 loss: 0.686442  [   96/  130]
train() client id: f_00008-12-3 loss: 0.750617  [  128/  130]
train() client id: f_00009-0-0 loss: 1.123475  [   32/  118]
train() client id: f_00009-0-1 loss: 1.274054  [   64/  118]
train() client id: f_00009-0-2 loss: 1.319746  [   96/  118]
train() client id: f_00009-1-0 loss: 1.132829  [   32/  118]
train() client id: f_00009-1-1 loss: 1.342048  [   64/  118]
train() client id: f_00009-1-2 loss: 0.988345  [   96/  118]
train() client id: f_00009-2-0 loss: 1.129587  [   32/  118]
train() client id: f_00009-2-1 loss: 1.171402  [   64/  118]
train() client id: f_00009-2-2 loss: 1.104492  [   96/  118]
train() client id: f_00009-3-0 loss: 1.084108  [   32/  118]
train() client id: f_00009-3-1 loss: 1.152612  [   64/  118]
train() client id: f_00009-3-2 loss: 1.177545  [   96/  118]
train() client id: f_00009-4-0 loss: 1.111493  [   32/  118]
train() client id: f_00009-4-1 loss: 1.115814  [   64/  118]
train() client id: f_00009-4-2 loss: 0.963842  [   96/  118]
train() client id: f_00009-5-0 loss: 0.949244  [   32/  118]
train() client id: f_00009-5-1 loss: 1.144555  [   64/  118]
train() client id: f_00009-5-2 loss: 1.091322  [   96/  118]
train() client id: f_00009-6-0 loss: 1.059975  [   32/  118]
train() client id: f_00009-6-1 loss: 0.986292  [   64/  118]
train() client id: f_00009-6-2 loss: 0.911557  [   96/  118]
train() client id: f_00009-7-0 loss: 0.988058  [   32/  118]
train() client id: f_00009-7-1 loss: 1.133035  [   64/  118]
train() client id: f_00009-7-2 loss: 0.926507  [   96/  118]
train() client id: f_00009-8-0 loss: 0.990590  [   32/  118]
train() client id: f_00009-8-1 loss: 1.022425  [   64/  118]
train() client id: f_00009-8-2 loss: 0.965446  [   96/  118]
train() client id: f_00009-9-0 loss: 0.987440  [   32/  118]
train() client id: f_00009-9-1 loss: 0.744021  [   64/  118]
train() client id: f_00009-9-2 loss: 1.104964  [   96/  118]
train() client id: f_00009-10-0 loss: 0.972173  [   32/  118]
train() client id: f_00009-10-1 loss: 0.940058  [   64/  118]
train() client id: f_00009-10-2 loss: 0.952513  [   96/  118]
train() client id: f_00009-11-0 loss: 0.945029  [   32/  118]
train() client id: f_00009-11-1 loss: 1.186484  [   64/  118]
train() client id: f_00009-11-2 loss: 0.761935  [   96/  118]
train() client id: f_00009-12-0 loss: 0.971935  [   32/  118]
train() client id: f_00009-12-1 loss: 1.036562  [   64/  118]
train() client id: f_00009-12-2 loss: 0.938432  [   96/  118]
At round 72 accuracy: 0.636604774535809
At round 72 training accuracy: 0.5835010060362174
At round 72 training loss: 0.8359199911688275
gradient difference: 0.4654901623725891
train() client id: f_00000-0-0 loss: 0.970176  [   32/  126]
train() client id: f_00000-0-1 loss: 0.862746  [   64/  126]
train() client id: f_00000-0-2 loss: 0.888844  [   96/  126]
train() client id: f_00000-1-0 loss: 0.951443  [   32/  126]
train() client id: f_00000-1-1 loss: 0.911207  [   64/  126]
train() client id: f_00000-1-2 loss: 0.835465  [   96/  126]
train() client id: f_00000-2-0 loss: 0.774397  [   32/  126]
train() client id: f_00000-2-1 loss: 0.697250  [   64/  126]
train() client id: f_00000-2-2 loss: 0.927501  [   96/  126]
train() client id: f_00000-3-0 loss: 0.879114  [   32/  126]
train() client id: f_00000-3-1 loss: 0.767293  [   64/  126]
train() client id: f_00000-3-2 loss: 0.720031  [   96/  126]
train() client id: f_00000-4-0 loss: 0.673006  [   32/  126]
train() client id: f_00000-4-1 loss: 0.821888  [   64/  126]
train() client id: f_00000-4-2 loss: 0.818233  [   96/  126]
train() client id: f_00000-5-0 loss: 0.749912  [   32/  126]
train() client id: f_00000-5-1 loss: 0.666513  [   64/  126]
train() client id: f_00000-5-2 loss: 0.919123  [   96/  126]
train() client id: f_00000-6-0 loss: 0.798148  [   32/  126]
train() client id: f_00000-6-1 loss: 0.731147  [   64/  126]
train() client id: f_00000-6-2 loss: 0.763789  [   96/  126]
train() client id: f_00000-7-0 loss: 0.639567  [   32/  126]
train() client id: f_00000-7-1 loss: 0.703615  [   64/  126]
train() client id: f_00000-7-2 loss: 0.792410  [   96/  126]
train() client id: f_00000-8-0 loss: 0.870580  [   32/  126]
train() client id: f_00000-8-1 loss: 0.780496  [   64/  126]
train() client id: f_00000-8-2 loss: 0.635450  [   96/  126]
train() client id: f_00000-9-0 loss: 0.704255  [   32/  126]
train() client id: f_00000-9-1 loss: 0.864902  [   64/  126]
train() client id: f_00000-9-2 loss: 0.748834  [   96/  126]
train() client id: f_00000-10-0 loss: 0.584243  [   32/  126]
train() client id: f_00000-10-1 loss: 0.828303  [   64/  126]
train() client id: f_00000-10-2 loss: 0.915829  [   96/  126]
train() client id: f_00000-11-0 loss: 0.800313  [   32/  126]
train() client id: f_00000-11-1 loss: 0.829958  [   64/  126]
train() client id: f_00000-11-2 loss: 0.865855  [   96/  126]
train() client id: f_00000-12-0 loss: 0.856025  [   32/  126]
train() client id: f_00000-12-1 loss: 0.683414  [   64/  126]
train() client id: f_00000-12-2 loss: 0.798042  [   96/  126]
train() client id: f_00001-0-0 loss: 0.483893  [   32/  265]
train() client id: f_00001-0-1 loss: 0.373616  [   64/  265]
train() client id: f_00001-0-2 loss: 0.500827  [   96/  265]
train() client id: f_00001-0-3 loss: 0.785492  [  128/  265]
train() client id: f_00001-0-4 loss: 0.448410  [  160/  265]
train() client id: f_00001-0-5 loss: 0.405969  [  192/  265]
train() client id: f_00001-0-6 loss: 0.467794  [  224/  265]
train() client id: f_00001-0-7 loss: 0.441285  [  256/  265]
train() client id: f_00001-1-0 loss: 0.556613  [   32/  265]
train() client id: f_00001-1-1 loss: 0.511408  [   64/  265]
train() client id: f_00001-1-2 loss: 0.492613  [   96/  265]
train() client id: f_00001-1-3 loss: 0.539384  [  128/  265]
train() client id: f_00001-1-4 loss: 0.475917  [  160/  265]
train() client id: f_00001-1-5 loss: 0.427276  [  192/  265]
train() client id: f_00001-1-6 loss: 0.466152  [  224/  265]
train() client id: f_00001-1-7 loss: 0.394478  [  256/  265]
train() client id: f_00001-2-0 loss: 0.447458  [   32/  265]
train() client id: f_00001-2-1 loss: 0.385613  [   64/  265]
train() client id: f_00001-2-2 loss: 0.457498  [   96/  265]
train() client id: f_00001-2-3 loss: 0.453600  [  128/  265]
train() client id: f_00001-2-4 loss: 0.479984  [  160/  265]
train() client id: f_00001-2-5 loss: 0.563691  [  192/  265]
train() client id: f_00001-2-6 loss: 0.471961  [  224/  265]
train() client id: f_00001-2-7 loss: 0.514885  [  256/  265]
train() client id: f_00001-3-0 loss: 0.459940  [   32/  265]
train() client id: f_00001-3-1 loss: 0.402306  [   64/  265]
train() client id: f_00001-3-2 loss: 0.490975  [   96/  265]
train() client id: f_00001-3-3 loss: 0.477192  [  128/  265]
train() client id: f_00001-3-4 loss: 0.447698  [  160/  265]
train() client id: f_00001-3-5 loss: 0.511665  [  192/  265]
train() client id: f_00001-3-6 loss: 0.415764  [  224/  265]
train() client id: f_00001-3-7 loss: 0.579678  [  256/  265]
train() client id: f_00001-4-0 loss: 0.518858  [   32/  265]
train() client id: f_00001-4-1 loss: 0.447737  [   64/  265]
train() client id: f_00001-4-2 loss: 0.451489  [   96/  265]
train() client id: f_00001-4-3 loss: 0.512775  [  128/  265]
train() client id: f_00001-4-4 loss: 0.470989  [  160/  265]
train() client id: f_00001-4-5 loss: 0.464451  [  192/  265]
train() client id: f_00001-4-6 loss: 0.426925  [  224/  265]
train() client id: f_00001-4-7 loss: 0.439286  [  256/  265]
train() client id: f_00001-5-0 loss: 0.522033  [   32/  265]
train() client id: f_00001-5-1 loss: 0.362359  [   64/  265]
train() client id: f_00001-5-2 loss: 0.545861  [   96/  265]
train() client id: f_00001-5-3 loss: 0.483350  [  128/  265]
train() client id: f_00001-5-4 loss: 0.406179  [  160/  265]
train() client id: f_00001-5-5 loss: 0.564603  [  192/  265]
train() client id: f_00001-5-6 loss: 0.498309  [  224/  265]
train() client id: f_00001-5-7 loss: 0.371563  [  256/  265]
train() client id: f_00001-6-0 loss: 0.414469  [   32/  265]
train() client id: f_00001-6-1 loss: 0.474008  [   64/  265]
train() client id: f_00001-6-2 loss: 0.395277  [   96/  265]
train() client id: f_00001-6-3 loss: 0.447388  [  128/  265]
train() client id: f_00001-6-4 loss: 0.399757  [  160/  265]
train() client id: f_00001-6-5 loss: 0.656951  [  192/  265]
train() client id: f_00001-6-6 loss: 0.404071  [  224/  265]
train() client id: f_00001-6-7 loss: 0.563954  [  256/  265]
train() client id: f_00001-7-0 loss: 0.431315  [   32/  265]
train() client id: f_00001-7-1 loss: 0.626030  [   64/  265]
train() client id: f_00001-7-2 loss: 0.553878  [   96/  265]
train() client id: f_00001-7-3 loss: 0.424454  [  128/  265]
train() client id: f_00001-7-4 loss: 0.358512  [  160/  265]
train() client id: f_00001-7-5 loss: 0.416747  [  192/  265]
train() client id: f_00001-7-6 loss: 0.408354  [  224/  265]
train() client id: f_00001-7-7 loss: 0.529833  [  256/  265]
train() client id: f_00001-8-0 loss: 0.419900  [   32/  265]
train() client id: f_00001-8-1 loss: 0.376555  [   64/  265]
train() client id: f_00001-8-2 loss: 0.552469  [   96/  265]
train() client id: f_00001-8-3 loss: 0.456899  [  128/  265]
train() client id: f_00001-8-4 loss: 0.459066  [  160/  265]
train() client id: f_00001-8-5 loss: 0.461930  [  192/  265]
train() client id: f_00001-8-6 loss: 0.446651  [  224/  265]
train() client id: f_00001-8-7 loss: 0.572224  [  256/  265]
train() client id: f_00001-9-0 loss: 0.354792  [   32/  265]
train() client id: f_00001-9-1 loss: 0.385985  [   64/  265]
train() client id: f_00001-9-2 loss: 0.455903  [   96/  265]
train() client id: f_00001-9-3 loss: 0.485905  [  128/  265]
train() client id: f_00001-9-4 loss: 0.554231  [  160/  265]
train() client id: f_00001-9-5 loss: 0.425182  [  192/  265]
train() client id: f_00001-9-6 loss: 0.382120  [  224/  265]
train() client id: f_00001-9-7 loss: 0.498365  [  256/  265]
train() client id: f_00001-10-0 loss: 0.388596  [   32/  265]
train() client id: f_00001-10-1 loss: 0.475307  [   64/  265]
train() client id: f_00001-10-2 loss: 0.433510  [   96/  265]
train() client id: f_00001-10-3 loss: 0.613646  [  128/  265]
train() client id: f_00001-10-4 loss: 0.423752  [  160/  265]
train() client id: f_00001-10-5 loss: 0.369892  [  192/  265]
train() client id: f_00001-10-6 loss: 0.467813  [  224/  265]
train() client id: f_00001-10-7 loss: 0.575106  [  256/  265]
train() client id: f_00001-11-0 loss: 0.422059  [   32/  265]
train() client id: f_00001-11-1 loss: 0.451142  [   64/  265]
train() client id: f_00001-11-2 loss: 0.530701  [   96/  265]
train() client id: f_00001-11-3 loss: 0.588782  [  128/  265]
train() client id: f_00001-11-4 loss: 0.491186  [  160/  265]
train() client id: f_00001-11-5 loss: 0.450813  [  192/  265]
train() client id: f_00001-11-6 loss: 0.381627  [  224/  265]
train() client id: f_00001-11-7 loss: 0.373775  [  256/  265]
train() client id: f_00001-12-0 loss: 0.617665  [   32/  265]
train() client id: f_00001-12-1 loss: 0.361021  [   64/  265]
train() client id: f_00001-12-2 loss: 0.478813  [   96/  265]
train() client id: f_00001-12-3 loss: 0.360819  [  128/  265]
train() client id: f_00001-12-4 loss: 0.535152  [  160/  265]
train() client id: f_00001-12-5 loss: 0.548098  [  192/  265]
train() client id: f_00001-12-6 loss: 0.463678  [  224/  265]
train() client id: f_00001-12-7 loss: 0.396497  [  256/  265]
train() client id: f_00002-0-0 loss: 0.988175  [   32/  124]
train() client id: f_00002-0-1 loss: 1.231756  [   64/  124]
train() client id: f_00002-0-2 loss: 1.347490  [   96/  124]
train() client id: f_00002-1-0 loss: 1.053064  [   32/  124]
train() client id: f_00002-1-1 loss: 1.057751  [   64/  124]
train() client id: f_00002-1-2 loss: 1.398932  [   96/  124]
train() client id: f_00002-2-0 loss: 1.121693  [   32/  124]
train() client id: f_00002-2-1 loss: 1.154426  [   64/  124]
train() client id: f_00002-2-2 loss: 0.952299  [   96/  124]
train() client id: f_00002-3-0 loss: 1.178906  [   32/  124]
train() client id: f_00002-3-1 loss: 1.354140  [   64/  124]
train() client id: f_00002-3-2 loss: 0.947916  [   96/  124]
train() client id: f_00002-4-0 loss: 0.925977  [   32/  124]
train() client id: f_00002-4-1 loss: 1.157661  [   64/  124]
train() client id: f_00002-4-2 loss: 1.100375  [   96/  124]
train() client id: f_00002-5-0 loss: 1.056377  [   32/  124]
train() client id: f_00002-5-1 loss: 1.058779  [   64/  124]
train() client id: f_00002-5-2 loss: 0.962186  [   96/  124]
train() client id: f_00002-6-0 loss: 1.168910  [   32/  124]
train() client id: f_00002-6-1 loss: 1.104020  [   64/  124]
train() client id: f_00002-6-2 loss: 0.999687  [   96/  124]
train() client id: f_00002-7-0 loss: 1.167737  [   32/  124]
train() client id: f_00002-7-1 loss: 0.923721  [   64/  124]
train() client id: f_00002-7-2 loss: 0.794551  [   96/  124]
train() client id: f_00002-8-0 loss: 0.977833  [   32/  124]
train() client id: f_00002-8-1 loss: 1.072469  [   64/  124]
train() client id: f_00002-8-2 loss: 0.950314  [   96/  124]
train() client id: f_00002-9-0 loss: 1.107079  [   32/  124]
train() client id: f_00002-9-1 loss: 0.928806  [   64/  124]
train() client id: f_00002-9-2 loss: 0.880858  [   96/  124]
train() client id: f_00002-10-0 loss: 0.938379  [   32/  124]
train() client id: f_00002-10-1 loss: 1.061314  [   64/  124]
train() client id: f_00002-10-2 loss: 0.893987  [   96/  124]
train() client id: f_00002-11-0 loss: 1.069812  [   32/  124]
train() client id: f_00002-11-1 loss: 1.125868  [   64/  124]
train() client id: f_00002-11-2 loss: 0.803344  [   96/  124]
train() client id: f_00002-12-0 loss: 0.890401  [   32/  124]
train() client id: f_00002-12-1 loss: 0.929638  [   64/  124]
train() client id: f_00002-12-2 loss: 1.109011  [   96/  124]
train() client id: f_00003-0-0 loss: 0.798329  [   32/   43]
train() client id: f_00003-1-0 loss: 0.660728  [   32/   43]
train() client id: f_00003-2-0 loss: 0.740013  [   32/   43]
train() client id: f_00003-3-0 loss: 0.578050  [   32/   43]
train() client id: f_00003-4-0 loss: 0.788400  [   32/   43]
train() client id: f_00003-5-0 loss: 0.416154  [   32/   43]
train() client id: f_00003-6-0 loss: 0.760178  [   32/   43]
train() client id: f_00003-7-0 loss: 0.669267  [   32/   43]
train() client id: f_00003-8-0 loss: 0.640822  [   32/   43]
train() client id: f_00003-9-0 loss: 0.724693  [   32/   43]
train() client id: f_00003-10-0 loss: 0.810253  [   32/   43]
train() client id: f_00003-11-0 loss: 0.660757  [   32/   43]
train() client id: f_00003-12-0 loss: 1.010716  [   32/   43]
train() client id: f_00004-0-0 loss: 0.770667  [   32/  306]
train() client id: f_00004-0-1 loss: 0.889605  [   64/  306]
train() client id: f_00004-0-2 loss: 0.831745  [   96/  306]
train() client id: f_00004-0-3 loss: 0.845378  [  128/  306]
train() client id: f_00004-0-4 loss: 0.852253  [  160/  306]
train() client id: f_00004-0-5 loss: 0.923450  [  192/  306]
train() client id: f_00004-0-6 loss: 0.811364  [  224/  306]
train() client id: f_00004-0-7 loss: 0.633912  [  256/  306]
train() client id: f_00004-0-8 loss: 0.832696  [  288/  306]
train() client id: f_00004-1-0 loss: 0.872971  [   32/  306]
train() client id: f_00004-1-1 loss: 0.776379  [   64/  306]
train() client id: f_00004-1-2 loss: 0.922525  [   96/  306]
train() client id: f_00004-1-3 loss: 0.902548  [  128/  306]
train() client id: f_00004-1-4 loss: 0.681431  [  160/  306]
train() client id: f_00004-1-5 loss: 0.864775  [  192/  306]
train() client id: f_00004-1-6 loss: 0.807229  [  224/  306]
train() client id: f_00004-1-7 loss: 0.919211  [  256/  306]
train() client id: f_00004-1-8 loss: 0.829046  [  288/  306]
train() client id: f_00004-2-0 loss: 0.687459  [   32/  306]
train() client id: f_00004-2-1 loss: 0.832127  [   64/  306]
train() client id: f_00004-2-2 loss: 0.854935  [   96/  306]
train() client id: f_00004-2-3 loss: 0.898484  [  128/  306]
train() client id: f_00004-2-4 loss: 0.718018  [  160/  306]
train() client id: f_00004-2-5 loss: 0.841173  [  192/  306]
train() client id: f_00004-2-6 loss: 0.849564  [  224/  306]
train() client id: f_00004-2-7 loss: 0.831430  [  256/  306]
train() client id: f_00004-2-8 loss: 0.955951  [  288/  306]
train() client id: f_00004-3-0 loss: 0.850320  [   32/  306]
train() client id: f_00004-3-1 loss: 0.925441  [   64/  306]
train() client id: f_00004-3-2 loss: 0.852429  [   96/  306]
train() client id: f_00004-3-3 loss: 0.905494  [  128/  306]
train() client id: f_00004-3-4 loss: 0.846195  [  160/  306]
train() client id: f_00004-3-5 loss: 0.806752  [  192/  306]
train() client id: f_00004-3-6 loss: 0.821752  [  224/  306]
train() client id: f_00004-3-7 loss: 0.728906  [  256/  306]
train() client id: f_00004-3-8 loss: 0.767125  [  288/  306]
train() client id: f_00004-4-0 loss: 0.836960  [   32/  306]
train() client id: f_00004-4-1 loss: 0.817033  [   64/  306]
train() client id: f_00004-4-2 loss: 0.840189  [   96/  306]
train() client id: f_00004-4-3 loss: 0.826613  [  128/  306]
train() client id: f_00004-4-4 loss: 0.759132  [  160/  306]
train() client id: f_00004-4-5 loss: 0.784160  [  192/  306]
train() client id: f_00004-4-6 loss: 0.931109  [  224/  306]
train() client id: f_00004-4-7 loss: 0.794766  [  256/  306]
train() client id: f_00004-4-8 loss: 0.835204  [  288/  306]
train() client id: f_00004-5-0 loss: 0.643676  [   32/  306]
train() client id: f_00004-5-1 loss: 0.942845  [   64/  306]
train() client id: f_00004-5-2 loss: 0.939444  [   96/  306]
train() client id: f_00004-5-3 loss: 0.895618  [  128/  306]
train() client id: f_00004-5-4 loss: 0.797544  [  160/  306]
train() client id: f_00004-5-5 loss: 0.834904  [  192/  306]
train() client id: f_00004-5-6 loss: 0.777562  [  224/  306]
train() client id: f_00004-5-7 loss: 0.814450  [  256/  306]
train() client id: f_00004-5-8 loss: 0.822477  [  288/  306]
train() client id: f_00004-6-0 loss: 0.853540  [   32/  306]
train() client id: f_00004-6-1 loss: 0.858336  [   64/  306]
train() client id: f_00004-6-2 loss: 0.874435  [   96/  306]
train() client id: f_00004-6-3 loss: 0.790388  [  128/  306]
train() client id: f_00004-6-4 loss: 0.728356  [  160/  306]
train() client id: f_00004-6-5 loss: 0.915749  [  192/  306]
train() client id: f_00004-6-6 loss: 0.689215  [  224/  306]
train() client id: f_00004-6-7 loss: 0.750117  [  256/  306]
train() client id: f_00004-6-8 loss: 0.879550  [  288/  306]
train() client id: f_00004-7-0 loss: 0.904330  [   32/  306]
train() client id: f_00004-7-1 loss: 0.841423  [   64/  306]
train() client id: f_00004-7-2 loss: 0.741395  [   96/  306]
train() client id: f_00004-7-3 loss: 0.806780  [  128/  306]
train() client id: f_00004-7-4 loss: 0.857754  [  160/  306]
train() client id: f_00004-7-5 loss: 0.793265  [  192/  306]
train() client id: f_00004-7-6 loss: 0.853854  [  224/  306]
train() client id: f_00004-7-7 loss: 0.780093  [  256/  306]
train() client id: f_00004-7-8 loss: 0.764861  [  288/  306]
train() client id: f_00004-8-0 loss: 0.715865  [   32/  306]
train() client id: f_00004-8-1 loss: 0.900927  [   64/  306]
train() client id: f_00004-8-2 loss: 0.972993  [   96/  306]
train() client id: f_00004-8-3 loss: 0.705072  [  128/  306]
train() client id: f_00004-8-4 loss: 0.744403  [  160/  306]
train() client id: f_00004-8-5 loss: 0.826687  [  192/  306]
train() client id: f_00004-8-6 loss: 0.817103  [  224/  306]
train() client id: f_00004-8-7 loss: 0.754857  [  256/  306]
train() client id: f_00004-8-8 loss: 0.756554  [  288/  306]
train() client id: f_00004-9-0 loss: 0.724026  [   32/  306]
train() client id: f_00004-9-1 loss: 0.762905  [   64/  306]
train() client id: f_00004-9-2 loss: 0.786446  [   96/  306]
train() client id: f_00004-9-3 loss: 0.761434  [  128/  306]
train() client id: f_00004-9-4 loss: 0.925341  [  160/  306]
train() client id: f_00004-9-5 loss: 0.768833  [  192/  306]
train() client id: f_00004-9-6 loss: 0.799590  [  224/  306]
train() client id: f_00004-9-7 loss: 0.912690  [  256/  306]
train() client id: f_00004-9-8 loss: 0.738073  [  288/  306]
train() client id: f_00004-10-0 loss: 0.758518  [   32/  306]
train() client id: f_00004-10-1 loss: 0.821123  [   64/  306]
train() client id: f_00004-10-2 loss: 0.786350  [   96/  306]
train() client id: f_00004-10-3 loss: 0.777450  [  128/  306]
train() client id: f_00004-10-4 loss: 0.825667  [  160/  306]
train() client id: f_00004-10-5 loss: 0.952032  [  192/  306]
train() client id: f_00004-10-6 loss: 0.940156  [  224/  306]
train() client id: f_00004-10-7 loss: 0.822491  [  256/  306]
train() client id: f_00004-10-8 loss: 0.685183  [  288/  306]
train() client id: f_00004-11-0 loss: 0.872869  [   32/  306]
train() client id: f_00004-11-1 loss: 0.896450  [   64/  306]
train() client id: f_00004-11-2 loss: 0.821341  [   96/  306]
train() client id: f_00004-11-3 loss: 0.794846  [  128/  306]
train() client id: f_00004-11-4 loss: 0.763370  [  160/  306]
train() client id: f_00004-11-5 loss: 0.853288  [  192/  306]
train() client id: f_00004-11-6 loss: 0.745310  [  224/  306]
train() client id: f_00004-11-7 loss: 0.738111  [  256/  306]
train() client id: f_00004-11-8 loss: 0.851557  [  288/  306]
train() client id: f_00004-12-0 loss: 0.824441  [   32/  306]
train() client id: f_00004-12-1 loss: 0.864492  [   64/  306]
train() client id: f_00004-12-2 loss: 0.796082  [   96/  306]
train() client id: f_00004-12-3 loss: 0.764516  [  128/  306]
train() client id: f_00004-12-4 loss: 0.787964  [  160/  306]
train() client id: f_00004-12-5 loss: 0.823956  [  192/  306]
train() client id: f_00004-12-6 loss: 0.855098  [  224/  306]
train() client id: f_00004-12-7 loss: 0.925650  [  256/  306]
train() client id: f_00004-12-8 loss: 0.658781  [  288/  306]
train() client id: f_00005-0-0 loss: 0.455063  [   32/  146]
train() client id: f_00005-0-1 loss: 0.075956  [   64/  146]
train() client id: f_00005-0-2 loss: 0.448125  [   96/  146]
train() client id: f_00005-0-3 loss: 0.491124  [  128/  146]
train() client id: f_00005-1-0 loss: 0.614561  [   32/  146]
train() client id: f_00005-1-1 loss: 0.443349  [   64/  146]
train() client id: f_00005-1-2 loss: 0.352692  [   96/  146]
train() client id: f_00005-1-3 loss: 0.303721  [  128/  146]
train() client id: f_00005-2-0 loss: 0.181651  [   32/  146]
train() client id: f_00005-2-1 loss: 0.285114  [   64/  146]
train() client id: f_00005-2-2 loss: 0.264603  [   96/  146]
train() client id: f_00005-2-3 loss: 0.845832  [  128/  146]
train() client id: f_00005-3-0 loss: 0.200510  [   32/  146]
train() client id: f_00005-3-1 loss: 0.302857  [   64/  146]
train() client id: f_00005-3-2 loss: 0.414647  [   96/  146]
train() client id: f_00005-3-3 loss: 0.545716  [  128/  146]
train() client id: f_00005-4-0 loss: 0.580135  [   32/  146]
train() client id: f_00005-4-1 loss: 0.283898  [   64/  146]
train() client id: f_00005-4-2 loss: 0.600111  [   96/  146]
train() client id: f_00005-4-3 loss: 0.197143  [  128/  146]
train() client id: f_00005-5-0 loss: 0.480004  [   32/  146]
train() client id: f_00005-5-1 loss: 0.493917  [   64/  146]
train() client id: f_00005-5-2 loss: 0.322960  [   96/  146]
train() client id: f_00005-5-3 loss: 0.310299  [  128/  146]
train() client id: f_00005-6-0 loss: 0.375090  [   32/  146]
train() client id: f_00005-6-1 loss: 0.439833  [   64/  146]
train() client id: f_00005-6-2 loss: 0.216380  [   96/  146]
train() client id: f_00005-6-3 loss: 0.333769  [  128/  146]
train() client id: f_00005-7-0 loss: 0.910326  [   32/  146]
train() client id: f_00005-7-1 loss: -0.018616  [   64/  146]
train() client id: f_00005-7-2 loss: 0.525075  [   96/  146]
train() client id: f_00005-7-3 loss: 0.131601  [  128/  146]
train() client id: f_00005-8-0 loss: 0.466622  [   32/  146]
train() client id: f_00005-8-1 loss: 0.226534  [   64/  146]
train() client id: f_00005-8-2 loss: 0.454449  [   96/  146]
train() client id: f_00005-8-3 loss: 0.434812  [  128/  146]
train() client id: f_00005-9-0 loss: 0.405557  [   32/  146]
train() client id: f_00005-9-1 loss: 0.392190  [   64/  146]
train() client id: f_00005-9-2 loss: 0.316347  [   96/  146]
train() client id: f_00005-9-3 loss: 0.504460  [  128/  146]
train() client id: f_00005-10-0 loss: 0.366439  [   32/  146]
train() client id: f_00005-10-1 loss: 0.475713  [   64/  146]
train() client id: f_00005-10-2 loss: 0.403975  [   96/  146]
train() client id: f_00005-10-3 loss: 0.145487  [  128/  146]
train() client id: f_00005-11-0 loss: 0.446177  [   32/  146]
train() client id: f_00005-11-1 loss: 0.581867  [   64/  146]
train() client id: f_00005-11-2 loss: 0.467391  [   96/  146]
train() client id: f_00005-11-3 loss: 0.125950  [  128/  146]
train() client id: f_00005-12-0 loss: 0.373025  [   32/  146]
train() client id: f_00005-12-1 loss: 0.407300  [   64/  146]
train() client id: f_00005-12-2 loss: 0.492348  [   96/  146]
train() client id: f_00005-12-3 loss: 0.173148  [  128/  146]
train() client id: f_00006-0-0 loss: 0.501166  [   32/   54]
train() client id: f_00006-1-0 loss: 0.431664  [   32/   54]
train() client id: f_00006-2-0 loss: 0.394091  [   32/   54]
train() client id: f_00006-3-0 loss: 0.397171  [   32/   54]
train() client id: f_00006-4-0 loss: 0.481342  [   32/   54]
train() client id: f_00006-5-0 loss: 0.444219  [   32/   54]
train() client id: f_00006-6-0 loss: 0.443662  [   32/   54]
train() client id: f_00006-7-0 loss: 0.480088  [   32/   54]
train() client id: f_00006-8-0 loss: 0.408343  [   32/   54]
train() client id: f_00006-9-0 loss: 0.490034  [   32/   54]
train() client id: f_00006-10-0 loss: 0.440691  [   32/   54]
train() client id: f_00006-11-0 loss: 0.439258  [   32/   54]
train() client id: f_00006-12-0 loss: 0.361775  [   32/   54]
train() client id: f_00007-0-0 loss: 0.726362  [   32/  179]
train() client id: f_00007-0-1 loss: 0.775951  [   64/  179]
train() client id: f_00007-0-2 loss: 0.638701  [   96/  179]
train() client id: f_00007-0-3 loss: 0.609089  [  128/  179]
train() client id: f_00007-0-4 loss: 0.629479  [  160/  179]
train() client id: f_00007-1-0 loss: 0.468183  [   32/  179]
train() client id: f_00007-1-1 loss: 0.628881  [   64/  179]
train() client id: f_00007-1-2 loss: 0.700669  [   96/  179]
train() client id: f_00007-1-3 loss: 0.662272  [  128/  179]
train() client id: f_00007-1-4 loss: 0.727260  [  160/  179]
train() client id: f_00007-2-0 loss: 0.501317  [   32/  179]
train() client id: f_00007-2-1 loss: 0.530039  [   64/  179]
train() client id: f_00007-2-2 loss: 0.565530  [   96/  179]
train() client id: f_00007-2-3 loss: 0.866501  [  128/  179]
train() client id: f_00007-2-4 loss: 0.767907  [  160/  179]
train() client id: f_00007-3-0 loss: 0.734620  [   32/  179]
train() client id: f_00007-3-1 loss: 0.422835  [   64/  179]
train() client id: f_00007-3-2 loss: 0.549562  [   96/  179]
train() client id: f_00007-3-3 loss: 0.770915  [  128/  179]
train() client id: f_00007-3-4 loss: 0.530520  [  160/  179]
train() client id: f_00007-4-0 loss: 0.561929  [   32/  179]
train() client id: f_00007-4-1 loss: 0.592168  [   64/  179]
train() client id: f_00007-4-2 loss: 0.740576  [   96/  179]
train() client id: f_00007-4-3 loss: 0.819632  [  128/  179]
train() client id: f_00007-4-4 loss: 0.442448  [  160/  179]
train() client id: f_00007-5-0 loss: 0.505285  [   32/  179]
train() client id: f_00007-5-1 loss: 0.620356  [   64/  179]
train() client id: f_00007-5-2 loss: 0.500434  [   96/  179]
train() client id: f_00007-5-3 loss: 0.599718  [  128/  179]
train() client id: f_00007-5-4 loss: 0.586648  [  160/  179]
train() client id: f_00007-6-0 loss: 0.644423  [   32/  179]
train() client id: f_00007-6-1 loss: 0.559329  [   64/  179]
train() client id: f_00007-6-2 loss: 0.544003  [   96/  179]
train() client id: f_00007-6-3 loss: 0.645287  [  128/  179]
train() client id: f_00007-6-4 loss: 0.558539  [  160/  179]
train() client id: f_00007-7-0 loss: 0.832950  [   32/  179]
train() client id: f_00007-7-1 loss: 0.643562  [   64/  179]
train() client id: f_00007-7-2 loss: 0.412861  [   96/  179]
train() client id: f_00007-7-3 loss: 0.600649  [  128/  179]
train() client id: f_00007-7-4 loss: 0.518011  [  160/  179]
train() client id: f_00007-8-0 loss: 0.594439  [   32/  179]
train() client id: f_00007-8-1 loss: 0.796446  [   64/  179]
train() client id: f_00007-8-2 loss: 0.499488  [   96/  179]
train() client id: f_00007-8-3 loss: 0.651803  [  128/  179]
train() client id: f_00007-8-4 loss: 0.529834  [  160/  179]
train() client id: f_00007-9-0 loss: 0.552010  [   32/  179]
train() client id: f_00007-9-1 loss: 0.665275  [   64/  179]
train() client id: f_00007-9-2 loss: 0.519380  [   96/  179]
train() client id: f_00007-9-3 loss: 0.411214  [  128/  179]
train() client id: f_00007-9-4 loss: 0.820122  [  160/  179]
train() client id: f_00007-10-0 loss: 0.564364  [   32/  179]
train() client id: f_00007-10-1 loss: 0.800863  [   64/  179]
train() client id: f_00007-10-2 loss: 0.422113  [   96/  179]
train() client id: f_00007-10-3 loss: 0.645047  [  128/  179]
train() client id: f_00007-10-4 loss: 0.553825  [  160/  179]
train() client id: f_00007-11-0 loss: 0.537779  [   32/  179]
train() client id: f_00007-11-1 loss: 0.421428  [   64/  179]
train() client id: f_00007-11-2 loss: 0.677770  [   96/  179]
train() client id: f_00007-11-3 loss: 0.647997  [  128/  179]
train() client id: f_00007-11-4 loss: 0.685338  [  160/  179]
train() client id: f_00007-12-0 loss: 0.551859  [   32/  179]
train() client id: f_00007-12-1 loss: 0.695518  [   64/  179]
train() client id: f_00007-12-2 loss: 0.606134  [   96/  179]
train() client id: f_00007-12-3 loss: 0.657374  [  128/  179]
train() client id: f_00007-12-4 loss: 0.441005  [  160/  179]
train() client id: f_00008-0-0 loss: 0.731168  [   32/  130]
train() client id: f_00008-0-1 loss: 0.756371  [   64/  130]
train() client id: f_00008-0-2 loss: 0.614694  [   96/  130]
train() client id: f_00008-0-3 loss: 0.678123  [  128/  130]
train() client id: f_00008-1-0 loss: 0.590703  [   32/  130]
train() client id: f_00008-1-1 loss: 0.700009  [   64/  130]
train() client id: f_00008-1-2 loss: 0.825462  [   96/  130]
train() client id: f_00008-1-3 loss: 0.689786  [  128/  130]
train() client id: f_00008-2-0 loss: 0.705394  [   32/  130]
train() client id: f_00008-2-1 loss: 0.644486  [   64/  130]
train() client id: f_00008-2-2 loss: 0.684754  [   96/  130]
train() client id: f_00008-2-3 loss: 0.783505  [  128/  130]
train() client id: f_00008-3-0 loss: 0.824359  [   32/  130]
train() client id: f_00008-3-1 loss: 0.684497  [   64/  130]
train() client id: f_00008-3-2 loss: 0.644385  [   96/  130]
train() client id: f_00008-3-3 loss: 0.668412  [  128/  130]
train() client id: f_00008-4-0 loss: 0.785781  [   32/  130]
train() client id: f_00008-4-1 loss: 0.650408  [   64/  130]
train() client id: f_00008-4-2 loss: 0.677690  [   96/  130]
train() client id: f_00008-4-3 loss: 0.700611  [  128/  130]
train() client id: f_00008-5-0 loss: 0.650439  [   32/  130]
train() client id: f_00008-5-1 loss: 0.698525  [   64/  130]
train() client id: f_00008-5-2 loss: 0.622600  [   96/  130]
train() client id: f_00008-5-3 loss: 0.797686  [  128/  130]
train() client id: f_00008-6-0 loss: 0.796085  [   32/  130]
train() client id: f_00008-6-1 loss: 0.607745  [   64/  130]
train() client id: f_00008-6-2 loss: 0.744419  [   96/  130]
train() client id: f_00008-6-3 loss: 0.672009  [  128/  130]
train() client id: f_00008-7-0 loss: 0.594060  [   32/  130]
train() client id: f_00008-7-1 loss: 0.770529  [   64/  130]
train() client id: f_00008-7-2 loss: 0.659640  [   96/  130]
train() client id: f_00008-7-3 loss: 0.801274  [  128/  130]
train() client id: f_00008-8-0 loss: 0.862329  [   32/  130]
train() client id: f_00008-8-1 loss: 0.611363  [   64/  130]
train() client id: f_00008-8-2 loss: 0.642712  [   96/  130]
train() client id: f_00008-8-3 loss: 0.710187  [  128/  130]
train() client id: f_00008-9-0 loss: 0.657874  [   32/  130]
train() client id: f_00008-9-1 loss: 0.598218  [   64/  130]
train() client id: f_00008-9-2 loss: 0.842465  [   96/  130]
train() client id: f_00008-9-3 loss: 0.708193  [  128/  130]
train() client id: f_00008-10-0 loss: 0.753699  [   32/  130]
train() client id: f_00008-10-1 loss: 0.703272  [   64/  130]
train() client id: f_00008-10-2 loss: 0.603679  [   96/  130]
train() client id: f_00008-10-3 loss: 0.766531  [  128/  130]
train() client id: f_00008-11-0 loss: 0.640434  [   32/  130]
train() client id: f_00008-11-1 loss: 0.709677  [   64/  130]
train() client id: f_00008-11-2 loss: 0.636812  [   96/  130]
train() client id: f_00008-11-3 loss: 0.835404  [  128/  130]
train() client id: f_00008-12-0 loss: 0.783877  [   32/  130]
train() client id: f_00008-12-1 loss: 0.689543  [   64/  130]
train() client id: f_00008-12-2 loss: 0.654016  [   96/  130]
train() client id: f_00008-12-3 loss: 0.703875  [  128/  130]
train() client id: f_00009-0-0 loss: 1.088262  [   32/  118]
train() client id: f_00009-0-1 loss: 1.044614  [   64/  118]
train() client id: f_00009-0-2 loss: 1.057917  [   96/  118]
train() client id: f_00009-1-0 loss: 1.023555  [   32/  118]
train() client id: f_00009-1-1 loss: 0.969581  [   64/  118]
train() client id: f_00009-1-2 loss: 1.173920  [   96/  118]
train() client id: f_00009-2-0 loss: 1.015445  [   32/  118]
train() client id: f_00009-2-1 loss: 0.982539  [   64/  118]
train() client id: f_00009-2-2 loss: 0.817640  [   96/  118]
train() client id: f_00009-3-0 loss: 0.835734  [   32/  118]
train() client id: f_00009-3-1 loss: 1.005623  [   64/  118]
train() client id: f_00009-3-2 loss: 0.838372  [   96/  118]
train() client id: f_00009-4-0 loss: 0.861081  [   32/  118]
train() client id: f_00009-4-1 loss: 0.877741  [   64/  118]
train() client id: f_00009-4-2 loss: 0.832998  [   96/  118]
train() client id: f_00009-5-0 loss: 0.880845  [   32/  118]
train() client id: f_00009-5-1 loss: 0.818505  [   64/  118]
train() client id: f_00009-5-2 loss: 0.870282  [   96/  118]
train() client id: f_00009-6-0 loss: 0.851599  [   32/  118]
train() client id: f_00009-6-1 loss: 0.865933  [   64/  118]
train() client id: f_00009-6-2 loss: 0.866100  [   96/  118]
train() client id: f_00009-7-0 loss: 0.763544  [   32/  118]
train() client id: f_00009-7-1 loss: 0.796614  [   64/  118]
train() client id: f_00009-7-2 loss: 1.011842  [   96/  118]
train() client id: f_00009-8-0 loss: 0.708899  [   32/  118]
train() client id: f_00009-8-1 loss: 0.907703  [   64/  118]
train() client id: f_00009-8-2 loss: 0.841502  [   96/  118]
train() client id: f_00009-9-0 loss: 0.863998  [   32/  118]
train() client id: f_00009-9-1 loss: 0.808274  [   64/  118]
train() client id: f_00009-9-2 loss: 0.884007  [   96/  118]
train() client id: f_00009-10-0 loss: 0.796564  [   32/  118]
train() client id: f_00009-10-1 loss: 0.814867  [   64/  118]
train() client id: f_00009-10-2 loss: 0.844284  [   96/  118]
train() client id: f_00009-11-0 loss: 0.701179  [   32/  118]
train() client id: f_00009-11-1 loss: 1.020691  [   64/  118]
train() client id: f_00009-11-2 loss: 0.722633  [   96/  118]
train() client id: f_00009-12-0 loss: 0.824370  [   32/  118]
train() client id: f_00009-12-1 loss: 0.767940  [   64/  118]
train() client id: f_00009-12-2 loss: 0.855122  [   96/  118]
At round 73 accuracy: 0.636604774535809
At round 73 training accuracy: 0.5848423876592891
At round 73 training loss: 0.833073570971891
gradient difference: 0.49086079001426697
train() client id: f_00000-0-0 loss: 1.035399  [   32/  126]
train() client id: f_00000-0-1 loss: 1.154116  [   64/  126]
train() client id: f_00000-0-2 loss: 1.278704  [   96/  126]
train() client id: f_00000-1-0 loss: 1.124505  [   32/  126]
train() client id: f_00000-1-1 loss: 1.136803  [   64/  126]
train() client id: f_00000-1-2 loss: 0.956529  [   96/  126]
train() client id: f_00000-2-0 loss: 0.958034  [   32/  126]
train() client id: f_00000-2-1 loss: 1.107296  [   64/  126]
train() client id: f_00000-2-2 loss: 0.948790  [   96/  126]
train() client id: f_00000-3-0 loss: 0.985908  [   32/  126]
train() client id: f_00000-3-1 loss: 0.914682  [   64/  126]
train() client id: f_00000-3-2 loss: 0.897759  [   96/  126]
train() client id: f_00000-4-0 loss: 0.869948  [   32/  126]
train() client id: f_00000-4-1 loss: 0.839277  [   64/  126]
train() client id: f_00000-4-2 loss: 0.926975  [   96/  126]
train() client id: f_00000-5-0 loss: 0.945980  [   32/  126]
train() client id: f_00000-5-1 loss: 0.781658  [   64/  126]
train() client id: f_00000-5-2 loss: 0.756742  [   96/  126]
train() client id: f_00000-6-0 loss: 0.867974  [   32/  126]
train() client id: f_00000-6-1 loss: 0.811767  [   64/  126]
train() client id: f_00000-6-2 loss: 0.838664  [   96/  126]
train() client id: f_00000-7-0 loss: 0.868468  [   32/  126]
train() client id: f_00000-7-1 loss: 0.743005  [   64/  126]
train() client id: f_00000-7-2 loss: 0.905454  [   96/  126]
train() client id: f_00000-8-0 loss: 0.966204  [   32/  126]
train() client id: f_00000-8-1 loss: 0.607114  [   64/  126]
train() client id: f_00000-8-2 loss: 0.938079  [   96/  126]
train() client id: f_00000-9-0 loss: 0.777195  [   32/  126]
train() client id: f_00000-9-1 loss: 0.831977  [   64/  126]
train() client id: f_00000-9-2 loss: 0.850226  [   96/  126]
train() client id: f_00000-10-0 loss: 0.899488  [   32/  126]
train() client id: f_00000-10-1 loss: 0.773335  [   64/  126]
train() client id: f_00000-10-2 loss: 0.864169  [   96/  126]
train() client id: f_00000-11-0 loss: 0.754426  [   32/  126]
train() client id: f_00000-11-1 loss: 0.838634  [   64/  126]
train() client id: f_00000-11-2 loss: 0.942589  [   96/  126]
train() client id: f_00000-12-0 loss: 0.735447  [   32/  126]
train() client id: f_00000-12-1 loss: 0.760527  [   64/  126]
train() client id: f_00000-12-2 loss: 0.933119  [   96/  126]
train() client id: f_00001-0-0 loss: 0.465117  [   32/  265]
train() client id: f_00001-0-1 loss: 0.621743  [   64/  265]
train() client id: f_00001-0-2 loss: 0.593074  [   96/  265]
train() client id: f_00001-0-3 loss: 0.441847  [  128/  265]
train() client id: f_00001-0-4 loss: 0.509491  [  160/  265]
train() client id: f_00001-0-5 loss: 0.577076  [  192/  265]
train() client id: f_00001-0-6 loss: 0.440860  [  224/  265]
train() client id: f_00001-0-7 loss: 0.421561  [  256/  265]
train() client id: f_00001-1-0 loss: 0.467646  [   32/  265]
train() client id: f_00001-1-1 loss: 0.525765  [   64/  265]
train() client id: f_00001-1-2 loss: 0.479954  [   96/  265]
train() client id: f_00001-1-3 loss: 0.581828  [  128/  265]
train() client id: f_00001-1-4 loss: 0.505714  [  160/  265]
train() client id: f_00001-1-5 loss: 0.462030  [  192/  265]
train() client id: f_00001-1-6 loss: 0.489228  [  224/  265]
train() client id: f_00001-1-7 loss: 0.492242  [  256/  265]
train() client id: f_00001-2-0 loss: 0.409639  [   32/  265]
train() client id: f_00001-2-1 loss: 0.571213  [   64/  265]
train() client id: f_00001-2-2 loss: 0.560518  [   96/  265]
train() client id: f_00001-2-3 loss: 0.401507  [  128/  265]
train() client id: f_00001-2-4 loss: 0.434670  [  160/  265]
train() client id: f_00001-2-5 loss: 0.575252  [  192/  265]
train() client id: f_00001-2-6 loss: 0.410735  [  224/  265]
train() client id: f_00001-2-7 loss: 0.603887  [  256/  265]
train() client id: f_00001-3-0 loss: 0.482631  [   32/  265]
train() client id: f_00001-3-1 loss: 0.427461  [   64/  265]
train() client id: f_00001-3-2 loss: 0.629545  [   96/  265]
train() client id: f_00001-3-3 loss: 0.472059  [  128/  265]
train() client id: f_00001-3-4 loss: 0.429394  [  160/  265]
train() client id: f_00001-3-5 loss: 0.399496  [  192/  265]
train() client id: f_00001-3-6 loss: 0.664338  [  224/  265]
train() client id: f_00001-3-7 loss: 0.436333  [  256/  265]
train() client id: f_00001-4-0 loss: 0.510655  [   32/  265]
train() client id: f_00001-4-1 loss: 0.418223  [   64/  265]
train() client id: f_00001-4-2 loss: 0.460184  [   96/  265]
train() client id: f_00001-4-3 loss: 0.704001  [  128/  265]
train() client id: f_00001-4-4 loss: 0.422072  [  160/  265]
train() client id: f_00001-4-5 loss: 0.407471  [  192/  265]
train() client id: f_00001-4-6 loss: 0.484626  [  224/  265]
train() client id: f_00001-4-7 loss: 0.381558  [  256/  265]
train() client id: f_00001-5-0 loss: 0.400060  [   32/  265]
train() client id: f_00001-5-1 loss: 0.468535  [   64/  265]
train() client id: f_00001-5-2 loss: 0.538482  [   96/  265]
train() client id: f_00001-5-3 loss: 0.495602  [  128/  265]
train() client id: f_00001-5-4 loss: 0.430484  [  160/  265]
train() client id: f_00001-5-5 loss: 0.440895  [  192/  265]
train() client id: f_00001-5-6 loss: 0.495213  [  224/  265]
train() client id: f_00001-5-7 loss: 0.609913  [  256/  265]
train() client id: f_00001-6-0 loss: 0.473949  [   32/  265]
train() client id: f_00001-6-1 loss: 0.542483  [   64/  265]
train() client id: f_00001-6-2 loss: 0.446342  [   96/  265]
train() client id: f_00001-6-3 loss: 0.487194  [  128/  265]
train() client id: f_00001-6-4 loss: 0.499512  [  160/  265]
train() client id: f_00001-6-5 loss: 0.496178  [  192/  265]
train() client id: f_00001-6-6 loss: 0.484852  [  224/  265]
train() client id: f_00001-6-7 loss: 0.469003  [  256/  265]
train() client id: f_00001-7-0 loss: 0.532785  [   32/  265]
train() client id: f_00001-7-1 loss: 0.445804  [   64/  265]
train() client id: f_00001-7-2 loss: 0.455520  [   96/  265]
train() client id: f_00001-7-3 loss: 0.502240  [  128/  265]
train() client id: f_00001-7-4 loss: 0.594832  [  160/  265]
train() client id: f_00001-7-5 loss: 0.474507  [  192/  265]
train() client id: f_00001-7-6 loss: 0.405837  [  224/  265]
train() client id: f_00001-7-7 loss: 0.384652  [  256/  265]
train() client id: f_00001-8-0 loss: 0.442135  [   32/  265]
train() client id: f_00001-8-1 loss: 0.424958  [   64/  265]
train() client id: f_00001-8-2 loss: 0.490412  [   96/  265]
train() client id: f_00001-8-3 loss: 0.539096  [  128/  265]
train() client id: f_00001-8-4 loss: 0.388604  [  160/  265]
train() client id: f_00001-8-5 loss: 0.454455  [  192/  265]
train() client id: f_00001-8-6 loss: 0.498917  [  224/  265]
train() client id: f_00001-8-7 loss: 0.541141  [  256/  265]
train() client id: f_00001-9-0 loss: 0.590760  [   32/  265]
train() client id: f_00001-9-1 loss: 0.483029  [   64/  265]
train() client id: f_00001-9-2 loss: 0.480742  [   96/  265]
train() client id: f_00001-9-3 loss: 0.554305  [  128/  265]
train() client id: f_00001-9-4 loss: 0.493626  [  160/  265]
train() client id: f_00001-9-5 loss: 0.378727  [  192/  265]
train() client id: f_00001-9-6 loss: 0.457514  [  224/  265]
train() client id: f_00001-9-7 loss: 0.419102  [  256/  265]
train() client id: f_00001-10-0 loss: 0.431068  [   32/  265]
train() client id: f_00001-10-1 loss: 0.481062  [   64/  265]
train() client id: f_00001-10-2 loss: 0.364790  [   96/  265]
train() client id: f_00001-10-3 loss: 0.456813  [  128/  265]
train() client id: f_00001-10-4 loss: 0.470436  [  160/  265]
train() client id: f_00001-10-5 loss: 0.607385  [  192/  265]
train() client id: f_00001-10-6 loss: 0.561779  [  224/  265]
train() client id: f_00001-10-7 loss: 0.402680  [  256/  265]
train() client id: f_00001-11-0 loss: 0.621406  [   32/  265]
train() client id: f_00001-11-1 loss: 0.465752  [   64/  265]
train() client id: f_00001-11-2 loss: 0.449044  [   96/  265]
train() client id: f_00001-11-3 loss: 0.432313  [  128/  265]
train() client id: f_00001-11-4 loss: 0.587176  [  160/  265]
train() client id: f_00001-11-5 loss: 0.405912  [  192/  265]
train() client id: f_00001-11-6 loss: 0.406628  [  224/  265]
train() client id: f_00001-11-7 loss: 0.506392  [  256/  265]
train() client id: f_00001-12-0 loss: 0.500819  [   32/  265]
train() client id: f_00001-12-1 loss: 0.528955  [   64/  265]
train() client id: f_00001-12-2 loss: 0.499625  [   96/  265]
train() client id: f_00001-12-3 loss: 0.463794  [  128/  265]
train() client id: f_00001-12-4 loss: 0.489458  [  160/  265]
train() client id: f_00001-12-5 loss: 0.382186  [  192/  265]
train() client id: f_00001-12-6 loss: 0.579398  [  224/  265]
train() client id: f_00001-12-7 loss: 0.430420  [  256/  265]
train() client id: f_00002-0-0 loss: 0.978843  [   32/  124]
train() client id: f_00002-0-1 loss: 1.028161  [   64/  124]
train() client id: f_00002-0-2 loss: 1.056959  [   96/  124]
train() client id: f_00002-1-0 loss: 1.019030  [   32/  124]
train() client id: f_00002-1-1 loss: 0.873007  [   64/  124]
train() client id: f_00002-1-2 loss: 0.945943  [   96/  124]
train() client id: f_00002-2-0 loss: 0.864240  [   32/  124]
train() client id: f_00002-2-1 loss: 0.899202  [   64/  124]
train() client id: f_00002-2-2 loss: 0.931408  [   96/  124]
train() client id: f_00002-3-0 loss: 0.955112  [   32/  124]
train() client id: f_00002-3-1 loss: 0.868309  [   64/  124]
train() client id: f_00002-3-2 loss: 0.739568  [   96/  124]
train() client id: f_00002-4-0 loss: 0.810383  [   32/  124]
train() client id: f_00002-4-1 loss: 0.869042  [   64/  124]
train() client id: f_00002-4-2 loss: 1.037406  [   96/  124]
train() client id: f_00002-5-0 loss: 0.850809  [   32/  124]
train() client id: f_00002-5-1 loss: 0.858431  [   64/  124]
train() client id: f_00002-5-2 loss: 0.761631  [   96/  124]
train() client id: f_00002-6-0 loss: 0.762521  [   32/  124]
train() client id: f_00002-6-1 loss: 0.921951  [   64/  124]
train() client id: f_00002-6-2 loss: 0.829675  [   96/  124]
train() client id: f_00002-7-0 loss: 0.908131  [   32/  124]
train() client id: f_00002-7-1 loss: 0.757569  [   64/  124]
train() client id: f_00002-7-2 loss: 0.701383  [   96/  124]
train() client id: f_00002-8-0 loss: 0.814862  [   32/  124]
train() client id: f_00002-8-1 loss: 0.737994  [   64/  124]
train() client id: f_00002-8-2 loss: 0.897933  [   96/  124]
train() client id: f_00002-9-0 loss: 0.761594  [   32/  124]
train() client id: f_00002-9-1 loss: 0.771395  [   64/  124]
train() client id: f_00002-9-2 loss: 1.028155  [   96/  124]
train() client id: f_00002-10-0 loss: 0.807115  [   32/  124]
train() client id: f_00002-10-1 loss: 0.803985  [   64/  124]
train() client id: f_00002-10-2 loss: 0.899301  [   96/  124]
train() client id: f_00002-11-0 loss: 0.623028  [   32/  124]
train() client id: f_00002-11-1 loss: 1.039136  [   64/  124]
train() client id: f_00002-11-2 loss: 0.662441  [   96/  124]
train() client id: f_00002-12-0 loss: 0.637452  [   32/  124]
train() client id: f_00002-12-1 loss: 0.815126  [   64/  124]
train() client id: f_00002-12-2 loss: 0.822943  [   96/  124]
train() client id: f_00003-0-0 loss: 0.183061  [   32/   43]
train() client id: f_00003-1-0 loss: 0.237182  [   32/   43]
train() client id: f_00003-2-0 loss: 0.103974  [   32/   43]
train() client id: f_00003-3-0 loss: 0.092755  [   32/   43]
train() client id: f_00003-4-0 loss: 0.430459  [   32/   43]
train() client id: f_00003-5-0 loss: 0.043066  [   32/   43]
train() client id: f_00003-6-0 loss: 0.176371  [   32/   43]
train() client id: f_00003-7-0 loss: 0.389051  [   32/   43]
train() client id: f_00003-8-0 loss: 0.342300  [   32/   43]
train() client id: f_00003-9-0 loss: 0.016331  [   32/   43]
train() client id: f_00003-10-0 loss: 0.148771  [   32/   43]
train() client id: f_00003-11-0 loss: 0.385624  [   32/   43]
train() client id: f_00003-12-0 loss: 0.188033  [   32/   43]
train() client id: f_00004-0-0 loss: 0.850253  [   32/  306]
train() client id: f_00004-0-1 loss: 1.023866  [   64/  306]
train() client id: f_00004-0-2 loss: 1.035504  [   96/  306]
train() client id: f_00004-0-3 loss: 1.021781  [  128/  306]
train() client id: f_00004-0-4 loss: 0.927873  [  160/  306]
train() client id: f_00004-0-5 loss: 0.945736  [  192/  306]
train() client id: f_00004-0-6 loss: 0.915686  [  224/  306]
train() client id: f_00004-0-7 loss: 0.920012  [  256/  306]
train() client id: f_00004-0-8 loss: 1.120206  [  288/  306]
train() client id: f_00004-1-0 loss: 0.840196  [   32/  306]
train() client id: f_00004-1-1 loss: 1.131899  [   64/  306]
train() client id: f_00004-1-2 loss: 0.892059  [   96/  306]
train() client id: f_00004-1-3 loss: 0.880246  [  128/  306]
train() client id: f_00004-1-4 loss: 0.933332  [  160/  306]
train() client id: f_00004-1-5 loss: 0.907601  [  192/  306]
train() client id: f_00004-1-6 loss: 1.143722  [  224/  306]
train() client id: f_00004-1-7 loss: 0.952982  [  256/  306]
train() client id: f_00004-1-8 loss: 1.075042  [  288/  306]
train() client id: f_00004-2-0 loss: 0.928138  [   32/  306]
train() client id: f_00004-2-1 loss: 0.878860  [   64/  306]
train() client id: f_00004-2-2 loss: 0.988886  [   96/  306]
train() client id: f_00004-2-3 loss: 1.068121  [  128/  306]
train() client id: f_00004-2-4 loss: 0.954773  [  160/  306]
train() client id: f_00004-2-5 loss: 0.984980  [  192/  306]
train() client id: f_00004-2-6 loss: 0.984474  [  224/  306]
train() client id: f_00004-2-7 loss: 1.041277  [  256/  306]
train() client id: f_00004-2-8 loss: 0.861682  [  288/  306]
train() client id: f_00004-3-0 loss: 0.910633  [   32/  306]
train() client id: f_00004-3-1 loss: 0.848400  [   64/  306]
train() client id: f_00004-3-2 loss: 0.858860  [   96/  306]
train() client id: f_00004-3-3 loss: 0.983851  [  128/  306]
train() client id: f_00004-3-4 loss: 1.082112  [  160/  306]
train() client id: f_00004-3-5 loss: 1.066000  [  192/  306]
train() client id: f_00004-3-6 loss: 0.930760  [  224/  306]
train() client id: f_00004-3-7 loss: 0.896583  [  256/  306]
train() client id: f_00004-3-8 loss: 0.961004  [  288/  306]
train() client id: f_00004-4-0 loss: 0.952212  [   32/  306]
train() client id: f_00004-4-1 loss: 0.875031  [   64/  306]
train() client id: f_00004-4-2 loss: 0.947777  [   96/  306]
train() client id: f_00004-4-3 loss: 1.002994  [  128/  306]
train() client id: f_00004-4-4 loss: 1.030941  [  160/  306]
train() client id: f_00004-4-5 loss: 0.806955  [  192/  306]
train() client id: f_00004-4-6 loss: 0.921476  [  224/  306]
train() client id: f_00004-4-7 loss: 1.052611  [  256/  306]
train() client id: f_00004-4-8 loss: 1.093058  [  288/  306]
train() client id: f_00004-5-0 loss: 0.954206  [   32/  306]
train() client id: f_00004-5-1 loss: 0.781582  [   64/  306]
train() client id: f_00004-5-2 loss: 0.974449  [   96/  306]
train() client id: f_00004-5-3 loss: 0.995958  [  128/  306]
train() client id: f_00004-5-4 loss: 0.991720  [  160/  306]
train() client id: f_00004-5-5 loss: 0.974022  [  192/  306]
train() client id: f_00004-5-6 loss: 0.963987  [  224/  306]
train() client id: f_00004-5-7 loss: 1.133639  [  256/  306]
train() client id: f_00004-5-8 loss: 0.822246  [  288/  306]
train() client id: f_00004-6-0 loss: 0.928511  [   32/  306]
train() client id: f_00004-6-1 loss: 0.871029  [   64/  306]
train() client id: f_00004-6-2 loss: 1.030547  [   96/  306]
train() client id: f_00004-6-3 loss: 0.962177  [  128/  306]
train() client id: f_00004-6-4 loss: 0.892100  [  160/  306]
train() client id: f_00004-6-5 loss: 1.051923  [  192/  306]
train() client id: f_00004-6-6 loss: 1.013609  [  224/  306]
train() client id: f_00004-6-7 loss: 0.862785  [  256/  306]
train() client id: f_00004-6-8 loss: 0.842538  [  288/  306]
train() client id: f_00004-7-0 loss: 0.868771  [   32/  306]
train() client id: f_00004-7-1 loss: 1.017392  [   64/  306]
train() client id: f_00004-7-2 loss: 1.087777  [   96/  306]
train() client id: f_00004-7-3 loss: 0.971008  [  128/  306]
train() client id: f_00004-7-4 loss: 0.784069  [  160/  306]
train() client id: f_00004-7-5 loss: 0.865764  [  192/  306]
train() client id: f_00004-7-6 loss: 0.973056  [  224/  306]
train() client id: f_00004-7-7 loss: 0.960925  [  256/  306]
train() client id: f_00004-7-8 loss: 0.926282  [  288/  306]
train() client id: f_00004-8-0 loss: 0.794640  [   32/  306]
train() client id: f_00004-8-1 loss: 1.013947  [   64/  306]
train() client id: f_00004-8-2 loss: 0.919796  [   96/  306]
train() client id: f_00004-8-3 loss: 0.888651  [  128/  306]
train() client id: f_00004-8-4 loss: 1.014171  [  160/  306]
train() client id: f_00004-8-5 loss: 0.992650  [  192/  306]
train() client id: f_00004-8-6 loss: 0.965811  [  224/  306]
train() client id: f_00004-8-7 loss: 0.911524  [  256/  306]
train() client id: f_00004-8-8 loss: 0.973958  [  288/  306]
train() client id: f_00004-9-0 loss: 0.865003  [   32/  306]
train() client id: f_00004-9-1 loss: 0.966408  [   64/  306]
train() client id: f_00004-9-2 loss: 0.926919  [   96/  306]
train() client id: f_00004-9-3 loss: 0.998884  [  128/  306]
train() client id: f_00004-9-4 loss: 1.058761  [  160/  306]
train() client id: f_00004-9-5 loss: 0.876972  [  192/  306]
train() client id: f_00004-9-6 loss: 0.921134  [  224/  306]
train() client id: f_00004-9-7 loss: 0.944798  [  256/  306]
train() client id: f_00004-9-8 loss: 0.949124  [  288/  306]
train() client id: f_00004-10-0 loss: 1.040545  [   32/  306]
train() client id: f_00004-10-1 loss: 1.002092  [   64/  306]
train() client id: f_00004-10-2 loss: 0.928048  [   96/  306]
train() client id: f_00004-10-3 loss: 0.954421  [  128/  306]
train() client id: f_00004-10-4 loss: 0.879077  [  160/  306]
train() client id: f_00004-10-5 loss: 1.039183  [  192/  306]
train() client id: f_00004-10-6 loss: 0.941435  [  224/  306]
train() client id: f_00004-10-7 loss: 0.815407  [  256/  306]
train() client id: f_00004-10-8 loss: 0.886951  [  288/  306]
train() client id: f_00004-11-0 loss: 0.836861  [   32/  306]
train() client id: f_00004-11-1 loss: 0.920958  [   64/  306]
train() client id: f_00004-11-2 loss: 1.031075  [   96/  306]
train() client id: f_00004-11-3 loss: 1.003239  [  128/  306]
train() client id: f_00004-11-4 loss: 0.892826  [  160/  306]
train() client id: f_00004-11-5 loss: 1.064306  [  192/  306]
train() client id: f_00004-11-6 loss: 0.871985  [  224/  306]
train() client id: f_00004-11-7 loss: 0.826952  [  256/  306]
train() client id: f_00004-11-8 loss: 1.042795  [  288/  306]
train() client id: f_00004-12-0 loss: 0.871700  [   32/  306]
train() client id: f_00004-12-1 loss: 1.017931  [   64/  306]
train() client id: f_00004-12-2 loss: 0.902766  [   96/  306]
train() client id: f_00004-12-3 loss: 0.969172  [  128/  306]
train() client id: f_00004-12-4 loss: 0.852163  [  160/  306]
train() client id: f_00004-12-5 loss: 0.915671  [  192/  306]
train() client id: f_00004-12-6 loss: 0.880099  [  224/  306]
train() client id: f_00004-12-7 loss: 1.047879  [  256/  306]
train() client id: f_00004-12-8 loss: 0.939879  [  288/  306]
train() client id: f_00005-0-0 loss: 0.841340  [   32/  146]
train() client id: f_00005-0-1 loss: 0.937059  [   64/  146]
train() client id: f_00005-0-2 loss: 0.683579  [   96/  146]
train() client id: f_00005-0-3 loss: 0.731909  [  128/  146]
train() client id: f_00005-1-0 loss: 0.622068  [   32/  146]
train() client id: f_00005-1-1 loss: 0.989321  [   64/  146]
train() client id: f_00005-1-2 loss: 0.659160  [   96/  146]
train() client id: f_00005-1-3 loss: 0.865259  [  128/  146]
train() client id: f_00005-2-0 loss: 0.731318  [   32/  146]
train() client id: f_00005-2-1 loss: 1.070379  [   64/  146]
train() client id: f_00005-2-2 loss: 0.675164  [   96/  146]
train() client id: f_00005-2-3 loss: 0.676767  [  128/  146]
train() client id: f_00005-3-0 loss: 0.610639  [   32/  146]
train() client id: f_00005-3-1 loss: 0.750883  [   64/  146]
train() client id: f_00005-3-2 loss: 1.045269  [   96/  146]
train() client id: f_00005-3-3 loss: 0.856201  [  128/  146]
train() client id: f_00005-4-0 loss: 0.635195  [   32/  146]
train() client id: f_00005-4-1 loss: 0.935694  [   64/  146]
train() client id: f_00005-4-2 loss: 0.755325  [   96/  146]
train() client id: f_00005-4-3 loss: 0.873609  [  128/  146]
train() client id: f_00005-5-0 loss: 0.544222  [   32/  146]
train() client id: f_00005-5-1 loss: 1.168929  [   64/  146]
train() client id: f_00005-5-2 loss: 0.632796  [   96/  146]
train() client id: f_00005-5-3 loss: 0.669434  [  128/  146]
train() client id: f_00005-6-0 loss: 1.096050  [   32/  146]
train() client id: f_00005-6-1 loss: 0.787076  [   64/  146]
train() client id: f_00005-6-2 loss: 0.532914  [   96/  146]
train() client id: f_00005-6-3 loss: 0.834094  [  128/  146]
train() client id: f_00005-7-0 loss: 0.800973  [   32/  146]
train() client id: f_00005-7-1 loss: 0.696926  [   64/  146]
train() client id: f_00005-7-2 loss: 0.865192  [   96/  146]
train() client id: f_00005-7-3 loss: 0.988198  [  128/  146]
train() client id: f_00005-8-0 loss: 0.779984  [   32/  146]
train() client id: f_00005-8-1 loss: 0.761933  [   64/  146]
train() client id: f_00005-8-2 loss: 0.493113  [   96/  146]
train() client id: f_00005-8-3 loss: 0.758264  [  128/  146]
train() client id: f_00005-9-0 loss: 0.674328  [   32/  146]
train() client id: f_00005-9-1 loss: 0.955089  [   64/  146]
train() client id: f_00005-9-2 loss: 0.623943  [   96/  146]
train() client id: f_00005-9-3 loss: 0.590906  [  128/  146]
train() client id: f_00005-10-0 loss: 0.699681  [   32/  146]
train() client id: f_00005-10-1 loss: 0.762799  [   64/  146]
train() client id: f_00005-10-2 loss: 0.725445  [   96/  146]
train() client id: f_00005-10-3 loss: 0.989280  [  128/  146]
train() client id: f_00005-11-0 loss: 0.900366  [   32/  146]
train() client id: f_00005-11-1 loss: 0.915549  [   64/  146]
train() client id: f_00005-11-2 loss: 0.516448  [   96/  146]
train() client id: f_00005-11-3 loss: 0.819076  [  128/  146]
train() client id: f_00005-12-0 loss: 0.795097  [   32/  146]
train() client id: f_00005-12-1 loss: 0.564320  [   64/  146]
train() client id: f_00005-12-2 loss: 0.889737  [   96/  146]
train() client id: f_00005-12-3 loss: 0.874595  [  128/  146]
train() client id: f_00006-0-0 loss: 0.591125  [   32/   54]
train() client id: f_00006-1-0 loss: 0.493824  [   32/   54]
train() client id: f_00006-2-0 loss: 0.499000  [   32/   54]
train() client id: f_00006-3-0 loss: 0.556157  [   32/   54]
train() client id: f_00006-4-0 loss: 0.566566  [   32/   54]
train() client id: f_00006-5-0 loss: 0.526769  [   32/   54]
train() client id: f_00006-6-0 loss: 0.578598  [   32/   54]
train() client id: f_00006-7-0 loss: 0.569141  [   32/   54]
train() client id: f_00006-8-0 loss: 0.526975  [   32/   54]
train() client id: f_00006-9-0 loss: 0.466246  [   32/   54]
train() client id: f_00006-10-0 loss: 0.580688  [   32/   54]
train() client id: f_00006-11-0 loss: 0.588771  [   32/   54]
train() client id: f_00006-12-0 loss: 0.523565  [   32/   54]
train() client id: f_00007-0-0 loss: 0.625427  [   32/  179]
train() client id: f_00007-0-1 loss: 0.823578  [   64/  179]
train() client id: f_00007-0-2 loss: 0.951951  [   96/  179]
train() client id: f_00007-0-3 loss: 0.792624  [  128/  179]
train() client id: f_00007-0-4 loss: 0.580364  [  160/  179]
train() client id: f_00007-1-0 loss: 0.694931  [   32/  179]
train() client id: f_00007-1-1 loss: 0.633266  [   64/  179]
train() client id: f_00007-1-2 loss: 0.971841  [   96/  179]
train() client id: f_00007-1-3 loss: 0.662036  [  128/  179]
train() client id: f_00007-1-4 loss: 0.625262  [  160/  179]
train() client id: f_00007-2-0 loss: 0.659383  [   32/  179]
train() client id: f_00007-2-1 loss: 0.846629  [   64/  179]
train() client id: f_00007-2-2 loss: 0.532090  [   96/  179]
train() client id: f_00007-2-3 loss: 0.723879  [  128/  179]
train() client id: f_00007-2-4 loss: 0.880770  [  160/  179]
train() client id: f_00007-3-0 loss: 0.524695  [   32/  179]
train() client id: f_00007-3-1 loss: 0.629743  [   64/  179]
train() client id: f_00007-3-2 loss: 0.598708  [   96/  179]
train() client id: f_00007-3-3 loss: 0.701660  [  128/  179]
train() client id: f_00007-3-4 loss: 0.738150  [  160/  179]
train() client id: f_00007-4-0 loss: 0.722281  [   32/  179]
train() client id: f_00007-4-1 loss: 0.578019  [   64/  179]
train() client id: f_00007-4-2 loss: 0.673098  [   96/  179]
train() client id: f_00007-4-3 loss: 0.803103  [  128/  179]
train() client id: f_00007-4-4 loss: 0.783049  [  160/  179]
train() client id: f_00007-5-0 loss: 0.758957  [   32/  179]
train() client id: f_00007-5-1 loss: 0.610662  [   64/  179]
train() client id: f_00007-5-2 loss: 0.626588  [   96/  179]
train() client id: f_00007-5-3 loss: 0.932068  [  128/  179]
train() client id: f_00007-5-4 loss: 0.643161  [  160/  179]
train() client id: f_00007-6-0 loss: 0.756694  [   32/  179]
train() client id: f_00007-6-1 loss: 0.726856  [   64/  179]
train() client id: f_00007-6-2 loss: 0.717106  [   96/  179]
train() client id: f_00007-6-3 loss: 0.630946  [  128/  179]
train() client id: f_00007-6-4 loss: 0.602648  [  160/  179]
train() client id: f_00007-7-0 loss: 0.652711  [   32/  179]
train() client id: f_00007-7-1 loss: 0.753268  [   64/  179]
train() client id: f_00007-7-2 loss: 0.723112  [   96/  179]
train() client id: f_00007-7-3 loss: 0.547205  [  128/  179]
train() client id: f_00007-7-4 loss: 0.827788  [  160/  179]
train() client id: f_00007-8-0 loss: 0.533078  [   32/  179]
train() client id: f_00007-8-1 loss: 0.873006  [   64/  179]
train() client id: f_00007-8-2 loss: 0.522710  [   96/  179]
train() client id: f_00007-8-3 loss: 0.490404  [  128/  179]
train() client id: f_00007-8-4 loss: 0.984578  [  160/  179]
train() client id: f_00007-9-0 loss: 0.932240  [   32/  179]
train() client id: f_00007-9-1 loss: 0.599811  [   64/  179]
train() client id: f_00007-9-2 loss: 0.694450  [   96/  179]
train() client id: f_00007-9-3 loss: 0.763905  [  128/  179]
train() client id: f_00007-9-4 loss: 0.503689  [  160/  179]
train() client id: f_00007-10-0 loss: 0.610548  [   32/  179]
train() client id: f_00007-10-1 loss: 0.493460  [   64/  179]
train() client id: f_00007-10-2 loss: 0.547210  [   96/  179]
train() client id: f_00007-10-3 loss: 0.912468  [  128/  179]
train() client id: f_00007-10-4 loss: 0.928042  [  160/  179]
train() client id: f_00007-11-0 loss: 0.636790  [   32/  179]
train() client id: f_00007-11-1 loss: 0.882758  [   64/  179]
train() client id: f_00007-11-2 loss: 0.617666  [   96/  179]
train() client id: f_00007-11-3 loss: 0.630510  [  128/  179]
train() client id: f_00007-11-4 loss: 0.714679  [  160/  179]
train() client id: f_00007-12-0 loss: 0.727912  [   32/  179]
train() client id: f_00007-12-1 loss: 0.495632  [   64/  179]
train() client id: f_00007-12-2 loss: 0.906053  [   96/  179]
train() client id: f_00007-12-3 loss: 0.579923  [  128/  179]
train() client id: f_00007-12-4 loss: 0.624756  [  160/  179]
train() client id: f_00008-0-0 loss: 0.664709  [   32/  130]
train() client id: f_00008-0-1 loss: 0.744461  [   64/  130]
train() client id: f_00008-0-2 loss: 0.760199  [   96/  130]
train() client id: f_00008-0-3 loss: 0.698823  [  128/  130]
train() client id: f_00008-1-0 loss: 0.715396  [   32/  130]
train() client id: f_00008-1-1 loss: 0.657567  [   64/  130]
train() client id: f_00008-1-2 loss: 0.595154  [   96/  130]
train() client id: f_00008-1-3 loss: 0.897816  [  128/  130]
train() client id: f_00008-2-0 loss: 0.771870  [   32/  130]
train() client id: f_00008-2-1 loss: 0.674058  [   64/  130]
train() client id: f_00008-2-2 loss: 0.748092  [   96/  130]
train() client id: f_00008-2-3 loss: 0.674304  [  128/  130]
train() client id: f_00008-3-0 loss: 0.679371  [   32/  130]
train() client id: f_00008-3-1 loss: 0.777982  [   64/  130]
train() client id: f_00008-3-2 loss: 0.744013  [   96/  130]
train() client id: f_00008-3-3 loss: 0.656044  [  128/  130]
train() client id: f_00008-4-0 loss: 0.768359  [   32/  130]
train() client id: f_00008-4-1 loss: 0.667426  [   64/  130]
train() client id: f_00008-4-2 loss: 0.721257  [   96/  130]
train() client id: f_00008-4-3 loss: 0.695965  [  128/  130]
train() client id: f_00008-5-0 loss: 0.586558  [   32/  130]
train() client id: f_00008-5-1 loss: 0.734483  [   64/  130]
train() client id: f_00008-5-2 loss: 0.674344  [   96/  130]
train() client id: f_00008-5-3 loss: 0.816723  [  128/  130]
train() client id: f_00008-6-0 loss: 0.682091  [   32/  130]
train() client id: f_00008-6-1 loss: 0.690656  [   64/  130]
train() client id: f_00008-6-2 loss: 0.712480  [   96/  130]
train() client id: f_00008-6-3 loss: 0.771588  [  128/  130]
train() client id: f_00008-7-0 loss: 0.779182  [   32/  130]
train() client id: f_00008-7-1 loss: 0.640016  [   64/  130]
train() client id: f_00008-7-2 loss: 0.713939  [   96/  130]
train() client id: f_00008-7-3 loss: 0.682916  [  128/  130]
train() client id: f_00008-8-0 loss: 0.715130  [   32/  130]
train() client id: f_00008-8-1 loss: 0.669420  [   64/  130]
train() client id: f_00008-8-2 loss: 0.771060  [   96/  130]
train() client id: f_00008-8-3 loss: 0.681916  [  128/  130]
train() client id: f_00008-9-0 loss: 0.674744  [   32/  130]
train() client id: f_00008-9-1 loss: 0.758689  [   64/  130]
train() client id: f_00008-9-2 loss: 0.629807  [   96/  130]
train() client id: f_00008-9-3 loss: 0.778630  [  128/  130]
train() client id: f_00008-10-0 loss: 0.689771  [   32/  130]
train() client id: f_00008-10-1 loss: 0.823811  [   64/  130]
train() client id: f_00008-10-2 loss: 0.629367  [   96/  130]
train() client id: f_00008-10-3 loss: 0.695960  [  128/  130]
train() client id: f_00008-11-0 loss: 0.682553  [   32/  130]
train() client id: f_00008-11-1 loss: 0.689393  [   64/  130]
train() client id: f_00008-11-2 loss: 0.711587  [   96/  130]
train() client id: f_00008-11-3 loss: 0.726582  [  128/  130]
train() client id: f_00008-12-0 loss: 0.719016  [   32/  130]
train() client id: f_00008-12-1 loss: 0.661486  [   64/  130]
train() client id: f_00008-12-2 loss: 0.788866  [   96/  130]
train() client id: f_00008-12-3 loss: 0.640637  [  128/  130]
train() client id: f_00009-0-0 loss: 1.086164  [   32/  118]
train() client id: f_00009-0-1 loss: 0.904690  [   64/  118]
train() client id: f_00009-0-2 loss: 0.967224  [   96/  118]
train() client id: f_00009-1-0 loss: 0.986618  [   32/  118]
train() client id: f_00009-1-1 loss: 1.027380  [   64/  118]
train() client id: f_00009-1-2 loss: 0.894738  [   96/  118]
train() client id: f_00009-2-0 loss: 0.856940  [   32/  118]
train() client id: f_00009-2-1 loss: 0.840222  [   64/  118]
train() client id: f_00009-2-2 loss: 0.938881  [   96/  118]
train() client id: f_00009-3-0 loss: 0.891147  [   32/  118]
train() client id: f_00009-3-1 loss: 0.846452  [   64/  118]
train() client id: f_00009-3-2 loss: 0.889387  [   96/  118]
train() client id: f_00009-4-0 loss: 0.720401  [   32/  118]
train() client id: f_00009-4-1 loss: 0.840756  [   64/  118]
train() client id: f_00009-4-2 loss: 0.996857  [   96/  118]
train() client id: f_00009-5-0 loss: 0.791738  [   32/  118]
train() client id: f_00009-5-1 loss: 0.793340  [   64/  118]
train() client id: f_00009-5-2 loss: 0.899972  [   96/  118]
train() client id: f_00009-6-0 loss: 0.886674  [   32/  118]
train() client id: f_00009-6-1 loss: 0.842762  [   64/  118]
train() client id: f_00009-6-2 loss: 0.681845  [   96/  118]
train() client id: f_00009-7-0 loss: 0.638115  [   32/  118]
train() client id: f_00009-7-1 loss: 0.754577  [   64/  118]
train() client id: f_00009-7-2 loss: 1.000368  [   96/  118]
train() client id: f_00009-8-0 loss: 0.863630  [   32/  118]
train() client id: f_00009-8-1 loss: 0.593165  [   64/  118]
train() client id: f_00009-8-2 loss: 0.822127  [   96/  118]
train() client id: f_00009-9-0 loss: 0.720331  [   32/  118]
train() client id: f_00009-9-1 loss: 0.742563  [   64/  118]
train() client id: f_00009-9-2 loss: 0.739627  [   96/  118]
train() client id: f_00009-10-0 loss: 0.758592  [   32/  118]
train() client id: f_00009-10-1 loss: 0.669768  [   64/  118]
train() client id: f_00009-10-2 loss: 0.714890  [   96/  118]
train() client id: f_00009-11-0 loss: 0.843668  [   32/  118]
train() client id: f_00009-11-1 loss: 0.676810  [   64/  118]
train() client id: f_00009-11-2 loss: 0.777338  [   96/  118]
train() client id: f_00009-12-0 loss: 0.777440  [   32/  118]
train() client id: f_00009-12-1 loss: 0.739128  [   64/  118]
train() client id: f_00009-12-2 loss: 0.797898  [   96/  118]
At round 74 accuracy: 0.636604774535809
At round 74 training accuracy: 0.5848423876592891
At round 74 training loss: 0.8279354051180249
gradient difference: 0.41337037086486816
train() client id: f_00000-0-0 loss: 0.940187  [   32/  126]
train() client id: f_00000-0-1 loss: 1.071814  [   64/  126]
train() client id: f_00000-0-2 loss: 1.005131  [   96/  126]
train() client id: f_00000-1-0 loss: 1.056705  [   32/  126]
train() client id: f_00000-1-1 loss: 0.845509  [   64/  126]
train() client id: f_00000-1-2 loss: 0.780023  [   96/  126]
train() client id: f_00000-2-0 loss: 0.799182  [   32/  126]
train() client id: f_00000-2-1 loss: 0.829450  [   64/  126]
train() client id: f_00000-2-2 loss: 0.921875  [   96/  126]
train() client id: f_00000-3-0 loss: 0.808395  [   32/  126]
train() client id: f_00000-3-1 loss: 0.849143  [   64/  126]
train() client id: f_00000-3-2 loss: 0.693696  [   96/  126]
train() client id: f_00000-4-0 loss: 0.759935  [   32/  126]
train() client id: f_00000-4-1 loss: 0.714042  [   64/  126]
train() client id: f_00000-4-2 loss: 0.758186  [   96/  126]
train() client id: f_00000-5-0 loss: 0.699821  [   32/  126]
train() client id: f_00000-5-1 loss: 0.758168  [   64/  126]
train() client id: f_00000-5-2 loss: 0.761706  [   96/  126]
train() client id: f_00000-6-0 loss: 0.823943  [   32/  126]
train() client id: f_00000-6-1 loss: 0.653110  [   64/  126]
train() client id: f_00000-6-2 loss: 0.664368  [   96/  126]
train() client id: f_00000-7-0 loss: 0.648156  [   32/  126]
train() client id: f_00000-7-1 loss: 0.783264  [   64/  126]
train() client id: f_00000-7-2 loss: 0.651026  [   96/  126]
train() client id: f_00000-8-0 loss: 0.762241  [   32/  126]
train() client id: f_00000-8-1 loss: 0.780773  [   64/  126]
train() client id: f_00000-8-2 loss: 0.701533  [   96/  126]
train() client id: f_00000-9-0 loss: 0.764761  [   32/  126]
train() client id: f_00000-9-1 loss: 0.722478  [   64/  126]
train() client id: f_00000-9-2 loss: 0.664688  [   96/  126]
train() client id: f_00000-10-0 loss: 0.610773  [   32/  126]
train() client id: f_00000-10-1 loss: 0.710768  [   64/  126]
train() client id: f_00000-10-2 loss: 0.666704  [   96/  126]
train() client id: f_00000-11-0 loss: 0.673852  [   32/  126]
train() client id: f_00000-11-1 loss: 0.676293  [   64/  126]
train() client id: f_00000-11-2 loss: 0.625604  [   96/  126]
train() client id: f_00000-12-0 loss: 0.567651  [   32/  126]
train() client id: f_00000-12-1 loss: 0.598022  [   64/  126]
train() client id: f_00000-12-2 loss: 0.852601  [   96/  126]
train() client id: f_00001-0-0 loss: 0.400369  [   32/  265]
train() client id: f_00001-0-1 loss: 0.455625  [   64/  265]
train() client id: f_00001-0-2 loss: 0.469792  [   96/  265]
train() client id: f_00001-0-3 loss: 0.461618  [  128/  265]
train() client id: f_00001-0-4 loss: 0.507130  [  160/  265]
train() client id: f_00001-0-5 loss: 0.440686  [  192/  265]
train() client id: f_00001-0-6 loss: 0.402385  [  224/  265]
train() client id: f_00001-0-7 loss: 0.497200  [  256/  265]
train() client id: f_00001-1-0 loss: 0.508973  [   32/  265]
train() client id: f_00001-1-1 loss: 0.560956  [   64/  265]
train() client id: f_00001-1-2 loss: 0.547177  [   96/  265]
train() client id: f_00001-1-3 loss: 0.341407  [  128/  265]
train() client id: f_00001-1-4 loss: 0.414020  [  160/  265]
train() client id: f_00001-1-5 loss: 0.362682  [  192/  265]
train() client id: f_00001-1-6 loss: 0.421991  [  224/  265]
train() client id: f_00001-1-7 loss: 0.421720  [  256/  265]
train() client id: f_00001-2-0 loss: 0.443554  [   32/  265]
train() client id: f_00001-2-1 loss: 0.567126  [   64/  265]
train() client id: f_00001-2-2 loss: 0.368144  [   96/  265]
train() client id: f_00001-2-3 loss: 0.527677  [  128/  265]
train() client id: f_00001-2-4 loss: 0.404760  [  160/  265]
train() client id: f_00001-2-5 loss: 0.431170  [  192/  265]
train() client id: f_00001-2-6 loss: 0.413978  [  224/  265]
train() client id: f_00001-2-7 loss: 0.363398  [  256/  265]
train() client id: f_00001-3-0 loss: 0.449854  [   32/  265]
train() client id: f_00001-3-1 loss: 0.329473  [   64/  265]
train() client id: f_00001-3-2 loss: 0.411739  [   96/  265]
train() client id: f_00001-3-3 loss: 0.429908  [  128/  265]
train() client id: f_00001-3-4 loss: 0.489398  [  160/  265]
train() client id: f_00001-3-5 loss: 0.401085  [  192/  265]
train() client id: f_00001-3-6 loss: 0.509071  [  224/  265]
train() client id: f_00001-3-7 loss: 0.383909  [  256/  265]
train() client id: f_00001-4-0 loss: 0.387134  [   32/  265]
train() client id: f_00001-4-1 loss: 0.444300  [   64/  265]
train() client id: f_00001-4-2 loss: 0.340346  [   96/  265]
train() client id: f_00001-4-3 loss: 0.362383  [  128/  265]
train() client id: f_00001-4-4 loss: 0.436479  [  160/  265]
train() client id: f_00001-4-5 loss: 0.464351  [  192/  265]
train() client id: f_00001-4-6 loss: 0.489083  [  224/  265]
train() client id: f_00001-4-7 loss: 0.516714  [  256/  265]
train() client id: f_00001-5-0 loss: 0.534663  [   32/  265]
train() client id: f_00001-5-1 loss: 0.357416  [   64/  265]
train() client id: f_00001-5-2 loss: 0.424253  [   96/  265]
train() client id: f_00001-5-3 loss: 0.395992  [  128/  265]
train() client id: f_00001-5-4 loss: 0.426745  [  160/  265]
train() client id: f_00001-5-5 loss: 0.332923  [  192/  265]
train() client id: f_00001-5-6 loss: 0.585558  [  224/  265]
train() client id: f_00001-5-7 loss: 0.371131  [  256/  265]
train() client id: f_00001-6-0 loss: 0.460959  [   32/  265]
train() client id: f_00001-6-1 loss: 0.312588  [   64/  265]
train() client id: f_00001-6-2 loss: 0.538746  [   96/  265]
train() client id: f_00001-6-3 loss: 0.398589  [  128/  265]
train() client id: f_00001-6-4 loss: 0.344770  [  160/  265]
train() client id: f_00001-6-5 loss: 0.338856  [  192/  265]
train() client id: f_00001-6-6 loss: 0.435399  [  224/  265]
train() client id: f_00001-6-7 loss: 0.564586  [  256/  265]
train() client id: f_00001-7-0 loss: 0.410845  [   32/  265]
train() client id: f_00001-7-1 loss: 0.384338  [   64/  265]
train() client id: f_00001-7-2 loss: 0.563618  [   96/  265]
train() client id: f_00001-7-3 loss: 0.329688  [  128/  265]
train() client id: f_00001-7-4 loss: 0.405759  [  160/  265]
train() client id: f_00001-7-5 loss: 0.457185  [  192/  265]
train() client id: f_00001-7-6 loss: 0.477273  [  224/  265]
train() client id: f_00001-7-7 loss: 0.337058  [  256/  265]
train() client id: f_00001-8-0 loss: 0.475805  [   32/  265]
train() client id: f_00001-8-1 loss: 0.495592  [   64/  265]
train() client id: f_00001-8-2 loss: 0.309983  [   96/  265]
train() client id: f_00001-8-3 loss: 0.414734  [  128/  265]
train() client id: f_00001-8-4 loss: 0.446632  [  160/  265]
train() client id: f_00001-8-5 loss: 0.423856  [  192/  265]
train() client id: f_00001-8-6 loss: 0.468528  [  224/  265]
train() client id: f_00001-8-7 loss: 0.340218  [  256/  265]
train() client id: f_00001-9-0 loss: 0.350980  [   32/  265]
train() client id: f_00001-9-1 loss: 0.379513  [   64/  265]
train() client id: f_00001-9-2 loss: 0.427473  [   96/  265]
train() client id: f_00001-9-3 loss: 0.569989  [  128/  265]
train() client id: f_00001-9-4 loss: 0.484573  [  160/  265]
train() client id: f_00001-9-5 loss: 0.326612  [  192/  265]
train() client id: f_00001-9-6 loss: 0.376310  [  224/  265]
train() client id: f_00001-9-7 loss: 0.397446  [  256/  265]
train() client id: f_00001-10-0 loss: 0.341865  [   32/  265]
train() client id: f_00001-10-1 loss: 0.339505  [   64/  265]
train() client id: f_00001-10-2 loss: 0.378199  [   96/  265]
train() client id: f_00001-10-3 loss: 0.336499  [  128/  265]
train() client id: f_00001-10-4 loss: 0.384168  [  160/  265]
train() client id: f_00001-10-5 loss: 0.403338  [  192/  265]
train() client id: f_00001-10-6 loss: 0.728012  [  224/  265]
train() client id: f_00001-10-7 loss: 0.421565  [  256/  265]
train() client id: f_00001-11-0 loss: 0.320395  [   32/  265]
train() client id: f_00001-11-1 loss: 0.516385  [   64/  265]
train() client id: f_00001-11-2 loss: 0.505884  [   96/  265]
train() client id: f_00001-11-3 loss: 0.397135  [  128/  265]
train() client id: f_00001-11-4 loss: 0.436494  [  160/  265]
train() client id: f_00001-11-5 loss: 0.343408  [  192/  265]
train() client id: f_00001-11-6 loss: 0.501369  [  224/  265]
train() client id: f_00001-11-7 loss: 0.348055  [  256/  265]
train() client id: f_00001-12-0 loss: 0.507273  [   32/  265]
train() client id: f_00001-12-1 loss: 0.330643  [   64/  265]
train() client id: f_00001-12-2 loss: 0.311651  [   96/  265]
train() client id: f_00001-12-3 loss: 0.427487  [  128/  265]
train() client id: f_00001-12-4 loss: 0.390225  [  160/  265]
train() client id: f_00001-12-5 loss: 0.492968  [  192/  265]
train() client id: f_00001-12-6 loss: 0.346438  [  224/  265]
train() client id: f_00001-12-7 loss: 0.418551  [  256/  265]
train() client id: f_00002-0-0 loss: 1.042660  [   32/  124]
train() client id: f_00002-0-1 loss: 0.917220  [   64/  124]
train() client id: f_00002-0-2 loss: 0.985095  [   96/  124]
train() client id: f_00002-1-0 loss: 0.691778  [   32/  124]
train() client id: f_00002-1-1 loss: 0.903244  [   64/  124]
train() client id: f_00002-1-2 loss: 1.239372  [   96/  124]
train() client id: f_00002-2-0 loss: 0.967727  [   32/  124]
train() client id: f_00002-2-1 loss: 1.148567  [   64/  124]
train() client id: f_00002-2-2 loss: 0.908617  [   96/  124]
train() client id: f_00002-3-0 loss: 1.017537  [   32/  124]
train() client id: f_00002-3-1 loss: 0.935915  [   64/  124]
train() client id: f_00002-3-2 loss: 0.976191  [   96/  124]
train() client id: f_00002-4-0 loss: 1.038779  [   32/  124]
train() client id: f_00002-4-1 loss: 0.872703  [   64/  124]
train() client id: f_00002-4-2 loss: 0.801465  [   96/  124]
train() client id: f_00002-5-0 loss: 0.841098  [   32/  124]
train() client id: f_00002-5-1 loss: 0.838377  [   64/  124]
train() client id: f_00002-5-2 loss: 1.078174  [   96/  124]
train() client id: f_00002-6-0 loss: 0.808348  [   32/  124]
train() client id: f_00002-6-1 loss: 0.962908  [   64/  124]
train() client id: f_00002-6-2 loss: 1.036169  [   96/  124]
train() client id: f_00002-7-0 loss: 0.707984  [   32/  124]
train() client id: f_00002-7-1 loss: 0.903886  [   64/  124]
train() client id: f_00002-7-2 loss: 0.939374  [   96/  124]
train() client id: f_00002-8-0 loss: 0.919295  [   32/  124]
train() client id: f_00002-8-1 loss: 0.860127  [   64/  124]
train() client id: f_00002-8-2 loss: 0.782841  [   96/  124]
train() client id: f_00002-9-0 loss: 0.808952  [   32/  124]
train() client id: f_00002-9-1 loss: 0.803272  [   64/  124]
train() client id: f_00002-9-2 loss: 1.013609  [   96/  124]
train() client id: f_00002-10-0 loss: 0.993726  [   32/  124]
train() client id: f_00002-10-1 loss: 0.751182  [   64/  124]
train() client id: f_00002-10-2 loss: 0.936272  [   96/  124]
train() client id: f_00002-11-0 loss: 0.918546  [   32/  124]
train() client id: f_00002-11-1 loss: 0.954463  [   64/  124]
train() client id: f_00002-11-2 loss: 0.912754  [   96/  124]
train() client id: f_00002-12-0 loss: 0.956071  [   32/  124]
train() client id: f_00002-12-1 loss: 0.794060  [   64/  124]
train() client id: f_00002-12-2 loss: 0.978721  [   96/  124]
train() client id: f_00003-0-0 loss: 0.843430  [   32/   43]
train() client id: f_00003-1-0 loss: 0.699466  [   32/   43]
train() client id: f_00003-2-0 loss: 0.498760  [   32/   43]
train() client id: f_00003-3-0 loss: 0.647497  [   32/   43]
train() client id: f_00003-4-0 loss: 0.767546  [   32/   43]
train() client id: f_00003-5-0 loss: 0.801495  [   32/   43]
train() client id: f_00003-6-0 loss: 0.547920  [   32/   43]
train() client id: f_00003-7-0 loss: 0.645299  [   32/   43]
train() client id: f_00003-8-0 loss: 0.653920  [   32/   43]
train() client id: f_00003-9-0 loss: 0.656827  [   32/   43]
train() client id: f_00003-10-0 loss: 0.853737  [   32/   43]
train() client id: f_00003-11-0 loss: 0.603398  [   32/   43]
train() client id: f_00003-12-0 loss: 0.803982  [   32/   43]
train() client id: f_00004-0-0 loss: 0.807689  [   32/  306]
train() client id: f_00004-0-1 loss: 0.860614  [   64/  306]
train() client id: f_00004-0-2 loss: 0.933767  [   96/  306]
train() client id: f_00004-0-3 loss: 0.918274  [  128/  306]
train() client id: f_00004-0-4 loss: 0.769646  [  160/  306]
train() client id: f_00004-0-5 loss: 0.782394  [  192/  306]
train() client id: f_00004-0-6 loss: 0.778461  [  224/  306]
train() client id: f_00004-0-7 loss: 0.803572  [  256/  306]
train() client id: f_00004-0-8 loss: 0.844998  [  288/  306]
train() client id: f_00004-1-0 loss: 0.944042  [   32/  306]
train() client id: f_00004-1-1 loss: 0.853271  [   64/  306]
train() client id: f_00004-1-2 loss: 0.874174  [   96/  306]
train() client id: f_00004-1-3 loss: 0.775277  [  128/  306]
train() client id: f_00004-1-4 loss: 0.722011  [  160/  306]
train() client id: f_00004-1-5 loss: 0.840576  [  192/  306]
train() client id: f_00004-1-6 loss: 0.754996  [  224/  306]
train() client id: f_00004-1-7 loss: 0.753290  [  256/  306]
train() client id: f_00004-1-8 loss: 0.840246  [  288/  306]
train() client id: f_00004-2-0 loss: 0.876339  [   32/  306]
train() client id: f_00004-2-1 loss: 0.814444  [   64/  306]
train() client id: f_00004-2-2 loss: 0.847655  [   96/  306]
train() client id: f_00004-2-3 loss: 0.709326  [  128/  306]
train() client id: f_00004-2-4 loss: 0.869270  [  160/  306]
train() client id: f_00004-2-5 loss: 0.768967  [  192/  306]
train() client id: f_00004-2-6 loss: 0.826226  [  224/  306]
train() client id: f_00004-2-7 loss: 0.805023  [  256/  306]
train() client id: f_00004-2-8 loss: 0.865881  [  288/  306]
train() client id: f_00004-3-0 loss: 0.773852  [   32/  306]
train() client id: f_00004-3-1 loss: 0.879107  [   64/  306]
train() client id: f_00004-3-2 loss: 0.864345  [   96/  306]
train() client id: f_00004-3-3 loss: 0.879748  [  128/  306]
train() client id: f_00004-3-4 loss: 0.874687  [  160/  306]
train() client id: f_00004-3-5 loss: 0.794162  [  192/  306]
train() client id: f_00004-3-6 loss: 0.693252  [  224/  306]
train() client id: f_00004-3-7 loss: 0.795582  [  256/  306]
train() client id: f_00004-3-8 loss: 0.785038  [  288/  306]
train() client id: f_00004-4-0 loss: 0.829001  [   32/  306]
train() client id: f_00004-4-1 loss: 0.904308  [   64/  306]
train() client id: f_00004-4-2 loss: 0.816990  [   96/  306]
train() client id: f_00004-4-3 loss: 0.737202  [  128/  306]
train() client id: f_00004-4-4 loss: 0.733389  [  160/  306]
train() client id: f_00004-4-5 loss: 0.731581  [  192/  306]
train() client id: f_00004-4-6 loss: 0.873861  [  224/  306]
train() client id: f_00004-4-7 loss: 0.897640  [  256/  306]
train() client id: f_00004-4-8 loss: 0.922396  [  288/  306]
train() client id: f_00004-5-0 loss: 0.866302  [   32/  306]
train() client id: f_00004-5-1 loss: 0.992000  [   64/  306]
train() client id: f_00004-5-2 loss: 0.805823  [   96/  306]
train() client id: f_00004-5-3 loss: 0.799456  [  128/  306]
train() client id: f_00004-5-4 loss: 0.825153  [  160/  306]
train() client id: f_00004-5-5 loss: 0.754949  [  192/  306]
train() client id: f_00004-5-6 loss: 0.654208  [  224/  306]
train() client id: f_00004-5-7 loss: 0.846874  [  256/  306]
train() client id: f_00004-5-8 loss: 0.888489  [  288/  306]
train() client id: f_00004-6-0 loss: 0.912583  [   32/  306]
train() client id: f_00004-6-1 loss: 0.884446  [   64/  306]
train() client id: f_00004-6-2 loss: 0.904529  [   96/  306]
train() client id: f_00004-6-3 loss: 0.668958  [  128/  306]
train() client id: f_00004-6-4 loss: 0.899290  [  160/  306]
train() client id: f_00004-6-5 loss: 0.712430  [  192/  306]
train() client id: f_00004-6-6 loss: 0.716043  [  224/  306]
train() client id: f_00004-6-7 loss: 0.758018  [  256/  306]
train() client id: f_00004-6-8 loss: 0.931764  [  288/  306]
train() client id: f_00004-7-0 loss: 0.837311  [   32/  306]
train() client id: f_00004-7-1 loss: 0.698759  [   64/  306]
train() client id: f_00004-7-2 loss: 0.786572  [   96/  306]
train() client id: f_00004-7-3 loss: 0.833393  [  128/  306]
train() client id: f_00004-7-4 loss: 0.857578  [  160/  306]
train() client id: f_00004-7-5 loss: 0.836133  [  192/  306]
train() client id: f_00004-7-6 loss: 0.764941  [  224/  306]
train() client id: f_00004-7-7 loss: 0.869898  [  256/  306]
train() client id: f_00004-7-8 loss: 0.690573  [  288/  306]
train() client id: f_00004-8-0 loss: 0.893452  [   32/  306]
train() client id: f_00004-8-1 loss: 0.720201  [   64/  306]
train() client id: f_00004-8-2 loss: 0.694598  [   96/  306]
train() client id: f_00004-8-3 loss: 0.806230  [  128/  306]
train() client id: f_00004-8-4 loss: 0.794731  [  160/  306]
train() client id: f_00004-8-5 loss: 0.864782  [  192/  306]
train() client id: f_00004-8-6 loss: 0.837868  [  224/  306]
train() client id: f_00004-8-7 loss: 0.737270  [  256/  306]
train() client id: f_00004-8-8 loss: 0.990314  [  288/  306]
train() client id: f_00004-9-0 loss: 0.709702  [   32/  306]
train() client id: f_00004-9-1 loss: 0.842794  [   64/  306]
train() client id: f_00004-9-2 loss: 0.796899  [   96/  306]
train() client id: f_00004-9-3 loss: 0.664687  [  128/  306]
train() client id: f_00004-9-4 loss: 0.782527  [  160/  306]
train() client id: f_00004-9-5 loss: 0.780687  [  192/  306]
train() client id: f_00004-9-6 loss: 0.859479  [  224/  306]
train() client id: f_00004-9-7 loss: 0.952952  [  256/  306]
train() client id: f_00004-9-8 loss: 0.976635  [  288/  306]
train() client id: f_00004-10-0 loss: 0.678911  [   32/  306]
train() client id: f_00004-10-1 loss: 0.828325  [   64/  306]
train() client id: f_00004-10-2 loss: 0.905616  [   96/  306]
train() client id: f_00004-10-3 loss: 1.013758  [  128/  306]
train() client id: f_00004-10-4 loss: 0.753283  [  160/  306]
train() client id: f_00004-10-5 loss: 0.796243  [  192/  306]
train() client id: f_00004-10-6 loss: 0.951834  [  224/  306]
train() client id: f_00004-10-7 loss: 0.758849  [  256/  306]
train() client id: f_00004-10-8 loss: 0.740430  [  288/  306]
train() client id: f_00004-11-0 loss: 0.815690  [   32/  306]
train() client id: f_00004-11-1 loss: 0.862934  [   64/  306]
train() client id: f_00004-11-2 loss: 0.876186  [   96/  306]
train() client id: f_00004-11-3 loss: 0.771001  [  128/  306]
train() client id: f_00004-11-4 loss: 0.792634  [  160/  306]
train() client id: f_00004-11-5 loss: 0.710496  [  192/  306]
train() client id: f_00004-11-6 loss: 0.844429  [  224/  306]
train() client id: f_00004-11-7 loss: 0.805717  [  256/  306]
train() client id: f_00004-11-8 loss: 0.953483  [  288/  306]
train() client id: f_00004-12-0 loss: 0.882105  [   32/  306]
train() client id: f_00004-12-1 loss: 0.885111  [   64/  306]
train() client id: f_00004-12-2 loss: 0.760304  [   96/  306]
train() client id: f_00004-12-3 loss: 0.694069  [  128/  306]
train() client id: f_00004-12-4 loss: 0.846623  [  160/  306]
train() client id: f_00004-12-5 loss: 0.957177  [  192/  306]
train() client id: f_00004-12-6 loss: 0.735622  [  224/  306]
train() client id: f_00004-12-7 loss: 0.781926  [  256/  306]
train() client id: f_00004-12-8 loss: 0.801673  [  288/  306]
train() client id: f_00005-0-0 loss: 0.428667  [   32/  146]
train() client id: f_00005-0-1 loss: 0.384662  [   64/  146]
train() client id: f_00005-0-2 loss: 0.442811  [   96/  146]
train() client id: f_00005-0-3 loss: 0.697936  [  128/  146]
train() client id: f_00005-1-0 loss: 0.565178  [   32/  146]
train() client id: f_00005-1-1 loss: 0.549907  [   64/  146]
train() client id: f_00005-1-2 loss: 0.429477  [   96/  146]
train() client id: f_00005-1-3 loss: 0.162984  [  128/  146]
train() client id: f_00005-2-0 loss: 0.219260  [   32/  146]
train() client id: f_00005-2-1 loss: 0.513926  [   64/  146]
train() client id: f_00005-2-2 loss: 0.532773  [   96/  146]
train() client id: f_00005-2-3 loss: 0.773737  [  128/  146]
train() client id: f_00005-3-0 loss: 0.282602  [   32/  146]
train() client id: f_00005-3-1 loss: 0.854059  [   64/  146]
train() client id: f_00005-3-2 loss: 0.675124  [   96/  146]
train() client id: f_00005-3-3 loss: 0.173621  [  128/  146]
train() client id: f_00005-4-0 loss: 0.402518  [   32/  146]
train() client id: f_00005-4-1 loss: 0.370655  [   64/  146]
train() client id: f_00005-4-2 loss: 0.551008  [   96/  146]
train() client id: f_00005-4-3 loss: 0.441877  [  128/  146]
train() client id: f_00005-5-0 loss: 0.317611  [   32/  146]
train() client id: f_00005-5-1 loss: 0.571928  [   64/  146]
train() client id: f_00005-5-2 loss: 0.429845  [   96/  146]
train() client id: f_00005-5-3 loss: 0.485790  [  128/  146]
train() client id: f_00005-6-0 loss: 0.493098  [   32/  146]
train() client id: f_00005-6-1 loss: 0.272677  [   64/  146]
train() client id: f_00005-6-2 loss: 0.603397  [   96/  146]
train() client id: f_00005-6-3 loss: 0.445219  [  128/  146]
train() client id: f_00005-7-0 loss: 0.091646  [   32/  146]
train() client id: f_00005-7-1 loss: 0.548235  [   64/  146]
train() client id: f_00005-7-2 loss: 0.727194  [   96/  146]
train() client id: f_00005-7-3 loss: 0.441554  [  128/  146]
train() client id: f_00005-8-0 loss: 0.356085  [   32/  146]
train() client id: f_00005-8-1 loss: 0.700066  [   64/  146]
train() client id: f_00005-8-2 loss: 0.497923  [   96/  146]
train() client id: f_00005-8-3 loss: 0.150177  [  128/  146]
train() client id: f_00005-9-0 loss: 0.524316  [   32/  146]
train() client id: f_00005-9-1 loss: 0.428154  [   64/  146]
train() client id: f_00005-9-2 loss: 0.785729  [   96/  146]
train() client id: f_00005-9-3 loss: 0.287900  [  128/  146]
train() client id: f_00005-10-0 loss: 0.339723  [   32/  146]
train() client id: f_00005-10-1 loss: 0.685834  [   64/  146]
train() client id: f_00005-10-2 loss: 0.401015  [   96/  146]
train() client id: f_00005-10-3 loss: 0.331538  [  128/  146]
train() client id: f_00005-11-0 loss: 0.510603  [   32/  146]
train() client id: f_00005-11-1 loss: 0.277915  [   64/  146]
train() client id: f_00005-11-2 loss: 0.391721  [   96/  146]
train() client id: f_00005-11-3 loss: 0.657873  [  128/  146]
train() client id: f_00005-12-0 loss: 0.449983  [   32/  146]
train() client id: f_00005-12-1 loss: 0.434055  [   64/  146]
train() client id: f_00005-12-2 loss: 0.513974  [   96/  146]
train() client id: f_00005-12-3 loss: 0.468055  [  128/  146]
train() client id: f_00006-0-0 loss: 0.488251  [   32/   54]
train() client id: f_00006-1-0 loss: 0.461078  [   32/   54]
train() client id: f_00006-2-0 loss: 0.527490  [   32/   54]
train() client id: f_00006-3-0 loss: 0.514868  [   32/   54]
train() client id: f_00006-4-0 loss: 0.489776  [   32/   54]
train() client id: f_00006-5-0 loss: 0.543194  [   32/   54]
train() client id: f_00006-6-0 loss: 0.495223  [   32/   54]
train() client id: f_00006-7-0 loss: 0.559990  [   32/   54]
train() client id: f_00006-8-0 loss: 0.460675  [   32/   54]
train() client id: f_00006-9-0 loss: 0.557435  [   32/   54]
train() client id: f_00006-10-0 loss: 0.439414  [   32/   54]
train() client id: f_00006-11-0 loss: 0.566724  [   32/   54]
train() client id: f_00006-12-0 loss: 0.524264  [   32/   54]
train() client id: f_00007-0-0 loss: 0.661506  [   32/  179]
train() client id: f_00007-0-1 loss: 0.688509  [   64/  179]
train() client id: f_00007-0-2 loss: 0.634799  [   96/  179]
train() client id: f_00007-0-3 loss: 0.666015  [  128/  179]
train() client id: f_00007-0-4 loss: 0.747616  [  160/  179]
train() client id: f_00007-1-0 loss: 0.710733  [   32/  179]
train() client id: f_00007-1-1 loss: 0.751884  [   64/  179]
train() client id: f_00007-1-2 loss: 0.460702  [   96/  179]
train() client id: f_00007-1-3 loss: 0.587247  [  128/  179]
train() client id: f_00007-1-4 loss: 0.770026  [  160/  179]
train() client id: f_00007-2-0 loss: 0.658349  [   32/  179]
train() client id: f_00007-2-1 loss: 0.552214  [   64/  179]
train() client id: f_00007-2-2 loss: 0.832492  [   96/  179]
train() client id: f_00007-2-3 loss: 0.569758  [  128/  179]
train() client id: f_00007-2-4 loss: 0.527963  [  160/  179]
train() client id: f_00007-3-0 loss: 0.786945  [   32/  179]
train() client id: f_00007-3-1 loss: 0.615724  [   64/  179]
train() client id: f_00007-3-2 loss: 0.684608  [   96/  179]
train() client id: f_00007-3-3 loss: 0.491786  [  128/  179]
train() client id: f_00007-3-4 loss: 0.546143  [  160/  179]
train() client id: f_00007-4-0 loss: 0.821220  [   32/  179]
train() client id: f_00007-4-1 loss: 0.398477  [   64/  179]
train() client id: f_00007-4-2 loss: 0.698482  [   96/  179]
train() client id: f_00007-4-3 loss: 0.493590  [  128/  179]
train() client id: f_00007-4-4 loss: 0.568723  [  160/  179]
train() client id: f_00007-5-0 loss: 0.680888  [   32/  179]
train() client id: f_00007-5-1 loss: 0.499097  [   64/  179]
train() client id: f_00007-5-2 loss: 0.546078  [   96/  179]
train() client id: f_00007-5-3 loss: 0.586133  [  128/  179]
train() client id: f_00007-5-4 loss: 0.802752  [  160/  179]
train() client id: f_00007-6-0 loss: 0.454812  [   32/  179]
train() client id: f_00007-6-1 loss: 0.599999  [   64/  179]
train() client id: f_00007-6-2 loss: 0.872881  [   96/  179]
train() client id: f_00007-6-3 loss: 0.615283  [  128/  179]
train() client id: f_00007-6-4 loss: 0.643208  [  160/  179]
train() client id: f_00007-7-0 loss: 0.591178  [   32/  179]
train() client id: f_00007-7-1 loss: 0.738260  [   64/  179]
train() client id: f_00007-7-2 loss: 0.637818  [   96/  179]
train() client id: f_00007-7-3 loss: 0.516198  [  128/  179]
train() client id: f_00007-7-4 loss: 0.553909  [  160/  179]
train() client id: f_00007-8-0 loss: 0.636900  [   32/  179]
train() client id: f_00007-8-1 loss: 0.630222  [   64/  179]
train() client id: f_00007-8-2 loss: 0.507372  [   96/  179]
train() client id: f_00007-8-3 loss: 0.577804  [  128/  179]
train() client id: f_00007-8-4 loss: 0.660126  [  160/  179]
train() client id: f_00007-9-0 loss: 0.700362  [   32/  179]
train() client id: f_00007-9-1 loss: 0.593589  [   64/  179]
train() client id: f_00007-9-2 loss: 0.630843  [   96/  179]
train() client id: f_00007-9-3 loss: 0.561857  [  128/  179]
train() client id: f_00007-9-4 loss: 0.663561  [  160/  179]
train() client id: f_00007-10-0 loss: 0.478116  [   32/  179]
train() client id: f_00007-10-1 loss: 0.731853  [   64/  179]
train() client id: f_00007-10-2 loss: 0.562227  [   96/  179]
train() client id: f_00007-10-3 loss: 0.540151  [  128/  179]
train() client id: f_00007-10-4 loss: 0.454321  [  160/  179]
train() client id: f_00007-11-0 loss: 0.676367  [   32/  179]
train() client id: f_00007-11-1 loss: 0.718385  [   64/  179]
train() client id: f_00007-11-2 loss: 0.647887  [   96/  179]
train() client id: f_00007-11-3 loss: 0.466475  [  128/  179]
train() client id: f_00007-11-4 loss: 0.635519  [  160/  179]
train() client id: f_00007-12-0 loss: 0.810247  [   32/  179]
train() client id: f_00007-12-1 loss: 0.630488  [   64/  179]
train() client id: f_00007-12-2 loss: 0.415466  [   96/  179]
train() client id: f_00007-12-3 loss: 0.548208  [  128/  179]
train() client id: f_00007-12-4 loss: 0.752272  [  160/  179]
train() client id: f_00008-0-0 loss: 0.726548  [   32/  130]
train() client id: f_00008-0-1 loss: 0.726130  [   64/  130]
train() client id: f_00008-0-2 loss: 0.676907  [   96/  130]
train() client id: f_00008-0-3 loss: 0.726642  [  128/  130]
train() client id: f_00008-1-0 loss: 0.626184  [   32/  130]
train() client id: f_00008-1-1 loss: 0.747081  [   64/  130]
train() client id: f_00008-1-2 loss: 0.904905  [   96/  130]
train() client id: f_00008-1-3 loss: 0.602445  [  128/  130]
train() client id: f_00008-2-0 loss: 0.765736  [   32/  130]
train() client id: f_00008-2-1 loss: 0.661428  [   64/  130]
train() client id: f_00008-2-2 loss: 0.704886  [   96/  130]
train() client id: f_00008-2-3 loss: 0.722673  [  128/  130]
train() client id: f_00008-3-0 loss: 0.944506  [   32/  130]
train() client id: f_00008-3-1 loss: 0.715503  [   64/  130]
train() client id: f_00008-3-2 loss: 0.603963  [   96/  130]
train() client id: f_00008-3-3 loss: 0.626410  [  128/  130]
train() client id: f_00008-4-0 loss: 0.723231  [   32/  130]
train() client id: f_00008-4-1 loss: 0.804952  [   64/  130]
train() client id: f_00008-4-2 loss: 0.675088  [   96/  130]
train() client id: f_00008-4-3 loss: 0.685596  [  128/  130]
train() client id: f_00008-5-0 loss: 0.777738  [   32/  130]
train() client id: f_00008-5-1 loss: 0.556647  [   64/  130]
train() client id: f_00008-5-2 loss: 0.743276  [   96/  130]
train() client id: f_00008-5-3 loss: 0.805626  [  128/  130]
train() client id: f_00008-6-0 loss: 0.673460  [   32/  130]
train() client id: f_00008-6-1 loss: 0.713516  [   64/  130]
train() client id: f_00008-6-2 loss: 0.678427  [   96/  130]
train() client id: f_00008-6-3 loss: 0.829105  [  128/  130]
train() client id: f_00008-7-0 loss: 0.713465  [   32/  130]
train() client id: f_00008-7-1 loss: 0.784442  [   64/  130]
train() client id: f_00008-7-2 loss: 0.752424  [   96/  130]
train() client id: f_00008-7-3 loss: 0.594371  [  128/  130]
train() client id: f_00008-8-0 loss: 0.714737  [   32/  130]
train() client id: f_00008-8-1 loss: 0.767030  [   64/  130]
train() client id: f_00008-8-2 loss: 0.666015  [   96/  130]
train() client id: f_00008-8-3 loss: 0.722607  [  128/  130]
train() client id: f_00008-9-0 loss: 0.678293  [   32/  130]
train() client id: f_00008-9-1 loss: 0.789897  [   64/  130]
train() client id: f_00008-9-2 loss: 0.815710  [   96/  130]
train() client id: f_00008-9-3 loss: 0.601637  [  128/  130]
train() client id: f_00008-10-0 loss: 0.763279  [   32/  130]
train() client id: f_00008-10-1 loss: 0.742260  [   64/  130]
train() client id: f_00008-10-2 loss: 0.666901  [   96/  130]
train() client id: f_00008-10-3 loss: 0.682978  [  128/  130]
train() client id: f_00008-11-0 loss: 0.711515  [   32/  130]
train() client id: f_00008-11-1 loss: 0.735646  [   64/  130]
train() client id: f_00008-11-2 loss: 0.674661  [   96/  130]
train() client id: f_00008-11-3 loss: 0.766509  [  128/  130]
train() client id: f_00008-12-0 loss: 0.795184  [   32/  130]
train() client id: f_00008-12-1 loss: 0.738236  [   64/  130]
train() client id: f_00008-12-2 loss: 0.696829  [   96/  130]
train() client id: f_00008-12-3 loss: 0.653863  [  128/  130]
train() client id: f_00009-0-0 loss: 1.318617  [   32/  118]
train() client id: f_00009-0-1 loss: 1.065078  [   64/  118]
train() client id: f_00009-0-2 loss: 0.954185  [   96/  118]
train() client id: f_00009-1-0 loss: 0.880689  [   32/  118]
train() client id: f_00009-1-1 loss: 1.188511  [   64/  118]
train() client id: f_00009-1-2 loss: 1.129835  [   96/  118]
train() client id: f_00009-2-0 loss: 1.038604  [   32/  118]
train() client id: f_00009-2-1 loss: 1.028669  [   64/  118]
train() client id: f_00009-2-2 loss: 0.902605  [   96/  118]
train() client id: f_00009-3-0 loss: 1.105350  [   32/  118]
train() client id: f_00009-3-1 loss: 0.844308  [   64/  118]
train() client id: f_00009-3-2 loss: 0.961506  [   96/  118]
train() client id: f_00009-4-0 loss: 0.911602  [   32/  118]
train() client id: f_00009-4-1 loss: 0.942143  [   64/  118]
train() client id: f_00009-4-2 loss: 0.847079  [   96/  118]
train() client id: f_00009-5-0 loss: 0.819630  [   32/  118]
train() client id: f_00009-5-1 loss: 0.844959  [   64/  118]
train() client id: f_00009-5-2 loss: 0.906937  [   96/  118]
train() client id: f_00009-6-0 loss: 0.898816  [   32/  118]
train() client id: f_00009-6-1 loss: 0.815889  [   64/  118]
train() client id: f_00009-6-2 loss: 0.847842  [   96/  118]
train() client id: f_00009-7-0 loss: 0.928403  [   32/  118]
train() client id: f_00009-7-1 loss: 0.843735  [   64/  118]
train() client id: f_00009-7-2 loss: 0.783432  [   96/  118]
train() client id: f_00009-8-0 loss: 0.877763  [   32/  118]
train() client id: f_00009-8-1 loss: 0.797794  [   64/  118]
train() client id: f_00009-8-2 loss: 0.729773  [   96/  118]
train() client id: f_00009-9-0 loss: 0.751366  [   32/  118]
train() client id: f_00009-9-1 loss: 0.802955  [   64/  118]
train() client id: f_00009-9-2 loss: 0.909188  [   96/  118]
train() client id: f_00009-10-0 loss: 0.728399  [   32/  118]
train() client id: f_00009-10-1 loss: 0.785505  [   64/  118]
train() client id: f_00009-10-2 loss: 0.911775  [   96/  118]
train() client id: f_00009-11-0 loss: 0.718107  [   32/  118]
train() client id: f_00009-11-1 loss: 0.798438  [   64/  118]
train() client id: f_00009-11-2 loss: 0.879420  [   96/  118]
train() client id: f_00009-12-0 loss: 0.810526  [   32/  118]
train() client id: f_00009-12-1 loss: 0.708491  [   64/  118]
train() client id: f_00009-12-2 loss: 0.674333  [   96/  118]
At round 75 accuracy: 0.636604774535809
At round 75 training accuracy: 0.5848423876592891
At round 75 training loss: 0.8209560505990016
gradient difference: 0.4125470519065857
train() client id: f_00000-0-0 loss: 1.029890  [   32/  126]
train() client id: f_00000-0-1 loss: 1.090820  [   64/  126]
train() client id: f_00000-0-2 loss: 1.143428  [   96/  126]
train() client id: f_00000-1-0 loss: 0.964236  [   32/  126]
train() client id: f_00000-1-1 loss: 1.088116  [   64/  126]
train() client id: f_00000-1-2 loss: 0.901424  [   96/  126]
train() client id: f_00000-2-0 loss: 0.969488  [   32/  126]
train() client id: f_00000-2-1 loss: 0.955055  [   64/  126]
train() client id: f_00000-2-2 loss: 0.832214  [   96/  126]
train() client id: f_00000-3-0 loss: 0.902676  [   32/  126]
train() client id: f_00000-3-1 loss: 0.920986  [   64/  126]
train() client id: f_00000-3-2 loss: 0.849609  [   96/  126]
train() client id: f_00000-4-0 loss: 0.707242  [   32/  126]
train() client id: f_00000-4-1 loss: 0.875736  [   64/  126]
train() client id: f_00000-4-2 loss: 0.782605  [   96/  126]
train() client id: f_00000-5-0 loss: 0.707683  [   32/  126]
train() client id: f_00000-5-1 loss: 0.940537  [   64/  126]
train() client id: f_00000-5-2 loss: 0.732804  [   96/  126]
train() client id: f_00000-6-0 loss: 0.642363  [   32/  126]
train() client id: f_00000-6-1 loss: 0.790856  [   64/  126]
train() client id: f_00000-6-2 loss: 0.753034  [   96/  126]
train() client id: f_00000-7-0 loss: 0.770927  [   32/  126]
train() client id: f_00000-7-1 loss: 0.662988  [   64/  126]
train() client id: f_00000-7-2 loss: 0.775752  [   96/  126]
train() client id: f_00000-8-0 loss: 0.750588  [   32/  126]
train() client id: f_00000-8-1 loss: 0.715596  [   64/  126]
train() client id: f_00000-8-2 loss: 0.718814  [   96/  126]
train() client id: f_00000-9-0 loss: 0.682680  [   32/  126]
train() client id: f_00000-9-1 loss: 0.732345  [   64/  126]
train() client id: f_00000-9-2 loss: 0.671050  [   96/  126]
train() client id: f_00000-10-0 loss: 0.744255  [   32/  126]
train() client id: f_00000-10-1 loss: 0.592380  [   64/  126]
train() client id: f_00000-10-2 loss: 0.794562  [   96/  126]
train() client id: f_00000-11-0 loss: 0.667612  [   32/  126]
train() client id: f_00000-11-1 loss: 0.708726  [   64/  126]
train() client id: f_00000-11-2 loss: 0.591243  [   96/  126]
train() client id: f_00000-12-0 loss: 0.691872  [   32/  126]
train() client id: f_00000-12-1 loss: 0.832457  [   64/  126]
train() client id: f_00000-12-2 loss: 0.703695  [   96/  126]
train() client id: f_00001-0-0 loss: 0.423559  [   32/  265]
train() client id: f_00001-0-1 loss: 0.466847  [   64/  265]
train() client id: f_00001-0-2 loss: 0.356460  [   96/  265]
train() client id: f_00001-0-3 loss: 0.524948  [  128/  265]
train() client id: f_00001-0-4 loss: 0.321159  [  160/  265]
train() client id: f_00001-0-5 loss: 0.414200  [  192/  265]
train() client id: f_00001-0-6 loss: 0.345254  [  224/  265]
train() client id: f_00001-0-7 loss: 0.442502  [  256/  265]
train() client id: f_00001-1-0 loss: 0.333993  [   32/  265]
train() client id: f_00001-1-1 loss: 0.358900  [   64/  265]
train() client id: f_00001-1-2 loss: 0.529874  [   96/  265]
train() client id: f_00001-1-3 loss: 0.463336  [  128/  265]
train() client id: f_00001-1-4 loss: 0.372365  [  160/  265]
train() client id: f_00001-1-5 loss: 0.393253  [  192/  265]
train() client id: f_00001-1-6 loss: 0.416313  [  224/  265]
train() client id: f_00001-1-7 loss: 0.427439  [  256/  265]
train() client id: f_00001-2-0 loss: 0.460762  [   32/  265]
train() client id: f_00001-2-1 loss: 0.400645  [   64/  265]
train() client id: f_00001-2-2 loss: 0.358424  [   96/  265]
train() client id: f_00001-2-3 loss: 0.417293  [  128/  265]
train() client id: f_00001-2-4 loss: 0.316309  [  160/  265]
train() client id: f_00001-2-5 loss: 0.377086  [  192/  265]
train() client id: f_00001-2-6 loss: 0.377191  [  224/  265]
train() client id: f_00001-2-7 loss: 0.512388  [  256/  265]
train() client id: f_00001-3-0 loss: 0.332558  [   32/  265]
train() client id: f_00001-3-1 loss: 0.352255  [   64/  265]
train() client id: f_00001-3-2 loss: 0.590901  [   96/  265]
train() client id: f_00001-3-3 loss: 0.341210  [  128/  265]
train() client id: f_00001-3-4 loss: 0.381072  [  160/  265]
train() client id: f_00001-3-5 loss: 0.433546  [  192/  265]
train() client id: f_00001-3-6 loss: 0.414502  [  224/  265]
train() client id: f_00001-3-7 loss: 0.305955  [  256/  265]
train() client id: f_00001-4-0 loss: 0.436301  [   32/  265]
train() client id: f_00001-4-1 loss: 0.412119  [   64/  265]
train() client id: f_00001-4-2 loss: 0.387999  [   96/  265]
train() client id: f_00001-4-3 loss: 0.545890  [  128/  265]
train() client id: f_00001-4-4 loss: 0.307803  [  160/  265]
train() client id: f_00001-4-5 loss: 0.381858  [  192/  265]
train() client id: f_00001-4-6 loss: 0.301630  [  224/  265]
train() client id: f_00001-4-7 loss: 0.407763  [  256/  265]
train() client id: f_00001-5-0 loss: 0.371804  [   32/  265]
train() client id: f_00001-5-1 loss: 0.478866  [   64/  265]
train() client id: f_00001-5-2 loss: 0.440693  [   96/  265]
train() client id: f_00001-5-3 loss: 0.384493  [  128/  265]
train() client id: f_00001-5-4 loss: 0.377748  [  160/  265]
train() client id: f_00001-5-5 loss: 0.354373  [  192/  265]
train() client id: f_00001-5-6 loss: 0.341498  [  224/  265]
train() client id: f_00001-5-7 loss: 0.391043  [  256/  265]
train() client id: f_00001-6-0 loss: 0.329966  [   32/  265]
train() client id: f_00001-6-1 loss: 0.376871  [   64/  265]
train() client id: f_00001-6-2 loss: 0.361294  [   96/  265]
train() client id: f_00001-6-3 loss: 0.402528  [  128/  265]
train() client id: f_00001-6-4 loss: 0.388798  [  160/  265]
train() client id: f_00001-6-5 loss: 0.463680  [  192/  265]
train() client id: f_00001-6-6 loss: 0.360992  [  224/  265]
train() client id: f_00001-6-7 loss: 0.427285  [  256/  265]
train() client id: f_00001-7-0 loss: 0.458076  [   32/  265]
train() client id: f_00001-7-1 loss: 0.364118  [   64/  265]
train() client id: f_00001-7-2 loss: 0.340839  [   96/  265]
train() client id: f_00001-7-3 loss: 0.375884  [  128/  265]
train() client id: f_00001-7-4 loss: 0.544695  [  160/  265]
train() client id: f_00001-7-5 loss: 0.289639  [  192/  265]
train() client id: f_00001-7-6 loss: 0.314507  [  224/  265]
train() client id: f_00001-7-7 loss: 0.416384  [  256/  265]
train() client id: f_00001-8-0 loss: 0.398640  [   32/  265]
train() client id: f_00001-8-1 loss: 0.434107  [   64/  265]
train() client id: f_00001-8-2 loss: 0.297720  [   96/  265]
train() client id: f_00001-8-3 loss: 0.394514  [  128/  265]
train() client id: f_00001-8-4 loss: 0.420115  [  160/  265]
train() client id: f_00001-8-5 loss: 0.281642  [  192/  265]
train() client id: f_00001-8-6 loss: 0.367939  [  224/  265]
train() client id: f_00001-8-7 loss: 0.447237  [  256/  265]
train() client id: f_00001-9-0 loss: 0.537145  [   32/  265]
train() client id: f_00001-9-1 loss: 0.307918  [   64/  265]
train() client id: f_00001-9-2 loss: 0.293654  [   96/  265]
train() client id: f_00001-9-3 loss: 0.559418  [  128/  265]
train() client id: f_00001-9-4 loss: 0.270326  [  160/  265]
train() client id: f_00001-9-5 loss: 0.324154  [  192/  265]
train() client id: f_00001-9-6 loss: 0.504349  [  224/  265]
train() client id: f_00001-9-7 loss: 0.278431  [  256/  265]
train() client id: f_00001-10-0 loss: 0.307048  [   32/  265]
train() client id: f_00001-10-1 loss: 0.413753  [   64/  265]
train() client id: f_00001-10-2 loss: 0.384007  [   96/  265]
train() client id: f_00001-10-3 loss: 0.309117  [  128/  265]
train() client id: f_00001-10-4 loss: 0.528880  [  160/  265]
train() client id: f_00001-10-5 loss: 0.421385  [  192/  265]
train() client id: f_00001-10-6 loss: 0.361356  [  224/  265]
train() client id: f_00001-10-7 loss: 0.356776  [  256/  265]
train() client id: f_00001-11-0 loss: 0.334854  [   32/  265]
train() client id: f_00001-11-1 loss: 0.409729  [   64/  265]
train() client id: f_00001-11-2 loss: 0.343936  [   96/  265]
train() client id: f_00001-11-3 loss: 0.435934  [  128/  265]
train() client id: f_00001-11-4 loss: 0.276877  [  160/  265]
train() client id: f_00001-11-5 loss: 0.350990  [  192/  265]
train() client id: f_00001-11-6 loss: 0.469889  [  224/  265]
train() client id: f_00001-11-7 loss: 0.433885  [  256/  265]
train() client id: f_00001-12-0 loss: 0.288724  [   32/  265]
train() client id: f_00001-12-1 loss: 0.532670  [   64/  265]
train() client id: f_00001-12-2 loss: 0.468594  [   96/  265]
train() client id: f_00001-12-3 loss: 0.288578  [  128/  265]
train() client id: f_00001-12-4 loss: 0.296814  [  160/  265]
train() client id: f_00001-12-5 loss: 0.374921  [  192/  265]
train() client id: f_00001-12-6 loss: 0.327204  [  224/  265]
train() client id: f_00001-12-7 loss: 0.431349  [  256/  265]
train() client id: f_00002-0-0 loss: 1.168307  [   32/  124]
train() client id: f_00002-0-1 loss: 1.125076  [   64/  124]
train() client id: f_00002-0-2 loss: 1.101889  [   96/  124]
train() client id: f_00002-1-0 loss: 1.089772  [   32/  124]
train() client id: f_00002-1-1 loss: 1.043760  [   64/  124]
train() client id: f_00002-1-2 loss: 1.124843  [   96/  124]
train() client id: f_00002-2-0 loss: 1.001421  [   32/  124]
train() client id: f_00002-2-1 loss: 1.145176  [   64/  124]
train() client id: f_00002-2-2 loss: 0.839419  [   96/  124]
train() client id: f_00002-3-0 loss: 1.125612  [   32/  124]
train() client id: f_00002-3-1 loss: 0.983284  [   64/  124]
train() client id: f_00002-3-2 loss: 0.856506  [   96/  124]
train() client id: f_00002-4-0 loss: 0.822264  [   32/  124]
train() client id: f_00002-4-1 loss: 0.885189  [   64/  124]
train() client id: f_00002-4-2 loss: 1.229763  [   96/  124]
train() client id: f_00002-5-0 loss: 0.968126  [   32/  124]
train() client id: f_00002-5-1 loss: 0.968164  [   64/  124]
train() client id: f_00002-5-2 loss: 0.957431  [   96/  124]
train() client id: f_00002-6-0 loss: 0.795323  [   32/  124]
train() client id: f_00002-6-1 loss: 1.097003  [   64/  124]
train() client id: f_00002-6-2 loss: 0.772756  [   96/  124]
train() client id: f_00002-7-0 loss: 0.949337  [   32/  124]
train() client id: f_00002-7-1 loss: 0.857985  [   64/  124]
train() client id: f_00002-7-2 loss: 0.804854  [   96/  124]
train() client id: f_00002-8-0 loss: 0.910860  [   32/  124]
train() client id: f_00002-8-1 loss: 0.854142  [   64/  124]
train() client id: f_00002-8-2 loss: 1.064849  [   96/  124]
train() client id: f_00002-9-0 loss: 0.963372  [   32/  124]
train() client id: f_00002-9-1 loss: 1.059479  [   64/  124]
train() client id: f_00002-9-2 loss: 0.702418  [   96/  124]
train() client id: f_00002-10-0 loss: 0.980419  [   32/  124]
train() client id: f_00002-10-1 loss: 0.828601  [   64/  124]
train() client id: f_00002-10-2 loss: 0.844263  [   96/  124]
train() client id: f_00002-11-0 loss: 0.878136  [   32/  124]
train() client id: f_00002-11-1 loss: 1.059596  [   64/  124]
train() client id: f_00002-11-2 loss: 0.817390  [   96/  124]
train() client id: f_00002-12-0 loss: 0.865946  [   32/  124]
train() client id: f_00002-12-1 loss: 1.061197  [   64/  124]
train() client id: f_00002-12-2 loss: 0.906191  [   96/  124]
train() client id: f_00003-0-0 loss: 0.522433  [   32/   43]
train() client id: f_00003-1-0 loss: 0.667975  [   32/   43]
train() client id: f_00003-2-0 loss: 0.507179  [   32/   43]
train() client id: f_00003-3-0 loss: 0.502343  [   32/   43]
train() client id: f_00003-4-0 loss: 0.492467  [   32/   43]
train() client id: f_00003-5-0 loss: 0.838028  [   32/   43]
train() client id: f_00003-6-0 loss: 0.585672  [   32/   43]
train() client id: f_00003-7-0 loss: 0.509372  [   32/   43]
train() client id: f_00003-8-0 loss: 0.553651  [   32/   43]
train() client id: f_00003-9-0 loss: 0.630131  [   32/   43]
train() client id: f_00003-10-0 loss: 0.516979  [   32/   43]
train() client id: f_00003-11-0 loss: 0.632870  [   32/   43]
train() client id: f_00003-12-0 loss: 0.481589  [   32/   43]
train() client id: f_00004-0-0 loss: 0.783469  [   32/  306]
train() client id: f_00004-0-1 loss: 0.868916  [   64/  306]
train() client id: f_00004-0-2 loss: 0.979290  [   96/  306]
train() client id: f_00004-0-3 loss: 0.886929  [  128/  306]
train() client id: f_00004-0-4 loss: 0.817503  [  160/  306]
train() client id: f_00004-0-5 loss: 0.728953  [  192/  306]
train() client id: f_00004-0-6 loss: 0.751351  [  224/  306]
train() client id: f_00004-0-7 loss: 0.881214  [  256/  306]
train() client id: f_00004-0-8 loss: 0.847374  [  288/  306]
train() client id: f_00004-1-0 loss: 0.843976  [   32/  306]
train() client id: f_00004-1-1 loss: 0.653168  [   64/  306]
train() client id: f_00004-1-2 loss: 0.891773  [   96/  306]
train() client id: f_00004-1-3 loss: 0.788192  [  128/  306]
train() client id: f_00004-1-4 loss: 0.873250  [  160/  306]
train() client id: f_00004-1-5 loss: 0.970275  [  192/  306]
train() client id: f_00004-1-6 loss: 0.957218  [  224/  306]
train() client id: f_00004-1-7 loss: 0.733220  [  256/  306]
train() client id: f_00004-1-8 loss: 0.760951  [  288/  306]
train() client id: f_00004-2-0 loss: 0.783861  [   32/  306]
train() client id: f_00004-2-1 loss: 0.895234  [   64/  306]
train() client id: f_00004-2-2 loss: 0.888761  [   96/  306]
train() client id: f_00004-2-3 loss: 0.877657  [  128/  306]
train() client id: f_00004-2-4 loss: 0.942975  [  160/  306]
train() client id: f_00004-2-5 loss: 0.779230  [  192/  306]
train() client id: f_00004-2-6 loss: 0.928506  [  224/  306]
train() client id: f_00004-2-7 loss: 0.848797  [  256/  306]
train() client id: f_00004-2-8 loss: 0.648783  [  288/  306]
train() client id: f_00004-3-0 loss: 0.780001  [   32/  306]
train() client id: f_00004-3-1 loss: 0.918911  [   64/  306]
train() client id: f_00004-3-2 loss: 0.759105  [   96/  306]
train() client id: f_00004-3-3 loss: 0.621620  [  128/  306]
train() client id: f_00004-3-4 loss: 0.781751  [  160/  306]
train() client id: f_00004-3-5 loss: 0.882640  [  192/  306]
train() client id: f_00004-3-6 loss: 0.739123  [  224/  306]
train() client id: f_00004-3-7 loss: 1.016509  [  256/  306]
train() client id: f_00004-3-8 loss: 0.940959  [  288/  306]
train() client id: f_00004-4-0 loss: 0.789148  [   32/  306]
train() client id: f_00004-4-1 loss: 0.828599  [   64/  306]
train() client id: f_00004-4-2 loss: 0.954108  [   96/  306]
train() client id: f_00004-4-3 loss: 0.892045  [  128/  306]
train() client id: f_00004-4-4 loss: 0.703026  [  160/  306]
train() client id: f_00004-4-5 loss: 0.848169  [  192/  306]
train() client id: f_00004-4-6 loss: 0.847677  [  224/  306]
train() client id: f_00004-4-7 loss: 0.879749  [  256/  306]
train() client id: f_00004-4-8 loss: 0.777657  [  288/  306]
train() client id: f_00004-5-0 loss: 0.834303  [   32/  306]
train() client id: f_00004-5-1 loss: 0.876309  [   64/  306]
train() client id: f_00004-5-2 loss: 0.727652  [   96/  306]
train() client id: f_00004-5-3 loss: 0.811598  [  128/  306]
train() client id: f_00004-5-4 loss: 0.778905  [  160/  306]
train() client id: f_00004-5-5 loss: 0.911379  [  192/  306]
train() client id: f_00004-5-6 loss: 0.909056  [  224/  306]
train() client id: f_00004-5-7 loss: 0.866247  [  256/  306]
train() client id: f_00004-5-8 loss: 0.891853  [  288/  306]
train() client id: f_00004-6-0 loss: 0.823028  [   32/  306]
train() client id: f_00004-6-1 loss: 0.831164  [   64/  306]
train() client id: f_00004-6-2 loss: 0.767099  [   96/  306]
train() client id: f_00004-6-3 loss: 0.795859  [  128/  306]
train() client id: f_00004-6-4 loss: 0.960265  [  160/  306]
train() client id: f_00004-6-5 loss: 0.902736  [  192/  306]
train() client id: f_00004-6-6 loss: 0.817890  [  224/  306]
train() client id: f_00004-6-7 loss: 0.740007  [  256/  306]
train() client id: f_00004-6-8 loss: 0.870889  [  288/  306]
train() client id: f_00004-7-0 loss: 0.807311  [   32/  306]
train() client id: f_00004-7-1 loss: 0.835111  [   64/  306]
train() client id: f_00004-7-2 loss: 0.865861  [   96/  306]
train() client id: f_00004-7-3 loss: 0.717726  [  128/  306]
train() client id: f_00004-7-4 loss: 0.935077  [  160/  306]
train() client id: f_00004-7-5 loss: 0.810602  [  192/  306]
train() client id: f_00004-7-6 loss: 0.862131  [  224/  306]
train() client id: f_00004-7-7 loss: 0.911572  [  256/  306]
train() client id: f_00004-7-8 loss: 0.758655  [  288/  306]
train() client id: f_00004-8-0 loss: 0.815813  [   32/  306]
train() client id: f_00004-8-1 loss: 0.954325  [   64/  306]
train() client id: f_00004-8-2 loss: 0.771576  [   96/  306]
train() client id: f_00004-8-3 loss: 0.923976  [  128/  306]
train() client id: f_00004-8-4 loss: 0.902149  [  160/  306]
train() client id: f_00004-8-5 loss: 0.657370  [  192/  306]
train() client id: f_00004-8-6 loss: 0.819242  [  224/  306]
train() client id: f_00004-8-7 loss: 0.953184  [  256/  306]
train() client id: f_00004-8-8 loss: 0.812449  [  288/  306]
train() client id: f_00004-9-0 loss: 0.910358  [   32/  306]
train() client id: f_00004-9-1 loss: 0.805065  [   64/  306]
train() client id: f_00004-9-2 loss: 0.891748  [   96/  306]
train() client id: f_00004-9-3 loss: 0.717956  [  128/  306]
train() client id: f_00004-9-4 loss: 0.754646  [  160/  306]
train() client id: f_00004-9-5 loss: 0.857019  [  192/  306]
train() client id: f_00004-9-6 loss: 0.854386  [  224/  306]
train() client id: f_00004-9-7 loss: 0.925018  [  256/  306]
train() client id: f_00004-9-8 loss: 0.767819  [  288/  306]
train() client id: f_00004-10-0 loss: 0.970327  [   32/  306]
train() client id: f_00004-10-1 loss: 0.670791  [   64/  306]
train() client id: f_00004-10-2 loss: 0.909054  [   96/  306]
train() client id: f_00004-10-3 loss: 0.838870  [  128/  306]
train() client id: f_00004-10-4 loss: 0.896662  [  160/  306]
train() client id: f_00004-10-5 loss: 0.744902  [  192/  306]
train() client id: f_00004-10-6 loss: 0.844782  [  224/  306]
train() client id: f_00004-10-7 loss: 0.906156  [  256/  306]
train() client id: f_00004-10-8 loss: 0.803397  [  288/  306]
train() client id: f_00004-11-0 loss: 0.978997  [   32/  306]
train() client id: f_00004-11-1 loss: 0.778710  [   64/  306]
train() client id: f_00004-11-2 loss: 0.893896  [   96/  306]
train() client id: f_00004-11-3 loss: 0.764600  [  128/  306]
train() client id: f_00004-11-4 loss: 0.777039  [  160/  306]
train() client id: f_00004-11-5 loss: 0.954201  [  192/  306]
train() client id: f_00004-11-6 loss: 0.829260  [  224/  306]
train() client id: f_00004-11-7 loss: 0.786902  [  256/  306]
train() client id: f_00004-11-8 loss: 0.912250  [  288/  306]
train() client id: f_00004-12-0 loss: 1.020467  [   32/  306]
train() client id: f_00004-12-1 loss: 0.898260  [   64/  306]
train() client id: f_00004-12-2 loss: 0.629706  [   96/  306]
train() client id: f_00004-12-3 loss: 0.867054  [  128/  306]
train() client id: f_00004-12-4 loss: 0.841277  [  160/  306]
train() client id: f_00004-12-5 loss: 0.827700  [  192/  306]
train() client id: f_00004-12-6 loss: 0.994435  [  224/  306]
train() client id: f_00004-12-7 loss: 0.756453  [  256/  306]
train() client id: f_00004-12-8 loss: 0.826518  [  288/  306]
train() client id: f_00005-0-0 loss: 0.575271  [   32/  146]
train() client id: f_00005-0-1 loss: 0.394866  [   64/  146]
train() client id: f_00005-0-2 loss: 0.879382  [   96/  146]
train() client id: f_00005-0-3 loss: 0.442932  [  128/  146]
train() client id: f_00005-1-0 loss: 0.548528  [   32/  146]
train() client id: f_00005-1-1 loss: 0.394531  [   64/  146]
train() client id: f_00005-1-2 loss: 0.683692  [   96/  146]
train() client id: f_00005-1-3 loss: 0.524584  [  128/  146]
train() client id: f_00005-2-0 loss: 0.620481  [   32/  146]
train() client id: f_00005-2-1 loss: 0.557073  [   64/  146]
train() client id: f_00005-2-2 loss: 0.339708  [   96/  146]
train() client id: f_00005-2-3 loss: 0.543754  [  128/  146]
train() client id: f_00005-3-0 loss: 0.423203  [   32/  146]
train() client id: f_00005-3-1 loss: 0.670453  [   64/  146]
train() client id: f_00005-3-2 loss: 0.554623  [   96/  146]
train() client id: f_00005-3-3 loss: 0.557564  [  128/  146]
train() client id: f_00005-4-0 loss: 0.600773  [   32/  146]
train() client id: f_00005-4-1 loss: 0.539205  [   64/  146]
train() client id: f_00005-4-2 loss: 0.405663  [   96/  146]
train() client id: f_00005-4-3 loss: 0.692569  [  128/  146]
train() client id: f_00005-5-0 loss: 0.291542  [   32/  146]
train() client id: f_00005-5-1 loss: 0.461435  [   64/  146]
train() client id: f_00005-5-2 loss: 0.666184  [   96/  146]
train() client id: f_00005-5-3 loss: 0.611521  [  128/  146]
train() client id: f_00005-6-0 loss: 0.274218  [   32/  146]
train() client id: f_00005-6-1 loss: 0.801643  [   64/  146]
train() client id: f_00005-6-2 loss: 0.350734  [   96/  146]
train() client id: f_00005-6-3 loss: 0.652758  [  128/  146]
train() client id: f_00005-7-0 loss: 0.655542  [   32/  146]
train() client id: f_00005-7-1 loss: 0.518589  [   64/  146]
train() client id: f_00005-7-2 loss: 0.559090  [   96/  146]
train() client id: f_00005-7-3 loss: 0.484862  [  128/  146]
train() client id: f_00005-8-0 loss: 0.405585  [   32/  146]
train() client id: f_00005-8-1 loss: 0.618021  [   64/  146]
train() client id: f_00005-8-2 loss: 0.570517  [   96/  146]
train() client id: f_00005-8-3 loss: 0.735686  [  128/  146]
train() client id: f_00005-9-0 loss: 0.408953  [   32/  146]
train() client id: f_00005-9-1 loss: 0.745407  [   64/  146]
train() client id: f_00005-9-2 loss: 0.424303  [   96/  146]
train() client id: f_00005-9-3 loss: 0.369742  [  128/  146]
train() client id: f_00005-10-0 loss: 0.475756  [   32/  146]
train() client id: f_00005-10-1 loss: 0.635392  [   64/  146]
train() client id: f_00005-10-2 loss: 0.687083  [   96/  146]
train() client id: f_00005-10-3 loss: 0.361711  [  128/  146]
train() client id: f_00005-11-0 loss: 0.364208  [   32/  146]
train() client id: f_00005-11-1 loss: 0.597473  [   64/  146]
train() client id: f_00005-11-2 loss: 0.515368  [   96/  146]
train() client id: f_00005-11-3 loss: 0.534785  [  128/  146]
train() client id: f_00005-12-0 loss: 0.484588  [   32/  146]
train() client id: f_00005-12-1 loss: 0.357120  [   64/  146]
train() client id: f_00005-12-2 loss: 0.531942  [   96/  146]
train() client id: f_00005-12-3 loss: 0.655574  [  128/  146]
train() client id: f_00006-0-0 loss: 0.397901  [   32/   54]
train() client id: f_00006-1-0 loss: 0.506157  [   32/   54]
train() client id: f_00006-2-0 loss: 0.436285  [   32/   54]
train() client id: f_00006-3-0 loss: 0.511651  [   32/   54]
train() client id: f_00006-4-0 loss: 0.398857  [   32/   54]
train() client id: f_00006-5-0 loss: 0.453850  [   32/   54]
train() client id: f_00006-6-0 loss: 0.420202  [   32/   54]
train() client id: f_00006-7-0 loss: 0.466331  [   32/   54]
train() client id: f_00006-8-0 loss: 0.484945  [   32/   54]
train() client id: f_00006-9-0 loss: 0.428131  [   32/   54]
train() client id: f_00006-10-0 loss: 0.489301  [   32/   54]
train() client id: f_00006-11-0 loss: 0.519874  [   32/   54]
train() client id: f_00006-12-0 loss: 0.536479  [   32/   54]
train() client id: f_00007-0-0 loss: 0.597268  [   32/  179]
train() client id: f_00007-0-1 loss: 0.430197  [   64/  179]
train() client id: f_00007-0-2 loss: 0.303704  [   96/  179]
train() client id: f_00007-0-3 loss: 0.356755  [  128/  179]
train() client id: f_00007-0-4 loss: 0.608561  [  160/  179]
train() client id: f_00007-1-0 loss: 0.284188  [   32/  179]
train() client id: f_00007-1-1 loss: 0.432388  [   64/  179]
train() client id: f_00007-1-2 loss: 0.746247  [   96/  179]
train() client id: f_00007-1-3 loss: 0.499917  [  128/  179]
train() client id: f_00007-1-4 loss: 0.300662  [  160/  179]
train() client id: f_00007-2-0 loss: 0.509238  [   32/  179]
train() client id: f_00007-2-1 loss: 0.392396  [   64/  179]
train() client id: f_00007-2-2 loss: 0.557689  [   96/  179]
train() client id: f_00007-2-3 loss: 0.326988  [  128/  179]
train() client id: f_00007-2-4 loss: 0.464491  [  160/  179]
train() client id: f_00007-3-0 loss: 0.299114  [   32/  179]
train() client id: f_00007-3-1 loss: 0.485540  [   64/  179]
train() client id: f_00007-3-2 loss: 0.343544  [   96/  179]
train() client id: f_00007-3-3 loss: 0.620031  [  128/  179]
train() client id: f_00007-3-4 loss: 0.422765  [  160/  179]
train() client id: f_00007-4-0 loss: 0.653358  [   32/  179]
train() client id: f_00007-4-1 loss: 0.392834  [   64/  179]
train() client id: f_00007-4-2 loss: 0.290022  [   96/  179]
train() client id: f_00007-4-3 loss: 0.435055  [  128/  179]
train() client id: f_00007-4-4 loss: 0.432626  [  160/  179]
train() client id: f_00007-5-0 loss: 0.469626  [   32/  179]
train() client id: f_00007-5-1 loss: 0.516242  [   64/  179]
train() client id: f_00007-5-2 loss: 0.257671  [   96/  179]
train() client id: f_00007-5-3 loss: 0.432847  [  128/  179]
train() client id: f_00007-5-4 loss: 0.456530  [  160/  179]
train() client id: f_00007-6-0 loss: 0.377762  [   32/  179]
train() client id: f_00007-6-1 loss: 0.334292  [   64/  179]
train() client id: f_00007-6-2 loss: 0.496164  [   96/  179]
train() client id: f_00007-6-3 loss: 0.624508  [  128/  179]
train() client id: f_00007-6-4 loss: 0.287067  [  160/  179]
train() client id: f_00007-7-0 loss: 0.188798  [   32/  179]
train() client id: f_00007-7-1 loss: 0.457576  [   64/  179]
train() client id: f_00007-7-2 loss: 0.506662  [   96/  179]
train() client id: f_00007-7-3 loss: 0.485651  [  128/  179]
train() client id: f_00007-7-4 loss: 0.249271  [  160/  179]
train() client id: f_00007-8-0 loss: 0.468501  [   32/  179]
train() client id: f_00007-8-1 loss: 0.324481  [   64/  179]
train() client id: f_00007-8-2 loss: 0.467824  [   96/  179]
train() client id: f_00007-8-3 loss: 0.420505  [  128/  179]
train() client id: f_00007-8-4 loss: 0.332875  [  160/  179]
train() client id: f_00007-9-0 loss: 0.455595  [   32/  179]
train() client id: f_00007-9-1 loss: 0.343381  [   64/  179]
train() client id: f_00007-9-2 loss: 0.506994  [   96/  179]
train() client id: f_00007-9-3 loss: 0.517442  [  128/  179]
train() client id: f_00007-9-4 loss: 0.236375  [  160/  179]
train() client id: f_00007-10-0 loss: 0.381010  [   32/  179]
train() client id: f_00007-10-1 loss: 0.302473  [   64/  179]
train() client id: f_00007-10-2 loss: 0.226039  [   96/  179]
train() client id: f_00007-10-3 loss: 0.533460  [  128/  179]
train() client id: f_00007-10-4 loss: 0.299342  [  160/  179]
train() client id: f_00007-11-0 loss: 0.356736  [   32/  179]
train() client id: f_00007-11-1 loss: 0.334947  [   64/  179]
train() client id: f_00007-11-2 loss: 0.256511  [   96/  179]
train() client id: f_00007-11-3 loss: 0.573293  [  128/  179]
train() client id: f_00007-11-4 loss: 0.420472  [  160/  179]
train() client id: f_00007-12-0 loss: 0.518137  [   32/  179]
train() client id: f_00007-12-1 loss: 0.354470  [   64/  179]
train() client id: f_00007-12-2 loss: 0.475894  [   96/  179]
train() client id: f_00007-12-3 loss: 0.327696  [  128/  179]
train() client id: f_00007-12-4 loss: 0.229659  [  160/  179]
train() client id: f_00008-0-0 loss: 0.765694  [   32/  130]
train() client id: f_00008-0-1 loss: 0.752349  [   64/  130]
train() client id: f_00008-0-2 loss: 0.782013  [   96/  130]
train() client id: f_00008-0-3 loss: 0.775389  [  128/  130]
train() client id: f_00008-1-0 loss: 0.719481  [   32/  130]
train() client id: f_00008-1-1 loss: 0.738560  [   64/  130]
train() client id: f_00008-1-2 loss: 0.774372  [   96/  130]
train() client id: f_00008-1-3 loss: 0.799033  [  128/  130]
train() client id: f_00008-2-0 loss: 0.788541  [   32/  130]
train() client id: f_00008-2-1 loss: 0.785372  [   64/  130]
train() client id: f_00008-2-2 loss: 0.668410  [   96/  130]
train() client id: f_00008-2-3 loss: 0.820160  [  128/  130]
train() client id: f_00008-3-0 loss: 0.749298  [   32/  130]
train() client id: f_00008-3-1 loss: 0.598879  [   64/  130]
train() client id: f_00008-3-2 loss: 0.877566  [   96/  130]
train() client id: f_00008-3-3 loss: 0.840910  [  128/  130]
train() client id: f_00008-4-0 loss: 0.754955  [   32/  130]
train() client id: f_00008-4-1 loss: 0.805697  [   64/  130]
train() client id: f_00008-4-2 loss: 0.733132  [   96/  130]
train() client id: f_00008-4-3 loss: 0.763696  [  128/  130]
train() client id: f_00008-5-0 loss: 0.775593  [   32/  130]
train() client id: f_00008-5-1 loss: 0.703453  [   64/  130]
train() client id: f_00008-5-2 loss: 0.759827  [   96/  130]
train() client id: f_00008-5-3 loss: 0.782628  [  128/  130]
train() client id: f_00008-6-0 loss: 0.632026  [   32/  130]
train() client id: f_00008-6-1 loss: 0.827955  [   64/  130]
train() client id: f_00008-6-2 loss: 0.801258  [   96/  130]
train() client id: f_00008-6-3 loss: 0.790848  [  128/  130]
train() client id: f_00008-7-0 loss: 0.730125  [   32/  130]
train() client id: f_00008-7-1 loss: 0.746697  [   64/  130]
train() client id: f_00008-7-2 loss: 0.903758  [   96/  130]
train() client id: f_00008-7-3 loss: 0.636688  [  128/  130]
train() client id: f_00008-8-0 loss: 0.827891  [   32/  130]
train() client id: f_00008-8-1 loss: 0.856037  [   64/  130]
train() client id: f_00008-8-2 loss: 0.627478  [   96/  130]
train() client id: f_00008-8-3 loss: 0.685636  [  128/  130]
train() client id: f_00008-9-0 loss: 0.830141  [   32/  130]
train() client id: f_00008-9-1 loss: 0.817349  [   64/  130]
train() client id: f_00008-9-2 loss: 0.649783  [   96/  130]
train() client id: f_00008-9-3 loss: 0.753522  [  128/  130]
train() client id: f_00008-10-0 loss: 0.740190  [   32/  130]
train() client id: f_00008-10-1 loss: 0.940796  [   64/  130]
train() client id: f_00008-10-2 loss: 0.763835  [   96/  130]
train() client id: f_00008-10-3 loss: 0.597615  [  128/  130]
train() client id: f_00008-11-0 loss: 0.803590  [   32/  130]
train() client id: f_00008-11-1 loss: 0.773823  [   64/  130]
train() client id: f_00008-11-2 loss: 0.773614  [   96/  130]
train() client id: f_00008-11-3 loss: 0.656654  [  128/  130]
train() client id: f_00008-12-0 loss: 0.761428  [   32/  130]
train() client id: f_00008-12-1 loss: 0.808692  [   64/  130]
train() client id: f_00008-12-2 loss: 0.719925  [   96/  130]
train() client id: f_00008-12-3 loss: 0.711632  [  128/  130]
train() client id: f_00009-0-0 loss: 1.180491  [   32/  118]
train() client id: f_00009-0-1 loss: 1.123946  [   64/  118]
train() client id: f_00009-0-2 loss: 1.259002  [   96/  118]
train() client id: f_00009-1-0 loss: 1.203162  [   32/  118]
train() client id: f_00009-1-1 loss: 0.921170  [   64/  118]
train() client id: f_00009-1-2 loss: 1.076275  [   96/  118]
train() client id: f_00009-2-0 loss: 1.030315  [   32/  118]
train() client id: f_00009-2-1 loss: 1.016016  [   64/  118]
train() client id: f_00009-2-2 loss: 1.086882  [   96/  118]
train() client id: f_00009-3-0 loss: 0.941347  [   32/  118]
train() client id: f_00009-3-1 loss: 1.141993  [   64/  118]
train() client id: f_00009-3-2 loss: 0.883206  [   96/  118]
train() client id: f_00009-4-0 loss: 0.931755  [   32/  118]
train() client id: f_00009-4-1 loss: 0.961141  [   64/  118]
train() client id: f_00009-4-2 loss: 1.020180  [   96/  118]
train() client id: f_00009-5-0 loss: 0.931060  [   32/  118]
train() client id: f_00009-5-1 loss: 0.898265  [   64/  118]
train() client id: f_00009-5-2 loss: 0.932136  [   96/  118]
train() client id: f_00009-6-0 loss: 0.890138  [   32/  118]
train() client id: f_00009-6-1 loss: 0.870520  [   64/  118]
train() client id: f_00009-6-2 loss: 1.034855  [   96/  118]
train() client id: f_00009-7-0 loss: 0.952787  [   32/  118]
train() client id: f_00009-7-1 loss: 0.833412  [   64/  118]
train() client id: f_00009-7-2 loss: 0.903636  [   96/  118]
train() client id: f_00009-8-0 loss: 0.935366  [   32/  118]
train() client id: f_00009-8-1 loss: 0.953766  [   64/  118]
train() client id: f_00009-8-2 loss: 0.965097  [   96/  118]
train() client id: f_00009-9-0 loss: 0.952980  [   32/  118]
train() client id: f_00009-9-1 loss: 0.913908  [   64/  118]
train() client id: f_00009-9-2 loss: 0.807048  [   96/  118]
train() client id: f_00009-10-0 loss: 0.990075  [   32/  118]
train() client id: f_00009-10-1 loss: 0.753860  [   64/  118]
train() client id: f_00009-10-2 loss: 0.976045  [   96/  118]
train() client id: f_00009-11-0 loss: 1.015262  [   32/  118]
train() client id: f_00009-11-1 loss: 0.805524  [   64/  118]
train() client id: f_00009-11-2 loss: 0.811859  [   96/  118]
train() client id: f_00009-12-0 loss: 0.921498  [   32/  118]
train() client id: f_00009-12-1 loss: 0.732484  [   64/  118]
train() client id: f_00009-12-2 loss: 1.021273  [   96/  118]
At round 76 accuracy: 0.6392572944297082
At round 76 training accuracy: 0.5881958417169685
At round 76 training loss: 0.8270188853389501
gradient difference: 0.3966810405254364
train() client id: f_00000-0-0 loss: 1.175430  [   32/  126]
train() client id: f_00000-0-1 loss: 1.057123  [   64/  126]
train() client id: f_00000-0-2 loss: 0.900667  [   96/  126]
train() client id: f_00000-1-0 loss: 0.826063  [   32/  126]
train() client id: f_00000-1-1 loss: 1.403620  [   64/  126]
train() client id: f_00000-1-2 loss: 0.963750  [   96/  126]
train() client id: f_00000-2-0 loss: 0.934755  [   32/  126]
train() client id: f_00000-2-1 loss: 1.072441  [   64/  126]
train() client id: f_00000-2-2 loss: 0.873294  [   96/  126]
train() client id: f_00000-3-0 loss: 1.097813  [   32/  126]
train() client id: f_00000-3-1 loss: 0.894750  [   64/  126]
train() client id: f_00000-3-2 loss: 0.654453  [   96/  126]
train() client id: f_00000-4-0 loss: 0.886959  [   32/  126]
train() client id: f_00000-4-1 loss: 0.960033  [   64/  126]
train() client id: f_00000-4-2 loss: 0.814748  [   96/  126]
train() client id: f_00000-5-0 loss: 0.872024  [   32/  126]
train() client id: f_00000-5-1 loss: 0.826644  [   64/  126]
train() client id: f_00000-5-2 loss: 0.831255  [   96/  126]
train() client id: f_00000-6-0 loss: 0.732046  [   32/  126]
train() client id: f_00000-6-1 loss: 0.899669  [   64/  126]
train() client id: f_00000-6-2 loss: 0.833770  [   96/  126]
train() client id: f_00000-7-0 loss: 0.791153  [   32/  126]
train() client id: f_00000-7-1 loss: 0.797900  [   64/  126]
train() client id: f_00000-7-2 loss: 0.837178  [   96/  126]
train() client id: f_00000-8-0 loss: 0.774768  [   32/  126]
train() client id: f_00000-8-1 loss: 0.722973  [   64/  126]
train() client id: f_00000-8-2 loss: 0.700035  [   96/  126]
train() client id: f_00000-9-0 loss: 0.677323  [   32/  126]
train() client id: f_00000-9-1 loss: 0.930896  [   64/  126]
train() client id: f_00000-9-2 loss: 0.793234  [   96/  126]
train() client id: f_00000-10-0 loss: 0.723556  [   32/  126]
train() client id: f_00000-10-1 loss: 0.685738  [   64/  126]
train() client id: f_00000-10-2 loss: 0.888431  [   96/  126]
train() client id: f_00000-11-0 loss: 0.823276  [   32/  126]
train() client id: f_00000-11-1 loss: 0.663755  [   64/  126]
train() client id: f_00000-11-2 loss: 0.918472  [   96/  126]
train() client id: f_00000-12-0 loss: 0.720212  [   32/  126]
train() client id: f_00000-12-1 loss: 0.825294  [   64/  126]
train() client id: f_00000-12-2 loss: 0.851325  [   96/  126]
train() client id: f_00001-0-0 loss: 0.479052  [   32/  265]
train() client id: f_00001-0-1 loss: 0.302429  [   64/  265]
train() client id: f_00001-0-2 loss: 0.328884  [   96/  265]
train() client id: f_00001-0-3 loss: 0.295174  [  128/  265]
train() client id: f_00001-0-4 loss: 0.451666  [  160/  265]
train() client id: f_00001-0-5 loss: 0.441658  [  192/  265]
train() client id: f_00001-0-6 loss: 0.400941  [  224/  265]
train() client id: f_00001-0-7 loss: 0.365352  [  256/  265]
train() client id: f_00001-1-0 loss: 0.319211  [   32/  265]
train() client id: f_00001-1-1 loss: 0.296826  [   64/  265]
train() client id: f_00001-1-2 loss: 0.454572  [   96/  265]
train() client id: f_00001-1-3 loss: 0.287673  [  128/  265]
train() client id: f_00001-1-4 loss: 0.363138  [  160/  265]
train() client id: f_00001-1-5 loss: 0.282925  [  192/  265]
train() client id: f_00001-1-6 loss: 0.391830  [  224/  265]
train() client id: f_00001-1-7 loss: 0.595784  [  256/  265]
train() client id: f_00001-2-0 loss: 0.443696  [   32/  265]
train() client id: f_00001-2-1 loss: 0.409217  [   64/  265]
train() client id: f_00001-2-2 loss: 0.271904  [   96/  265]
train() client id: f_00001-2-3 loss: 0.377536  [  128/  265]
train() client id: f_00001-2-4 loss: 0.391031  [  160/  265]
train() client id: f_00001-2-5 loss: 0.385892  [  192/  265]
train() client id: f_00001-2-6 loss: 0.302969  [  224/  265]
train() client id: f_00001-2-7 loss: 0.337487  [  256/  265]
train() client id: f_00001-3-0 loss: 0.301006  [   32/  265]
train() client id: f_00001-3-1 loss: 0.419298  [   64/  265]
train() client id: f_00001-3-2 loss: 0.370775  [   96/  265]
train() client id: f_00001-3-3 loss: 0.552608  [  128/  265]
train() client id: f_00001-3-4 loss: 0.300823  [  160/  265]
train() client id: f_00001-3-5 loss: 0.340045  [  192/  265]
train() client id: f_00001-3-6 loss: 0.297221  [  224/  265]
train() client id: f_00001-3-7 loss: 0.308291  [  256/  265]
train() client id: f_00001-4-0 loss: 0.346022  [   32/  265]
train() client id: f_00001-4-1 loss: 0.454530  [   64/  265]
train() client id: f_00001-4-2 loss: 0.432764  [   96/  265]
train() client id: f_00001-4-3 loss: 0.491685  [  128/  265]
train() client id: f_00001-4-4 loss: 0.308218  [  160/  265]
train() client id: f_00001-4-5 loss: 0.276364  [  192/  265]
train() client id: f_00001-4-6 loss: 0.252136  [  224/  265]
train() client id: f_00001-4-7 loss: 0.257613  [  256/  265]
train() client id: f_00001-5-0 loss: 0.389285  [   32/  265]
train() client id: f_00001-5-1 loss: 0.423546  [   64/  265]
train() client id: f_00001-5-2 loss: 0.282593  [   96/  265]
train() client id: f_00001-5-3 loss: 0.297135  [  128/  265]
train() client id: f_00001-5-4 loss: 0.345553  [  160/  265]
train() client id: f_00001-5-5 loss: 0.321986  [  192/  265]
train() client id: f_00001-5-6 loss: 0.349620  [  224/  265]
train() client id: f_00001-5-7 loss: 0.406165  [  256/  265]
train() client id: f_00001-6-0 loss: 0.345083  [   32/  265]
train() client id: f_00001-6-1 loss: 0.455650  [   64/  265]
train() client id: f_00001-6-2 loss: 0.336174  [   96/  265]
train() client id: f_00001-6-3 loss: 0.352567  [  128/  265]
train() client id: f_00001-6-4 loss: 0.358524  [  160/  265]
train() client id: f_00001-6-5 loss: 0.396868  [  192/  265]
train() client id: f_00001-6-6 loss: 0.256595  [  224/  265]
train() client id: f_00001-6-7 loss: 0.266163  [  256/  265]
train() client id: f_00001-7-0 loss: 0.317940  [   32/  265]
train() client id: f_00001-7-1 loss: 0.311940  [   64/  265]
train() client id: f_00001-7-2 loss: 0.346908  [   96/  265]
train() client id: f_00001-7-3 loss: 0.382313  [  128/  265]
train() client id: f_00001-7-4 loss: 0.380825  [  160/  265]
train() client id: f_00001-7-5 loss: 0.335095  [  192/  265]
train() client id: f_00001-7-6 loss: 0.341413  [  224/  265]
train() client id: f_00001-7-7 loss: 0.346156  [  256/  265]
train() client id: f_00001-8-0 loss: 0.416000  [   32/  265]
train() client id: f_00001-8-1 loss: 0.239137  [   64/  265]
train() client id: f_00001-8-2 loss: 0.294641  [   96/  265]
train() client id: f_00001-8-3 loss: 0.302396  [  128/  265]
train() client id: f_00001-8-4 loss: 0.240317  [  160/  265]
train() client id: f_00001-8-5 loss: 0.239536  [  192/  265]
train() client id: f_00001-8-6 loss: 0.291112  [  224/  265]
train() client id: f_00001-8-7 loss: 0.716562  [  256/  265]
train() client id: f_00001-9-0 loss: 0.292934  [   32/  265]
train() client id: f_00001-9-1 loss: 0.240866  [   64/  265]
train() client id: f_00001-9-2 loss: 0.357160  [   96/  265]
train() client id: f_00001-9-3 loss: 0.250365  [  128/  265]
train() client id: f_00001-9-4 loss: 0.518455  [  160/  265]
train() client id: f_00001-9-5 loss: 0.390041  [  192/  265]
train() client id: f_00001-9-6 loss: 0.380065  [  224/  265]
train() client id: f_00001-9-7 loss: 0.279785  [  256/  265]
train() client id: f_00001-10-0 loss: 0.356673  [   32/  265]
train() client id: f_00001-10-1 loss: 0.352577  [   64/  265]
train() client id: f_00001-10-2 loss: 0.515892  [   96/  265]
train() client id: f_00001-10-3 loss: 0.222775  [  128/  265]
train() client id: f_00001-10-4 loss: 0.496461  [  160/  265]
train() client id: f_00001-10-5 loss: 0.279357  [  192/  265]
train() client id: f_00001-10-6 loss: 0.240362  [  224/  265]
train() client id: f_00001-10-7 loss: 0.256678  [  256/  265]
train() client id: f_00001-11-0 loss: 0.320637  [   32/  265]
train() client id: f_00001-11-1 loss: 0.406350  [   64/  265]
train() client id: f_00001-11-2 loss: 0.363643  [   96/  265]
train() client id: f_00001-11-3 loss: 0.322991  [  128/  265]
train() client id: f_00001-11-4 loss: 0.261847  [  160/  265]
train() client id: f_00001-11-5 loss: 0.273421  [  192/  265]
train() client id: f_00001-11-6 loss: 0.494631  [  224/  265]
train() client id: f_00001-11-7 loss: 0.276393  [  256/  265]
train() client id: f_00001-12-0 loss: 0.474756  [   32/  265]
train() client id: f_00001-12-1 loss: 0.251101  [   64/  265]
train() client id: f_00001-12-2 loss: 0.226202  [   96/  265]
train() client id: f_00001-12-3 loss: 0.375188  [  128/  265]
train() client id: f_00001-12-4 loss: 0.395620  [  160/  265]
train() client id: f_00001-12-5 loss: 0.327267  [  192/  265]
train() client id: f_00001-12-6 loss: 0.401147  [  224/  265]
train() client id: f_00001-12-7 loss: 0.253412  [  256/  265]
train() client id: f_00002-0-0 loss: 1.199028  [   32/  124]
train() client id: f_00002-0-1 loss: 0.900631  [   64/  124]
train() client id: f_00002-0-2 loss: 1.134856  [   96/  124]
train() client id: f_00002-1-0 loss: 1.255138  [   32/  124]
train() client id: f_00002-1-1 loss: 1.186579  [   64/  124]
train() client id: f_00002-1-2 loss: 1.051411  [   96/  124]
train() client id: f_00002-2-0 loss: 1.008622  [   32/  124]
train() client id: f_00002-2-1 loss: 1.020537  [   64/  124]
train() client id: f_00002-2-2 loss: 1.178503  [   96/  124]
train() client id: f_00002-3-0 loss: 1.035397  [   32/  124]
train() client id: f_00002-3-1 loss: 1.277099  [   64/  124]
train() client id: f_00002-3-2 loss: 0.876088  [   96/  124]
train() client id: f_00002-4-0 loss: 1.151324  [   32/  124]
train() client id: f_00002-4-1 loss: 1.063025  [   64/  124]
train() client id: f_00002-4-2 loss: 0.870790  [   96/  124]
train() client id: f_00002-5-0 loss: 1.019354  [   32/  124]
train() client id: f_00002-5-1 loss: 0.938368  [   64/  124]
train() client id: f_00002-5-2 loss: 1.119676  [   96/  124]
train() client id: f_00002-6-0 loss: 0.890625  [   32/  124]
train() client id: f_00002-6-1 loss: 0.847879  [   64/  124]
train() client id: f_00002-6-2 loss: 1.092484  [   96/  124]
train() client id: f_00002-7-0 loss: 1.147139  [   32/  124]
train() client id: f_00002-7-1 loss: 0.893075  [   64/  124]
train() client id: f_00002-7-2 loss: 0.883907  [   96/  124]
train() client id: f_00002-8-0 loss: 1.001374  [   32/  124]
train() client id: f_00002-8-1 loss: 0.882693  [   64/  124]
train() client id: f_00002-8-2 loss: 0.785200  [   96/  124]
train() client id: f_00002-9-0 loss: 0.699923  [   32/  124]
train() client id: f_00002-9-1 loss: 0.827092  [   64/  124]
train() client id: f_00002-9-2 loss: 1.177435  [   96/  124]
train() client id: f_00002-10-0 loss: 0.812519  [   32/  124]
train() client id: f_00002-10-1 loss: 1.022700  [   64/  124]
train() client id: f_00002-10-2 loss: 0.915377  [   96/  124]
train() client id: f_00002-11-0 loss: 1.021893  [   32/  124]
train() client id: f_00002-11-1 loss: 0.849234  [   64/  124]
train() client id: f_00002-11-2 loss: 0.823325  [   96/  124]
train() client id: f_00002-12-0 loss: 0.975426  [   32/  124]
train() client id: f_00002-12-1 loss: 0.952254  [   64/  124]
train() client id: f_00002-12-2 loss: 1.016300  [   96/  124]
train() client id: f_00003-0-0 loss: 0.602833  [   32/   43]
train() client id: f_00003-1-0 loss: 0.757888  [   32/   43]
train() client id: f_00003-2-0 loss: 0.716631  [   32/   43]
train() client id: f_00003-3-0 loss: 0.655268  [   32/   43]
train() client id: f_00003-4-0 loss: 0.693883  [   32/   43]
train() client id: f_00003-5-0 loss: 0.586639  [   32/   43]
train() client id: f_00003-6-0 loss: 0.533648  [   32/   43]
train() client id: f_00003-7-0 loss: 0.844871  [   32/   43]
train() client id: f_00003-8-0 loss: 0.602339  [   32/   43]
train() client id: f_00003-9-0 loss: 0.714868  [   32/   43]
train() client id: f_00003-10-0 loss: 0.714881  [   32/   43]
train() client id: f_00003-11-0 loss: 0.736296  [   32/   43]
train() client id: f_00003-12-0 loss: 0.851607  [   32/   43]
train() client id: f_00004-0-0 loss: 0.770026  [   32/  306]
train() client id: f_00004-0-1 loss: 0.966717  [   64/  306]
train() client id: f_00004-0-2 loss: 0.660630  [   96/  306]
train() client id: f_00004-0-3 loss: 0.848460  [  128/  306]
train() client id: f_00004-0-4 loss: 0.980224  [  160/  306]
train() client id: f_00004-0-5 loss: 0.661774  [  192/  306]
train() client id: f_00004-0-6 loss: 0.710054  [  224/  306]
train() client id: f_00004-0-7 loss: 0.910596  [  256/  306]
train() client id: f_00004-0-8 loss: 0.817737  [  288/  306]
train() client id: f_00004-1-0 loss: 0.937653  [   32/  306]
train() client id: f_00004-1-1 loss: 0.897507  [   64/  306]
train() client id: f_00004-1-2 loss: 0.665297  [   96/  306]
train() client id: f_00004-1-3 loss: 0.769672  [  128/  306]
train() client id: f_00004-1-4 loss: 0.756641  [  160/  306]
train() client id: f_00004-1-5 loss: 0.849829  [  192/  306]
train() client id: f_00004-1-6 loss: 0.823364  [  224/  306]
train() client id: f_00004-1-7 loss: 0.775092  [  256/  306]
train() client id: f_00004-1-8 loss: 0.941925  [  288/  306]
train() client id: f_00004-2-0 loss: 0.738753  [   32/  306]
train() client id: f_00004-2-1 loss: 0.746239  [   64/  306]
train() client id: f_00004-2-2 loss: 0.929320  [   96/  306]
train() client id: f_00004-2-3 loss: 0.783304  [  128/  306]
train() client id: f_00004-2-4 loss: 0.927239  [  160/  306]
train() client id: f_00004-2-5 loss: 0.769162  [  192/  306]
train() client id: f_00004-2-6 loss: 0.742078  [  224/  306]
train() client id: f_00004-2-7 loss: 0.851363  [  256/  306]
train() client id: f_00004-2-8 loss: 0.831747  [  288/  306]
train() client id: f_00004-3-0 loss: 0.777947  [   32/  306]
train() client id: f_00004-3-1 loss: 0.872711  [   64/  306]
train() client id: f_00004-3-2 loss: 0.819092  [   96/  306]
train() client id: f_00004-3-3 loss: 0.709254  [  128/  306]
train() client id: f_00004-3-4 loss: 0.743392  [  160/  306]
train() client id: f_00004-3-5 loss: 0.837690  [  192/  306]
train() client id: f_00004-3-6 loss: 0.930323  [  224/  306]
train() client id: f_00004-3-7 loss: 0.768270  [  256/  306]
train() client id: f_00004-3-8 loss: 0.854955  [  288/  306]
train() client id: f_00004-4-0 loss: 0.771536  [   32/  306]
train() client id: f_00004-4-1 loss: 0.679735  [   64/  306]
train() client id: f_00004-4-2 loss: 0.857607  [   96/  306]
train() client id: f_00004-4-3 loss: 0.850162  [  128/  306]
train() client id: f_00004-4-4 loss: 0.961007  [  160/  306]
train() client id: f_00004-4-5 loss: 0.746958  [  192/  306]
train() client id: f_00004-4-6 loss: 0.765415  [  224/  306]
train() client id: f_00004-4-7 loss: 0.867617  [  256/  306]
train() client id: f_00004-4-8 loss: 0.812960  [  288/  306]
train() client id: f_00004-5-0 loss: 0.952836  [   32/  306]
train() client id: f_00004-5-1 loss: 0.867815  [   64/  306]
train() client id: f_00004-5-2 loss: 0.753470  [   96/  306]
train() client id: f_00004-5-3 loss: 0.759387  [  128/  306]
train() client id: f_00004-5-4 loss: 0.743872  [  160/  306]
train() client id: f_00004-5-5 loss: 0.835170  [  192/  306]
train() client id: f_00004-5-6 loss: 0.779872  [  224/  306]
train() client id: f_00004-5-7 loss: 0.810388  [  256/  306]
train() client id: f_00004-5-8 loss: 0.777686  [  288/  306]
train() client id: f_00004-6-0 loss: 0.901181  [   32/  306]
train() client id: f_00004-6-1 loss: 0.832219  [   64/  306]
train() client id: f_00004-6-2 loss: 0.744133  [   96/  306]
train() client id: f_00004-6-3 loss: 0.964965  [  128/  306]
train() client id: f_00004-6-4 loss: 0.743890  [  160/  306]
train() client id: f_00004-6-5 loss: 0.772571  [  192/  306]
train() client id: f_00004-6-6 loss: 0.791764  [  224/  306]
train() client id: f_00004-6-7 loss: 0.790257  [  256/  306]
train() client id: f_00004-6-8 loss: 0.823785  [  288/  306]
train() client id: f_00004-7-0 loss: 0.733347  [   32/  306]
train() client id: f_00004-7-1 loss: 0.801642  [   64/  306]
train() client id: f_00004-7-2 loss: 0.946912  [   96/  306]
train() client id: f_00004-7-3 loss: 0.847727  [  128/  306]
train() client id: f_00004-7-4 loss: 0.853015  [  160/  306]
train() client id: f_00004-7-5 loss: 0.873185  [  192/  306]
train() client id: f_00004-7-6 loss: 0.829118  [  224/  306]
train() client id: f_00004-7-7 loss: 0.814418  [  256/  306]
train() client id: f_00004-7-8 loss: 0.750554  [  288/  306]
train() client id: f_00004-8-0 loss: 0.863789  [   32/  306]
train() client id: f_00004-8-1 loss: 0.930662  [   64/  306]
train() client id: f_00004-8-2 loss: 0.754413  [   96/  306]
train() client id: f_00004-8-3 loss: 0.858479  [  128/  306]
train() client id: f_00004-8-4 loss: 0.785401  [  160/  306]
train() client id: f_00004-8-5 loss: 0.846295  [  192/  306]
train() client id: f_00004-8-6 loss: 0.852756  [  224/  306]
train() client id: f_00004-8-7 loss: 0.828746  [  256/  306]
train() client id: f_00004-8-8 loss: 0.768549  [  288/  306]
train() client id: f_00004-9-0 loss: 0.822368  [   32/  306]
train() client id: f_00004-9-1 loss: 0.841130  [   64/  306]
train() client id: f_00004-9-2 loss: 0.880530  [   96/  306]
train() client id: f_00004-9-3 loss: 0.787913  [  128/  306]
train() client id: f_00004-9-4 loss: 0.781756  [  160/  306]
train() client id: f_00004-9-5 loss: 0.810158  [  192/  306]
train() client id: f_00004-9-6 loss: 0.798455  [  224/  306]
train() client id: f_00004-9-7 loss: 0.810923  [  256/  306]
train() client id: f_00004-9-8 loss: 0.841656  [  288/  306]
train() client id: f_00004-10-0 loss: 0.748651  [   32/  306]
train() client id: f_00004-10-1 loss: 0.940331  [   64/  306]
train() client id: f_00004-10-2 loss: 0.780063  [   96/  306]
train() client id: f_00004-10-3 loss: 0.776464  [  128/  306]
train() client id: f_00004-10-4 loss: 0.843529  [  160/  306]
train() client id: f_00004-10-5 loss: 0.800843  [  192/  306]
train() client id: f_00004-10-6 loss: 0.892389  [  224/  306]
train() client id: f_00004-10-7 loss: 0.800176  [  256/  306]
train() client id: f_00004-10-8 loss: 0.866835  [  288/  306]
train() client id: f_00004-11-0 loss: 0.718446  [   32/  306]
train() client id: f_00004-11-1 loss: 0.742995  [   64/  306]
train() client id: f_00004-11-2 loss: 0.743951  [   96/  306]
train() client id: f_00004-11-3 loss: 0.781371  [  128/  306]
train() client id: f_00004-11-4 loss: 0.860934  [  160/  306]
train() client id: f_00004-11-5 loss: 0.866052  [  192/  306]
train() client id: f_00004-11-6 loss: 0.835101  [  224/  306]
train() client id: f_00004-11-7 loss: 0.887299  [  256/  306]
train() client id: f_00004-11-8 loss: 0.995910  [  288/  306]
train() client id: f_00004-12-0 loss: 0.715379  [   32/  306]
train() client id: f_00004-12-1 loss: 0.704481  [   64/  306]
train() client id: f_00004-12-2 loss: 0.794060  [   96/  306]
train() client id: f_00004-12-3 loss: 0.806260  [  128/  306]
train() client id: f_00004-12-4 loss: 0.957477  [  160/  306]
train() client id: f_00004-12-5 loss: 0.830993  [  192/  306]
train() client id: f_00004-12-6 loss: 0.840367  [  224/  306]
train() client id: f_00004-12-7 loss: 0.781333  [  256/  306]
train() client id: f_00004-12-8 loss: 0.923378  [  288/  306]
train() client id: f_00005-0-0 loss: 0.727108  [   32/  146]
train() client id: f_00005-0-1 loss: 0.501832  [   64/  146]
train() client id: f_00005-0-2 loss: 0.526875  [   96/  146]
train() client id: f_00005-0-3 loss: 0.373490  [  128/  146]
train() client id: f_00005-1-0 loss: 0.390346  [   32/  146]
train() client id: f_00005-1-1 loss: 0.641671  [   64/  146]
train() client id: f_00005-1-2 loss: 0.557071  [   96/  146]
train() client id: f_00005-1-3 loss: 0.470119  [  128/  146]
train() client id: f_00005-2-0 loss: 0.496625  [   32/  146]
train() client id: f_00005-2-1 loss: 0.850339  [   64/  146]
train() client id: f_00005-2-2 loss: 0.286130  [   96/  146]
train() client id: f_00005-2-3 loss: 0.496155  [  128/  146]
train() client id: f_00005-3-0 loss: 0.522600  [   32/  146]
train() client id: f_00005-3-1 loss: 0.670315  [   64/  146]
train() client id: f_00005-3-2 loss: 0.395035  [   96/  146]
train() client id: f_00005-3-3 loss: 0.377433  [  128/  146]
train() client id: f_00005-4-0 loss: 0.531605  [   32/  146]
train() client id: f_00005-4-1 loss: 0.604361  [   64/  146]
train() client id: f_00005-4-2 loss: 0.557859  [   96/  146]
train() client id: f_00005-4-3 loss: 0.517393  [  128/  146]
train() client id: f_00005-5-0 loss: 0.580162  [   32/  146]
train() client id: f_00005-5-1 loss: 0.524028  [   64/  146]
train() client id: f_00005-5-2 loss: 0.751053  [   96/  146]
train() client id: f_00005-5-3 loss: 0.458412  [  128/  146]
train() client id: f_00005-6-0 loss: 0.459673  [   32/  146]
train() client id: f_00005-6-1 loss: 0.730238  [   64/  146]
train() client id: f_00005-6-2 loss: 0.617299  [   96/  146]
train() client id: f_00005-6-3 loss: 0.316286  [  128/  146]
train() client id: f_00005-7-0 loss: 0.615995  [   32/  146]
train() client id: f_00005-7-1 loss: 0.524041  [   64/  146]
train() client id: f_00005-7-2 loss: 0.542531  [   96/  146]
train() client id: f_00005-7-3 loss: 0.381245  [  128/  146]
train() client id: f_00005-8-0 loss: 0.624390  [   32/  146]
train() client id: f_00005-8-1 loss: 0.414670  [   64/  146]
train() client id: f_00005-8-2 loss: 0.389424  [   96/  146]
train() client id: f_00005-8-3 loss: 0.521778  [  128/  146]
train() client id: f_00005-9-0 loss: 0.332773  [   32/  146]
train() client id: f_00005-9-1 loss: 0.473432  [   64/  146]
train() client id: f_00005-9-2 loss: 0.799340  [   96/  146]
train() client id: f_00005-9-3 loss: 0.594053  [  128/  146]
train() client id: f_00005-10-0 loss: 0.230889  [   32/  146]
train() client id: f_00005-10-1 loss: 0.708001  [   64/  146]
train() client id: f_00005-10-2 loss: 0.689785  [   96/  146]
train() client id: f_00005-10-3 loss: 0.618270  [  128/  146]
train() client id: f_00005-11-0 loss: 0.709322  [   32/  146]
train() client id: f_00005-11-1 loss: 0.349389  [   64/  146]
train() client id: f_00005-11-2 loss: 0.452438  [   96/  146]
train() client id: f_00005-11-3 loss: 0.593859  [  128/  146]
train() client id: f_00005-12-0 loss: 0.561447  [   32/  146]
train() client id: f_00005-12-1 loss: 0.638206  [   64/  146]
train() client id: f_00005-12-2 loss: 0.366340  [   96/  146]
train() client id: f_00005-12-3 loss: 0.624657  [  128/  146]
train() client id: f_00006-0-0 loss: 0.484732  [   32/   54]
train() client id: f_00006-1-0 loss: 0.418909  [   32/   54]
train() client id: f_00006-2-0 loss: 0.440552  [   32/   54]
train() client id: f_00006-3-0 loss: 0.509216  [   32/   54]
train() client id: f_00006-4-0 loss: 0.468395  [   32/   54]
train() client id: f_00006-5-0 loss: 0.468877  [   32/   54]
train() client id: f_00006-6-0 loss: 0.440453  [   32/   54]
train() client id: f_00006-7-0 loss: 0.473147  [   32/   54]
train() client id: f_00006-8-0 loss: 0.492277  [   32/   54]
train() client id: f_00006-9-0 loss: 0.479358  [   32/   54]
train() client id: f_00006-10-0 loss: 0.500647  [   32/   54]
train() client id: f_00006-11-0 loss: 0.370426  [   32/   54]
train() client id: f_00006-12-0 loss: 0.482536  [   32/   54]
train() client id: f_00007-0-0 loss: 0.749418  [   32/  179]
train() client id: f_00007-0-1 loss: 0.794988  [   64/  179]
train() client id: f_00007-0-2 loss: 0.677487  [   96/  179]
train() client id: f_00007-0-3 loss: 0.790467  [  128/  179]
train() client id: f_00007-0-4 loss: 0.624716  [  160/  179]
train() client id: f_00007-1-0 loss: 0.819193  [   32/  179]
train() client id: f_00007-1-1 loss: 0.620517  [   64/  179]
train() client id: f_00007-1-2 loss: 0.758567  [   96/  179]
train() client id: f_00007-1-3 loss: 0.514710  [  128/  179]
train() client id: f_00007-1-4 loss: 0.870345  [  160/  179]
train() client id: f_00007-2-0 loss: 0.664349  [   32/  179]
train() client id: f_00007-2-1 loss: 0.539727  [   64/  179]
train() client id: f_00007-2-2 loss: 0.720980  [   96/  179]
train() client id: f_00007-2-3 loss: 0.766191  [  128/  179]
train() client id: f_00007-2-4 loss: 0.832351  [  160/  179]
train() client id: f_00007-3-0 loss: 0.652338  [   32/  179]
train() client id: f_00007-3-1 loss: 0.763239  [   64/  179]
train() client id: f_00007-3-2 loss: 0.923606  [   96/  179]
train() client id: f_00007-3-3 loss: 0.592589  [  128/  179]
train() client id: f_00007-3-4 loss: 0.550224  [  160/  179]
train() client id: f_00007-4-0 loss: 0.613421  [   32/  179]
train() client id: f_00007-4-1 loss: 1.024714  [   64/  179]
train() client id: f_00007-4-2 loss: 0.599295  [   96/  179]
train() client id: f_00007-4-3 loss: 0.796391  [  128/  179]
train() client id: f_00007-4-4 loss: 0.559127  [  160/  179]
train() client id: f_00007-5-0 loss: 0.637087  [   32/  179]
train() client id: f_00007-5-1 loss: 0.897769  [   64/  179]
train() client id: f_00007-5-2 loss: 0.653537  [   96/  179]
train() client id: f_00007-5-3 loss: 0.533333  [  128/  179]
train() client id: f_00007-5-4 loss: 0.661500  [  160/  179]
train() client id: f_00007-6-0 loss: 0.703630  [   32/  179]
train() client id: f_00007-6-1 loss: 0.554668  [   64/  179]
train() client id: f_00007-6-2 loss: 0.746382  [   96/  179]
train() client id: f_00007-6-3 loss: 0.868534  [  128/  179]
train() client id: f_00007-6-4 loss: 0.588966  [  160/  179]
train() client id: f_00007-7-0 loss: 0.633846  [   32/  179]
train() client id: f_00007-7-1 loss: 0.979188  [   64/  179]
train() client id: f_00007-7-2 loss: 0.646996  [   96/  179]
train() client id: f_00007-7-3 loss: 0.619402  [  128/  179]
train() client id: f_00007-7-4 loss: 0.655403  [  160/  179]
train() client id: f_00007-8-0 loss: 0.504445  [   32/  179]
train() client id: f_00007-8-1 loss: 0.737163  [   64/  179]
train() client id: f_00007-8-2 loss: 0.549315  [   96/  179]
train() client id: f_00007-8-3 loss: 0.681799  [  128/  179]
train() client id: f_00007-8-4 loss: 0.848164  [  160/  179]
train() client id: f_00007-9-0 loss: 0.827707  [   32/  179]
train() client id: f_00007-9-1 loss: 0.549869  [   64/  179]
train() client id: f_00007-9-2 loss: 0.671602  [   96/  179]
train() client id: f_00007-9-3 loss: 0.591106  [  128/  179]
train() client id: f_00007-9-4 loss: 0.564923  [  160/  179]
train() client id: f_00007-10-0 loss: 0.886710  [   32/  179]
train() client id: f_00007-10-1 loss: 0.666875  [   64/  179]
train() client id: f_00007-10-2 loss: 0.598829  [   96/  179]
train() client id: f_00007-10-3 loss: 0.620618  [  128/  179]
train() client id: f_00007-10-4 loss: 0.827223  [  160/  179]
train() client id: f_00007-11-0 loss: 0.805702  [   32/  179]
train() client id: f_00007-11-1 loss: 0.578846  [   64/  179]
train() client id: f_00007-11-2 loss: 0.928514  [   96/  179]
train() client id: f_00007-11-3 loss: 0.520428  [  128/  179]
train() client id: f_00007-11-4 loss: 0.633528  [  160/  179]
train() client id: f_00007-12-0 loss: 0.730539  [   32/  179]
train() client id: f_00007-12-1 loss: 0.804283  [   64/  179]
train() client id: f_00007-12-2 loss: 0.632830  [   96/  179]
train() client id: f_00007-12-3 loss: 0.561984  [  128/  179]
train() client id: f_00007-12-4 loss: 0.703660  [  160/  179]
train() client id: f_00008-0-0 loss: 0.649161  [   32/  130]
train() client id: f_00008-0-1 loss: 0.761973  [   64/  130]
train() client id: f_00008-0-2 loss: 0.893173  [   96/  130]
train() client id: f_00008-0-3 loss: 0.707953  [  128/  130]
train() client id: f_00008-1-0 loss: 0.705816  [   32/  130]
train() client id: f_00008-1-1 loss: 0.720189  [   64/  130]
train() client id: f_00008-1-2 loss: 0.718402  [   96/  130]
train() client id: f_00008-1-3 loss: 0.871413  [  128/  130]
train() client id: f_00008-2-0 loss: 0.693968  [   32/  130]
train() client id: f_00008-2-1 loss: 0.799595  [   64/  130]
train() client id: f_00008-2-2 loss: 0.820043  [   96/  130]
train() client id: f_00008-2-3 loss: 0.695596  [  128/  130]
train() client id: f_00008-3-0 loss: 0.736033  [   32/  130]
train() client id: f_00008-3-1 loss: 0.820761  [   64/  130]
train() client id: f_00008-3-2 loss: 0.726746  [   96/  130]
train() client id: f_00008-3-3 loss: 0.711444  [  128/  130]
train() client id: f_00008-4-0 loss: 0.674997  [   32/  130]
train() client id: f_00008-4-1 loss: 0.822341  [   64/  130]
train() client id: f_00008-4-2 loss: 0.848251  [   96/  130]
train() client id: f_00008-4-3 loss: 0.652403  [  128/  130]
train() client id: f_00008-5-0 loss: 0.708764  [   32/  130]
train() client id: f_00008-5-1 loss: 0.794193  [   64/  130]
train() client id: f_00008-5-2 loss: 0.677292  [   96/  130]
train() client id: f_00008-5-3 loss: 0.777201  [  128/  130]
train() client id: f_00008-6-0 loss: 0.836031  [   32/  130]
train() client id: f_00008-6-1 loss: 0.757800  [   64/  130]
train() client id: f_00008-6-2 loss: 0.747896  [   96/  130]
train() client id: f_00008-6-3 loss: 0.619955  [  128/  130]
train() client id: f_00008-7-0 loss: 0.670228  [   32/  130]
train() client id: f_00008-7-1 loss: 0.786402  [   64/  130]
train() client id: f_00008-7-2 loss: 0.759394  [   96/  130]
train() client id: f_00008-7-3 loss: 0.751281  [  128/  130]
train() client id: f_00008-8-0 loss: 0.774495  [   32/  130]
train() client id: f_00008-8-1 loss: 0.761752  [   64/  130]
train() client id: f_00008-8-2 loss: 0.869063  [   96/  130]
train() client id: f_00008-8-3 loss: 0.579237  [  128/  130]
train() client id: f_00008-9-0 loss: 0.751302  [   32/  130]
train() client id: f_00008-9-1 loss: 0.660136  [   64/  130]
train() client id: f_00008-9-2 loss: 0.785422  [   96/  130]
train() client id: f_00008-9-3 loss: 0.778043  [  128/  130]
train() client id: f_00008-10-0 loss: 0.688878  [   32/  130]
train() client id: f_00008-10-1 loss: 0.793381  [   64/  130]
train() client id: f_00008-10-2 loss: 0.774201  [   96/  130]
train() client id: f_00008-10-3 loss: 0.700830  [  128/  130]
train() client id: f_00008-11-0 loss: 0.798519  [   32/  130]
train() client id: f_00008-11-1 loss: 0.706488  [   64/  130]
train() client id: f_00008-11-2 loss: 0.678727  [   96/  130]
train() client id: f_00008-11-3 loss: 0.792980  [  128/  130]
train() client id: f_00008-12-0 loss: 0.883778  [   32/  130]
train() client id: f_00008-12-1 loss: 0.689462  [   64/  130]
train() client id: f_00008-12-2 loss: 0.733476  [   96/  130]
train() client id: f_00008-12-3 loss: 0.683922  [  128/  130]
train() client id: f_00009-0-0 loss: 0.861402  [   32/  118]
train() client id: f_00009-0-1 loss: 1.130948  [   64/  118]
train() client id: f_00009-0-2 loss: 0.978488  [   96/  118]
train() client id: f_00009-1-0 loss: 0.862197  [   32/  118]
train() client id: f_00009-1-1 loss: 1.049618  [   64/  118]
train() client id: f_00009-1-2 loss: 0.989281  [   96/  118]
train() client id: f_00009-2-0 loss: 0.832948  [   32/  118]
train() client id: f_00009-2-1 loss: 0.860880  [   64/  118]
train() client id: f_00009-2-2 loss: 0.821303  [   96/  118]
train() client id: f_00009-3-0 loss: 0.906032  [   32/  118]
train() client id: f_00009-3-1 loss: 0.922440  [   64/  118]
train() client id: f_00009-3-2 loss: 0.764309  [   96/  118]
train() client id: f_00009-4-0 loss: 0.714077  [   32/  118]
train() client id: f_00009-4-1 loss: 0.944213  [   64/  118]
train() client id: f_00009-4-2 loss: 0.772817  [   96/  118]
train() client id: f_00009-5-0 loss: 0.725109  [   32/  118]
train() client id: f_00009-5-1 loss: 0.700932  [   64/  118]
train() client id: f_00009-5-2 loss: 0.765364  [   96/  118]
train() client id: f_00009-6-0 loss: 0.756756  [   32/  118]
train() client id: f_00009-6-1 loss: 0.778810  [   64/  118]
train() client id: f_00009-6-2 loss: 0.551862  [   96/  118]
train() client id: f_00009-7-0 loss: 0.745652  [   32/  118]
train() client id: f_00009-7-1 loss: 0.835898  [   64/  118]
train() client id: f_00009-7-2 loss: 0.659352  [   96/  118]
train() client id: f_00009-8-0 loss: 0.762808  [   32/  118]
train() client id: f_00009-8-1 loss: 0.700988  [   64/  118]
train() client id: f_00009-8-2 loss: 0.732531  [   96/  118]
train() client id: f_00009-9-0 loss: 0.590815  [   32/  118]
train() client id: f_00009-9-1 loss: 0.713087  [   64/  118]
train() client id: f_00009-9-2 loss: 0.786445  [   96/  118]
train() client id: f_00009-10-0 loss: 0.587047  [   32/  118]
train() client id: f_00009-10-1 loss: 0.775911  [   64/  118]
train() client id: f_00009-10-2 loss: 0.743482  [   96/  118]
train() client id: f_00009-11-0 loss: 0.608580  [   32/  118]
train() client id: f_00009-11-1 loss: 0.592471  [   64/  118]
train() client id: f_00009-11-2 loss: 0.900966  [   96/  118]
train() client id: f_00009-12-0 loss: 0.671277  [   32/  118]
train() client id: f_00009-12-1 loss: 0.691891  [   64/  118]
train() client id: f_00009-12-2 loss: 0.734066  [   96/  118]
At round 77 accuracy: 0.6392572944297082
At round 77 training accuracy: 0.5902079141515761
At round 77 training loss: 0.8180429727144717
gradient difference: 0.46988677978515625
train() client id: f_00000-0-0 loss: 1.309641  [   32/  126]
train() client id: f_00000-0-1 loss: 1.533694  [   64/  126]
train() client id: f_00000-0-2 loss: 1.297670  [   96/  126]
train() client id: f_00000-1-0 loss: 1.202076  [   32/  126]
train() client id: f_00000-1-1 loss: 1.181064  [   64/  126]
train() client id: f_00000-1-2 loss: 1.092626  [   96/  126]
train() client id: f_00000-2-0 loss: 0.978674  [   32/  126]
train() client id: f_00000-2-1 loss: 1.166614  [   64/  126]
train() client id: f_00000-2-2 loss: 0.918664  [   96/  126]
train() client id: f_00000-3-0 loss: 0.943514  [   32/  126]
train() client id: f_00000-3-1 loss: 0.857469  [   64/  126]
train() client id: f_00000-3-2 loss: 0.978167  [   96/  126]
train() client id: f_00000-4-0 loss: 0.856874  [   32/  126]
train() client id: f_00000-4-1 loss: 0.897758  [   64/  126]
train() client id: f_00000-4-2 loss: 0.823169  [   96/  126]
train() client id: f_00000-5-0 loss: 0.715711  [   32/  126]
train() client id: f_00000-5-1 loss: 1.007668  [   64/  126]
train() client id: f_00000-5-2 loss: 0.841455  [   96/  126]
train() client id: f_00000-6-0 loss: 0.879385  [   32/  126]
train() client id: f_00000-6-1 loss: 0.669533  [   64/  126]
train() client id: f_00000-6-2 loss: 0.815127  [   96/  126]
train() client id: f_00000-7-0 loss: 0.781105  [   32/  126]
train() client id: f_00000-7-1 loss: 0.833626  [   64/  126]
train() client id: f_00000-7-2 loss: 0.691009  [   96/  126]
train() client id: f_00000-8-0 loss: 0.669629  [   32/  126]
train() client id: f_00000-8-1 loss: 0.605072  [   64/  126]
train() client id: f_00000-8-2 loss: 0.956553  [   96/  126]
train() client id: f_00000-9-0 loss: 0.726950  [   32/  126]
train() client id: f_00000-9-1 loss: 0.711214  [   64/  126]
train() client id: f_00000-9-2 loss: 0.789385  [   96/  126]
train() client id: f_00000-10-0 loss: 0.622575  [   32/  126]
train() client id: f_00000-10-1 loss: 0.678574  [   64/  126]
train() client id: f_00000-10-2 loss: 0.655548  [   96/  126]
train() client id: f_00000-11-0 loss: 0.775330  [   32/  126]
train() client id: f_00000-11-1 loss: 0.629824  [   64/  126]
train() client id: f_00000-11-2 loss: 0.638717  [   96/  126]
train() client id: f_00000-12-0 loss: 0.721733  [   32/  126]
train() client id: f_00000-12-1 loss: 0.505121  [   64/  126]
train() client id: f_00000-12-2 loss: 0.625304  [   96/  126]
train() client id: f_00001-0-0 loss: 0.384589  [   32/  265]
train() client id: f_00001-0-1 loss: 0.537036  [   64/  265]
train() client id: f_00001-0-2 loss: 0.462463  [   96/  265]
train() client id: f_00001-0-3 loss: 0.696712  [  128/  265]
train() client id: f_00001-0-4 loss: 0.466340  [  160/  265]
train() client id: f_00001-0-5 loss: 0.484262  [  192/  265]
train() client id: f_00001-0-6 loss: 0.610436  [  224/  265]
train() client id: f_00001-0-7 loss: 0.469278  [  256/  265]
train() client id: f_00001-1-0 loss: 0.603162  [   32/  265]
train() client id: f_00001-1-1 loss: 0.644104  [   64/  265]
train() client id: f_00001-1-2 loss: 0.472078  [   96/  265]
train() client id: f_00001-1-3 loss: 0.506074  [  128/  265]
train() client id: f_00001-1-4 loss: 0.524625  [  160/  265]
train() client id: f_00001-1-5 loss: 0.441513  [  192/  265]
train() client id: f_00001-1-6 loss: 0.444031  [  224/  265]
train() client id: f_00001-1-7 loss: 0.418435  [  256/  265]
train() client id: f_00001-2-0 loss: 0.487359  [   32/  265]
train() client id: f_00001-2-1 loss: 0.452007  [   64/  265]
train() client id: f_00001-2-2 loss: 0.585463  [   96/  265]
train() client id: f_00001-2-3 loss: 0.538994  [  128/  265]
train() client id: f_00001-2-4 loss: 0.473206  [  160/  265]
train() client id: f_00001-2-5 loss: 0.490212  [  192/  265]
train() client id: f_00001-2-6 loss: 0.394244  [  224/  265]
train() client id: f_00001-2-7 loss: 0.545233  [  256/  265]
train() client id: f_00001-3-0 loss: 0.489051  [   32/  265]
train() client id: f_00001-3-1 loss: 0.419118  [   64/  265]
train() client id: f_00001-3-2 loss: 0.524953  [   96/  265]
train() client id: f_00001-3-3 loss: 0.460785  [  128/  265]
train() client id: f_00001-3-4 loss: 0.550589  [  160/  265]
train() client id: f_00001-3-5 loss: 0.531206  [  192/  265]
train() client id: f_00001-3-6 loss: 0.435479  [  224/  265]
train() client id: f_00001-3-7 loss: 0.570898  [  256/  265]
train() client id: f_00001-4-0 loss: 0.457727  [   32/  265]
train() client id: f_00001-4-1 loss: 0.425761  [   64/  265]
train() client id: f_00001-4-2 loss: 0.479242  [   96/  265]
train() client id: f_00001-4-3 loss: 0.516173  [  128/  265]
train() client id: f_00001-4-4 loss: 0.476450  [  160/  265]
train() client id: f_00001-4-5 loss: 0.605422  [  192/  265]
train() client id: f_00001-4-6 loss: 0.566231  [  224/  265]
train() client id: f_00001-4-7 loss: 0.443703  [  256/  265]
train() client id: f_00001-5-0 loss: 0.384509  [   32/  265]
train() client id: f_00001-5-1 loss: 0.515765  [   64/  265]
train() client id: f_00001-5-2 loss: 0.554572  [   96/  265]
train() client id: f_00001-5-3 loss: 0.505884  [  128/  265]
train() client id: f_00001-5-4 loss: 0.539535  [  160/  265]
train() client id: f_00001-5-5 loss: 0.399136  [  192/  265]
train() client id: f_00001-5-6 loss: 0.448080  [  224/  265]
train() client id: f_00001-5-7 loss: 0.606932  [  256/  265]
train() client id: f_00001-6-0 loss: 0.429569  [   32/  265]
train() client id: f_00001-6-1 loss: 0.541907  [   64/  265]
train() client id: f_00001-6-2 loss: 0.395687  [   96/  265]
train() client id: f_00001-6-3 loss: 0.492532  [  128/  265]
train() client id: f_00001-6-4 loss: 0.536179  [  160/  265]
train() client id: f_00001-6-5 loss: 0.489336  [  192/  265]
train() client id: f_00001-6-6 loss: 0.507059  [  224/  265]
train() client id: f_00001-6-7 loss: 0.564834  [  256/  265]
train() client id: f_00001-7-0 loss: 0.402295  [   32/  265]
train() client id: f_00001-7-1 loss: 0.440198  [   64/  265]
train() client id: f_00001-7-2 loss: 0.537764  [   96/  265]
train() client id: f_00001-7-3 loss: 0.557648  [  128/  265]
train() client id: f_00001-7-4 loss: 0.509021  [  160/  265]
train() client id: f_00001-7-5 loss: 0.388682  [  192/  265]
train() client id: f_00001-7-6 loss: 0.406212  [  224/  265]
train() client id: f_00001-7-7 loss: 0.575846  [  256/  265]
train() client id: f_00001-8-0 loss: 0.559298  [   32/  265]
train() client id: f_00001-8-1 loss: 0.413342  [   64/  265]
train() client id: f_00001-8-2 loss: 0.392494  [   96/  265]
train() client id: f_00001-8-3 loss: 0.431278  [  128/  265]
train() client id: f_00001-8-4 loss: 0.484120  [  160/  265]
train() client id: f_00001-8-5 loss: 0.586142  [  192/  265]
train() client id: f_00001-8-6 loss: 0.485811  [  224/  265]
train() client id: f_00001-8-7 loss: 0.575194  [  256/  265]
train() client id: f_00001-9-0 loss: 0.491877  [   32/  265]
train() client id: f_00001-9-1 loss: 0.399561  [   64/  265]
train() client id: f_00001-9-2 loss: 0.532870  [   96/  265]
train() client id: f_00001-9-3 loss: 0.513389  [  128/  265]
train() client id: f_00001-9-4 loss: 0.488933  [  160/  265]
train() client id: f_00001-9-5 loss: 0.424213  [  192/  265]
train() client id: f_00001-9-6 loss: 0.519057  [  224/  265]
train() client id: f_00001-9-7 loss: 0.460316  [  256/  265]
train() client id: f_00001-10-0 loss: 0.470333  [   32/  265]
train() client id: f_00001-10-1 loss: 0.431953  [   64/  265]
train() client id: f_00001-10-2 loss: 0.431715  [   96/  265]
train() client id: f_00001-10-3 loss: 0.471011  [  128/  265]
train() client id: f_00001-10-4 loss: 0.475751  [  160/  265]
train() client id: f_00001-10-5 loss: 0.541885  [  192/  265]
train() client id: f_00001-10-6 loss: 0.613436  [  224/  265]
train() client id: f_00001-10-7 loss: 0.402357  [  256/  265]
train() client id: f_00001-11-0 loss: 0.520418  [   32/  265]
train() client id: f_00001-11-1 loss: 0.398737  [   64/  265]
train() client id: f_00001-11-2 loss: 0.408123  [   96/  265]
train() client id: f_00001-11-3 loss: 0.528411  [  128/  265]
train() client id: f_00001-11-4 loss: 0.505198  [  160/  265]
train() client id: f_00001-11-5 loss: 0.521399  [  192/  265]
train() client id: f_00001-11-6 loss: 0.546819  [  224/  265]
train() client id: f_00001-11-7 loss: 0.525026  [  256/  265]
train() client id: f_00001-12-0 loss: 0.593515  [   32/  265]
train() client id: f_00001-12-1 loss: 0.394268  [   64/  265]
train() client id: f_00001-12-2 loss: 0.536317  [   96/  265]
train() client id: f_00001-12-3 loss: 0.578378  [  128/  265]
train() client id: f_00001-12-4 loss: 0.401006  [  160/  265]
train() client id: f_00001-12-5 loss: 0.602858  [  192/  265]
train() client id: f_00001-12-6 loss: 0.392736  [  224/  265]
train() client id: f_00001-12-7 loss: 0.450038  [  256/  265]
train() client id: f_00002-0-0 loss: 1.238067  [   32/  124]
train() client id: f_00002-0-1 loss: 0.932947  [   64/  124]
train() client id: f_00002-0-2 loss: 1.128445  [   96/  124]
train() client id: f_00002-1-0 loss: 0.824288  [   32/  124]
train() client id: f_00002-1-1 loss: 1.166313  [   64/  124]
train() client id: f_00002-1-2 loss: 1.102758  [   96/  124]
train() client id: f_00002-2-0 loss: 0.940024  [   32/  124]
train() client id: f_00002-2-1 loss: 1.032986  [   64/  124]
train() client id: f_00002-2-2 loss: 1.018587  [   96/  124]
train() client id: f_00002-3-0 loss: 1.170987  [   32/  124]
train() client id: f_00002-3-1 loss: 0.836084  [   64/  124]
train() client id: f_00002-3-2 loss: 0.776481  [   96/  124]
train() client id: f_00002-4-0 loss: 1.004097  [   32/  124]
train() client id: f_00002-4-1 loss: 0.777271  [   64/  124]
train() client id: f_00002-4-2 loss: 1.120138  [   96/  124]
train() client id: f_00002-5-0 loss: 1.065105  [   32/  124]
train() client id: f_00002-5-1 loss: 0.837199  [   64/  124]
train() client id: f_00002-5-2 loss: 0.856534  [   96/  124]
train() client id: f_00002-6-0 loss: 0.971922  [   32/  124]
train() client id: f_00002-6-1 loss: 0.763966  [   64/  124]
train() client id: f_00002-6-2 loss: 1.041225  [   96/  124]
train() client id: f_00002-7-0 loss: 0.722891  [   32/  124]
train() client id: f_00002-7-1 loss: 0.960651  [   64/  124]
train() client id: f_00002-7-2 loss: 0.888858  [   96/  124]
train() client id: f_00002-8-0 loss: 0.945185  [   32/  124]
train() client id: f_00002-8-1 loss: 0.775648  [   64/  124]
train() client id: f_00002-8-2 loss: 1.027377  [   96/  124]
train() client id: f_00002-9-0 loss: 0.866069  [   32/  124]
train() client id: f_00002-9-1 loss: 0.890459  [   64/  124]
train() client id: f_00002-9-2 loss: 0.810098  [   96/  124]
train() client id: f_00002-10-0 loss: 0.723634  [   32/  124]
train() client id: f_00002-10-1 loss: 0.872052  [   64/  124]
train() client id: f_00002-10-2 loss: 0.750831  [   96/  124]
train() client id: f_00002-11-0 loss: 0.807976  [   32/  124]
train() client id: f_00002-11-1 loss: 0.899341  [   64/  124]
train() client id: f_00002-11-2 loss: 0.793971  [   96/  124]
train() client id: f_00002-12-0 loss: 0.583833  [   32/  124]
train() client id: f_00002-12-1 loss: 1.082600  [   64/  124]
train() client id: f_00002-12-2 loss: 0.935653  [   96/  124]
train() client id: f_00003-0-0 loss: 0.415453  [   32/   43]
train() client id: f_00003-1-0 loss: 0.415017  [   32/   43]
train() client id: f_00003-2-0 loss: 0.360325  [   32/   43]
train() client id: f_00003-3-0 loss: 0.614124  [   32/   43]
train() client id: f_00003-4-0 loss: 0.281687  [   32/   43]
train() client id: f_00003-5-0 loss: 0.445093  [   32/   43]
train() client id: f_00003-6-0 loss: 0.282298  [   32/   43]
train() client id: f_00003-7-0 loss: 0.691251  [   32/   43]
train() client id: f_00003-8-0 loss: 0.536406  [   32/   43]
train() client id: f_00003-9-0 loss: 0.512861  [   32/   43]
train() client id: f_00003-10-0 loss: 0.484805  [   32/   43]
train() client id: f_00003-11-0 loss: 0.453756  [   32/   43]
train() client id: f_00003-12-0 loss: 0.380089  [   32/   43]
train() client id: f_00004-0-0 loss: 0.858581  [   32/  306]
train() client id: f_00004-0-1 loss: 0.695275  [   64/  306]
train() client id: f_00004-0-2 loss: 0.573749  [   96/  306]
train() client id: f_00004-0-3 loss: 0.719352  [  128/  306]
train() client id: f_00004-0-4 loss: 0.773479  [  160/  306]
train() client id: f_00004-0-5 loss: 0.750672  [  192/  306]
train() client id: f_00004-0-6 loss: 0.634772  [  224/  306]
train() client id: f_00004-0-7 loss: 0.716787  [  256/  306]
train() client id: f_00004-0-8 loss: 0.689706  [  288/  306]
train() client id: f_00004-1-0 loss: 0.951916  [   32/  306]
train() client id: f_00004-1-1 loss: 0.615282  [   64/  306]
train() client id: f_00004-1-2 loss: 0.776667  [   96/  306]
train() client id: f_00004-1-3 loss: 0.577296  [  128/  306]
train() client id: f_00004-1-4 loss: 0.583004  [  160/  306]
train() client id: f_00004-1-5 loss: 0.703679  [  192/  306]
train() client id: f_00004-1-6 loss: 0.680514  [  224/  306]
train() client id: f_00004-1-7 loss: 0.732112  [  256/  306]
train() client id: f_00004-1-8 loss: 0.721184  [  288/  306]
train() client id: f_00004-2-0 loss: 0.613277  [   32/  306]
train() client id: f_00004-2-1 loss: 0.643138  [   64/  306]
train() client id: f_00004-2-2 loss: 0.700261  [   96/  306]
train() client id: f_00004-2-3 loss: 0.793109  [  128/  306]
train() client id: f_00004-2-4 loss: 0.706534  [  160/  306]
train() client id: f_00004-2-5 loss: 0.600543  [  192/  306]
train() client id: f_00004-2-6 loss: 0.763342  [  224/  306]
train() client id: f_00004-2-7 loss: 0.725518  [  256/  306]
train() client id: f_00004-2-8 loss: 0.800651  [  288/  306]
train() client id: f_00004-3-0 loss: 0.689975  [   32/  306]
train() client id: f_00004-3-1 loss: 0.780008  [   64/  306]
train() client id: f_00004-3-2 loss: 0.700495  [   96/  306]
train() client id: f_00004-3-3 loss: 0.585362  [  128/  306]
train() client id: f_00004-3-4 loss: 0.730190  [  160/  306]
train() client id: f_00004-3-5 loss: 0.703524  [  192/  306]
train() client id: f_00004-3-6 loss: 0.763817  [  224/  306]
train() client id: f_00004-3-7 loss: 0.690642  [  256/  306]
train() client id: f_00004-3-8 loss: 0.770731  [  288/  306]
train() client id: f_00004-4-0 loss: 0.672529  [   32/  306]
train() client id: f_00004-4-1 loss: 0.650718  [   64/  306]
train() client id: f_00004-4-2 loss: 0.623039  [   96/  306]
train() client id: f_00004-4-3 loss: 0.643849  [  128/  306]
train() client id: f_00004-4-4 loss: 0.719015  [  160/  306]
train() client id: f_00004-4-5 loss: 0.749904  [  192/  306]
train() client id: f_00004-4-6 loss: 0.854466  [  224/  306]
train() client id: f_00004-4-7 loss: 0.703779  [  256/  306]
train() client id: f_00004-4-8 loss: 0.769960  [  288/  306]
train() client id: f_00004-5-0 loss: 0.775903  [   32/  306]
train() client id: f_00004-5-1 loss: 0.853694  [   64/  306]
train() client id: f_00004-5-2 loss: 0.729944  [   96/  306]
train() client id: f_00004-5-3 loss: 0.692600  [  128/  306]
train() client id: f_00004-5-4 loss: 0.679566  [  160/  306]
train() client id: f_00004-5-5 loss: 0.582078  [  192/  306]
train() client id: f_00004-5-6 loss: 0.754905  [  224/  306]
train() client id: f_00004-5-7 loss: 0.641809  [  256/  306]
train() client id: f_00004-5-8 loss: 0.711989  [  288/  306]
train() client id: f_00004-6-0 loss: 0.721307  [   32/  306]
train() client id: f_00004-6-1 loss: 0.638827  [   64/  306]
train() client id: f_00004-6-2 loss: 0.708599  [   96/  306]
train() client id: f_00004-6-3 loss: 0.700912  [  128/  306]
train() client id: f_00004-6-4 loss: 0.787559  [  160/  306]
train() client id: f_00004-6-5 loss: 0.670294  [  192/  306]
train() client id: f_00004-6-6 loss: 0.608427  [  224/  306]
train() client id: f_00004-6-7 loss: 0.814732  [  256/  306]
train() client id: f_00004-6-8 loss: 0.716012  [  288/  306]
train() client id: f_00004-7-0 loss: 0.654393  [   32/  306]
train() client id: f_00004-7-1 loss: 0.770721  [   64/  306]
train() client id: f_00004-7-2 loss: 0.628181  [   96/  306]
train() client id: f_00004-7-3 loss: 0.802365  [  128/  306]
train() client id: f_00004-7-4 loss: 0.636120  [  160/  306]
train() client id: f_00004-7-5 loss: 0.827836  [  192/  306]
train() client id: f_00004-7-6 loss: 0.676543  [  224/  306]
train() client id: f_00004-7-7 loss: 0.726955  [  256/  306]
train() client id: f_00004-7-8 loss: 0.623390  [  288/  306]
train() client id: f_00004-8-0 loss: 0.659649  [   32/  306]
train() client id: f_00004-8-1 loss: 0.807886  [   64/  306]
train() client id: f_00004-8-2 loss: 0.710765  [   96/  306]
train() client id: f_00004-8-3 loss: 0.701575  [  128/  306]
train() client id: f_00004-8-4 loss: 0.723676  [  160/  306]
train() client id: f_00004-8-5 loss: 0.602320  [  192/  306]
train() client id: f_00004-8-6 loss: 0.513886  [  224/  306]
train() client id: f_00004-8-7 loss: 0.853261  [  256/  306]
train() client id: f_00004-8-8 loss: 0.691297  [  288/  306]
train() client id: f_00004-9-0 loss: 0.613232  [   32/  306]
train() client id: f_00004-9-1 loss: 0.782399  [   64/  306]
train() client id: f_00004-9-2 loss: 0.714771  [   96/  306]
train() client id: f_00004-9-3 loss: 0.707914  [  128/  306]
train() client id: f_00004-9-4 loss: 0.650847  [  160/  306]
train() client id: f_00004-9-5 loss: 0.724155  [  192/  306]
train() client id: f_00004-9-6 loss: 0.664078  [  224/  306]
train() client id: f_00004-9-7 loss: 0.735427  [  256/  306]
train() client id: f_00004-9-8 loss: 0.775167  [  288/  306]
train() client id: f_00004-10-0 loss: 0.761003  [   32/  306]
train() client id: f_00004-10-1 loss: 0.604405  [   64/  306]
train() client id: f_00004-10-2 loss: 0.716032  [   96/  306]
train() client id: f_00004-10-3 loss: 0.557102  [  128/  306]
train() client id: f_00004-10-4 loss: 0.663421  [  160/  306]
train() client id: f_00004-10-5 loss: 0.696100  [  192/  306]
train() client id: f_00004-10-6 loss: 0.854682  [  224/  306]
train() client id: f_00004-10-7 loss: 0.738053  [  256/  306]
train() client id: f_00004-10-8 loss: 0.708485  [  288/  306]
train() client id: f_00004-11-0 loss: 0.634738  [   32/  306]
train() client id: f_00004-11-1 loss: 0.661349  [   64/  306]
train() client id: f_00004-11-2 loss: 0.699846  [   96/  306]
train() client id: f_00004-11-3 loss: 0.652794  [  128/  306]
train() client id: f_00004-11-4 loss: 0.767449  [  160/  306]
train() client id: f_00004-11-5 loss: 0.713494  [  192/  306]
train() client id: f_00004-11-6 loss: 0.705558  [  224/  306]
train() client id: f_00004-11-7 loss: 0.728673  [  256/  306]
train() client id: f_00004-11-8 loss: 0.719717  [  288/  306]
train() client id: f_00004-12-0 loss: 0.677340  [   32/  306]
train() client id: f_00004-12-1 loss: 0.561369  [   64/  306]
train() client id: f_00004-12-2 loss: 0.745340  [   96/  306]
train() client id: f_00004-12-3 loss: 0.752641  [  128/  306]
train() client id: f_00004-12-4 loss: 0.612400  [  160/  306]
train() client id: f_00004-12-5 loss: 0.823968  [  192/  306]
train() client id: f_00004-12-6 loss: 0.713037  [  224/  306]
train() client id: f_00004-12-7 loss: 0.753427  [  256/  306]
train() client id: f_00004-12-8 loss: 0.740925  [  288/  306]
train() client id: f_00005-0-0 loss: 0.660814  [   32/  146]
train() client id: f_00005-0-1 loss: 0.598790  [   64/  146]
train() client id: f_00005-0-2 loss: 0.447910  [   96/  146]
train() client id: f_00005-0-3 loss: 0.503544  [  128/  146]
train() client id: f_00005-1-0 loss: 0.318132  [   32/  146]
train() client id: f_00005-1-1 loss: 0.835334  [   64/  146]
train() client id: f_00005-1-2 loss: 0.555477  [   96/  146]
train() client id: f_00005-1-3 loss: 0.584361  [  128/  146]
train() client id: f_00005-2-0 loss: 0.546070  [   32/  146]
train() client id: f_00005-2-1 loss: 0.556331  [   64/  146]
train() client id: f_00005-2-2 loss: 0.758344  [   96/  146]
train() client id: f_00005-2-3 loss: 0.434022  [  128/  146]
train() client id: f_00005-3-0 loss: 0.651123  [   32/  146]
train() client id: f_00005-3-1 loss: 0.414051  [   64/  146]
train() client id: f_00005-3-2 loss: 0.470519  [   96/  146]
train() client id: f_00005-3-3 loss: 0.591914  [  128/  146]
train() client id: f_00005-4-0 loss: 0.677269  [   32/  146]
train() client id: f_00005-4-1 loss: 0.567847  [   64/  146]
train() client id: f_00005-4-2 loss: 0.735454  [   96/  146]
train() client id: f_00005-4-3 loss: 0.334738  [  128/  146]
train() client id: f_00005-5-0 loss: 0.626068  [   32/  146]
train() client id: f_00005-5-1 loss: 0.497687  [   64/  146]
train() client id: f_00005-5-2 loss: 0.917395  [   96/  146]
train() client id: f_00005-5-3 loss: 0.302566  [  128/  146]
train() client id: f_00005-6-0 loss: 0.534849  [   32/  146]
train() client id: f_00005-6-1 loss: 0.660787  [   64/  146]
train() client id: f_00005-6-2 loss: 0.393202  [   96/  146]
train() client id: f_00005-6-3 loss: 0.661201  [  128/  146]
train() client id: f_00005-7-0 loss: 0.667292  [   32/  146]
train() client id: f_00005-7-1 loss: 0.343911  [   64/  146]
train() client id: f_00005-7-2 loss: 0.587985  [   96/  146]
train() client id: f_00005-7-3 loss: 0.750913  [  128/  146]
train() client id: f_00005-8-0 loss: 0.519390  [   32/  146]
train() client id: f_00005-8-1 loss: 0.345726  [   64/  146]
train() client id: f_00005-8-2 loss: 0.476548  [   96/  146]
train() client id: f_00005-8-3 loss: 0.843307  [  128/  146]
train() client id: f_00005-9-0 loss: 0.476519  [   32/  146]
train() client id: f_00005-9-1 loss: 0.490387  [   64/  146]
train() client id: f_00005-9-2 loss: 0.285744  [   96/  146]
train() client id: f_00005-9-3 loss: 1.060390  [  128/  146]
train() client id: f_00005-10-0 loss: 0.642491  [   32/  146]
train() client id: f_00005-10-1 loss: 0.348150  [   64/  146]
train() client id: f_00005-10-2 loss: 0.515534  [   96/  146]
train() client id: f_00005-10-3 loss: 0.665585  [  128/  146]
train() client id: f_00005-11-0 loss: 0.400730  [   32/  146]
train() client id: f_00005-11-1 loss: 0.825849  [   64/  146]
train() client id: f_00005-11-2 loss: 0.441831  [   96/  146]
train() client id: f_00005-11-3 loss: 0.605409  [  128/  146]
train() client id: f_00005-12-0 loss: 0.540318  [   32/  146]
train() client id: f_00005-12-1 loss: 0.514101  [   64/  146]
train() client id: f_00005-12-2 loss: 0.394846  [   96/  146]
train() client id: f_00005-12-3 loss: 0.772778  [  128/  146]
train() client id: f_00006-0-0 loss: 0.496040  [   32/   54]
train() client id: f_00006-1-0 loss: 0.492943  [   32/   54]
train() client id: f_00006-2-0 loss: 0.446169  [   32/   54]
train() client id: f_00006-3-0 loss: 0.440973  [   32/   54]
train() client id: f_00006-4-0 loss: 0.440204  [   32/   54]
train() client id: f_00006-5-0 loss: 0.394068  [   32/   54]
train() client id: f_00006-6-0 loss: 0.451115  [   32/   54]
train() client id: f_00006-7-0 loss: 0.412893  [   32/   54]
train() client id: f_00006-8-0 loss: 0.476724  [   32/   54]
train() client id: f_00006-9-0 loss: 0.431601  [   32/   54]
train() client id: f_00006-10-0 loss: 0.419554  [   32/   54]
train() client id: f_00006-11-0 loss: 0.437057  [   32/   54]
train() client id: f_00006-12-0 loss: 0.495231  [   32/   54]
train() client id: f_00007-0-0 loss: 0.752438  [   32/  179]
train() client id: f_00007-0-1 loss: 0.561310  [   64/  179]
train() client id: f_00007-0-2 loss: 0.486161  [   96/  179]
train() client id: f_00007-0-3 loss: 0.563751  [  128/  179]
train() client id: f_00007-0-4 loss: 0.613013  [  160/  179]
train() client id: f_00007-1-0 loss: 0.612836  [   32/  179]
train() client id: f_00007-1-1 loss: 0.577118  [   64/  179]
train() client id: f_00007-1-2 loss: 0.374025  [   96/  179]
train() client id: f_00007-1-3 loss: 0.384661  [  128/  179]
train() client id: f_00007-1-4 loss: 0.975613  [  160/  179]
train() client id: f_00007-2-0 loss: 0.696767  [   32/  179]
train() client id: f_00007-2-1 loss: 0.481158  [   64/  179]
train() client id: f_00007-2-2 loss: 0.685212  [   96/  179]
train() client id: f_00007-2-3 loss: 0.628849  [  128/  179]
train() client id: f_00007-2-4 loss: 0.416226  [  160/  179]
train() client id: f_00007-3-0 loss: 0.385286  [   32/  179]
train() client id: f_00007-3-1 loss: 0.599697  [   64/  179]
train() client id: f_00007-3-2 loss: 0.710370  [   96/  179]
train() client id: f_00007-3-3 loss: 0.483489  [  128/  179]
train() client id: f_00007-3-4 loss: 0.648126  [  160/  179]
train() client id: f_00007-4-0 loss: 0.523271  [   32/  179]
train() client id: f_00007-4-1 loss: 0.343193  [   64/  179]
train() client id: f_00007-4-2 loss: 0.498939  [   96/  179]
train() client id: f_00007-4-3 loss: 0.666152  [  128/  179]
train() client id: f_00007-4-4 loss: 0.393854  [  160/  179]
train() client id: f_00007-5-0 loss: 0.473353  [   32/  179]
train() client id: f_00007-5-1 loss: 0.468260  [   64/  179]
train() client id: f_00007-5-2 loss: 0.499200  [   96/  179]
train() client id: f_00007-5-3 loss: 0.857207  [  128/  179]
train() client id: f_00007-5-4 loss: 0.453665  [  160/  179]
train() client id: f_00007-6-0 loss: 0.370365  [   32/  179]
train() client id: f_00007-6-1 loss: 0.523341  [   64/  179]
train() client id: f_00007-6-2 loss: 0.528479  [   96/  179]
train() client id: f_00007-6-3 loss: 0.339343  [  128/  179]
train() client id: f_00007-6-4 loss: 0.765436  [  160/  179]
train() client id: f_00007-7-0 loss: 0.325644  [   32/  179]
train() client id: f_00007-7-1 loss: 0.561965  [   64/  179]
train() client id: f_00007-7-2 loss: 0.595648  [   96/  179]
train() client id: f_00007-7-3 loss: 0.499387  [  128/  179]
train() client id: f_00007-7-4 loss: 0.693120  [  160/  179]
train() client id: f_00007-8-0 loss: 0.507422  [   32/  179]
train() client id: f_00007-8-1 loss: 0.427830  [   64/  179]
train() client id: f_00007-8-2 loss: 0.416502  [   96/  179]
train() client id: f_00007-8-3 loss: 0.417957  [  128/  179]
train() client id: f_00007-8-4 loss: 0.619570  [  160/  179]
train() client id: f_00007-9-0 loss: 0.736089  [   32/  179]
train() client id: f_00007-9-1 loss: 0.461511  [   64/  179]
train() client id: f_00007-9-2 loss: 0.463685  [   96/  179]
train() client id: f_00007-9-3 loss: 0.537107  [  128/  179]
train() client id: f_00007-9-4 loss: 0.417871  [  160/  179]
train() client id: f_00007-10-0 loss: 0.591896  [   32/  179]
train() client id: f_00007-10-1 loss: 0.581293  [   64/  179]
train() client id: f_00007-10-2 loss: 0.325838  [   96/  179]
train() client id: f_00007-10-3 loss: 0.529943  [  128/  179]
train() client id: f_00007-10-4 loss: 0.566914  [  160/  179]
train() client id: f_00007-11-0 loss: 0.540805  [   32/  179]
train() client id: f_00007-11-1 loss: 0.399925  [   64/  179]
train() client id: f_00007-11-2 loss: 0.463143  [   96/  179]
train() client id: f_00007-11-3 loss: 0.380970  [  128/  179]
train() client id: f_00007-11-4 loss: 0.683471  [  160/  179]
train() client id: f_00007-12-0 loss: 0.547411  [   32/  179]
train() client id: f_00007-12-1 loss: 0.531114  [   64/  179]
train() client id: f_00007-12-2 loss: 0.610870  [   96/  179]
train() client id: f_00007-12-3 loss: 0.465844  [  128/  179]
train() client id: f_00007-12-4 loss: 0.450841  [  160/  179]
train() client id: f_00008-0-0 loss: 0.649770  [   32/  130]
train() client id: f_00008-0-1 loss: 0.772836  [   64/  130]
train() client id: f_00008-0-2 loss: 0.727591  [   96/  130]
train() client id: f_00008-0-3 loss: 0.817208  [  128/  130]
train() client id: f_00008-1-0 loss: 0.843668  [   32/  130]
train() client id: f_00008-1-1 loss: 0.710857  [   64/  130]
train() client id: f_00008-1-2 loss: 0.724555  [   96/  130]
train() client id: f_00008-1-3 loss: 0.713012  [  128/  130]
train() client id: f_00008-2-0 loss: 0.803315  [   32/  130]
train() client id: f_00008-2-1 loss: 0.731778  [   64/  130]
train() client id: f_00008-2-2 loss: 0.743605  [   96/  130]
train() client id: f_00008-2-3 loss: 0.717437  [  128/  130]
train() client id: f_00008-3-0 loss: 0.797196  [   32/  130]
train() client id: f_00008-3-1 loss: 0.742069  [   64/  130]
train() client id: f_00008-3-2 loss: 0.667500  [   96/  130]
train() client id: f_00008-3-3 loss: 0.784725  [  128/  130]
train() client id: f_00008-4-0 loss: 0.750049  [   32/  130]
train() client id: f_00008-4-1 loss: 0.707132  [   64/  130]
train() client id: f_00008-4-2 loss: 0.845609  [   96/  130]
train() client id: f_00008-4-3 loss: 0.676265  [  128/  130]
train() client id: f_00008-5-0 loss: 0.724448  [   32/  130]
train() client id: f_00008-5-1 loss: 0.777058  [   64/  130]
train() client id: f_00008-5-2 loss: 0.716156  [   96/  130]
train() client id: f_00008-5-3 loss: 0.740394  [  128/  130]
train() client id: f_00008-6-0 loss: 0.757693  [   32/  130]
train() client id: f_00008-6-1 loss: 0.832724  [   64/  130]
train() client id: f_00008-6-2 loss: 0.641160  [   96/  130]
train() client id: f_00008-6-3 loss: 0.750600  [  128/  130]
train() client id: f_00008-7-0 loss: 0.752302  [   32/  130]
train() client id: f_00008-7-1 loss: 0.715950  [   64/  130]
train() client id: f_00008-7-2 loss: 0.742153  [   96/  130]
train() client id: f_00008-7-3 loss: 0.775157  [  128/  130]
train() client id: f_00008-8-0 loss: 0.734137  [   32/  130]
train() client id: f_00008-8-1 loss: 0.702866  [   64/  130]
train() client id: f_00008-8-2 loss: 0.759469  [   96/  130]
train() client id: f_00008-8-3 loss: 0.726315  [  128/  130]
train() client id: f_00008-9-0 loss: 0.709500  [   32/  130]
train() client id: f_00008-9-1 loss: 0.748235  [   64/  130]
train() client id: f_00008-9-2 loss: 0.738207  [   96/  130]
train() client id: f_00008-9-3 loss: 0.756337  [  128/  130]
train() client id: f_00008-10-0 loss: 0.700525  [   32/  130]
train() client id: f_00008-10-1 loss: 0.777608  [   64/  130]
train() client id: f_00008-10-2 loss: 0.791739  [   96/  130]
train() client id: f_00008-10-3 loss: 0.714143  [  128/  130]
train() client id: f_00008-11-0 loss: 0.862821  [   32/  130]
train() client id: f_00008-11-1 loss: 0.630767  [   64/  130]
train() client id: f_00008-11-2 loss: 0.712847  [   96/  130]
train() client id: f_00008-11-3 loss: 0.780979  [  128/  130]
train() client id: f_00008-12-0 loss: 0.805475  [   32/  130]
train() client id: f_00008-12-1 loss: 0.771537  [   64/  130]
train() client id: f_00008-12-2 loss: 0.659808  [   96/  130]
train() client id: f_00008-12-3 loss: 0.721042  [  128/  130]
train() client id: f_00009-0-0 loss: 0.929280  [   32/  118]
train() client id: f_00009-0-1 loss: 0.960900  [   64/  118]
train() client id: f_00009-0-2 loss: 0.835181  [   96/  118]
train() client id: f_00009-1-0 loss: 0.822750  [   32/  118]
train() client id: f_00009-1-1 loss: 0.944195  [   64/  118]
train() client id: f_00009-1-2 loss: 0.848311  [   96/  118]
train() client id: f_00009-2-0 loss: 0.817071  [   32/  118]
train() client id: f_00009-2-1 loss: 0.888082  [   64/  118]
train() client id: f_00009-2-2 loss: 0.857733  [   96/  118]
train() client id: f_00009-3-0 loss: 0.938109  [   32/  118]
train() client id: f_00009-3-1 loss: 0.632921  [   64/  118]
train() client id: f_00009-3-2 loss: 0.739032  [   96/  118]
train() client id: f_00009-4-0 loss: 0.777880  [   32/  118]
train() client id: f_00009-4-1 loss: 0.651820  [   64/  118]
train() client id: f_00009-4-2 loss: 0.815645  [   96/  118]
train() client id: f_00009-5-0 loss: 0.763165  [   32/  118]
train() client id: f_00009-5-1 loss: 0.792296  [   64/  118]
train() client id: f_00009-5-2 loss: 0.794969  [   96/  118]
train() client id: f_00009-6-0 loss: 0.815557  [   32/  118]
train() client id: f_00009-6-1 loss: 0.721578  [   64/  118]
train() client id: f_00009-6-2 loss: 0.729754  [   96/  118]
train() client id: f_00009-7-0 loss: 0.751760  [   32/  118]
train() client id: f_00009-7-1 loss: 0.820116  [   64/  118]
train() client id: f_00009-7-2 loss: 0.624236  [   96/  118]
train() client id: f_00009-8-0 loss: 0.725176  [   32/  118]
train() client id: f_00009-8-1 loss: 0.785257  [   64/  118]
train() client id: f_00009-8-2 loss: 0.616040  [   96/  118]
train() client id: f_00009-9-0 loss: 0.821688  [   32/  118]
train() client id: f_00009-9-1 loss: 0.606332  [   64/  118]
train() client id: f_00009-9-2 loss: 0.748554  [   96/  118]
train() client id: f_00009-10-0 loss: 0.625918  [   32/  118]
train() client id: f_00009-10-1 loss: 0.690705  [   64/  118]
train() client id: f_00009-10-2 loss: 0.661566  [   96/  118]
train() client id: f_00009-11-0 loss: 0.707830  [   32/  118]
train() client id: f_00009-11-1 loss: 0.643287  [   64/  118]
train() client id: f_00009-11-2 loss: 0.838043  [   96/  118]
train() client id: f_00009-12-0 loss: 0.680647  [   32/  118]
train() client id: f_00009-12-1 loss: 0.784736  [   64/  118]
train() client id: f_00009-12-2 loss: 0.824042  [   96/  118]
At round 78 accuracy: 0.6392572944297082
At round 78 training accuracy: 0.5881958417169685
At round 78 training loss: 0.8248392600672753
gradient difference: 0.4005679488182068
train() client id: f_00000-0-0 loss: 1.040689  [   32/  126]
train() client id: f_00000-0-1 loss: 1.367973  [   64/  126]
train() client id: f_00000-0-2 loss: 1.254723  [   96/  126]
train() client id: f_00000-1-0 loss: 1.183948  [   32/  126]
train() client id: f_00000-1-1 loss: 1.148749  [   64/  126]
train() client id: f_00000-1-2 loss: 1.039663  [   96/  126]
train() client id: f_00000-2-0 loss: 1.335898  [   32/  126]
train() client id: f_00000-2-1 loss: 0.905223  [   64/  126]
train() client id: f_00000-2-2 loss: 1.054700  [   96/  126]
train() client id: f_00000-3-0 loss: 1.160910  [   32/  126]
train() client id: f_00000-3-1 loss: 0.997926  [   64/  126]
train() client id: f_00000-3-2 loss: 0.854600  [   96/  126]
train() client id: f_00000-4-0 loss: 1.183784  [   32/  126]
train() client id: f_00000-4-1 loss: 0.793149  [   64/  126]
train() client id: f_00000-4-2 loss: 1.024277  [   96/  126]
train() client id: f_00000-5-0 loss: 0.877329  [   32/  126]
train() client id: f_00000-5-1 loss: 0.825339  [   64/  126]
train() client id: f_00000-5-2 loss: 1.124061  [   96/  126]
train() client id: f_00000-6-0 loss: 0.946530  [   32/  126]
train() client id: f_00000-6-1 loss: 0.878967  [   64/  126]
train() client id: f_00000-6-2 loss: 0.905099  [   96/  126]
train() client id: f_00000-7-0 loss: 0.955738  [   32/  126]
train() client id: f_00000-7-1 loss: 0.788935  [   64/  126]
train() client id: f_00000-7-2 loss: 0.954142  [   96/  126]
train() client id: f_00000-8-0 loss: 0.814427  [   32/  126]
train() client id: f_00000-8-1 loss: 0.925032  [   64/  126]
train() client id: f_00000-8-2 loss: 0.897775  [   96/  126]
train() client id: f_00000-9-0 loss: 0.896110  [   32/  126]
train() client id: f_00000-9-1 loss: 0.804992  [   64/  126]
train() client id: f_00000-9-2 loss: 0.764698  [   96/  126]
train() client id: f_00000-10-0 loss: 0.913862  [   32/  126]
train() client id: f_00000-10-1 loss: 0.903824  [   64/  126]
train() client id: f_00000-10-2 loss: 0.703507  [   96/  126]
train() client id: f_00000-11-0 loss: 0.907866  [   32/  126]
train() client id: f_00000-11-1 loss: 0.749718  [   64/  126]
train() client id: f_00000-11-2 loss: 0.862619  [   96/  126]
train() client id: f_00000-12-0 loss: 0.799670  [   32/  126]
train() client id: f_00000-12-1 loss: 0.953830  [   64/  126]
train() client id: f_00000-12-2 loss: 0.789475  [   96/  126]
train() client id: f_00001-0-0 loss: 0.506743  [   32/  265]
train() client id: f_00001-0-1 loss: 0.567598  [   64/  265]
train() client id: f_00001-0-2 loss: 0.560937  [   96/  265]
train() client id: f_00001-0-3 loss: 0.453832  [  128/  265]
train() client id: f_00001-0-4 loss: 0.513627  [  160/  265]
train() client id: f_00001-0-5 loss: 0.396273  [  192/  265]
train() client id: f_00001-0-6 loss: 0.483659  [  224/  265]
train() client id: f_00001-0-7 loss: 0.480542  [  256/  265]
train() client id: f_00001-1-0 loss: 0.483285  [   32/  265]
train() client id: f_00001-1-1 loss: 0.543676  [   64/  265]
train() client id: f_00001-1-2 loss: 0.416210  [   96/  265]
train() client id: f_00001-1-3 loss: 0.423872  [  128/  265]
train() client id: f_00001-1-4 loss: 0.585311  [  160/  265]
train() client id: f_00001-1-5 loss: 0.602450  [  192/  265]
train() client id: f_00001-1-6 loss: 0.528076  [  224/  265]
train() client id: f_00001-1-7 loss: 0.400639  [  256/  265]
train() client id: f_00001-2-0 loss: 0.445196  [   32/  265]
train() client id: f_00001-2-1 loss: 0.402918  [   64/  265]
train() client id: f_00001-2-2 loss: 0.426952  [   96/  265]
train() client id: f_00001-2-3 loss: 0.398369  [  128/  265]
train() client id: f_00001-2-4 loss: 0.478990  [  160/  265]
train() client id: f_00001-2-5 loss: 0.626985  [  192/  265]
train() client id: f_00001-2-6 loss: 0.467272  [  224/  265]
train() client id: f_00001-2-7 loss: 0.694997  [  256/  265]
train() client id: f_00001-3-0 loss: 0.467673  [   32/  265]
train() client id: f_00001-3-1 loss: 0.419884  [   64/  265]
train() client id: f_00001-3-2 loss: 0.423424  [   96/  265]
train() client id: f_00001-3-3 loss: 0.531803  [  128/  265]
train() client id: f_00001-3-4 loss: 0.509014  [  160/  265]
train() client id: f_00001-3-5 loss: 0.388467  [  192/  265]
train() client id: f_00001-3-6 loss: 0.664388  [  224/  265]
train() client id: f_00001-3-7 loss: 0.509489  [  256/  265]
train() client id: f_00001-4-0 loss: 0.399724  [   32/  265]
train() client id: f_00001-4-1 loss: 0.585257  [   64/  265]
train() client id: f_00001-4-2 loss: 0.456939  [   96/  265]
train() client id: f_00001-4-3 loss: 0.395700  [  128/  265]
train() client id: f_00001-4-4 loss: 0.420972  [  160/  265]
train() client id: f_00001-4-5 loss: 0.657070  [  192/  265]
train() client id: f_00001-4-6 loss: 0.384635  [  224/  265]
train() client id: f_00001-4-7 loss: 0.572135  [  256/  265]
train() client id: f_00001-5-0 loss: 0.626761  [   32/  265]
train() client id: f_00001-5-1 loss: 0.398136  [   64/  265]
train() client id: f_00001-5-2 loss: 0.418690  [   96/  265]
train() client id: f_00001-5-3 loss: 0.441859  [  128/  265]
train() client id: f_00001-5-4 loss: 0.428777  [  160/  265]
train() client id: f_00001-5-5 loss: 0.486309  [  192/  265]
train() client id: f_00001-5-6 loss: 0.566601  [  224/  265]
train() client id: f_00001-5-7 loss: 0.506234  [  256/  265]
train() client id: f_00001-6-0 loss: 0.462985  [   32/  265]
train() client id: f_00001-6-1 loss: 0.598495  [   64/  265]
train() client id: f_00001-6-2 loss: 0.553021  [   96/  265]
train() client id: f_00001-6-3 loss: 0.393800  [  128/  265]
train() client id: f_00001-6-4 loss: 0.441915  [  160/  265]
train() client id: f_00001-6-5 loss: 0.411217  [  192/  265]
train() client id: f_00001-6-6 loss: 0.468643  [  224/  265]
train() client id: f_00001-6-7 loss: 0.479639  [  256/  265]
train() client id: f_00001-7-0 loss: 0.426567  [   32/  265]
train() client id: f_00001-7-1 loss: 0.391731  [   64/  265]
train() client id: f_00001-7-2 loss: 0.653233  [   96/  265]
train() client id: f_00001-7-3 loss: 0.450241  [  128/  265]
train() client id: f_00001-7-4 loss: 0.433677  [  160/  265]
train() client id: f_00001-7-5 loss: 0.505926  [  192/  265]
train() client id: f_00001-7-6 loss: 0.411113  [  224/  265]
train() client id: f_00001-7-7 loss: 0.451063  [  256/  265]
train() client id: f_00001-8-0 loss: 0.512971  [   32/  265]
train() client id: f_00001-8-1 loss: 0.398023  [   64/  265]
train() client id: f_00001-8-2 loss: 0.600854  [   96/  265]
train() client id: f_00001-8-3 loss: 0.453013  [  128/  265]
train() client id: f_00001-8-4 loss: 0.488362  [  160/  265]
train() client id: f_00001-8-5 loss: 0.446894  [  192/  265]
train() client id: f_00001-8-6 loss: 0.437710  [  224/  265]
train() client id: f_00001-8-7 loss: 0.421322  [  256/  265]
train() client id: f_00001-9-0 loss: 0.458987  [   32/  265]
train() client id: f_00001-9-1 loss: 0.586013  [   64/  265]
train() client id: f_00001-9-2 loss: 0.460635  [   96/  265]
train() client id: f_00001-9-3 loss: 0.380362  [  128/  265]
train() client id: f_00001-9-4 loss: 0.386813  [  160/  265]
train() client id: f_00001-9-5 loss: 0.446741  [  192/  265]
train() client id: f_00001-9-6 loss: 0.542421  [  224/  265]
train() client id: f_00001-9-7 loss: 0.558805  [  256/  265]
train() client id: f_00001-10-0 loss: 0.484530  [   32/  265]
train() client id: f_00001-10-1 loss: 0.452885  [   64/  265]
train() client id: f_00001-10-2 loss: 0.544035  [   96/  265]
train() client id: f_00001-10-3 loss: 0.391006  [  128/  265]
train() client id: f_00001-10-4 loss: 0.441832  [  160/  265]
train() client id: f_00001-10-5 loss: 0.511277  [  192/  265]
train() client id: f_00001-10-6 loss: 0.378396  [  224/  265]
train() client id: f_00001-10-7 loss: 0.590965  [  256/  265]
train() client id: f_00001-11-0 loss: 0.398975  [   32/  265]
train() client id: f_00001-11-1 loss: 0.418547  [   64/  265]
train() client id: f_00001-11-2 loss: 0.549801  [   96/  265]
train() client id: f_00001-11-3 loss: 0.505899  [  128/  265]
train() client id: f_00001-11-4 loss: 0.500631  [  160/  265]
train() client id: f_00001-11-5 loss: 0.590464  [  192/  265]
train() client id: f_00001-11-6 loss: 0.454687  [  224/  265]
train() client id: f_00001-11-7 loss: 0.391245  [  256/  265]
train() client id: f_00001-12-0 loss: 0.445644  [   32/  265]
train() client id: f_00001-12-1 loss: 0.409379  [   64/  265]
train() client id: f_00001-12-2 loss: 0.491077  [   96/  265]
train() client id: f_00001-12-3 loss: 0.381930  [  128/  265]
train() client id: f_00001-12-4 loss: 0.490473  [  160/  265]
train() client id: f_00001-12-5 loss: 0.487752  [  192/  265]
train() client id: f_00001-12-6 loss: 0.456607  [  224/  265]
train() client id: f_00001-12-7 loss: 0.604840  [  256/  265]
train() client id: f_00002-0-0 loss: 0.890247  [   32/  124]
train() client id: f_00002-0-1 loss: 0.907529  [   64/  124]
train() client id: f_00002-0-2 loss: 1.236553  [   96/  124]
train() client id: f_00002-1-0 loss: 1.209058  [   32/  124]
train() client id: f_00002-1-1 loss: 0.874984  [   64/  124]
train() client id: f_00002-1-2 loss: 0.917037  [   96/  124]
train() client id: f_00002-2-0 loss: 1.001536  [   32/  124]
train() client id: f_00002-2-1 loss: 0.921985  [   64/  124]
train() client id: f_00002-2-2 loss: 0.959280  [   96/  124]
train() client id: f_00002-3-0 loss: 0.956740  [   32/  124]
train() client id: f_00002-3-1 loss: 0.917851  [   64/  124]
train() client id: f_00002-3-2 loss: 0.855371  [   96/  124]
train() client id: f_00002-4-0 loss: 0.698072  [   32/  124]
train() client id: f_00002-4-1 loss: 0.945649  [   64/  124]
train() client id: f_00002-4-2 loss: 0.949942  [   96/  124]
train() client id: f_00002-5-0 loss: 1.106551  [   32/  124]
train() client id: f_00002-5-1 loss: 0.801151  [   64/  124]
train() client id: f_00002-5-2 loss: 0.918046  [   96/  124]
train() client id: f_00002-6-0 loss: 0.876240  [   32/  124]
train() client id: f_00002-6-1 loss: 0.757473  [   64/  124]
train() client id: f_00002-6-2 loss: 0.978825  [   96/  124]
train() client id: f_00002-7-0 loss: 0.883292  [   32/  124]
train() client id: f_00002-7-1 loss: 1.021654  [   64/  124]
train() client id: f_00002-7-2 loss: 0.819871  [   96/  124]
train() client id: f_00002-8-0 loss: 1.011839  [   32/  124]
train() client id: f_00002-8-1 loss: 0.779739  [   64/  124]
train() client id: f_00002-8-2 loss: 0.782560  [   96/  124]
train() client id: f_00002-9-0 loss: 0.768308  [   32/  124]
train() client id: f_00002-9-1 loss: 0.701917  [   64/  124]
train() client id: f_00002-9-2 loss: 1.068549  [   96/  124]
train() client id: f_00002-10-0 loss: 0.807806  [   32/  124]
train() client id: f_00002-10-1 loss: 0.710008  [   64/  124]
train() client id: f_00002-10-2 loss: 0.947830  [   96/  124]
train() client id: f_00002-11-0 loss: 0.871470  [   32/  124]
train() client id: f_00002-11-1 loss: 0.924585  [   64/  124]
train() client id: f_00002-11-2 loss: 0.724594  [   96/  124]
train() client id: f_00002-12-0 loss: 0.807423  [   32/  124]
train() client id: f_00002-12-1 loss: 0.845103  [   64/  124]
train() client id: f_00002-12-2 loss: 0.728495  [   96/  124]
train() client id: f_00003-0-0 loss: 0.755193  [   32/   43]
train() client id: f_00003-1-0 loss: 0.637613  [   32/   43]
train() client id: f_00003-2-0 loss: 0.769011  [   32/   43]
train() client id: f_00003-3-0 loss: 0.750344  [   32/   43]
train() client id: f_00003-4-0 loss: 0.987264  [   32/   43]
train() client id: f_00003-5-0 loss: 0.771158  [   32/   43]
train() client id: f_00003-6-0 loss: 0.848591  [   32/   43]
train() client id: f_00003-7-0 loss: 0.535884  [   32/   43]
train() client id: f_00003-8-0 loss: 0.747731  [   32/   43]
train() client id: f_00003-9-0 loss: 0.800776  [   32/   43]
train() client id: f_00003-10-0 loss: 0.753056  [   32/   43]
train() client id: f_00003-11-0 loss: 0.415745  [   32/   43]
train() client id: f_00003-12-0 loss: 0.788991  [   32/   43]
train() client id: f_00004-0-0 loss: 0.640801  [   32/  306]
train() client id: f_00004-0-1 loss: 0.723852  [   64/  306]
train() client id: f_00004-0-2 loss: 0.737561  [   96/  306]
train() client id: f_00004-0-3 loss: 0.801050  [  128/  306]
train() client id: f_00004-0-4 loss: 0.728952  [  160/  306]
train() client id: f_00004-0-5 loss: 0.762219  [  192/  306]
train() client id: f_00004-0-6 loss: 0.845746  [  224/  306]
train() client id: f_00004-0-7 loss: 0.853650  [  256/  306]
train() client id: f_00004-0-8 loss: 0.806993  [  288/  306]
train() client id: f_00004-1-0 loss: 0.722526  [   32/  306]
train() client id: f_00004-1-1 loss: 0.816858  [   64/  306]
train() client id: f_00004-1-2 loss: 0.764923  [   96/  306]
train() client id: f_00004-1-3 loss: 0.739238  [  128/  306]
train() client id: f_00004-1-4 loss: 0.671150  [  160/  306]
train() client id: f_00004-1-5 loss: 0.678136  [  192/  306]
train() client id: f_00004-1-6 loss: 0.858792  [  224/  306]
train() client id: f_00004-1-7 loss: 0.749252  [  256/  306]
train() client id: f_00004-1-8 loss: 0.831539  [  288/  306]
train() client id: f_00004-2-0 loss: 0.850360  [   32/  306]
train() client id: f_00004-2-1 loss: 0.668441  [   64/  306]
train() client id: f_00004-2-2 loss: 0.817960  [   96/  306]
train() client id: f_00004-2-3 loss: 0.816088  [  128/  306]
train() client id: f_00004-2-4 loss: 0.645770  [  160/  306]
train() client id: f_00004-2-5 loss: 0.725276  [  192/  306]
train() client id: f_00004-2-6 loss: 0.746748  [  224/  306]
train() client id: f_00004-2-7 loss: 0.801583  [  256/  306]
train() client id: f_00004-2-8 loss: 0.746112  [  288/  306]
train() client id: f_00004-3-0 loss: 0.728304  [   32/  306]
train() client id: f_00004-3-1 loss: 0.797032  [   64/  306]
train() client id: f_00004-3-2 loss: 0.827472  [   96/  306]
train() client id: f_00004-3-3 loss: 0.796322  [  128/  306]
train() client id: f_00004-3-4 loss: 0.837914  [  160/  306]
train() client id: f_00004-3-5 loss: 0.773505  [  192/  306]
train() client id: f_00004-3-6 loss: 0.696464  [  224/  306]
train() client id: f_00004-3-7 loss: 0.677593  [  256/  306]
train() client id: f_00004-3-8 loss: 0.835865  [  288/  306]
train() client id: f_00004-4-0 loss: 0.788027  [   32/  306]
train() client id: f_00004-4-1 loss: 0.843976  [   64/  306]
train() client id: f_00004-4-2 loss: 0.717637  [   96/  306]
train() client id: f_00004-4-3 loss: 0.766974  [  128/  306]
train() client id: f_00004-4-4 loss: 0.780736  [  160/  306]
train() client id: f_00004-4-5 loss: 0.737368  [  192/  306]
train() client id: f_00004-4-6 loss: 0.784867  [  224/  306]
train() client id: f_00004-4-7 loss: 0.674478  [  256/  306]
train() client id: f_00004-4-8 loss: 0.778131  [  288/  306]
train() client id: f_00004-5-0 loss: 0.778377  [   32/  306]
train() client id: f_00004-5-1 loss: 0.688065  [   64/  306]
train() client id: f_00004-5-2 loss: 0.822299  [   96/  306]
train() client id: f_00004-5-3 loss: 0.752261  [  128/  306]
train() client id: f_00004-5-4 loss: 0.758210  [  160/  306]
train() client id: f_00004-5-5 loss: 0.747640  [  192/  306]
train() client id: f_00004-5-6 loss: 0.873601  [  224/  306]
train() client id: f_00004-5-7 loss: 0.724623  [  256/  306]
train() client id: f_00004-5-8 loss: 0.757106  [  288/  306]
train() client id: f_00004-6-0 loss: 0.767582  [   32/  306]
train() client id: f_00004-6-1 loss: 0.802841  [   64/  306]
train() client id: f_00004-6-2 loss: 0.797394  [   96/  306]
train() client id: f_00004-6-3 loss: 0.695025  [  128/  306]
train() client id: f_00004-6-4 loss: 0.821020  [  160/  306]
train() client id: f_00004-6-5 loss: 0.735427  [  192/  306]
train() client id: f_00004-6-6 loss: 0.666643  [  224/  306]
train() client id: f_00004-6-7 loss: 0.780285  [  256/  306]
train() client id: f_00004-6-8 loss: 0.879854  [  288/  306]
train() client id: f_00004-7-0 loss: 0.760861  [   32/  306]
train() client id: f_00004-7-1 loss: 0.855335  [   64/  306]
train() client id: f_00004-7-2 loss: 0.650571  [   96/  306]
train() client id: f_00004-7-3 loss: 0.771382  [  128/  306]
train() client id: f_00004-7-4 loss: 0.668423  [  160/  306]
train() client id: f_00004-7-5 loss: 0.891769  [  192/  306]
train() client id: f_00004-7-6 loss: 0.901790  [  224/  306]
train() client id: f_00004-7-7 loss: 0.723469  [  256/  306]
train() client id: f_00004-7-8 loss: 0.661337  [  288/  306]
train() client id: f_00004-8-0 loss: 0.906572  [   32/  306]
train() client id: f_00004-8-1 loss: 0.626800  [   64/  306]
train() client id: f_00004-8-2 loss: 0.882249  [   96/  306]
train() client id: f_00004-8-3 loss: 0.711660  [  128/  306]
train() client id: f_00004-8-4 loss: 0.711369  [  160/  306]
train() client id: f_00004-8-5 loss: 0.925408  [  192/  306]
train() client id: f_00004-8-6 loss: 0.838469  [  224/  306]
train() client id: f_00004-8-7 loss: 0.614822  [  256/  306]
train() client id: f_00004-8-8 loss: 0.662470  [  288/  306]
train() client id: f_00004-9-0 loss: 0.883539  [   32/  306]
train() client id: f_00004-9-1 loss: 0.731423  [   64/  306]
train() client id: f_00004-9-2 loss: 0.815274  [   96/  306]
train() client id: f_00004-9-3 loss: 0.657984  [  128/  306]
train() client id: f_00004-9-4 loss: 0.837289  [  160/  306]
train() client id: f_00004-9-5 loss: 0.806549  [  192/  306]
train() client id: f_00004-9-6 loss: 0.760226  [  224/  306]
train() client id: f_00004-9-7 loss: 0.691909  [  256/  306]
train() client id: f_00004-9-8 loss: 0.845731  [  288/  306]
train() client id: f_00004-10-0 loss: 0.729660  [   32/  306]
train() client id: f_00004-10-1 loss: 0.707459  [   64/  306]
train() client id: f_00004-10-2 loss: 0.758376  [   96/  306]
train() client id: f_00004-10-3 loss: 0.700666  [  128/  306]
train() client id: f_00004-10-4 loss: 0.879920  [  160/  306]
train() client id: f_00004-10-5 loss: 0.658891  [  192/  306]
train() client id: f_00004-10-6 loss: 0.813223  [  224/  306]
train() client id: f_00004-10-7 loss: 0.764306  [  256/  306]
train() client id: f_00004-10-8 loss: 0.867376  [  288/  306]
train() client id: f_00004-11-0 loss: 0.716657  [   32/  306]
train() client id: f_00004-11-1 loss: 0.792138  [   64/  306]
train() client id: f_00004-11-2 loss: 0.816586  [   96/  306]
train() client id: f_00004-11-3 loss: 0.711852  [  128/  306]
train() client id: f_00004-11-4 loss: 0.755265  [  160/  306]
train() client id: f_00004-11-5 loss: 0.833255  [  192/  306]
train() client id: f_00004-11-6 loss: 0.776337  [  224/  306]
train() client id: f_00004-11-7 loss: 0.770233  [  256/  306]
train() client id: f_00004-11-8 loss: 0.690513  [  288/  306]
train() client id: f_00004-12-0 loss: 0.754688  [   32/  306]
train() client id: f_00004-12-1 loss: 0.727727  [   64/  306]
train() client id: f_00004-12-2 loss: 0.741600  [   96/  306]
train() client id: f_00004-12-3 loss: 0.859527  [  128/  306]
train() client id: f_00004-12-4 loss: 0.785634  [  160/  306]
train() client id: f_00004-12-5 loss: 0.708453  [  192/  306]
train() client id: f_00004-12-6 loss: 0.760690  [  224/  306]
train() client id: f_00004-12-7 loss: 0.880144  [  256/  306]
train() client id: f_00004-12-8 loss: 0.676473  [  288/  306]
train() client id: f_00005-0-0 loss: 0.347925  [   32/  146]
train() client id: f_00005-0-1 loss: 0.203264  [   64/  146]
train() client id: f_00005-0-2 loss: 0.527855  [   96/  146]
train() client id: f_00005-0-3 loss: 0.640312  [  128/  146]
train() client id: f_00005-1-0 loss: 0.775201  [   32/  146]
train() client id: f_00005-1-1 loss: 0.201077  [   64/  146]
train() client id: f_00005-1-2 loss: 0.305739  [   96/  146]
train() client id: f_00005-1-3 loss: 0.244178  [  128/  146]
train() client id: f_00005-2-0 loss: 0.351216  [   32/  146]
train() client id: f_00005-2-1 loss: 0.338182  [   64/  146]
train() client id: f_00005-2-2 loss: 0.526539  [   96/  146]
train() client id: f_00005-2-3 loss: 0.466715  [  128/  146]
train() client id: f_00005-3-0 loss: 0.316090  [   32/  146]
train() client id: f_00005-3-1 loss: 0.463007  [   64/  146]
train() client id: f_00005-3-2 loss: 0.428890  [   96/  146]
train() client id: f_00005-3-3 loss: 0.313311  [  128/  146]
train() client id: f_00005-4-0 loss: 0.694115  [   32/  146]
train() client id: f_00005-4-1 loss: 0.215811  [   64/  146]
train() client id: f_00005-4-2 loss: 0.275650  [   96/  146]
train() client id: f_00005-4-3 loss: 0.395985  [  128/  146]
train() client id: f_00005-5-0 loss: 0.353997  [   32/  146]
train() client id: f_00005-5-1 loss: 0.303181  [   64/  146]
train() client id: f_00005-5-2 loss: 0.318782  [   96/  146]
train() client id: f_00005-5-3 loss: 0.577376  [  128/  146]
train() client id: f_00005-6-0 loss: 0.485280  [   32/  146]
train() client id: f_00005-6-1 loss: 0.164052  [   64/  146]
train() client id: f_00005-6-2 loss: 0.906911  [   96/  146]
train() client id: f_00005-6-3 loss: 0.194672  [  128/  146]
train() client id: f_00005-7-0 loss: 0.214427  [   32/  146]
train() client id: f_00005-7-1 loss: 0.424877  [   64/  146]
train() client id: f_00005-7-2 loss: 0.285765  [   96/  146]
train() client id: f_00005-7-3 loss: 0.587231  [  128/  146]
train() client id: f_00005-8-0 loss: 0.296304  [   32/  146]
train() client id: f_00005-8-1 loss: 0.321213  [   64/  146]
train() client id: f_00005-8-2 loss: 0.617631  [   96/  146]
train() client id: f_00005-8-3 loss: 0.331568  [  128/  146]
train() client id: f_00005-9-0 loss: 0.194784  [   32/  146]
train() client id: f_00005-9-1 loss: 0.217215  [   64/  146]
train() client id: f_00005-9-2 loss: 0.556416  [   96/  146]
train() client id: f_00005-9-3 loss: 0.520984  [  128/  146]
train() client id: f_00005-10-0 loss: 0.196826  [   32/  146]
train() client id: f_00005-10-1 loss: 0.219978  [   64/  146]
train() client id: f_00005-10-2 loss: 0.536794  [   96/  146]
train() client id: f_00005-10-3 loss: 0.406674  [  128/  146]
train() client id: f_00005-11-0 loss: 0.434680  [   32/  146]
train() client id: f_00005-11-1 loss: 0.118093  [   64/  146]
train() client id: f_00005-11-2 loss: 0.572987  [   96/  146]
train() client id: f_00005-11-3 loss: 0.148151  [  128/  146]
train() client id: f_00005-12-0 loss: 0.339601  [   32/  146]
train() client id: f_00005-12-1 loss: 0.339442  [   64/  146]
train() client id: f_00005-12-2 loss: 0.220891  [   96/  146]
train() client id: f_00005-12-3 loss: 0.474504  [  128/  146]
train() client id: f_00006-0-0 loss: 0.479623  [   32/   54]
train() client id: f_00006-1-0 loss: 0.438273  [   32/   54]
train() client id: f_00006-2-0 loss: 0.378678  [   32/   54]
train() client id: f_00006-3-0 loss: 0.440798  [   32/   54]
train() client id: f_00006-4-0 loss: 0.421313  [   32/   54]
train() client id: f_00006-5-0 loss: 0.394828  [   32/   54]
train() client id: f_00006-6-0 loss: 0.417549  [   32/   54]
train() client id: f_00006-7-0 loss: 0.477168  [   32/   54]
train() client id: f_00006-8-0 loss: 0.466399  [   32/   54]
train() client id: f_00006-9-0 loss: 0.445145  [   32/   54]
train() client id: f_00006-10-0 loss: 0.374677  [   32/   54]
train() client id: f_00006-11-0 loss: 0.450816  [   32/   54]
train() client id: f_00006-12-0 loss: 0.501832  [   32/   54]
train() client id: f_00007-0-0 loss: 0.539547  [   32/  179]
train() client id: f_00007-0-1 loss: 0.626510  [   64/  179]
train() client id: f_00007-0-2 loss: 0.782363  [   96/  179]
train() client id: f_00007-0-3 loss: 0.690550  [  128/  179]
train() client id: f_00007-0-4 loss: 0.452921  [  160/  179]
train() client id: f_00007-1-0 loss: 0.539407  [   32/  179]
train() client id: f_00007-1-1 loss: 0.803057  [   64/  179]
train() client id: f_00007-1-2 loss: 0.740660  [   96/  179]
train() client id: f_00007-1-3 loss: 0.384532  [  128/  179]
train() client id: f_00007-1-4 loss: 0.625695  [  160/  179]
train() client id: f_00007-2-0 loss: 0.541013  [   32/  179]
train() client id: f_00007-2-1 loss: 0.594299  [   64/  179]
train() client id: f_00007-2-2 loss: 0.430798  [   96/  179]
train() client id: f_00007-2-3 loss: 0.486880  [  128/  179]
train() client id: f_00007-2-4 loss: 0.691563  [  160/  179]
train() client id: f_00007-3-0 loss: 0.403871  [   32/  179]
train() client id: f_00007-3-1 loss: 0.764330  [   64/  179]
train() client id: f_00007-3-2 loss: 0.702612  [   96/  179]
train() client id: f_00007-3-3 loss: 0.448978  [  128/  179]
train() client id: f_00007-3-4 loss: 0.605709  [  160/  179]
train() client id: f_00007-4-0 loss: 0.503012  [   32/  179]
train() client id: f_00007-4-1 loss: 0.728162  [   64/  179]
train() client id: f_00007-4-2 loss: 0.634954  [   96/  179]
train() client id: f_00007-4-3 loss: 0.581906  [  128/  179]
train() client id: f_00007-4-4 loss: 0.512216  [  160/  179]
train() client id: f_00007-5-0 loss: 0.630884  [   32/  179]
train() client id: f_00007-5-1 loss: 0.457505  [   64/  179]
train() client id: f_00007-5-2 loss: 0.739045  [   96/  179]
train() client id: f_00007-5-3 loss: 0.618325  [  128/  179]
train() client id: f_00007-5-4 loss: 0.500277  [  160/  179]
train() client id: f_00007-6-0 loss: 0.670887  [   32/  179]
train() client id: f_00007-6-1 loss: 0.458137  [   64/  179]
train() client id: f_00007-6-2 loss: 0.639415  [   96/  179]
train() client id: f_00007-6-3 loss: 0.567311  [  128/  179]
train() client id: f_00007-6-4 loss: 0.559976  [  160/  179]
train() client id: f_00007-7-0 loss: 0.506085  [   32/  179]
train() client id: f_00007-7-1 loss: 0.423795  [   64/  179]
train() client id: f_00007-7-2 loss: 0.792208  [   96/  179]
train() client id: f_00007-7-3 loss: 0.575743  [  128/  179]
train() client id: f_00007-7-4 loss: 0.475681  [  160/  179]
train() client id: f_00007-8-0 loss: 0.630422  [   32/  179]
train() client id: f_00007-8-1 loss: 0.520955  [   64/  179]
train() client id: f_00007-8-2 loss: 0.641830  [   96/  179]
train() client id: f_00007-8-3 loss: 0.476320  [  128/  179]
train() client id: f_00007-8-4 loss: 0.619631  [  160/  179]
train() client id: f_00007-9-0 loss: 0.748193  [   32/  179]
train() client id: f_00007-9-1 loss: 0.464260  [   64/  179]
train() client id: f_00007-9-2 loss: 0.385753  [   96/  179]
train() client id: f_00007-9-3 loss: 0.562302  [  128/  179]
train() client id: f_00007-9-4 loss: 0.532759  [  160/  179]
train() client id: f_00007-10-0 loss: 0.738669  [   32/  179]
train() client id: f_00007-10-1 loss: 0.509735  [   64/  179]
train() client id: f_00007-10-2 loss: 0.509095  [   96/  179]
train() client id: f_00007-10-3 loss: 0.402905  [  128/  179]
train() client id: f_00007-10-4 loss: 0.594197  [  160/  179]
train() client id: f_00007-11-0 loss: 0.610652  [   32/  179]
train() client id: f_00007-11-1 loss: 0.750854  [   64/  179]
train() client id: f_00007-11-2 loss: 0.455725  [   96/  179]
train() client id: f_00007-11-3 loss: 0.655560  [  128/  179]
train() client id: f_00007-11-4 loss: 0.397027  [  160/  179]
train() client id: f_00007-12-0 loss: 0.377833  [   32/  179]
train() client id: f_00007-12-1 loss: 0.874097  [   64/  179]
train() client id: f_00007-12-2 loss: 0.488697  [   96/  179]
train() client id: f_00007-12-3 loss: 0.469583  [  128/  179]
train() client id: f_00007-12-4 loss: 0.654962  [  160/  179]
train() client id: f_00008-0-0 loss: 0.747340  [   32/  130]
train() client id: f_00008-0-1 loss: 0.774629  [   64/  130]
train() client id: f_00008-0-2 loss: 0.709333  [   96/  130]
train() client id: f_00008-0-3 loss: 0.752715  [  128/  130]
train() client id: f_00008-1-0 loss: 0.788079  [   32/  130]
train() client id: f_00008-1-1 loss: 0.729123  [   64/  130]
train() client id: f_00008-1-2 loss: 0.710101  [   96/  130]
train() client id: f_00008-1-3 loss: 0.809841  [  128/  130]
train() client id: f_00008-2-0 loss: 0.778940  [   32/  130]
train() client id: f_00008-2-1 loss: 0.837239  [   64/  130]
train() client id: f_00008-2-2 loss: 0.650219  [   96/  130]
train() client id: f_00008-2-3 loss: 0.760113  [  128/  130]
train() client id: f_00008-3-0 loss: 0.703344  [   32/  130]
train() client id: f_00008-3-1 loss: 0.817821  [   64/  130]
train() client id: f_00008-3-2 loss: 0.773650  [   96/  130]
train() client id: f_00008-3-3 loss: 0.744682  [  128/  130]
train() client id: f_00008-4-0 loss: 0.690479  [   32/  130]
train() client id: f_00008-4-1 loss: 0.753579  [   64/  130]
train() client id: f_00008-4-2 loss: 0.845236  [   96/  130]
train() client id: f_00008-4-3 loss: 0.737093  [  128/  130]
train() client id: f_00008-5-0 loss: 0.803850  [   32/  130]
train() client id: f_00008-5-1 loss: 0.664418  [   64/  130]
train() client id: f_00008-5-2 loss: 0.820185  [   96/  130]
train() client id: f_00008-5-3 loss: 0.745727  [  128/  130]
train() client id: f_00008-6-0 loss: 0.839894  [   32/  130]
train() client id: f_00008-6-1 loss: 0.737004  [   64/  130]
train() client id: f_00008-6-2 loss: 0.768505  [   96/  130]
train() client id: f_00008-6-3 loss: 0.682636  [  128/  130]
train() client id: f_00008-7-0 loss: 0.676185  [   32/  130]
train() client id: f_00008-7-1 loss: 0.749218  [   64/  130]
train() client id: f_00008-7-2 loss: 0.841076  [   96/  130]
train() client id: f_00008-7-3 loss: 0.768119  [  128/  130]
train() client id: f_00008-8-0 loss: 0.805395  [   32/  130]
train() client id: f_00008-8-1 loss: 0.671673  [   64/  130]
train() client id: f_00008-8-2 loss: 0.797301  [   96/  130]
train() client id: f_00008-8-3 loss: 0.730246  [  128/  130]
train() client id: f_00008-9-0 loss: 0.781401  [   32/  130]
train() client id: f_00008-9-1 loss: 0.770235  [   64/  130]
train() client id: f_00008-9-2 loss: 0.739945  [   96/  130]
train() client id: f_00008-9-3 loss: 0.720666  [  128/  130]
train() client id: f_00008-10-0 loss: 0.855924  [   32/  130]
train() client id: f_00008-10-1 loss: 0.740570  [   64/  130]
train() client id: f_00008-10-2 loss: 0.687876  [   96/  130]
train() client id: f_00008-10-3 loss: 0.733818  [  128/  130]
train() client id: f_00008-11-0 loss: 0.781364  [   32/  130]
train() client id: f_00008-11-1 loss: 0.658650  [   64/  130]
train() client id: f_00008-11-2 loss: 0.792981  [   96/  130]
train() client id: f_00008-11-3 loss: 0.780801  [  128/  130]
train() client id: f_00008-12-0 loss: 0.671248  [   32/  130]
train() client id: f_00008-12-1 loss: 0.755566  [   64/  130]
train() client id: f_00008-12-2 loss: 0.794564  [   96/  130]
train() client id: f_00008-12-3 loss: 0.774824  [  128/  130]
train() client id: f_00009-0-0 loss: 0.942467  [   32/  118]
train() client id: f_00009-0-1 loss: 0.787260  [   64/  118]
train() client id: f_00009-0-2 loss: 0.925180  [   96/  118]
train() client id: f_00009-1-0 loss: 0.889242  [   32/  118]
train() client id: f_00009-1-1 loss: 0.815433  [   64/  118]
train() client id: f_00009-1-2 loss: 0.782647  [   96/  118]
train() client id: f_00009-2-0 loss: 0.812258  [   32/  118]
train() client id: f_00009-2-1 loss: 0.842724  [   64/  118]
train() client id: f_00009-2-2 loss: 0.708296  [   96/  118]
train() client id: f_00009-3-0 loss: 0.752961  [   32/  118]
train() client id: f_00009-3-1 loss: 0.780355  [   64/  118]
train() client id: f_00009-3-2 loss: 0.803204  [   96/  118]
train() client id: f_00009-4-0 loss: 0.889015  [   32/  118]
train() client id: f_00009-4-1 loss: 0.643952  [   64/  118]
train() client id: f_00009-4-2 loss: 0.807534  [   96/  118]
train() client id: f_00009-5-0 loss: 0.800803  [   32/  118]
train() client id: f_00009-5-1 loss: 0.667963  [   64/  118]
train() client id: f_00009-5-2 loss: 0.895427  [   96/  118]
train() client id: f_00009-6-0 loss: 0.594889  [   32/  118]
train() client id: f_00009-6-1 loss: 0.768642  [   64/  118]
train() client id: f_00009-6-2 loss: 0.805439  [   96/  118]
train() client id: f_00009-7-0 loss: 0.744494  [   32/  118]
train() client id: f_00009-7-1 loss: 0.654242  [   64/  118]
train() client id: f_00009-7-2 loss: 0.765248  [   96/  118]
train() client id: f_00009-8-0 loss: 0.683622  [   32/  118]
train() client id: f_00009-8-1 loss: 0.758276  [   64/  118]
train() client id: f_00009-8-2 loss: 0.741527  [   96/  118]
train() client id: f_00009-9-0 loss: 0.637496  [   32/  118]
train() client id: f_00009-9-1 loss: 0.846870  [   64/  118]
train() client id: f_00009-9-2 loss: 0.642799  [   96/  118]
train() client id: f_00009-10-0 loss: 0.767511  [   32/  118]
train() client id: f_00009-10-1 loss: 0.729937  [   64/  118]
train() client id: f_00009-10-2 loss: 0.603872  [   96/  118]
train() client id: f_00009-11-0 loss: 0.747170  [   32/  118]
train() client id: f_00009-11-1 loss: 0.733607  [   64/  118]
train() client id: f_00009-11-2 loss: 0.652836  [   96/  118]
train() client id: f_00009-12-0 loss: 0.621753  [   32/  118]
train() client id: f_00009-12-1 loss: 0.816431  [   64/  118]
train() client id: f_00009-12-2 loss: 0.599275  [   96/  118]
At round 79 accuracy: 0.6392572944297082
At round 79 training accuracy: 0.5875251509054326
At round 79 training loss: 0.8317276038478483
