['f_00000', 'f_00001', 'f_00002', 'f_00003', 'f_00004', 'f_00005', 'f_00006', 'f_00007', 'f_00008', 'f_00009']
10
dict_keys(['x', 'y'])
id = f_00000, model = CustomLogisticRegression(
  (linear): Linear(in_features=784, out_features=10, bias=True)
), num_samples = 974
id = f_00001, model = CustomLogisticRegression(
  (linear): Linear(in_features=784, out_features=10, bias=True)
), num_samples = 173
id = f_00002, model = CustomLogisticRegression(
  (linear): Linear(in_features=784, out_features=10, bias=True)
), num_samples = 347
id = f_00003, model = CustomLogisticRegression(
  (linear): Linear(in_features=784, out_features=10, bias=True)
), num_samples = 307
id = f_00004, model = CustomLogisticRegression(
  (linear): Linear(in_features=784, out_features=10, bias=True)
), num_samples = 103
id = f_00005, model = CustomLogisticRegression(
  (linear): Linear(in_features=784, out_features=10, bias=True)
), num_samples = 107
id = f_00006, model = CustomLogisticRegression(
  (linear): Linear(in_features=784, out_features=10, bias=True)
), num_samples = 162
id = f_00007, model = CustomLogisticRegression(
  (linear): Linear(in_features=784, out_features=10, bias=True)
), num_samples = 171
id = f_00008, model = CustomLogisticRegression(
  (linear): Linear(in_features=784, out_features=10, bias=True)
), num_samples = 103
id = f_00009, model = CustomLogisticRegression(
  (linear): Linear(in_features=784, out_features=10, bias=True)
), num_samples = 441
BaseFederated generated!
Round 1
-------------------------------
gradient difference: 7.207571506500244
At round 0 accuracy: 0.7603305785123967
At round 0 training accuracy: 0.7728531855955678
At round 0 training loss: 0.86526317760856
Round 2
-------------------------------
gradient difference: 0.9944568872451782
At round 1 accuracy: 0.7995867768595041
At round 1 training accuracy: 0.8213296398891967
At round 1 training loss: 0.6183932454036072
Round 3
-------------------------------
gradient difference: 0.918350338935852
At round 2 accuracy: 0.8192148760330579
At round 2 training accuracy: 0.8549168975069252
At round 2 training loss: 0.5116047994999603
Round 4
-------------------------------
gradient difference: 20.20734214782715
At round 3 accuracy: 0.8409090909090909
At round 3 training accuracy: 0.875
At round 3 training loss: 0.43425246215333096
Round 5
-------------------------------
gradient difference: 0.7241579294204712
At round 4 accuracy: 0.8553719008264463
At round 4 training accuracy: 0.8909279778393352
At round 4 training loss: 0.3716441804844618
Round 6
-------------------------------
gradient difference: 0.6201549768447876
At round 5 accuracy: 0.862603305785124
At round 5 training accuracy: 0.9013157894736842
At round 5 training loss: 0.3552211462116021
Round 7
-------------------------------
gradient difference: 0.4538382589817047
At round 6 accuracy: 0.868801652892562
At round 6 training accuracy: 0.9082409972299169
At round 6 training loss: 0.3234272252836124
Round 8
-------------------------------
gradient difference: 3.450878143310547
At round 7 accuracy: 0.8739669421487604
At round 7 training accuracy: 0.9117036011080333
At round 7 training loss: 0.2941332432854768
Round 9
-------------------------------
gradient difference: 1.29337477684021
At round 8 accuracy: 0.881198347107438
At round 8 training accuracy: 0.9179362880886427
At round 8 training loss: 0.28156823795066355
Round 10
-------------------------------
gradient difference: 0.3750302195549011
At round 9 accuracy: 0.8842975206611571
At round 9 training accuracy: 0.9220914127423823
At round 9 training loss: 0.2650797891789856
Round 11
-------------------------------
gradient difference: 8.930673599243164
At round 10 accuracy: 0.8884297520661157
At round 10 training accuracy: 0.9265927977839336
At round 10 training loss: 0.2482835171701313
Round 12
-------------------------------
gradient difference: 1.312252402305603
At round 11 accuracy: 0.8894628099173554
At round 11 training accuracy: 0.9307479224376731
At round 11 training loss: 0.23236913887419308
Round 13
-------------------------------
gradient difference: 9.489062309265137
At round 12 accuracy: 0.893595041322314
At round 12 training accuracy: 0.9331717451523546
At round 12 training loss: 0.22308395575413018
Round 14
-------------------------------
gradient difference: 0.5691112279891968
At round 13 accuracy: 0.8946280991735537
At round 13 training accuracy: 0.9369806094182825
At round 13 training loss: 0.22724484220071178
Round 15
-------------------------------
gradient difference: 1.1779038906097412
At round 14 accuracy: 0.8956611570247934
At round 14 training accuracy: 0.9397506925207756
At round 14 training loss: 0.21062568895903905
Round 16
-------------------------------
gradient difference: 1.1863834857940674
At round 15 accuracy: 0.8966942148760331
At round 15 training accuracy: 0.943213296398892
At round 15 training loss: 0.20496001173248846
Round 17
-------------------------------
gradient difference: 0.3700709939002991
At round 16 accuracy: 0.8997933884297521
At round 16 training accuracy: 0.9452908587257618
At round 16 training loss: 0.19524290961087754
Round 18
-------------------------------
gradient difference: 1.544543981552124
At round 17 accuracy: 0.9028925619834711
At round 17 training accuracy: 0.9466759002770083
At round 17 training loss: 0.1851258251916914
Round 19
-------------------------------
gradient difference: 0.22535201907157898
At round 18 accuracy: 0.9018595041322314
At round 18 training accuracy: 0.949792243767313
At round 18 training loss: 0.1796547198330962
Round 20
-------------------------------
gradient difference: 1.0344642400741577
At round 19 accuracy: 0.9008264462809917
At round 19 training accuracy: 0.949792243767313
At round 19 training loss: 0.1816194405969156
Round 21
-------------------------------
gradient difference: 0.4568557143211365
At round 20 accuracy: 0.9008264462809917
At round 20 training accuracy: 0.9511772853185596
At round 20 training loss: 0.17701331440168114
Round 22
-------------------------------
gradient difference: 0.358103483915329
At round 21 accuracy: 0.9039256198347108
At round 21 training accuracy: 0.9525623268698061
At round 21 training loss: 0.17553844243696512
Round 23
-------------------------------
gradient difference: 0.7662786245346069
At round 22 accuracy: 0.9049586776859504
At round 22 training accuracy: 0.9542936288088643
At round 22 training loss: 0.16043866915887797
Round 24
-------------------------------
gradient difference: 0.3963795602321625
At round 23 accuracy: 0.9039256198347108
At round 23 training accuracy: 0.9549861495844876
At round 23 training loss: 0.15715740846109486
Round 25
-------------------------------
gradient difference: 0.7890016436576843
At round 24 accuracy: 0.9039256198347108
At round 24 training accuracy: 0.9560249307479224
At round 24 training loss: 0.15044220940985287
Round 26
-------------------------------
gradient difference: 0.6308513879776001
At round 25 accuracy: 0.9049586776859504
At round 25 training accuracy: 0.9570637119113573
At round 25 training loss: 0.1485715280937156
Round 27
-------------------------------
gradient difference: 0.31305140256881714
At round 26 accuracy: 0.90599173553719
At round 26 training accuracy: 0.957409972299169
At round 26 training loss: 0.1512184216734133
Round 28
-------------------------------
gradient difference: 0.4584384560585022
At round 27 accuracy: 0.90599173553719
At round 27 training accuracy: 0.957409972299169
At round 27 training loss: 0.1447711392319275
Round 29
-------------------------------
gradient difference: 0.43995052576065063
At round 28 accuracy: 0.9028925619834711
At round 28 training accuracy: 0.9581024930747922
At round 28 training loss: 0.14590010983537055
Round 30
-------------------------------
gradient difference: 0.6073359251022339
At round 29 accuracy: 0.9018595041322314
At round 29 training accuracy: 0.9591412742382271
At round 29 training loss: 0.14029002403873253
Round 31
-------------------------------
gradient difference: 0.5442191362380981
At round 30 accuracy: 0.9008264462809917
At round 30 training accuracy: 0.9598337950138505
At round 30 training loss: 0.1337901015198507
Round 32
-------------------------------
gradient difference: 0.6925987005233765
At round 31 accuracy: 0.9008264462809917
At round 31 training accuracy: 0.9601800554016621
At round 31 training loss: 0.13977956235503466
Round 33
-------------------------------
gradient difference: 0.7239560484886169
At round 32 accuracy: 0.9008264462809917
At round 32 training accuracy: 0.961218836565097
At round 32 training loss: 0.13262816230587188
Round 34
-------------------------------
gradient difference: 0.5215942859649658
At round 33 accuracy: 0.9008264462809917
At round 33 training accuracy: 0.961218836565097
At round 33 training loss: 0.14147607112454857
Round 35
-------------------------------
gradient difference: 0.9854928255081177
At round 34 accuracy: 0.9018595041322314
At round 34 training accuracy: 0.9622576177285319
At round 34 training loss: 0.13407471241452004
Round 36
-------------------------------
gradient difference: 0.6054288744926453
At round 35 accuracy: 0.9018595041322314
At round 35 training accuracy: 0.9629501385041551
At round 35 training loss: 0.11985009435381414
Round 37
-------------------------------
gradient difference: 0.42348575592041016
At round 36 accuracy: 0.9028925619834711
At round 36 training accuracy: 0.9646814404432132
At round 36 training loss: 0.12135582572556143
Round 38
-------------------------------
gradient difference: 1.2449184656143188
At round 37 accuracy: 0.9028925619834711
At round 37 training accuracy: 0.9653739612188366
At round 37 training loss: 0.12318194419884046
Round 39
-------------------------------
gradient difference: 0.25245407223701477
At round 38 accuracy: 0.9028925619834711
At round 38 training accuracy: 0.9653739612188366
At round 38 training loss: 0.11937709443776218
Round 40
-------------------------------
gradient difference: 0.3467617928981781
At round 39 accuracy: 0.9028925619834711
At round 39 training accuracy: 0.9664127423822715
At round 39 training loss: 0.12004643543260957
Round 41
-------------------------------
gradient difference: 1.9310121536254883
At round 40 accuracy: 0.9028925619834711
At round 40 training accuracy: 0.9671052631578947
At round 40 training loss: 0.11075225798992856
Round 42
-------------------------------
gradient difference: 0.23902329802513123
At round 41 accuracy: 0.9028925619834711
At round 41 training accuracy: 0.9674515235457064
At round 41 training loss: 0.11523952851014999
Round 43
-------------------------------
gradient difference: 3.650606155395508
At round 42 accuracy: 0.9018595041322314
At round 42 training accuracy: 0.9684903047091413
At round 42 training loss: 0.10765498046487627
Round 44
-------------------------------
gradient difference: 5.099369525909424
At round 43 accuracy: 0.9008264462809917
At round 43 training accuracy: 0.9691828254847645
At round 43 training loss: 0.11160756899888352
Round 45
-------------------------------
gradient difference: 0.28106561303138733
At round 44 accuracy: 0.9018595041322314
At round 44 training accuracy: 0.9691828254847645
At round 44 training loss: 0.11094825984643096
Round 46
-------------------------------
gradient difference: 1.3749988079071045
At round 45 accuracy: 0.9008264462809917
At round 45 training accuracy: 0.9691828254847645
At round 45 training loss: 0.10678346592229049
Round 47
-------------------------------
gradient difference: 0.39875757694244385
At round 46 accuracy: 0.9008264462809917
At round 46 training accuracy: 0.9695290858725761
At round 46 training loss: 0.10413865950688858
Round 48
-------------------------------
gradient difference: 0.2263633757829666
At round 47 accuracy: 0.9008264462809917
At round 47 training accuracy: 0.9698753462603878
At round 47 training loss: 0.09967971154957936
Round 49
-------------------------------
gradient difference: 0.6191378831863403
At round 48 accuracy: 0.9018595041322314
At round 48 training accuracy: 0.9702216066481995
At round 48 training loss: 0.10120844194623979
Round 50
-------------------------------
gradient difference: 0.42476242780685425
At round 49 accuracy: 0.9018595041322314
At round 49 training accuracy: 0.9702216066481995
At round 49 training loss: 0.10043487789177508
Round 51
-------------------------------
gradient difference: 0.15933595597743988
At round 50 accuracy: 0.9018595041322314
At round 50 training accuracy: 0.9712603878116344
At round 50 training loss: 0.10678319801578169
Round 52
-------------------------------
gradient difference: 0.1866796314716339
At round 51 accuracy: 0.9018595041322314
At round 51 training accuracy: 0.971606648199446
At round 51 training loss: 0.0977017609874878
Round 53
-------------------------------
gradient difference: 0.20146897435188293
At round 52 accuracy: 0.9018595041322314
At round 52 training accuracy: 0.971606648199446
At round 52 training loss: 0.10402910895255998
Round 54
-------------------------------
gradient difference: 2.227600336074829
At round 53 accuracy: 0.9018595041322314
At round 53 training accuracy: 0.9719529085872576
At round 53 training loss: 0.09405584858856597
Round 55
-------------------------------
gradient difference: 0.29134055972099304
At round 54 accuracy: 0.9008264462809917
At round 54 training accuracy: 0.9719529085872576
At round 54 training loss: 0.09726324578455235
Round 56
-------------------------------
gradient difference: 0.19353145360946655
At round 55 accuracy: 0.9008264462809917
At round 55 training accuracy: 0.9719529085872576
At round 55 training loss: 0.09966109721064173
Round 57
-------------------------------
gradient difference: 0.4313265383243561
At round 56 accuracy: 0.9018595041322314
At round 56 training accuracy: 0.9722991689750693
At round 56 training loss: 0.08804727155137364
Round 58
-------------------------------
gradient difference: 0.18213224411010742
At round 57 accuracy: 0.9018595041322314
At round 57 training accuracy: 0.9726454293628809
At round 57 training loss: 0.09103287813416581
Round 59
-------------------------------
gradient difference: 0.4678994119167328
At round 58 accuracy: 0.9018595041322314
At round 58 training accuracy: 0.9726454293628809
At round 58 training loss: 0.09677792665550833
Round 60
-------------------------------
gradient difference: 0.21822519600391388
At round 59 accuracy: 0.9028925619834711
At round 59 training accuracy: 0.9726454293628809
At round 59 training loss: 0.08890033840224464
Round 61
-------------------------------
gradient difference: 0.7526823878288269
At round 60 accuracy: 0.9028925619834711
At round 60 training accuracy: 0.9729916897506925
At round 60 training loss: 0.09306149765213853
Round 62
-------------------------------
gradient difference: 1.477690577507019
At round 61 accuracy: 0.9028925619834711
At round 61 training accuracy: 0.9740304709141274
At round 61 training loss: 0.08697052186244895
Round 63
-------------------------------
gradient difference: 0.23142346739768982
At round 62 accuracy: 0.9018595041322314
At round 62 training accuracy: 0.9747229916897507
At round 62 training loss: 0.08868096273615014
Round 64
-------------------------------
gradient difference: 0.19064798951148987
At round 63 accuracy: 0.9028925619834711
At round 63 training accuracy: 0.975415512465374
At round 63 training loss: 0.09148499291422633
Round 65
-------------------------------
gradient difference: 0.5006273984909058
At round 64 accuracy: 0.9028925619834711
At round 64 training accuracy: 0.975415512465374
At round 64 training loss: 0.08202702915257795
Round 66
-------------------------------
gradient difference: 0.23519225418567657
At round 65 accuracy: 0.9028925619834711
At round 65 training accuracy: 0.9757617728531855
At round 65 training loss: 0.07979229243372819
Round 67
-------------------------------
gradient difference: 0.286178857088089
At round 66 accuracy: 0.9028925619834711
At round 66 training accuracy: 0.9761080332409973
At round 66 training loss: 0.07997675038409759
Round 68
-------------------------------
gradient difference: 0.32231658697128296
At round 67 accuracy: 0.9028925619834711
At round 67 training accuracy: 0.9768005540166205
At round 67 training loss: 0.08698064951838869
Round 69
-------------------------------
gradient difference: 0.08569563180208206
At round 68 accuracy: 0.9039256198347108
At round 68 training accuracy: 0.9771468144044322
At round 68 training loss: 0.07980249018144707
Round 70
-------------------------------
gradient difference: 0.6407904624938965
At round 69 accuracy: 0.9049586776859504
At round 69 training accuracy: 0.9774930747922438
At round 69 training loss: 0.08397318451060654
Round 71
-------------------------------
gradient difference: 0.9884532690048218
At round 70 accuracy: 0.9049586776859504
At round 70 training accuracy: 0.9774930747922438
At round 70 training loss: 0.07906162477337313
Round 72
-------------------------------
gradient difference: 0.16305866837501526
At round 71 accuracy: 0.9049586776859504
At round 71 training accuracy: 0.9774930747922438
At round 71 training loss: 0.07636578084623262
Round 73
-------------------------------
gradient difference: 0.3917510509490967
At round 72 accuracy: 0.90599173553719
At round 72 training accuracy: 0.9774930747922438
At round 72 training loss: 0.0778326278343827
Round 74
-------------------------------
gradient difference: 1.7624775171279907
At round 73 accuracy: 0.9049586776859504
At round 73 training accuracy: 0.9788781163434903
At round 73 training loss: 0.07471948557925671
Round 75
-------------------------------
gradient difference: 0.1805078238248825
At round 74 accuracy: 0.90599173553719
At round 74 training accuracy: 0.9792243767313019
At round 74 training loss: 0.07441843676851125
Round 76
-------------------------------
gradient difference: 0.7733569741249084
At round 75 accuracy: 0.90599173553719
At round 75 training accuracy: 0.9795706371191135
At round 75 training loss: 0.0717518468136884
Round 77
-------------------------------
gradient difference: 0.14227673411369324
At round 76 accuracy: 0.90599173553719
At round 76 training accuracy: 0.9799168975069252
At round 76 training loss: 0.07516376425083197
Round 78
-------------------------------
gradient difference: 0.26467758417129517
At round 77 accuracy: 0.90599173553719
At round 77 training accuracy: 0.9799168975069252
At round 77 training loss: 0.07146897605721846
Round 79
-------------------------------
gradient difference: 0.12299543619155884
At round 78 accuracy: 0.90599173553719
At round 78 training accuracy: 0.9802631578947368
At round 78 training loss: 0.07155935792720863
Round 80
-------------------------------
gradient difference: 0.8490541577339172
At round 79 accuracy: 0.90599173553719
At round 79 training accuracy: 0.9806094182825484
At round 79 training loss: 0.07023206590107993
Round 81
-------------------------------
gradient difference: 0.12634626030921936
At round 80 accuracy: 0.90599173553719
At round 80 training accuracy: 0.9806094182825484
At round 80 training loss: 0.07323035973067221
Round 82
-------------------------------
gradient difference: 0.4628097116947174
At round 81 accuracy: 0.9049586776859504
At round 81 training accuracy: 0.9809556786703602
At round 81 training loss: 0.06902700402293739
Round 83
-------------------------------
gradient difference: 0.4032610356807709
At round 82 accuracy: 0.9049586776859504
At round 82 training accuracy: 0.9809556786703602
At round 82 training loss: 0.07025874781602302
Round 84
-------------------------------
gradient difference: 0.1701921969652176
At round 83 accuracy: 0.9049586776859504
At round 83 training accuracy: 0.9816481994459834
At round 83 training loss: 0.06819915476263713
Round 85
-------------------------------
gradient difference: 0.5863581895828247
At round 84 accuracy: 0.90599173553719
At round 84 training accuracy: 0.9823407202216067
At round 84 training loss: 0.0659872509089028
Round 86
-------------------------------
gradient difference: 0.7814852595329285
At round 85 accuracy: 0.90599173553719
At round 85 training accuracy: 0.9823407202216067
At round 85 training loss: 0.07085937939938776
Round 87
-------------------------------
gradient difference: 0.2583127021789551
At round 86 accuracy: 0.90599173553719
At round 86 training accuracy: 0.9826869806094183
At round 86 training loss: 0.06791308670371708
Round 88
-------------------------------
gradient difference: 0.148824542760849
At round 87 accuracy: 0.90599173553719
At round 87 training accuracy: 0.9830332409972299
At round 87 training loss: 0.06520330583356654
Round 89
-------------------------------
gradient difference: 0.6929186582565308
At round 88 accuracy: 0.90599173553719
At round 88 training accuracy: 0.9837257617728532
At round 88 training loss: 0.0631745424164579
Round 90
-------------------------------
gradient difference: 0.10483703762292862
At round 89 accuracy: 0.90599173553719
At round 89 training accuracy: 0.9840720221606648
At round 89 training loss: 0.06259595116281173
Round 91
-------------------------------
gradient difference: 1.301898717880249
At round 90 accuracy: 0.90599173553719
At round 90 training accuracy: 0.9840720221606648
At round 90 training loss: 0.06481338044670795
Round 92
-------------------------------
gradient difference: 0.26209157705307007
At round 91 accuracy: 0.90599173553719
At round 91 training accuracy: 0.9844182825484764
At round 91 training loss: 0.06612360994186685
Round 93
-------------------------------
gradient difference: 0.2838020622730255
At round 92 accuracy: 0.90599173553719
At round 92 training accuracy: 0.9847645429362881
At round 92 training loss: 0.06510366786965253
Round 94
-------------------------------
gradient difference: 0.10238026082515717
At round 93 accuracy: 0.90599173553719
At round 93 training accuracy: 0.9847645429362881
At round 93 training loss: 0.059953823418495825
Round 95
-------------------------------
gradient difference: 0.13052409887313843
At round 94 accuracy: 0.90599173553719
At round 94 training accuracy: 0.9847645429362881
At round 94 training loss: 0.06051349616479024
Round 96
-------------------------------
gradient difference: 0.20925351977348328
At round 95 accuracy: 0.90599173553719
At round 95 training accuracy: 0.9847645429362881
At round 95 training loss: 0.05887007839273487
Round 97
-------------------------------
gradient difference: 0.09870238602161407
At round 96 accuracy: 0.90599173553719
At round 96 training accuracy: 0.9854570637119113
At round 96 training loss: 0.06386979135796211
Round 98
-------------------------------
gradient difference: 0.13008616864681244
At round 97 accuracy: 0.90599173553719
At round 97 training accuracy: 0.985803324099723
At round 97 training loss: 0.059726989743167015
Round 99
-------------------------------
gradient difference: 0.2042808085680008
At round 98 accuracy: 0.90599173553719
At round 98 training accuracy: 0.985803324099723
At round 98 training loss: 0.059001898156878826
Round 100
-------------------------------
gradient difference: 0.17427635192871094
At round 99 accuracy: 0.9049586776859504
At round 99 training accuracy: 0.985803324099723
At round 99 training loss: 0.059169790601317274
Done!
Done!
