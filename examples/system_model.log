v = 22.697160301531774
a = 91.65029380654791
['f_00000', 'f_00001', 'f_00002', 'f_00003', 'f_00004', 'f_00005', 'f_00006', 'f_00007', 'f_00008', 'f_00009']
10
dict_keys(['x', 'y'])
id = f_00000, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 83
id = f_00001, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 129
id = f_00002, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 85
id = f_00003, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 80
id = f_00004, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 235
id = f_00005, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 100
id = f_00006, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 146
id = f_00007, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 93
id = f_00008, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 89
id = f_00009, model = CustomLogisticRegression(
  (linear): Linear(in_features=5, out_features=3, bias=True)
), num_samples = 86
BaseFederated generated!
num_samples = [ 83 129  85  80 235 100 146  93  89  86]
msize = 502400
xs = [  6.0943416  -20.79968212  15.00902392  18.81129433 -39.02070377
 -26.04359014   2.55680806  -6.32485185  -0.33602315 -17.06087855]
ys = [ 17.5879595   15.55583871   1.32061395  22.54482414   9.35018685
 -17.18584926   7.37501568 -19.17765202  17.56900603  -0.99851822]
dists_uav = [101.71763524 103.31800857 101.12870423 104.22156154 107.7499017
 104.75505717 100.304178   102.01855757 101.5321766  101.44984286]
dists_bs = [239.94522511 221.81113273 257.42563646 246.58750669 214.31339109
 243.15306433 244.18139867 257.20860434 235.14255819 236.47461703]
uav_gains = [9.58312886e-11 9.21631668e-11 9.72326274e-11 9.01785356e-11
 8.29761259e-11 8.90347214e-11 9.92432040e-11 9.51261523e-11
 9.62695134e-11 9.64649612e-11]
bs_gains = [2.39320649e-11 2.98222725e-11 1.96548195e-11 2.21704798e-11
 3.28364367e-11 2.30584863e-11 2.27876148e-11 1.97012919e-11
 2.53260008e-11 2.49285719e-11]
SystemModel __init__!
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.25032247 0.38905541 0.25635434 0.24127467 0.70874434 0.30159334
 0.44032627 0.2804818  0.26841807 0.25937027]
ene_total = [23.95862193 36.76263384 24.55578251 23.13563591 66.34214127 28.71212373
 41.55773658 26.7889216  25.62334201 24.78863831]
obj_prev = 322.2255776928103
t_co_uav = [0.06351163 0.06396501 0.06334461 0.06422068 0.06521719 0.06437154
 0.0631106  0.06359693 0.06345904 0.0634357 ]
t_co_bs = [0.08476871 0.08051968 0.08895491 0.08634835 0.0787878  0.08552995
 0.08577462 0.08890235 0.0836346  0.08394849]
difference = [-0.02125708 -0.01655467 -0.0256103  -0.02212767 -0.01357061 -0.0211584
 -0.02266402 -0.02530541 -0.02017555 -0.0205128 ]
decs_opt = [1 0 1 1 0 0 1 1 0 0]
af = 16.896171935691484	bf = 66.9234999628387	zeta = 33.79234387138297	eta = 0.5
af = 16.896171935691484	bf = 66.9234999628387	zeta = 157.27006780463867	eta = 0.1074341238072076
af = 16.896171935691484	bf = 66.9234999628387	zeta = 117.20903882473088	eta = 0.1441541719402482
af = 16.896171935691484	bf = 66.9234999628387	zeta = 116.43361171638361	eta = 0.14511421304054584
af = 16.896171935691484	bf = 66.9234999628387	zeta = 116.4331772754501	eta = 0.14511475449750555
af = 16.896171935691484	bf = 66.9234999628387	zeta = 116.43317727531253	eta = 0.14511475449767702
eta_opt = 0.14511475449767702
solve_bound_eta tau = 65.0
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [5.82085955 7.37965242 5.80555201 5.88584406 7.22092485 7.83884461
 5.78410521 5.82867765 7.66513541 7.69390417]
solve_bound_eta tau = 37.5
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [5.82085955 7.37965242 5.80555201 5.88584406 7.22092485 7.83884461
 5.78410521 5.82867765 7.66513541 7.69390417]
solve_bound_eta tau = 23.75
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [5.82085955 7.37965242 5.80555201 5.88584406 7.22092485 7.83884461
 5.78410521 5.82867765 7.66513541 7.69390417]
solve_bound_eta tau = 16.875
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [5.82085955 7.37965242 5.80555201 5.88584406 7.22092485 7.83884461
 5.78410521 5.82867765 7.66513541 7.69390417]
solve_bound_eta tau = 13.4375
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [5.82085955 7.37965242 5.80555201 5.88584406 7.22092485 7.83884461
 5.78410521 5.82867765 7.66513541 7.69390417]
solve_bound_eta tau = 15.15625
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [5.82085955 7.37965242 5.80555201 5.88584406 7.22092485 7.83884461
 5.78410521 5.82867765 7.66513541 7.69390417]
solve_bound_eta tau = 16.015625
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [5.82085955 7.37965242 5.80555201 5.88584406 7.22092485 7.83884461
 5.78410521 5.82867765 7.66513541 7.69390417]
solve_bound_eta tau = 16.4453125
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [5.82085955 7.37965242 5.80555201 5.88584406 7.22092485 7.83884461
 5.78410521 5.82867765 7.66513541 7.69390417]
solve_bound_eta tau = 16.23046875
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [5.82085955 7.37965242 5.80555201 5.88584406 7.22092485 7.83884461
 5.78410521 5.82867765 7.66513541 7.69390417]
solve_bound_eta tau = 16.337890625
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [5.82085955 7.37965242 5.80555201 5.88584406 7.22092485 7.83884461
 5.78410521 5.82867765 7.66513541 7.69390417]
solve_bound_eta tau = 16.3916015625
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [5.82085955 7.37965242 5.80555201 5.88584406 7.22092485 7.83884461
 5.78410521 5.82867765 7.66513541 7.69390417]
solve_bound_eta tau = 16.41845703125
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [5.82085955 7.37965242 5.80555201 5.88584406 7.22092485 7.83884461
 5.78410521 5.82867765 7.66513541 7.69390417]
solve_bound_eta tau = 16.405029296875
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [5.82085955 7.37965242 5.80555201 5.88584406 7.22092485 7.83884461
 5.78410521 5.82867765 7.66513541 7.69390417]
solve_bound_eta tau = 16.4117431640625
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [5.82085955 7.37965242 5.80555201 5.88584406 7.22092485 7.83884461
 5.78410521 5.82867765 7.66513541 7.69390417]
solve_bound_eta tau = 16.40838623046875
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [5.82085955 7.37965242 5.80555201 5.88584406 7.22092485 7.83884461
 5.78410521 5.82867765 7.66513541 7.69390417]
solve_bound_eta tau = 16.410064697265625
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [5.82085955 7.37965242 5.80555201 5.88584406 7.22092485 7.83884461
 5.78410521 5.82867765 7.66513541 7.69390417]
solve_bound_eta tau = 16.409225463867188
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [5.82085955 7.37965242 5.80555201 5.88584406 7.22092485 7.83884461
 5.78410521 5.82867765 7.66513541 7.69390417]
initialize_feasible_solution eta = 0.14511475449767702, tau = 16.409225463867188
ti_comp = [0.0262303  0.04076758 0.02686236 0.02528222 0.07426652 0.03160278
 0.04614005 0.02939058 0.02812647 0.02717839]
ti_coms = [0.06351163 0.08051968 0.06334461 0.06422068 0.0787878  0.08552995
 0.0631106  0.06359693 0.0836346  0.08394849]
t_total = [ 9.62102767 13.00293018  9.67088294  9.5954013  16.40860404 12.55753137
 11.71251303  9.96897901 11.98164868 11.91365904]
optimize_network_fake eta = 0.14511475449767702	tau = 21	t_min = 16.409225463867188
solve_bound_eta tau = 21
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [7.76907748 7.37965242 8.15274363 7.91385127 7.22092485 7.83884461
 7.86126889 8.1479262  7.66513541 7.69390417]
eta_min = 0.02304542908779013	eta_max = 0.5582623390540764
af = 67.58468774276595	bf = 7.764332893581674	zeta = 135.1693754855319	eta = 0.5
af = 67.58468774276595	bf = 7.764332893581674	zeta = 109.22093730300837	eta = 0.6187887543508969
af = 67.58468774276595	bf = 7.764332893581674	zeta = 105.46487745121274	eta = 0.6408264948113187
af = 67.58468774276595	bf = 7.764332893581674	zeta = 105.35099162053821	eta = 0.6415192368212156
af = 67.58468774276595	bf = 7.764332893581674	zeta = 105.3508816214889	eta = 0.6415199066448096
eta = 0.6415199066448096
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.02412982 0.03750297 0.02471126 0.02325766 0.06831936 0.02907207
 0.04244522 0.02703702 0.02587414 0.02500198]
ene_total = [ 8.33634183 11.64673705  8.59202099  8.15374723 19.48108766  9.61935739
 13.04464025  9.18529062  8.75330672  8.53835188]
ti_comp = [0.01644745 0.02069648 0.01226125 0.01486781 0.02242836 0.01568622
 0.01544154 0.01231381 0.01758156 0.01726767]
ti_coms = [0.08476871 0.08051968 0.08895491 0.08634835 0.0787878  0.08552995
 0.08577462 0.08890235 0.0836346  0.08394849]
t_total = [21. 21. 21. 21. 21. 21. 21. 21. 21. 21.]
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00734998 0.01742711 0.01420484 0.00805424 0.08971345 0.0141323
 0.04538646 0.01844645 0.00793057 0.00741783]
ene_total = [ 3.2837044   5.28631548  4.79278146  3.46259575 20.24811869  4.70667053
 11.19625817  5.67172621  3.38063131  3.28076434]
optimize_network_iter = 0 obj = 65.30956634498901
eta = 0.5582623390540764
freqs = [9.63250592e+08 1.18974237e+09 1.32325593e+09 1.02707591e+09
 2.00000000e+09 1.21686254e+09 1.80476996e+09 1.44161754e+09
 9.66256019e+08 9.50658428e+08]
solve_bound_eta tau = 21
af = [2.58594172 3.2539937  1.92776905 2.33758478 3.5262881  2.4662574
 2.42778893 1.93603327 2.76425256 2.71490023]
bf = [7.76907748 7.37965242 8.15274363 7.91385127 7.22092485 7.83884461
 7.86126889 8.1479262  7.66513541 7.69390417]
eta_min = 0.023045429087790035	eta_max = 0.5582623390540764
af = 36.17157556423893	bf = 7.764332893581674	zeta = 72.34315112847786	eta = 0.5
af = 36.17157556423893	bf = 7.764332893581674	zeta = 65.6731170246898	eta = 0.5507820734417133
af = 36.17157556423893	bf = 7.764332893581674	zeta = 65.30826066169419	eta = 0.5538591167143876
af = 36.17157556423893	bf = 7.764332893581674	zeta = 65.30700478715184	eta = 0.5538697676019454
af = 36.17157556423893	bf = 7.764332893581674	zeta = 65.3070047721606	eta = 0.5538697677290865
eta = 0.5538697677290865
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00744959 0.01766327 0.01439733 0.00816339 0.09092918 0.01432381
 0.0460015  0.01869642 0.00803803 0.00751836]
ene_total = [ 3.27183485  5.28278201  4.78513685  3.45092543 20.29851     4.6996718
 11.21237174  5.66723576  3.3694237   3.26911263]
ti_comp = [0.01745393 0.02170296 0.01326773 0.01587429 0.02343484 0.01669269
 0.01644802 0.01332029 0.01858804 0.01827414]
ti_coms = [0.08476871 0.08051968 0.08895491 0.08634835 0.0787878  0.08552995
 0.08577462 0.08890235 0.0836346  0.08394849]
t_total = [21. 21. 21. 21. 21. 21. 21. 21. 21. 21.]
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.0067957  0.01650128 0.01263135 0.00735644 0.08555904 0.01299372
 0.04165025 0.01641374 0.00738736 0.00689616]
ene_total = [ 3.13750511  5.04407039  4.42234481  3.28514996 19.19529995  4.42642645
 10.31847617  5.19829631  3.23575237  3.14129319]
optimize_network_iter = 1 obj = 61.40461470687329
eta = 0.5538697677290865
freqs = [9.20005479e+08 1.14994276e+09 1.23944648e+09 9.74991965e+08
 1.94004274e+09 1.15898821e+09 1.71729393e+09 1.35074895e+09
 9.26321642e+08 9.10472511e+08]
solve_bound_eta tau = 21
af = [2.70749463 3.36661467 2.0581218  2.46245825 3.63526847 2.58941051
 2.55145637 2.06627554 2.88342143 2.83472895]
bf = [7.76907748 7.37965242 8.15274363 7.91385127 7.22092485 7.83884461
 7.86126889 8.1479262  7.66513541 7.69390417]
eta_min = 0.026291547098068947	eta_max = 0.5538697677290861
af = 33.224895693134066	bf = 7.764332893581674	zeta = 66.44979138626813	eta = 0.5
af = 33.224895693134066	bf = 7.764332893581674	zeta = 61.58815133535164	eta = 0.5394689558422084
af = 33.224895693134066	bf = 7.764332893581674	zeta = 61.38509749342208	eta = 0.5412534483095737
af = 33.224895693134066	bf = 7.764332893581674	zeta = 61.384702995440236	eta = 0.5412569267558739
af = 33.224895693134066	bf = 7.764332893581674	zeta = 61.384702993944586	eta = 0.5412569267690617
eta = 0.5412569267690617
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00706066 0.01714464 0.01312383 0.00764325 0.08889487 0.01350033
 0.04327413 0.01705369 0.00767538 0.00716504]
ene_total = [ 3.10417575  5.03392165  4.39914571  3.25212897 19.33398934  4.40593773
 10.35920588  5.18322539  3.20433038  3.10864221]
ti_comp = [0.02034393 0.02459296 0.01615773 0.0187643  0.02632484 0.0195827
 0.01933802 0.0162103  0.02147804 0.02116415]
ti_coms = [0.08476871 0.08051968 0.08895491 0.08634835 0.0787878  0.08552995
 0.08577462 0.08890235 0.0836346  0.08394849]
t_total = [21. 21. 21. 21. 21. 21. 21. 21. 21. 21.]
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00561026 0.01441339 0.00955245 0.00590506 0.07604851 0.01058946
 0.03379505 0.01243042 0.00620582 0.0057665 ]
ene_total = [ 2.81440801  4.48825734  3.68563406  2.90486218 16.76747076  3.82438785
  8.46542089  4.25956097  2.91073365  2.82923537]
optimize_network_iter = 2 obj = 52.949971073622805
eta = 0.5412569267690617
freqs = [8.20086216e+08 1.05437509e+09 1.05743765e+09 8.56986448e+08
 1.79439606e+09 1.02646406e+09 1.51759887e+09 1.15320965e+09
 8.32935761e+08 8.16796588e+08]
solve_bound_eta tau = 21
af = [3.03737564 3.67176181 2.41237091 2.80153439 3.93033421 2.92372269
 2.8871928  2.42021867 3.20670068 3.15983541]
bf = [7.76907748 7.37965242 8.15274363 7.91385127 7.22092485 7.83884461
 7.86126889 8.1479262  7.66513541 7.69390417]
eta_min = 0.03648353382794034	eta_max = 0.5412569267690615
af = 26.921557364754932	bf = 7.764332893581674	zeta = 53.843114729509864	eta = 0.5
af = 26.921557364754932	bf = 7.764332893581674	zeta = 52.84986895448877	eta = 0.5093968612852798
af = 26.921557364754932	bf = 7.764332893581674	zeta = 52.840415828713894	eta = 0.5094879921464499
af = 26.921557364754932	bf = 7.764332893581674	zeta = 52.84041495063129	eta = 0.5094880006129342
eta = 0.5094880006129342
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00616308 0.01583364 0.01049371 0.00648692 0.08354207 0.01163291
 0.0371251  0.01365527 0.00681732 0.00633471]
ene_total = [ 2.73541922  4.46293457  3.62279895  2.82544244 17.08163715  3.77165866
  8.53934889  4.21254123  2.83647105  2.75216279]
ti_comp = [0.0276232  0.03187223 0.023437   0.02604357 0.03360412 0.02686197
 0.0266173  0.02348957 0.02875732 0.02844342]
ti_coms = [0.08476871 0.08051968 0.08895491 0.08634835 0.0787878  0.08552995
 0.08577462 0.08890235 0.0836346  0.08394849]
t_total = [21. 21. 21. 21. 21. 21. 21. 21. 21. 21.]
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00403412 0.01137644 0.00601887 0.00406379 0.06187012 0.00746082
 0.02364792 0.00784804 0.00458919 0.00423247]
ene_total = [ 2.33763053  3.63012415  2.78669116  2.37268955 13.03231494  2.99212025
  6.02118976  3.12748233  2.42015224  2.35936667]
optimize_network_iter = 3 obj = 41.079761574099024
eta = 0.5094880006129342
freqs = [6.63490719e+08 8.93733381e+08 8.00843377e+08 6.78297569e+08
 1.54420925e+09 8.22039942e+08 1.21121063e+09 8.74256137e+08
 6.83395956e+08 6.67647770e+08]
solve_bound_eta tau = 21
af = [3.75424979 4.33173277 3.18530676 3.53956304 4.56711174 3.65079129
 3.61753806 3.19245059 3.90838671 3.86572516]
bf = [7.76907748 7.37965242 8.15274363 7.91385127 7.22092485 7.83884461
 7.86126889 8.1479262  7.66513541 7.69390417]
eta_min = 0.06643345159429744	eta_max = 0.5094880006129343
af = 18.367022856793394	bf = 7.764332893581674	zeta = 36.73404571358679	eta = 0.5
af = 18.367022856793394	bf = 7.764332893581674	zeta = 40.99076600409617	eta = 0.44807708289613307
af = 18.367022856793394	bf = 7.764332893581674	zeta = 40.78322261985632	eta = 0.45035732041074544
af = 18.367022856793394	bf = 7.764332893581674	zeta = 40.782792842941845	eta = 0.4503620663628023
af = 18.367022856793394	bf = 7.764332893581674	zeta = 40.782792841086355	eta = 0.45036206638329235
eta = 0.45036206638329235
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00477205 0.01345746 0.00711986 0.00480715 0.07318763 0.00882558
 0.02797369 0.00928363 0.00542866 0.00500669]
ene_total = [ 2.2092141   3.58662596  2.67050688  2.2414068  13.51755386  2.89781976
  6.09478242  3.03043148  2.29978938  2.2346622 ]
ti_comp = [0.04117084 0.04541987 0.03698464 0.0395912  0.04715175 0.0404096
 0.04016493 0.0370372  0.04230495 0.04199105]
ti_coms = [0.08476871 0.08051968 0.08895491 0.08634835 0.0787878  0.08552995
 0.08577462 0.08890235 0.0836346  0.08394849]
t_total = [21. 21. 21. 21. 21. 21. 21. 21. 21. 21.]
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00300599 0.00927278 0.0040008  0.00291075 0.05201643 0.00545712
 0.01719084 0.00522523 0.00351011 0.00321451]
ene_total = [1.91472882 2.88884409 2.15041317 1.92518802 9.98732627 2.3361397
 4.2967784  2.35370604 1.97987747 1.9358215 ]
optimize_network_iter = 4 obj = 31.768823472935438
eta = 0.45036206638329235
freqs = [5.26594039e+08 7.41876085e+08 6.00323122e+08 5.27811462e+08
 1.30183987e+09 6.46402367e+08 9.49496470e+08 6.55891956e+08
 5.49523578e+08 5.34969716e+08]
solve_bound_eta tau = 21
af = [4.73022805 5.2184108  4.24926465 4.54873981 5.41739148 4.64276806
 4.61465701 4.25530378 4.8605297  4.8244652 ]
bf = [7.76907748 7.37965242 8.15274363 7.91385127 7.22092485 7.83884461
 7.86126889 8.1479262  7.66513541 7.69390417]
eta_min = 0.13017437166785475	eta_max = 0.4503620663832922
af = 12.156168891839336	bf = 7.764332893581674	zeta = 24.31233778367867	eta = 0.5
af = 12.156168891839336	bf = 7.764332893581674	zeta = 32.38069417474125	eta = 0.3754140916880598
af = 12.156168891839336	bf = 7.764332893581674	zeta = 31.499338535607322	eta = 0.3859182273969919
af = 12.156168891839336	bf = 7.764332893581674	zeta = 31.49186988716194	eta = 0.3860097522121083
af = 12.156168891839336	bf = 7.764332893581674	zeta = 31.491869330546717	eta = 0.38600975903478696
eta = 0.38600975903478696
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00358702 0.01106513 0.00477412 0.00347337 0.06207076 0.00651193
 0.02051368 0.00623522 0.00418858 0.00383584]
ene_total = [ 1.80077673  2.85360818  2.0404618   1.80739184 10.44136372  2.24874097
  4.34243347  2.25777548  1.8736422   1.82567495]
ti_comp = [0.055916   0.06016503 0.0517298  0.05433636 0.06189691 0.05515477
 0.05491009 0.05178236 0.05705011 0.05673622]
ti_coms = [0.08476871 0.08051968 0.08895491 0.08634835 0.0787878  0.08552995
 0.08577462 0.08890235 0.0836346  0.08394849]
t_total = [21. 21. 21. 21. 21. 21. 21. 21. 21. 21.]
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00276907 0.00897952 0.00347494 0.0026258  0.05129059 0.00497744
 0.01562882 0.00454211 0.00327966 0.0029919 ]
ene_total = [1.67868139 2.54228887 1.84653357 1.6808737  8.8322091  2.01968726
 3.61327107 2.00504472 1.73796821 1.69969916]
optimize_network_iter = 5 obj = 27.65625705916787
eta = 0.38600975903478696
freqs = [4.62675011e+08 6.68312529e+08 5.12167655e+08 4.58916248e+08
 1.18340365e+09 5.65133414e+08 8.28771299e+08 5.59802848e+08
 4.86258853e+08 4.72467684e+08]
solve_bound_eta tau = 21
af = [5.38371391 5.79281999 4.98065779 5.23162345 5.95956943 5.31042084
 5.28686327 4.98571869 5.49290908 5.46268637]
bf = [7.76907748 7.37965242 8.15274363 7.91385127 7.22092485 7.83884461
 7.86126889 8.1479262  7.66513541 7.69390417]
eta_min = 0.2014361185142318	eta_max = 0.3860097590347867
af = 9.682120417195517	bf = 7.764332893581674	zeta = 19.364240834391033	eta = 0.5
af = 9.682120417195517	bf = 7.764332893581674	zeta = 28.950934725205254	eta = 0.3344320488818647
af = 9.682120417195517	bf = 7.764332893581674	zeta = 27.59953829731341	eta = 0.350807332821868
af = 9.682120417195517	bf = 7.764332893581674	zeta = 27.58276599992629	eta = 0.35102064880735273
af = 9.682120417195517	bf = 7.764332893581674	zeta = 27.582763244003335	eta = 0.35102068387946844
eta = 0.35102068387946844
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00304548 0.00987585 0.00382181 0.0028879  0.05641039 0.00547429
 0.01718889 0.0049955  0.00360704 0.00329055]
ene_total = [1.62721183 2.53180579 1.79596486 1.62726622 9.07905938 1.98096349
 3.63878059 1.9609736  1.69049992 1.65023756]
ti_comp = [0.06393311 0.06818214 0.05974691 0.06235348 0.06991402 0.06317188
 0.0629272  0.05979947 0.06506722 0.06475333]
ti_coms = [0.08476871 0.08051968 0.08895491 0.08634835 0.0787878  0.08552995
 0.08577462 0.08890235 0.0836346  0.08394849]
t_total = [21. 21. 21. 21. 21. 21. 21. 21. 21. 21.]
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00281786 0.00930174 0.00346547 0.00265268 0.05348246 0.00504765
 0.01583136 0.00453096 0.00335415 0.00305568]
ene_total = [1.59506659 2.45072924 1.74564237 1.59404791 8.66557032 1.92071246
 3.44706711 1.89537119 1.65478607 1.61706879]
optimize_network_iter = 6 obj = 26.586062041785034
eta = 0.35102068387946844
freqs = [4.45048906e+08 6.48596415e+08 4.87706934e+08 4.39829936e+08
 1.15228268e+09 5.42664846e+08 7.95371244e+08 5.33139725e+08
 4.68903194e+08 4.55293896e+08]
solve_bound_eta tau = 21
af = [5.59693521 5.96891084 5.23046044 5.45864847 6.12052612 5.53029421
 5.50887472 5.23506201 5.69621983 5.66874013]
bf = [7.76907748 7.37965242 8.15274363 7.91385127 7.22092485 7.83884461
 7.86126889 8.1479262  7.66513541 7.69390417]
eta_min = 0.2390397782203006	eta_max = 0.3510206838794681
af = 9.064265601595835	bf = 7.764332893581674	zeta = 18.12853120319167	eta = 0.5
af = 9.064265601595835	bf = 7.764332893581674	zeta = 28.094406078348648	eta = 0.3226359573616806
af = 9.064265601595835	bf = 7.764332893581674	zeta = 26.60033143702843	eta = 0.3407576188685422
af = 9.064265601595835	bf = 7.764332893581674	zeta = 26.580170434624815	eta = 0.3410160827933675
af = 9.064265601595835	bf = 7.764332893581674	zeta = 26.58016648189191	eta = 0.3410161335058223
eta = 0.3410161335058223
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00289569 0.00955865 0.00356119 0.00272595 0.05495963 0.00518706
 0.01626861 0.00465611 0.00344679 0.00314007]
ene_total = [1.58167487 2.44925359 1.73245232 1.58003716 8.73945373 1.91094214
 3.45554748 1.88400087 1.64254775 1.60425658]
ti_comp = [0.06622547 0.0704745  0.06203927 0.06464584 0.07220638 0.06546424
 0.06521957 0.06209184 0.06735959 0.06704569]
ti_coms = [0.08476871 0.08051968 0.08895491 0.08634835 0.0787878  0.08552995
 0.08577462 0.08890235 0.0836346  0.08394849]
t_total = [21. 21. 21. 21. 21. 21. 21. 21. 21. 21.]
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00284982 0.00944798 0.00348784 0.00267807 0.05441092 0.00510065
 0.01599324 0.00456051 0.00339629 0.00309305]
ene_total = [1.57529631 2.43386086 1.72225203 1.57337899 8.6631398  1.89892428
 3.41724913 1.87070561 1.63552503 1.59771683]
optimize_network_iter = 7 obj = 26.38804887654326
eta = 0.3410161335058223
freqs = [4.41510404e+08 6.44830530e+08 4.82658682e+08 4.35950641e+08
 1.14651610e+09 5.38125759e+08 7.88611038e+08 5.27638336e+08
 4.65455853e+08 4.51872063e+08]
solve_bound_eta tau = 21
af = [5.64179207 6.00376997 5.28516717 5.50722211 6.15131023 5.5769422
 5.55609841 5.28964507 5.73840818 5.71166706]
bf = [7.76907748 7.37965242 8.15274363 7.91385127 7.22092485 7.83884461
 7.86126889 8.1479262  7.66513541 7.69390417]
eta_min = 0.24957298796376445	eta_max = 0.3410161335058218
af = 8.946586290672279	bf = 7.764332893581674	zeta = 17.893172581344558	eta = 0.5
af = 8.946586290672279	bf = 7.764332893581674	zeta = 27.931267913194844	eta = 0.32030720261166074
af = 8.946586290672279	bf = 7.764332893581674	zeta = 26.408688489581753	eta = 0.3387743505021733
af = 8.946586290672279	bf = 7.764332893581674	zeta = 26.38782391232965	eta = 0.3390422158491063
af = 8.946586290672279	bf = 7.764332893581674	zeta = 26.38781968556592	eta = 0.3390422701564102
eta = 0.3390422701564102
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.0028652  0.00949896 0.00350666 0.00269252 0.05470451 0.00512817
 0.01607954 0.00458512 0.00341462 0.00310974]
ene_total = [1.57272415 2.43366147 1.71971837 1.57068405 8.67797898 1.89706972
 3.41901018 1.86853119 1.63318187 1.5952597 ]
ti_comp = [0.06667774 0.07092678 0.06249155 0.06509811 0.07265866 0.06591651
 0.06567184 0.06254411 0.06781186 0.06749796]
ti_coms = [0.08476871 0.08051968 0.08895491 0.08634835 0.0787878  0.08552995
 0.08577462 0.08890235 0.0836346  0.08394849]
t_total = [21. 21. 21. 21. 21. 21. 21. 21. 21. 21.]
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00285705 0.00947968 0.00349349 0.00268397 0.0546102  0.00511277
 0.01603043 0.00456795 0.00340568 0.00310141]
ene_total = [1.57159366 2.43098849 1.71789126 1.56949831 8.6649014  1.89493452
 3.41220074 1.86614991 1.63194246 1.59410409]
optimize_network_iter = 8 obj = 26.354204826209177
eta = 0.3390422701564102
freqs = [4.40881807e+08 6.44175899e+08 4.81751006e+08 4.35257818e+08
 1.14552736e+09 5.37317227e+08 7.87405883e+08 5.26649299e+08
 4.64846251e+08 4.51266161e+08]
solve_bound_eta tau = 21
af = [5.64983598 6.00987118 5.29512505 5.51598824 6.15661961 5.58533416
 5.56460223 5.29957891 5.74593356 5.71933596]
bf = [7.76907748 7.37965242 8.15274363 7.91385127 7.22092485 7.83884461
 7.86126889 8.1479262  7.66513541 7.69390417]
eta_min = 0.2516389517544012	eta_max = 0.33904227015640936
af = 8.926045078712642	bf = 7.764332893581674	zeta = 17.852090157425284	eta = 0.5
af = 8.926045078712642	bf = 7.764332893581674	zeta = 27.90279174688463	eta = 0.319897921314961
af = 8.926045078712642	bf = 7.764332893581674	zeta = 26.37519139800493	eta = 0.3384257935427845
af = 8.926045078712642	bf = 7.764332893581674	zeta = 26.354202024349146	eta = 0.3386953272372163
af = 8.926045078712642	bf = 7.764332893581674	zeta = 26.354197748073503	eta = 0.33869538219447937
eta = 0.33869538219447937
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00285975 0.00948865 0.00349679 0.00268651 0.05466189 0.00511761
 0.0160456  0.00457227 0.0034089  0.00310434]
ene_total = [1.57114402 2.43095669 1.71744835 1.56902706 8.66751905 1.89461113
 3.41251346 1.86577017 1.63153312 1.59367469]
ti_comp = [0.06675723 0.07100626 0.06257103 0.06517759 0.07273814 0.065996
 0.06575132 0.06262359 0.06789134 0.06757745]
ti_coms = [0.08476871 0.08051968 0.08895491 0.08634835 0.0787878  0.08552995
 0.08577462 0.08890235 0.0836346  0.08394849]
t_total = [21. 21. 21. 21. 21. 21. 21. 21. 21. 21.]
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00285835 0.00948535 0.00349452 0.00268504 0.05464578 0.00511496
 0.01603714 0.00456931 0.00340736 0.00310291]
ene_total = [1.57094956 2.43049902 1.71713332 1.56882289 8.66528662 1.89424366
 3.41134134 1.8653596  1.63132013 1.59347605]
optimize_network_iter = 9 obj = 26.34843218580518
eta = 0.33869538219447937
freqs = [4.40773638e+08 6.44063792e+08 4.81594399e+08 4.35138457e+08
 1.14535856e+09 5.37178011e+08 7.87198340e+08 5.26478658e+08
 4.64741456e+08 4.51161972e+08]
solve_bound_eta tau = 21
af = [5.65122249 6.01091727 5.29684694 5.51750131 6.15752694 5.58678165
 5.56606933 5.3012966  5.74722921 5.72065676]
bf = [7.76907748 7.37965242 8.15274363 7.91385127 7.22092485 7.83884461
 7.86126889 8.1479262  7.66513541 7.69390417]
eta_min = 0.2520016061891967	eta_max = 0.338695382194479
af = 8.922523369641436	bf = 7.764332893581674	zeta = 17.84504673928287	eta = 0.5
af = 8.922523369641436	bf = 7.764332893581674	zeta = 27.897909621457714	eta = 0.31982766776112376
af = 8.922523369641436	bf = 7.764332893581674	zeta = 26.369447091279792	eta = 0.3383659634104371
af = 8.922523369641436	bf = 7.764332893581674	zeta = 26.348436262074046	eta = 0.3386357839567322
af = 8.922523369641436	bf = 7.764332893581674	zeta = 26.34843197725868	eta = 0.3386358390261121
eta = 0.3386358390261121
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00285881 0.00948689 0.00349509 0.00268548 0.05465465 0.00511579
 0.01603975 0.00457005 0.00340792 0.00310341]
ene_total = [1.57087245 2.43049366 1.71705737 1.56874207 8.66573624 1.89418822
 3.41139512 1.86529449 1.63124995 1.59340241]
ti_comp = [0.06677087 0.0710199  0.06258467 0.06519124 0.07275179 0.06600964
 0.06576497 0.06263724 0.06790499 0.06759109]
ti_coms = [0.08476871 0.08051968 0.08895491 0.08634835 0.0787878  0.08552995
 0.08577462 0.08890235 0.0836346  0.08394849]
t_total = [21. 21. 21. 21. 21. 21. 21. 21. 21. 21.]
ene_coms = [0.00847687 0.00805197 0.00889549 0.00863483 0.00787878 0.00855299
 0.00857746 0.00889023 0.00836346 0.00839485]
ene_comp = [0.00285857 0.00948632 0.0034947  0.00268522 0.0546519  0.00511534
 0.0160383  0.00456954 0.00340766 0.00310317]
ene_total = [1.5708392  2.43041546 1.71700347 1.56870715 8.66535501 1.89412538
 3.41119466 1.86522425 1.63121353 1.59336845]
optimize_network_iter = 10 obj = 26.34744656525751
eta = 0.3386358390261121
freqs = [4.40755140e+08 6.44044637e+08 4.81567604e+08 4.35118041e+08
 1.14532974e+09 5.37154201e+08 7.87162842e+08 5.26449463e+08
 4.64723538e+08 4.51144156e+08]
Done!
optimize_network_fake num_local_rounds = 35.457354658795744	num_global_rounds = 138.57765390792997
iter = 0	num_local_rounds = 35.457354658795744	num_global_rounds = 138.57765390792997
Round 1
-------------------------------
gradient difference: 0.9868304133415222
At round 0 accuracy: 0.5993031358885017
At round 0 training accuracy: 0.5825932504440497
At round 0 training loss: 0.9196891057700395
Round 2
-------------------------------
gradient difference: 0.31714481115341187
At round 1 accuracy: 0.627177700348432
At round 1 training accuracy: 0.6119005328596803
At round 1 training loss: 0.8899210614100972
Round 3
-------------------------------
gradient difference: 0.3697069585323334
At round 2 accuracy: 0.6550522648083623
At round 2 training accuracy: 0.6154529307282416
At round 2 training loss: 0.8480973101190697
Round 4
-------------------------------
gradient difference: 0.2787511348724365
At round 3 accuracy: 0.6759581881533101
At round 3 training accuracy: 0.6234458259325044
At round 3 training loss: 0.8410131026798271
Round 5
-------------------------------
gradient difference: 0.3925393223762512
At round 4 accuracy: 0.6724738675958188
At round 4 training accuracy: 0.6341030195381883
At round 4 training loss: 0.8384586687745111
Round 6
-------------------------------
gradient difference: 0.23576688766479492
At round 5 accuracy: 0.6794425087108014
At round 5 training accuracy: 0.6376554174067496
At round 5 training loss: 0.8216234277311852
Round 7
-------------------------------
gradient difference: 0.44197624921798706
At round 6 accuracy: 0.6829268292682927
At round 6 training accuracy: 0.6412078152753108
At round 6 training loss: 0.7995617209246096
Round 8
-------------------------------
gradient difference: 0.34947913885116577
At round 7 accuracy: 0.6829268292682927
At round 7 training accuracy: 0.6420959147424512
At round 7 training loss: 0.81882992441407
Round 9
-------------------------------
gradient difference: 0.2978007197380066
At round 8 accuracy: 0.6898954703832753
At round 8 training accuracy: 0.6420959147424512
At round 8 training loss: 0.8139066896562908
Round 10
-------------------------------
gradient difference: 0.306811660528183
At round 9 accuracy: 0.6898954703832753
At round 9 training accuracy: 0.6465364120781527
At round 9 training loss: 0.801178046807982
Round 11
-------------------------------
gradient difference: 0.25892946124076843
At round 10 accuracy: 0.6898954703832753
At round 10 training accuracy: 0.6474245115452931
At round 10 training loss: 0.8007324057400155
Round 12
-------------------------------
gradient difference: 0.5946719646453857
At round 11 accuracy: 0.6898954703832753
At round 11 training accuracy: 0.6474245115452931
At round 11 training loss: 0.8106153249014951
Round 13
-------------------------------
gradient difference: 0.3681613802909851
At round 12 accuracy: 0.6898954703832753
At round 12 training accuracy: 0.6492007104795737
At round 12 training loss: 0.7985617015235096
Round 14
-------------------------------
gradient difference: 0.3118416965007782
At round 13 accuracy: 0.686411149825784
At round 13 training accuracy: 0.6527531083481349
At round 13 training loss: 0.8086425215885916
Round 15
-------------------------------
gradient difference: 0.3357599377632141
At round 14 accuracy: 0.686411149825784
At round 14 training accuracy: 0.6563055062166963
At round 14 training loss: 0.8118722368358172
Round 16
-------------------------------
gradient difference: 0.2747032344341278
At round 15 accuracy: 0.686411149825784
At round 15 training accuracy: 0.6563055062166963
At round 15 training loss: 0.8034490546088084
Round 17
-------------------------------
gradient difference: 0.4936350882053375
At round 16 accuracy: 0.686411149825784
At round 16 training accuracy: 0.6571936056838366
At round 16 training loss: 0.7949763174727338
Round 18
-------------------------------
gradient difference: 0.3204804062843323
At round 17 accuracy: 0.686411149825784
At round 17 training accuracy: 0.6571936056838366
At round 17 training loss: 0.8246352702582144
Round 19
-------------------------------
gradient difference: 0.3701605200767517
At round 18 accuracy: 0.6898954703832753
At round 18 training accuracy: 0.6589698046181173
At round 18 training loss: 0.8189924767678698
Round 20
-------------------------------
gradient difference: 0.3656390309333801
At round 19 accuracy: 0.6898954703832753
At round 19 training accuracy: 0.6607460035523979
At round 19 training loss: 0.8167057767530264
Round 21
-------------------------------
gradient difference: 0.4455067217350006
At round 20 accuracy: 0.6829268292682927
At round 20 training accuracy: 0.6598579040852576
At round 20 training loss: 0.809859199663806
Round 22
-------------------------------
gradient difference: 0.4480084776878357
At round 21 accuracy: 0.686411149825784
At round 21 training accuracy: 0.6607460035523979
At round 21 training loss: 0.7932051664131186
Round 23
-------------------------------
gradient difference: 0.2711714804172516
At round 22 accuracy: 0.6933797909407665
At round 22 training accuracy: 0.6642984014209592
At round 22 training loss: 0.8040037741898926
Round 24
-------------------------------
gradient difference: 0.34123408794403076
At round 23 accuracy: 0.6898954703832753
At round 23 training accuracy: 0.6607460035523979
At round 23 training loss: 0.8197716014983564
Round 25
-------------------------------
gradient difference: 0.3027462363243103
At round 24 accuracy: 0.6933797909407665
At round 24 training accuracy: 0.6634103019538188
At round 24 training loss: 0.7900868371389299
Round 26
-------------------------------
gradient difference: 0.27589917182922363
At round 25 accuracy: 0.6898954703832753
At round 25 training accuracy: 0.6607460035523979
At round 25 training loss: 0.812116694461186
Round 27
-------------------------------
gradient difference: 0.3254148066043854
At round 26 accuracy: 0.6933797909407665
At round 26 training accuracy: 0.6616341030195382
At round 26 training loss: 0.7860494936382438
Round 28
-------------------------------
gradient difference: 0.29617735743522644
At round 27 accuracy: 0.6933797909407665
At round 27 training accuracy: 0.6607460035523979
At round 27 training loss: 0.8411983982341716
Round 29
-------------------------------
gradient difference: 0.25161051750183105
At round 28 accuracy: 0.6933797909407665
At round 28 training accuracy: 0.6616341030195382
At round 28 training loss: 0.8074940313397074
Round 30
-------------------------------
gradient difference: 0.2649843990802765
At round 29 accuracy: 0.6933797909407665
At round 29 training accuracy: 0.6651865008880995
At round 29 training loss: 0.8025938725488259
Round 31
-------------------------------
gradient difference: 0.31207695603370667
At round 30 accuracy: 0.6933797909407665
At round 30 training accuracy: 0.6651865008880995
At round 30 training loss: 0.8196495803899053
Round 32
-------------------------------
gradient difference: 0.9111285209655762
At round 31 accuracy: 0.6933797909407665
At round 31 training accuracy: 0.6651865008880995
At round 31 training loss: 0.7905650368466522
Round 33
-------------------------------
gradient difference: 0.365477979183197
At round 32 accuracy: 0.6933797909407665
At round 32 training accuracy: 0.6642984014209592
At round 32 training loss: 0.8112635232759624
Round 34
-------------------------------
gradient difference: 0.29811710119247437
At round 33 accuracy: 0.6933797909407665
At round 33 training accuracy: 0.6634103019538188
At round 33 training loss: 0.8251283705479352
Round 35
-------------------------------
gradient difference: 0.28597861528396606
At round 34 accuracy: 0.6933797909407665
At round 34 training accuracy: 0.6634103019538188
At round 34 training loss: 0.7921559869793127
Done!
update_location
xs = [-493.9056584   479.20031788  515.00902392   18.81129433  460.97929623
  473.95640986    2.55680806   -6.32485185  499.66397685  -17.06087855]
ys = [  17.5879595    15.55583871    1.32061395 -477.45517586    9.35018685
  -17.18584926 -492.62498432  480.82234798   17.56900603  499.00148178]
dists_uav = [504.23420721 489.77028163 524.62942992 488.17753917 471.79374471
 484.69581375 502.67873681 491.15184421 509.87523938 509.2087513 ]
dists_bs = [355.6393812  673.35020344 711.53143446 680.63248109 657.19823937
 676.81594437 690.83249763 349.25436881 692.78856769 360.44656508]
uav_gains = [3.64260914e-13 3.94348189e-13 3.27481438e-13 3.97896753e-13
 4.37529010e-13 4.05830733e-13 3.67322769e-13 3.91310096e-13
 3.53480040e-13 3.54728092e-13]
bs_gains = [7.95181956e-12 1.33112640e-12 1.14064534e-12 1.29163144e-12
 1.42476812e-12 1.31212877e-12 1.23894024e-12 8.36559649e-12
 1.22917039e-12 7.65842723e-12]
ene_coms = [0.01145981 0.02376943 0.02582419 0.02414986 0.0229444  0.02394982
 0.02469171 0.0112803  0.02479683 0.01159627]
ene_comp = [0.25032247 0.38905541 0.25635434 0.24127467 0.70874434 0.30159334
 0.44032627 0.2804818  0.26841807 0.25937027]
ene_total = [24.23477019 38.21769453 26.12297453 24.57195569 67.73685675 30.13750109
 43.04952971 27.01018487 27.1446784  25.08501349]
obj_prev = 333.3111592311691
t_co_uav = [0.53786392 0.50759189 0.58221569 0.50431535 0.47123304 0.49719102
 0.53456273 0.51044297 0.54993092 0.54849738]
t_co_bs = [0.11459805 0.23769431 0.25824188 0.24149859 0.22944398 0.2394982
 0.24691706 0.11280305 0.24796828 0.11596273]
difference = [0.42326587 0.26989758 0.32397381 0.26281676 0.24178906 0.25769281
 0.28764568 0.39763992 0.30196264 0.43253465]
decs_opt = [0 0 0 0 0 0 0 0 0 0]
af = 16.896171935691484	bf = 187.39058616556858	zeta = 33.79234387138297	eta = 0.5
af = 16.896171935691484	bf = 187.39058616556858	zeta = 398.2042402100984	eta = 0.04243091918553357
af = 16.896171935691484	bf = 187.39058616556858	zeta = 251.4496679533076	eta = 0.0671950457251309
af = 16.896171935691484	bf = 187.39058616556858	zeta = 249.79807519939155	eta = 0.0676393199675569
af = 16.896171935691484	bf = 187.39058616556858	zeta = 249.79768256791135	eta = 0.06763942628289996
af = 16.896171935691484	bf = 187.39058616556858	zeta = 249.79768256788898	eta = 0.06763942628290602
eta_opt = 0.06763942628290602
solve_bound_eta tau = 65.0
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
solve_bound_eta tau = 37.5
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
solve_bound_eta tau = 23.75
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
solve_bound_eta tau = 30.625
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
solve_bound_eta tau = 34.0625
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
solve_bound_eta tau = 32.34375
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
solve_bound_eta tau = 33.203125
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
solve_bound_eta tau = 32.7734375
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
solve_bound_eta tau = 32.55859375
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
solve_bound_eta tau = 32.666015625
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
solve_bound_eta tau = 32.7197265625
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
solve_bound_eta tau = 32.74658203125
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
solve_bound_eta tau = 32.733154296875
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
solve_bound_eta tau = 32.7398681640625
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
solve_bound_eta tau = 32.74322509765625
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
solve_bound_eta tau = 32.741546630859375
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
initialize_feasible_solution eta = 0.06763942628290602, tau = 32.741546630859375
ti_comp = [0.03660341 0.05688963 0.03748542 0.03528039 0.10363615 0.04410049
 0.06438671 0.04101345 0.03924944 0.03792642]
ti_coms = [0.11459805 0.23769431 0.25824188 0.24149859 0.22944398 0.2394982
 0.24691706 0.11280305 0.24796828 0.11596273]
t_total = [14.86298168 28.9573641  29.06975551 27.20715144 32.74150848 27.87752292
 30.60091009 15.1200384  28.23327014 15.12717981]
optimize_network_fake eta = 0.06763942628290602	tau = 42	t_min = 32.741546630859375
solve_bound_eta tau = 42
af = [1.24545495 1.93570709 1.27546591 1.2004385  3.5262881  1.50054813
 2.19080027 1.39550976 1.33548784 1.29047139]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
eta_min = 0.0026986170626016946	eta_max = 0.40935331101911426
af = 67.58468774276595	bf = 18.739058616556857	zeta = 135.1693754855319	eta = 0.5
af = 67.58468774276595	bf = 18.739058616556857	zeta = 131.17038874895874	eta = 0.5152434813021202
af = 67.58468774276595	bf = 18.739058616556857	zeta = 131.10814278493507	eta = 0.5154881024714794
af = 67.58468774276595	bf = 18.739058616556857	zeta = 131.10812707399847	eta = 0.5154881642434005
eta = 0.5154881642434005
ene_coms = [0.01145981 0.02376943 0.02582419 0.02414986 0.0229444  0.02394982
 0.02469171 0.0112803  0.02479683 0.01159627]
ene_comp = [0.03601906 0.05598144 0.03688699 0.03471717 0.10198168 0.04339646
 0.06335883 0.04035871 0.03862285 0.03732096]
ene_total = [ 8.98110619 15.08567965 11.8624515  11.13529141 23.63102686 12.73922752
 16.65564646  9.76803965 11.99647103  9.2531868 ]
ti_comp = [0.15607387 0.03297761 0.01243004 0.02917333 0.04122794 0.03117372
 0.02375486 0.15786887 0.02270364 0.15470919]
ti_coms = [0.11459805 0.23769431 0.25824188 0.24149859 0.22944398 0.2394982
 0.24691706 0.11280305 0.24796828 0.11596273]
t_total = [42. 42. 42. 42. 42. 42. 42. 42. 42. 42.]
ene_coms = [0.01145981 0.02376943 0.02582419 0.02414986 0.0229444  0.02394982
 0.02469171 0.0112803  0.02479683 0.01159627]
ene_comp = [0.00029363 0.0246917  0.04972014 0.00752521 0.09550819 0.01287191
 0.06898804 0.00040372 0.017108   0.00033242]
ene_total = [ 1.82377288  7.51968516 11.7221684   4.91500094 18.38021672  5.7136062
 14.53623056  1.81300255  6.50234764  1.85096775]
optimize_network_iter = 0 obj = 74.77699879722674
eta = 0.40935331101911426
freqs = [1.55536145e+08 1.14407356e+09 2.00000000e+09 8.02024214e+08
 1.66709233e+09 9.38198684e+08 1.79756154e+09 1.72293888e+08
 1.14651026e+09 1.62579496e+08]
solve_bound_eta tau = 42
af = [16.01499058  3.38388571  1.27546591  2.99352185  4.23046528  3.19878541
  2.43752464 16.19917893  2.32965702 15.87495867]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
eta_min = 0.36296577646600475	eta_max = 0.409353311019114
af = 28.46886783346189	bf = 18.739058616556857	zeta = 56.93773566692378	eta = 0.5
af = 28.46886783346189	bf = 18.739058616556857	zeta = 76.94434817810937	eta = 0.36999296904254325
af = 28.46886783346189	bf = 18.739058616556857	zeta = 74.67350974687407	eta = 0.3812445394620497
af = 28.46886783346189	bf = 18.739058616556857	zeta = 74.65306922635729	eta = 0.38134892682229554
af = 28.46886783346189	bf = 18.739058616556857	zeta = 74.6530675020111	eta = 0.3813489356307423
eta = 0.3813489356307423
ene_coms = [0.01145981 0.02376943 0.02582419 0.02414986 0.0229444  0.02394982
 0.02469171 0.0112803  0.02479683 0.01159627]
ene_comp = [0.00031692 0.02665072 0.05366489 0.00812225 0.10308572 0.01389316
 0.07446149 0.00043575 0.01846534 0.00035879]
ene_total = [ 1.74466765  7.46951217 11.77593955  4.78096356 18.67077895  5.60626219
 14.68908754  1.73567883  6.40908963  1.77108744]
ti_comp = [0.16890725 0.045811   0.02526342 0.04200671 0.05406133 0.04400711
 0.03658825 0.17070226 0.03553703 0.16754258]
ti_coms = [0.11459805 0.23769431 0.25824188 0.24149859 0.22944398 0.2394982
 0.24691706 0.11280305 0.24796828 0.11596273]
t_total = [42. 42. 42. 42. 42. 42. 42. 42. 42. 42.]
ene_coms = [0.01145981 0.02376943 0.02582419 0.02414986 0.0229444  0.02394982
 0.02469171 0.0112803  0.02479683 0.01159627]
ene_comp = [0.00031523 0.0160888  0.01513444 0.0045638  0.06984321 0.00812173
 0.03656531 0.00043417 0.00878015 0.0003564 ]
ene_total = [ 1.74441746  5.90481238  6.06783158  4.25379578 13.74605458  4.75125136
  9.07494405  1.73544593  4.97427366  1.77073341]
optimize_network_iter = 1 obj = 54.023560182859335
eta = 0.3813489356307423
freqs = [1.55121189e+08 8.88917153e+08 1.06210650e+09 6.01191209e+08
 1.37221603e+09 7.17329222e+08 1.25965772e+09 1.71982800e+08
 7.90588041e+08 1.62037151e+08]
solve_bound_eta tau = 42
af = [16.05783137  4.35520246  2.40176651  3.99353313  5.13955243  4.18370835
  3.47840566 16.22848056  3.37846708 15.9280928 ]
bf = [10.50294522 21.78475322 23.66794456 22.13341711 21.02860811 21.95008049
 22.63002084 10.33843249 22.72636567 10.62801845]
eta_min = 0.3813489356307518	eta_max = 0.3813489356307163
af = 15.230350461815739	bf = 18.739058616556857	zeta = 30.460700923631478	eta = 0.5
af = 15.230350461815739	bf = 18.739058616556857	zeta = 58.5918661962086	eta = 0.25993967167410814
af = 15.230350461815739	bf = 18.739058616556857	zeta = 53.04837350335061	eta = 0.28710306190356183
af = 15.230350461815739	bf = 18.739058616556857	zeta = 52.94625993819006	eta = 0.28765677650500315
af = 15.230350461815739	bf = 18.739058616556857	zeta = 52.94622027651022	eta = 0.28765699198688105
eta = 0.28765699198688105
ene_coms = [0.01145981 0.02376943 0.02582419 0.02414986 0.0229444  0.02394982
 0.02469171 0.0112803  0.02479683 0.01159627]
ene_comp = [0.00040743 0.02079417 0.0195607  0.00589854 0.09026975 0.01049703
 0.04725931 0.00056115 0.01134801 0.00046064]
ene_total = [ 1.52684214  5.73356867  5.83923562  3.86603748 14.56617092  4.43194351
  9.25724205  1.52352617  4.65040778  1.55124593]
ti_comp = [0.16890725 0.045811   0.02526342 0.04200671 0.05406133 0.04400711
 0.03658825 0.17070226 0.03553703 0.16754258]
ti_coms = [0.11459805 0.23769431 0.25824188 0.24149859 0.22944398 0.2394982
 0.24691706 0.11280305 0.24796828 0.11596273]
t_total = [42. 42. 42. 42. 42. 42. 42. 42. 42. 42.]
ene_coms = [0.01145981 0.02376943 0.02582419 0.02414986 0.0229444  0.02394982
 0.02469171 0.0112803  0.02479683 0.01159627]
ene_comp = [0.00031523 0.0160888  0.01513444 0.0045638  0.06984321 0.00812173
 0.03656531 0.00043417 0.00878015 0.0003564 ]
ene_total = [ 1.74441746  5.90481238  6.06783158  4.25379578 13.74605458  4.75125136
  9.07494405  1.73544593  4.97427366  1.77073341]
optimize_network_iter = 2 obj = 54.02356018286326
eta = 0.3813489356307518
freqs = [1.55121189e+08 8.88917153e+08 1.06210650e+09 6.01191209e+08
 1.37221603e+09 7.17329222e+08 1.25965772e+09 1.71982800e+08
 7.90588041e+08 1.62037151e+08]
Done!
optimize_network_fake num_local_rounds = 31.56758327509822	num_global_rounds = 148.14537480831925
iter = 1	num_local_rounds = 31.56758327509822	num_global_rounds = 148.14537480831925
Round 1
-------------------------------
gradient difference: 0.2876749634742737
At round 0 accuracy: 0.6933797909407665
At round 0 training accuracy: 0.6651865008880995
At round 0 training loss: 0.8006223027282844
Round 2
-------------------------------
gradient difference: 0.7355552911758423
At round 1 accuracy: 0.6933797909407665
At round 1 training accuracy: 0.6660746003552398
At round 1 training loss: 0.8103649017422545
Round 3
-------------------------------
gradient difference: 0.3504113256931305
At round 2 accuracy: 0.6933797909407665
At round 2 training accuracy: 0.6642984014209592
At round 2 training loss: 0.8147615597064481
Round 4
-------------------------------
gradient difference: 0.30860427021980286
At round 3 accuracy: 0.6933797909407665
At round 3 training accuracy: 0.6642984014209592
At round 3 training loss: 0.8005334831297821
Round 5
-------------------------------
gradient difference: 0.46695685386657715
At round 4 accuracy: 0.6933797909407665
At round 4 training accuracy: 0.6660746003552398
At round 4 training loss: 0.8231090405039475
Round 6
-------------------------------
gradient difference: 0.32720667123794556
At round 5 accuracy: 0.6898954703832753
At round 5 training accuracy: 0.6669626998223801
At round 5 training loss: 0.8268384852152717
Round 7
-------------------------------
gradient difference: 0.3412333130836487
At round 6 accuracy: 0.6898954703832753
At round 6 training accuracy: 0.6678507992895204
At round 6 training loss: 0.8092179198162118
Round 8
-------------------------------
gradient difference: 0.28603655099868774
At round 7 accuracy: 0.6898954703832753
At round 7 training accuracy: 0.6678507992895204
At round 7 training loss: 0.8039888500514434
Round 9
-------------------------------
gradient difference: 0.34338098764419556
At round 8 accuracy: 0.6933797909407665
At round 8 training accuracy: 0.6669626998223801
At round 8 training loss: 0.7975714562574371
Round 10
-------------------------------
gradient difference: 0.3969328999519348
At round 9 accuracy: 0.6933797909407665
At round 9 training accuracy: 0.6669626998223801
At round 9 training loss: 0.8172789268347818
Round 11
-------------------------------
gradient difference: 0.44240379333496094
At round 10 accuracy: 0.6933797909407665
At round 10 training accuracy: 0.6669626998223801
At round 10 training loss: 0.8018334663067788
Round 12
-------------------------------
gradient difference: 0.34268900752067566
At round 11 accuracy: 0.6898954703832753
At round 11 training accuracy: 0.6669626998223801
At round 11 training loss: 0.7933215945745146
Round 13
-------------------------------
gradient difference: 0.22318799793720245
At round 12 accuracy: 0.6898954703832753
At round 12 training accuracy: 0.6669626998223801
At round 12 training loss: 0.8093191588389018
Round 14
-------------------------------
gradient difference: 0.7512893676757812
At round 13 accuracy: 0.6898954703832753
At round 13 training accuracy: 0.6660746003552398
At round 13 training loss: 0.8164224941309932
Round 15
-------------------------------
gradient difference: 0.455753892660141
At round 14 accuracy: 0.6898954703832753
At round 14 training accuracy: 0.6660746003552398
At round 14 training loss: 0.7913809043334885
Round 16
-------------------------------
gradient difference: 0.8481898307800293
At round 15 accuracy: 0.6898954703832753
At round 15 training accuracy: 0.6669626998223801
At round 15 training loss: 0.797680369955132
Round 17
-------------------------------
gradient difference: 0.34706544876098633
At round 16 accuracy: 0.6898954703832753
At round 16 training accuracy: 0.6660746003552398
At round 16 training loss: 0.7961806999559168
Round 18
-------------------------------
gradient difference: 0.4611237645149231
At round 17 accuracy: 0.686411149825784
At round 17 training accuracy: 0.6687388987566607
At round 17 training loss: 0.7941392978995182
Round 19
-------------------------------
gradient difference: 0.6883460283279419
At round 18 accuracy: 0.686411149825784
At round 18 training accuracy: 0.6669626998223801
At round 18 training loss: 0.7951276523620772
Round 20
-------------------------------
gradient difference: 0.3200618326663971
At round 19 accuracy: 0.686411149825784
At round 19 training accuracy: 0.6669626998223801
At round 19 training loss: 0.7994013891625398
Round 21
-------------------------------
gradient difference: 0.33961862325668335
At round 20 accuracy: 0.686411149825784
At round 20 training accuracy: 0.6687388987566607
At round 20 training loss: 0.803949876516934
Round 22
-------------------------------
gradient difference: 0.9701005220413208
At round 21 accuracy: 0.6829268292682927
At round 21 training accuracy: 0.6669626998223801
At round 21 training loss: 0.8026881304180803
Round 23
-------------------------------
gradient difference: 0.39946916699409485
At round 22 accuracy: 0.6829268292682927
At round 22 training accuracy: 0.6669626998223801
At round 22 training loss: 0.7933619375486762
Round 24
-------------------------------
gradient difference: 0.2041877806186676
At round 23 accuracy: 0.6829268292682927
At round 23 training accuracy: 0.6687388987566607
At round 23 training loss: 0.7817517860192098
Round 25
-------------------------------
gradient difference: 0.35958966612815857
At round 24 accuracy: 0.6829268292682927
At round 24 training accuracy: 0.6660746003552398
At round 24 training loss: 0.8002118543712361
Round 26
-------------------------------
gradient difference: 0.41875022649765015
At round 25 accuracy: 0.6794425087108014
At round 25 training accuracy: 0.6651865008880995
At round 25 training loss: 0.8258795923617921
Round 27
-------------------------------
gradient difference: 0.4781290888786316
At round 26 accuracy: 0.6794425087108014
At round 26 training accuracy: 0.6651865008880995
At round 26 training loss: 0.7941853359319565
Round 28
-------------------------------
gradient difference: 0.8228022456169128
At round 27 accuracy: 0.6829268292682927
At round 27 training accuracy: 0.6634103019538188
At round 27 training loss: 0.829257773515554
Round 29
-------------------------------
gradient difference: 0.5164240002632141
At round 28 accuracy: 0.6829268292682927
At round 28 training accuracy: 0.6642984014209592
At round 28 training loss: 0.8045136831222183
Round 30
-------------------------------
gradient difference: 0.5169561505317688
At round 29 accuracy: 0.6794425087108014
At round 29 training accuracy: 0.6625222024866785
At round 29 training loss: 0.8046118712702257
Round 31
-------------------------------
gradient difference: 0.29227888584136963
At round 30 accuracy: 0.6829268292682927
At round 30 training accuracy: 0.6625222024866785
At round 30 training loss: 0.8374954653201352
Done!
update_location
xs = [-493.9056584   -20.79968212 1015.00902392   18.81129433  460.97929623
  -26.04359014  502.55680806 -506.32485185  999.66397685  482.93912145]
ys = [ 517.5879595    15.55583871    1.32061395 -977.45517586 -490.64981315
  -17.18584926 -492.62498432  480.82234798   17.56900603  499.00148178]
dists_uav = [ 722.38500484  103.31800857 1019.92404749  982.73724139  680.61674289
  104.75505717  710.80427721  705.37577639 1004.80681555  701.59295453]
dists_bs = [ 468.04628933  221.81113273 1202.61631709 1168.63841721  920.62985992
  243.15306433  951.21309276  450.89185619 1185.16664498  733.38996975]
uav_gains = [1.43676383e-13 9.21631668e-11 6.03478381e-14 6.62375393e-14
 1.67080995e-13 8.90347214e-11 1.49673614e-13 1.52607570e-13
 6.26498031e-14 1.54700579e-13]
bs_gains = [3.68540675e-12 2.98222725e-11 2.62384531e-13 2.84308367e-13
 5.54441751e-13 2.30584863e-11 5.05960008e-13 4.09158323e-12
 2.73345361e-13 1.04798769e-12]
Done!
